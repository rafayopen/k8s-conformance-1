I1221 01:25:17.008205      22 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-448192630
I1221 01:25:17.008310      22 e2e.go:92] Starting e2e run "568d324f-6762-4fa7-b52f-35eb163af0a2" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1576891515 - Will randomize all specs
Will run 276 of 4732 specs

Dec 21 01:25:17.029: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 01:25:17.031: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec 21 01:25:17.051: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec 21 01:25:17.074: INFO: The status of Pod helm-install-traefik-hhwxg is Succeeded, skipping waiting
Dec 21 01:25:17.074: INFO: 7 / 8 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec 21 01:25:17.074: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Dec 21 01:25:17.074: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec 21 01:25:17.080: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'svclb-traefik' (0 seconds elapsed)
Dec 21 01:25:17.080: INFO: e2e test version: v1.16.3
Dec 21 01:25:17.081: INFO: kube-apiserver version: v1.16.3-k3s.2
Dec 21 01:25:17.081: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 01:25:17.085: INFO: Cluster IP family: ipv4
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:25:17.086: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename daemonsets
Dec 21 01:25:17.111: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 01:25:17.128: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec 21 01:25:17.137: INFO: Number of nodes with available pods: 0
Dec 21 01:25:17.137: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec 21 01:25:17.148: INFO: Number of nodes with available pods: 0
Dec 21 01:25:17.148: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:25:18.151: INFO: Number of nodes with available pods: 0
Dec 21 01:25:18.151: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:25:19.151: INFO: Number of nodes with available pods: 0
Dec 21 01:25:19.151: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:25:20.151: INFO: Number of nodes with available pods: 0
Dec 21 01:25:20.151: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:25:21.151: INFO: Number of nodes with available pods: 0
Dec 21 01:25:21.151: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:25:22.152: INFO: Number of nodes with available pods: 0
Dec 21 01:25:22.152: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:25:23.151: INFO: Number of nodes with available pods: 0
Dec 21 01:25:23.151: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:25:24.151: INFO: Number of nodes with available pods: 0
Dec 21 01:25:24.151: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:25:25.151: INFO: Number of nodes with available pods: 0
Dec 21 01:25:25.151: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:25:26.151: INFO: Number of nodes with available pods: 0
Dec 21 01:25:26.151: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:25:27.155: INFO: Number of nodes with available pods: 0
Dec 21 01:25:27.155: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:25:28.151: INFO: Number of nodes with available pods: 1
Dec 21 01:25:28.151: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec 21 01:25:28.162: INFO: Number of nodes with available pods: 1
Dec 21 01:25:28.162: INFO: Number of running nodes: 0, number of available pods: 1
Dec 21 01:25:29.165: INFO: Number of nodes with available pods: 0
Dec 21 01:25:29.165: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec 21 01:25:29.170: INFO: Number of nodes with available pods: 0
Dec 21 01:25:29.170: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:25:30.173: INFO: Number of nodes with available pods: 0
Dec 21 01:25:30.173: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:25:31.173: INFO: Number of nodes with available pods: 0
Dec 21 01:25:31.173: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:25:32.173: INFO: Number of nodes with available pods: 0
Dec 21 01:25:32.173: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:25:33.173: INFO: Number of nodes with available pods: 0
Dec 21 01:25:33.173: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:25:34.173: INFO: Number of nodes with available pods: 0
Dec 21 01:25:34.173: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:25:35.179: INFO: Number of nodes with available pods: 0
Dec 21 01:25:35.179: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:25:36.173: INFO: Number of nodes with available pods: 1
Dec 21 01:25:36.173: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8891, will wait for the garbage collector to delete the pods
Dec 21 01:25:36.237: INFO: Deleting DaemonSet.extensions daemon-set took: 7.60693ms
Dec 21 01:25:36.637: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.289278ms
Dec 21 01:25:43.440: INFO: Number of nodes with available pods: 0
Dec 21 01:25:43.440: INFO: Number of running nodes: 0, number of available pods: 0
Dec 21 01:25:43.444: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8891/daemonsets","resourceVersion":"3211"},"items":null}

Dec 21 01:25:43.446: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8891/pods","resourceVersion":"3211"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:25:43.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8891" for this suite.
Dec 21 01:25:49.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:25:49.565: INFO: namespace daemonsets-8891 deletion completed in 6.104553494s

â€¢ [SLOW TEST:32.479 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:25:49.565: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-291f556c-351f-473e-93ac-fc5c7b484075 in namespace container-probe-9665
Dec 21 01:25:53.601: INFO: Started pod busybox-291f556c-351f-473e-93ac-fc5c7b484075 in namespace container-probe-9665
STEP: checking the pod's current state and verifying that restartCount is present
Dec 21 01:25:53.603: INFO: Initial restart count of pod busybox-291f556c-351f-473e-93ac-fc5c7b484075 is 0
Dec 21 01:26:39.674: INFO: Restart count of pod container-probe-9665/busybox-291f556c-351f-473e-93ac-fc5c7b484075 is now 1 (46.070741971s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:26:39.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9665" for this suite.
Dec 21 01:26:45.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:26:45.766: INFO: namespace container-probe-9665 deletion completed in 6.082735202s

â€¢ [SLOW TEST:56.201 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:26:45.766: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-63e040dd-e9bc-4635-a0a6-a12eb9e465b1
STEP: Creating a pod to test consume secrets
Dec 21 01:26:45.795: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1db781ab-993c-4775-a9ab-3d2a2e5ea4d6" in namespace "projected-8855" to be "success or failure"
Dec 21 01:26:45.799: INFO: Pod "pod-projected-secrets-1db781ab-993c-4775-a9ab-3d2a2e5ea4d6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.380254ms
Dec 21 01:26:47.801: INFO: Pod "pod-projected-secrets-1db781ab-993c-4775-a9ab-3d2a2e5ea4d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005582262s
Dec 21 01:26:49.804: INFO: Pod "pod-projected-secrets-1db781ab-993c-4775-a9ab-3d2a2e5ea4d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00857464s
STEP: Saw pod success
Dec 21 01:26:49.804: INFO: Pod "pod-projected-secrets-1db781ab-993c-4775-a9ab-3d2a2e5ea4d6" satisfied condition "success or failure"
Dec 21 01:26:49.806: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-projected-secrets-1db781ab-993c-4775-a9ab-3d2a2e5ea4d6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 21 01:26:49.826: INFO: Waiting for pod pod-projected-secrets-1db781ab-993c-4775-a9ab-3d2a2e5ea4d6 to disappear
Dec 21 01:26:49.831: INFO: Pod pod-projected-secrets-1db781ab-993c-4775-a9ab-3d2a2e5ea4d6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:26:49.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8855" for this suite.
Dec 21 01:26:55.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:26:55.916: INFO: namespace projected-8855 deletion completed in 6.082655742s

â€¢ [SLOW TEST:10.150 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:26:55.916: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-fa0ed6ae-3d58-4d7b-a027-a390d27179a8
STEP: Creating a pod to test consume secrets
Dec 21 01:26:55.948: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-35abc989-5ccb-4bf4-b218-d9e83374f928" in namespace "projected-4460" to be "success or failure"
Dec 21 01:26:55.950: INFO: Pod "pod-projected-secrets-35abc989-5ccb-4bf4-b218-d9e83374f928": Phase="Pending", Reason="", readiness=false. Elapsed: 2.315327ms
Dec 21 01:26:57.953: INFO: Pod "pod-projected-secrets-35abc989-5ccb-4bf4-b218-d9e83374f928": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005188542s
STEP: Saw pod success
Dec 21 01:26:57.953: INFO: Pod "pod-projected-secrets-35abc989-5ccb-4bf4-b218-d9e83374f928" satisfied condition "success or failure"
Dec 21 01:26:57.955: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-projected-secrets-35abc989-5ccb-4bf4-b218-d9e83374f928 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 21 01:26:57.966: INFO: Waiting for pod pod-projected-secrets-35abc989-5ccb-4bf4-b218-d9e83374f928 to disappear
Dec 21 01:26:57.969: INFO: Pod pod-projected-secrets-35abc989-5ccb-4bf4-b218-d9e83374f928 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:26:57.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4460" for this suite.
Dec 21 01:27:03.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:27:04.059: INFO: namespace projected-4460 deletion completed in 6.087528195s

â€¢ [SLOW TEST:8.143 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:27:04.061: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 21 01:27:04.088: INFO: Waiting up to 5m0s for pod "pod-4207d9cf-0cd2-4aaa-b8f4-69149396da2c" in namespace "emptydir-7786" to be "success or failure"
Dec 21 01:27:04.091: INFO: Pod "pod-4207d9cf-0cd2-4aaa-b8f4-69149396da2c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.179969ms
Dec 21 01:27:06.094: INFO: Pod "pod-4207d9cf-0cd2-4aaa-b8f4-69149396da2c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005087894s
STEP: Saw pod success
Dec 21 01:27:06.094: INFO: Pod "pod-4207d9cf-0cd2-4aaa-b8f4-69149396da2c" satisfied condition "success or failure"
Dec 21 01:27:06.095: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-4207d9cf-0cd2-4aaa-b8f4-69149396da2c container test-container: <nil>
STEP: delete the pod
Dec 21 01:27:06.108: INFO: Waiting for pod pod-4207d9cf-0cd2-4aaa-b8f4-69149396da2c to disappear
Dec 21 01:27:06.112: INFO: Pod pod-4207d9cf-0cd2-4aaa-b8f4-69149396da2c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:27:06.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7786" for this suite.
Dec 21 01:27:12.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:27:12.216: INFO: namespace emptydir-7786 deletion completed in 6.101136911s

â€¢ [SLOW TEST:8.155 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:27:12.217: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 01:27:16.278: INFO: Waiting up to 5m0s for pod "client-envvars-c6b100d4-3b98-4a56-8311-cf3d0ee69c3e" in namespace "pods-8442" to be "success or failure"
Dec 21 01:27:16.285: INFO: Pod "client-envvars-c6b100d4-3b98-4a56-8311-cf3d0ee69c3e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.926005ms
Dec 21 01:27:18.289: INFO: Pod "client-envvars-c6b100d4-3b98-4a56-8311-cf3d0ee69c3e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011393379s
Dec 21 01:27:20.300: INFO: Pod "client-envvars-c6b100d4-3b98-4a56-8311-cf3d0ee69c3e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02229806s
STEP: Saw pod success
Dec 21 01:27:20.300: INFO: Pod "client-envvars-c6b100d4-3b98-4a56-8311-cf3d0ee69c3e" satisfied condition "success or failure"
Dec 21 01:27:20.302: INFO: Trying to get logs from node ip-172-31-25-252 pod client-envvars-c6b100d4-3b98-4a56-8311-cf3d0ee69c3e container env3cont: <nil>
STEP: delete the pod
Dec 21 01:27:20.319: INFO: Waiting for pod client-envvars-c6b100d4-3b98-4a56-8311-cf3d0ee69c3e to disappear
Dec 21 01:27:20.322: INFO: Pod client-envvars-c6b100d4-3b98-4a56-8311-cf3d0ee69c3e no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:27:20.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8442" for this suite.
Dec 21 01:27:32.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:27:32.416: INFO: namespace pods-8442 deletion completed in 12.091942464s

â€¢ [SLOW TEST:20.200 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:27:32.417: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:27:39.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3451" for this suite.
Dec 21 01:27:45.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:27:45.535: INFO: namespace resourcequota-3451 deletion completed in 6.083228881s

â€¢ [SLOW TEST:13.118 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:27:45.537: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Dec 21 01:27:45.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 api-versions'
Dec 21 01:27:45.659: INFO: stderr: ""
Dec 21 01:27:45.659: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nhelm.cattle.io/v1\nk3s.cattle.io/v1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:27:45.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8901" for this suite.
Dec 21 01:27:51.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:27:51.746: INFO: namespace kubectl-8901 deletion completed in 6.083416103s

â€¢ [SLOW TEST:6.209 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:27:51.747: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Dec 21 01:27:51.782: INFO: Waiting up to 5m0s for pod "pod-26652574-9673-4e37-ab46-f879c33d210e" in namespace "emptydir-9701" to be "success or failure"
Dec 21 01:27:51.785: INFO: Pod "pod-26652574-9673-4e37-ab46-f879c33d210e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.618456ms
Dec 21 01:27:53.788: INFO: Pod "pod-26652574-9673-4e37-ab46-f879c33d210e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005598351s
STEP: Saw pod success
Dec 21 01:27:53.788: INFO: Pod "pod-26652574-9673-4e37-ab46-f879c33d210e" satisfied condition "success or failure"
Dec 21 01:27:53.790: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-26652574-9673-4e37-ab46-f879c33d210e container test-container: <nil>
STEP: delete the pod
Dec 21 01:27:53.801: INFO: Waiting for pod pod-26652574-9673-4e37-ab46-f879c33d210e to disappear
Dec 21 01:27:53.803: INFO: Pod pod-26652574-9673-4e37-ab46-f879c33d210e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:27:53.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9701" for this suite.
Dec 21 01:27:59.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:27:59.925: INFO: namespace emptydir-9701 deletion completed in 6.118660734s

â€¢ [SLOW TEST:8.178 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:27:59.925: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Dec 21 01:27:59.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 --namespace=kubectl-9556 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec 21 01:28:02.314: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec 21 01:28:02.314: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:28:04.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9556" for this suite.
Dec 21 01:28:10.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:28:10.406: INFO: namespace kubectl-9556 deletion completed in 6.084964278s

â€¢ [SLOW TEST:10.481 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:28:10.406: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-8447/configmap-test-45f581e8-a755-4a1b-baf9-87473b3ccfba
STEP: Creating a pod to test consume configMaps
Dec 21 01:28:10.435: INFO: Waiting up to 5m0s for pod "pod-configmaps-bdc17669-aefb-4583-b9ad-3d4955dcfcf2" in namespace "configmap-8447" to be "success or failure"
Dec 21 01:28:10.438: INFO: Pod "pod-configmaps-bdc17669-aefb-4583-b9ad-3d4955dcfcf2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.341889ms
Dec 21 01:28:12.440: INFO: Pod "pod-configmaps-bdc17669-aefb-4583-b9ad-3d4955dcfcf2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004908585s
STEP: Saw pod success
Dec 21 01:28:12.440: INFO: Pod "pod-configmaps-bdc17669-aefb-4583-b9ad-3d4955dcfcf2" satisfied condition "success or failure"
Dec 21 01:28:12.442: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-configmaps-bdc17669-aefb-4583-b9ad-3d4955dcfcf2 container env-test: <nil>
STEP: delete the pod
Dec 21 01:28:12.453: INFO: Waiting for pod pod-configmaps-bdc17669-aefb-4583-b9ad-3d4955dcfcf2 to disappear
Dec 21 01:28:12.455: INFO: Pod pod-configmaps-bdc17669-aefb-4583-b9ad-3d4955dcfcf2 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:28:12.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8447" for this suite.
Dec 21 01:28:18.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:28:18.544: INFO: namespace configmap-8447 deletion completed in 6.08628681s

â€¢ [SLOW TEST:8.138 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:28:18.544: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 21 01:28:20.583: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:28:20.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5628" for this suite.
Dec 21 01:28:26.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:28:26.684: INFO: namespace container-runtime-5628 deletion completed in 6.083601324s

â€¢ [SLOW TEST:8.140 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:28:26.685: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Dec 21 01:28:26.713: INFO: Waiting up to 5m0s for pod "client-containers-3bb18c60-397d-4f9a-8ca8-14dbd06acd52" in namespace "containers-6120" to be "success or failure"
Dec 21 01:28:26.720: INFO: Pod "client-containers-3bb18c60-397d-4f9a-8ca8-14dbd06acd52": Phase="Pending", Reason="", readiness=false. Elapsed: 7.615127ms
Dec 21 01:28:28.723: INFO: Pod "client-containers-3bb18c60-397d-4f9a-8ca8-14dbd06acd52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010434957s
STEP: Saw pod success
Dec 21 01:28:28.723: INFO: Pod "client-containers-3bb18c60-397d-4f9a-8ca8-14dbd06acd52" satisfied condition "success or failure"
Dec 21 01:28:28.725: INFO: Trying to get logs from node ip-172-31-29-169 pod client-containers-3bb18c60-397d-4f9a-8ca8-14dbd06acd52 container test-container: <nil>
STEP: delete the pod
Dec 21 01:28:28.737: INFO: Waiting for pod client-containers-3bb18c60-397d-4f9a-8ca8-14dbd06acd52 to disappear
Dec 21 01:28:28.741: INFO: Pod client-containers-3bb18c60-397d-4f9a-8ca8-14dbd06acd52 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:28:28.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6120" for this suite.
Dec 21 01:28:34.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:28:34.831: INFO: namespace containers-6120 deletion completed in 6.087313933s

â€¢ [SLOW TEST:8.146 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:28:34.831: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-4711
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 21 01:28:34.854: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 21 01:28:58.928: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.2.7:8080/dial?request=hostName&protocol=udp&host=10.42.1.14&port=8081&tries=1'] Namespace:pod-network-test-4711 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 01:28:58.928: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 01:28:58.996: INFO: Waiting for endpoints: map[]
Dec 21 01:28:58.998: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.2.7:8080/dial?request=hostName&protocol=udp&host=10.42.0.9&port=8081&tries=1'] Namespace:pod-network-test-4711 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 01:28:58.998: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 01:28:59.067: INFO: Waiting for endpoints: map[]
Dec 21 01:28:59.070: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.2.7:8080/dial?request=hostName&protocol=udp&host=10.42.2.6&port=8081&tries=1'] Namespace:pod-network-test-4711 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 01:28:59.070: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 01:28:59.136: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:28:59.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4711" for this suite.
Dec 21 01:29:27.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:29:27.239: INFO: namespace pod-network-test-4711 deletion completed in 28.099227694s

â€¢ [SLOW TEST:52.408 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:29:27.239: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec 21 01:29:29.288: INFO: &Pod{ObjectMeta:{send-events-3c07a0c9-9167-4435-95b3-71b360ff59db  events-1292 /api/v1/namespaces/events-1292/pods/send-events-3c07a0c9-9167-4435-95b3-71b360ff59db 83d2553e-cc42-4317-941a-78d7f4821514 3868 0 2019-12-21 01:29:27 +0000 UTC <nil> <nil> map[name:foo time:271348390] map[] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-k4f8k,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-k4f8k,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-k4f8k,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-169,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 01:29:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 01:29:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 01:29:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 01:29:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.169,PodIP:10.42.1.15,StartTime:2019-12-21 01:29:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-21 01:29:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:containerd://5ff6436c2e2b4ec2dd418097fa301e72e5ee7cc72f331002a9594f3a302d7f0d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.15,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Dec 21 01:29:31.292: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec 21 01:29:33.295: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:29:33.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1292" for this suite.
Dec 21 01:30:17.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:30:17.418: INFO: namespace events-1292 deletion completed in 44.114682897s

â€¢ [SLOW TEST:50.179 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:30:17.418: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:30:21.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-887" for this suite.
Dec 21 01:30:27.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:30:27.968: INFO: namespace watch-887 deletion completed in 6.194505596s

â€¢ [SLOW TEST:10.550 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:30:27.968: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 21 01:30:27.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-179'
Dec 21 01:30:28.085: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 21 01:30:28.085: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Dec 21 01:30:30.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 delete deployment e2e-test-httpd-deployment --namespace=kubectl-179'
Dec 21 01:30:30.180: INFO: stderr: ""
Dec 21 01:30:30.180: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:30:30.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-179" for this suite.
Dec 21 01:30:36.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:30:36.278: INFO: namespace kubectl-179 deletion completed in 6.093929236s

â€¢ [SLOW TEST:8.310 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:30:36.279: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:30:38.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3166" for this suite.
Dec 21 01:30:46.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:30:46.421: INFO: namespace containers-3166 deletion completed in 8.086085955s

â€¢ [SLOW TEST:10.142 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:30:46.421: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:30:46.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8591" for this suite.
Dec 21 01:30:52.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:30:52.575: INFO: namespace services-8591 deletion completed in 6.126532272s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:6.155 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:30:52.576: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec 21 01:30:53.092: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Dec 21 01:30:55.100: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712488653, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712488653, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712488653, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712488653, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 01:30:58.109: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 01:30:58.112: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:31:00.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-1348" for this suite.
Dec 21 01:31:06.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:31:06.318: INFO: namespace crd-webhook-1348 deletion completed in 6.096018321s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

â€¢ [SLOW TEST:13.753 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:31:06.330: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 01:31:06.943: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 21 01:31:08.950: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712488666, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712488666, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712488666, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712488666, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 01:31:11.965: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:31:27.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5185" for this suite.
Dec 21 01:31:33.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:31:33.240: INFO: namespace webhook-5185 deletion completed in 6.096208588s
STEP: Destroying namespace "webhook-5185-markers" for this suite.
Dec 21 01:31:39.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:31:39.348: INFO: namespace webhook-5185-markers deletion completed in 6.107830431s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:33.030 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:31:39.360: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Dec 21 01:31:39.384: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:31:57.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9223" for this suite.
Dec 21 01:32:03.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:32:03.643: INFO: namespace crd-publish-openapi-9223 deletion completed in 6.115341705s

â€¢ [SLOW TEST:24.283 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:32:03.643: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 21 01:32:03.686: INFO: Waiting up to 5m0s for pod "pod-03cf9936-b0ef-4f0d-8b16-b943214d1c0f" in namespace "emptydir-701" to be "success or failure"
Dec 21 01:32:03.689: INFO: Pod "pod-03cf9936-b0ef-4f0d-8b16-b943214d1c0f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.0374ms
Dec 21 01:32:05.692: INFO: Pod "pod-03cf9936-b0ef-4f0d-8b16-b943214d1c0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005722741s
STEP: Saw pod success
Dec 21 01:32:05.692: INFO: Pod "pod-03cf9936-b0ef-4f0d-8b16-b943214d1c0f" satisfied condition "success or failure"
Dec 21 01:32:05.695: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-03cf9936-b0ef-4f0d-8b16-b943214d1c0f container test-container: <nil>
STEP: delete the pod
Dec 21 01:32:05.722: INFO: Waiting for pod pod-03cf9936-b0ef-4f0d-8b16-b943214d1c0f to disappear
Dec 21 01:32:05.725: INFO: Pod pod-03cf9936-b0ef-4f0d-8b16-b943214d1c0f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:32:05.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-701" for this suite.
Dec 21 01:32:11.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:32:11.824: INFO: namespace emptydir-701 deletion completed in 6.09642984s

â€¢ [SLOW TEST:8.181 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:32:11.825: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 01:32:12.530: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 21 01:32:14.538: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712488732, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712488732, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712488732, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712488732, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 01:32:17.547: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 01:32:17.550: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-282-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:32:19.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8295" for this suite.
Dec 21 01:32:25.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:32:25.335: INFO: namespace webhook-8295 deletion completed in 6.102185015s
STEP: Destroying namespace "webhook-8295-markers" for this suite.
Dec 21 01:32:31.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:32:31.436: INFO: namespace webhook-8295-markers deletion completed in 6.101038757s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:19.623 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:32:31.449: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 01:32:31.486: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec 21 01:32:31.495: INFO: Number of nodes with available pods: 0
Dec 21 01:32:31.495: INFO: Node ip-172-31-25-252 is running more than one daemon pod
Dec 21 01:32:32.503: INFO: Number of nodes with available pods: 0
Dec 21 01:32:32.503: INFO: Node ip-172-31-25-252 is running more than one daemon pod
Dec 21 01:32:33.501: INFO: Number of nodes with available pods: 1
Dec 21 01:32:33.502: INFO: Node ip-172-31-25-252 is running more than one daemon pod
Dec 21 01:32:34.501: INFO: Number of nodes with available pods: 2
Dec 21 01:32:34.501: INFO: Node ip-172-31-25-252 is running more than one daemon pod
Dec 21 01:32:35.502: INFO: Number of nodes with available pods: 2
Dec 21 01:32:35.502: INFO: Node ip-172-31-25-252 is running more than one daemon pod
Dec 21 01:32:36.502: INFO: Number of nodes with available pods: 2
Dec 21 01:32:36.502: INFO: Node ip-172-31-25-252 is running more than one daemon pod
Dec 21 01:32:37.502: INFO: Number of nodes with available pods: 3
Dec 21 01:32:37.502: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec 21 01:32:37.528: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:37.528: INFO: Wrong image for pod: daemon-set-lv6bq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:37.528: INFO: Wrong image for pod: daemon-set-2f79c. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:38.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:38.539: INFO: Wrong image for pod: daemon-set-lv6bq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:38.539: INFO: Wrong image for pod: daemon-set-2f79c. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:39.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:39.539: INFO: Wrong image for pod: daemon-set-lv6bq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:39.539: INFO: Wrong image for pod: daemon-set-2f79c. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:40.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:40.539: INFO: Wrong image for pod: daemon-set-lv6bq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:40.539: INFO: Wrong image for pod: daemon-set-2f79c. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:40.539: INFO: Pod daemon-set-2f79c is not available
Dec 21 01:32:41.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:41.539: INFO: Wrong image for pod: daemon-set-lv6bq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:41.539: INFO: Wrong image for pod: daemon-set-2f79c. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:41.539: INFO: Pod daemon-set-2f79c is not available
Dec 21 01:32:42.538: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:42.538: INFO: Wrong image for pod: daemon-set-lv6bq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:42.538: INFO: Wrong image for pod: daemon-set-2f79c. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:42.538: INFO: Pod daemon-set-2f79c is not available
Dec 21 01:32:43.538: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:43.539: INFO: Wrong image for pod: daemon-set-lv6bq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:43.539: INFO: Wrong image for pod: daemon-set-2f79c. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:43.539: INFO: Pod daemon-set-2f79c is not available
Dec 21 01:32:44.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:44.539: INFO: Wrong image for pod: daemon-set-lv6bq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:44.539: INFO: Wrong image for pod: daemon-set-2f79c. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:44.539: INFO: Pod daemon-set-2f79c is not available
Dec 21 01:32:45.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:45.539: INFO: Wrong image for pod: daemon-set-lv6bq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:45.539: INFO: Wrong image for pod: daemon-set-2f79c. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:45.539: INFO: Pod daemon-set-2f79c is not available
Dec 21 01:32:46.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:46.539: INFO: Wrong image for pod: daemon-set-lv6bq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:46.539: INFO: Wrong image for pod: daemon-set-2f79c. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:46.539: INFO: Pod daemon-set-2f79c is not available
Dec 21 01:32:47.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:47.539: INFO: Wrong image for pod: daemon-set-lv6bq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:47.539: INFO: Wrong image for pod: daemon-set-2f79c. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:47.539: INFO: Pod daemon-set-2f79c is not available
Dec 21 01:32:48.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:48.539: INFO: Wrong image for pod: daemon-set-lv6bq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:48.539: INFO: Wrong image for pod: daemon-set-2f79c. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:48.539: INFO: Pod daemon-set-2f79c is not available
Dec 21 01:32:49.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:49.539: INFO: Wrong image for pod: daemon-set-lv6bq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:49.539: INFO: Wrong image for pod: daemon-set-2f79c. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:49.539: INFO: Pod daemon-set-2f79c is not available
Dec 21 01:32:50.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:50.539: INFO: Wrong image for pod: daemon-set-lv6bq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:50.539: INFO: Wrong image for pod: daemon-set-2f79c. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:50.539: INFO: Pod daemon-set-2f79c is not available
Dec 21 01:32:51.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:51.539: INFO: Wrong image for pod: daemon-set-lv6bq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:51.539: INFO: Wrong image for pod: daemon-set-2f79c. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:51.539: INFO: Pod daemon-set-2f79c is not available
Dec 21 01:32:52.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:52.539: INFO: Wrong image for pod: daemon-set-lv6bq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:52.539: INFO: Pod daemon-set-t2n7k is not available
Dec 21 01:32:53.538: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:53.538: INFO: Wrong image for pod: daemon-set-lv6bq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:53.538: INFO: Pod daemon-set-t2n7k is not available
Dec 21 01:32:54.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:54.539: INFO: Wrong image for pod: daemon-set-lv6bq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:54.539: INFO: Pod daemon-set-t2n7k is not available
Dec 21 01:32:55.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:55.539: INFO: Wrong image for pod: daemon-set-lv6bq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:56.538: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:56.539: INFO: Wrong image for pod: daemon-set-lv6bq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:56.539: INFO: Pod daemon-set-lv6bq is not available
Dec 21 01:32:57.538: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:57.539: INFO: Wrong image for pod: daemon-set-lv6bq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:57.539: INFO: Pod daemon-set-lv6bq is not available
Dec 21 01:32:58.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:58.539: INFO: Wrong image for pod: daemon-set-lv6bq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:58.539: INFO: Pod daemon-set-lv6bq is not available
Dec 21 01:32:59.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:32:59.539: INFO: Pod daemon-set-85x5w is not available
Dec 21 01:33:00.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:33:00.539: INFO: Pod daemon-set-85x5w is not available
Dec 21 01:33:01.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:33:01.539: INFO: Pod daemon-set-85x5w is not available
Dec 21 01:33:02.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:33:02.539: INFO: Pod daemon-set-85x5w is not available
Dec 21 01:33:03.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:33:04.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:33:04.539: INFO: Pod daemon-set-cl445 is not available
Dec 21 01:33:05.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:33:05.539: INFO: Pod daemon-set-cl445 is not available
Dec 21 01:33:06.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:33:06.539: INFO: Pod daemon-set-cl445 is not available
Dec 21 01:33:07.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:33:07.539: INFO: Pod daemon-set-cl445 is not available
Dec 21 01:33:08.543: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:33:08.543: INFO: Pod daemon-set-cl445 is not available
Dec 21 01:33:09.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:33:09.539: INFO: Pod daemon-set-cl445 is not available
Dec 21 01:33:10.552: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:33:10.552: INFO: Pod daemon-set-cl445 is not available
Dec 21 01:33:11.554: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:33:11.554: INFO: Pod daemon-set-cl445 is not available
Dec 21 01:33:12.539: INFO: Wrong image for pod: daemon-set-cl445. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 01:33:12.539: INFO: Pod daemon-set-cl445 is not available
Dec 21 01:33:13.539: INFO: Pod daemon-set-kzgzf is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Dec 21 01:33:13.546: INFO: Number of nodes with available pods: 2
Dec 21 01:33:13.546: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:33:14.552: INFO: Number of nodes with available pods: 2
Dec 21 01:33:14.552: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:33:15.552: INFO: Number of nodes with available pods: 2
Dec 21 01:33:15.552: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:33:16.552: INFO: Number of nodes with available pods: 2
Dec 21 01:33:16.552: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:33:17.556: INFO: Number of nodes with available pods: 3
Dec 21 01:33:17.556: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9484, will wait for the garbage collector to delete the pods
Dec 21 01:33:17.625: INFO: Deleting DaemonSet.extensions daemon-set took: 6.133261ms
Dec 21 01:33:18.126: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.268907ms
Dec 21 01:33:23.428: INFO: Number of nodes with available pods: 0
Dec 21 01:33:23.428: INFO: Number of running nodes: 0, number of available pods: 0
Dec 21 01:33:23.431: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9484/daemonsets","resourceVersion":"4688"},"items":null}

Dec 21 01:33:23.433: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9484/pods","resourceVersion":"4688"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:33:23.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9484" for this suite.
Dec 21 01:33:29.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:33:29.541: INFO: namespace daemonsets-9484 deletion completed in 6.097177989s

â€¢ [SLOW TEST:58.093 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:33:29.541: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Dec 21 01:33:29.565: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-448192630 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:33:29.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6958" for this suite.
Dec 21 01:33:35.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:33:35.741: INFO: namespace kubectl-6958 deletion completed in 6.100432329s

â€¢ [SLOW TEST:6.200 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:33:35.742: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Dec 21 01:33:35.778: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec 21 01:33:35.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 create -f - --namespace=kubectl-5024'
Dec 21 01:33:35.979: INFO: stderr: ""
Dec 21 01:33:35.979: INFO: stdout: "service/redis-slave created\n"
Dec 21 01:33:35.979: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec 21 01:33:35.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 create -f - --namespace=kubectl-5024'
Dec 21 01:33:36.150: INFO: stderr: ""
Dec 21 01:33:36.150: INFO: stdout: "service/redis-master created\n"
Dec 21 01:33:36.150: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec 21 01:33:36.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 create -f - --namespace=kubectl-5024'
Dec 21 01:33:36.321: INFO: stderr: ""
Dec 21 01:33:36.322: INFO: stdout: "service/frontend created\n"
Dec 21 01:33:36.322: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec 21 01:33:36.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 create -f - --namespace=kubectl-5024'
Dec 21 01:33:36.486: INFO: stderr: ""
Dec 21 01:33:36.486: INFO: stdout: "deployment.apps/frontend created\n"
Dec 21 01:33:36.486: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 21 01:33:36.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 create -f - --namespace=kubectl-5024'
Dec 21 01:33:36.658: INFO: stderr: ""
Dec 21 01:33:36.658: INFO: stdout: "deployment.apps/redis-master created\n"
Dec 21 01:33:36.658: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec 21 01:33:36.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 create -f - --namespace=kubectl-5024'
Dec 21 01:33:36.824: INFO: stderr: ""
Dec 21 01:33:36.824: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Dec 21 01:33:36.824: INFO: Waiting for all frontend pods to be Running.
Dec 21 01:33:51.875: INFO: Waiting for frontend to serve content.
Dec 21 01:33:51.888: INFO: Trying to add a new entry to the guestbook.
Dec 21 01:33:51.897: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec 21 01:33:51.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 delete --grace-period=0 --force -f - --namespace=kubectl-5024'
Dec 21 01:33:52.004: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 21 01:33:52.004: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec 21 01:33:52.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 delete --grace-period=0 --force -f - --namespace=kubectl-5024'
Dec 21 01:33:52.099: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 21 01:33:52.099: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 21 01:33:52.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 delete --grace-period=0 --force -f - --namespace=kubectl-5024'
Dec 21 01:33:52.194: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 21 01:33:52.194: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 21 01:33:52.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 delete --grace-period=0 --force -f - --namespace=kubectl-5024'
Dec 21 01:33:52.275: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 21 01:33:52.275: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 21 01:33:52.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 delete --grace-period=0 --force -f - --namespace=kubectl-5024'
Dec 21 01:33:52.353: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 21 01:33:52.353: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 21 01:33:52.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 delete --grace-period=0 --force -f - --namespace=kubectl-5024'
Dec 21 01:33:52.432: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 21 01:33:52.432: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:33:52.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5024" for this suite.
Dec 21 01:34:20.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:34:20.524: INFO: namespace kubectl-5024 deletion completed in 28.090128881s

â€¢ [SLOW TEST:44.783 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:34:20.525: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-3106/configmap-test-dcd2b2f8-bfe8-4232-b351-120ccf09cfe8
STEP: Creating a pod to test consume configMaps
Dec 21 01:34:20.556: INFO: Waiting up to 5m0s for pod "pod-configmaps-a7ac4828-2358-4cc5-a2c5-82667d4c50f4" in namespace "configmap-3106" to be "success or failure"
Dec 21 01:34:20.558: INFO: Pod "pod-configmaps-a7ac4828-2358-4cc5-a2c5-82667d4c50f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.338083ms
Dec 21 01:34:22.562: INFO: Pod "pod-configmaps-a7ac4828-2358-4cc5-a2c5-82667d4c50f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005586114s
STEP: Saw pod success
Dec 21 01:34:22.562: INFO: Pod "pod-configmaps-a7ac4828-2358-4cc5-a2c5-82667d4c50f4" satisfied condition "success or failure"
Dec 21 01:34:22.564: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-configmaps-a7ac4828-2358-4cc5-a2c5-82667d4c50f4 container env-test: <nil>
STEP: delete the pod
Dec 21 01:34:22.580: INFO: Waiting for pod pod-configmaps-a7ac4828-2358-4cc5-a2c5-82667d4c50f4 to disappear
Dec 21 01:34:22.585: INFO: Pod pod-configmaps-a7ac4828-2358-4cc5-a2c5-82667d4c50f4 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:34:22.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3106" for this suite.
Dec 21 01:34:28.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:34:28.679: INFO: namespace configmap-3106 deletion completed in 6.091437397s

â€¢ [SLOW TEST:8.154 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:34:28.679: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:34:39.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7843" for this suite.
Dec 21 01:34:45.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:34:45.831: INFO: namespace resourcequota-7843 deletion completed in 6.099528289s

â€¢ [SLOW TEST:17.152 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:34:45.832: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Dec 21 01:34:45.857: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-448192630 proxy --unix-socket=/tmp/kubectl-proxy-unix011321257/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:34:45.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5222" for this suite.
Dec 21 01:34:51.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:34:52.015: INFO: namespace kubectl-5222 deletion completed in 6.101745994s

â€¢ [SLOW TEST:6.183 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:34:52.015: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Dec 21 01:34:52.045: INFO: Waiting up to 5m0s for pod "client-containers-e989a2bd-2f0a-44bf-a010-e52892529762" in namespace "containers-9427" to be "success or failure"
Dec 21 01:34:52.047: INFO: Pod "client-containers-e989a2bd-2f0a-44bf-a010-e52892529762": Phase="Pending", Reason="", readiness=false. Elapsed: 1.965374ms
Dec 21 01:34:54.051: INFO: Pod "client-containers-e989a2bd-2f0a-44bf-a010-e52892529762": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005402256s
STEP: Saw pod success
Dec 21 01:34:54.051: INFO: Pod "client-containers-e989a2bd-2f0a-44bf-a010-e52892529762" satisfied condition "success or failure"
Dec 21 01:34:54.053: INFO: Trying to get logs from node ip-172-31-29-169 pod client-containers-e989a2bd-2f0a-44bf-a010-e52892529762 container test-container: <nil>
STEP: delete the pod
Dec 21 01:34:54.067: INFO: Waiting for pod client-containers-e989a2bd-2f0a-44bf-a010-e52892529762 to disappear
Dec 21 01:34:54.071: INFO: Pod client-containers-e989a2bd-2f0a-44bf-a010-e52892529762 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:34:54.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9427" for this suite.
Dec 21 01:35:00.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:35:00.187: INFO: namespace containers-9427 deletion completed in 6.113735999s

â€¢ [SLOW TEST:8.172 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:35:00.187: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-63d6766e-15d3-4654-a090-ee9fc3b6ab76
STEP: Creating a pod to test consume secrets
Dec 21 01:35:00.221: INFO: Waiting up to 5m0s for pod "pod-secrets-755dcc5e-57b5-4557-ac60-6ffada59ab06" in namespace "secrets-372" to be "success or failure"
Dec 21 01:35:00.229: INFO: Pod "pod-secrets-755dcc5e-57b5-4557-ac60-6ffada59ab06": Phase="Pending", Reason="", readiness=false. Elapsed: 7.660425ms
Dec 21 01:35:02.232: INFO: Pod "pod-secrets-755dcc5e-57b5-4557-ac60-6ffada59ab06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01058854s
STEP: Saw pod success
Dec 21 01:35:02.232: INFO: Pod "pod-secrets-755dcc5e-57b5-4557-ac60-6ffada59ab06" satisfied condition "success or failure"
Dec 21 01:35:02.234: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-secrets-755dcc5e-57b5-4557-ac60-6ffada59ab06 container secret-volume-test: <nil>
STEP: delete the pod
Dec 21 01:35:02.247: INFO: Waiting for pod pod-secrets-755dcc5e-57b5-4557-ac60-6ffada59ab06 to disappear
Dec 21 01:35:02.251: INFO: Pod pod-secrets-755dcc5e-57b5-4557-ac60-6ffada59ab06 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:35:02.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-372" for this suite.
Dec 21 01:35:08.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:35:08.345: INFO: namespace secrets-372 deletion completed in 6.090424233s

â€¢ [SLOW TEST:8.158 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:35:08.345: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-7032
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 21 01:35:08.370: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 21 01:35:32.442: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.42.0.13 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7032 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 01:35:32.442: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 01:35:33.505: INFO: Found all expected endpoints: [netserver-0]
Dec 21 01:35:33.508: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.42.2.12 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7032 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 01:35:33.508: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 01:35:34.583: INFO: Found all expected endpoints: [netserver-1]
Dec 21 01:35:34.586: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.42.1.30 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7032 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 01:35:34.586: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 01:35:35.656: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:35:35.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7032" for this suite.
Dec 21 01:36:03.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:36:03.758: INFO: namespace pod-network-test-7032 deletion completed in 28.097905256s

â€¢ [SLOW TEST:55.413 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:36:03.758: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 21 01:36:03.788: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d3e3ca5f-e27a-4312-96eb-e5f57f454265" in namespace "downward-api-5644" to be "success or failure"
Dec 21 01:36:03.791: INFO: Pod "downwardapi-volume-d3e3ca5f-e27a-4312-96eb-e5f57f454265": Phase="Pending", Reason="", readiness=false. Elapsed: 2.229902ms
Dec 21 01:36:05.794: INFO: Pod "downwardapi-volume-d3e3ca5f-e27a-4312-96eb-e5f57f454265": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005291086s
STEP: Saw pod success
Dec 21 01:36:05.794: INFO: Pod "downwardapi-volume-d3e3ca5f-e27a-4312-96eb-e5f57f454265" satisfied condition "success or failure"
Dec 21 01:36:05.796: INFO: Trying to get logs from node ip-172-31-29-169 pod downwardapi-volume-d3e3ca5f-e27a-4312-96eb-e5f57f454265 container client-container: <nil>
STEP: delete the pod
Dec 21 01:36:05.810: INFO: Waiting for pod downwardapi-volume-d3e3ca5f-e27a-4312-96eb-e5f57f454265 to disappear
Dec 21 01:36:05.812: INFO: Pod downwardapi-volume-d3e3ca5f-e27a-4312-96eb-e5f57f454265 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:36:05.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5644" for this suite.
Dec 21 01:36:11.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:36:11.913: INFO: namespace downward-api-5644 deletion completed in 6.097947015s

â€¢ [SLOW TEST:8.155 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:36:11.913: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-5f2a22b5-8342-485a-8ab3-c5f077f4993d
STEP: Creating a pod to test consume configMaps
Dec 21 01:36:11.947: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6d59aaaa-11ed-4e01-bf94-c03b227aa720" in namespace "projected-6686" to be "success or failure"
Dec 21 01:36:11.950: INFO: Pod "pod-projected-configmaps-6d59aaaa-11ed-4e01-bf94-c03b227aa720": Phase="Pending", Reason="", readiness=false. Elapsed: 3.557344ms
Dec 21 01:36:13.962: INFO: Pod "pod-projected-configmaps-6d59aaaa-11ed-4e01-bf94-c03b227aa720": Phase="Running", Reason="", readiness=true. Elapsed: 2.015174607s
Dec 21 01:36:15.965: INFO: Pod "pod-projected-configmaps-6d59aaaa-11ed-4e01-bf94-c03b227aa720": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018387503s
STEP: Saw pod success
Dec 21 01:36:15.965: INFO: Pod "pod-projected-configmaps-6d59aaaa-11ed-4e01-bf94-c03b227aa720" satisfied condition "success or failure"
Dec 21 01:36:15.967: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-projected-configmaps-6d59aaaa-11ed-4e01-bf94-c03b227aa720 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 01:36:15.982: INFO: Waiting for pod pod-projected-configmaps-6d59aaaa-11ed-4e01-bf94-c03b227aa720 to disappear
Dec 21 01:36:15.984: INFO: Pod pod-projected-configmaps-6d59aaaa-11ed-4e01-bf94-c03b227aa720 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:36:15.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6686" for this suite.
Dec 21 01:36:21.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:36:22.098: INFO: namespace projected-6686 deletion completed in 6.110485236s

â€¢ [SLOW TEST:10.185 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:36:22.098: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 21 01:36:28.174: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 21 01:36:28.177: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 21 01:36:30.177: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 21 01:36:30.182: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 21 01:36:32.177: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 21 01:36:32.180: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 21 01:36:34.177: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 21 01:36:34.180: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:36:34.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8553" for this suite.
Dec 21 01:37:02.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:37:02.281: INFO: namespace container-lifecycle-hook-8553 deletion completed in 28.093232149s

â€¢ [SLOW TEST:40.182 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:37:02.281: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-46a1c544-e7bc-4b95-b3fa-6562e39a0957
STEP: Creating a pod to test consume secrets
Dec 21 01:37:02.325: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a0d4b48c-4dd8-4ad6-916e-ad779199a4b4" in namespace "projected-5097" to be "success or failure"
Dec 21 01:37:02.330: INFO: Pod "pod-projected-secrets-a0d4b48c-4dd8-4ad6-916e-ad779199a4b4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.972849ms
Dec 21 01:37:04.333: INFO: Pod "pod-projected-secrets-a0d4b48c-4dd8-4ad6-916e-ad779199a4b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008156533s
STEP: Saw pod success
Dec 21 01:37:04.333: INFO: Pod "pod-projected-secrets-a0d4b48c-4dd8-4ad6-916e-ad779199a4b4" satisfied condition "success or failure"
Dec 21 01:37:04.335: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-projected-secrets-a0d4b48c-4dd8-4ad6-916e-ad779199a4b4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 21 01:37:04.346: INFO: Waiting for pod pod-projected-secrets-a0d4b48c-4dd8-4ad6-916e-ad779199a4b4 to disappear
Dec 21 01:37:04.349: INFO: Pod pod-projected-secrets-a0d4b48c-4dd8-4ad6-916e-ad779199a4b4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:37:04.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5097" for this suite.
Dec 21 01:37:10.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:37:10.445: INFO: namespace projected-5097 deletion completed in 6.09312945s

â€¢ [SLOW TEST:8.164 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:37:10.445: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Dec 21 01:37:14.491: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-448192630 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec 21 01:37:19.569: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:37:19.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2420" for this suite.
Dec 21 01:37:25.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:37:25.669: INFO: namespace pods-2420 deletion completed in 6.094068749s

â€¢ [SLOW TEST:15.224 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:37:25.669: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-73f63d04-44b7-414e-879b-43175386e5c6
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-73f63d04-44b7-414e-879b-43175386e5c6
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:37:29.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9546" for this suite.
Dec 21 01:37:41.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:37:41.849: INFO: namespace projected-9546 deletion completed in 12.110562107s

â€¢ [SLOW TEST:16.180 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:37:41.850: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 21 01:37:44.410: INFO: Successfully updated pod "labelsupdateeeb9a3eb-f30a-4fa0-8ea7-457ca4d62cbd"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:37:48.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7114" for this suite.
Dec 21 01:38:00.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:38:00.564: INFO: namespace projected-7114 deletion completed in 12.124672977s

â€¢ [SLOW TEST:18.715 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:38:00.564: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 01:38:00.615: INFO: (0) /api/v1/nodes/ip-172-31-25-252:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 6.638418ms)
Dec 21 01:38:00.618: INFO: (1) /api/v1/nodes/ip-172-31-25-252:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.961417ms)
Dec 21 01:38:00.621: INFO: (2) /api/v1/nodes/ip-172-31-25-252:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.341701ms)
Dec 21 01:38:00.627: INFO: (3) /api/v1/nodes/ip-172-31-25-252:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 6.055626ms)
Dec 21 01:38:00.630: INFO: (4) /api/v1/nodes/ip-172-31-25-252:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.930222ms)
Dec 21 01:38:00.633: INFO: (5) /api/v1/nodes/ip-172-31-25-252:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.918385ms)
Dec 21 01:38:00.637: INFO: (6) /api/v1/nodes/ip-172-31-25-252:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 4.493797ms)
Dec 21 01:38:00.647: INFO: (7) /api/v1/nodes/ip-172-31-25-252:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 9.66844ms)
Dec 21 01:38:00.650: INFO: (8) /api/v1/nodes/ip-172-31-25-252:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.278733ms)
Dec 21 01:38:00.658: INFO: (9) /api/v1/nodes/ip-172-31-25-252:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 7.27696ms)
Dec 21 01:38:00.661: INFO: (10) /api/v1/nodes/ip-172-31-25-252:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.400159ms)
Dec 21 01:38:00.668: INFO: (11) /api/v1/nodes/ip-172-31-25-252:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 6.600046ms)
Dec 21 01:38:00.680: INFO: (12) /api/v1/nodes/ip-172-31-25-252:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 12.658321ms)
Dec 21 01:38:00.683: INFO: (13) /api/v1/nodes/ip-172-31-25-252:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.808404ms)
Dec 21 01:38:00.686: INFO: (14) /api/v1/nodes/ip-172-31-25-252:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.025911ms)
Dec 21 01:38:00.692: INFO: (15) /api/v1/nodes/ip-172-31-25-252:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 5.853462ms)
Dec 21 01:38:00.695: INFO: (16) /api/v1/nodes/ip-172-31-25-252:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.686167ms)
Dec 21 01:38:00.698: INFO: (17) /api/v1/nodes/ip-172-31-25-252:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.728227ms)
Dec 21 01:38:00.700: INFO: (18) /api/v1/nodes/ip-172-31-25-252:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.718778ms)
Dec 21 01:38:00.705: INFO: (19) /api/v1/nodes/ip-172-31-25-252:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 5.020994ms)
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:38:00.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-678" for this suite.
Dec 21 01:38:06.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:38:06.814: INFO: namespace proxy-678 deletion completed in 6.105797828s

â€¢ [SLOW TEST:6.250 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:38:06.814: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-7720
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-7720
STEP: creating replication controller externalsvc in namespace services-7720
I1221 01:38:06.861475      22 runners.go:184] Created replication controller with name: externalsvc, namespace: services-7720, replica count: 2
I1221 01:38:09.912043      22 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Dec 21 01:38:09.924: INFO: Creating new exec pod
Dec 21 01:38:11.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=services-7720 execpod69d6s -- /bin/sh -x -c nslookup clusterip-service'
Dec 21 01:38:12.838: INFO: stderr: "+ nslookup clusterip-service\n"
Dec 21 01:38:12.838: INFO: stdout: "Server:\t\t10.43.0.10\nAddress:\t10.43.0.10#53\n\nclusterip-service.services-7720.svc.cluster.local\tcanonical name = externalsvc.services-7720.svc.cluster.local.\nName:\texternalsvc.services-7720.svc.cluster.local\nAddress: 10.43.44.223\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-7720, will wait for the garbage collector to delete the pods
Dec 21 01:38:12.898: INFO: Deleting ReplicationController externalsvc took: 5.74678ms
Dec 21 01:38:13.298: INFO: Terminating ReplicationController externalsvc pods took: 400.257729ms
Dec 21 01:38:23.521: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:38:23.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7720" for this suite.
Dec 21 01:38:29.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:38:29.642: INFO: namespace services-7720 deletion completed in 6.105454644s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:22.828 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:38:29.642: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4345.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-4345.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4345.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4345.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-4345.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4345.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 21 01:38:41.720: INFO: DNS probes using dns-4345/dns-test-a844f2d3-6f90-4c54-9c52-b473fbab7169 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:38:41.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4345" for this suite.
Dec 21 01:38:47.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:38:47.850: INFO: namespace dns-4345 deletion completed in 6.096789551s

â€¢ [SLOW TEST:18.208 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:38:47.850: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:39:00.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-475" for this suite.
Dec 21 01:39:06.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:39:07.026: INFO: namespace resourcequota-475 deletion completed in 6.100959452s

â€¢ [SLOW TEST:19.176 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:39:07.027: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 21 01:39:07.062: INFO: Waiting up to 5m0s for pod "downwardapi-volume-096b5946-eb99-417c-989f-b561e8a3d452" in namespace "downward-api-8235" to be "success or failure"
Dec 21 01:39:07.068: INFO: Pod "downwardapi-volume-096b5946-eb99-417c-989f-b561e8a3d452": Phase="Pending", Reason="", readiness=false. Elapsed: 6.698765ms
Dec 21 01:39:09.072: INFO: Pod "downwardapi-volume-096b5946-eb99-417c-989f-b561e8a3d452": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010285213s
STEP: Saw pod success
Dec 21 01:39:09.072: INFO: Pod "downwardapi-volume-096b5946-eb99-417c-989f-b561e8a3d452" satisfied condition "success or failure"
Dec 21 01:39:09.075: INFO: Trying to get logs from node ip-172-31-29-169 pod downwardapi-volume-096b5946-eb99-417c-989f-b561e8a3d452 container client-container: <nil>
STEP: delete the pod
Dec 21 01:39:09.092: INFO: Waiting for pod downwardapi-volume-096b5946-eb99-417c-989f-b561e8a3d452 to disappear
Dec 21 01:39:09.101: INFO: Pod downwardapi-volume-096b5946-eb99-417c-989f-b561e8a3d452 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:39:09.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8235" for this suite.
Dec 21 01:39:15.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:39:15.196: INFO: namespace downward-api-8235 deletion completed in 6.092602386s

â€¢ [SLOW TEST:8.169 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:39:15.197: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:39:31.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8302" for this suite.
Dec 21 01:39:37.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:39:37.407: INFO: namespace resourcequota-8302 deletion completed in 6.090337953s

â€¢ [SLOW TEST:22.211 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:39:37.408: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 21 01:39:37.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-3924'
Dec 21 01:39:37.515: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 21 01:39:37.515: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Dec 21 01:39:37.524: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec 21 01:39:37.534: INFO: scanned /root for discovery docs: <nil>
Dec 21 01:39:37.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-3924'
Dec 21 01:39:53.280: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 21 01:39:53.280: INFO: stdout: "Created e2e-test-httpd-rc-d810282171e64ec9fc3d681180205404\nScaling up e2e-test-httpd-rc-d810282171e64ec9fc3d681180205404 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-d810282171e64ec9fc3d681180205404 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-d810282171e64ec9fc3d681180205404 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Dec 21 01:39:53.280: INFO: stdout: "Created e2e-test-httpd-rc-d810282171e64ec9fc3d681180205404\nScaling up e2e-test-httpd-rc-d810282171e64ec9fc3d681180205404 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-d810282171e64ec9fc3d681180205404 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-d810282171e64ec9fc3d681180205404 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Dec 21 01:39:53.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-3924'
Dec 21 01:39:53.357: INFO: stderr: ""
Dec 21 01:39:53.357: INFO: stdout: "e2e-test-httpd-rc-d810282171e64ec9fc3d681180205404-2h74c "
Dec 21 01:39:53.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods e2e-test-httpd-rc-d810282171e64ec9fc3d681180205404-2h74c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3924'
Dec 21 01:39:53.433: INFO: stderr: ""
Dec 21 01:39:53.433: INFO: stdout: "true"
Dec 21 01:39:53.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods e2e-test-httpd-rc-d810282171e64ec9fc3d681180205404-2h74c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3924'
Dec 21 01:39:53.513: INFO: stderr: ""
Dec 21 01:39:53.513: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Dec 21 01:39:53.513: INFO: e2e-test-httpd-rc-d810282171e64ec9fc3d681180205404-2h74c is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Dec 21 01:39:53.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 delete rc e2e-test-httpd-rc --namespace=kubectl-3924'
Dec 21 01:39:53.594: INFO: stderr: ""
Dec 21 01:39:53.594: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:39:53.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3924" for this suite.
Dec 21 01:39:59.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:39:59.707: INFO: namespace kubectl-3924 deletion completed in 6.104493989s

â€¢ [SLOW TEST:22.299 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:39:59.707: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 21 01:39:59.737: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3f2ac665-e04f-4d93-b6c1-41460b2a6ff6" in namespace "projected-3756" to be "success or failure"
Dec 21 01:39:59.740: INFO: Pod "downwardapi-volume-3f2ac665-e04f-4d93-b6c1-41460b2a6ff6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.929709ms
Dec 21 01:40:01.743: INFO: Pod "downwardapi-volume-3f2ac665-e04f-4d93-b6c1-41460b2a6ff6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006302625s
STEP: Saw pod success
Dec 21 01:40:01.743: INFO: Pod "downwardapi-volume-3f2ac665-e04f-4d93-b6c1-41460b2a6ff6" satisfied condition "success or failure"
Dec 21 01:40:01.746: INFO: Trying to get logs from node ip-172-31-29-169 pod downwardapi-volume-3f2ac665-e04f-4d93-b6c1-41460b2a6ff6 container client-container: <nil>
STEP: delete the pod
Dec 21 01:40:01.762: INFO: Waiting for pod downwardapi-volume-3f2ac665-e04f-4d93-b6c1-41460b2a6ff6 to disappear
Dec 21 01:40:01.767: INFO: Pod downwardapi-volume-3f2ac665-e04f-4d93-b6c1-41460b2a6ff6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:40:01.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3756" for this suite.
Dec 21 01:40:07.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:40:07.865: INFO: namespace projected-3756 deletion completed in 6.091800242s

â€¢ [SLOW TEST:8.158 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:40:07.865: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 21 01:40:10.419: INFO: Successfully updated pod "annotationupdated3d6f07a-c39b-44a2-8e47-3ee348fe62c1"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:40:14.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7603" for this suite.
Dec 21 01:40:26.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:40:26.534: INFO: namespace projected-7603 deletion completed in 12.088016068s

â€¢ [SLOW TEST:18.668 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:40:26.534: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 21 01:40:26.564: INFO: Waiting up to 5m0s for pod "pod-f6df6e7b-df61-4f39-af83-a2187643edab" in namespace "emptydir-8935" to be "success or failure"
Dec 21 01:40:26.567: INFO: Pod "pod-f6df6e7b-df61-4f39-af83-a2187643edab": Phase="Pending", Reason="", readiness=false. Elapsed: 3.368732ms
Dec 21 01:40:28.570: INFO: Pod "pod-f6df6e7b-df61-4f39-af83-a2187643edab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006662985s
STEP: Saw pod success
Dec 21 01:40:28.570: INFO: Pod "pod-f6df6e7b-df61-4f39-af83-a2187643edab" satisfied condition "success or failure"
Dec 21 01:40:28.573: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-f6df6e7b-df61-4f39-af83-a2187643edab container test-container: <nil>
STEP: delete the pod
Dec 21 01:40:28.585: INFO: Waiting for pod pod-f6df6e7b-df61-4f39-af83-a2187643edab to disappear
Dec 21 01:40:28.588: INFO: Pod pod-f6df6e7b-df61-4f39-af83-a2187643edab no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:40:28.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8935" for this suite.
Dec 21 01:40:34.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:40:34.686: INFO: namespace emptydir-8935 deletion completed in 6.095384629s

â€¢ [SLOW TEST:8.152 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:40:34.686: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 01:40:34.762: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:40:35.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4888" for this suite.
Dec 21 01:40:41.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:40:41.876: INFO: namespace custom-resource-definition-4888 deletion completed in 6.090688851s

â€¢ [SLOW TEST:7.190 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:40:41.877: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-2842e6dd-5a8c-4fc9-8475-93702c768a13
STEP: Creating secret with name s-test-opt-upd-17962286-a5c2-4220-822e-4745e131a9e0
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-2842e6dd-5a8c-4fc9-8475-93702c768a13
STEP: Updating secret s-test-opt-upd-17962286-a5c2-4220-822e-4745e131a9e0
STEP: Creating secret with name s-test-opt-create-a2f33302-bb0e-48c9-b591-57d47e63c438
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:40:45.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3061" for this suite.
Dec 21 01:40:57.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:40:58.067: INFO: namespace projected-3061 deletion completed in 12.093455959s

â€¢ [SLOW TEST:16.191 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:40:58.068: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 21 01:40:58.098: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c3d365f4-0a48-4dd6-bdbe-7e46c9e15010" in namespace "downward-api-2733" to be "success or failure"
Dec 21 01:40:58.102: INFO: Pod "downwardapi-volume-c3d365f4-0a48-4dd6-bdbe-7e46c9e15010": Phase="Pending", Reason="", readiness=false. Elapsed: 3.357594ms
Dec 21 01:41:00.105: INFO: Pod "downwardapi-volume-c3d365f4-0a48-4dd6-bdbe-7e46c9e15010": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006802709s
Dec 21 01:41:02.109: INFO: Pod "downwardapi-volume-c3d365f4-0a48-4dd6-bdbe-7e46c9e15010": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010293234s
STEP: Saw pod success
Dec 21 01:41:02.109: INFO: Pod "downwardapi-volume-c3d365f4-0a48-4dd6-bdbe-7e46c9e15010" satisfied condition "success or failure"
Dec 21 01:41:02.111: INFO: Trying to get logs from node ip-172-31-29-169 pod downwardapi-volume-c3d365f4-0a48-4dd6-bdbe-7e46c9e15010 container client-container: <nil>
STEP: delete the pod
Dec 21 01:41:02.129: INFO: Waiting for pod downwardapi-volume-c3d365f4-0a48-4dd6-bdbe-7e46c9e15010 to disappear
Dec 21 01:41:02.133: INFO: Pod downwardapi-volume-c3d365f4-0a48-4dd6-bdbe-7e46c9e15010 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:41:02.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2733" for this suite.
Dec 21 01:41:08.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:41:08.232: INFO: namespace downward-api-2733 deletion completed in 6.096522058s

â€¢ [SLOW TEST:10.164 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:41:08.233: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 21 01:41:08.262: INFO: Waiting up to 5m0s for pod "downwardapi-volume-570e176a-2948-468c-ae14-de07ca6c6111" in namespace "downward-api-6463" to be "success or failure"
Dec 21 01:41:08.265: INFO: Pod "downwardapi-volume-570e176a-2948-468c-ae14-de07ca6c6111": Phase="Pending", Reason="", readiness=false. Elapsed: 3.353609ms
Dec 21 01:41:10.268: INFO: Pod "downwardapi-volume-570e176a-2948-468c-ae14-de07ca6c6111": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006650213s
Dec 21 01:41:12.272: INFO: Pod "downwardapi-volume-570e176a-2948-468c-ae14-de07ca6c6111": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010033233s
STEP: Saw pod success
Dec 21 01:41:12.272: INFO: Pod "downwardapi-volume-570e176a-2948-468c-ae14-de07ca6c6111" satisfied condition "success or failure"
Dec 21 01:41:12.274: INFO: Trying to get logs from node ip-172-31-29-141 pod downwardapi-volume-570e176a-2948-468c-ae14-de07ca6c6111 container client-container: <nil>
STEP: delete the pod
Dec 21 01:41:12.299: INFO: Waiting for pod downwardapi-volume-570e176a-2948-468c-ae14-de07ca6c6111 to disappear
Dec 21 01:41:12.301: INFO: Pod downwardapi-volume-570e176a-2948-468c-ae14-de07ca6c6111 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:41:12.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6463" for this suite.
Dec 21 01:41:18.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:41:18.410: INFO: namespace downward-api-6463 deletion completed in 6.106274654s

â€¢ [SLOW TEST:10.177 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:41:18.410: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-aa2fafe5-7d22-4c29-a36a-25edc5b44c85
STEP: Creating secret with name secret-projected-all-test-volume-cd8c0ed2-ab05-4e3d-912c-37089301030e
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec 21 01:41:18.444: INFO: Waiting up to 5m0s for pod "projected-volume-3619cdfd-f919-408d-9488-680f5efe1b81" in namespace "projected-2364" to be "success or failure"
Dec 21 01:41:18.448: INFO: Pod "projected-volume-3619cdfd-f919-408d-9488-680f5efe1b81": Phase="Pending", Reason="", readiness=false. Elapsed: 3.738433ms
Dec 21 01:41:20.451: INFO: Pod "projected-volume-3619cdfd-f919-408d-9488-680f5efe1b81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006615295s
STEP: Saw pod success
Dec 21 01:41:20.451: INFO: Pod "projected-volume-3619cdfd-f919-408d-9488-680f5efe1b81" satisfied condition "success or failure"
Dec 21 01:41:20.453: INFO: Trying to get logs from node ip-172-31-29-169 pod projected-volume-3619cdfd-f919-408d-9488-680f5efe1b81 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec 21 01:41:20.465: INFO: Waiting for pod projected-volume-3619cdfd-f919-408d-9488-680f5efe1b81 to disappear
Dec 21 01:41:20.469: INFO: Pod projected-volume-3619cdfd-f919-408d-9488-680f5efe1b81 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:41:20.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2364" for this suite.
Dec 21 01:41:26.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:41:26.574: INFO: namespace projected-2364 deletion completed in 6.102493589s

â€¢ [SLOW TEST:8.163 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:41:26.574: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 01:41:26.611: INFO: (0) /api/v1/nodes/ip-172-31-29-169/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 9.391154ms)
Dec 21 01:41:26.617: INFO: (1) /api/v1/nodes/ip-172-31-29-169/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 6.099993ms)
Dec 21 01:41:26.621: INFO: (2) /api/v1/nodes/ip-172-31-29-169/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.78778ms)
Dec 21 01:41:26.624: INFO: (3) /api/v1/nodes/ip-172-31-29-169/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.286145ms)
Dec 21 01:41:26.627: INFO: (4) /api/v1/nodes/ip-172-31-29-169/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.465985ms)
Dec 21 01:41:26.631: INFO: (5) /api/v1/nodes/ip-172-31-29-169/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.219166ms)
Dec 21 01:41:26.634: INFO: (6) /api/v1/nodes/ip-172-31-29-169/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.047072ms)
Dec 21 01:41:26.637: INFO: (7) /api/v1/nodes/ip-172-31-29-169/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.302799ms)
Dec 21 01:41:26.640: INFO: (8) /api/v1/nodes/ip-172-31-29-169/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.190657ms)
Dec 21 01:41:26.643: INFO: (9) /api/v1/nodes/ip-172-31-29-169/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.182613ms)
Dec 21 01:41:26.647: INFO: (10) /api/v1/nodes/ip-172-31-29-169/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.595835ms)
Dec 21 01:41:26.650: INFO: (11) /api/v1/nodes/ip-172-31-29-169/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.390807ms)
Dec 21 01:41:26.654: INFO: (12) /api/v1/nodes/ip-172-31-29-169/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.110549ms)
Dec 21 01:41:26.657: INFO: (13) /api/v1/nodes/ip-172-31-29-169/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.601097ms)
Dec 21 01:41:26.661: INFO: (14) /api/v1/nodes/ip-172-31-29-169/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.317319ms)
Dec 21 01:41:26.664: INFO: (15) /api/v1/nodes/ip-172-31-29-169/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.051531ms)
Dec 21 01:41:26.667: INFO: (16) /api/v1/nodes/ip-172-31-29-169/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.001988ms)
Dec 21 01:41:26.672: INFO: (17) /api/v1/nodes/ip-172-31-29-169/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 5.684984ms)
Dec 21 01:41:26.677: INFO: (18) /api/v1/nodes/ip-172-31-29-169/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 4.546248ms)
Dec 21 01:41:26.680: INFO: (19) /api/v1/nodes/ip-172-31-29-169/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.244181ms)
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:41:26.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3559" for this suite.
Dec 21 01:41:32.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:41:32.778: INFO: namespace proxy-3559 deletion completed in 6.094845128s

â€¢ [SLOW TEST:6.203 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:41:32.778: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Dec 21 01:41:32.811: INFO: Waiting up to 5m0s for pod "var-expansion-39804c6e-7291-4eb5-ba7a-622421c507f7" in namespace "var-expansion-9726" to be "success or failure"
Dec 21 01:41:32.813: INFO: Pod "var-expansion-39804c6e-7291-4eb5-ba7a-622421c507f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.085224ms
Dec 21 01:41:34.818: INFO: Pod "var-expansion-39804c6e-7291-4eb5-ba7a-622421c507f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00651832s
STEP: Saw pod success
Dec 21 01:41:34.818: INFO: Pod "var-expansion-39804c6e-7291-4eb5-ba7a-622421c507f7" satisfied condition "success or failure"
Dec 21 01:41:34.820: INFO: Trying to get logs from node ip-172-31-29-169 pod var-expansion-39804c6e-7291-4eb5-ba7a-622421c507f7 container dapi-container: <nil>
STEP: delete the pod
Dec 21 01:41:34.834: INFO: Waiting for pod var-expansion-39804c6e-7291-4eb5-ba7a-622421c507f7 to disappear
Dec 21 01:41:34.837: INFO: Pod var-expansion-39804c6e-7291-4eb5-ba7a-622421c507f7 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:41:34.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9726" for this suite.
Dec 21 01:41:40.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:41:40.930: INFO: namespace var-expansion-9726 deletion completed in 6.09069354s

â€¢ [SLOW TEST:8.153 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:41:40.931: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 01:41:41.786: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 21 01:41:43.793: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712489301, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712489301, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712489301, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712489301, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 01:41:46.802: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 01:41:46.806: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:41:48.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2944" for this suite.
Dec 21 01:41:54.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:41:55.025: INFO: namespace webhook-2944 deletion completed in 6.109932287s
STEP: Destroying namespace "webhook-2944-markers" for this suite.
Dec 21 01:42:01.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:42:01.112: INFO: namespace webhook-2944-markers deletion completed in 6.087649818s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:20.192 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:42:01.123: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-gmcm
STEP: Creating a pod to test atomic-volume-subpath
Dec 21 01:42:01.158: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-gmcm" in namespace "subpath-3965" to be "success or failure"
Dec 21 01:42:01.161: INFO: Pod "pod-subpath-test-secret-gmcm": Phase="Pending", Reason="", readiness=false. Elapsed: 3.456927ms
Dec 21 01:42:03.165: INFO: Pod "pod-subpath-test-secret-gmcm": Phase="Running", Reason="", readiness=true. Elapsed: 2.006984899s
Dec 21 01:42:05.168: INFO: Pod "pod-subpath-test-secret-gmcm": Phase="Running", Reason="", readiness=true. Elapsed: 4.010053913s
Dec 21 01:42:07.171: INFO: Pod "pod-subpath-test-secret-gmcm": Phase="Running", Reason="", readiness=true. Elapsed: 6.013488976s
Dec 21 01:42:09.174: INFO: Pod "pod-subpath-test-secret-gmcm": Phase="Running", Reason="", readiness=true. Elapsed: 8.016559273s
Dec 21 01:42:11.177: INFO: Pod "pod-subpath-test-secret-gmcm": Phase="Running", Reason="", readiness=true. Elapsed: 10.01980384s
Dec 21 01:42:13.181: INFO: Pod "pod-subpath-test-secret-gmcm": Phase="Running", Reason="", readiness=true. Elapsed: 12.022945642s
Dec 21 01:42:15.184: INFO: Pod "pod-subpath-test-secret-gmcm": Phase="Running", Reason="", readiness=true. Elapsed: 14.026124845s
Dec 21 01:42:17.187: INFO: Pod "pod-subpath-test-secret-gmcm": Phase="Running", Reason="", readiness=true. Elapsed: 16.029108338s
Dec 21 01:42:19.190: INFO: Pod "pod-subpath-test-secret-gmcm": Phase="Running", Reason="", readiness=true. Elapsed: 18.032137708s
Dec 21 01:42:21.193: INFO: Pod "pod-subpath-test-secret-gmcm": Phase="Running", Reason="", readiness=true. Elapsed: 20.035530679s
Dec 21 01:42:23.196: INFO: Pod "pod-subpath-test-secret-gmcm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.038709632s
STEP: Saw pod success
Dec 21 01:42:23.196: INFO: Pod "pod-subpath-test-secret-gmcm" satisfied condition "success or failure"
Dec 21 01:42:23.198: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-subpath-test-secret-gmcm container test-container-subpath-secret-gmcm: <nil>
STEP: delete the pod
Dec 21 01:42:23.214: INFO: Waiting for pod pod-subpath-test-secret-gmcm to disappear
Dec 21 01:42:23.218: INFO: Pod pod-subpath-test-secret-gmcm no longer exists
STEP: Deleting pod pod-subpath-test-secret-gmcm
Dec 21 01:42:23.218: INFO: Deleting pod "pod-subpath-test-secret-gmcm" in namespace "subpath-3965"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:42:23.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3965" for this suite.
Dec 21 01:42:29.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:42:29.310: INFO: namespace subpath-3965 deletion completed in 6.088237065s

â€¢ [SLOW TEST:28.187 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:42:29.311: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 21 01:42:29.340: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2dc55cc2-f81d-4492-bfd1-45b172dc9178" in namespace "downward-api-6625" to be "success or failure"
Dec 21 01:42:29.343: INFO: Pod "downwardapi-volume-2dc55cc2-f81d-4492-bfd1-45b172dc9178": Phase="Pending", Reason="", readiness=false. Elapsed: 3.342004ms
Dec 21 01:42:31.346: INFO: Pod "downwardapi-volume-2dc55cc2-f81d-4492-bfd1-45b172dc9178": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006669303s
STEP: Saw pod success
Dec 21 01:42:31.346: INFO: Pod "downwardapi-volume-2dc55cc2-f81d-4492-bfd1-45b172dc9178" satisfied condition "success or failure"
Dec 21 01:42:31.349: INFO: Trying to get logs from node ip-172-31-29-169 pod downwardapi-volume-2dc55cc2-f81d-4492-bfd1-45b172dc9178 container client-container: <nil>
STEP: delete the pod
Dec 21 01:42:31.374: INFO: Waiting for pod downwardapi-volume-2dc55cc2-f81d-4492-bfd1-45b172dc9178 to disappear
Dec 21 01:42:31.376: INFO: Pod downwardapi-volume-2dc55cc2-f81d-4492-bfd1-45b172dc9178 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:42:31.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6625" for this suite.
Dec 21 01:42:37.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:42:37.499: INFO: namespace downward-api-6625 deletion completed in 6.119422978s

â€¢ [SLOW TEST:8.188 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:42:37.499: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 21 01:42:37.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-1735'
Dec 21 01:42:37.609: INFO: stderr: ""
Dec 21 01:42:37.609: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Dec 21 01:42:42.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pod e2e-test-httpd-pod --namespace=kubectl-1735 -o json'
Dec 21 01:42:42.735: INFO: stderr: ""
Dec 21 01:42:42.735: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-12-21T01:42:37Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-1735\",\n        \"resourceVersion\": \"6641\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-1735/pods/e2e-test-httpd-pod\",\n        \"uid\": \"1ba52754-3810-4cd9-891b-f7d630b06358\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-qq65l\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-29-169\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-qq65l\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-qq65l\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-21T01:42:37Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-21T01:42:39Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-21T01:42:39Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-21T01:42:37Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://230008a48b7f42a7f80275fb8929903ce8f40bf8d6485f415fcd1880b3f18e98\",\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imageID\": \"docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-12-21T01:42:38Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.29.169\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.42.1.55\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.42.1.55\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-12-21T01:42:37Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec 21 01:42:42.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 replace -f - --namespace=kubectl-1735'
Dec 21 01:42:42.935: INFO: stderr: ""
Dec 21 01:42:42.935: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Dec 21 01:42:42.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 delete pods e2e-test-httpd-pod --namespace=kubectl-1735'
Dec 21 01:42:49.299: INFO: stderr: ""
Dec 21 01:42:49.299: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:42:49.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1735" for this suite.
Dec 21 01:42:55.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:42:55.399: INFO: namespace kubectl-1735 deletion completed in 6.096588258s

â€¢ [SLOW TEST:17.900 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:42:55.399: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 01:42:55.882: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 01:42:58.896: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:43:00.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7000" for this suite.
Dec 21 01:43:06.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:43:07.053: INFO: namespace webhook-7000 deletion completed in 6.088303897s
STEP: Destroying namespace "webhook-7000-markers" for this suite.
Dec 21 01:43:13.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:43:13.142: INFO: namespace webhook-7000-markers deletion completed in 6.088746336s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:17.759 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:43:13.158: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec 21 01:43:13.196: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8000 /api/v1/namespaces/watch-8000/configmaps/e2e-watch-test-label-changed cc523607-ea68-4516-8a9b-8c731d37e37c 6801 0 2019-12-21 01:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 21 01:43:13.196: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8000 /api/v1/namespaces/watch-8000/configmaps/e2e-watch-test-label-changed cc523607-ea68-4516-8a9b-8c731d37e37c 6802 0 2019-12-21 01:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 21 01:43:13.196: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8000 /api/v1/namespaces/watch-8000/configmaps/e2e-watch-test-label-changed cc523607-ea68-4516-8a9b-8c731d37e37c 6803 0 2019-12-21 01:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec 21 01:43:23.215: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8000 /api/v1/namespaces/watch-8000/configmaps/e2e-watch-test-label-changed cc523607-ea68-4516-8a9b-8c731d37e37c 6815 0 2019-12-21 01:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 21 01:43:23.215: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8000 /api/v1/namespaces/watch-8000/configmaps/e2e-watch-test-label-changed cc523607-ea68-4516-8a9b-8c731d37e37c 6816 0 2019-12-21 01:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec 21 01:43:23.215: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8000 /api/v1/namespaces/watch-8000/configmaps/e2e-watch-test-label-changed cc523607-ea68-4516-8a9b-8c731d37e37c 6817 0 2019-12-21 01:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:43:23.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8000" for this suite.
Dec 21 01:43:29.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:43:29.311: INFO: namespace watch-8000 deletion completed in 6.093273747s

â€¢ [SLOW TEST:16.153 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:43:29.311: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 01:43:29.342: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-3412acd6-c4c0-4191-99ec-77fc9e7ffaaa" in namespace "security-context-test-8031" to be "success or failure"
Dec 21 01:43:29.347: INFO: Pod "busybox-privileged-false-3412acd6-c4c0-4191-99ec-77fc9e7ffaaa": Phase="Pending", Reason="", readiness=false. Elapsed: 4.669405ms
Dec 21 01:43:31.350: INFO: Pod "busybox-privileged-false-3412acd6-c4c0-4191-99ec-77fc9e7ffaaa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007768281s
Dec 21 01:43:31.350: INFO: Pod "busybox-privileged-false-3412acd6-c4c0-4191-99ec-77fc9e7ffaaa" satisfied condition "success or failure"
Dec 21 01:43:31.355: INFO: Got logs for pod "busybox-privileged-false-3412acd6-c4c0-4191-99ec-77fc9e7ffaaa": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:43:31.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8031" for this suite.
Dec 21 01:43:37.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:43:37.450: INFO: namespace security-context-test-8031 deletion completed in 6.092452572s

â€¢ [SLOW TEST:8.139 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:43:37.452: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:43:37.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2123" for this suite.
Dec 21 01:43:43.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:43:43.572: INFO: namespace custom-resource-definition-2123 deletion completed in 6.088924844s

â€¢ [SLOW TEST:6.120 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:43:43.572: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Dec 21 01:43:43.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 create -f - --namespace=kubectl-9118'
Dec 21 01:43:43.752: INFO: stderr: ""
Dec 21 01:43:43.752: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 21 01:43:43.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9118'
Dec 21 01:43:43.832: INFO: stderr: ""
Dec 21 01:43:43.832: INFO: stdout: "update-demo-nautilus-j5rrs update-demo-nautilus-vlxpf "
Dec 21 01:43:43.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-j5rrs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9118'
Dec 21 01:43:43.908: INFO: stderr: ""
Dec 21 01:43:43.908: INFO: stdout: ""
Dec 21 01:43:43.908: INFO: update-demo-nautilus-j5rrs is created but not running
Dec 21 01:43:48.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9118'
Dec 21 01:43:48.999: INFO: stderr: ""
Dec 21 01:43:49.000: INFO: stdout: "update-demo-nautilus-vlxpf update-demo-nautilus-j5rrs "
Dec 21 01:43:49.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-vlxpf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9118'
Dec 21 01:43:49.076: INFO: stderr: ""
Dec 21 01:43:49.077: INFO: stdout: "true"
Dec 21 01:43:49.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-vlxpf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9118'
Dec 21 01:43:49.162: INFO: stderr: ""
Dec 21 01:43:49.162: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 21 01:43:49.162: INFO: validating pod update-demo-nautilus-vlxpf
Dec 21 01:43:49.166: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 21 01:43:49.166: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 21 01:43:49.166: INFO: update-demo-nautilus-vlxpf is verified up and running
Dec 21 01:43:49.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-j5rrs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9118'
Dec 21 01:43:49.242: INFO: stderr: ""
Dec 21 01:43:49.242: INFO: stdout: "true"
Dec 21 01:43:49.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-j5rrs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9118'
Dec 21 01:43:49.317: INFO: stderr: ""
Dec 21 01:43:49.317: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 21 01:43:49.317: INFO: validating pod update-demo-nautilus-j5rrs
Dec 21 01:43:49.320: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 21 01:43:49.320: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 21 01:43:49.320: INFO: update-demo-nautilus-j5rrs is verified up and running
STEP: scaling down the replication controller
Dec 21 01:43:49.322: INFO: scanned /root for discovery docs: <nil>
Dec 21 01:43:49.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-9118'
Dec 21 01:43:50.421: INFO: stderr: ""
Dec 21 01:43:50.421: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 21 01:43:50.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9118'
Dec 21 01:43:50.498: INFO: stderr: ""
Dec 21 01:43:50.498: INFO: stdout: "update-demo-nautilus-vlxpf update-demo-nautilus-j5rrs "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 21 01:43:55.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9118'
Dec 21 01:43:55.590: INFO: stderr: ""
Dec 21 01:43:55.590: INFO: stdout: "update-demo-nautilus-vlxpf update-demo-nautilus-j5rrs "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 21 01:44:00.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9118'
Dec 21 01:44:00.666: INFO: stderr: ""
Dec 21 01:44:00.666: INFO: stdout: "update-demo-nautilus-vlxpf "
Dec 21 01:44:00.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-vlxpf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9118'
Dec 21 01:44:00.741: INFO: stderr: ""
Dec 21 01:44:00.741: INFO: stdout: "true"
Dec 21 01:44:00.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-vlxpf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9118'
Dec 21 01:44:00.816: INFO: stderr: ""
Dec 21 01:44:00.816: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 21 01:44:00.816: INFO: validating pod update-demo-nautilus-vlxpf
Dec 21 01:44:00.819: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 21 01:44:00.819: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 21 01:44:00.819: INFO: update-demo-nautilus-vlxpf is verified up and running
STEP: scaling up the replication controller
Dec 21 01:44:00.821: INFO: scanned /root for discovery docs: <nil>
Dec 21 01:44:00.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-9118'
Dec 21 01:44:01.921: INFO: stderr: ""
Dec 21 01:44:01.921: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 21 01:44:01.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9118'
Dec 21 01:44:01.997: INFO: stderr: ""
Dec 21 01:44:01.997: INFO: stdout: "update-demo-nautilus-vlxpf update-demo-nautilus-5wjp2 "
Dec 21 01:44:01.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-vlxpf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9118'
Dec 21 01:44:02.075: INFO: stderr: ""
Dec 21 01:44:02.075: INFO: stdout: "true"
Dec 21 01:44:02.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-vlxpf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9118'
Dec 21 01:44:02.157: INFO: stderr: ""
Dec 21 01:44:02.157: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 21 01:44:02.157: INFO: validating pod update-demo-nautilus-vlxpf
Dec 21 01:44:02.160: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 21 01:44:02.160: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 21 01:44:02.160: INFO: update-demo-nautilus-vlxpf is verified up and running
Dec 21 01:44:02.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-5wjp2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9118'
Dec 21 01:44:02.236: INFO: stderr: ""
Dec 21 01:44:02.236: INFO: stdout: ""
Dec 21 01:44:02.236: INFO: update-demo-nautilus-5wjp2 is created but not running
Dec 21 01:44:07.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9118'
Dec 21 01:44:07.314: INFO: stderr: ""
Dec 21 01:44:07.314: INFO: stdout: "update-demo-nautilus-vlxpf update-demo-nautilus-5wjp2 "
Dec 21 01:44:07.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-vlxpf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9118'
Dec 21 01:44:07.389: INFO: stderr: ""
Dec 21 01:44:07.389: INFO: stdout: "true"
Dec 21 01:44:07.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-vlxpf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9118'
Dec 21 01:44:07.469: INFO: stderr: ""
Dec 21 01:44:07.469: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 21 01:44:07.469: INFO: validating pod update-demo-nautilus-vlxpf
Dec 21 01:44:07.473: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 21 01:44:07.473: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 21 01:44:07.473: INFO: update-demo-nautilus-vlxpf is verified up and running
Dec 21 01:44:07.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-5wjp2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9118'
Dec 21 01:44:07.549: INFO: stderr: ""
Dec 21 01:44:07.549: INFO: stdout: "true"
Dec 21 01:44:07.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-5wjp2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9118'
Dec 21 01:44:07.626: INFO: stderr: ""
Dec 21 01:44:07.626: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 21 01:44:07.626: INFO: validating pod update-demo-nautilus-5wjp2
Dec 21 01:44:07.630: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 21 01:44:07.630: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 21 01:44:07.630: INFO: update-demo-nautilus-5wjp2 is verified up and running
STEP: using delete to clean up resources
Dec 21 01:44:07.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 delete --grace-period=0 --force -f - --namespace=kubectl-9118'
Dec 21 01:44:07.711: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 21 01:44:07.711: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 21 01:44:07.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9118'
Dec 21 01:44:07.793: INFO: stderr: "No resources found in kubectl-9118 namespace.\n"
Dec 21 01:44:07.793: INFO: stdout: ""
Dec 21 01:44:07.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods -l name=update-demo --namespace=kubectl-9118 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 21 01:44:07.871: INFO: stderr: ""
Dec 21 01:44:07.871: INFO: stdout: "update-demo-nautilus-vlxpf\nupdate-demo-nautilus-5wjp2\n"
Dec 21 01:44:08.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9118'
Dec 21 01:44:08.452: INFO: stderr: "No resources found in kubectl-9118 namespace.\n"
Dec 21 01:44:08.452: INFO: stdout: ""
Dec 21 01:44:08.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods -l name=update-demo --namespace=kubectl-9118 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 21 01:44:08.531: INFO: stderr: ""
Dec 21 01:44:08.531: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:44:08.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9118" for this suite.
Dec 21 01:44:14.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:44:14.626: INFO: namespace kubectl-9118 deletion completed in 6.092909808s

â€¢ [SLOW TEST:31.054 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:44:14.626: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-10dabcc6-5848-41ce-ae25-426baf3f1617
STEP: Creating a pod to test consume configMaps
Dec 21 01:44:14.659: INFO: Waiting up to 5m0s for pod "pod-configmaps-6080303a-5740-4817-9247-3f79572dc147" in namespace "configmap-8913" to be "success or failure"
Dec 21 01:44:14.661: INFO: Pod "pod-configmaps-6080303a-5740-4817-9247-3f79572dc147": Phase="Pending", Reason="", readiness=false. Elapsed: 2.417134ms
Dec 21 01:44:16.664: INFO: Pod "pod-configmaps-6080303a-5740-4817-9247-3f79572dc147": Phase="Running", Reason="", readiness=true. Elapsed: 2.005237697s
Dec 21 01:44:18.667: INFO: Pod "pod-configmaps-6080303a-5740-4817-9247-3f79572dc147": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008462226s
STEP: Saw pod success
Dec 21 01:44:18.667: INFO: Pod "pod-configmaps-6080303a-5740-4817-9247-3f79572dc147" satisfied condition "success or failure"
Dec 21 01:44:18.669: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-configmaps-6080303a-5740-4817-9247-3f79572dc147 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 01:44:18.683: INFO: Waiting for pod pod-configmaps-6080303a-5740-4817-9247-3f79572dc147 to disappear
Dec 21 01:44:18.687: INFO: Pod pod-configmaps-6080303a-5740-4817-9247-3f79572dc147 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:44:18.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8913" for this suite.
Dec 21 01:44:24.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:44:24.778: INFO: namespace configmap-8913 deletion completed in 6.088492412s

â€¢ [SLOW TEST:10.151 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:44:24.778: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 21 01:44:24.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-5344'
Dec 21 01:44:24.884: INFO: stderr: ""
Dec 21 01:44:24.884: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Dec 21 01:44:24.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 delete pods e2e-test-httpd-pod --namespace=kubectl-5344'
Dec 21 01:44:39.303: INFO: stderr: ""
Dec 21 01:44:39.303: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:44:39.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5344" for this suite.
Dec 21 01:44:45.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:44:45.397: INFO: namespace kubectl-5344 deletion completed in 6.091702491s

â€¢ [SLOW TEST:20.619 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:44:45.398: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:45:14.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-6275" for this suite.
Dec 21 01:45:20.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:45:20.590: INFO: namespace namespaces-6275 deletion completed in 6.087612994s
STEP: Destroying namespace "nsdeletetest-3443" for this suite.
Dec 21 01:45:20.592: INFO: Namespace nsdeletetest-3443 was already deleted
STEP: Destroying namespace "nsdeletetest-93" for this suite.
Dec 21 01:45:26.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:45:26.686: INFO: namespace nsdeletetest-93 deletion completed in 6.094419047s

â€¢ [SLOW TEST:41.288 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:45:26.687: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 01:45:26.716: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-e4265b9b-519a-40ee-807c-1c8180f181b0" in namespace "security-context-test-8676" to be "success or failure"
Dec 21 01:45:26.718: INFO: Pod "alpine-nnp-false-e4265b9b-519a-40ee-807c-1c8180f181b0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.279261ms
Dec 21 01:45:28.722: INFO: Pod "alpine-nnp-false-e4265b9b-519a-40ee-807c-1c8180f181b0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005499287s
Dec 21 01:45:30.725: INFO: Pod "alpine-nnp-false-e4265b9b-519a-40ee-807c-1c8180f181b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008780467s
Dec 21 01:45:30.725: INFO: Pod "alpine-nnp-false-e4265b9b-519a-40ee-807c-1c8180f181b0" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:45:30.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8676" for this suite.
Dec 21 01:45:36.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:45:36.824: INFO: namespace security-context-test-8676 deletion completed in 6.091006036s

â€¢ [SLOW TEST:10.137 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:45:36.825: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 01:45:36.851: INFO: Creating deployment "test-recreate-deployment"
Dec 21 01:45:36.854: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec 21 01:45:36.862: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Dec 21 01:45:38.867: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec 21 01:45:38.869: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec 21 01:45:38.879: INFO: Updating deployment test-recreate-deployment
Dec 21 01:45:38.879: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 21 01:45:38.972: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-7525 /apis/apps/v1/namespaces/deployment-7525/deployments/test-recreate-deployment 9a365ece-30e4-4ecd-99b3-b2adacbf12f7 7270 2 2019-12-21 01:45:36 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00387b028 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-12-21 01:45:38 +0000 UTC,LastTransitionTime:2019-12-21 01:45:38 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2019-12-21 01:45:38 +0000 UTC,LastTransitionTime:2019-12-21 01:45:36 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Dec 21 01:45:38.976: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-7525 /apis/apps/v1/namespaces/deployment-7525/replicasets/test-recreate-deployment-5f94c574ff b162595c-a6fb-419c-b500-42027e50fccb 7269 1 2019-12-21 01:45:38 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 9a365ece-30e4-4ecd-99b3-b2adacbf12f7 0xc0038de0f7 0xc0038de0f8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0038de158 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 21 01:45:38.977: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec 21 01:45:38.977: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-7525 /apis/apps/v1/namespaces/deployment-7525/replicasets/test-recreate-deployment-68fc85c7bb 6c9bd903-6944-43ba-b47c-e0b348f4be77 7260 2 2019-12-21 01:45:36 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 9a365ece-30e4-4ecd-99b3-b2adacbf12f7 0xc0038de037 0xc0038de038}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0038de098 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 21 01:45:38.979: INFO: Pod "test-recreate-deployment-5f94c574ff-jlxd8" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-jlxd8 test-recreate-deployment-5f94c574ff- deployment-7525 /api/v1/namespaces/deployment-7525/pods/test-recreate-deployment-5f94c574ff-jlxd8 b3b1a95a-524e-4c25-9886-02112703af71 7267 0 2019-12-21 01:45:38 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff b162595c-a6fb-419c-b500-42027e50fccb 0xc00387b7a7 0xc00387b7a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-vcpvn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-vcpvn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-vcpvn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-169,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 01:45:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:45:38.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7525" for this suite.
Dec 21 01:45:44.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:45:45.090: INFO: namespace deployment-7525 deletion completed in 6.10729172s

â€¢ [SLOW TEST:8.265 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:45:45.090: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Dec 21 01:45:45.120: INFO: Waiting up to 5m0s for pod "var-expansion-ce31c8a4-6fe2-45ea-9121-33c14633bdd9" in namespace "var-expansion-1024" to be "success or failure"
Dec 21 01:45:45.123: INFO: Pod "var-expansion-ce31c8a4-6fe2-45ea-9121-33c14633bdd9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.787195ms
Dec 21 01:45:47.126: INFO: Pod "var-expansion-ce31c8a4-6fe2-45ea-9121-33c14633bdd9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005869621s
STEP: Saw pod success
Dec 21 01:45:47.126: INFO: Pod "var-expansion-ce31c8a4-6fe2-45ea-9121-33c14633bdd9" satisfied condition "success or failure"
Dec 21 01:45:47.128: INFO: Trying to get logs from node ip-172-31-29-169 pod var-expansion-ce31c8a4-6fe2-45ea-9121-33c14633bdd9 container dapi-container: <nil>
STEP: delete the pod
Dec 21 01:45:47.140: INFO: Waiting for pod var-expansion-ce31c8a4-6fe2-45ea-9121-33c14633bdd9 to disappear
Dec 21 01:45:47.143: INFO: Pod var-expansion-ce31c8a4-6fe2-45ea-9121-33c14633bdd9 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:45:47.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1024" for this suite.
Dec 21 01:45:53.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:45:53.234: INFO: namespace var-expansion-1024 deletion completed in 6.088311804s

â€¢ [SLOW TEST:8.144 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:45:53.234: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 01:45:53.260: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 21 01:45:56.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 --namespace=crd-publish-openapi-7765 create -f -'
Dec 21 01:45:57.265: INFO: stderr: ""
Dec 21 01:45:57.265: INFO: stdout: "e2e-test-crd-publish-openapi-6451-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 21 01:45:57.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 --namespace=crd-publish-openapi-7765 delete e2e-test-crd-publish-openapi-6451-crds test-cr'
Dec 21 01:45:57.347: INFO: stderr: ""
Dec 21 01:45:57.347: INFO: stdout: "e2e-test-crd-publish-openapi-6451-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Dec 21 01:45:57.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 --namespace=crd-publish-openapi-7765 apply -f -'
Dec 21 01:45:57.518: INFO: stderr: ""
Dec 21 01:45:57.518: INFO: stdout: "e2e-test-crd-publish-openapi-6451-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 21 01:45:57.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 --namespace=crd-publish-openapi-7765 delete e2e-test-crd-publish-openapi-6451-crds test-cr'
Dec 21 01:45:57.600: INFO: stderr: ""
Dec 21 01:45:57.600: INFO: stdout: "e2e-test-crd-publish-openapi-6451-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec 21 01:45:57.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 explain e2e-test-crd-publish-openapi-6451-crds'
Dec 21 01:45:57.755: INFO: stderr: ""
Dec 21 01:45:57.755: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-6451-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:46:00.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7765" for this suite.
Dec 21 01:46:06.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:46:06.910: INFO: namespace crd-publish-openapi-7765 deletion completed in 6.158377453s

â€¢ [SLOW TEST:13.676 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:46:06.910: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 01:46:06.970: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"4799cbe3-fadd-427d-9dd2-7efc98fb2ef0", Controller:(*bool)(0xc004bf1dde), BlockOwnerDeletion:(*bool)(0xc004bf1ddf)}}
Dec 21 01:46:06.979: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"57881582-851b-4ca9-9f07-65591af156d8", Controller:(*bool)(0xc00566160e), BlockOwnerDeletion:(*bool)(0xc00566160f)}}
Dec 21 01:46:06.989: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"82cfd7ff-2a9b-45c5-9de3-610a0525ecb2", Controller:(*bool)(0xc0057ec036), BlockOwnerDeletion:(*bool)(0xc0057ec037)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:46:11.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3849" for this suite.
Dec 21 01:46:18.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:46:18.127: INFO: namespace gc-3849 deletion completed in 6.126129008s

â€¢ [SLOW TEST:11.216 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:46:18.127: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 01:46:18.153: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 21 01:46:21.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 --namespace=crd-publish-openapi-7236 create -f -'
Dec 21 01:46:22.677: INFO: stderr: ""
Dec 21 01:46:22.677: INFO: stdout: "e2e-test-crd-publish-openapi-7366-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 21 01:46:22.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 --namespace=crd-publish-openapi-7236 delete e2e-test-crd-publish-openapi-7366-crds test-cr'
Dec 21 01:46:22.756: INFO: stderr: ""
Dec 21 01:46:22.756: INFO: stdout: "e2e-test-crd-publish-openapi-7366-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Dec 21 01:46:22.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 --namespace=crd-publish-openapi-7236 apply -f -'
Dec 21 01:46:22.922: INFO: stderr: ""
Dec 21 01:46:22.922: INFO: stdout: "e2e-test-crd-publish-openapi-7366-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 21 01:46:22.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 --namespace=crd-publish-openapi-7236 delete e2e-test-crd-publish-openapi-7366-crds test-cr'
Dec 21 01:46:23.004: INFO: stderr: ""
Dec 21 01:46:23.004: INFO: stdout: "e2e-test-crd-publish-openapi-7366-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Dec 21 01:46:23.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 explain e2e-test-crd-publish-openapi-7366-crds'
Dec 21 01:46:23.168: INFO: stderr: ""
Dec 21 01:46:23.168: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7366-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:46:26.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7236" for this suite.
Dec 21 01:46:32.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:46:32.763: INFO: namespace crd-publish-openapi-7236 deletion completed in 6.096274162s

â€¢ [SLOW TEST:14.637 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:46:32.764: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec 21 01:46:32.851: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8483 /api/v1/namespaces/watch-8483/configmaps/e2e-watch-test-watch-closed 87e00f23-3cbf-405f-b436-1dcad8b4667e 7460 0 2019-12-21 01:46:32 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 21 01:46:32.851: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8483 /api/v1/namespaces/watch-8483/configmaps/e2e-watch-test-watch-closed 87e00f23-3cbf-405f-b436-1dcad8b4667e 7461 0 2019-12-21 01:46:32 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec 21 01:46:32.861: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8483 /api/v1/namespaces/watch-8483/configmaps/e2e-watch-test-watch-closed 87e00f23-3cbf-405f-b436-1dcad8b4667e 7462 0 2019-12-21 01:46:32 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 21 01:46:32.861: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8483 /api/v1/namespaces/watch-8483/configmaps/e2e-watch-test-watch-closed 87e00f23-3cbf-405f-b436-1dcad8b4667e 7463 0 2019-12-21 01:46:32 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:46:32.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8483" for this suite.
Dec 21 01:46:38.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:46:38.963: INFO: namespace watch-8483 deletion completed in 6.099496536s

â€¢ [SLOW TEST:6.199 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:46:38.964: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-77eac97b-1069-4697-abd5-995e633d3c3a
STEP: Creating a pod to test consume secrets
Dec 21 01:46:39.002: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-96c1571e-bc57-43a7-b1d1-191a85a2a166" in namespace "projected-2073" to be "success or failure"
Dec 21 01:46:39.004: INFO: Pod "pod-projected-secrets-96c1571e-bc57-43a7-b1d1-191a85a2a166": Phase="Pending", Reason="", readiness=false. Elapsed: 2.260467ms
Dec 21 01:46:41.009: INFO: Pod "pod-projected-secrets-96c1571e-bc57-43a7-b1d1-191a85a2a166": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006636865s
STEP: Saw pod success
Dec 21 01:46:41.009: INFO: Pod "pod-projected-secrets-96c1571e-bc57-43a7-b1d1-191a85a2a166" satisfied condition "success or failure"
Dec 21 01:46:41.011: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-projected-secrets-96c1571e-bc57-43a7-b1d1-191a85a2a166 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 21 01:46:41.023: INFO: Waiting for pod pod-projected-secrets-96c1571e-bc57-43a7-b1d1-191a85a2a166 to disappear
Dec 21 01:46:41.026: INFO: Pod pod-projected-secrets-96c1571e-bc57-43a7-b1d1-191a85a2a166 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:46:41.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2073" for this suite.
Dec 21 01:46:47.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:46:47.124: INFO: namespace projected-2073 deletion completed in 6.094201757s

â€¢ [SLOW TEST:8.161 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:46:47.125: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-90f5d7cf-4df3-439e-88b3-633277603ead in namespace container-probe-4035
Dec 21 01:46:49.164: INFO: Started pod busybox-90f5d7cf-4df3-439e-88b3-633277603ead in namespace container-probe-4035
STEP: checking the pod's current state and verifying that restartCount is present
Dec 21 01:46:49.167: INFO: Initial restart count of pod busybox-90f5d7cf-4df3-439e-88b3-633277603ead is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:50:49.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4035" for this suite.
Dec 21 01:50:55.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:50:55.673: INFO: namespace container-probe-4035 deletion completed in 6.103712933s

â€¢ [SLOW TEST:248.549 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:50:55.674: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Dec 21 01:50:55.703: INFO: Waiting up to 5m0s for pod "var-expansion-6ad52f5a-b13c-4fa3-91fc-f590aefd6409" in namespace "var-expansion-9875" to be "success or failure"
Dec 21 01:50:55.706: INFO: Pod "var-expansion-6ad52f5a-b13c-4fa3-91fc-f590aefd6409": Phase="Pending", Reason="", readiness=false. Elapsed: 3.722259ms
Dec 21 01:50:57.710: INFO: Pod "var-expansion-6ad52f5a-b13c-4fa3-91fc-f590aefd6409": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007620209s
STEP: Saw pod success
Dec 21 01:50:57.711: INFO: Pod "var-expansion-6ad52f5a-b13c-4fa3-91fc-f590aefd6409" satisfied condition "success or failure"
Dec 21 01:50:57.717: INFO: Trying to get logs from node ip-172-31-29-169 pod var-expansion-6ad52f5a-b13c-4fa3-91fc-f590aefd6409 container dapi-container: <nil>
STEP: delete the pod
Dec 21 01:50:57.733: INFO: Waiting for pod var-expansion-6ad52f5a-b13c-4fa3-91fc-f590aefd6409 to disappear
Dec 21 01:50:57.736: INFO: Pod var-expansion-6ad52f5a-b13c-4fa3-91fc-f590aefd6409 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:50:57.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9875" for this suite.
Dec 21 01:51:03.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:51:03.848: INFO: namespace var-expansion-9875 deletion completed in 6.11002487s

â€¢ [SLOW TEST:8.175 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:51:03.849: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Dec 21 01:51:06.408: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2478 pod-service-account-7f1ab0c7-a400-43f2-ae8e-1ad2e170c453 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Dec 21 01:51:06.560: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2478 pod-service-account-7f1ab0c7-a400-43f2-ae8e-1ad2e170c453 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Dec 21 01:51:06.709: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2478 pod-service-account-7f1ab0c7-a400-43f2-ae8e-1ad2e170c453 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:51:06.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2478" for this suite.
Dec 21 01:51:12.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:51:12.962: INFO: namespace svcaccounts-2478 deletion completed in 6.095563071s

â€¢ [SLOW TEST:9.113 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:51:12.962: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 01:51:13.647: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 21 01:51:15.655: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712489873, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712489873, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712489873, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712489873, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 01:51:18.664: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:51:19.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-568" for this suite.
Dec 21 01:51:25.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:51:25.828: INFO: namespace webhook-568 deletion completed in 6.094156919s
STEP: Destroying namespace "webhook-568-markers" for this suite.
Dec 21 01:51:31.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:51:31.952: INFO: namespace webhook-568-markers deletion completed in 6.123937409s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:19.011 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:51:31.974: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-8301
STEP: creating replication controller nodeport-test in namespace services-8301
I1221 01:51:32.017195      22 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-8301, replica count: 2
Dec 21 01:51:35.067: INFO: Creating new exec pod
I1221 01:51:35.067942      22 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 21 01:51:38.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=services-8301 execpodb7l2b -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Dec 21 01:51:38.259: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Dec 21 01:51:38.259: INFO: stdout: ""
Dec 21 01:51:38.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=services-8301 execpodb7l2b -- /bin/sh -x -c nc -zv -t -w 2 10.43.132.166 80'
Dec 21 01:51:38.414: INFO: stderr: "+ nc -zv -t -w 2 10.43.132.166 80\nConnection to 10.43.132.166 80 port [tcp/http] succeeded!\n"
Dec 21 01:51:38.414: INFO: stdout: ""
Dec 21 01:51:38.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=services-8301 execpodb7l2b -- /bin/sh -x -c nc -zv -t -w 2 172.31.29.169 30757'
Dec 21 01:51:38.569: INFO: stderr: "+ nc -zv -t -w 2 172.31.29.169 30757\nConnection to 172.31.29.169 30757 port [tcp/30757] succeeded!\n"
Dec 21 01:51:38.569: INFO: stdout: ""
Dec 21 01:51:38.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=services-8301 execpodb7l2b -- /bin/sh -x -c nc -zv -t -w 2 172.31.25.252 30757'
Dec 21 01:51:38.726: INFO: stderr: "+ nc -zv -t -w 2 172.31.25.252 30757\nConnection to 172.31.25.252 30757 port [tcp/30757] succeeded!\n"
Dec 21 01:51:38.726: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:51:38.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8301" for this suite.
Dec 21 01:51:56.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:51:56.820: INFO: namespace services-8301 deletion completed in 18.091229077s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:24.847 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:51:56.821: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 21 01:51:56.849: INFO: Waiting up to 5m0s for pod "pod-2d04a782-55d8-4918-91fd-3642e8f0bf2e" in namespace "emptydir-1094" to be "success or failure"
Dec 21 01:51:56.852: INFO: Pod "pod-2d04a782-55d8-4918-91fd-3642e8f0bf2e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.139218ms
Dec 21 01:51:58.855: INFO: Pod "pod-2d04a782-55d8-4918-91fd-3642e8f0bf2e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006124378s
STEP: Saw pod success
Dec 21 01:51:58.855: INFO: Pod "pod-2d04a782-55d8-4918-91fd-3642e8f0bf2e" satisfied condition "success or failure"
Dec 21 01:51:58.858: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-2d04a782-55d8-4918-91fd-3642e8f0bf2e container test-container: <nil>
STEP: delete the pod
Dec 21 01:51:58.870: INFO: Waiting for pod pod-2d04a782-55d8-4918-91fd-3642e8f0bf2e to disappear
Dec 21 01:51:58.874: INFO: Pod pod-2d04a782-55d8-4918-91fd-3642e8f0bf2e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:51:58.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1094" for this suite.
Dec 21 01:52:04.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:52:04.963: INFO: namespace emptydir-1094 deletion completed in 6.087216409s

â€¢ [SLOW TEST:8.143 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:52:04.964: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 21 01:52:09.020: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 21 01:52:09.023: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 21 01:52:11.023: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 21 01:52:11.026: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 21 01:52:13.023: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 21 01:52:13.026: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:52:13.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5029" for this suite.
Dec 21 01:52:41.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:52:41.120: INFO: namespace container-lifecycle-hook-5029 deletion completed in 28.091852764s

â€¢ [SLOW TEST:36.156 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:52:41.122: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1221 01:53:11.691348      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 21 01:53:11.691: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:53:11.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4825" for this suite.
Dec 21 01:53:17.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:53:17.818: INFO: namespace gc-4825 deletion completed in 6.123863359s

â€¢ [SLOW TEST:36.696 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:53:17.818: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 21 01:53:17.866: INFO: Waiting up to 5m0s for pod "downward-api-c255d239-f772-4385-96ed-196fc4d29109" in namespace "downward-api-7083" to be "success or failure"
Dec 21 01:53:17.869: INFO: Pod "downward-api-c255d239-f772-4385-96ed-196fc4d29109": Phase="Pending", Reason="", readiness=false. Elapsed: 3.014695ms
Dec 21 01:53:19.872: INFO: Pod "downward-api-c255d239-f772-4385-96ed-196fc4d29109": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006029834s
Dec 21 01:53:21.875: INFO: Pod "downward-api-c255d239-f772-4385-96ed-196fc4d29109": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009274111s
STEP: Saw pod success
Dec 21 01:53:21.875: INFO: Pod "downward-api-c255d239-f772-4385-96ed-196fc4d29109" satisfied condition "success or failure"
Dec 21 01:53:21.878: INFO: Trying to get logs from node ip-172-31-29-169 pod downward-api-c255d239-f772-4385-96ed-196fc4d29109 container dapi-container: <nil>
STEP: delete the pod
Dec 21 01:53:21.896: INFO: Waiting for pod downward-api-c255d239-f772-4385-96ed-196fc4d29109 to disappear
Dec 21 01:53:21.898: INFO: Pod downward-api-c255d239-f772-4385-96ed-196fc4d29109 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:53:21.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7083" for this suite.
Dec 21 01:53:27.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:53:27.987: INFO: namespace downward-api-7083 deletion completed in 6.085648673s

â€¢ [SLOW TEST:10.169 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:53:27.987: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-9821
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-9821
STEP: Creating statefulset with conflicting port in namespace statefulset-9821
STEP: Waiting until pod test-pod will start running in namespace statefulset-9821
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9821
Dec 21 01:53:30.034: INFO: Observed stateful pod in namespace: statefulset-9821, name: ss-0, uid: 76def869-152c-45e6-b362-42658287dcae, status phase: Pending. Waiting for statefulset controller to delete.
Dec 21 01:53:39.291: INFO: Observed stateful pod in namespace: statefulset-9821, name: ss-0, uid: 76def869-152c-45e6-b362-42658287dcae, status phase: Failed. Waiting for statefulset controller to delete.
Dec 21 01:53:39.300: INFO: Observed stateful pod in namespace: statefulset-9821, name: ss-0, uid: 76def869-152c-45e6-b362-42658287dcae, status phase: Failed. Waiting for statefulset controller to delete.
Dec 21 01:53:39.304: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9821
STEP: Removing pod with conflicting port in namespace statefulset-9821
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9821 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 21 01:53:41.363: INFO: Deleting all statefulset in ns statefulset-9821
Dec 21 01:53:41.365: INFO: Scaling statefulset ss to 0
Dec 21 01:53:51.376: INFO: Waiting for statefulset status.replicas updated to 0
Dec 21 01:53:51.378: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:53:51.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9821" for this suite.
Dec 21 01:53:57.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:53:57.499: INFO: namespace statefulset-9821 deletion completed in 6.108172622s

â€¢ [SLOW TEST:29.512 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:53:57.500: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 21 01:53:57.541: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f300c602-2739-4056-8e58-27b346aef076" in namespace "downward-api-4473" to be "success or failure"
Dec 21 01:53:57.546: INFO: Pod "downwardapi-volume-f300c602-2739-4056-8e58-27b346aef076": Phase="Pending", Reason="", readiness=false. Elapsed: 4.885201ms
Dec 21 01:53:59.549: INFO: Pod "downwardapi-volume-f300c602-2739-4056-8e58-27b346aef076": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007963367s
STEP: Saw pod success
Dec 21 01:53:59.549: INFO: Pod "downwardapi-volume-f300c602-2739-4056-8e58-27b346aef076" satisfied condition "success or failure"
Dec 21 01:53:59.551: INFO: Trying to get logs from node ip-172-31-29-169 pod downwardapi-volume-f300c602-2739-4056-8e58-27b346aef076 container client-container: <nil>
STEP: delete the pod
Dec 21 01:53:59.562: INFO: Waiting for pod downwardapi-volume-f300c602-2739-4056-8e58-27b346aef076 to disappear
Dec 21 01:53:59.565: INFO: Pod downwardapi-volume-f300c602-2739-4056-8e58-27b346aef076 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:53:59.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4473" for this suite.
Dec 21 01:54:05.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:54:05.655: INFO: namespace downward-api-4473 deletion completed in 6.087674956s

â€¢ [SLOW TEST:8.155 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:54:05.655: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 01:54:05.680: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Dec 21 01:54:08.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 --namespace=crd-publish-openapi-6524 create -f -'
Dec 21 01:54:09.671: INFO: stderr: ""
Dec 21 01:54:09.671: INFO: stdout: "e2e-test-crd-publish-openapi-5756-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 21 01:54:09.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 --namespace=crd-publish-openapi-6524 delete e2e-test-crd-publish-openapi-5756-crds test-foo'
Dec 21 01:54:09.753: INFO: stderr: ""
Dec 21 01:54:09.753: INFO: stdout: "e2e-test-crd-publish-openapi-5756-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Dec 21 01:54:09.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 --namespace=crd-publish-openapi-6524 apply -f -'
Dec 21 01:54:09.921: INFO: stderr: ""
Dec 21 01:54:09.921: INFO: stdout: "e2e-test-crd-publish-openapi-5756-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 21 01:54:09.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 --namespace=crd-publish-openapi-6524 delete e2e-test-crd-publish-openapi-5756-crds test-foo'
Dec 21 01:54:10.002: INFO: stderr: ""
Dec 21 01:54:10.002: INFO: stdout: "e2e-test-crd-publish-openapi-5756-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Dec 21 01:54:10.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 --namespace=crd-publish-openapi-6524 create -f -'
Dec 21 01:54:10.157: INFO: rc: 1
Dec 21 01:54:10.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 --namespace=crd-publish-openapi-6524 apply -f -'
Dec 21 01:54:10.312: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Dec 21 01:54:10.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 --namespace=crd-publish-openapi-6524 create -f -'
Dec 21 01:54:10.485: INFO: rc: 1
Dec 21 01:54:10.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 --namespace=crd-publish-openapi-6524 apply -f -'
Dec 21 01:54:10.639: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Dec 21 01:54:10.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 explain e2e-test-crd-publish-openapi-5756-crds'
Dec 21 01:54:10.795: INFO: stderr: ""
Dec 21 01:54:10.795: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5756-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Dec 21 01:54:10.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 explain e2e-test-crd-publish-openapi-5756-crds.metadata'
Dec 21 01:54:10.952: INFO: stderr: ""
Dec 21 01:54:10.952: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5756-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Dec 21 01:54:10.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 explain e2e-test-crd-publish-openapi-5756-crds.spec'
Dec 21 01:54:11.120: INFO: stderr: ""
Dec 21 01:54:11.120: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5756-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Dec 21 01:54:11.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 explain e2e-test-crd-publish-openapi-5756-crds.spec.bars'
Dec 21 01:54:11.276: INFO: stderr: ""
Dec 21 01:54:11.276: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5756-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Dec 21 01:54:11.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 explain e2e-test-crd-publish-openapi-5756-crds.spec.bars2'
Dec 21 01:54:11.442: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:54:14.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6524" for this suite.
Dec 21 01:54:20.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:54:20.544: INFO: namespace crd-publish-openapi-6524 deletion completed in 6.118128627s

â€¢ [SLOW TEST:14.889 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:54:20.545: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-66ffebc6-c44c-44b6-a81f-cca8c31a0d88
STEP: Creating a pod to test consume secrets
Dec 21 01:54:20.579: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4314aa19-5b2f-445c-8fc8-60beda9ba168" in namespace "projected-2125" to be "success or failure"
Dec 21 01:54:20.581: INFO: Pod "pod-projected-secrets-4314aa19-5b2f-445c-8fc8-60beda9ba168": Phase="Pending", Reason="", readiness=false. Elapsed: 2.1894ms
Dec 21 01:54:22.585: INFO: Pod "pod-projected-secrets-4314aa19-5b2f-445c-8fc8-60beda9ba168": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005392441s
STEP: Saw pod success
Dec 21 01:54:22.585: INFO: Pod "pod-projected-secrets-4314aa19-5b2f-445c-8fc8-60beda9ba168" satisfied condition "success or failure"
Dec 21 01:54:22.587: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-projected-secrets-4314aa19-5b2f-445c-8fc8-60beda9ba168 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 21 01:54:22.601: INFO: Waiting for pod pod-projected-secrets-4314aa19-5b2f-445c-8fc8-60beda9ba168 to disappear
Dec 21 01:54:22.605: INFO: Pod pod-projected-secrets-4314aa19-5b2f-445c-8fc8-60beda9ba168 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:54:22.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2125" for this suite.
Dec 21 01:54:28.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:54:28.701: INFO: namespace projected-2125 deletion completed in 6.093665966s

â€¢ [SLOW TEST:8.156 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:54:28.702: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-5006, will wait for the garbage collector to delete the pods
Dec 21 01:54:32.790: INFO: Deleting Job.batch foo took: 5.5407ms
Dec 21 01:54:33.191: INFO: Terminating Job.batch foo pods took: 400.292137ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:55:05.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5006" for this suite.
Dec 21 01:55:11.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:55:11.685: INFO: namespace job-5006 deletion completed in 6.089020324s

â€¢ [SLOW TEST:42.983 seconds]
[sig-apps] Job
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:55:11.685: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-3fef6499-4e49-45f2-893c-d913cabf7406
STEP: Creating a pod to test consume secrets
Dec 21 01:55:11.740: INFO: Waiting up to 5m0s for pod "pod-secrets-b9e9063b-c653-46ad-a749-e0e58968fcb1" in namespace "secrets-2502" to be "success or failure"
Dec 21 01:55:11.743: INFO: Pod "pod-secrets-b9e9063b-c653-46ad-a749-e0e58968fcb1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.795983ms
Dec 21 01:55:13.747: INFO: Pod "pod-secrets-b9e9063b-c653-46ad-a749-e0e58968fcb1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006834426s
STEP: Saw pod success
Dec 21 01:55:13.747: INFO: Pod "pod-secrets-b9e9063b-c653-46ad-a749-e0e58968fcb1" satisfied condition "success or failure"
Dec 21 01:55:13.751: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-secrets-b9e9063b-c653-46ad-a749-e0e58968fcb1 container secret-volume-test: <nil>
STEP: delete the pod
Dec 21 01:55:13.768: INFO: Waiting for pod pod-secrets-b9e9063b-c653-46ad-a749-e0e58968fcb1 to disappear
Dec 21 01:55:13.772: INFO: Pod pod-secrets-b9e9063b-c653-46ad-a749-e0e58968fcb1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:55:13.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2502" for this suite.
Dec 21 01:55:19.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:55:19.868: INFO: namespace secrets-2502 deletion completed in 6.09297306s
STEP: Destroying namespace "secret-namespace-8922" for this suite.
Dec 21 01:55:25.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:55:25.962: INFO: namespace secret-namespace-8922 deletion completed in 6.094145142s

â€¢ [SLOW TEST:14.277 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:55:25.962: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:55:37.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3826" for this suite.
Dec 21 01:55:43.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:55:43.121: INFO: namespace resourcequota-3826 deletion completed in 6.099057548s

â€¢ [SLOW TEST:17.159 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:55:43.122: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-9643da3e-8c5e-4e63-8f36-568475951121
STEP: Creating a pod to test consume secrets
Dec 21 01:55:43.154: INFO: Waiting up to 5m0s for pod "pod-secrets-e370b1bb-d5c3-49c7-8103-4a17250dc491" in namespace "secrets-8231" to be "success or failure"
Dec 21 01:55:43.158: INFO: Pod "pod-secrets-e370b1bb-d5c3-49c7-8103-4a17250dc491": Phase="Pending", Reason="", readiness=false. Elapsed: 3.58218ms
Dec 21 01:55:45.161: INFO: Pod "pod-secrets-e370b1bb-d5c3-49c7-8103-4a17250dc491": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006994528s
STEP: Saw pod success
Dec 21 01:55:45.161: INFO: Pod "pod-secrets-e370b1bb-d5c3-49c7-8103-4a17250dc491" satisfied condition "success or failure"
Dec 21 01:55:45.163: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-secrets-e370b1bb-d5c3-49c7-8103-4a17250dc491 container secret-volume-test: <nil>
STEP: delete the pod
Dec 21 01:55:45.176: INFO: Waiting for pod pod-secrets-e370b1bb-d5c3-49c7-8103-4a17250dc491 to disappear
Dec 21 01:55:45.179: INFO: Pod pod-secrets-e370b1bb-d5c3-49c7-8103-4a17250dc491 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:55:45.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8231" for this suite.
Dec 21 01:55:51.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:55:51.280: INFO: namespace secrets-8231 deletion completed in 6.099483867s

â€¢ [SLOW TEST:8.159 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:55:51.281: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 21 01:55:51.331: INFO: Number of nodes with available pods: 0
Dec 21 01:55:51.331: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:55:52.338: INFO: Number of nodes with available pods: 0
Dec 21 01:55:52.338: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:55:53.337: INFO: Number of nodes with available pods: 3
Dec 21 01:55:53.337: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec 21 01:55:53.353: INFO: Number of nodes with available pods: 2
Dec 21 01:55:53.353: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:55:54.359: INFO: Number of nodes with available pods: 2
Dec 21 01:55:54.360: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:55:55.360: INFO: Number of nodes with available pods: 2
Dec 21 01:55:55.360: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:55:56.360: INFO: Number of nodes with available pods: 2
Dec 21 01:55:56.360: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:55:57.359: INFO: Number of nodes with available pods: 2
Dec 21 01:55:57.359: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:55:58.359: INFO: Number of nodes with available pods: 2
Dec 21 01:55:58.359: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:55:59.360: INFO: Number of nodes with available pods: 2
Dec 21 01:55:59.360: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:56:00.360: INFO: Number of nodes with available pods: 2
Dec 21 01:56:00.360: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:56:01.360: INFO: Number of nodes with available pods: 2
Dec 21 01:56:01.360: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:56:02.361: INFO: Number of nodes with available pods: 2
Dec 21 01:56:02.361: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:56:03.360: INFO: Number of nodes with available pods: 2
Dec 21 01:56:03.360: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:56:04.359: INFO: Number of nodes with available pods: 2
Dec 21 01:56:04.360: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 01:56:05.359: INFO: Number of nodes with available pods: 3
Dec 21 01:56:05.359: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3679, will wait for the garbage collector to delete the pods
Dec 21 01:56:05.421: INFO: Deleting DaemonSet.extensions daemon-set took: 5.913558ms
Dec 21 01:56:05.821: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.251497ms
Dec 21 01:56:13.524: INFO: Number of nodes with available pods: 0
Dec 21 01:56:13.524: INFO: Number of running nodes: 0, number of available pods: 0
Dec 21 01:56:13.527: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3679/daemonsets","resourceVersion":"8806"},"items":null}

Dec 21 01:56:13.529: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3679/pods","resourceVersion":"8806"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:56:13.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3679" for this suite.
Dec 21 01:56:19.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:56:19.639: INFO: namespace daemonsets-3679 deletion completed in 6.097623304s

â€¢ [SLOW TEST:28.358 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:56:19.639: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-1da0644f-646e-435b-98cb-b8ea5cc3b14f
STEP: Creating a pod to test consume configMaps
Dec 21 01:56:19.673: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-13aad7f3-50cd-43fc-bfdb-adcd4a060873" in namespace "projected-2078" to be "success or failure"
Dec 21 01:56:19.676: INFO: Pod "pod-projected-configmaps-13aad7f3-50cd-43fc-bfdb-adcd4a060873": Phase="Pending", Reason="", readiness=false. Elapsed: 3.507586ms
Dec 21 01:56:21.680: INFO: Pod "pod-projected-configmaps-13aad7f3-50cd-43fc-bfdb-adcd4a060873": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006716109s
STEP: Saw pod success
Dec 21 01:56:21.680: INFO: Pod "pod-projected-configmaps-13aad7f3-50cd-43fc-bfdb-adcd4a060873" satisfied condition "success or failure"
Dec 21 01:56:21.682: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-projected-configmaps-13aad7f3-50cd-43fc-bfdb-adcd4a060873 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 01:56:21.697: INFO: Waiting for pod pod-projected-configmaps-13aad7f3-50cd-43fc-bfdb-adcd4a060873 to disappear
Dec 21 01:56:21.701: INFO: Pod pod-projected-configmaps-13aad7f3-50cd-43fc-bfdb-adcd4a060873 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:56:21.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2078" for this suite.
Dec 21 01:56:27.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:56:27.794: INFO: namespace projected-2078 deletion completed in 6.090202914s

â€¢ [SLOW TEST:8.155 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:56:27.794: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-4439/secret-test-ccf14f37-33b5-436d-b82b-b0dbd5371f3f
STEP: Creating a pod to test consume secrets
Dec 21 01:56:27.826: INFO: Waiting up to 5m0s for pod "pod-configmaps-b0ff7ecd-b5c7-479b-8688-2f9b378b2168" in namespace "secrets-4439" to be "success or failure"
Dec 21 01:56:27.829: INFO: Pod "pod-configmaps-b0ff7ecd-b5c7-479b-8688-2f9b378b2168": Phase="Pending", Reason="", readiness=false. Elapsed: 2.469441ms
Dec 21 01:56:29.832: INFO: Pod "pod-configmaps-b0ff7ecd-b5c7-479b-8688-2f9b378b2168": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005579935s
STEP: Saw pod success
Dec 21 01:56:29.832: INFO: Pod "pod-configmaps-b0ff7ecd-b5c7-479b-8688-2f9b378b2168" satisfied condition "success or failure"
Dec 21 01:56:29.834: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-configmaps-b0ff7ecd-b5c7-479b-8688-2f9b378b2168 container env-test: <nil>
STEP: delete the pod
Dec 21 01:56:29.847: INFO: Waiting for pod pod-configmaps-b0ff7ecd-b5c7-479b-8688-2f9b378b2168 to disappear
Dec 21 01:56:29.850: INFO: Pod pod-configmaps-b0ff7ecd-b5c7-479b-8688-2f9b378b2168 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:56:29.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4439" for this suite.
Dec 21 01:56:35.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:56:35.945: INFO: namespace secrets-4439 deletion completed in 6.091120135s

â€¢ [SLOW TEST:8.151 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:56:35.946: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-16c5ae2d-e0d0-46d2-b077-b76a5a757b91
STEP: Creating a pod to test consume secrets
Dec 21 01:56:35.977: INFO: Waiting up to 5m0s for pod "pod-secrets-7a64b2e0-8b58-4f65-8947-0006d2304527" in namespace "secrets-5599" to be "success or failure"
Dec 21 01:56:35.985: INFO: Pod "pod-secrets-7a64b2e0-8b58-4f65-8947-0006d2304527": Phase="Pending", Reason="", readiness=false. Elapsed: 8.753615ms
Dec 21 01:56:37.988: INFO: Pod "pod-secrets-7a64b2e0-8b58-4f65-8947-0006d2304527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0118794s
STEP: Saw pod success
Dec 21 01:56:37.988: INFO: Pod "pod-secrets-7a64b2e0-8b58-4f65-8947-0006d2304527" satisfied condition "success or failure"
Dec 21 01:56:37.991: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-secrets-7a64b2e0-8b58-4f65-8947-0006d2304527 container secret-volume-test: <nil>
STEP: delete the pod
Dec 21 01:56:38.006: INFO: Waiting for pod pod-secrets-7a64b2e0-8b58-4f65-8947-0006d2304527 to disappear
Dec 21 01:56:38.008: INFO: Pod pod-secrets-7a64b2e0-8b58-4f65-8947-0006d2304527 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:56:38.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5599" for this suite.
Dec 21 01:56:44.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:56:44.137: INFO: namespace secrets-5599 deletion completed in 6.12605849s

â€¢ [SLOW TEST:8.191 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:56:44.137: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 21 01:56:44.213: INFO: Waiting up to 5m0s for pod "pod-081e69e0-4eb6-4bcd-9601-050386e1391e" in namespace "emptydir-6697" to be "success or failure"
Dec 21 01:56:44.219: INFO: Pod "pod-081e69e0-4eb6-4bcd-9601-050386e1391e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.250426ms
Dec 21 01:56:46.224: INFO: Pod "pod-081e69e0-4eb6-4bcd-9601-050386e1391e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011699659s
STEP: Saw pod success
Dec 21 01:56:46.225: INFO: Pod "pod-081e69e0-4eb6-4bcd-9601-050386e1391e" satisfied condition "success or failure"
Dec 21 01:56:46.228: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-081e69e0-4eb6-4bcd-9601-050386e1391e container test-container: <nil>
STEP: delete the pod
Dec 21 01:56:46.242: INFO: Waiting for pod pod-081e69e0-4eb6-4bcd-9601-050386e1391e to disappear
Dec 21 01:56:46.247: INFO: Pod pod-081e69e0-4eb6-4bcd-9601-050386e1391e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:56:46.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6697" for this suite.
Dec 21 01:56:52.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:56:52.347: INFO: namespace emptydir-6697 deletion completed in 6.097598249s

â€¢ [SLOW TEST:8.210 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:56:52.348: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 21 01:56:52.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-1747'
Dec 21 01:56:52.456: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 21 01:56:52.456: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Dec 21 01:56:52.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 delete jobs e2e-test-httpd-job --namespace=kubectl-1747'
Dec 21 01:56:52.543: INFO: stderr: ""
Dec 21 01:56:52.543: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:56:52.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1747" for this suite.
Dec 21 01:56:58.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:56:58.637: INFO: namespace kubectl-1747 deletion completed in 6.090820253s

â€¢ [SLOW TEST:6.289 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:56:58.637: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-739da18e-192d-433c-b6e4-babc7fb64c7e
STEP: Creating a pod to test consume configMaps
Dec 21 01:56:58.668: INFO: Waiting up to 5m0s for pod "pod-configmaps-66c40f14-a843-4a95-9461-3f1f0a6561d6" in namespace "configmap-8905" to be "success or failure"
Dec 21 01:56:58.676: INFO: Pod "pod-configmaps-66c40f14-a843-4a95-9461-3f1f0a6561d6": Phase="Pending", Reason="", readiness=false. Elapsed: 7.733026ms
Dec 21 01:57:00.679: INFO: Pod "pod-configmaps-66c40f14-a843-4a95-9461-3f1f0a6561d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01076891s
STEP: Saw pod success
Dec 21 01:57:00.679: INFO: Pod "pod-configmaps-66c40f14-a843-4a95-9461-3f1f0a6561d6" satisfied condition "success or failure"
Dec 21 01:57:00.681: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-configmaps-66c40f14-a843-4a95-9461-3f1f0a6561d6 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 01:57:00.693: INFO: Waiting for pod pod-configmaps-66c40f14-a843-4a95-9461-3f1f0a6561d6 to disappear
Dec 21 01:57:00.696: INFO: Pod pod-configmaps-66c40f14-a843-4a95-9461-3f1f0a6561d6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:57:00.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8905" for this suite.
Dec 21 01:57:06.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:57:06.803: INFO: namespace configmap-8905 deletion completed in 6.10389642s

â€¢ [SLOW TEST:8.166 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:57:06.803: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:57:08.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2990" for this suite.
Dec 21 01:57:14.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:57:14.956: INFO: namespace emptydir-wrapper-2990 deletion completed in 6.088915406s

â€¢ [SLOW TEST:8.153 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:57:14.956: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 01:57:14.980: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Creating first CR 
Dec 21 01:57:15.532: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-21T01:57:15Z generation:1 name:name1 resourceVersion:9084 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:7f7d3d5e-1c60-49ac-94b9-ee1250eb4b6e] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Dec 21 01:57:25.536: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-21T01:57:25Z generation:1 name:name2 resourceVersion:9094 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:b3fc1a5a-28c5-4b46-a51c-ab04f856ff0c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Dec 21 01:57:35.540: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-21T01:57:15Z generation:2 name:name1 resourceVersion:9104 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:7f7d3d5e-1c60-49ac-94b9-ee1250eb4b6e] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Dec 21 01:57:45.544: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-21T01:57:25Z generation:2 name:name2 resourceVersion:9115 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:b3fc1a5a-28c5-4b46-a51c-ab04f856ff0c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Dec 21 01:57:55.552: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-21T01:57:15Z generation:2 name:name1 resourceVersion:9126 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:7f7d3d5e-1c60-49ac-94b9-ee1250eb4b6e] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Dec 21 01:58:05.559: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-21T01:57:25Z generation:2 name:name2 resourceVersion:9136 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:b3fc1a5a-28c5-4b46-a51c-ab04f856ff0c] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:58:16.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-7493" for this suite.
Dec 21 01:58:22.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:58:22.157: INFO: namespace crd-watch-7493 deletion completed in 6.088289363s

â€¢ [SLOW TEST:67.201 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:58:22.158: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 01:58:22.635: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 21 01:58:24.642: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712490302, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712490302, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712490302, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712490302, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 01:58:27.651: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:58:28.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-381" for this suite.
Dec 21 01:58:34.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:58:34.803: INFO: namespace webhook-381 deletion completed in 6.097300555s
STEP: Destroying namespace "webhook-381-markers" for this suite.
Dec 21 01:58:40.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:58:40.889: INFO: namespace webhook-381-markers deletion completed in 6.085855874s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:18.742 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:58:40.899: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-136
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-136 to expose endpoints map[]
Dec 21 01:58:40.934: INFO: Get endpoints failed (3.640167ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Dec 21 01:58:41.938: INFO: successfully validated that service multi-endpoint-test in namespace services-136 exposes endpoints map[] (1.00716363s elapsed)
STEP: Creating pod pod1 in namespace services-136
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-136 to expose endpoints map[pod1:[100]]
Dec 21 01:58:43.959: INFO: successfully validated that service multi-endpoint-test in namespace services-136 exposes endpoints map[pod1:[100]] (2.016166629s elapsed)
STEP: Creating pod pod2 in namespace services-136
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-136 to expose endpoints map[pod1:[100] pod2:[101]]
Dec 21 01:58:45.990: INFO: successfully validated that service multi-endpoint-test in namespace services-136 exposes endpoints map[pod1:[100] pod2:[101]] (2.027749725s elapsed)
STEP: Deleting pod pod1 in namespace services-136
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-136 to expose endpoints map[pod2:[101]]
Dec 21 01:58:47.006: INFO: successfully validated that service multi-endpoint-test in namespace services-136 exposes endpoints map[pod2:[101]] (1.011847458s elapsed)
STEP: Deleting pod pod2 in namespace services-136
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-136 to expose endpoints map[]
Dec 21 01:58:48.018: INFO: successfully validated that service multi-endpoint-test in namespace services-136 exposes endpoints map[] (1.008261734s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:58:48.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-136" for this suite.
Dec 21 01:58:54.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:58:54.127: INFO: namespace services-136 deletion completed in 6.091925987s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:13.227 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:58:54.127: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-56gb
STEP: Creating a pod to test atomic-volume-subpath
Dec 21 01:58:54.160: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-56gb" in namespace "subpath-9728" to be "success or failure"
Dec 21 01:58:54.162: INFO: Pod "pod-subpath-test-projected-56gb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.8861ms
Dec 21 01:58:56.165: INFO: Pod "pod-subpath-test-projected-56gb": Phase="Running", Reason="", readiness=true. Elapsed: 2.005893697s
Dec 21 01:58:58.169: INFO: Pod "pod-subpath-test-projected-56gb": Phase="Running", Reason="", readiness=true. Elapsed: 4.009000508s
Dec 21 01:59:00.172: INFO: Pod "pod-subpath-test-projected-56gb": Phase="Running", Reason="", readiness=true. Elapsed: 6.012332572s
Dec 21 01:59:02.175: INFO: Pod "pod-subpath-test-projected-56gb": Phase="Running", Reason="", readiness=true. Elapsed: 8.015729388s
Dec 21 01:59:04.178: INFO: Pod "pod-subpath-test-projected-56gb": Phase="Running", Reason="", readiness=true. Elapsed: 10.018826814s
Dec 21 01:59:06.182: INFO: Pod "pod-subpath-test-projected-56gb": Phase="Running", Reason="", readiness=true. Elapsed: 12.022170205s
Dec 21 01:59:08.185: INFO: Pod "pod-subpath-test-projected-56gb": Phase="Running", Reason="", readiness=true. Elapsed: 14.025407575s
Dec 21 01:59:10.189: INFO: Pod "pod-subpath-test-projected-56gb": Phase="Running", Reason="", readiness=true. Elapsed: 16.029207865s
Dec 21 01:59:12.192: INFO: Pod "pod-subpath-test-projected-56gb": Phase="Running", Reason="", readiness=true. Elapsed: 18.032339657s
Dec 21 01:59:14.195: INFO: Pod "pod-subpath-test-projected-56gb": Phase="Running", Reason="", readiness=true. Elapsed: 20.035568813s
Dec 21 01:59:16.198: INFO: Pod "pod-subpath-test-projected-56gb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.03891414s
STEP: Saw pod success
Dec 21 01:59:16.199: INFO: Pod "pod-subpath-test-projected-56gb" satisfied condition "success or failure"
Dec 21 01:59:16.201: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-subpath-test-projected-56gb container test-container-subpath-projected-56gb: <nil>
STEP: delete the pod
Dec 21 01:59:16.218: INFO: Waiting for pod pod-subpath-test-projected-56gb to disappear
Dec 21 01:59:16.223: INFO: Pod pod-subpath-test-projected-56gb no longer exists
STEP: Deleting pod pod-subpath-test-projected-56gb
Dec 21 01:59:16.223: INFO: Deleting pod "pod-subpath-test-projected-56gb" in namespace "subpath-9728"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:59:16.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9728" for this suite.
Dec 21 01:59:22.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:59:22.319: INFO: namespace subpath-9728 deletion completed in 6.092186282s

â€¢ [SLOW TEST:28.193 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:59:22.320: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 21 01:59:26.871: INFO: Successfully updated pod "labelsupdatec270224c-8966-4798-b5c5-4f9840447651"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:59:28.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6444" for this suite.
Dec 21 01:59:40.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:59:40.977: INFO: namespace downward-api-6444 deletion completed in 12.087289283s

â€¢ [SLOW TEST:18.657 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:59:40.977: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 21 01:59:41.005: INFO: Waiting up to 5m0s for pod "downwardapi-volume-89ebb3f6-2bce-4497-935f-2d99e9d73872" in namespace "downward-api-2788" to be "success or failure"
Dec 21 01:59:41.007: INFO: Pod "downwardapi-volume-89ebb3f6-2bce-4497-935f-2d99e9d73872": Phase="Pending", Reason="", readiness=false. Elapsed: 2.563958ms
Dec 21 01:59:43.011: INFO: Pod "downwardapi-volume-89ebb3f6-2bce-4497-935f-2d99e9d73872": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005787271s
STEP: Saw pod success
Dec 21 01:59:43.011: INFO: Pod "downwardapi-volume-89ebb3f6-2bce-4497-935f-2d99e9d73872" satisfied condition "success or failure"
Dec 21 01:59:43.013: INFO: Trying to get logs from node ip-172-31-29-169 pod downwardapi-volume-89ebb3f6-2bce-4497-935f-2d99e9d73872 container client-container: <nil>
STEP: delete the pod
Dec 21 01:59:43.028: INFO: Waiting for pod downwardapi-volume-89ebb3f6-2bce-4497-935f-2d99e9d73872 to disappear
Dec 21 01:59:43.032: INFO: Pod downwardapi-volume-89ebb3f6-2bce-4497-935f-2d99e9d73872 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:59:43.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2788" for this suite.
Dec 21 01:59:49.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:59:49.124: INFO: namespace downward-api-2788 deletion completed in 6.089252142s

â€¢ [SLOW TEST:8.147 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:59:49.124: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 21 01:59:49.148: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 21 01:59:49.156: INFO: Waiting for terminating namespaces to be deleted...
Dec 21 01:59:49.158: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-29-141 before test
Dec 21 01:59:49.166: INFO: sonobuoy-systemd-logs-daemon-set-be71f149a5064d0d-pn2hq from sonobuoy started at 2019-12-21 01:24:53 +0000 UTC (2 container statuses recorded)
Dec 21 01:59:49.166: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 01:59:49.166: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 21 01:59:49.166: INFO: svclb-traefik-7ksbn from kube-system started at 2019-12-21 00:42:23 +0000 UTC (3 container statuses recorded)
Dec 21 01:59:49.166: INFO: 	Container lb-port-443 ready: true, restart count 0
Dec 21 01:59:49.166: INFO: 	Container lb-port-80 ready: true, restart count 0
Dec 21 01:59:49.166: INFO: 	Container lb-port-8080 ready: true, restart count 0
Dec 21 01:59:49.166: INFO: sonobuoy-e2e-job-c939600be6994601 from sonobuoy started at 2019-12-21 01:24:52 +0000 UTC (2 container statuses recorded)
Dec 21 01:59:49.166: INFO: 	Container e2e ready: true, restart count 0
Dec 21 01:59:49.166: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 01:59:49.166: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-25-252 before test
Dec 21 01:59:49.174: INFO: helm-install-traefik-hhwxg from kube-system started at 2019-12-21 00:41:22 +0000 UTC (1 container statuses recorded)
Dec 21 01:59:49.174: INFO: 	Container helm ready: false, restart count 0
Dec 21 01:59:49.174: INFO: metrics-server-6d684c7b5-t9j6h from kube-system started at 2019-12-21 00:41:22 +0000 UTC (1 container statuses recorded)
Dec 21 01:59:49.174: INFO: 	Container metrics-server ready: true, restart count 0
Dec 21 01:59:49.174: INFO: coredns-d798c9dd-llwxl from kube-system started at 2019-12-21 00:41:22 +0000 UTC (1 container statuses recorded)
Dec 21 01:59:49.174: INFO: 	Container coredns ready: true, restart count 0
Dec 21 01:59:49.174: INFO: local-path-provisioner-58fb86bdfd-62kwn from kube-system started at 2019-12-21 00:41:22 +0000 UTC (1 container statuses recorded)
Dec 21 01:59:49.174: INFO: 	Container local-path-provisioner ready: true, restart count 0
Dec 21 01:59:49.174: INFO: traefik-65bccdc4bd-xhwzd from kube-system started at 2019-12-21 00:41:53 +0000 UTC (1 container statuses recorded)
Dec 21 01:59:49.174: INFO: 	Container traefik ready: true, restart count 0
Dec 21 01:59:49.174: INFO: svclb-traefik-lnc6c from kube-system started at 2019-12-21 00:41:53 +0000 UTC (3 container statuses recorded)
Dec 21 01:59:49.174: INFO: 	Container lb-port-443 ready: true, restart count 0
Dec 21 01:59:49.174: INFO: 	Container lb-port-80 ready: true, restart count 0
Dec 21 01:59:49.174: INFO: 	Container lb-port-8080 ready: true, restart count 0
Dec 21 01:59:49.174: INFO: sonobuoy-systemd-logs-daemon-set-be71f149a5064d0d-5z58c from sonobuoy started at 2019-12-21 01:24:52 +0000 UTC (2 container statuses recorded)
Dec 21 01:59:49.174: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 01:59:49.174: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 21 01:59:49.174: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-29-169 before test
Dec 21 01:59:49.178: INFO: svclb-traefik-nnb5s from kube-system started at 2019-12-21 00:42:09 +0000 UTC (3 container statuses recorded)
Dec 21 01:59:49.178: INFO: 	Container lb-port-443 ready: true, restart count 0
Dec 21 01:59:49.178: INFO: 	Container lb-port-80 ready: true, restart count 0
Dec 21 01:59:49.178: INFO: 	Container lb-port-8080 ready: true, restart count 0
Dec 21 01:59:49.178: INFO: sonobuoy from sonobuoy started at 2019-12-21 01:24:48 +0000 UTC (1 container statuses recorded)
Dec 21 01:59:49.178: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 21 01:59:49.178: INFO: sonobuoy-systemd-logs-daemon-set-be71f149a5064d0d-kxt8c from sonobuoy started at 2019-12-21 01:24:53 +0000 UTC (2 container statuses recorded)
Dec 21 01:59:49.178: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 01:59:49.178: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15e2405d5789546c], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 01:59:50.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4479" for this suite.
Dec 21 01:59:56.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 01:59:56.290: INFO: namespace sched-pred-4479 deletion completed in 6.092178064s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

â€¢ [SLOW TEST:7.166 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 01:59:56.290: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-389
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-389
I1221 01:59:56.332787      22 runners.go:184] Created replication controller with name: externalname-service, namespace: services-389, replica count: 2
Dec 21 01:59:59.383: INFO: Creating new exec pod
I1221 01:59:59.383607      22 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 21 02:00:02.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=services-389 execpodl7hzp -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec 21 02:00:02.546: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 21 02:00:02.546: INFO: stdout: ""
Dec 21 02:00:02.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=services-389 execpodl7hzp -- /bin/sh -x -c nc -zv -t -w 2 10.43.18.92 80'
Dec 21 02:00:02.706: INFO: stderr: "+ nc -zv -t -w 2 10.43.18.92 80\nConnection to 10.43.18.92 80 port [tcp/http] succeeded!\n"
Dec 21 02:00:02.706: INFO: stdout: ""
Dec 21 02:00:02.706: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:00:02.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-389" for this suite.
Dec 21 02:00:30.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:00:30.820: INFO: namespace services-389 deletion completed in 28.093859036s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:34.529 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:00:30.820: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:00:36.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3250" for this suite.
Dec 21 02:00:42.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:00:42.956: INFO: namespace job-3250 deletion completed in 6.102588407s

â€¢ [SLOW TEST:12.136 seconds]
[sig-apps] Job
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:00:42.956: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-78c4d034-42ce-4f6f-9aa0-a1e31049c6a7 in namespace container-probe-4129
Dec 21 02:00:44.993: INFO: Started pod liveness-78c4d034-42ce-4f6f-9aa0-a1e31049c6a7 in namespace container-probe-4129
STEP: checking the pod's current state and verifying that restartCount is present
Dec 21 02:00:44.995: INFO: Initial restart count of pod liveness-78c4d034-42ce-4f6f-9aa0-a1e31049c6a7 is 0
Dec 21 02:01:01.022: INFO: Restart count of pod container-probe-4129/liveness-78c4d034-42ce-4f6f-9aa0-a1e31049c6a7 is now 1 (16.0275075s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:01:01.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4129" for this suite.
Dec 21 02:01:07.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:01:07.125: INFO: namespace container-probe-4129 deletion completed in 6.0921133s

â€¢ [SLOW TEST:24.169 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:01:07.126: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8471.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8471.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8471.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8471.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 21 02:01:09.173: INFO: DNS probes using dns-test-62ffde12-858d-4b10-97c2-c22682f7315b succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8471.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8471.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8471.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8471.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 21 02:01:11.205: INFO: File wheezy_udp@dns-test-service-3.dns-8471.svc.cluster.local from pod  dns-8471/dns-test-2c06d8b9-8110-4ceb-a1e1-20007c62ca50 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 21 02:01:11.208: INFO: File jessie_udp@dns-test-service-3.dns-8471.svc.cluster.local from pod  dns-8471/dns-test-2c06d8b9-8110-4ceb-a1e1-20007c62ca50 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 21 02:01:11.208: INFO: Lookups using dns-8471/dns-test-2c06d8b9-8110-4ceb-a1e1-20007c62ca50 failed for: [wheezy_udp@dns-test-service-3.dns-8471.svc.cluster.local jessie_udp@dns-test-service-3.dns-8471.svc.cluster.local]

Dec 21 02:01:16.215: INFO: DNS probes using dns-test-2c06d8b9-8110-4ceb-a1e1-20007c62ca50 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8471.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-8471.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8471.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-8471.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 21 02:01:18.266: INFO: DNS probes using dns-test-d1a34631-fcee-46aa-92e9-78e89f8bab21 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:01:18.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8471" for this suite.
Dec 21 02:01:24.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:01:24.391: INFO: namespace dns-8471 deletion completed in 6.098102527s

â€¢ [SLOW TEST:17.266 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:01:24.392: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 21 02:01:24.417: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 21 02:01:24.424: INFO: Waiting for terminating namespaces to be deleted...
Dec 21 02:01:24.426: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-29-169 before test
Dec 21 02:01:24.435: INFO: sonobuoy-systemd-logs-daemon-set-be71f149a5064d0d-kxt8c from sonobuoy started at 2019-12-21 01:24:53 +0000 UTC (2 container statuses recorded)
Dec 21 02:01:24.435: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 02:01:24.435: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 21 02:01:24.435: INFO: svclb-traefik-nnb5s from kube-system started at 2019-12-21 00:42:09 +0000 UTC (3 container statuses recorded)
Dec 21 02:01:24.435: INFO: 	Container lb-port-443 ready: true, restart count 0
Dec 21 02:01:24.435: INFO: 	Container lb-port-80 ready: true, restart count 0
Dec 21 02:01:24.435: INFO: 	Container lb-port-8080 ready: true, restart count 0
Dec 21 02:01:24.435: INFO: sonobuoy from sonobuoy started at 2019-12-21 01:24:48 +0000 UTC (1 container statuses recorded)
Dec 21 02:01:24.435: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 21 02:01:24.435: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-29-141 before test
Dec 21 02:01:24.442: INFO: sonobuoy-systemd-logs-daemon-set-be71f149a5064d0d-pn2hq from sonobuoy started at 2019-12-21 01:24:53 +0000 UTC (2 container statuses recorded)
Dec 21 02:01:24.442: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 02:01:24.442: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 21 02:01:24.442: INFO: svclb-traefik-7ksbn from kube-system started at 2019-12-21 00:42:23 +0000 UTC (3 container statuses recorded)
Dec 21 02:01:24.442: INFO: 	Container lb-port-443 ready: true, restart count 0
Dec 21 02:01:24.442: INFO: 	Container lb-port-80 ready: true, restart count 0
Dec 21 02:01:24.442: INFO: 	Container lb-port-8080 ready: true, restart count 0
Dec 21 02:01:24.442: INFO: sonobuoy-e2e-job-c939600be6994601 from sonobuoy started at 2019-12-21 01:24:52 +0000 UTC (2 container statuses recorded)
Dec 21 02:01:24.442: INFO: 	Container e2e ready: true, restart count 0
Dec 21 02:01:24.442: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 02:01:24.442: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-25-252 before test
Dec 21 02:01:24.449: INFO: local-path-provisioner-58fb86bdfd-62kwn from kube-system started at 2019-12-21 00:41:22 +0000 UTC (1 container statuses recorded)
Dec 21 02:01:24.449: INFO: 	Container local-path-provisioner ready: true, restart count 0
Dec 21 02:01:24.449: INFO: traefik-65bccdc4bd-xhwzd from kube-system started at 2019-12-21 00:41:53 +0000 UTC (1 container statuses recorded)
Dec 21 02:01:24.449: INFO: 	Container traefik ready: true, restart count 0
Dec 21 02:01:24.449: INFO: svclb-traefik-lnc6c from kube-system started at 2019-12-21 00:41:53 +0000 UTC (3 container statuses recorded)
Dec 21 02:01:24.449: INFO: 	Container lb-port-443 ready: true, restart count 0
Dec 21 02:01:24.449: INFO: 	Container lb-port-80 ready: true, restart count 0
Dec 21 02:01:24.449: INFO: 	Container lb-port-8080 ready: true, restart count 0
Dec 21 02:01:24.449: INFO: sonobuoy-systemd-logs-daemon-set-be71f149a5064d0d-5z58c from sonobuoy started at 2019-12-21 01:24:52 +0000 UTC (2 container statuses recorded)
Dec 21 02:01:24.449: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 02:01:24.449: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 21 02:01:24.449: INFO: helm-install-traefik-hhwxg from kube-system started at 2019-12-21 00:41:22 +0000 UTC (1 container statuses recorded)
Dec 21 02:01:24.449: INFO: 	Container helm ready: false, restart count 0
Dec 21 02:01:24.449: INFO: metrics-server-6d684c7b5-t9j6h from kube-system started at 2019-12-21 00:41:22 +0000 UTC (1 container statuses recorded)
Dec 21 02:01:24.449: INFO: 	Container metrics-server ready: true, restart count 0
Dec 21 02:01:24.449: INFO: coredns-d798c9dd-llwxl from kube-system started at 2019-12-21 00:41:22 +0000 UTC (1 container statuses recorded)
Dec 21 02:01:24.449: INFO: 	Container coredns ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-f0772ef7-03c8-4626-a710-61e6f94493a9 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-f0772ef7-03c8-4626-a710-61e6f94493a9 off the node ip-172-31-29-169
STEP: verifying the node doesn't have the label kubernetes.io/e2e-f0772ef7-03c8-4626-a710-61e6f94493a9
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:01:28.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5173" for this suite.
Dec 21 02:01:40.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:01:40.605: INFO: namespace sched-pred-5173 deletion completed in 12.098788129s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

â€¢ [SLOW TEST:16.212 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:01:40.605: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec 21 02:01:40.636: INFO: Waiting up to 5m0s for pod "pod-5d1066e4-45fd-4102-ad63-4568ea207cb4" in namespace "emptydir-9294" to be "success or failure"
Dec 21 02:01:40.643: INFO: Pod "pod-5d1066e4-45fd-4102-ad63-4568ea207cb4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.552012ms
Dec 21 02:01:42.646: INFO: Pod "pod-5d1066e4-45fd-4102-ad63-4568ea207cb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010111325s
STEP: Saw pod success
Dec 21 02:01:42.646: INFO: Pod "pod-5d1066e4-45fd-4102-ad63-4568ea207cb4" satisfied condition "success or failure"
Dec 21 02:01:42.649: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-5d1066e4-45fd-4102-ad63-4568ea207cb4 container test-container: <nil>
STEP: delete the pod
Dec 21 02:01:42.662: INFO: Waiting for pod pod-5d1066e4-45fd-4102-ad63-4568ea207cb4 to disappear
Dec 21 02:01:42.666: INFO: Pod pod-5d1066e4-45fd-4102-ad63-4568ea207cb4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:01:42.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9294" for this suite.
Dec 21 02:01:48.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:01:48.761: INFO: namespace emptydir-9294 deletion completed in 6.093031956s

â€¢ [SLOW TEST:8.157 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:01:48.762: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-039597fc-795b-4c12-865a-bd0d390a7773
Dec 21 02:01:48.791: INFO: Pod name my-hostname-basic-039597fc-795b-4c12-865a-bd0d390a7773: Found 0 pods out of 1
Dec 21 02:01:53.795: INFO: Pod name my-hostname-basic-039597fc-795b-4c12-865a-bd0d390a7773: Found 1 pods out of 1
Dec 21 02:01:53.795: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-039597fc-795b-4c12-865a-bd0d390a7773" are running
Dec 21 02:01:53.797: INFO: Pod "my-hostname-basic-039597fc-795b-4c12-865a-bd0d390a7773-67549" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-21 02:01:48 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-21 02:01:50 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-21 02:01:50 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-21 02:01:48 +0000 UTC Reason: Message:}])
Dec 21 02:01:53.797: INFO: Trying to dial the pod
Dec 21 02:01:58.806: INFO: Controller my-hostname-basic-039597fc-795b-4c12-865a-bd0d390a7773: Got expected result from replica 1 [my-hostname-basic-039597fc-795b-4c12-865a-bd0d390a7773-67549]: "my-hostname-basic-039597fc-795b-4c12-865a-bd0d390a7773-67549", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:01:58.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1513" for this suite.
Dec 21 02:02:04.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:02:04.899: INFO: namespace replication-controller-1513 deletion completed in 6.090244264s

â€¢ [SLOW TEST:16.137 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:02:04.899: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Dec 21 02:02:04.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 create -f - --namespace=kubectl-5781'
Dec 21 02:02:05.133: INFO: stderr: ""
Dec 21 02:02:05.133: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 21 02:02:05.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5781'
Dec 21 02:02:05.216: INFO: stderr: ""
Dec 21 02:02:05.216: INFO: stdout: "update-demo-nautilus-qhsbh update-demo-nautilus-8gnmr "
Dec 21 02:02:05.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-qhsbh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5781'
Dec 21 02:02:05.291: INFO: stderr: ""
Dec 21 02:02:05.292: INFO: stdout: ""
Dec 21 02:02:05.292: INFO: update-demo-nautilus-qhsbh is created but not running
Dec 21 02:02:10.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5781'
Dec 21 02:02:10.369: INFO: stderr: ""
Dec 21 02:02:10.369: INFO: stdout: "update-demo-nautilus-qhsbh update-demo-nautilus-8gnmr "
Dec 21 02:02:10.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-qhsbh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5781'
Dec 21 02:02:10.444: INFO: stderr: ""
Dec 21 02:02:10.444: INFO: stdout: "true"
Dec 21 02:02:10.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-qhsbh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5781'
Dec 21 02:02:10.519: INFO: stderr: ""
Dec 21 02:02:10.519: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 21 02:02:10.519: INFO: validating pod update-demo-nautilus-qhsbh
Dec 21 02:02:10.523: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 21 02:02:10.523: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 21 02:02:10.523: INFO: update-demo-nautilus-qhsbh is verified up and running
Dec 21 02:02:10.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-8gnmr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5781'
Dec 21 02:02:10.601: INFO: stderr: ""
Dec 21 02:02:10.601: INFO: stdout: "true"
Dec 21 02:02:10.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-8gnmr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5781'
Dec 21 02:02:10.675: INFO: stderr: ""
Dec 21 02:02:10.676: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 21 02:02:10.676: INFO: validating pod update-demo-nautilus-8gnmr
Dec 21 02:02:10.680: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 21 02:02:10.680: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 21 02:02:10.680: INFO: update-demo-nautilus-8gnmr is verified up and running
STEP: using delete to clean up resources
Dec 21 02:02:10.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 delete --grace-period=0 --force -f - --namespace=kubectl-5781'
Dec 21 02:02:10.758: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 21 02:02:10.758: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 21 02:02:10.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5781'
Dec 21 02:02:10.840: INFO: stderr: "No resources found in kubectl-5781 namespace.\n"
Dec 21 02:02:10.840: INFO: stdout: ""
Dec 21 02:02:10.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods -l name=update-demo --namespace=kubectl-5781 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 21 02:02:10.918: INFO: stderr: ""
Dec 21 02:02:10.918: INFO: stdout: "update-demo-nautilus-qhsbh\nupdate-demo-nautilus-8gnmr\n"
Dec 21 02:02:11.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5781'
Dec 21 02:02:11.503: INFO: stderr: "No resources found in kubectl-5781 namespace.\n"
Dec 21 02:02:11.503: INFO: stdout: ""
Dec 21 02:02:11.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods -l name=update-demo --namespace=kubectl-5781 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 21 02:02:11.585: INFO: stderr: ""
Dec 21 02:02:11.585: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:02:11.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5781" for this suite.
Dec 21 02:02:39.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:02:39.694: INFO: namespace kubectl-5781 deletion completed in 28.106362017s

â€¢ [SLOW TEST:34.795 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:02:39.695: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Dec 21 02:02:40.238: INFO: created pod pod-service-account-defaultsa
Dec 21 02:02:40.238: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec 21 02:02:40.243: INFO: created pod pod-service-account-mountsa
Dec 21 02:02:40.243: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec 21 02:02:40.253: INFO: created pod pod-service-account-nomountsa
Dec 21 02:02:40.253: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec 21 02:02:40.263: INFO: created pod pod-service-account-defaultsa-mountspec
Dec 21 02:02:40.263: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec 21 02:02:40.270: INFO: created pod pod-service-account-mountsa-mountspec
Dec 21 02:02:40.270: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec 21 02:02:40.285: INFO: created pod pod-service-account-nomountsa-mountspec
Dec 21 02:02:40.285: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec 21 02:02:40.320: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec 21 02:02:40.320: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec 21 02:02:40.325: INFO: created pod pod-service-account-mountsa-nomountspec
Dec 21 02:02:40.325: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec 21 02:02:40.330: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec 21 02:02:40.330: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:02:40.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5574" for this suite.
Dec 21 02:02:46.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:02:46.498: INFO: namespace svcaccounts-5574 deletion completed in 6.158843221s

â€¢ [SLOW TEST:6.803 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:02:46.499: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 02:03:10.546: INFO: Container started at 2019-12-21 02:02:47 +0000 UTC, pod became ready at 2019-12-21 02:03:08 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:03:10.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2730" for this suite.
Dec 21 02:03:22.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:03:22.636: INFO: namespace container-probe-2730 deletion completed in 12.088271485s

â€¢ [SLOW TEST:36.138 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:03:22.637: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 02:03:23.237: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 21 02:03:25.245: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712490603, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712490603, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712490603, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712490603, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 02:03:28.253: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 02:03:28.256: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8562-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:03:30.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1794" for this suite.
Dec 21 02:03:36.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:03:36.513: INFO: namespace webhook-1794 deletion completed in 6.105843032s
STEP: Destroying namespace "webhook-1794-markers" for this suite.
Dec 21 02:03:42.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:03:42.622: INFO: namespace webhook-1794-markers deletion completed in 6.10886905s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:19.998 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:03:42.635: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec 21 02:03:43.150: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 02:03:46.163: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 02:03:46.166: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:03:48.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-6212" for this suite.
Dec 21 02:03:54.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:03:54.413: INFO: namespace crd-webhook-6212 deletion completed in 6.096975589s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

â€¢ [SLOW TEST:11.789 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:03:54.424: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:03:56.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-55" for this suite.
Dec 21 02:04:40.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:04:40.577: INFO: namespace kubelet-test-55 deletion completed in 44.098604224s

â€¢ [SLOW TEST:46.153 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:04:40.577: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 21 02:04:42.617: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:04:42.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7587" for this suite.
Dec 21 02:04:48.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:04:48.723: INFO: namespace container-runtime-7587 deletion completed in 6.093619699s

â€¢ [SLOW TEST:8.146 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:04:48.724: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Dec 21 02:04:48.753: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:04:59.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4945" for this suite.
Dec 21 02:05:05.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:05:05.419: INFO: namespace pods-4945 deletion completed in 6.096621575s

â€¢ [SLOW TEST:16.695 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:05:05.419: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-9472
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-9472
I1221 02:05:05.468693      22 runners.go:184] Created replication controller with name: externalname-service, namespace: services-9472, replica count: 2
I1221 02:05:08.519191      22 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 21 02:05:08.519: INFO: Creating new exec pod
Dec 21 02:05:11.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=services-9472 execpod9twsb -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec 21 02:05:12.458: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 21 02:05:12.458: INFO: stdout: ""
Dec 21 02:05:12.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=services-9472 execpod9twsb -- /bin/sh -x -c nc -zv -t -w 2 10.43.150.203 80'
Dec 21 02:05:12.622: INFO: stderr: "+ nc -zv -t -w 2 10.43.150.203 80\nConnection to 10.43.150.203 80 port [tcp/http] succeeded!\n"
Dec 21 02:05:12.622: INFO: stdout: ""
Dec 21 02:05:12.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=services-9472 execpod9twsb -- /bin/sh -x -c nc -zv -t -w 2 172.31.25.252 30997'
Dec 21 02:05:13.783: INFO: stderr: "+ nc -zv -t -w 2 172.31.25.252 30997\nConnection to 172.31.25.252 30997 port [tcp/30997] succeeded!\n"
Dec 21 02:05:13.783: INFO: stdout: ""
Dec 21 02:05:13.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=services-9472 execpod9twsb -- /bin/sh -x -c nc -zv -t -w 2 172.31.29.141 30997'
Dec 21 02:05:13.940: INFO: stderr: "+ nc -zv -t -w 2 172.31.29.141 30997\nConnection to 172.31.29.141 30997 port [tcp/30997] succeeded!\n"
Dec 21 02:05:13.940: INFO: stdout: ""
Dec 21 02:05:13.940: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:05:13.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9472" for this suite.
Dec 21 02:05:41.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:05:42.057: INFO: namespace services-9472 deletion completed in 28.096170484s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:36.638 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:05:42.057: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:05:59.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2088" for this suite.
Dec 21 02:06:05.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:06:05.220: INFO: namespace resourcequota-2088 deletion completed in 6.090000765s

â€¢ [SLOW TEST:23.163 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:06:05.220: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-e38fa1c0-8719-4de1-80b5-72a805893567
STEP: Creating a pod to test consume configMaps
Dec 21 02:06:05.255: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6e575dcc-8d71-4e2e-8b27-312af097ea92" in namespace "projected-4275" to be "success or failure"
Dec 21 02:06:05.258: INFO: Pod "pod-projected-configmaps-6e575dcc-8d71-4e2e-8b27-312af097ea92": Phase="Pending", Reason="", readiness=false. Elapsed: 2.395788ms
Dec 21 02:06:07.261: INFO: Pod "pod-projected-configmaps-6e575dcc-8d71-4e2e-8b27-312af097ea92": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005634243s
STEP: Saw pod success
Dec 21 02:06:07.261: INFO: Pod "pod-projected-configmaps-6e575dcc-8d71-4e2e-8b27-312af097ea92" satisfied condition "success or failure"
Dec 21 02:06:07.263: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-projected-configmaps-6e575dcc-8d71-4e2e-8b27-312af097ea92 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 02:06:07.276: INFO: Waiting for pod pod-projected-configmaps-6e575dcc-8d71-4e2e-8b27-312af097ea92 to disappear
Dec 21 02:06:07.279: INFO: Pod pod-projected-configmaps-6e575dcc-8d71-4e2e-8b27-312af097ea92 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:06:07.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4275" for this suite.
Dec 21 02:06:13.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:06:13.375: INFO: namespace projected-4275 deletion completed in 6.093543275s

â€¢ [SLOW TEST:8.155 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:06:13.375: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-a821259f-9092-4e68-9ad6-a4338b34fb7b
STEP: Creating a pod to test consume configMaps
Dec 21 02:06:13.409: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ab0d7670-3a15-42f1-8344-d5052b9ef66c" in namespace "projected-996" to be "success or failure"
Dec 21 02:06:13.412: INFO: Pod "pod-projected-configmaps-ab0d7670-3a15-42f1-8344-d5052b9ef66c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.470009ms
Dec 21 02:06:15.415: INFO: Pod "pod-projected-configmaps-ab0d7670-3a15-42f1-8344-d5052b9ef66c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005487278s
STEP: Saw pod success
Dec 21 02:06:15.415: INFO: Pod "pod-projected-configmaps-ab0d7670-3a15-42f1-8344-d5052b9ef66c" satisfied condition "success or failure"
Dec 21 02:06:15.417: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-projected-configmaps-ab0d7670-3a15-42f1-8344-d5052b9ef66c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 02:06:15.428: INFO: Waiting for pod pod-projected-configmaps-ab0d7670-3a15-42f1-8344-d5052b9ef66c to disappear
Dec 21 02:06:15.434: INFO: Pod pod-projected-configmaps-ab0d7670-3a15-42f1-8344-d5052b9ef66c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:06:15.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-996" for this suite.
Dec 21 02:06:21.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:06:21.536: INFO: namespace projected-996 deletion completed in 6.097272548s

â€¢ [SLOW TEST:8.161 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:06:21.536: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-7192
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-7192
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7192
Dec 21 02:06:21.579: INFO: Found 0 stateful pods, waiting for 1
Dec 21 02:06:31.582: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec 21 02:06:31.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7192 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 21 02:06:31.736: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 21 02:06:31.736: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 21 02:06:31.736: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 21 02:06:31.739: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 21 02:06:41.742: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 21 02:06:41.742: INFO: Waiting for statefulset status.replicas updated to 0
Dec 21 02:06:41.752: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999861s
Dec 21 02:06:42.756: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996941192s
Dec 21 02:06:43.759: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.993548842s
Dec 21 02:06:44.763: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.990083424s
Dec 21 02:06:45.766: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.986849555s
Dec 21 02:06:46.769: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.983385599s
Dec 21 02:06:47.773: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.980115804s
Dec 21 02:06:48.776: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.976706627s
Dec 21 02:06:49.779: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.973389407s
Dec 21 02:06:50.783: INFO: Verifying statefulset ss doesn't scale past 1 for another 970.176086ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7192
Dec 21 02:06:51.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7192 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:06:51.938: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 21 02:06:51.938: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 21 02:06:51.938: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 21 02:06:51.941: INFO: Found 1 stateful pods, waiting for 3
Dec 21 02:07:01.945: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 21 02:07:01.945: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 21 02:07:01.945: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec 21 02:07:01.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7192 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 21 02:07:02.102: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 21 02:07:02.102: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 21 02:07:02.102: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 21 02:07:02.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7192 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 21 02:07:02.259: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 21 02:07:02.259: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 21 02:07:02.259: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 21 02:07:02.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7192 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 21 02:07:02.410: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 21 02:07:02.410: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 21 02:07:02.410: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 21 02:07:02.410: INFO: Waiting for statefulset status.replicas updated to 0
Dec 21 02:07:02.412: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec 21 02:07:12.420: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 21 02:07:12.420: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 21 02:07:12.420: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 21 02:07:12.427: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998624s
Dec 21 02:07:13.430: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997526664s
Dec 21 02:07:14.434: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.99416521s
Dec 21 02:07:15.437: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.990629877s
Dec 21 02:07:16.441: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.987076243s
Dec 21 02:07:17.444: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.983537773s
Dec 21 02:07:18.448: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.980153821s
Dec 21 02:07:19.451: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.976302462s
Dec 21 02:07:20.455: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.972934319s
Dec 21 02:07:21.458: INFO: Verifying statefulset ss doesn't scale past 3 for another 969.647173ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7192
Dec 21 02:07:22.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7192 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:07:22.629: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 21 02:07:22.629: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 21 02:07:22.629: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 21 02:07:22.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7192 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:07:22.777: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 21 02:07:22.777: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 21 02:07:22.777: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 21 02:07:22.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7192 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:07:22.934: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 21 02:07:22.934: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 21 02:07:22.934: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 21 02:07:22.934: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 21 02:07:52.947: INFO: Deleting all statefulset in ns statefulset-7192
Dec 21 02:07:52.949: INFO: Scaling statefulset ss to 0
Dec 21 02:07:52.956: INFO: Waiting for statefulset status.replicas updated to 0
Dec 21 02:07:52.958: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:07:52.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7192" for this suite.
Dec 21 02:07:58.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:07:59.090: INFO: namespace statefulset-7192 deletion completed in 6.114604007s

â€¢ [SLOW TEST:97.554 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:07:59.090: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 02:07:59.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 version'
Dec 21 02:07:59.197: INFO: stderr: ""
Dec 21 02:07:59.197: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.3\", GitCommit:\"b3cbbae08ec52a7fc73d334838e18d17e8512749\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T11:23:11Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.3-k3s.2\", GitCommit:\"e7e6a3c4e9a7d80b87793612730d10a863a25980\", GitTreeState:\"clean\", BuildDate:\"2019-11-18T18:31:23Z\", GoVersion:\"go1.13.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:07:59.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4218" for this suite.
Dec 21 02:08:05.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:08:05.300: INFO: namespace kubectl-4218 deletion completed in 6.099576389s

â€¢ [SLOW TEST:6.210 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:08:05.300: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 02:08:05.327: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:08:07.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7586" for this suite.
Dec 21 02:08:51.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:08:51.520: INFO: namespace pods-7586 deletion completed in 44.106435928s

â€¢ [SLOW TEST:46.220 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:08:51.521: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 21 02:08:51.549: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:08:54.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4933" for this suite.
Dec 21 02:09:06.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:09:06.851: INFO: namespace init-container-4933 deletion completed in 12.112495831s

â€¢ [SLOW TEST:15.331 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:09:06.852: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-1263
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1263 to expose endpoints map[]
Dec 21 02:09:06.892: INFO: Get endpoints failed (5.474866ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Dec 21 02:09:07.895: INFO: successfully validated that service endpoint-test2 in namespace services-1263 exposes endpoints map[] (1.008425996s elapsed)
STEP: Creating pod pod1 in namespace services-1263
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1263 to expose endpoints map[pod1:[80]]
Dec 21 02:09:09.916: INFO: successfully validated that service endpoint-test2 in namespace services-1263 exposes endpoints map[pod1:[80]] (2.015644371s elapsed)
STEP: Creating pod pod2 in namespace services-1263
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1263 to expose endpoints map[pod1:[80] pod2:[80]]
Dec 21 02:09:11.948: INFO: successfully validated that service endpoint-test2 in namespace services-1263 exposes endpoints map[pod1:[80] pod2:[80]] (2.029204404s elapsed)
STEP: Deleting pod pod1 in namespace services-1263
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1263 to expose endpoints map[pod2:[80]]
Dec 21 02:09:12.964: INFO: successfully validated that service endpoint-test2 in namespace services-1263 exposes endpoints map[pod2:[80]] (1.012422021s elapsed)
STEP: Deleting pod pod2 in namespace services-1263
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1263 to expose endpoints map[]
Dec 21 02:09:13.974: INFO: successfully validated that service endpoint-test2 in namespace services-1263 exposes endpoints map[] (1.005574036s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:09:13.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1263" for this suite.
Dec 21 02:09:20.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:09:20.095: INFO: namespace services-1263 deletion completed in 6.093583487s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:13.243 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:09:20.096: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 21 02:09:20.127: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6a9714f5-4335-4d2a-bd65-04c5947c5975" in namespace "projected-5764" to be "success or failure"
Dec 21 02:09:20.129: INFO: Pod "downwardapi-volume-6a9714f5-4335-4d2a-bd65-04c5947c5975": Phase="Pending", Reason="", readiness=false. Elapsed: 2.64309ms
Dec 21 02:09:22.132: INFO: Pod "downwardapi-volume-6a9714f5-4335-4d2a-bd65-04c5947c5975": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005787591s
Dec 21 02:09:24.136: INFO: Pod "downwardapi-volume-6a9714f5-4335-4d2a-bd65-04c5947c5975": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009057566s
STEP: Saw pod success
Dec 21 02:09:24.136: INFO: Pod "downwardapi-volume-6a9714f5-4335-4d2a-bd65-04c5947c5975" satisfied condition "success or failure"
Dec 21 02:09:24.138: INFO: Trying to get logs from node ip-172-31-29-169 pod downwardapi-volume-6a9714f5-4335-4d2a-bd65-04c5947c5975 container client-container: <nil>
STEP: delete the pod
Dec 21 02:09:24.154: INFO: Waiting for pod downwardapi-volume-6a9714f5-4335-4d2a-bd65-04c5947c5975 to disappear
Dec 21 02:09:24.157: INFO: Pod downwardapi-volume-6a9714f5-4335-4d2a-bd65-04c5947c5975 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:09:24.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5764" for this suite.
Dec 21 02:09:30.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:09:30.256: INFO: namespace projected-5764 deletion completed in 6.095534288s

â€¢ [SLOW TEST:10.160 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:09:30.256: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:09:36.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8950" for this suite.
Dec 21 02:09:42.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:09:42.435: INFO: namespace namespaces-8950 deletion completed in 6.091416631s
STEP: Destroying namespace "nsdeletetest-132" for this suite.
Dec 21 02:09:42.437: INFO: Namespace nsdeletetest-132 was already deleted
STEP: Destroying namespace "nsdeletetest-4420" for this suite.
Dec 21 02:09:48.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:09:48.528: INFO: namespace nsdeletetest-4420 deletion completed in 6.090304539s

â€¢ [SLOW TEST:18.272 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:09:48.528: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-7378
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-7378
Dec 21 02:09:48.562: INFO: Found 0 stateful pods, waiting for 1
Dec 21 02:09:58.566: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 21 02:09:58.581: INFO: Deleting all statefulset in ns statefulset-7378
Dec 21 02:09:58.585: INFO: Scaling statefulset ss to 0
Dec 21 02:10:18.606: INFO: Waiting for statefulset status.replicas updated to 0
Dec 21 02:10:18.608: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:10:18.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7378" for this suite.
Dec 21 02:10:24.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:10:24.723: INFO: namespace statefulset-7378 deletion completed in 6.102847393s

â€¢ [SLOW TEST:36.195 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:10:24.723: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 21 02:10:26.768: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:10:26.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7352" for this suite.
Dec 21 02:10:32.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:10:32.873: INFO: namespace container-runtime-7352 deletion completed in 6.091552178s

â€¢ [SLOW TEST:8.150 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:10:32.874: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:10:34.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5426" for this suite.
Dec 21 02:11:18.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:11:19.012: INFO: namespace kubelet-test-5426 deletion completed in 44.091495671s

â€¢ [SLOW TEST:46.138 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:11:19.012: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 02:11:19.036: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 21 02:11:22.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 --namespace=crd-publish-openapi-9284 create -f -'
Dec 21 02:11:23.552: INFO: stderr: ""
Dec 21 02:11:23.553: INFO: stdout: "e2e-test-crd-publish-openapi-21-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 21 02:11:23.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 --namespace=crd-publish-openapi-9284 delete e2e-test-crd-publish-openapi-21-crds test-cr'
Dec 21 02:11:23.637: INFO: stderr: ""
Dec 21 02:11:23.637: INFO: stdout: "e2e-test-crd-publish-openapi-21-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Dec 21 02:11:23.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 --namespace=crd-publish-openapi-9284 apply -f -'
Dec 21 02:11:23.800: INFO: stderr: ""
Dec 21 02:11:23.800: INFO: stdout: "e2e-test-crd-publish-openapi-21-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 21 02:11:23.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 --namespace=crd-publish-openapi-9284 delete e2e-test-crd-publish-openapi-21-crds test-cr'
Dec 21 02:11:23.880: INFO: stderr: ""
Dec 21 02:11:23.880: INFO: stdout: "e2e-test-crd-publish-openapi-21-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec 21 02:11:23.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 explain e2e-test-crd-publish-openapi-21-crds'
Dec 21 02:11:24.037: INFO: stderr: ""
Dec 21 02:11:24.037: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-21-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:11:26.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9284" for this suite.
Dec 21 02:11:32.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:11:32.122: INFO: namespace crd-publish-openapi-9284 deletion completed in 6.093881003s

â€¢ [SLOW TEST:13.110 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:11:32.122: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-6d57ed8d-48db-46db-8c94-d6d877928e14 in namespace container-probe-4265
Dec 21 02:11:34.157: INFO: Started pod liveness-6d57ed8d-48db-46db-8c94-d6d877928e14 in namespace container-probe-4265
STEP: checking the pod's current state and verifying that restartCount is present
Dec 21 02:11:34.159: INFO: Initial restart count of pod liveness-6d57ed8d-48db-46db-8c94-d6d877928e14 is 0
Dec 21 02:11:48.182: INFO: Restart count of pod container-probe-4265/liveness-6d57ed8d-48db-46db-8c94-d6d877928e14 is now 1 (14.022769363s elapsed)
Dec 21 02:12:08.215: INFO: Restart count of pod container-probe-4265/liveness-6d57ed8d-48db-46db-8c94-d6d877928e14 is now 2 (34.056357047s elapsed)
Dec 21 02:12:28.252: INFO: Restart count of pod container-probe-4265/liveness-6d57ed8d-48db-46db-8c94-d6d877928e14 is now 3 (54.09265362s elapsed)
Dec 21 02:12:48.285: INFO: Restart count of pod container-probe-4265/liveness-6d57ed8d-48db-46db-8c94-d6d877928e14 is now 4 (1m14.125741164s elapsed)
Dec 21 02:13:58.401: INFO: Restart count of pod container-probe-4265/liveness-6d57ed8d-48db-46db-8c94-d6d877928e14 is now 5 (2m24.241756212s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:13:58.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4265" for this suite.
Dec 21 02:14:04.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:14:04.528: INFO: namespace container-probe-4265 deletion completed in 6.115855619s

â€¢ [SLOW TEST:152.406 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:14:04.528: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-4327
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 21 02:14:04.553: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 21 02:14:26.628: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.0.25:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4327 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 02:14:26.629: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 02:14:26.696: INFO: Found all expected endpoints: [netserver-0]
Dec 21 02:14:26.698: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.2.30:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4327 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 02:14:26.698: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 02:14:26.765: INFO: Found all expected endpoints: [netserver-1]
Dec 21 02:14:26.768: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.1.140:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4327 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 02:14:26.768: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 02:14:26.828: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:14:26.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4327" for this suite.
Dec 21 02:14:54.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:14:54.951: INFO: namespace pod-network-test-4327 deletion completed in 28.12066255s

â€¢ [SLOW TEST:50.423 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:14:54.952: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:15:11.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9895" for this suite.
Dec 21 02:15:17.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:15:17.116: INFO: namespace resourcequota-9895 deletion completed in 6.100902169s

â€¢ [SLOW TEST:22.164 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:15:17.117: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 02:15:17.142: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec 21 02:15:17.149: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 21 02:15:22.152: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 21 02:15:22.152: INFO: Creating deployment "test-rolling-update-deployment"
Dec 21 02:15:22.156: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec 21 02:15:22.162: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec 21 02:15:24.168: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec 21 02:15:24.170: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 21 02:15:24.176: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-2541 /apis/apps/v1/namespaces/deployment-2541/deployments/test-rolling-update-deployment c3a7ba00-0e9b-491b-992b-dc31abc9f270 12063 1 2019-12-21 02:15:22 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000b121c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-21 02:15:22 +0000 UTC,LastTransitionTime:2019-12-21 02:15:22 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2019-12-21 02:15:23 +0000 UTC,LastTransitionTime:2019-12-21 02:15:22 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 21 02:15:24.178: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-2541 /apis/apps/v1/namespaces/deployment-2541/replicasets/test-rolling-update-deployment-55d946486 45b90981-c8f8-4e0f-82b1-d29f455d204b 12052 1 2019-12-21 02:15:22 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment c3a7ba00-0e9b-491b-992b-dc31abc9f270 0xc00325f2a0 0xc00325f2a1}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00325f308 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 21 02:15:24.179: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec 21 02:15:24.179: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-2541 /apis/apps/v1/namespaces/deployment-2541/replicasets/test-rolling-update-controller 2b106999-ac6f-420c-927c-742d8f3d6845 12062 2 2019-12-21 02:15:17 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment c3a7ba00-0e9b-491b-992b-dc31abc9f270 0xc00325f367 0xc00325f368}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00325f3c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 21 02:15:24.181: INFO: Pod "test-rolling-update-deployment-55d946486-phhzj" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-phhzj test-rolling-update-deployment-55d946486- deployment-2541 /api/v1/namespaces/deployment-2541/pods/test-rolling-update-deployment-55d946486-phhzj 3ba8313f-e2cb-4bb1-827b-33d50a1bfeb4 12051 0 2019-12-21 02:15:22 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 45b90981-c8f8-4e0f-82b1-d29f455d204b 0xc000b125d0 0xc000b125d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-77sh5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-77sh5,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-77sh5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-25-252,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:15:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:15:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:15:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:15:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.252,PodIP:10.42.0.26,StartTime:2019-12-21 02:15:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-21 02:15:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://2f28ece4c5c19a996a4e388c372cd2971631ef398307c616bb048830ede84f13,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.26,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:15:24.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2541" for this suite.
Dec 21 02:15:30.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:15:30.275: INFO: namespace deployment-2541 deletion completed in 6.090580714s

â€¢ [SLOW TEST:13.158 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:15:30.275: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 02:15:31.051: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 21 02:15:33.058: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491331, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491331, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491331, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491331, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 02:15:36.068: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:15:37.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4435" for this suite.
Dec 21 02:15:43.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:15:43.299: INFO: namespace webhook-4435 deletion completed in 6.089907317s
STEP: Destroying namespace "webhook-4435-markers" for this suite.
Dec 21 02:15:49.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:15:49.383: INFO: namespace webhook-4435-markers deletion completed in 6.083631763s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:19.118 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:15:49.393: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Dec 21 02:15:49.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 create -f - --namespace=kubectl-6302'
Dec 21 02:15:49.614: INFO: stderr: ""
Dec 21 02:15:49.614: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 21 02:15:50.618: INFO: Selector matched 1 pods for map[app:redis]
Dec 21 02:15:50.618: INFO: Found 0 / 1
Dec 21 02:15:51.618: INFO: Selector matched 1 pods for map[app:redis]
Dec 21 02:15:51.618: INFO: Found 1 / 1
Dec 21 02:15:51.618: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec 21 02:15:51.620: INFO: Selector matched 1 pods for map[app:redis]
Dec 21 02:15:51.620: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 21 02:15:51.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 patch pod redis-master-zbxwm --namespace=kubectl-6302 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec 21 02:15:51.699: INFO: stderr: ""
Dec 21 02:15:51.699: INFO: stdout: "pod/redis-master-zbxwm patched\n"
STEP: checking annotations
Dec 21 02:15:51.702: INFO: Selector matched 1 pods for map[app:redis]
Dec 21 02:15:51.702: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:15:51.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6302" for this suite.
Dec 21 02:16:19.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:16:19.793: INFO: namespace kubectl-6302 deletion completed in 28.088387866s

â€¢ [SLOW TEST:30.400 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:16:19.794: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 02:16:19.822: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-42084fae-e750-4f0b-90bb-85c8eee9569f" in namespace "security-context-test-6072" to be "success or failure"
Dec 21 02:16:19.826: INFO: Pod "busybox-readonly-false-42084fae-e750-4f0b-90bb-85c8eee9569f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.692941ms
Dec 21 02:16:21.829: INFO: Pod "busybox-readonly-false-42084fae-e750-4f0b-90bb-85c8eee9569f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006828313s
Dec 21 02:16:21.829: INFO: Pod "busybox-readonly-false-42084fae-e750-4f0b-90bb-85c8eee9569f" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:16:21.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6072" for this suite.
Dec 21 02:16:27.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:16:27.921: INFO: namespace security-context-test-6072 deletion completed in 6.088400608s

â€¢ [SLOW TEST:8.126 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:16:27.921: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 21 02:16:27.950: INFO: Waiting up to 5m0s for pod "downward-api-6a9ac1f1-2d64-4767-97a2-871fde68e28c" in namespace "downward-api-2673" to be "success or failure"
Dec 21 02:16:27.954: INFO: Pod "downward-api-6a9ac1f1-2d64-4767-97a2-871fde68e28c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.753555ms
Dec 21 02:16:29.957: INFO: Pod "downward-api-6a9ac1f1-2d64-4767-97a2-871fde68e28c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006935863s
STEP: Saw pod success
Dec 21 02:16:29.957: INFO: Pod "downward-api-6a9ac1f1-2d64-4767-97a2-871fde68e28c" satisfied condition "success or failure"
Dec 21 02:16:29.959: INFO: Trying to get logs from node ip-172-31-29-169 pod downward-api-6a9ac1f1-2d64-4767-97a2-871fde68e28c container dapi-container: <nil>
STEP: delete the pod
Dec 21 02:16:29.975: INFO: Waiting for pod downward-api-6a9ac1f1-2d64-4767-97a2-871fde68e28c to disappear
Dec 21 02:16:29.979: INFO: Pod downward-api-6a9ac1f1-2d64-4767-97a2-871fde68e28c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:16:29.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2673" for this suite.
Dec 21 02:16:35.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:16:36.067: INFO: namespace downward-api-2673 deletion completed in 6.085491873s

â€¢ [SLOW TEST:8.146 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:16:36.068: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:16:36.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1826" for this suite.
Dec 21 02:17:04.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:17:04.224: INFO: namespace pods-1826 deletion completed in 28.109460345s

â€¢ [SLOW TEST:28.156 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:17:04.224: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-055cfc88-4a8e-4097-b064-44a902b4c614
STEP: Creating a pod to test consume secrets
Dec 21 02:17:04.256: INFO: Waiting up to 5m0s for pod "pod-secrets-5ab435ff-97da-43c4-bb0c-13d71601026e" in namespace "secrets-5681" to be "success or failure"
Dec 21 02:17:04.258: INFO: Pod "pod-secrets-5ab435ff-97da-43c4-bb0c-13d71601026e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.424914ms
Dec 21 02:17:06.262: INFO: Pod "pod-secrets-5ab435ff-97da-43c4-bb0c-13d71601026e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005879056s
STEP: Saw pod success
Dec 21 02:17:06.262: INFO: Pod "pod-secrets-5ab435ff-97da-43c4-bb0c-13d71601026e" satisfied condition "success or failure"
Dec 21 02:17:06.264: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-secrets-5ab435ff-97da-43c4-bb0c-13d71601026e container secret-volume-test: <nil>
STEP: delete the pod
Dec 21 02:17:06.276: INFO: Waiting for pod pod-secrets-5ab435ff-97da-43c4-bb0c-13d71601026e to disappear
Dec 21 02:17:06.279: INFO: Pod pod-secrets-5ab435ff-97da-43c4-bb0c-13d71601026e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:17:06.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5681" for this suite.
Dec 21 02:17:12.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:17:12.375: INFO: namespace secrets-5681 deletion completed in 6.092559381s

â€¢ [SLOW TEST:8.151 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:17:12.375: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:17:35.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7687" for this suite.
Dec 21 02:17:41.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:17:41.633: INFO: namespace container-runtime-7687 deletion completed in 6.082355268s

â€¢ [SLOW TEST:29.259 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:17:41.634: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Dec 21 02:17:41.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 cluster-info'
Dec 21 02:17:41.742: INFO: stderr: ""
Dec 21 02:17:41.742: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:17:41.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3876" for this suite.
Dec 21 02:17:47.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:17:47.874: INFO: namespace kubectl-3876 deletion completed in 6.128900483s

â€¢ [SLOW TEST:6.239 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:17:47.874: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 02:17:48.571: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 02:17:51.584: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:17:52.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4159" for this suite.
Dec 21 02:18:04.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:18:04.757: INFO: namespace webhook-4159 deletion completed in 12.110196309s
STEP: Destroying namespace "webhook-4159-markers" for this suite.
Dec 21 02:18:10.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:18:10.849: INFO: namespace webhook-4159-markers deletion completed in 6.092073853s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:22.986 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:18:10.861: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-b6497de6-2cbd-4df2-9d75-0efbc012d994
STEP: Creating a pod to test consume configMaps
Dec 21 02:18:10.892: INFO: Waiting up to 5m0s for pod "pod-configmaps-fbef2d1c-12c9-4776-a1a5-8688d107d375" in namespace "configmap-4509" to be "success or failure"
Dec 21 02:18:10.902: INFO: Pod "pod-configmaps-fbef2d1c-12c9-4776-a1a5-8688d107d375": Phase="Pending", Reason="", readiness=false. Elapsed: 9.840491ms
Dec 21 02:18:12.905: INFO: Pod "pod-configmaps-fbef2d1c-12c9-4776-a1a5-8688d107d375": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012721336s
STEP: Saw pod success
Dec 21 02:18:12.905: INFO: Pod "pod-configmaps-fbef2d1c-12c9-4776-a1a5-8688d107d375" satisfied condition "success or failure"
Dec 21 02:18:12.907: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-configmaps-fbef2d1c-12c9-4776-a1a5-8688d107d375 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 02:18:12.918: INFO: Waiting for pod pod-configmaps-fbef2d1c-12c9-4776-a1a5-8688d107d375 to disappear
Dec 21 02:18:12.921: INFO: Pod pod-configmaps-fbef2d1c-12c9-4776-a1a5-8688d107d375 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:18:12.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4509" for this suite.
Dec 21 02:18:18.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:18:19.018: INFO: namespace configmap-4509 deletion completed in 6.094054869s

â€¢ [SLOW TEST:8.157 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:18:19.019: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Dec 21 02:18:29.061: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1221 02:18:29.060987      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:18:29.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5890" for this suite.
Dec 21 02:18:35.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:18:35.155: INFO: namespace gc-5890 deletion completed in 6.091636546s

â€¢ [SLOW TEST:16.135 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:18:35.155: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 21 02:18:35.183: INFO: Waiting up to 5m0s for pod "downwardapi-volume-345e63ae-866c-4f77-a3f0-f313ddbe7b38" in namespace "projected-8485" to be "success or failure"
Dec 21 02:18:35.186: INFO: Pod "downwardapi-volume-345e63ae-866c-4f77-a3f0-f313ddbe7b38": Phase="Pending", Reason="", readiness=false. Elapsed: 2.188416ms
Dec 21 02:18:37.189: INFO: Pod "downwardapi-volume-345e63ae-866c-4f77-a3f0-f313ddbe7b38": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005216662s
STEP: Saw pod success
Dec 21 02:18:37.189: INFO: Pod "downwardapi-volume-345e63ae-866c-4f77-a3f0-f313ddbe7b38" satisfied condition "success or failure"
Dec 21 02:18:37.191: INFO: Trying to get logs from node ip-172-31-29-169 pod downwardapi-volume-345e63ae-866c-4f77-a3f0-f313ddbe7b38 container client-container: <nil>
STEP: delete the pod
Dec 21 02:18:37.202: INFO: Waiting for pod downwardapi-volume-345e63ae-866c-4f77-a3f0-f313ddbe7b38 to disappear
Dec 21 02:18:37.205: INFO: Pod downwardapi-volume-345e63ae-866c-4f77-a3f0-f313ddbe7b38 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:18:37.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8485" for this suite.
Dec 21 02:18:43.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:18:43.296: INFO: namespace projected-8485 deletion completed in 6.087992564s

â€¢ [SLOW TEST:8.141 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:18:43.296: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 21 02:18:45.337: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:18:45.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8105" for this suite.
Dec 21 02:18:51.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:18:51.446: INFO: namespace container-runtime-8105 deletion completed in 6.096955053s

â€¢ [SLOW TEST:8.150 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:18:51.446: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Dec 21 02:18:51.475: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Dec 21 02:18:52.129: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
Dec 21 02:18:54.164: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491532, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491532, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491532, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491532, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 21 02:18:56.168: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491532, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491532, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491532, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491532, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 21 02:18:58.167: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491532, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491532, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491532, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491532, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 21 02:19:00.167: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491532, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491532, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491532, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491532, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 21 02:19:02.168: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491532, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491532, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491532, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491532, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 21 02:19:06.327: INFO: Waited 2.155396909s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:19:06.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-8672" for this suite.
Dec 21 02:19:12.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:19:13.012: INFO: namespace aggregator-8672 deletion completed in 6.168691252s

â€¢ [SLOW TEST:21.566 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:19:13.012: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-90f7aeeb-b376-4cb2-a183-0872ff4e3765
STEP: Creating a pod to test consume configMaps
Dec 21 02:19:13.045: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-56509a83-bc18-46c7-80bd-3551cccb5611" in namespace "projected-9803" to be "success or failure"
Dec 21 02:19:13.048: INFO: Pod "pod-projected-configmaps-56509a83-bc18-46c7-80bd-3551cccb5611": Phase="Pending", Reason="", readiness=false. Elapsed: 3.159948ms
Dec 21 02:19:15.051: INFO: Pod "pod-projected-configmaps-56509a83-bc18-46c7-80bd-3551cccb5611": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006309843s
STEP: Saw pod success
Dec 21 02:19:15.051: INFO: Pod "pod-projected-configmaps-56509a83-bc18-46c7-80bd-3551cccb5611" satisfied condition "success or failure"
Dec 21 02:19:15.053: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-projected-configmaps-56509a83-bc18-46c7-80bd-3551cccb5611 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 02:19:15.066: INFO: Waiting for pod pod-projected-configmaps-56509a83-bc18-46c7-80bd-3551cccb5611 to disappear
Dec 21 02:19:15.071: INFO: Pod pod-projected-configmaps-56509a83-bc18-46c7-80bd-3551cccb5611 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:19:15.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9803" for this suite.
Dec 21 02:19:21.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:19:21.164: INFO: namespace projected-9803 deletion completed in 6.090643864s

â€¢ [SLOW TEST:8.152 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:19:21.164: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec 21 02:19:21.205: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4120 /api/v1/namespaces/watch-4120/configmaps/e2e-watch-test-resource-version 3b498c10-6f44-432d-80e8-da8f90ac0dec 12910 0 2019-12-21 02:19:21 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 21 02:19:21.205: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4120 /api/v1/namespaces/watch-4120/configmaps/e2e-watch-test-resource-version 3b498c10-6f44-432d-80e8-da8f90ac0dec 12911 0 2019-12-21 02:19:21 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:19:21.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4120" for this suite.
Dec 21 02:19:27.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:19:27.305: INFO: namespace watch-4120 deletion completed in 6.097183771s

â€¢ [SLOW TEST:6.141 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:19:27.305: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 02:19:27.331: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:19:33.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2893" for this suite.
Dec 21 02:19:39.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:19:39.680: INFO: namespace custom-resource-definition-2893 deletion completed in 6.094403804s

â€¢ [SLOW TEST:12.375 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:19:39.680: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:19:50.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8505" for this suite.
Dec 21 02:19:56.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:19:56.841: INFO: namespace resourcequota-8505 deletion completed in 6.09753257s

â€¢ [SLOW TEST:17.160 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:19:56.841: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-1ebe66c5-8050-4fbf-b18f-bd9d26afd971
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:20:00.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5280" for this suite.
Dec 21 02:20:14.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:20:15.001: INFO: namespace configmap-5280 deletion completed in 14.100703919s

â€¢ [SLOW TEST:18.160 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:20:15.001: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 21 02:20:15.026: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:20:18.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6243" for this suite.
Dec 21 02:20:24.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:20:24.773: INFO: namespace init-container-6243 deletion completed in 6.09182857s

â€¢ [SLOW TEST:9.772 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:20:24.774: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Dec 21 02:20:26.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec pod-sharedvolume-d52c9bfd-41c6-4fa1-b8c2-f079f4e6251d -c busybox-main-container --namespace=emptydir-6432 -- cat /usr/share/volumeshare/shareddata.txt'
Dec 21 02:20:27.002: INFO: stderr: ""
Dec 21 02:20:27.002: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:20:27.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6432" for this suite.
Dec 21 02:20:33.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:20:33.099: INFO: namespace emptydir-6432 deletion completed in 6.093759628s

â€¢ [SLOW TEST:8.325 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:20:33.099: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 02:20:33.388: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 21 02:20:35.396: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491633, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491633, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491633, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491633, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 02:20:38.406: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 02:20:38.409: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4893-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:20:40.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7671" for this suite.
Dec 21 02:20:46.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:20:46.589: INFO: namespace webhook-7671 deletion completed in 6.087839015s
STEP: Destroying namespace "webhook-7671-markers" for this suite.
Dec 21 02:20:52.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:20:52.677: INFO: namespace webhook-7671-markers deletion completed in 6.087969681s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:19.592 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:20:52.691: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 02:20:53.154: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Dec 21 02:20:55.161: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491653, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491653, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491653, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712491653, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 02:20:58.170: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:20:59.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8042" for this suite.
Dec 21 02:21:05.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:21:05.397: INFO: namespace webhook-8042 deletion completed in 6.087324967s
STEP: Destroying namespace "webhook-8042-markers" for this suite.
Dec 21 02:21:11.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:21:11.497: INFO: namespace webhook-8042-markers deletion completed in 6.099034207s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:18.819 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:21:11.511: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 21 02:21:11.539: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fcbada07-9c9f-4527-b11a-01b2c4d90da3" in namespace "projected-6982" to be "success or failure"
Dec 21 02:21:11.546: INFO: Pod "downwardapi-volume-fcbada07-9c9f-4527-b11a-01b2c4d90da3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.958438ms
Dec 21 02:21:13.549: INFO: Pod "downwardapi-volume-fcbada07-9c9f-4527-b11a-01b2c4d90da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010073343s
STEP: Saw pod success
Dec 21 02:21:13.549: INFO: Pod "downwardapi-volume-fcbada07-9c9f-4527-b11a-01b2c4d90da3" satisfied condition "success or failure"
Dec 21 02:21:13.552: INFO: Trying to get logs from node ip-172-31-29-141 pod downwardapi-volume-fcbada07-9c9f-4527-b11a-01b2c4d90da3 container client-container: <nil>
STEP: delete the pod
Dec 21 02:21:13.566: INFO: Waiting for pod downwardapi-volume-fcbada07-9c9f-4527-b11a-01b2c4d90da3 to disappear
Dec 21 02:21:13.569: INFO: Pod downwardapi-volume-fcbada07-9c9f-4527-b11a-01b2c4d90da3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:21:13.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6982" for this suite.
Dec 21 02:21:19.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:21:19.674: INFO: namespace projected-6982 deletion completed in 6.102981229s

â€¢ [SLOW TEST:8.164 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:21:19.675: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Dec 21 02:21:19.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 create -f - --namespace=kubectl-4774'
Dec 21 02:21:19.903: INFO: stderr: ""
Dec 21 02:21:19.903: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 21 02:21:19.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4774'
Dec 21 02:21:19.990: INFO: stderr: ""
Dec 21 02:21:19.990: INFO: stdout: "update-demo-nautilus-p7hjs update-demo-nautilus-v8prg "
Dec 21 02:21:19.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-p7hjs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4774'
Dec 21 02:21:20.069: INFO: stderr: ""
Dec 21 02:21:20.069: INFO: stdout: ""
Dec 21 02:21:20.069: INFO: update-demo-nautilus-p7hjs is created but not running
Dec 21 02:21:25.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4774'
Dec 21 02:21:25.922: INFO: stderr: ""
Dec 21 02:21:25.922: INFO: stdout: "update-demo-nautilus-v8prg update-demo-nautilus-p7hjs "
Dec 21 02:21:25.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-v8prg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4774'
Dec 21 02:21:25.998: INFO: stderr: ""
Dec 21 02:21:25.998: INFO: stdout: "true"
Dec 21 02:21:25.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-v8prg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4774'
Dec 21 02:21:26.074: INFO: stderr: ""
Dec 21 02:21:26.074: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 21 02:21:26.074: INFO: validating pod update-demo-nautilus-v8prg
Dec 21 02:21:26.078: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 21 02:21:26.078: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 21 02:21:26.078: INFO: update-demo-nautilus-v8prg is verified up and running
Dec 21 02:21:26.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-p7hjs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4774'
Dec 21 02:21:26.155: INFO: stderr: ""
Dec 21 02:21:26.155: INFO: stdout: "true"
Dec 21 02:21:26.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-nautilus-p7hjs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4774'
Dec 21 02:21:26.235: INFO: stderr: ""
Dec 21 02:21:26.235: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 21 02:21:26.235: INFO: validating pod update-demo-nautilus-p7hjs
Dec 21 02:21:26.239: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 21 02:21:26.239: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 21 02:21:26.239: INFO: update-demo-nautilus-p7hjs is verified up and running
STEP: rolling-update to new replication controller
Dec 21 02:21:26.241: INFO: scanned /root for discovery docs: <nil>
Dec 21 02:21:26.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-4774'
Dec 21 02:21:48.556: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 21 02:21:48.556: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 21 02:21:48.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4774'
Dec 21 02:21:48.636: INFO: stderr: ""
Dec 21 02:21:48.636: INFO: stdout: "update-demo-kitten-sklxr update-demo-kitten-t964r "
Dec 21 02:21:48.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-kitten-sklxr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4774'
Dec 21 02:21:48.712: INFO: stderr: ""
Dec 21 02:21:48.712: INFO: stdout: "true"
Dec 21 02:21:48.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-kitten-sklxr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4774'
Dec 21 02:21:48.785: INFO: stderr: ""
Dec 21 02:21:48.785: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 21 02:21:48.785: INFO: validating pod update-demo-kitten-sklxr
Dec 21 02:21:48.789: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 21 02:21:48.789: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 21 02:21:48.789: INFO: update-demo-kitten-sklxr is verified up and running
Dec 21 02:21:48.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-kitten-t964r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4774'
Dec 21 02:21:48.865: INFO: stderr: ""
Dec 21 02:21:48.865: INFO: stdout: "true"
Dec 21 02:21:48.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods update-demo-kitten-t964r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4774'
Dec 21 02:21:48.941: INFO: stderr: ""
Dec 21 02:21:48.941: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 21 02:21:48.941: INFO: validating pod update-demo-kitten-t964r
Dec 21 02:21:48.945: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 21 02:21:48.945: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 21 02:21:48.945: INFO: update-demo-kitten-t964r is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:21:48.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4774" for this suite.
Dec 21 02:22:00.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:22:01.041: INFO: namespace kubectl-4774 deletion completed in 12.09351532s

â€¢ [SLOW TEST:41.366 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:22:01.041: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec 21 02:22:11.119: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1221 02:22:11.119115      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:22:11.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7842" for this suite.
Dec 21 02:22:17.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:22:17.213: INFO: namespace gc-7842 deletion completed in 6.091501147s

â€¢ [SLOW TEST:16.171 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:22:17.213: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-8838
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 21 02:22:17.237: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 21 02:22:39.304: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.2.43:8080/dial?request=hostName&protocol=http&host=10.42.2.42&port=8080&tries=1'] Namespace:pod-network-test-8838 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 02:22:39.304: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 02:22:39.368: INFO: Waiting for endpoints: map[]
Dec 21 02:22:39.371: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.2.43:8080/dial?request=hostName&protocol=http&host=10.42.0.32&port=8080&tries=1'] Namespace:pod-network-test-8838 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 02:22:39.371: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 02:22:39.436: INFO: Waiting for endpoints: map[]
Dec 21 02:22:39.439: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.2.43:8080/dial?request=hostName&protocol=http&host=10.42.1.165&port=8080&tries=1'] Namespace:pod-network-test-8838 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 02:22:39.439: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 02:22:39.505: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:22:39.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8838" for this suite.
Dec 21 02:23:07.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:23:07.612: INFO: namespace pod-network-test-8838 deletion completed in 28.103551368s

â€¢ [SLOW TEST:50.399 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:23:07.612: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 02:23:07.714: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:23:09.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3327" for this suite.
Dec 21 02:23:53.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:23:53.834: INFO: namespace pods-3327 deletion completed in 44.090946s

â€¢ [SLOW TEST:46.221 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:23:53.834: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-5736
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-5736
STEP: Deleting pre-stop pod
Dec 21 02:24:02.888: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:24:02.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-5736" for this suite.
Dec 21 02:24:46.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:24:46.996: INFO: namespace prestop-5736 deletion completed in 44.099187455s

â€¢ [SLOW TEST:53.162 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:24:46.996: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 21 02:24:47.028: INFO: Waiting up to 5m0s for pod "downward-api-b7903710-9c7a-460e-a118-c6de687d6014" in namespace "downward-api-3698" to be "success or failure"
Dec 21 02:24:47.032: INFO: Pod "downward-api-b7903710-9c7a-460e-a118-c6de687d6014": Phase="Pending", Reason="", readiness=false. Elapsed: 3.606688ms
Dec 21 02:24:49.035: INFO: Pod "downward-api-b7903710-9c7a-460e-a118-c6de687d6014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006876032s
STEP: Saw pod success
Dec 21 02:24:49.035: INFO: Pod "downward-api-b7903710-9c7a-460e-a118-c6de687d6014" satisfied condition "success or failure"
Dec 21 02:24:49.038: INFO: Trying to get logs from node ip-172-31-29-141 pod downward-api-b7903710-9c7a-460e-a118-c6de687d6014 container dapi-container: <nil>
STEP: delete the pod
Dec 21 02:24:49.054: INFO: Waiting for pod downward-api-b7903710-9c7a-460e-a118-c6de687d6014 to disappear
Dec 21 02:24:49.059: INFO: Pod downward-api-b7903710-9c7a-460e-a118-c6de687d6014 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:24:49.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3698" for this suite.
Dec 21 02:24:55.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:24:55.179: INFO: namespace downward-api-3698 deletion completed in 6.117858868s

â€¢ [SLOW TEST:8.183 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:24:55.180: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-5293
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Dec 21 02:24:55.230: INFO: Found 0 stateful pods, waiting for 3
Dec 21 02:25:05.234: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 21 02:25:05.234: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 21 02:25:05.234: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec 21 02:25:05.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-5293 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 21 02:25:05.401: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 21 02:25:05.401: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 21 02:25:05.401: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec 21 02:25:15.429: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec 21 02:25:25.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-5293 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:25:25.601: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 21 02:25:25.601: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 21 02:25:25.601: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 21 02:25:45.617: INFO: Waiting for StatefulSet statefulset-5293/ss2 to complete update
Dec 21 02:25:45.617: INFO: Waiting for Pod statefulset-5293/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 21 02:25:55.622: INFO: Waiting for StatefulSet statefulset-5293/ss2 to complete update
STEP: Rolling back to a previous revision
Dec 21 02:26:05.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-5293 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 21 02:26:05.778: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 21 02:26:05.778: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 21 02:26:05.778: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 21 02:26:15.804: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec 21 02:26:25.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-5293 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:26:25.979: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 21 02:26:25.979: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 21 02:26:25.979: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 21 02:26:45.995: INFO: Waiting for StatefulSet statefulset-5293/ss2 to complete update
Dec 21 02:26:45.995: INFO: Waiting for Pod statefulset-5293/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 21 02:26:56.001: INFO: Deleting all statefulset in ns statefulset-5293
Dec 21 02:26:56.003: INFO: Scaling statefulset ss2 to 0
Dec 21 02:27:16.015: INFO: Waiting for statefulset status.replicas updated to 0
Dec 21 02:27:16.019: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:27:16.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5293" for this suite.
Dec 21 02:27:22.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:27:22.139: INFO: namespace statefulset-5293 deletion completed in 6.106576111s

â€¢ [SLOW TEST:146.960 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:27:22.140: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 02:27:22.549: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 21 02:27:24.562: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492042, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492042, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492042, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492042, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 02:27:27.572: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:27:28.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1621" for this suite.
Dec 21 02:27:34.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:27:34.720: INFO: namespace webhook-1621 deletion completed in 6.090300114s
STEP: Destroying namespace "webhook-1621-markers" for this suite.
Dec 21 02:27:40.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:27:40.806: INFO: namespace webhook-1621-markers deletion completed in 6.085997089s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:18.677 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:27:40.817: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 02:27:40.842: INFO: Creating deployment "webserver-deployment"
Dec 21 02:27:40.846: INFO: Waiting for observed generation 1
Dec 21 02:27:42.862: INFO: Waiting for all required pods to come up
Dec 21 02:27:42.866: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec 21 02:27:44.894: INFO: Waiting for deployment "webserver-deployment" to complete
Dec 21 02:27:44.899: INFO: Updating deployment "webserver-deployment" with a non-existent image
Dec 21 02:27:44.904: INFO: Updating deployment webserver-deployment
Dec 21 02:27:44.904: INFO: Waiting for observed generation 2
Dec 21 02:27:46.909: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec 21 02:27:46.911: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec 21 02:27:46.913: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 21 02:27:46.920: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec 21 02:27:46.920: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec 21 02:27:46.922: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 21 02:27:46.925: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Dec 21 02:27:46.926: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Dec 21 02:27:46.930: INFO: Updating deployment webserver-deployment
Dec 21 02:27:46.930: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Dec 21 02:27:46.952: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec 21 02:27:48.976: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 21 02:27:48.982: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-2337 /apis/apps/v1/namespaces/deployment-2337/deployments/webserver-deployment c7f31a2b-aa45-4320-b93e-bae6db9659fb 15105 3 2019-12-21 02:27:40 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00406bc98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-12-21 02:27:46 +0000 UTC,LastTransitionTime:2019-12-21 02:27:46 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2019-12-21 02:27:47 +0000 UTC,LastTransitionTime:2019-12-21 02:27:40 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Dec 21 02:27:48.985: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-2337 /apis/apps/v1/namespaces/deployment-2337/replicasets/webserver-deployment-c7997dcc8 a9e0b59b-b6d1-4d32-9d8f-f400d278740c 15098 3 2019-12-21 02:27:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment c7f31a2b-aa45-4320-b93e-bae6db9659fb 0xc0062b4427 0xc0062b4428}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0062b4498 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 21 02:27:48.986: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Dec 21 02:27:48.986: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-2337 /apis/apps/v1/namespaces/deployment-2337/replicasets/webserver-deployment-595b5b9587 9772bd39-11cb-47b5-ba00-fdfcc74a6be9 15084 3 2019-12-21 02:27:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment c7f31a2b-aa45-4320-b93e-bae6db9659fb 0xc0062b4367 0xc0062b4368}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0062b43c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Dec 21 02:27:48.995: INFO: Pod "webserver-deployment-595b5b9587-qzqjr" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-qzqjr webserver-deployment-595b5b9587- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-595b5b9587-qzqjr 12ec492b-e653-409c-a301-1a2b428fb1c3 14901 0 2019-12-21 02:27:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9772bd39-11cb-47b5-ba00-fdfcc74a6be9 0xc00360e107 0xc00360e108}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.141,PodIP:10.42.2.49,StartTime:2019-12-21 02:27:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-21 02:27:42 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://3e4f2eda567172d154829f6dd322b6b4eedc10d4d3028092694f50010572dbf3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.49,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:48.995: INFO: Pod "webserver-deployment-595b5b9587-99zcx" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-99zcx webserver-deployment-595b5b9587- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-595b5b9587-99zcx f517d104-efdc-4502-94e0-75c91e80d830 14909 0 2019-12-21 02:27:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9772bd39-11cb-47b5-ba00-fdfcc74a6be9 0xc00360e280 0xc00360e281}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-169,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.169,PodIP:10.42.1.173,StartTime:2019-12-21 02:27:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-21 02:27:42 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://680c93fb5c90a7ed724ddb642ecf22426948fe78396e688e2659d7329a42bcd0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.173,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:48.995: INFO: Pod "webserver-deployment-595b5b9587-z2zq4" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-z2zq4 webserver-deployment-595b5b9587- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-595b5b9587-z2zq4 ec0eb7c9-a931-4749-a7d0-c6ccb3648f49 14915 0 2019-12-21 02:27:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9772bd39-11cb-47b5-ba00-fdfcc74a6be9 0xc00360e3f0 0xc00360e3f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-169,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.169,PodIP:10.42.1.174,StartTime:2019-12-21 02:27:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-21 02:27:42 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://a482f23ce6cd2888f96c9b6ad6df132942d66c16e48365cba2becf5f7e43fa14,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.174,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:48.995: INFO: Pod "webserver-deployment-595b5b9587-wbzhx" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-wbzhx webserver-deployment-595b5b9587- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-595b5b9587-wbzhx c674d4a8-06aa-4ba2-bf40-abb5a96f7c63 14918 0 2019-12-21 02:27:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9772bd39-11cb-47b5-ba00-fdfcc74a6be9 0xc00360e560 0xc00360e561}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-25-252,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.252,PodIP:10.42.0.37,StartTime:2019-12-21 02:27:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-21 02:27:42 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://fac5145ba6a0d3041f540c194d324773440b2328aaf06f22a94da59e4529a178,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.37,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:48.996: INFO: Pod "webserver-deployment-595b5b9587-nn5ld" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-nn5ld webserver-deployment-595b5b9587- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-595b5b9587-nn5ld 24824561-ee13-4b8d-bcc8-fe0c4ba53c5e 14923 0 2019-12-21 02:27:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9772bd39-11cb-47b5-ba00-fdfcc74a6be9 0xc00360e6d0 0xc00360e6d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-25-252,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.252,PodIP:10.42.0.38,StartTime:2019-12-21 02:27:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-21 02:27:43 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://bb0c16eb76b2fa512364157565e891a405e07c2c91ee6f7691cf327b8d9e7081,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.38,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:48.996: INFO: Pod "webserver-deployment-595b5b9587-tm7lc" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-tm7lc webserver-deployment-595b5b9587- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-595b5b9587-tm7lc a07a01d1-31e9-4e21-b795-27fd2ade5a03 14927 0 2019-12-21 02:27:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9772bd39-11cb-47b5-ba00-fdfcc74a6be9 0xc00360e840 0xc00360e841}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.141,PodIP:10.42.2.50,StartTime:2019-12-21 02:27:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-21 02:27:43 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://e4e1f096774a96b73ba47108d86e995a96696494c1d20d0be6eab226c88fbe01,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.50,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:48.996: INFO: Pod "webserver-deployment-595b5b9587-sjzbd" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-sjzbd webserver-deployment-595b5b9587- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-595b5b9587-sjzbd 15697975-92fb-47bf-9678-0251f225858f 14929 0 2019-12-21 02:27:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9772bd39-11cb-47b5-ba00-fdfcc74a6be9 0xc00360e9b0 0xc00360e9b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.141,PodIP:10.42.2.51,StartTime:2019-12-21 02:27:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-21 02:27:42 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://9d74a709be69d6d063a9d1f5ee916097a78316d2412d444bfbd5c1153aec19af,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.51,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:48.997: INFO: Pod "webserver-deployment-595b5b9587-xbsfd" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-xbsfd webserver-deployment-595b5b9587- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-595b5b9587-xbsfd 05a9fb1c-beb0-4603-a308-0cda2b1868aa 14933 0 2019-12-21 02:27:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9772bd39-11cb-47b5-ba00-fdfcc74a6be9 0xc00360eb20 0xc00360eb21}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.141,PodIP:10.42.2.52,StartTime:2019-12-21 02:27:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-21 02:27:43 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://64846e4dcdc893561df26788ee99c11eebbbba551acf73ef320d858668189e9a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.52,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:48.997: INFO: Pod "webserver-deployment-c7997dcc8-f7n9r" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-f7n9r webserver-deployment-c7997dcc8- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-c7997dcc8-f7n9r a05a4091-a6aa-441e-b9b0-213e47d9c52d 15001 0 2019-12-21 02:27:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 a9e0b59b-b6d1-4d32-9d8f-f400d278740c 0xc00360ec90 0xc00360ec91}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-25-252,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.252,PodIP:10.42.0.39,StartTime:2019-12-21 02:27:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.39,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:48.997: INFO: Pod "webserver-deployment-c7997dcc8-sx24s" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-sx24s webserver-deployment-c7997dcc8- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-c7997dcc8-sx24s 75a72cd2-6410-4e10-8e22-fde5c68fcd57 15007 0 2019-12-21 02:27:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 a9e0b59b-b6d1-4d32-9d8f-f400d278740c 0xc00360ee30 0xc00360ee31}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.141,PodIP:10.42.2.53,StartTime:2019-12-21 02:27:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.53,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:48.997: INFO: Pod "webserver-deployment-c7997dcc8-js95k" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-js95k webserver-deployment-c7997dcc8- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-c7997dcc8-js95k fdc99979-3608-40cf-9c95-217f3532f5a3 15010 0 2019-12-21 02:27:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 a9e0b59b-b6d1-4d32-9d8f-f400d278740c 0xc00360eff0 0xc00360eff1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:45 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:45 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.141,PodIP:10.42.2.54,StartTime:2019-12-21 02:27:45 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.54,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:48.998: INFO: Pod "webserver-deployment-c7997dcc8-kdc9h" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-kdc9h webserver-deployment-c7997dcc8- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-c7997dcc8-kdc9h 3cbe4a24-4a04-4ac1-9693-229b40577790 15018 0 2019-12-21 02:27:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 a9e0b59b-b6d1-4d32-9d8f-f400d278740c 0xc00360f1a0 0xc00360f1a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-169,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:45 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:45 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.169,PodIP:10.42.1.176,StartTime:2019-12-21 02:27:45 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.176,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:48.998: INFO: Pod "webserver-deployment-c7997dcc8-xvmj4" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-xvmj4 webserver-deployment-c7997dcc8- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-c7997dcc8-xvmj4 ae7bc30f-ace9-44b6-8213-789bfaec12e1 15021 0 2019-12-21 02:27:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 a9e0b59b-b6d1-4d32-9d8f-f400d278740c 0xc00360f340 0xc00360f341}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-169,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.169,PodIP:10.42.1.175,StartTime:2019-12-21 02:27:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.175,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:48.998: INFO: Pod "webserver-deployment-595b5b9587-62lhx" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-62lhx webserver-deployment-595b5b9587- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-595b5b9587-62lhx 9a42a4cb-47f1-4d2d-8004-1e6454338861 15053 0 2019-12-21 02:27:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9772bd39-11cb-47b5-ba00-fdfcc74a6be9 0xc00360f4f0 0xc00360f4f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-169,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.169,PodIP:,StartTime:2019-12-21 02:27:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:48.998: INFO: Pod "webserver-deployment-595b5b9587-v8qhq" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-v8qhq webserver-deployment-595b5b9587- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-595b5b9587-v8qhq 40f9fd28-0c97-4d17-be1b-5605047cdd70 15076 0 2019-12-21 02:27:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9772bd39-11cb-47b5-ba00-fdfcc74a6be9 0xc00360f647 0xc00360f648}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-169,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.169,PodIP:,StartTime:2019-12-21 02:27:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:48.998: INFO: Pod "webserver-deployment-595b5b9587-qxxjn" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-qxxjn webserver-deployment-595b5b9587- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-595b5b9587-qxxjn 7a7bc3dc-9ff6-41a1-94a7-517f1b7e6c21 15083 0 2019-12-21 02:27:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9772bd39-11cb-47b5-ba00-fdfcc74a6be9 0xc00360f7a7 0xc00360f7a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-25-252,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.252,PodIP:,StartTime:2019-12-21 02:27:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:48.999: INFO: Pod "webserver-deployment-c7997dcc8-wbh95" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-wbh95 webserver-deployment-c7997dcc8- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-c7997dcc8-wbh95 83abb4e2-f351-4f8d-be82-74220cb3fb49 15089 0 2019-12-21 02:27:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 a9e0b59b-b6d1-4d32-9d8f-f400d278740c 0xc00360f907 0xc00360f908}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.141,PodIP:,StartTime:2019-12-21 02:27:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:48.999: INFO: Pod "webserver-deployment-595b5b9587-mbphs" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mbphs webserver-deployment-595b5b9587- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-595b5b9587-mbphs 148f941a-8aae-4b86-ac04-8a1d85873da5 15110 0 2019-12-21 02:27:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9772bd39-11cb-47b5-ba00-fdfcc74a6be9 0xc00360fa87 0xc00360fa88}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-169,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.169,PodIP:,StartTime:2019-12-21 02:27:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:48.999: INFO: Pod "webserver-deployment-c7997dcc8-c2hr5" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-c2hr5 webserver-deployment-c7997dcc8- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-c7997dcc8-c2hr5 b412754a-ded3-463a-983a-c14ebfa9c5e0 15111 0 2019-12-21 02:27:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 a9e0b59b-b6d1-4d32-9d8f-f400d278740c 0xc00360fbe7 0xc00360fbe8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.141,PodIP:,StartTime:2019-12-21 02:27:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:48.999: INFO: Pod "webserver-deployment-c7997dcc8-2dhmj" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-2dhmj webserver-deployment-c7997dcc8- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-c7997dcc8-2dhmj 69812456-519e-4e88-bdda-3c9173d40f0c 15113 0 2019-12-21 02:27:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 a9e0b59b-b6d1-4d32-9d8f-f400d278740c 0xc00360fd67 0xc00360fd68}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-169,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.169,PodIP:,StartTime:2019-12-21 02:27:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:48.999: INFO: Pod "webserver-deployment-595b5b9587-nkq74" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-nkq74 webserver-deployment-595b5b9587- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-595b5b9587-nkq74 46eff50b-d8ff-455b-a065-6764cc41cf1f 15114 0 2019-12-21 02:27:47 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9772bd39-11cb-47b5-ba00-fdfcc74a6be9 0xc00360fee7 0xc00360fee8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.141,PodIP:,StartTime:2019-12-21 02:27:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:48.999: INFO: Pod "webserver-deployment-595b5b9587-v2lcj" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-v2lcj webserver-deployment-595b5b9587- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-595b5b9587-v2lcj c121eec8-ed15-4054-9a46-80890117e462 15115 0 2019-12-21 02:27:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9772bd39-11cb-47b5-ba00-fdfcc74a6be9 0xc007556047 0xc007556048}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-25-252,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.252,PodIP:,StartTime:2019-12-21 02:27:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:48.999: INFO: Pod "webserver-deployment-595b5b9587-ksblp" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-ksblp webserver-deployment-595b5b9587- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-595b5b9587-ksblp 48e8043b-f807-40cb-bffd-ec66769f9faa 15117 0 2019-12-21 02:27:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9772bd39-11cb-47b5-ba00-fdfcc74a6be9 0xc0075561a7 0xc0075561a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-25-252,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.252,PodIP:,StartTime:2019-12-21 02:27:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:48.999: INFO: Pod "webserver-deployment-595b5b9587-2qmqk" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-2qmqk webserver-deployment-595b5b9587- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-595b5b9587-2qmqk c5ea2588-e167-48fb-a50e-0a5ae9e06845 15120 0 2019-12-21 02:27:47 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9772bd39-11cb-47b5-ba00-fdfcc74a6be9 0xc007556307 0xc007556308}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.141,PodIP:,StartTime:2019-12-21 02:27:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:49.000: INFO: Pod "webserver-deployment-c7997dcc8-7ddf9" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-7ddf9 webserver-deployment-c7997dcc8- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-c7997dcc8-7ddf9 aca4b9b9-7113-4b87-a942-69cde5b34721 15125 0 2019-12-21 02:27:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 a9e0b59b-b6d1-4d32-9d8f-f400d278740c 0xc007556467 0xc007556468}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-25-252,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.252,PodIP:,StartTime:2019-12-21 02:27:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:49.000: INFO: Pod "webserver-deployment-595b5b9587-twr8m" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-twr8m webserver-deployment-595b5b9587- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-595b5b9587-twr8m 8abbf5de-2f5b-4164-976c-21026f65119f 15128 0 2019-12-21 02:27:47 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9772bd39-11cb-47b5-ba00-fdfcc74a6be9 0xc0075565e7 0xc0075565e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-169,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.169,PodIP:,StartTime:2019-12-21 02:27:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:49.000: INFO: Pod "webserver-deployment-595b5b9587-7g569" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-7g569 webserver-deployment-595b5b9587- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-595b5b9587-7g569 e02a18ca-7fba-4c0c-8014-de7e09ee9ef3 15133 0 2019-12-21 02:27:47 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9772bd39-11cb-47b5-ba00-fdfcc74a6be9 0xc007556747 0xc007556748}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-25-252,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.252,PodIP:,StartTime:2019-12-21 02:27:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:49.000: INFO: Pod "webserver-deployment-595b5b9587-9m5lj" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-9m5lj webserver-deployment-595b5b9587- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-595b5b9587-9m5lj 3bdbc900-2c7a-4160-b8d5-40e8672b2a5e 15138 0 2019-12-21 02:27:47 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9772bd39-11cb-47b5-ba00-fdfcc74a6be9 0xc0075568a7 0xc0075568a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-169,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.169,PodIP:,StartTime:2019-12-21 02:27:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:49.000: INFO: Pod "webserver-deployment-c7997dcc8-7dftt" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-7dftt webserver-deployment-c7997dcc8- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-c7997dcc8-7dftt 3422b0e6-b335-45fe-8e9f-9df7cb8d05f0 15170 0 2019-12-21 02:27:47 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 a9e0b59b-b6d1-4d32-9d8f-f400d278740c 0xc007556a07 0xc007556a08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-169,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.169,PodIP:,StartTime:2019-12-21 02:27:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:49.000: INFO: Pod "webserver-deployment-c7997dcc8-r6w42" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-r6w42 webserver-deployment-c7997dcc8- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-c7997dcc8-r6w42 33645667-4e0c-4fad-a1f3-376fa066c115 15178 0 2019-12-21 02:27:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 a9e0b59b-b6d1-4d32-9d8f-f400d278740c 0xc007556ba7 0xc007556ba8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-169,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.169,PodIP:10.42.1.179,StartTime:2019-12-21 02:27:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.179,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:49.000: INFO: Pod "webserver-deployment-c7997dcc8-l6dw8" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-l6dw8 webserver-deployment-c7997dcc8- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-c7997dcc8-l6dw8 7615182e-b033-4892-b8b9-b4c00690b31e 15181 0 2019-12-21 02:27:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 a9e0b59b-b6d1-4d32-9d8f-f400d278740c 0xc007556d50 0xc007556d51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-25-252,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.252,PodIP:10.42.0.40,StartTime:2019-12-21 02:27:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.40,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:49.000: INFO: Pod "webserver-deployment-c7997dcc8-drqbk" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-drqbk webserver-deployment-c7997dcc8- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-c7997dcc8-drqbk 3d405f1d-0473-42a7-a3d6-d93548703a78 15184 0 2019-12-21 02:27:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 a9e0b59b-b6d1-4d32-9d8f-f400d278740c 0xc007556f90 0xc007556f91}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-25-252,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.252,PodIP:10.42.0.42,StartTime:2019-12-21 02:27:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.42,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 02:27:49.001: INFO: Pod "webserver-deployment-595b5b9587-2rcth" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-2rcth webserver-deployment-595b5b9587- deployment-2337 /api/v1/namespaces/deployment-2337/pods/webserver-deployment-595b5b9587-2rcth 715d72dc-6e72-4099-8733-8741464aa01a 15185 0 2019-12-21 02:27:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9772bd39-11cb-47b5-ba00-fdfcc74a6be9 0xc007557240 0xc007557241}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hgwq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hgwq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hgwq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:27:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.141,PodIP:10.42.2.56,StartTime:2019-12-21 02:27:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-21 02:27:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://a5a6e17debd6b98795c68e4a98ed307755bd822de208819fc5a9ff77936462f5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.56,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:27:49.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2337" for this suite.
Dec 21 02:27:57.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:27:57.117: INFO: namespace deployment-2337 deletion completed in 8.112387569s

â€¢ [SLOW TEST:16.301 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:27:57.118: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 21 02:27:57.168: INFO: Number of nodes with available pods: 0
Dec 21 02:27:57.168: INFO: Node ip-172-31-29-169 is running more than one daemon pod
Dec 21 02:27:58.175: INFO: Number of nodes with available pods: 0
Dec 21 02:27:58.175: INFO: Node ip-172-31-29-169 is running more than one daemon pod
Dec 21 02:27:59.175: INFO: Number of nodes with available pods: 3
Dec 21 02:27:59.175: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec 21 02:27:59.191: INFO: Number of nodes with available pods: 3
Dec 21 02:27:59.191: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5205, will wait for the garbage collector to delete the pods
Dec 21 02:28:00.262: INFO: Deleting DaemonSet.extensions daemon-set took: 10.120303ms
Dec 21 02:28:00.662: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.292244ms
Dec 21 02:28:13.466: INFO: Number of nodes with available pods: 0
Dec 21 02:28:13.466: INFO: Number of running nodes: 0, number of available pods: 0
Dec 21 02:28:13.469: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5205/daemonsets","resourceVersion":"15581"},"items":null}

Dec 21 02:28:13.471: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5205/pods","resourceVersion":"15581"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:28:13.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5205" for this suite.
Dec 21 02:28:19.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:28:19.585: INFO: namespace daemonsets-5205 deletion completed in 6.099134084s

â€¢ [SLOW TEST:22.467 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:28:19.585: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-9142b31e-1f2e-48cb-aed1-c09406612547 in namespace container-probe-4816
Dec 21 02:28:21.622: INFO: Started pod test-webserver-9142b31e-1f2e-48cb-aed1-c09406612547 in namespace container-probe-4816
STEP: checking the pod's current state and verifying that restartCount is present
Dec 21 02:28:21.625: INFO: Initial restart count of pod test-webserver-9142b31e-1f2e-48cb-aed1-c09406612547 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:32:22.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4816" for this suite.
Dec 21 02:32:28.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:32:28.174: INFO: namespace container-probe-4816 deletion completed in 6.103543037s

â€¢ [SLOW TEST:248.589 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:32:28.175: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Dec 21 02:32:28.204: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-9925" to be "success or failure"
Dec 21 02:32:28.212: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 7.95247ms
Dec 21 02:32:30.215: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011391544s
STEP: Saw pod success
Dec 21 02:32:30.215: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec 21 02:32:30.218: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec 21 02:32:30.235: INFO: Waiting for pod pod-host-path-test to disappear
Dec 21 02:32:30.238: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:32:30.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-9925" for this suite.
Dec 21 02:32:36.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:32:36.332: INFO: namespace hostpath-9925 deletion completed in 6.091501499s

â€¢ [SLOW TEST:8.157 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:32:36.333: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6893.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6893.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 21 02:32:38.397: INFO: DNS probes using dns-6893/dns-test-9055be7b-0cb4-476e-af80-0e70c1b3ff19 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:32:38.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6893" for this suite.
Dec 21 02:32:44.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:32:44.502: INFO: namespace dns-6893 deletion completed in 6.092099213s

â€¢ [SLOW TEST:8.169 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:32:44.502: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 02:32:44.945: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 21 02:32:46.953: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492364, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492364, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492364, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492364, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 02:32:49.965: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Dec 21 02:32:50.989: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:32:50.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5655" for this suite.
Dec 21 02:32:57.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:32:57.100: INFO: namespace webhook-5655 deletion completed in 6.097989871s
STEP: Destroying namespace "webhook-5655-markers" for this suite.
Dec 21 02:33:03.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:33:03.191: INFO: namespace webhook-5655-markers deletion completed in 6.091262913s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:18.702 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:33:03.205: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-2d7e24e3-8650-443a-b85e-be5fea0fe461
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:33:03.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2859" for this suite.
Dec 21 02:33:09.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:33:09.376: INFO: namespace secrets-2859 deletion completed in 6.09046556s

â€¢ [SLOW TEST:6.171 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:33:09.376: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 21 02:33:09.409: INFO: Waiting up to 5m0s for pod "downward-api-0b44ecdf-bb3a-4867-ab0a-0fb023a5638d" in namespace "downward-api-4270" to be "success or failure"
Dec 21 02:33:09.413: INFO: Pod "downward-api-0b44ecdf-bb3a-4867-ab0a-0fb023a5638d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.047838ms
Dec 21 02:33:11.416: INFO: Pod "downward-api-0b44ecdf-bb3a-4867-ab0a-0fb023a5638d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007198801s
STEP: Saw pod success
Dec 21 02:33:11.417: INFO: Pod "downward-api-0b44ecdf-bb3a-4867-ab0a-0fb023a5638d" satisfied condition "success or failure"
Dec 21 02:33:11.419: INFO: Trying to get logs from node ip-172-31-29-169 pod downward-api-0b44ecdf-bb3a-4867-ab0a-0fb023a5638d container dapi-container: <nil>
STEP: delete the pod
Dec 21 02:33:11.433: INFO: Waiting for pod downward-api-0b44ecdf-bb3a-4867-ab0a-0fb023a5638d to disappear
Dec 21 02:33:11.437: INFO: Pod downward-api-0b44ecdf-bb3a-4867-ab0a-0fb023a5638d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:33:11.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4270" for this suite.
Dec 21 02:33:17.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:33:17.527: INFO: namespace downward-api-4270 deletion completed in 6.084706437s

â€¢ [SLOW TEST:8.151 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:33:17.528: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec 21 02:33:23.576: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4583 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 02:33:23.576: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 02:33:23.651: INFO: Exec stderr: ""
Dec 21 02:33:23.651: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4583 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 02:33:23.651: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 02:33:23.723: INFO: Exec stderr: ""
Dec 21 02:33:23.723: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4583 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 02:33:23.723: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 02:33:23.790: INFO: Exec stderr: ""
Dec 21 02:33:23.790: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4583 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 02:33:23.790: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 02:33:23.858: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec 21 02:33:23.858: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4583 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 02:33:23.858: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 02:33:23.930: INFO: Exec stderr: ""
Dec 21 02:33:23.930: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4583 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 02:33:23.930: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 02:33:24.001: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec 21 02:33:24.001: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4583 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 02:33:24.001: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 02:33:24.085: INFO: Exec stderr: ""
Dec 21 02:33:24.085: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4583 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 02:33:24.085: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 02:33:24.160: INFO: Exec stderr: ""
Dec 21 02:33:24.160: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4583 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 02:33:24.160: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 02:33:24.224: INFO: Exec stderr: ""
Dec 21 02:33:24.224: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4583 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 02:33:24.224: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 02:33:24.293: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:33:24.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-4583" for this suite.
Dec 21 02:34:10.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:34:10.386: INFO: namespace e2e-kubelet-etc-hosts-4583 deletion completed in 46.089309427s

â€¢ [SLOW TEST:52.858 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:34:10.386: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 21 02:34:10.410: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 21 02:34:10.417: INFO: Waiting for terminating namespaces to be deleted...
Dec 21 02:34:10.419: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-29-169 before test
Dec 21 02:34:10.424: INFO: sonobuoy-systemd-logs-daemon-set-be71f149a5064d0d-kxt8c from sonobuoy started at 2019-12-21 01:24:53 +0000 UTC (2 container statuses recorded)
Dec 21 02:34:10.424: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 21 02:34:10.424: INFO: 	Container systemd-logs ready: true, restart count 1
Dec 21 02:34:10.424: INFO: svclb-traefik-nnb5s from kube-system started at 2019-12-21 00:42:09 +0000 UTC (3 container statuses recorded)
Dec 21 02:34:10.424: INFO: 	Container lb-port-443 ready: true, restart count 0
Dec 21 02:34:10.424: INFO: 	Container lb-port-80 ready: true, restart count 0
Dec 21 02:34:10.424: INFO: 	Container lb-port-8080 ready: true, restart count 0
Dec 21 02:34:10.424: INFO: sonobuoy from sonobuoy started at 2019-12-21 01:24:48 +0000 UTC (1 container statuses recorded)
Dec 21 02:34:10.424: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 21 02:34:10.424: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-25-252 before test
Dec 21 02:34:10.432: INFO: helm-install-traefik-hhwxg from kube-system started at 2019-12-21 00:41:22 +0000 UTC (1 container statuses recorded)
Dec 21 02:34:10.432: INFO: 	Container helm ready: false, restart count 0
Dec 21 02:34:10.432: INFO: coredns-d798c9dd-llwxl from kube-system started at 2019-12-21 00:41:22 +0000 UTC (1 container statuses recorded)
Dec 21 02:34:10.432: INFO: 	Container coredns ready: true, restart count 0
Dec 21 02:34:10.432: INFO: traefik-65bccdc4bd-xhwzd from kube-system started at 2019-12-21 00:41:53 +0000 UTC (1 container statuses recorded)
Dec 21 02:34:10.432: INFO: 	Container traefik ready: true, restart count 0
Dec 21 02:34:10.432: INFO: sonobuoy-systemd-logs-daemon-set-be71f149a5064d0d-5z58c from sonobuoy started at 2019-12-21 01:24:52 +0000 UTC (2 container statuses recorded)
Dec 21 02:34:10.432: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 21 02:34:10.432: INFO: 	Container systemd-logs ready: true, restart count 1
Dec 21 02:34:10.432: INFO: metrics-server-6d684c7b5-t9j6h from kube-system started at 2019-12-21 00:41:22 +0000 UTC (1 container statuses recorded)
Dec 21 02:34:10.432: INFO: 	Container metrics-server ready: true, restart count 0
Dec 21 02:34:10.432: INFO: local-path-provisioner-58fb86bdfd-62kwn from kube-system started at 2019-12-21 00:41:22 +0000 UTC (1 container statuses recorded)
Dec 21 02:34:10.432: INFO: 	Container local-path-provisioner ready: true, restart count 0
Dec 21 02:34:10.432: INFO: svclb-traefik-lnc6c from kube-system started at 2019-12-21 00:41:53 +0000 UTC (3 container statuses recorded)
Dec 21 02:34:10.432: INFO: 	Container lb-port-443 ready: true, restart count 0
Dec 21 02:34:10.432: INFO: 	Container lb-port-80 ready: true, restart count 0
Dec 21 02:34:10.432: INFO: 	Container lb-port-8080 ready: true, restart count 0
Dec 21 02:34:10.432: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-29-141 before test
Dec 21 02:34:10.443: INFO: sonobuoy-e2e-job-c939600be6994601 from sonobuoy started at 2019-12-21 01:24:52 +0000 UTC (2 container statuses recorded)
Dec 21 02:34:10.443: INFO: 	Container e2e ready: true, restart count 0
Dec 21 02:34:10.443: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 02:34:10.443: INFO: sonobuoy-systemd-logs-daemon-set-be71f149a5064d0d-pn2hq from sonobuoy started at 2019-12-21 01:24:53 +0000 UTC (2 container statuses recorded)
Dec 21 02:34:10.443: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 21 02:34:10.443: INFO: 	Container systemd-logs ready: true, restart count 1
Dec 21 02:34:10.443: INFO: svclb-traefik-7ksbn from kube-system started at 2019-12-21 00:42:23 +0000 UTC (3 container statuses recorded)
Dec 21 02:34:10.443: INFO: 	Container lb-port-443 ready: true, restart count 0
Dec 21 02:34:10.443: INFO: 	Container lb-port-80 ready: true, restart count 0
Dec 21 02:34:10.443: INFO: 	Container lb-port-8080 ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-de5c9f8b-aaf1-4f05-9145-c319d5787a3e 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-de5c9f8b-aaf1-4f05-9145-c319d5787a3e off the node ip-172-31-29-169
STEP: verifying the node doesn't have the label kubernetes.io/e2e-de5c9f8b-aaf1-4f05-9145-c319d5787a3e
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:39:14.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1182" for this suite.
Dec 21 02:39:22.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:39:22.626: INFO: namespace sched-pred-1182 deletion completed in 8.104314731s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

â€¢ [SLOW TEST:312.240 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:39:22.626: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-b820d91e-5c86-4b4c-b1ac-b1c0420eafe9
STEP: Creating a pod to test consume secrets
Dec 21 02:39:22.659: INFO: Waiting up to 5m0s for pod "pod-secrets-c138aa79-a3ac-4529-8577-86b734499edd" in namespace "secrets-7310" to be "success or failure"
Dec 21 02:39:22.664: INFO: Pod "pod-secrets-c138aa79-a3ac-4529-8577-86b734499edd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.66436ms
Dec 21 02:39:24.667: INFO: Pod "pod-secrets-c138aa79-a3ac-4529-8577-86b734499edd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007689573s
STEP: Saw pod success
Dec 21 02:39:24.667: INFO: Pod "pod-secrets-c138aa79-a3ac-4529-8577-86b734499edd" satisfied condition "success or failure"
Dec 21 02:39:24.669: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-secrets-c138aa79-a3ac-4529-8577-86b734499edd container secret-volume-test: <nil>
STEP: delete the pod
Dec 21 02:39:24.685: INFO: Waiting for pod pod-secrets-c138aa79-a3ac-4529-8577-86b734499edd to disappear
Dec 21 02:39:24.688: INFO: Pod pod-secrets-c138aa79-a3ac-4529-8577-86b734499edd no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:39:24.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7310" for this suite.
Dec 21 02:39:30.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:39:30.786: INFO: namespace secrets-7310 deletion completed in 6.095166285s

â€¢ [SLOW TEST:8.160 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:39:30.787: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 21 02:39:30.822: INFO: Waiting up to 5m0s for pod "pod-53058c53-b463-44d6-b895-3053019e5ddd" in namespace "emptydir-1137" to be "success or failure"
Dec 21 02:39:30.824: INFO: Pod "pod-53058c53-b463-44d6-b895-3053019e5ddd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.441832ms
Dec 21 02:39:32.828: INFO: Pod "pod-53058c53-b463-44d6-b895-3053019e5ddd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005595536s
Dec 21 02:39:34.831: INFO: Pod "pod-53058c53-b463-44d6-b895-3053019e5ddd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008922814s
STEP: Saw pod success
Dec 21 02:39:34.831: INFO: Pod "pod-53058c53-b463-44d6-b895-3053019e5ddd" satisfied condition "success or failure"
Dec 21 02:39:34.833: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-53058c53-b463-44d6-b895-3053019e5ddd container test-container: <nil>
STEP: delete the pod
Dec 21 02:39:34.845: INFO: Waiting for pod pod-53058c53-b463-44d6-b895-3053019e5ddd to disappear
Dec 21 02:39:34.848: INFO: Pod pod-53058c53-b463-44d6-b895-3053019e5ddd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:39:34.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1137" for this suite.
Dec 21 02:39:40.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:39:40.940: INFO: namespace emptydir-1137 deletion completed in 6.089278286s

â€¢ [SLOW TEST:10.154 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:39:40.940: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1221 02:40:20.986556      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 21 02:40:20.986: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:40:20.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7943" for this suite.
Dec 21 02:40:26.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:40:27.084: INFO: namespace gc-7943 deletion completed in 6.094698834s

â€¢ [SLOW TEST:46.143 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:40:27.084: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 02:40:27.114: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec 21 02:40:32.121: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 21 02:40:32.121: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec 21 02:40:34.124: INFO: Creating deployment "test-rollover-deployment"
Dec 21 02:40:34.130: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec 21 02:40:36.135: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec 21 02:40:36.139: INFO: Ensure that both replica sets have 1 created replica
Dec 21 02:40:36.144: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec 21 02:40:36.149: INFO: Updating deployment test-rollover-deployment
Dec 21 02:40:36.149: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec 21 02:40:38.154: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec 21 02:40:38.158: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec 21 02:40:38.162: INFO: all replica sets need to contain the pod-template-hash label
Dec 21 02:40:38.162: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492834, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492834, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492837, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492834, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 21 02:40:40.167: INFO: all replica sets need to contain the pod-template-hash label
Dec 21 02:40:40.167: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492834, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492834, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492837, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492834, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 21 02:40:42.167: INFO: all replica sets need to contain the pod-template-hash label
Dec 21 02:40:42.167: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492834, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492834, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492837, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492834, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 21 02:40:44.167: INFO: all replica sets need to contain the pod-template-hash label
Dec 21 02:40:44.167: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492834, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492834, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492837, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492834, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 21 02:40:46.168: INFO: all replica sets need to contain the pod-template-hash label
Dec 21 02:40:46.168: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492834, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492834, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492837, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712492834, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 21 02:40:48.167: INFO: 
Dec 21 02:40:48.167: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 21 02:40:48.174: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-5878 /apis/apps/v1/namespaces/deployment-5878/deployments/test-rollover-deployment e4062af1-16cf-454a-a2f3-abc238f1b501 16967 2 2019-12-21 02:40:34 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003c365b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-21 02:40:34 +0000 UTC,LastTransitionTime:2019-12-21 02:40:34 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2019-12-21 02:40:47 +0000 UTC,LastTransitionTime:2019-12-21 02:40:34 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 21 02:40:48.176: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-5878 /apis/apps/v1/namespaces/deployment-5878/replicasets/test-rollover-deployment-7d7dc6548c 1bbc5a83-185b-45f6-8668-ee9cdb128ed8 16956 2 2019-12-21 02:40:36 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment e4062af1-16cf-454a-a2f3-abc238f1b501 0xc003a4e147 0xc003a4e148}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003a4e1b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 21 02:40:48.176: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec 21 02:40:48.176: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-5878 /apis/apps/v1/namespaces/deployment-5878/replicasets/test-rollover-controller 18bcf250-6ece-4893-bb29-13cc8f827932 16966 2 2019-12-21 02:40:27 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment e4062af1-16cf-454a-a2f3-abc238f1b501 0xc003a4e217 0xc003a4e218}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003a4e278 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 21 02:40:48.177: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-5878 /apis/apps/v1/namespaces/deployment-5878/replicasets/test-rollover-deployment-f6c94f66c 849731dd-5eab-4d8d-89d8-f504a7ea7efc 16928 2 2019-12-21 02:40:34 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment e4062af1-16cf-454a-a2f3-abc238f1b501 0xc003a4e060 0xc003a4e061}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003a4e0d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 21 02:40:48.179: INFO: Pod "test-rollover-deployment-7d7dc6548c-t9cr2" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-t9cr2 test-rollover-deployment-7d7dc6548c- deployment-5878 /api/v1/namespaces/deployment-5878/pods/test-rollover-deployment-7d7dc6548c-t9cr2 0cbd5786-ac19-4020-8dd6-c7c8c47ac184 16943 0 2019-12-21 02:40:36 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c 1bbc5a83-185b-45f6-8668-ee9cdb128ed8 0xc003c36997 0xc003c36998}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h5tqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h5tqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h5tqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-169,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:40:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:40:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:40:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:40:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.169,PodIP:10.42.1.203,StartTime:2019-12-21 02:40:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-21 02:40:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://bad379ce3cc0b45e6c1536e61d7bae8a4c5566499302f39c0b7086725d98a460,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.203,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:40:48.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5878" for this suite.
Dec 21 02:40:54.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:40:54.273: INFO: namespace deployment-5878 deletion completed in 6.091702861s

â€¢ [SLOW TEST:27.189 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:40:54.273: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-d06e3811-9762-490f-9152-b1520a532bad
STEP: Creating a pod to test consume configMaps
Dec 21 02:40:54.304: INFO: Waiting up to 5m0s for pod "pod-configmaps-d4aa7ba2-8c3b-413d-8190-5a54969a3c62" in namespace "configmap-9191" to be "success or failure"
Dec 21 02:40:54.306: INFO: Pod "pod-configmaps-d4aa7ba2-8c3b-413d-8190-5a54969a3c62": Phase="Pending", Reason="", readiness=false. Elapsed: 1.986ms
Dec 21 02:40:56.309: INFO: Pod "pod-configmaps-d4aa7ba2-8c3b-413d-8190-5a54969a3c62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004947532s
STEP: Saw pod success
Dec 21 02:40:56.309: INFO: Pod "pod-configmaps-d4aa7ba2-8c3b-413d-8190-5a54969a3c62" satisfied condition "success or failure"
Dec 21 02:40:56.311: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-configmaps-d4aa7ba2-8c3b-413d-8190-5a54969a3c62 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 02:40:56.326: INFO: Waiting for pod pod-configmaps-d4aa7ba2-8c3b-413d-8190-5a54969a3c62 to disappear
Dec 21 02:40:56.329: INFO: Pod pod-configmaps-d4aa7ba2-8c3b-413d-8190-5a54969a3c62 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:40:56.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9191" for this suite.
Dec 21 02:41:02.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:41:02.423: INFO: namespace configmap-9191 deletion completed in 6.091374602s

â€¢ [SLOW TEST:8.150 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:41:02.424: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 21 02:41:02.450: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 21 02:41:02.461: INFO: Waiting for terminating namespaces to be deleted...
Dec 21 02:41:02.464: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-29-169 before test
Dec 21 02:41:02.469: INFO: svclb-traefik-nnb5s from kube-system started at 2019-12-21 00:42:09 +0000 UTC (3 container statuses recorded)
Dec 21 02:41:02.469: INFO: 	Container lb-port-443 ready: true, restart count 0
Dec 21 02:41:02.469: INFO: 	Container lb-port-80 ready: true, restart count 0
Dec 21 02:41:02.469: INFO: 	Container lb-port-8080 ready: true, restart count 0
Dec 21 02:41:02.469: INFO: sonobuoy from sonobuoy started at 2019-12-21 01:24:48 +0000 UTC (1 container statuses recorded)
Dec 21 02:41:02.469: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 21 02:41:02.469: INFO: sonobuoy-systemd-logs-daemon-set-be71f149a5064d0d-kxt8c from sonobuoy started at 2019-12-21 01:24:53 +0000 UTC (2 container statuses recorded)
Dec 21 02:41:02.469: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 21 02:41:02.469: INFO: 	Container systemd-logs ready: true, restart count 1
Dec 21 02:41:02.469: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-25-252 before test
Dec 21 02:41:02.477: INFO: local-path-provisioner-58fb86bdfd-62kwn from kube-system started at 2019-12-21 00:41:22 +0000 UTC (1 container statuses recorded)
Dec 21 02:41:02.477: INFO: 	Container local-path-provisioner ready: true, restart count 0
Dec 21 02:41:02.477: INFO: svclb-traefik-lnc6c from kube-system started at 2019-12-21 00:41:53 +0000 UTC (3 container statuses recorded)
Dec 21 02:41:02.477: INFO: 	Container lb-port-443 ready: true, restart count 0
Dec 21 02:41:02.477: INFO: 	Container lb-port-80 ready: true, restart count 0
Dec 21 02:41:02.477: INFO: 	Container lb-port-8080 ready: true, restart count 0
Dec 21 02:41:02.477: INFO: metrics-server-6d684c7b5-t9j6h from kube-system started at 2019-12-21 00:41:22 +0000 UTC (1 container statuses recorded)
Dec 21 02:41:02.477: INFO: 	Container metrics-server ready: true, restart count 0
Dec 21 02:41:02.477: INFO: coredns-d798c9dd-llwxl from kube-system started at 2019-12-21 00:41:22 +0000 UTC (1 container statuses recorded)
Dec 21 02:41:02.477: INFO: 	Container coredns ready: true, restart count 0
Dec 21 02:41:02.477: INFO: traefik-65bccdc4bd-xhwzd from kube-system started at 2019-12-21 00:41:53 +0000 UTC (1 container statuses recorded)
Dec 21 02:41:02.477: INFO: 	Container traefik ready: true, restart count 0
Dec 21 02:41:02.477: INFO: helm-install-traefik-hhwxg from kube-system started at 2019-12-21 00:41:22 +0000 UTC (1 container statuses recorded)
Dec 21 02:41:02.477: INFO: 	Container helm ready: false, restart count 0
Dec 21 02:41:02.477: INFO: sonobuoy-systemd-logs-daemon-set-be71f149a5064d0d-5z58c from sonobuoy started at 2019-12-21 01:24:52 +0000 UTC (2 container statuses recorded)
Dec 21 02:41:02.478: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 21 02:41:02.478: INFO: 	Container systemd-logs ready: true, restart count 1
Dec 21 02:41:02.478: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-29-141 before test
Dec 21 02:41:02.487: INFO: sonobuoy-systemd-logs-daemon-set-be71f149a5064d0d-pn2hq from sonobuoy started at 2019-12-21 01:24:53 +0000 UTC (2 container statuses recorded)
Dec 21 02:41:02.487: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 21 02:41:02.487: INFO: 	Container systemd-logs ready: true, restart count 1
Dec 21 02:41:02.487: INFO: svclb-traefik-7ksbn from kube-system started at 2019-12-21 00:42:23 +0000 UTC (3 container statuses recorded)
Dec 21 02:41:02.487: INFO: 	Container lb-port-443 ready: true, restart count 0
Dec 21 02:41:02.487: INFO: 	Container lb-port-80 ready: true, restart count 0
Dec 21 02:41:02.487: INFO: 	Container lb-port-8080 ready: true, restart count 0
Dec 21 02:41:02.487: INFO: sonobuoy-e2e-job-c939600be6994601 from sonobuoy started at 2019-12-21 01:24:52 +0000 UTC (2 container statuses recorded)
Dec 21 02:41:02.487: INFO: 	Container e2e ready: true, restart count 0
Dec 21 02:41:02.487: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node ip-172-31-29-169
STEP: verifying the node has the label node ip-172-31-25-252
STEP: verifying the node has the label node ip-172-31-29-141
Dec 21 02:41:02.523: INFO: Pod local-path-provisioner-58fb86bdfd-62kwn requesting resource cpu=0m on Node ip-172-31-25-252
Dec 21 02:41:02.523: INFO: Pod metrics-server-6d684c7b5-t9j6h requesting resource cpu=0m on Node ip-172-31-25-252
Dec 21 02:41:02.523: INFO: Pod coredns-d798c9dd-llwxl requesting resource cpu=100m on Node ip-172-31-25-252
Dec 21 02:41:02.523: INFO: Pod svclb-traefik-lnc6c requesting resource cpu=0m on Node ip-172-31-25-252
Dec 21 02:41:02.523: INFO: Pod traefik-65bccdc4bd-xhwzd requesting resource cpu=0m on Node ip-172-31-25-252
Dec 21 02:41:02.523: INFO: Pod svclb-traefik-nnb5s requesting resource cpu=0m on Node ip-172-31-29-169
Dec 21 02:41:02.523: INFO: Pod svclb-traefik-7ksbn requesting resource cpu=0m on Node ip-172-31-29-141
Dec 21 02:41:02.523: INFO: Pod sonobuoy-e2e-job-c939600be6994601 requesting resource cpu=0m on Node ip-172-31-29-141
Dec 21 02:41:02.523: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-29-169
Dec 21 02:41:02.523: INFO: Pod sonobuoy-systemd-logs-daemon-set-be71f149a5064d0d-kxt8c requesting resource cpu=0m on Node ip-172-31-29-169
Dec 21 02:41:02.523: INFO: Pod sonobuoy-systemd-logs-daemon-set-be71f149a5064d0d-5z58c requesting resource cpu=0m on Node ip-172-31-25-252
Dec 21 02:41:02.523: INFO: Pod sonobuoy-systemd-logs-daemon-set-be71f149a5064d0d-pn2hq requesting resource cpu=0m on Node ip-172-31-29-141
STEP: Starting Pods to consume most of the cluster CPU.
Dec 21 02:41:02.523: INFO: Creating a pod which consumes cpu=1400m on Node ip-172-31-29-169
Dec 21 02:41:02.528: INFO: Creating a pod which consumes cpu=1330m on Node ip-172-31-25-252
Dec 21 02:41:02.533: INFO: Creating a pod which consumes cpu=1400m on Node ip-172-31-29-141
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3dbe7a96-b5eb-46bf-a5aa-f74a0e7400f2.15e2429d36dbfac1], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7777/filler-pod-3dbe7a96-b5eb-46bf-a5aa-f74a0e7400f2 to ip-172-31-29-169]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1e55ae0f-144f-431c-a678-682cf4fd4f9c.15e2429d370540ca], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7777/filler-pod-1e55ae0f-144f-431c-a678-682cf4fd4f9c to ip-172-31-25-252]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f62ec19a-6cd7-420e-a011-7772bdd8cf29.15e2429d37c08e2f], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7777/filler-pod-f62ec19a-6cd7-420e-a011-7772bdd8cf29 to ip-172-31-29-141]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3dbe7a96-b5eb-46bf-a5aa-f74a0e7400f2.15e2429d60de19ff], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1e55ae0f-144f-431c-a678-682cf4fd4f9c.15e2429d625d52de], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f62ec19a-6cd7-420e-a011-7772bdd8cf29.15e2429d63a8d176], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3dbe7a96-b5eb-46bf-a5aa-f74a0e7400f2.15e2429d6665bea4], Reason = [Created], Message = [Created container filler-pod-3dbe7a96-b5eb-46bf-a5aa-f74a0e7400f2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f62ec19a-6cd7-420e-a011-7772bdd8cf29.15e2429d6946750b], Reason = [Created], Message = [Created container filler-pod-f62ec19a-6cd7-420e-a011-7772bdd8cf29]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1e55ae0f-144f-431c-a678-682cf4fd4f9c.15e2429d68e5940e], Reason = [Created], Message = [Created container filler-pod-1e55ae0f-144f-431c-a678-682cf4fd4f9c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3dbe7a96-b5eb-46bf-a5aa-f74a0e7400f2.15e2429d6e78b8ec], Reason = [Started], Message = [Started container filler-pod-3dbe7a96-b5eb-46bf-a5aa-f74a0e7400f2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f62ec19a-6cd7-420e-a011-7772bdd8cf29.15e2429d7028fa04], Reason = [Started], Message = [Started container filler-pod-f62ec19a-6cd7-420e-a011-7772bdd8cf29]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1e55ae0f-144f-431c-a678-682cf4fd4f9c.15e2429d71f6a00a], Reason = [Started], Message = [Started container filler-pod-1e55ae0f-144f-431c-a678-682cf4fd4f9c]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15e2429dafbf7bbb], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node ip-172-31-29-169
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-31-25-252
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-31-29-141
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:41:05.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7777" for this suite.
Dec 21 02:41:33.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:41:33.691: INFO: namespace sched-pred-7777 deletion completed in 28.093205752s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

â€¢ [SLOW TEST:31.267 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:41:33.691: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:41:37.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9030" for this suite.
Dec 21 02:41:43.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:41:43.822: INFO: namespace kubelet-test-9030 deletion completed in 6.089603934s

â€¢ [SLOW TEST:10.131 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:41:43.823: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8890.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8890.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8890.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8890.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8890.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8890.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 21 02:41:47.890: INFO: DNS probes using dns-8890/dns-test-b6219366-eae2-4148-8ea8-1b00b5f3e1ff succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:41:47.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8890" for this suite.
Dec 21 02:41:53.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:41:53.998: INFO: namespace dns-8890 deletion completed in 6.094115205s

â€¢ [SLOW TEST:10.175 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:41:53.999: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-2814
I1221 02:41:54.028593      22 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-2814, replica count: 1
I1221 02:41:55.079158      22 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1221 02:41:56.079451      22 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 21 02:41:56.186: INFO: Created: latency-svc-lm4f8
Dec 21 02:41:56.191: INFO: Got endpoints: latency-svc-lm4f8 [11.220634ms]
Dec 21 02:41:56.203: INFO: Created: latency-svc-kfm6p
Dec 21 02:41:56.211: INFO: Got endpoints: latency-svc-kfm6p [19.5199ms]
Dec 21 02:41:56.212: INFO: Created: latency-svc-979tc
Dec 21 02:41:56.216: INFO: Created: latency-svc-b698w
Dec 21 02:41:56.218: INFO: Got endpoints: latency-svc-979tc [26.225403ms]
Dec 21 02:41:56.220: INFO: Got endpoints: latency-svc-b698w [29.021188ms]
Dec 21 02:41:56.226: INFO: Created: latency-svc-jvdp8
Dec 21 02:41:56.231: INFO: Created: latency-svc-5vmfp
Dec 21 02:41:56.233: INFO: Got endpoints: latency-svc-jvdp8 [41.608978ms]
Dec 21 02:41:56.237: INFO: Got endpoints: latency-svc-5vmfp [44.45643ms]
Dec 21 02:41:56.239: INFO: Created: latency-svc-zns5r
Dec 21 02:41:56.244: INFO: Got endpoints: latency-svc-zns5r [51.207714ms]
Dec 21 02:41:56.247: INFO: Created: latency-svc-gtwvl
Dec 21 02:41:56.252: INFO: Got endpoints: latency-svc-gtwvl [59.637963ms]
Dec 21 02:41:56.254: INFO: Created: latency-svc-wsghc
Dec 21 02:41:56.259: INFO: Got endpoints: latency-svc-wsghc [66.716182ms]
Dec 21 02:41:56.264: INFO: Created: latency-svc-sj2c7
Dec 21 02:41:56.269: INFO: Got endpoints: latency-svc-sj2c7 [76.666904ms]
Dec 21 02:41:56.281: INFO: Created: latency-svc-j5db7
Dec 21 02:41:56.285: INFO: Got endpoints: latency-svc-j5db7 [93.036272ms]
Dec 21 02:41:56.287: INFO: Created: latency-svc-bz9wm
Dec 21 02:41:56.293: INFO: Got endpoints: latency-svc-bz9wm [101.042754ms]
Dec 21 02:41:56.298: INFO: Created: latency-svc-bvf9g
Dec 21 02:41:56.298: INFO: Got endpoints: latency-svc-bvf9g [106.186579ms]
Dec 21 02:41:56.302: INFO: Created: latency-svc-8v9tc
Dec 21 02:41:56.309: INFO: Got endpoints: latency-svc-8v9tc [116.899007ms]
Dec 21 02:41:56.316: INFO: Created: latency-svc-tw4cq
Dec 21 02:41:56.321: INFO: Got endpoints: latency-svc-tw4cq [129.23597ms]
Dec 21 02:41:56.330: INFO: Created: latency-svc-wsj9b
Dec 21 02:41:56.330: INFO: Created: latency-svc-tfmhj
Dec 21 02:41:56.333: INFO: Got endpoints: latency-svc-wsj9b [141.114777ms]
Dec 21 02:41:56.334: INFO: Created: latency-svc-8s85z
Dec 21 02:41:56.341: INFO: Got endpoints: latency-svc-tfmhj [129.998984ms]
Dec 21 02:41:56.342: INFO: Got endpoints: latency-svc-8s85z [124.213236ms]
Dec 21 02:41:56.350: INFO: Created: latency-svc-txr5k
Dec 21 02:41:56.361: INFO: Got endpoints: latency-svc-txr5k [141.004586ms]
Dec 21 02:41:56.362: INFO: Created: latency-svc-nkhl9
Dec 21 02:41:56.364: INFO: Created: latency-svc-n5plj
Dec 21 02:41:56.369: INFO: Got endpoints: latency-svc-nkhl9 [136.413899ms]
Dec 21 02:41:56.373: INFO: Got endpoints: latency-svc-n5plj [136.308252ms]
Dec 21 02:41:56.374: INFO: Created: latency-svc-vj5cz
Dec 21 02:41:56.382: INFO: Got endpoints: latency-svc-vj5cz [138.034788ms]
Dec 21 02:41:56.393: INFO: Created: latency-svc-ppnv9
Dec 21 02:41:56.402: INFO: Created: latency-svc-nqkt9
Dec 21 02:41:56.407: INFO: Got endpoints: latency-svc-ppnv9 [154.601411ms]
Dec 21 02:41:56.407: INFO: Got endpoints: latency-svc-nqkt9 [147.664187ms]
Dec 21 02:41:56.408: INFO: Created: latency-svc-qfzvx
Dec 21 02:41:56.416: INFO: Got endpoints: latency-svc-qfzvx [146.965748ms]
Dec 21 02:41:56.421: INFO: Created: latency-svc-b2f9x
Dec 21 02:41:56.421: INFO: Created: latency-svc-jpjdc
Dec 21 02:41:56.430: INFO: Created: latency-svc-p4m9v
Dec 21 02:41:56.431: INFO: Got endpoints: latency-svc-jpjdc [138.223037ms]
Dec 21 02:41:56.432: INFO: Got endpoints: latency-svc-b2f9x [146.433572ms]
Dec 21 02:41:56.443: INFO: Got endpoints: latency-svc-p4m9v [144.724336ms]
Dec 21 02:41:56.444: INFO: Created: latency-svc-nqxrx
Dec 21 02:41:56.449: INFO: Got endpoints: latency-svc-nqxrx [140.496593ms]
Dec 21 02:41:56.453: INFO: Created: latency-svc-jb2lk
Dec 21 02:41:56.456: INFO: Created: latency-svc-8n7s5
Dec 21 02:41:56.480: INFO: Got endpoints: latency-svc-jb2lk [159.095978ms]
Dec 21 02:41:56.517: INFO: Got endpoints: latency-svc-8n7s5 [184.504738ms]
Dec 21 02:41:56.556: INFO: Created: latency-svc-qvj97
Dec 21 02:41:56.586: INFO: Got endpoints: latency-svc-qvj97 [245.35168ms]
Dec 21 02:41:56.589: INFO: Created: latency-svc-662wx
Dec 21 02:41:56.600: INFO: Got endpoints: latency-svc-662wx [257.924419ms]
Dec 21 02:41:56.604: INFO: Created: latency-svc-ncqds
Dec 21 02:41:56.619: INFO: Created: latency-svc-9p2tp
Dec 21 02:41:56.621: INFO: Created: latency-svc-dwwff
Dec 21 02:41:56.629: INFO: Got endpoints: latency-svc-ncqds [267.271929ms]
Dec 21 02:41:56.632: INFO: Got endpoints: latency-svc-9p2tp [258.108799ms]
Dec 21 02:41:56.642: INFO: Created: latency-svc-zclvq
Dec 21 02:41:56.657: INFO: Created: latency-svc-9pqx5
Dec 21 02:41:56.662: INFO: Got endpoints: latency-svc-zclvq [279.805558ms]
Dec 21 02:41:56.662: INFO: Got endpoints: latency-svc-dwwff [292.732395ms]
Dec 21 02:41:56.674: INFO: Created: latency-svc-x8jj5
Dec 21 02:41:56.675: INFO: Got endpoints: latency-svc-9pqx5 [268.405352ms]
Dec 21 02:41:56.685: INFO: Got endpoints: latency-svc-x8jj5 [278.054089ms]
Dec 21 02:41:56.691: INFO: Created: latency-svc-mdg9h
Dec 21 02:41:56.709: INFO: Created: latency-svc-8xvxf
Dec 21 02:41:56.709: INFO: Created: latency-svc-twtg2
Dec 21 02:41:56.718: INFO: Got endpoints: latency-svc-mdg9h [302.190878ms]
Dec 21 02:41:56.729: INFO: Created: latency-svc-mrj5x
Dec 21 02:41:56.737: INFO: Created: latency-svc-7dmzg
Dec 21 02:41:56.747: INFO: Got endpoints: latency-svc-twtg2 [315.591503ms]
Dec 21 02:41:56.755: INFO: Created: latency-svc-h2rp7
Dec 21 02:41:56.763: INFO: Created: latency-svc-gqth9
Dec 21 02:41:56.774: INFO: Created: latency-svc-7xx9m
Dec 21 02:41:56.782: INFO: Created: latency-svc-mzww7
Dec 21 02:41:56.791: INFO: Created: latency-svc-s95k7
Dec 21 02:41:56.798: INFO: Got endpoints: latency-svc-8xvxf [366.627848ms]
Dec 21 02:41:56.810: INFO: Created: latency-svc-cn6rj
Dec 21 02:41:56.851: INFO: Got endpoints: latency-svc-mrj5x [408.485494ms]
Dec 21 02:41:56.852: INFO: Created: latency-svc-29c8z
Dec 21 02:41:56.879: INFO: Created: latency-svc-hjls2
Dec 21 02:41:56.879: INFO: Created: latency-svc-plsgs
Dec 21 02:41:56.908: INFO: Got endpoints: latency-svc-7dmzg [459.174619ms]
Dec 21 02:41:56.919: INFO: Created: latency-svc-nqhhg
Dec 21 02:41:56.930: INFO: Created: latency-svc-kjmkp
Dec 21 02:41:56.948: INFO: Created: latency-svc-4n8ln
Dec 21 02:41:56.950: INFO: Got endpoints: latency-svc-h2rp7 [469.706618ms]
Dec 21 02:41:56.953: INFO: Created: latency-svc-sdmm7
Dec 21 02:41:56.964: INFO: Created: latency-svc-94dtd
Dec 21 02:41:56.970: INFO: Created: latency-svc-mwstd
Dec 21 02:41:56.973: INFO: Created: latency-svc-v8c57
Dec 21 02:41:56.990: INFO: Got endpoints: latency-svc-gqth9 [473.15528ms]
Dec 21 02:41:56.996: INFO: Created: latency-svc-qqt9r
Dec 21 02:41:57.041: INFO: Got endpoints: latency-svc-7xx9m [454.611324ms]
Dec 21 02:41:57.047: INFO: Created: latency-svc-6nq8h
Dec 21 02:41:57.092: INFO: Got endpoints: latency-svc-mzww7 [491.728082ms]
Dec 21 02:41:57.098: INFO: Created: latency-svc-ml7s4
Dec 21 02:41:57.141: INFO: Got endpoints: latency-svc-s95k7 [512.37866ms]
Dec 21 02:41:57.147: INFO: Created: latency-svc-7zpk6
Dec 21 02:41:57.192: INFO: Got endpoints: latency-svc-cn6rj [560.22137ms]
Dec 21 02:41:57.198: INFO: Created: latency-svc-77jsk
Dec 21 02:41:57.242: INFO: Got endpoints: latency-svc-29c8z [580.028025ms]
Dec 21 02:41:57.248: INFO: Created: latency-svc-2v7jg
Dec 21 02:41:57.292: INFO: Got endpoints: latency-svc-hjls2 [629.883528ms]
Dec 21 02:41:57.297: INFO: Created: latency-svc-z6mxp
Dec 21 02:41:57.342: INFO: Got endpoints: latency-svc-plsgs [666.65852ms]
Dec 21 02:41:57.348: INFO: Created: latency-svc-pzqgq
Dec 21 02:41:57.391: INFO: Got endpoints: latency-svc-nqhhg [706.110026ms]
Dec 21 02:41:57.434: INFO: Created: latency-svc-m9wh2
Dec 21 02:41:57.441: INFO: Got endpoints: latency-svc-kjmkp [722.375189ms]
Dec 21 02:41:57.447: INFO: Created: latency-svc-rn8dm
Dec 21 02:41:57.491: INFO: Got endpoints: latency-svc-4n8ln [744.12854ms]
Dec 21 02:41:57.499: INFO: Created: latency-svc-p9ntn
Dec 21 02:41:57.541: INFO: Got endpoints: latency-svc-sdmm7 [743.288357ms]
Dec 21 02:41:57.548: INFO: Created: latency-svc-phlnp
Dec 21 02:41:57.592: INFO: Got endpoints: latency-svc-94dtd [740.048197ms]
Dec 21 02:41:57.599: INFO: Created: latency-svc-l52xd
Dec 21 02:41:57.642: INFO: Got endpoints: latency-svc-mwstd [733.412378ms]
Dec 21 02:41:57.650: INFO: Created: latency-svc-v4n2c
Dec 21 02:41:57.692: INFO: Got endpoints: latency-svc-v8c57 [742.08959ms]
Dec 21 02:41:57.698: INFO: Created: latency-svc-zc9rn
Dec 21 02:41:57.741: INFO: Got endpoints: latency-svc-qqt9r [750.713119ms]
Dec 21 02:41:57.747: INFO: Created: latency-svc-qq4ss
Dec 21 02:41:57.791: INFO: Got endpoints: latency-svc-6nq8h [750.219516ms]
Dec 21 02:41:57.798: INFO: Created: latency-svc-74kdw
Dec 21 02:41:57.843: INFO: Got endpoints: latency-svc-ml7s4 [751.544637ms]
Dec 21 02:41:57.849: INFO: Created: latency-svc-zq28k
Dec 21 02:41:57.891: INFO: Got endpoints: latency-svc-7zpk6 [750.152954ms]
Dec 21 02:41:57.898: INFO: Created: latency-svc-ld4fm
Dec 21 02:41:57.942: INFO: Got endpoints: latency-svc-77jsk [749.678717ms]
Dec 21 02:41:57.948: INFO: Created: latency-svc-gc9rc
Dec 21 02:41:57.992: INFO: Got endpoints: latency-svc-2v7jg [750.133689ms]
Dec 21 02:41:57.999: INFO: Created: latency-svc-lpds2
Dec 21 02:41:58.044: INFO: Got endpoints: latency-svc-z6mxp [751.8929ms]
Dec 21 02:41:58.050: INFO: Created: latency-svc-dmqwr
Dec 21 02:41:58.092: INFO: Got endpoints: latency-svc-pzqgq [749.733336ms]
Dec 21 02:41:58.098: INFO: Created: latency-svc-7r6lr
Dec 21 02:41:58.141: INFO: Got endpoints: latency-svc-m9wh2 [749.96082ms]
Dec 21 02:41:58.148: INFO: Created: latency-svc-96wzz
Dec 21 02:41:58.191: INFO: Got endpoints: latency-svc-rn8dm [750.151861ms]
Dec 21 02:41:58.198: INFO: Created: latency-svc-hg2ld
Dec 21 02:41:58.241: INFO: Got endpoints: latency-svc-p9ntn [749.917238ms]
Dec 21 02:41:58.248: INFO: Created: latency-svc-w4sj5
Dec 21 02:41:58.291: INFO: Got endpoints: latency-svc-phlnp [750.01044ms]
Dec 21 02:41:58.297: INFO: Created: latency-svc-2zm2g
Dec 21 02:41:58.342: INFO: Got endpoints: latency-svc-l52xd [750.217482ms]
Dec 21 02:41:58.347: INFO: Created: latency-svc-z2vqs
Dec 21 02:41:58.391: INFO: Got endpoints: latency-svc-v4n2c [749.049272ms]
Dec 21 02:41:58.397: INFO: Created: latency-svc-fx97j
Dec 21 02:41:58.441: INFO: Got endpoints: latency-svc-zc9rn [748.82888ms]
Dec 21 02:41:58.447: INFO: Created: latency-svc-7nmwq
Dec 21 02:41:58.491: INFO: Got endpoints: latency-svc-qq4ss [749.915907ms]
Dec 21 02:41:58.497: INFO: Created: latency-svc-tk9gw
Dec 21 02:41:58.541: INFO: Got endpoints: latency-svc-74kdw [749.536261ms]
Dec 21 02:41:58.548: INFO: Created: latency-svc-nstvs
Dec 21 02:41:58.592: INFO: Got endpoints: latency-svc-zq28k [748.132247ms]
Dec 21 02:41:58.597: INFO: Created: latency-svc-tg66l
Dec 21 02:41:58.642: INFO: Got endpoints: latency-svc-ld4fm [750.150812ms]
Dec 21 02:41:58.648: INFO: Created: latency-svc-9lwx8
Dec 21 02:41:58.691: INFO: Got endpoints: latency-svc-gc9rc [749.465361ms]
Dec 21 02:41:58.704: INFO: Created: latency-svc-xvthp
Dec 21 02:41:58.742: INFO: Got endpoints: latency-svc-lpds2 [749.313222ms]
Dec 21 02:41:58.747: INFO: Created: latency-svc-7d7cs
Dec 21 02:41:58.792: INFO: Got endpoints: latency-svc-dmqwr [747.924667ms]
Dec 21 02:41:58.808: INFO: Created: latency-svc-8d6q6
Dec 21 02:41:58.842: INFO: Got endpoints: latency-svc-7r6lr [749.811403ms]
Dec 21 02:41:58.848: INFO: Created: latency-svc-fm8qc
Dec 21 02:41:58.890: INFO: Got endpoints: latency-svc-96wzz [749.09352ms]
Dec 21 02:41:58.898: INFO: Created: latency-svc-nlrs5
Dec 21 02:41:58.941: INFO: Got endpoints: latency-svc-hg2ld [750.025858ms]
Dec 21 02:41:58.948: INFO: Created: latency-svc-dnkkc
Dec 21 02:41:58.992: INFO: Got endpoints: latency-svc-w4sj5 [750.091837ms]
Dec 21 02:41:58.999: INFO: Created: latency-svc-vgqgm
Dec 21 02:41:59.046: INFO: Got endpoints: latency-svc-2zm2g [754.459586ms]
Dec 21 02:41:59.052: INFO: Created: latency-svc-bfhzt
Dec 21 02:41:59.094: INFO: Got endpoints: latency-svc-z2vqs [751.967573ms]
Dec 21 02:41:59.102: INFO: Created: latency-svc-w942b
Dec 21 02:41:59.145: INFO: Got endpoints: latency-svc-fx97j [753.788307ms]
Dec 21 02:41:59.152: INFO: Created: latency-svc-rpznx
Dec 21 02:41:59.192: INFO: Got endpoints: latency-svc-7nmwq [750.918517ms]
Dec 21 02:41:59.198: INFO: Created: latency-svc-w2lt5
Dec 21 02:41:59.242: INFO: Got endpoints: latency-svc-tk9gw [750.270495ms]
Dec 21 02:41:59.247: INFO: Created: latency-svc-hkvrw
Dec 21 02:41:59.292: INFO: Got endpoints: latency-svc-nstvs [751.268595ms]
Dec 21 02:41:59.309: INFO: Created: latency-svc-rtr28
Dec 21 02:41:59.345: INFO: Got endpoints: latency-svc-tg66l [753.616278ms]
Dec 21 02:41:59.357: INFO: Created: latency-svc-4pz5l
Dec 21 02:41:59.392: INFO: Got endpoints: latency-svc-9lwx8 [750.671266ms]
Dec 21 02:41:59.399: INFO: Created: latency-svc-p4x6q
Dec 21 02:41:59.442: INFO: Got endpoints: latency-svc-xvthp [750.498079ms]
Dec 21 02:41:59.448: INFO: Created: latency-svc-fbqzl
Dec 21 02:41:59.491: INFO: Got endpoints: latency-svc-7d7cs [749.456715ms]
Dec 21 02:41:59.497: INFO: Created: latency-svc-wtbqx
Dec 21 02:41:59.541: INFO: Got endpoints: latency-svc-8d6q6 [749.622568ms]
Dec 21 02:41:59.549: INFO: Created: latency-svc-9n4qp
Dec 21 02:41:59.591: INFO: Got endpoints: latency-svc-fm8qc [749.427878ms]
Dec 21 02:41:59.623: INFO: Created: latency-svc-4sjfw
Dec 21 02:41:59.642: INFO: Got endpoints: latency-svc-nlrs5 [750.992971ms]
Dec 21 02:41:59.647: INFO: Created: latency-svc-5qwbt
Dec 21 02:41:59.691: INFO: Got endpoints: latency-svc-dnkkc [749.675974ms]
Dec 21 02:41:59.697: INFO: Created: latency-svc-5kvlk
Dec 21 02:41:59.742: INFO: Got endpoints: latency-svc-vgqgm [750.376645ms]
Dec 21 02:41:59.749: INFO: Created: latency-svc-sjz5m
Dec 21 02:41:59.791: INFO: Got endpoints: latency-svc-bfhzt [744.947338ms]
Dec 21 02:41:59.798: INFO: Created: latency-svc-gmqzt
Dec 21 02:41:59.841: INFO: Got endpoints: latency-svc-w942b [747.26763ms]
Dec 21 02:41:59.849: INFO: Created: latency-svc-vc7gc
Dec 21 02:41:59.891: INFO: Got endpoints: latency-svc-rpznx [746.310517ms]
Dec 21 02:41:59.897: INFO: Created: latency-svc-p2lpg
Dec 21 02:41:59.941: INFO: Got endpoints: latency-svc-w2lt5 [749.638942ms]
Dec 21 02:41:59.947: INFO: Created: latency-svc-cwvcb
Dec 21 02:41:59.992: INFO: Got endpoints: latency-svc-hkvrw [750.835879ms]
Dec 21 02:41:59.999: INFO: Created: latency-svc-ph2zf
Dec 21 02:42:00.045: INFO: Got endpoints: latency-svc-rtr28 [752.152132ms]
Dec 21 02:42:00.052: INFO: Created: latency-svc-chzcj
Dec 21 02:42:00.092: INFO: Got endpoints: latency-svc-4pz5l [746.587977ms]
Dec 21 02:42:00.099: INFO: Created: latency-svc-rprnn
Dec 21 02:42:00.142: INFO: Got endpoints: latency-svc-p4x6q [749.276565ms]
Dec 21 02:42:00.149: INFO: Created: latency-svc-9pclm
Dec 21 02:42:00.192: INFO: Got endpoints: latency-svc-fbqzl [750.34887ms]
Dec 21 02:42:00.198: INFO: Created: latency-svc-7dnnn
Dec 21 02:42:00.241: INFO: Got endpoints: latency-svc-wtbqx [749.628333ms]
Dec 21 02:42:00.248: INFO: Created: latency-svc-xhqt8
Dec 21 02:42:00.291: INFO: Got endpoints: latency-svc-9n4qp [749.704524ms]
Dec 21 02:42:00.298: INFO: Created: latency-svc-z24tw
Dec 21 02:42:00.342: INFO: Got endpoints: latency-svc-4sjfw [750.524554ms]
Dec 21 02:42:00.348: INFO: Created: latency-svc-26mjt
Dec 21 02:42:00.391: INFO: Got endpoints: latency-svc-5qwbt [749.560321ms]
Dec 21 02:42:00.398: INFO: Created: latency-svc-5p9qn
Dec 21 02:42:00.441: INFO: Got endpoints: latency-svc-5kvlk [750.226191ms]
Dec 21 02:42:00.447: INFO: Created: latency-svc-fg8j5
Dec 21 02:42:00.493: INFO: Got endpoints: latency-svc-sjz5m [750.940364ms]
Dec 21 02:42:00.499: INFO: Created: latency-svc-bp2x2
Dec 21 02:42:00.541: INFO: Got endpoints: latency-svc-gmqzt [749.805062ms]
Dec 21 02:42:00.547: INFO: Created: latency-svc-dh6qk
Dec 21 02:42:00.592: INFO: Got endpoints: latency-svc-vc7gc [750.150272ms]
Dec 21 02:42:00.598: INFO: Created: latency-svc-f5k75
Dec 21 02:42:00.642: INFO: Got endpoints: latency-svc-p2lpg [750.02361ms]
Dec 21 02:42:00.648: INFO: Created: latency-svc-jfq9x
Dec 21 02:42:00.691: INFO: Got endpoints: latency-svc-cwvcb [749.629334ms]
Dec 21 02:42:00.697: INFO: Created: latency-svc-jmgz6
Dec 21 02:42:00.742: INFO: Got endpoints: latency-svc-ph2zf [749.155896ms]
Dec 21 02:42:00.749: INFO: Created: latency-svc-lcn69
Dec 21 02:42:00.794: INFO: Got endpoints: latency-svc-chzcj [748.906846ms]
Dec 21 02:42:00.800: INFO: Created: latency-svc-j2tfq
Dec 21 02:42:00.842: INFO: Got endpoints: latency-svc-rprnn [749.995112ms]
Dec 21 02:42:00.848: INFO: Created: latency-svc-s76l7
Dec 21 02:42:00.891: INFO: Got endpoints: latency-svc-9pclm [749.737945ms]
Dec 21 02:42:00.897: INFO: Created: latency-svc-9hxsv
Dec 21 02:42:00.943: INFO: Got endpoints: latency-svc-7dnnn [750.809043ms]
Dec 21 02:42:00.949: INFO: Created: latency-svc-mx26g
Dec 21 02:42:00.991: INFO: Got endpoints: latency-svc-xhqt8 [750.482975ms]
Dec 21 02:42:00.997: INFO: Created: latency-svc-l6kn2
Dec 21 02:42:01.042: INFO: Got endpoints: latency-svc-z24tw [750.326492ms]
Dec 21 02:42:01.049: INFO: Created: latency-svc-zkwmx
Dec 21 02:42:01.091: INFO: Got endpoints: latency-svc-26mjt [748.878368ms]
Dec 21 02:42:01.098: INFO: Created: latency-svc-ztjfc
Dec 21 02:42:01.142: INFO: Got endpoints: latency-svc-5p9qn [750.705759ms]
Dec 21 02:42:01.148: INFO: Created: latency-svc-6kpnx
Dec 21 02:42:01.191: INFO: Got endpoints: latency-svc-fg8j5 [750.002996ms]
Dec 21 02:42:01.198: INFO: Created: latency-svc-c2sz5
Dec 21 02:42:01.242: INFO: Got endpoints: latency-svc-bp2x2 [748.587702ms]
Dec 21 02:42:01.247: INFO: Created: latency-svc-4zshb
Dec 21 02:42:01.293: INFO: Got endpoints: latency-svc-dh6qk [752.408585ms]
Dec 21 02:42:01.311: INFO: Created: latency-svc-7jnp4
Dec 21 02:42:01.342: INFO: Got endpoints: latency-svc-f5k75 [750.119829ms]
Dec 21 02:42:01.350: INFO: Created: latency-svc-nr5wf
Dec 21 02:42:01.392: INFO: Got endpoints: latency-svc-jfq9x [750.801786ms]
Dec 21 02:42:01.398: INFO: Created: latency-svc-6tvxp
Dec 21 02:42:01.441: INFO: Got endpoints: latency-svc-jmgz6 [749.738459ms]
Dec 21 02:42:01.447: INFO: Created: latency-svc-twtld
Dec 21 02:42:01.491: INFO: Got endpoints: latency-svc-lcn69 [749.620483ms]
Dec 21 02:42:01.497: INFO: Created: latency-svc-cxp6r
Dec 21 02:42:01.541: INFO: Got endpoints: latency-svc-j2tfq [747.766486ms]
Dec 21 02:42:01.547: INFO: Created: latency-svc-j7llz
Dec 21 02:42:01.592: INFO: Got endpoints: latency-svc-s76l7 [749.97447ms]
Dec 21 02:42:01.598: INFO: Created: latency-svc-xfsns
Dec 21 02:42:01.642: INFO: Got endpoints: latency-svc-9hxsv [750.055048ms]
Dec 21 02:42:01.648: INFO: Created: latency-svc-x2xbf
Dec 21 02:42:01.692: INFO: Got endpoints: latency-svc-mx26g [748.551039ms]
Dec 21 02:42:01.698: INFO: Created: latency-svc-trlzl
Dec 21 02:42:01.741: INFO: Got endpoints: latency-svc-l6kn2 [749.850575ms]
Dec 21 02:42:01.748: INFO: Created: latency-svc-545fb
Dec 21 02:42:01.792: INFO: Got endpoints: latency-svc-zkwmx [750.26042ms]
Dec 21 02:42:01.798: INFO: Created: latency-svc-wbnwh
Dec 21 02:42:01.842: INFO: Got endpoints: latency-svc-ztjfc [750.727291ms]
Dec 21 02:42:01.848: INFO: Created: latency-svc-7fhkb
Dec 21 02:42:01.891: INFO: Got endpoints: latency-svc-6kpnx [749.227599ms]
Dec 21 02:42:01.927: INFO: Created: latency-svc-jt6gb
Dec 21 02:42:01.942: INFO: Got endpoints: latency-svc-c2sz5 [750.650267ms]
Dec 21 02:42:01.948: INFO: Created: latency-svc-qcgst
Dec 21 02:42:01.993: INFO: Got endpoints: latency-svc-4zshb [751.366843ms]
Dec 21 02:42:02.001: INFO: Created: latency-svc-5nns4
Dec 21 02:42:02.042: INFO: Got endpoints: latency-svc-7jnp4 [748.51902ms]
Dec 21 02:42:02.049: INFO: Created: latency-svc-lxnnc
Dec 21 02:42:02.092: INFO: Got endpoints: latency-svc-nr5wf [750.190792ms]
Dec 21 02:42:02.098: INFO: Created: latency-svc-t2l68
Dec 21 02:42:02.143: INFO: Got endpoints: latency-svc-6tvxp [750.688919ms]
Dec 21 02:42:02.150: INFO: Created: latency-svc-l5d7z
Dec 21 02:42:02.192: INFO: Got endpoints: latency-svc-twtld [750.397708ms]
Dec 21 02:42:02.197: INFO: Created: latency-svc-jkf67
Dec 21 02:42:02.242: INFO: Got endpoints: latency-svc-cxp6r [750.406712ms]
Dec 21 02:42:02.252: INFO: Created: latency-svc-fl8g8
Dec 21 02:42:02.291: INFO: Got endpoints: latency-svc-j7llz [749.881222ms]
Dec 21 02:42:02.298: INFO: Created: latency-svc-cffcx
Dec 21 02:42:02.341: INFO: Got endpoints: latency-svc-xfsns [748.821967ms]
Dec 21 02:42:02.351: INFO: Created: latency-svc-s65lz
Dec 21 02:42:02.391: INFO: Got endpoints: latency-svc-x2xbf [749.663917ms]
Dec 21 02:42:02.397: INFO: Created: latency-svc-z56gz
Dec 21 02:42:02.442: INFO: Got endpoints: latency-svc-trlzl [749.76578ms]
Dec 21 02:42:02.448: INFO: Created: latency-svc-c6cht
Dec 21 02:42:02.492: INFO: Got endpoints: latency-svc-545fb [750.193659ms]
Dec 21 02:42:02.498: INFO: Created: latency-svc-t6lhm
Dec 21 02:42:02.542: INFO: Got endpoints: latency-svc-wbnwh [750.154685ms]
Dec 21 02:42:02.548: INFO: Created: latency-svc-g5bwd
Dec 21 02:42:02.591: INFO: Got endpoints: latency-svc-7fhkb [749.71514ms]
Dec 21 02:42:02.600: INFO: Created: latency-svc-g5pmj
Dec 21 02:42:02.641: INFO: Got endpoints: latency-svc-jt6gb [750.093687ms]
Dec 21 02:42:02.648: INFO: Created: latency-svc-xppbk
Dec 21 02:42:02.692: INFO: Got endpoints: latency-svc-qcgst [749.823769ms]
Dec 21 02:42:02.699: INFO: Created: latency-svc-jhbfg
Dec 21 02:42:02.741: INFO: Got endpoints: latency-svc-5nns4 [747.549993ms]
Dec 21 02:42:02.748: INFO: Created: latency-svc-dsxfp
Dec 21 02:42:02.792: INFO: Got endpoints: latency-svc-lxnnc [749.660804ms]
Dec 21 02:42:02.800: INFO: Created: latency-svc-rt4cd
Dec 21 02:42:02.841: INFO: Got endpoints: latency-svc-t2l68 [749.290933ms]
Dec 21 02:42:02.848: INFO: Created: latency-svc-4grt4
Dec 21 02:42:02.892: INFO: Got endpoints: latency-svc-l5d7z [748.355635ms]
Dec 21 02:42:02.898: INFO: Created: latency-svc-sf6pf
Dec 21 02:42:02.942: INFO: Got endpoints: latency-svc-jkf67 [750.172711ms]
Dec 21 02:42:02.949: INFO: Created: latency-svc-cblqb
Dec 21 02:42:02.991: INFO: Got endpoints: latency-svc-fl8g8 [748.789053ms]
Dec 21 02:42:02.997: INFO: Created: latency-svc-j65xt
Dec 21 02:42:03.041: INFO: Got endpoints: latency-svc-cffcx [749.771407ms]
Dec 21 02:42:03.048: INFO: Created: latency-svc-7tf9v
Dec 21 02:42:03.093: INFO: Got endpoints: latency-svc-s65lz [752.34859ms]
Dec 21 02:42:03.099: INFO: Created: latency-svc-sm5x7
Dec 21 02:42:03.150: INFO: Got endpoints: latency-svc-z56gz [758.196854ms]
Dec 21 02:42:03.156: INFO: Created: latency-svc-srxvx
Dec 21 02:42:03.191: INFO: Got endpoints: latency-svc-c6cht [749.39258ms]
Dec 21 02:42:03.198: INFO: Created: latency-svc-4blhb
Dec 21 02:42:03.245: INFO: Got endpoints: latency-svc-t6lhm [753.224532ms]
Dec 21 02:42:03.251: INFO: Created: latency-svc-5xsk2
Dec 21 02:42:03.292: INFO: Got endpoints: latency-svc-g5bwd [749.28169ms]
Dec 21 02:42:03.298: INFO: Created: latency-svc-rwbvx
Dec 21 02:42:03.342: INFO: Got endpoints: latency-svc-g5pmj [750.09951ms]
Dec 21 02:42:03.348: INFO: Created: latency-svc-vcxdb
Dec 21 02:42:03.392: INFO: Got endpoints: latency-svc-xppbk [750.472905ms]
Dec 21 02:42:03.398: INFO: Created: latency-svc-jmbl2
Dec 21 02:42:03.442: INFO: Got endpoints: latency-svc-jhbfg [749.596127ms]
Dec 21 02:42:03.452: INFO: Created: latency-svc-6gd4r
Dec 21 02:42:03.493: INFO: Got endpoints: latency-svc-dsxfp [751.715086ms]
Dec 21 02:42:03.499: INFO: Created: latency-svc-2ccvx
Dec 21 02:42:03.546: INFO: Got endpoints: latency-svc-rt4cd [754.048087ms]
Dec 21 02:42:03.556: INFO: Created: latency-svc-f26pt
Dec 21 02:42:03.593: INFO: Got endpoints: latency-svc-4grt4 [751.516528ms]
Dec 21 02:42:03.599: INFO: Created: latency-svc-qjsd4
Dec 21 02:42:03.642: INFO: Got endpoints: latency-svc-sf6pf [749.744151ms]
Dec 21 02:42:03.648: INFO: Created: latency-svc-d85zv
Dec 21 02:42:03.693: INFO: Got endpoints: latency-svc-cblqb [750.814361ms]
Dec 21 02:42:03.700: INFO: Created: latency-svc-lrqc9
Dec 21 02:42:03.744: INFO: Got endpoints: latency-svc-j65xt [753.530148ms]
Dec 21 02:42:03.751: INFO: Created: latency-svc-zpqk9
Dec 21 02:42:03.792: INFO: Got endpoints: latency-svc-7tf9v [750.238526ms]
Dec 21 02:42:03.798: INFO: Created: latency-svc-dgv7q
Dec 21 02:42:03.846: INFO: Got endpoints: latency-svc-sm5x7 [752.420038ms]
Dec 21 02:42:03.852: INFO: Created: latency-svc-m4mzl
Dec 21 02:42:03.894: INFO: Got endpoints: latency-svc-srxvx [744.108003ms]
Dec 21 02:42:03.901: INFO: Created: latency-svc-b7gs8
Dec 21 02:42:03.948: INFO: Got endpoints: latency-svc-4blhb [756.647594ms]
Dec 21 02:42:03.957: INFO: Created: latency-svc-m8lkh
Dec 21 02:42:03.993: INFO: Got endpoints: latency-svc-5xsk2 [747.375892ms]
Dec 21 02:42:04.001: INFO: Created: latency-svc-866sj
Dec 21 02:42:04.041: INFO: Got endpoints: latency-svc-rwbvx [749.85564ms]
Dec 21 02:42:04.093: INFO: Got endpoints: latency-svc-vcxdb [750.863702ms]
Dec 21 02:42:04.142: INFO: Got endpoints: latency-svc-jmbl2 [749.990599ms]
Dec 21 02:42:04.192: INFO: Got endpoints: latency-svc-6gd4r [749.743053ms]
Dec 21 02:42:04.241: INFO: Got endpoints: latency-svc-2ccvx [748.112806ms]
Dec 21 02:42:04.291: INFO: Got endpoints: latency-svc-f26pt [745.24804ms]
Dec 21 02:42:04.342: INFO: Got endpoints: latency-svc-qjsd4 [748.916711ms]
Dec 21 02:42:04.391: INFO: Got endpoints: latency-svc-d85zv [749.63042ms]
Dec 21 02:42:04.442: INFO: Got endpoints: latency-svc-lrqc9 [749.418736ms]
Dec 21 02:42:04.491: INFO: Got endpoints: latency-svc-zpqk9 [746.918438ms]
Dec 21 02:42:04.541: INFO: Got endpoints: latency-svc-dgv7q [749.636979ms]
Dec 21 02:42:04.591: INFO: Got endpoints: latency-svc-m4mzl [744.610666ms]
Dec 21 02:42:04.642: INFO: Got endpoints: latency-svc-b7gs8 [747.675993ms]
Dec 21 02:42:04.691: INFO: Got endpoints: latency-svc-m8lkh [743.400415ms]
Dec 21 02:42:04.743: INFO: Got endpoints: latency-svc-866sj [750.007498ms]
Dec 21 02:42:04.743: INFO: Latencies: [19.5199ms 26.225403ms 29.021188ms 41.608978ms 44.45643ms 51.207714ms 59.637963ms 66.716182ms 76.666904ms 93.036272ms 101.042754ms 106.186579ms 116.899007ms 124.213236ms 129.23597ms 129.998984ms 136.308252ms 136.413899ms 138.034788ms 138.223037ms 140.496593ms 141.004586ms 141.114777ms 144.724336ms 146.433572ms 146.965748ms 147.664187ms 154.601411ms 159.095978ms 184.504738ms 245.35168ms 257.924419ms 258.108799ms 267.271929ms 268.405352ms 278.054089ms 279.805558ms 292.732395ms 302.190878ms 315.591503ms 366.627848ms 408.485494ms 454.611324ms 459.174619ms 469.706618ms 473.15528ms 491.728082ms 512.37866ms 560.22137ms 580.028025ms 629.883528ms 666.65852ms 706.110026ms 722.375189ms 733.412378ms 740.048197ms 742.08959ms 743.288357ms 743.400415ms 744.108003ms 744.12854ms 744.610666ms 744.947338ms 745.24804ms 746.310517ms 746.587977ms 746.918438ms 747.26763ms 747.375892ms 747.549993ms 747.675993ms 747.766486ms 747.924667ms 748.112806ms 748.132247ms 748.355635ms 748.51902ms 748.551039ms 748.587702ms 748.789053ms 748.821967ms 748.82888ms 748.878368ms 748.906846ms 748.916711ms 749.049272ms 749.09352ms 749.155896ms 749.227599ms 749.276565ms 749.28169ms 749.290933ms 749.313222ms 749.39258ms 749.418736ms 749.427878ms 749.456715ms 749.465361ms 749.536261ms 749.560321ms 749.596127ms 749.620483ms 749.622568ms 749.628333ms 749.629334ms 749.63042ms 749.636979ms 749.638942ms 749.660804ms 749.663917ms 749.675974ms 749.678717ms 749.704524ms 749.71514ms 749.733336ms 749.737945ms 749.738459ms 749.743053ms 749.744151ms 749.76578ms 749.771407ms 749.805062ms 749.811403ms 749.823769ms 749.850575ms 749.85564ms 749.881222ms 749.915907ms 749.917238ms 749.96082ms 749.97447ms 749.990599ms 749.995112ms 750.002996ms 750.007498ms 750.01044ms 750.02361ms 750.025858ms 750.055048ms 750.091837ms 750.093687ms 750.09951ms 750.119829ms 750.133689ms 750.150272ms 750.150812ms 750.151861ms 750.152954ms 750.154685ms 750.172711ms 750.190792ms 750.193659ms 750.217482ms 750.219516ms 750.226191ms 750.238526ms 750.26042ms 750.270495ms 750.326492ms 750.34887ms 750.376645ms 750.397708ms 750.406712ms 750.472905ms 750.482975ms 750.498079ms 750.524554ms 750.650267ms 750.671266ms 750.688919ms 750.705759ms 750.713119ms 750.727291ms 750.801786ms 750.809043ms 750.814361ms 750.835879ms 750.863702ms 750.918517ms 750.940364ms 750.992971ms 751.268595ms 751.366843ms 751.516528ms 751.544637ms 751.715086ms 751.8929ms 751.967573ms 752.152132ms 752.34859ms 752.408585ms 752.420038ms 753.224532ms 753.530148ms 753.616278ms 753.788307ms 754.048087ms 754.459586ms 756.647594ms 758.196854ms]
Dec 21 02:42:04.743: INFO: 50 %ile: 749.596127ms
Dec 21 02:42:04.743: INFO: 90 %ile: 750.992971ms
Dec 21 02:42:04.743: INFO: 99 %ile: 756.647594ms
Dec 21 02:42:04.743: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:42:04.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-2814" for this suite.
Dec 21 02:42:16.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:42:16.843: INFO: namespace svc-latency-2814 deletion completed in 12.097141938s

â€¢ [SLOW TEST:22.844 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:42:16.844: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 02:42:16.871: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:42:17.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6257" for this suite.
Dec 21 02:42:23.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:42:23.613: INFO: namespace custom-resource-definition-6257 deletion completed in 6.12816507s

â€¢ [SLOW TEST:6.769 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:42:23.613: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-d7a0fe96-abec-4d21-8709-f95fb5fda33f
STEP: Creating a pod to test consume configMaps
Dec 21 02:42:23.647: INFO: Waiting up to 5m0s for pod "pod-configmaps-81ff3e16-5cfd-47a5-86bd-be848eed2f63" in namespace "configmap-2336" to be "success or failure"
Dec 21 02:42:23.649: INFO: Pod "pod-configmaps-81ff3e16-5cfd-47a5-86bd-be848eed2f63": Phase="Pending", Reason="", readiness=false. Elapsed: 2.54247ms
Dec 21 02:42:25.652: INFO: Pod "pod-configmaps-81ff3e16-5cfd-47a5-86bd-be848eed2f63": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005637795s
STEP: Saw pod success
Dec 21 02:42:25.652: INFO: Pod "pod-configmaps-81ff3e16-5cfd-47a5-86bd-be848eed2f63" satisfied condition "success or failure"
Dec 21 02:42:25.655: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-configmaps-81ff3e16-5cfd-47a5-86bd-be848eed2f63 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 02:42:25.667: INFO: Waiting for pod pod-configmaps-81ff3e16-5cfd-47a5-86bd-be848eed2f63 to disappear
Dec 21 02:42:25.670: INFO: Pod pod-configmaps-81ff3e16-5cfd-47a5-86bd-be848eed2f63 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:42:25.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2336" for this suite.
Dec 21 02:42:31.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:42:31.771: INFO: namespace configmap-2336 deletion completed in 6.097503559s

â€¢ [SLOW TEST:8.157 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:42:31.771: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1382
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Dec 21 02:42:31.809: INFO: Found 0 stateful pods, waiting for 3
Dec 21 02:42:41.812: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 21 02:42:41.812: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 21 02:42:41.812: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec 21 02:42:41.836: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec 21 02:42:51.863: INFO: Updating stateful set ss2
Dec 21 02:42:51.883: INFO: Waiting for Pod statefulset-1382/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 21 02:43:01.892: INFO: Waiting for Pod statefulset-1382/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Dec 21 02:43:12.037: INFO: Found 2 stateful pods, waiting for 3
Dec 21 02:43:22.041: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 21 02:43:22.042: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 21 02:43:22.042: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec 21 02:43:22.067: INFO: Updating stateful set ss2
Dec 21 02:43:22.087: INFO: Waiting for Pod statefulset-1382/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 21 02:43:32.110: INFO: Updating stateful set ss2
Dec 21 02:43:32.120: INFO: Waiting for StatefulSet statefulset-1382/ss2 to complete update
Dec 21 02:43:32.120: INFO: Waiting for Pod statefulset-1382/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 21 02:43:42.126: INFO: Deleting all statefulset in ns statefulset-1382
Dec 21 02:43:42.128: INFO: Scaling statefulset ss2 to 0
Dec 21 02:44:12.140: INFO: Waiting for statefulset status.replicas updated to 0
Dec 21 02:44:12.143: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:44:12.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1382" for this suite.
Dec 21 02:44:18.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:44:18.258: INFO: namespace statefulset-1382 deletion completed in 6.099542005s

â€¢ [SLOW TEST:106.487 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:44:18.259: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Dec 21 02:44:18.286: INFO: namespace kubectl-6309
Dec 21 02:44:18.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 create -f - --namespace=kubectl-6309'
Dec 21 02:44:19.384: INFO: stderr: ""
Dec 21 02:44:19.384: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 21 02:44:20.388: INFO: Selector matched 1 pods for map[app:redis]
Dec 21 02:44:20.388: INFO: Found 0 / 1
Dec 21 02:44:21.388: INFO: Selector matched 1 pods for map[app:redis]
Dec 21 02:44:21.388: INFO: Found 1 / 1
Dec 21 02:44:21.388: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 21 02:44:21.391: INFO: Selector matched 1 pods for map[app:redis]
Dec 21 02:44:21.391: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 21 02:44:21.391: INFO: wait on redis-master startup in kubectl-6309 
Dec 21 02:44:21.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 logs redis-master-tqqdr redis-master --namespace=kubectl-6309'
Dec 21 02:44:21.490: INFO: stderr: ""
Dec 21 02:44:21.490: INFO: stdout: "1:C 21 Dec 2019 02:44:20.362 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 21 Dec 2019 02:44:20.362 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 21 Dec 2019 02:44:20.362 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 21 Dec 2019 02:44:20.364 * Running mode=standalone, port=6379.\n1:M 21 Dec 2019 02:44:20.364 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Dec 2019 02:44:20.364 # Server initialized\n1:M 21 Dec 2019 02:44:20.364 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Dec 2019 02:44:20.364 * Ready to accept connections\n"
STEP: exposing RC
Dec 21 02:44:21.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-6309'
Dec 21 02:44:21.587: INFO: stderr: ""
Dec 21 02:44:21.587: INFO: stdout: "service/rm2 exposed\n"
Dec 21 02:44:21.590: INFO: Service rm2 in namespace kubectl-6309 found.
STEP: exposing service
Dec 21 02:44:23.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-6309'
Dec 21 02:44:23.684: INFO: stderr: ""
Dec 21 02:44:23.685: INFO: stdout: "service/rm3 exposed\n"
Dec 21 02:44:23.690: INFO: Service rm3 in namespace kubectl-6309 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:44:25.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6309" for this suite.
Dec 21 02:44:53.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:44:53.804: INFO: namespace kubectl-6309 deletion completed in 28.105151765s

â€¢ [SLOW TEST:35.545 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:44:53.804: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-4ee924df-e91d-47a1-80e1-588c6312651e
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-4ee924df-e91d-47a1-80e1-588c6312651e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:44:57.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6242" for this suite.
Dec 21 02:45:09.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:45:09.979: INFO: namespace configmap-6242 deletion completed in 12.101419107s

â€¢ [SLOW TEST:16.175 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:45:09.980: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 21 02:45:10.013: INFO: Waiting up to 5m0s for pod "downward-api-12ee4493-cded-48ae-b02d-d5fa8d259c2a" in namespace "downward-api-2415" to be "success or failure"
Dec 21 02:45:10.015: INFO: Pod "downward-api-12ee4493-cded-48ae-b02d-d5fa8d259c2a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.679149ms
Dec 21 02:45:12.019: INFO: Pod "downward-api-12ee4493-cded-48ae-b02d-d5fa8d259c2a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006309339s
STEP: Saw pod success
Dec 21 02:45:12.019: INFO: Pod "downward-api-12ee4493-cded-48ae-b02d-d5fa8d259c2a" satisfied condition "success or failure"
Dec 21 02:45:12.022: INFO: Trying to get logs from node ip-172-31-29-141 pod downward-api-12ee4493-cded-48ae-b02d-d5fa8d259c2a container dapi-container: <nil>
STEP: delete the pod
Dec 21 02:45:12.041: INFO: Waiting for pod downward-api-12ee4493-cded-48ae-b02d-d5fa8d259c2a to disappear
Dec 21 02:45:12.044: INFO: Pod downward-api-12ee4493-cded-48ae-b02d-d5fa8d259c2a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:45:12.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2415" for this suite.
Dec 21 02:45:18.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:45:18.142: INFO: namespace downward-api-2415 deletion completed in 6.095633427s

â€¢ [SLOW TEST:8.162 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:45:18.143: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Dec 21 02:45:18.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 create -f - --namespace=kubectl-1004'
Dec 21 02:45:18.331: INFO: stderr: ""
Dec 21 02:45:18.331: INFO: stdout: "pod/pause created\n"
Dec 21 02:45:18.331: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec 21 02:45:18.331: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-1004" to be "running and ready"
Dec 21 02:45:18.334: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.478879ms
Dec 21 02:45:20.338: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.006900245s
Dec 21 02:45:20.338: INFO: Pod "pause" satisfied condition "running and ready"
Dec 21 02:45:20.338: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Dec 21 02:45:20.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 label pods pause testing-label=testing-label-value --namespace=kubectl-1004'
Dec 21 02:45:20.430: INFO: stderr: ""
Dec 21 02:45:20.430: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec 21 02:45:20.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pod pause -L testing-label --namespace=kubectl-1004'
Dec 21 02:45:20.506: INFO: stderr: ""
Dec 21 02:45:20.506: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec 21 02:45:20.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 label pods pause testing-label- --namespace=kubectl-1004'
Dec 21 02:45:20.587: INFO: stderr: ""
Dec 21 02:45:20.587: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec 21 02:45:20.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pod pause -L testing-label --namespace=kubectl-1004'
Dec 21 02:45:20.667: INFO: stderr: ""
Dec 21 02:45:20.667: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Dec 21 02:45:20.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 delete --grace-period=0 --force -f - --namespace=kubectl-1004'
Dec 21 02:45:20.751: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 21 02:45:20.752: INFO: stdout: "pod \"pause\" force deleted\n"
Dec 21 02:45:20.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get rc,svc -l name=pause --no-headers --namespace=kubectl-1004'
Dec 21 02:45:20.834: INFO: stderr: "No resources found in kubectl-1004 namespace.\n"
Dec 21 02:45:20.834: INFO: stdout: ""
Dec 21 02:45:20.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 get pods -l name=pause --namespace=kubectl-1004 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 21 02:45:20.910: INFO: stderr: ""
Dec 21 02:45:20.910: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:45:20.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1004" for this suite.
Dec 21 02:45:26.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:45:27.022: INFO: namespace kubectl-1004 deletion completed in 6.109324318s

â€¢ [SLOW TEST:8.880 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:45:27.023: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 02:45:27.466: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 21 02:45:29.474: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712493127, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712493127, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712493127, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712493127, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 02:45:32.484: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:45:46.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8746" for this suite.
Dec 21 02:45:52.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:45:52.742: INFO: namespace webhook-8746 deletion completed in 6.094035922s
STEP: Destroying namespace "webhook-8746-markers" for this suite.
Dec 21 02:45:58.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:45:58.837: INFO: namespace webhook-8746-markers deletion completed in 6.094842558s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:31.826 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:45:58.850: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:45:58.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6495" for this suite.
Dec 21 02:46:04.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:46:05.071: INFO: namespace kubelet-test-6495 deletion completed in 6.09561515s

â€¢ [SLOW TEST:6.221 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:46:05.071: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-c5k7
STEP: Creating a pod to test atomic-volume-subpath
Dec 21 02:46:05.106: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-c5k7" in namespace "subpath-2427" to be "success or failure"
Dec 21 02:46:05.109: INFO: Pod "pod-subpath-test-downwardapi-c5k7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.215366ms
Dec 21 02:46:07.112: INFO: Pod "pod-subpath-test-downwardapi-c5k7": Phase="Running", Reason="", readiness=true. Elapsed: 2.006634311s
Dec 21 02:46:09.116: INFO: Pod "pod-subpath-test-downwardapi-c5k7": Phase="Running", Reason="", readiness=true. Elapsed: 4.009786996s
Dec 21 02:46:11.119: INFO: Pod "pod-subpath-test-downwardapi-c5k7": Phase="Running", Reason="", readiness=true. Elapsed: 6.012809647s
Dec 21 02:46:13.122: INFO: Pod "pod-subpath-test-downwardapi-c5k7": Phase="Running", Reason="", readiness=true. Elapsed: 8.016166573s
Dec 21 02:46:15.125: INFO: Pod "pod-subpath-test-downwardapi-c5k7": Phase="Running", Reason="", readiness=true. Elapsed: 10.018901632s
Dec 21 02:46:17.128: INFO: Pod "pod-subpath-test-downwardapi-c5k7": Phase="Running", Reason="", readiness=true. Elapsed: 12.022337401s
Dec 21 02:46:19.131: INFO: Pod "pod-subpath-test-downwardapi-c5k7": Phase="Running", Reason="", readiness=true. Elapsed: 14.025583083s
Dec 21 02:46:21.135: INFO: Pod "pod-subpath-test-downwardapi-c5k7": Phase="Running", Reason="", readiness=true. Elapsed: 16.028891937s
Dec 21 02:46:23.138: INFO: Pod "pod-subpath-test-downwardapi-c5k7": Phase="Running", Reason="", readiness=true. Elapsed: 18.032171527s
Dec 21 02:46:25.141: INFO: Pod "pod-subpath-test-downwardapi-c5k7": Phase="Running", Reason="", readiness=true. Elapsed: 20.035431443s
Dec 21 02:46:27.144: INFO: Pod "pod-subpath-test-downwardapi-c5k7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.03856551s
STEP: Saw pod success
Dec 21 02:46:27.144: INFO: Pod "pod-subpath-test-downwardapi-c5k7" satisfied condition "success or failure"
Dec 21 02:46:27.147: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-subpath-test-downwardapi-c5k7 container test-container-subpath-downwardapi-c5k7: <nil>
STEP: delete the pod
Dec 21 02:46:27.159: INFO: Waiting for pod pod-subpath-test-downwardapi-c5k7 to disappear
Dec 21 02:46:27.162: INFO: Pod pod-subpath-test-downwardapi-c5k7 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-c5k7
Dec 21 02:46:27.162: INFO: Deleting pod "pod-subpath-test-downwardapi-c5k7" in namespace "subpath-2427"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:46:27.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2427" for this suite.
Dec 21 02:46:33.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:46:33.261: INFO: namespace subpath-2427 deletion completed in 6.093181284s

â€¢ [SLOW TEST:28.190 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:46:33.262: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 21 02:46:33.292: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9aca55c6-e0ef-46a4-93ff-632e902e8e60" in namespace "projected-7014" to be "success or failure"
Dec 21 02:46:33.295: INFO: Pod "downwardapi-volume-9aca55c6-e0ef-46a4-93ff-632e902e8e60": Phase="Pending", Reason="", readiness=false. Elapsed: 2.906399ms
Dec 21 02:46:35.298: INFO: Pod "downwardapi-volume-9aca55c6-e0ef-46a4-93ff-632e902e8e60": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006161265s
STEP: Saw pod success
Dec 21 02:46:35.298: INFO: Pod "downwardapi-volume-9aca55c6-e0ef-46a4-93ff-632e902e8e60" satisfied condition "success or failure"
Dec 21 02:46:35.301: INFO: Trying to get logs from node ip-172-31-29-169 pod downwardapi-volume-9aca55c6-e0ef-46a4-93ff-632e902e8e60 container client-container: <nil>
STEP: delete the pod
Dec 21 02:46:35.317: INFO: Waiting for pod downwardapi-volume-9aca55c6-e0ef-46a4-93ff-632e902e8e60 to disappear
Dec 21 02:46:35.323: INFO: Pod downwardapi-volume-9aca55c6-e0ef-46a4-93ff-632e902e8e60 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:46:35.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7014" for this suite.
Dec 21 02:46:41.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:46:41.417: INFO: namespace projected-7014 deletion completed in 6.091590058s

â€¢ [SLOW TEST:8.156 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:46:41.418: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 02:46:41.444: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Dec 21 02:46:43.467: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:46:44.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-978" for this suite.
Dec 21 02:46:50.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:46:50.571: INFO: namespace replication-controller-978 deletion completed in 6.095655507s

â€¢ [SLOW TEST:9.154 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:46:50.571: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Dec 21 02:46:53.112: INFO: Successfully updated pod "adopt-release-blxqb"
STEP: Checking that the Job readopts the Pod
Dec 21 02:46:53.112: INFO: Waiting up to 15m0s for pod "adopt-release-blxqb" in namespace "job-4175" to be "adopted"
Dec 21 02:46:53.115: INFO: Pod "adopt-release-blxqb": Phase="Running", Reason="", readiness=true. Elapsed: 3.952584ms
Dec 21 02:46:55.119: INFO: Pod "adopt-release-blxqb": Phase="Running", Reason="", readiness=true. Elapsed: 2.00728612s
Dec 21 02:46:55.119: INFO: Pod "adopt-release-blxqb" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Dec 21 02:46:55.626: INFO: Successfully updated pod "adopt-release-blxqb"
STEP: Checking that the Job releases the Pod
Dec 21 02:46:55.626: INFO: Waiting up to 15m0s for pod "adopt-release-blxqb" in namespace "job-4175" to be "released"
Dec 21 02:46:55.629: INFO: Pod "adopt-release-blxqb": Phase="Running", Reason="", readiness=true. Elapsed: 3.5327ms
Dec 21 02:46:57.633: INFO: Pod "adopt-release-blxqb": Phase="Running", Reason="", readiness=true. Elapsed: 2.006903675s
Dec 21 02:46:57.633: INFO: Pod "adopt-release-blxqb" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:46:57.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4175" for this suite.
Dec 21 02:47:45.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:47:45.751: INFO: namespace job-4175 deletion completed in 48.115282586s

â€¢ [SLOW TEST:55.180 seconds]
[sig-apps] Job
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:47:45.752: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 21 02:47:50.322: INFO: Successfully updated pod "annotationupdatec45e5091-1198-4937-a1d0-a36ee309d4e5"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:47:52.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1424" for this suite.
Dec 21 02:48:16.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:48:16.435: INFO: namespace downward-api-1424 deletion completed in 24.092827592s

â€¢ [SLOW TEST:30.683 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:48:16.436: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 21 02:48:16.468: INFO: Waiting up to 5m0s for pod "pod-3feaf2e9-a96e-4fe8-abc3-d9b2d2c9ab1e" in namespace "emptydir-8356" to be "success or failure"
Dec 21 02:48:16.472: INFO: Pod "pod-3feaf2e9-a96e-4fe8-abc3-d9b2d2c9ab1e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.943459ms
Dec 21 02:48:18.475: INFO: Pod "pod-3feaf2e9-a96e-4fe8-abc3-d9b2d2c9ab1e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007106058s
STEP: Saw pod success
Dec 21 02:48:18.475: INFO: Pod "pod-3feaf2e9-a96e-4fe8-abc3-d9b2d2c9ab1e" satisfied condition "success or failure"
Dec 21 02:48:18.477: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-3feaf2e9-a96e-4fe8-abc3-d9b2d2c9ab1e container test-container: <nil>
STEP: delete the pod
Dec 21 02:48:18.495: INFO: Waiting for pod pod-3feaf2e9-a96e-4fe8-abc3-d9b2d2c9ab1e to disappear
Dec 21 02:48:18.499: INFO: Pod pod-3feaf2e9-a96e-4fe8-abc3-d9b2d2c9ab1e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:48:18.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8356" for this suite.
Dec 21 02:48:24.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:48:24.607: INFO: namespace emptydir-8356 deletion completed in 6.104494223s

â€¢ [SLOW TEST:8.171 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:48:24.607: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Dec 21 02:48:24.632: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:48:40.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-161" for this suite.
Dec 21 02:48:46.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:48:46.390: INFO: namespace crd-publish-openapi-161 deletion completed in 6.11606718s

â€¢ [SLOW TEST:21.783 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:48:46.390: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-7383
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-7383
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7383
Dec 21 02:48:46.429: INFO: Found 0 stateful pods, waiting for 1
Dec 21 02:48:56.432: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec 21 02:48:56.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 21 02:48:56.588: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 21 02:48:56.588: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 21 02:48:56.588: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 21 02:48:56.593: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 21 02:49:06.597: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 21 02:49:06.597: INFO: Waiting for statefulset status.replicas updated to 0
Dec 21 02:49:06.609: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec 21 02:49:06.609: INFO: ss-0  ip-172-31-29-169  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:46 +0000 UTC  }]
Dec 21 02:49:06.609: INFO: 
Dec 21 02:49:06.609: INFO: StatefulSet ss has not reached scale 3, at 1
Dec 21 02:49:07.613: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99536068s
Dec 21 02:49:08.618: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991713268s
Dec 21 02:49:09.622: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.986780145s
Dec 21 02:49:10.625: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.982928326s
Dec 21 02:49:11.629: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.979292916s
Dec 21 02:49:12.634: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.975542547s
Dec 21 02:49:13.638: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.970631248s
Dec 21 02:49:14.641: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.966842701s
Dec 21 02:49:15.645: INFO: Verifying statefulset ss doesn't scale past 3 for another 963.292195ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7383
Dec 21 02:49:16.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:49:16.795: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 21 02:49:16.795: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 21 02:49:16.795: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 21 02:49:16.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:49:16.941: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 21 02:49:16.941: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 21 02:49:16.941: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 21 02:49:16.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:49:17.093: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 21 02:49:17.093: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 21 02:49:17.093: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 21 02:49:17.096: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 21 02:49:17.096: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 21 02:49:17.096: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec 21 02:49:17.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 21 02:49:17.270: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 21 02:49:17.270: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 21 02:49:17.270: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 21 02:49:17.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 21 02:49:17.428: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 21 02:49:17.429: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 21 02:49:17.429: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 21 02:49:17.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 21 02:49:17.575: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 21 02:49:17.575: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 21 02:49:17.575: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 21 02:49:17.575: INFO: Waiting for statefulset status.replicas updated to 0
Dec 21 02:49:17.578: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec 21 02:49:27.584: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 21 02:49:27.584: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 21 02:49:27.584: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 21 02:49:27.594: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec 21 02:49:27.594: INFO: ss-2  ip-172-31-29-141  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:06 +0000 UTC  }]
Dec 21 02:49:27.594: INFO: ss-1  ip-172-31-25-252  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:06 +0000 UTC  }]
Dec 21 02:49:27.594: INFO: ss-0  ip-172-31-29-169  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:46 +0000 UTC  }]
Dec 21 02:49:27.594: INFO: 
Dec 21 02:49:27.594: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 21 02:49:28.598: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec 21 02:49:28.598: INFO: ss-2  ip-172-31-29-141  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:06 +0000 UTC  }]
Dec 21 02:49:28.598: INFO: ss-0  ip-172-31-29-169  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:46 +0000 UTC  }]
Dec 21 02:49:28.598: INFO: ss-1  ip-172-31-25-252  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:06 +0000 UTC  }]
Dec 21 02:49:28.598: INFO: 
Dec 21 02:49:28.598: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 21 02:49:29.602: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec 21 02:49:29.602: INFO: ss-0  ip-172-31-29-169  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:46 +0000 UTC  }]
Dec 21 02:49:29.602: INFO: ss-1  ip-172-31-25-252  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:06 +0000 UTC  }]
Dec 21 02:49:29.602: INFO: ss-2  ip-172-31-29-141  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:06 +0000 UTC  }]
Dec 21 02:49:29.602: INFO: 
Dec 21 02:49:29.602: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 21 02:49:30.606: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec 21 02:49:30.606: INFO: ss-0  ip-172-31-29-169  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:46 +0000 UTC  }]
Dec 21 02:49:30.606: INFO: ss-1  ip-172-31-25-252  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:06 +0000 UTC  }]
Dec 21 02:49:30.606: INFO: 
Dec 21 02:49:30.606: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 21 02:49:31.609: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec 21 02:49:31.609: INFO: ss-0  ip-172-31-29-169  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:46 +0000 UTC  }]
Dec 21 02:49:31.609: INFO: ss-1  ip-172-31-25-252  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:06 +0000 UTC  }]
Dec 21 02:49:31.610: INFO: 
Dec 21 02:49:31.610: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 21 02:49:32.613: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec 21 02:49:32.613: INFO: ss-0  ip-172-31-29-169  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:46 +0000 UTC  }]
Dec 21 02:49:32.613: INFO: 
Dec 21 02:49:32.613: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 21 02:49:33.616: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec 21 02:49:33.617: INFO: ss-0  ip-172-31-29-169  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:46 +0000 UTC  }]
Dec 21 02:49:33.617: INFO: 
Dec 21 02:49:33.617: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 21 02:49:34.620: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec 21 02:49:34.620: INFO: ss-0  ip-172-31-29-169  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:46 +0000 UTC  }]
Dec 21 02:49:34.620: INFO: 
Dec 21 02:49:34.620: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 21 02:49:35.624: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec 21 02:49:35.624: INFO: ss-0  ip-172-31-29-169  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:46 +0000 UTC  }]
Dec 21 02:49:35.624: INFO: 
Dec 21 02:49:35.624: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 21 02:49:36.627: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec 21 02:49:36.627: INFO: ss-0  ip-172-31-29-169  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:49:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-21 02:48:46 +0000 UTC  }]
Dec 21 02:49:36.627: INFO: 
Dec 21 02:49:36.627: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7383
Dec 21 02:49:37.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:49:37.724: INFO: rc: 1
Dec 21 02:49:37.724: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  error: unable to upgrade connection: container not found ("webserver")
 [] <nil> 0xc003d430e0 exit status 1 <nil> <nil> true [0xc000781760 0xc0007817c0 0xc000781890] [0xc000781760 0xc0007817c0 0xc000781890] [0xc0007817b8 0xc000781888] [0x10efe30 0x10efe30] 0xc003a24fc0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Dec 21 02:49:47.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:49:47.803: INFO: rc: 1
Dec 21 02:49:47.803: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0040c05a0 exit status 1 <nil> <nil> true [0xc0036f46b8 0xc0036f46d0 0xc0036f46e8] [0xc0036f46b8 0xc0036f46d0 0xc0036f46e8] [0xc0036f46c8 0xc0036f46e0] [0x10efe30 0x10efe30] 0xc0043e2000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:49:57.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:49:57.879: INFO: rc: 1
Dec 21 02:49:57.879: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003d43500 exit status 1 <nil> <nil> true [0xc0007818a8 0xc000781910 0xc000781988] [0xc0007818a8 0xc000781910 0xc000781988] [0xc000781900 0xc000781958] [0x10efe30 0x10efe30] 0xc003a25320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:50:07.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:50:07.957: INFO: rc: 1
Dec 21 02:50:07.957: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003d439b0 exit status 1 <nil> <nil> true [0xc000781a00 0xc000781ab0 0xc000781bc8] [0xc000781a00 0xc000781ab0 0xc000781bc8] [0xc000781a68 0xc000781b58] [0x10efe30 0x10efe30] 0xc003a25680 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:50:17.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:50:18.037: INFO: rc: 1
Dec 21 02:50:18.037: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0040c09c0 exit status 1 <nil> <nil> true [0xc0036f46f0 0xc0036f4708 0xc0036f4720] [0xc0036f46f0 0xc0036f4708 0xc0036f4720] [0xc0036f4700 0xc0036f4718] [0x10efe30 0x10efe30] 0xc0043e2420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:50:28.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:50:28.125: INFO: rc: 1
Dec 21 02:50:28.125: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0040c0db0 exit status 1 <nil> <nil> true [0xc0036f4728 0xc0036f4740 0xc0036f4758] [0xc0036f4728 0xc0036f4740 0xc0036f4758] [0xc0036f4738 0xc0036f4750] [0x10efe30 0x10efe30] 0xc0043e27e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:50:38.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:50:38.219: INFO: rc: 1
Dec 21 02:50:38.219: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003d43dd0 exit status 1 <nil> <nil> true [0xc000781be0 0xc000781c78 0xc000781d60] [0xc000781be0 0xc000781c78 0xc000781d60] [0xc000781c60 0xc000781d08] [0x10efe30 0x10efe30] 0xc003a25b00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:50:48.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:50:48.297: INFO: rc: 1
Dec 21 02:50:48.297: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0037ac330 exit status 1 <nil> <nil> true [0xc001bbc010 0xc001bbc0a8 0xc001bbc270] [0xc001bbc010 0xc001bbc0a8 0xc001bbc270] [0xc001bbc030 0xc001bbc1b0] [0x10efe30 0x10efe30] 0xc001c242a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:50:58.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:50:58.376: INFO: rc: 1
Dec 21 02:50:58.376: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc005bf8330 exit status 1 <nil> <nil> true [0xc001eb8000 0xc001eb8018 0xc001eb8030] [0xc001eb8000 0xc001eb8018 0xc001eb8030] [0xc001eb8010 0xc001eb8028] [0x10efe30 0x10efe30] 0xc0031ea4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:51:08.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:51:08.454: INFO: rc: 1
Dec 21 02:51:08.454: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0037ac6c0 exit status 1 <nil> <nil> true [0xc001bbc2b0 0xc001bbc360 0xc001bbc3e0] [0xc001bbc2b0 0xc001bbc360 0xc001bbc3e0] [0xc001bbc320 0xc001bbc3c8] [0x10efe30 0x10efe30] 0xc001c24600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:51:18.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:51:18.532: INFO: rc: 1
Dec 21 02:51:18.532: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc005bf86c0 exit status 1 <nil> <nil> true [0xc001eb8038 0xc001eb8050 0xc001eb8070] [0xc001eb8038 0xc001eb8050 0xc001eb8070] [0xc001eb8048 0xc001eb8068] [0x10efe30 0x10efe30] 0xc0031eaba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:51:28.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:51:28.610: INFO: rc: 1
Dec 21 02:51:28.610: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc005bf8a20 exit status 1 <nil> <nil> true [0xc001eb8078 0xc001eb8090 0xc001eb80a8] [0xc001eb8078 0xc001eb8090 0xc001eb80a8] [0xc001eb8088 0xc001eb80a0] [0x10efe30 0x10efe30] 0xc0031eb020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:51:38.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:51:38.686: INFO: rc: 1
Dec 21 02:51:38.686: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc005bf8d80 exit status 1 <nil> <nil> true [0xc001eb80b0 0xc001eb80c8 0xc001eb80e0] [0xc001eb80b0 0xc001eb80c8 0xc001eb80e0] [0xc001eb80c0 0xc001eb80d8] [0x10efe30 0x10efe30] 0xc0031eb740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:51:48.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:51:48.763: INFO: rc: 1
Dec 21 02:51:48.763: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0037acae0 exit status 1 <nil> <nil> true [0xc001bbc490 0xc001bbc5a0 0xc001bbc640] [0xc001bbc490 0xc001bbc5a0 0xc001bbc640] [0xc001bbc530 0xc001bbc5f8] [0x10efe30 0x10efe30] 0xc001c24960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:51:58.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:51:58.838: INFO: rc: 1
Dec 21 02:51:58.838: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc005bf9110 exit status 1 <nil> <nil> true [0xc001eb80e8 0xc001eb8100 0xc001eb8118] [0xc001eb80e8 0xc001eb8100 0xc001eb8118] [0xc001eb80f8 0xc001eb8110] [0x10efe30 0x10efe30] 0xc0031ebaa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:52:08.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:52:08.916: INFO: rc: 1
Dec 21 02:52:08.916: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0037acea0 exit status 1 <nil> <nil> true [0xc001bbc698 0xc001bbc7b0 0xc001bbc8d0] [0xc001bbc698 0xc001bbc7b0 0xc001bbc8d0] [0xc001bbc6e0 0xc001bbc850] [0x10efe30 0x10efe30] 0xc001c24e40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:52:18.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:52:18.995: INFO: rc: 1
Dec 21 02:52:18.995: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc005bf94d0 exit status 1 <nil> <nil> true [0xc001eb8120 0xc001eb8138 0xc001eb8150] [0xc001eb8120 0xc001eb8138 0xc001eb8150] [0xc001eb8130 0xc001eb8148] [0x10efe30 0x10efe30] 0xc0031ebe00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:52:28.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:52:29.072: INFO: rc: 1
Dec 21 02:52:29.072: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0037ad230 exit status 1 <nil> <nil> true [0xc001bbc900 0xc001bbc9d8 0xc001bbcae0] [0xc001bbc900 0xc001bbc9d8 0xc001bbcae0] [0xc001bbc980 0xc001bbcab0] [0x10efe30 0x10efe30] 0xc001c251a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:52:39.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:52:39.151: INFO: rc: 1
Dec 21 02:52:39.151: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc005bf9890 exit status 1 <nil> <nil> true [0xc001eb8158 0xc001eb8170 0xc001eb8188] [0xc001eb8158 0xc001eb8170 0xc001eb8188] [0xc001eb8168 0xc001eb8180] [0x10efe30 0x10efe30] 0xc002538240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:52:49.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:52:49.227: INFO: rc: 1
Dec 21 02:52:49.227: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0037ac360 exit status 1 <nil> <nil> true [0xc001bbc010 0xc001bbc0a8 0xc001bbc270] [0xc001bbc010 0xc001bbc0a8 0xc001bbc270] [0xc001bbc030 0xc001bbc1b0] [0x10efe30 0x10efe30] 0xc0031ea480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:52:59.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:52:59.302: INFO: rc: 1
Dec 21 02:52:59.302: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0037ac6f0 exit status 1 <nil> <nil> true [0xc001bbc2b0 0xc001bbc360 0xc001bbc3e0] [0xc001bbc2b0 0xc001bbc360 0xc001bbc3e0] [0xc001bbc320 0xc001bbc3c8] [0x10efe30 0x10efe30] 0xc0031eaae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:53:09.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:53:09.380: INFO: rc: 1
Dec 21 02:53:09.380: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0037aca50 exit status 1 <nil> <nil> true [0xc001bbc490 0xc001bbc5a0 0xc001bbc640] [0xc001bbc490 0xc001bbc5a0 0xc001bbc640] [0xc001bbc530 0xc001bbc5f8] [0x10efe30 0x10efe30] 0xc0031eaf60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:53:19.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:53:19.458: INFO: rc: 1
Dec 21 02:53:19.458: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc005bf83c0 exit status 1 <nil> <nil> true [0xc001eb8000 0xc001eb8018 0xc001eb8030] [0xc001eb8000 0xc001eb8018 0xc001eb8030] [0xc001eb8010 0xc001eb8028] [0x10efe30 0x10efe30] 0xc001c242a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:53:29.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:53:29.534: INFO: rc: 1
Dec 21 02:53:29.534: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc005bf8750 exit status 1 <nil> <nil> true [0xc001eb8038 0xc001eb8050 0xc001eb8070] [0xc001eb8038 0xc001eb8050 0xc001eb8070] [0xc001eb8048 0xc001eb8068] [0x10efe30 0x10efe30] 0xc001c24600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:53:39.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:53:39.611: INFO: rc: 1
Dec 21 02:53:39.611: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0037ace40 exit status 1 <nil> <nil> true [0xc001bbc698 0xc001bbc7b0 0xc001bbc8d0] [0xc001bbc698 0xc001bbc7b0 0xc001bbc8d0] [0xc001bbc6e0 0xc001bbc850] [0x10efe30 0x10efe30] 0xc0031eb680 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:53:49.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:53:49.686: INFO: rc: 1
Dec 21 02:53:49.687: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc005bf8b10 exit status 1 <nil> <nil> true [0xc001eb8078 0xc001eb8090 0xc001eb80a8] [0xc001eb8078 0xc001eb8090 0xc001eb80a8] [0xc001eb8088 0xc001eb80a0] [0x10efe30 0x10efe30] 0xc001c24960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:53:59.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:53:59.761: INFO: rc: 1
Dec 21 02:53:59.761: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc005bf8ea0 exit status 1 <nil> <nil> true [0xc001eb80b0 0xc001eb80c8 0xc001eb80e0] [0xc001eb80b0 0xc001eb80c8 0xc001eb80e0] [0xc001eb80c0 0xc001eb80d8] [0x10efe30 0x10efe30] 0xc001c24e40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:54:09.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:54:09.839: INFO: rc: 1
Dec 21 02:54:09.839: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0037ad290 exit status 1 <nil> <nil> true [0xc001bbc900 0xc001bbc9d8 0xc001bbcae0] [0xc001bbc900 0xc001bbc9d8 0xc001bbcae0] [0xc001bbc980 0xc001bbcab0] [0x10efe30 0x10efe30] 0xc0031eba40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:54:19.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:54:20.654: INFO: rc: 1
Dec 21 02:54:20.654: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0037ad620 exit status 1 <nil> <nil> true [0xc001bbcb48 0xc001bbcbd0 0xc001bbcc28] [0xc001bbcb48 0xc001bbcbd0 0xc001bbcc28] [0xc001bbcbc0 0xc001bbcc18] [0x10efe30 0x10efe30] 0xc0031ebda0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:54:30.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:54:30.730: INFO: rc: 1
Dec 21 02:54:30.730: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc005bf9230 exit status 1 <nil> <nil> true [0xc001eb80e8 0xc001eb8100 0xc001eb8118] [0xc001eb80e8 0xc001eb8100 0xc001eb8118] [0xc001eb80f8 0xc001eb8110] [0x10efe30 0x10efe30] 0xc001c251a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 21 02:54:40.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=statefulset-7383 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 02:54:40.807: INFO: rc: 1
Dec 21 02:54:40.807: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: 
Dec 21 02:54:40.807: INFO: Scaling statefulset ss to 0
Dec 21 02:54:40.817: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 21 02:54:40.819: INFO: Deleting all statefulset in ns statefulset-7383
Dec 21 02:54:40.821: INFO: Scaling statefulset ss to 0
Dec 21 02:54:40.828: INFO: Waiting for statefulset status.replicas updated to 0
Dec 21 02:54:40.830: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:54:40.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7383" for this suite.
Dec 21 02:54:46.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:54:46.940: INFO: namespace statefulset-7383 deletion completed in 6.098868273s

â€¢ [SLOW TEST:360.550 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:54:46.941: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Dec 21 02:54:46.970: INFO: Waiting up to 5m0s for pod "client-containers-537e8774-918a-4945-ae0f-334188e31809" in namespace "containers-9883" to be "success or failure"
Dec 21 02:54:46.972: INFO: Pod "client-containers-537e8774-918a-4945-ae0f-334188e31809": Phase="Pending", Reason="", readiness=false. Elapsed: 2.710896ms
Dec 21 02:54:48.978: INFO: Pod "client-containers-537e8774-918a-4945-ae0f-334188e31809": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00848991s
STEP: Saw pod success
Dec 21 02:54:48.978: INFO: Pod "client-containers-537e8774-918a-4945-ae0f-334188e31809" satisfied condition "success or failure"
Dec 21 02:54:48.980: INFO: Trying to get logs from node ip-172-31-29-169 pod client-containers-537e8774-918a-4945-ae0f-334188e31809 container test-container: <nil>
STEP: delete the pod
Dec 21 02:54:48.998: INFO: Waiting for pod client-containers-537e8774-918a-4945-ae0f-334188e31809 to disappear
Dec 21 02:54:49.003: INFO: Pod client-containers-537e8774-918a-4945-ae0f-334188e31809 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:54:49.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9883" for this suite.
Dec 21 02:54:55.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:54:55.096: INFO: namespace containers-9883 deletion completed in 6.091021249s

â€¢ [SLOW TEST:8.156 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:54:55.098: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 02:54:55.131: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec 21 02:55:00.134: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 21 02:55:00.135: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 21 02:55:00.146: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-465 /apis/apps/v1/namespaces/deployment-465/deployments/test-cleanup-deployment 653ecba8-2b67-450d-8ecc-c4cc0d1389e9 20262 1 2019-12-21 02:55:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00360e048 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Dec 21 02:55:00.150: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Dec 21 02:55:00.150: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Dec 21 02:55:00.150: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-465 /apis/apps/v1/namespaces/deployment-465/replicasets/test-cleanup-controller 867f33f6-8537-40f8-b338-448783e66984 20263 1 2019-12-21 02:54:55 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 653ecba8-2b67-450d-8ecc-c4cc0d1389e9 0xc007556287 0xc007556288}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0075562e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 21 02:55:00.160: INFO: Pod "test-cleanup-controller-7pcjb" is available:
&Pod{ObjectMeta:{test-cleanup-controller-7pcjb test-cleanup-controller- deployment-465 /api/v1/namespaces/deployment-465/pods/test-cleanup-controller-7pcjb 2965e941-c301-4758-8629-0c82be79ad84 20255 0 2019-12-21 02:54:55 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller 867f33f6-8537-40f8-b338-448783e66984 0xc00360e4b7 0xc00360e4b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6wf85,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6wf85,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6wf85,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-169,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:54:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:54:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:54:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-21 02:54:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.169,PodIP:10.42.1.226,StartTime:2019-12-21 02:54:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-21 02:54:56 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://125f45f3eb014399da56d3763d789aed0ef6e641d42c618d9b18c60238d0b263,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.226,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:55:00.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-465" for this suite.
Dec 21 02:55:06.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:55:06.269: INFO: namespace deployment-465 deletion completed in 6.103039055s

â€¢ [SLOW TEST:11.171 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:55:06.269: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 21 02:55:06.300: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c2807889-ee50-483d-bb8e-f25b65edbdc0" in namespace "downward-api-6864" to be "success or failure"
Dec 21 02:55:06.304: INFO: Pod "downwardapi-volume-c2807889-ee50-483d-bb8e-f25b65edbdc0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.462579ms
Dec 21 02:55:08.308: INFO: Pod "downwardapi-volume-c2807889-ee50-483d-bb8e-f25b65edbdc0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007438368s
STEP: Saw pod success
Dec 21 02:55:08.308: INFO: Pod "downwardapi-volume-c2807889-ee50-483d-bb8e-f25b65edbdc0" satisfied condition "success or failure"
Dec 21 02:55:08.310: INFO: Trying to get logs from node ip-172-31-29-141 pod downwardapi-volume-c2807889-ee50-483d-bb8e-f25b65edbdc0 container client-container: <nil>
STEP: delete the pod
Dec 21 02:55:08.341: INFO: Waiting for pod downwardapi-volume-c2807889-ee50-483d-bb8e-f25b65edbdc0 to disappear
Dec 21 02:55:08.347: INFO: Pod downwardapi-volume-c2807889-ee50-483d-bb8e-f25b65edbdc0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:55:08.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6864" for this suite.
Dec 21 02:55:14.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:55:14.439: INFO: namespace downward-api-6864 deletion completed in 6.085287528s

â€¢ [SLOW TEST:8.170 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:55:14.439: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 21 02:55:14.468: INFO: Waiting up to 5m0s for pod "downwardapi-volume-44dcf9c9-9ef1-4698-ab16-acbfa95bc68a" in namespace "projected-1570" to be "success or failure"
Dec 21 02:55:14.471: INFO: Pod "downwardapi-volume-44dcf9c9-9ef1-4698-ab16-acbfa95bc68a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.656752ms
Dec 21 02:55:16.474: INFO: Pod "downwardapi-volume-44dcf9c9-9ef1-4698-ab16-acbfa95bc68a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005855672s
STEP: Saw pod success
Dec 21 02:55:16.474: INFO: Pod "downwardapi-volume-44dcf9c9-9ef1-4698-ab16-acbfa95bc68a" satisfied condition "success or failure"
Dec 21 02:55:16.476: INFO: Trying to get logs from node ip-172-31-29-169 pod downwardapi-volume-44dcf9c9-9ef1-4698-ab16-acbfa95bc68a container client-container: <nil>
STEP: delete the pod
Dec 21 02:55:16.489: INFO: Waiting for pod downwardapi-volume-44dcf9c9-9ef1-4698-ab16-acbfa95bc68a to disappear
Dec 21 02:55:16.492: INFO: Pod downwardapi-volume-44dcf9c9-9ef1-4698-ab16-acbfa95bc68a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:55:16.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1570" for this suite.
Dec 21 02:55:22.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:55:22.586: INFO: namespace projected-1570 deletion completed in 6.090939193s

â€¢ [SLOW TEST:8.147 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:55:22.586: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 21 02:55:22.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-7897'
Dec 21 02:55:22.696: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 21 02:55:22.696: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Dec 21 02:55:22.704: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-s2lwc]
Dec 21 02:55:22.704: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-s2lwc" in namespace "kubectl-7897" to be "running and ready"
Dec 21 02:55:22.709: INFO: Pod "e2e-test-httpd-rc-s2lwc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.971ms
Dec 21 02:55:24.712: INFO: Pod "e2e-test-httpd-rc-s2lwc": Phase="Running", Reason="", readiness=true. Elapsed: 2.008016727s
Dec 21 02:55:24.712: INFO: Pod "e2e-test-httpd-rc-s2lwc" satisfied condition "running and ready"
Dec 21 02:55:24.713: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-s2lwc]
Dec 21 02:55:24.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 logs rc/e2e-test-httpd-rc --namespace=kubectl-7897'
Dec 21 02:55:24.808: INFO: stderr: ""
Dec 21 02:55:24.808: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.42.1.229. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.42.1.229. Set the 'ServerName' directive globally to suppress this message\n[Sat Dec 21 02:55:23.634731 2019] [mpm_event:notice] [pid 1:tid 140143356955496] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Sat Dec 21 02:55:23.634773 2019] [core:notice] [pid 1:tid 140143356955496] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Dec 21 02:55:24.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 delete rc e2e-test-httpd-rc --namespace=kubectl-7897'
Dec 21 02:55:24.889: INFO: stderr: ""
Dec 21 02:55:24.889: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:55:24.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7897" for this suite.
Dec 21 02:55:52.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:55:52.983: INFO: namespace kubectl-7897 deletion completed in 28.090882248s

â€¢ [SLOW TEST:30.397 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:55:52.984: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec 21 02:55:56.081: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:55:57.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8498" for this suite.
Dec 21 02:56:09.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:56:09.182: INFO: namespace replicaset-8498 deletion completed in 12.083083648s

â€¢ [SLOW TEST:16.198 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:56:09.183: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-92b2be33-26c6-47ca-b5dd-8022a1730e10
STEP: Creating a pod to test consume configMaps
Dec 21 02:56:09.214: INFO: Waiting up to 5m0s for pod "pod-configmaps-4bbcb9ea-b07a-4d1b-8275-b68a736f25ac" in namespace "configmap-2420" to be "success or failure"
Dec 21 02:56:09.217: INFO: Pod "pod-configmaps-4bbcb9ea-b07a-4d1b-8275-b68a736f25ac": Phase="Pending", Reason="", readiness=false. Elapsed: 3.065489ms
Dec 21 02:56:11.221: INFO: Pod "pod-configmaps-4bbcb9ea-b07a-4d1b-8275-b68a736f25ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006249714s
STEP: Saw pod success
Dec 21 02:56:11.221: INFO: Pod "pod-configmaps-4bbcb9ea-b07a-4d1b-8275-b68a736f25ac" satisfied condition "success or failure"
Dec 21 02:56:11.223: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-configmaps-4bbcb9ea-b07a-4d1b-8275-b68a736f25ac container configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 02:56:11.235: INFO: Waiting for pod pod-configmaps-4bbcb9ea-b07a-4d1b-8275-b68a736f25ac to disappear
Dec 21 02:56:11.237: INFO: Pod pod-configmaps-4bbcb9ea-b07a-4d1b-8275-b68a736f25ac no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:56:11.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2420" for this suite.
Dec 21 02:56:17.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:56:17.330: INFO: namespace configmap-2420 deletion completed in 6.09077377s

â€¢ [SLOW TEST:8.147 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:56:17.330: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 02:56:17.643: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 02:56:20.655: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Dec 21 02:56:23.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 attach --namespace=webhook-6522 to-be-attached-pod -i -c=container1'
Dec 21 02:56:23.780: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:56:23.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6522" for this suite.
Dec 21 02:56:35.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:56:35.881: INFO: namespace webhook-6522 deletion completed in 12.093686881s
STEP: Destroying namespace "webhook-6522-markers" for this suite.
Dec 21 02:56:41.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:56:41.983: INFO: namespace webhook-6522-markers deletion completed in 6.101944635s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:24.664 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:56:41.995: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 21 02:56:42.024: INFO: Waiting up to 5m0s for pod "pod-c138f011-bfe2-4774-bd03-c0baf4ffd77b" in namespace "emptydir-5029" to be "success or failure"
Dec 21 02:56:42.027: INFO: Pod "pod-c138f011-bfe2-4774-bd03-c0baf4ffd77b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.407667ms
Dec 21 02:56:44.030: INFO: Pod "pod-c138f011-bfe2-4774-bd03-c0baf4ffd77b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006367301s
STEP: Saw pod success
Dec 21 02:56:44.030: INFO: Pod "pod-c138f011-bfe2-4774-bd03-c0baf4ffd77b" satisfied condition "success or failure"
Dec 21 02:56:44.032: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-c138f011-bfe2-4774-bd03-c0baf4ffd77b container test-container: <nil>
STEP: delete the pod
Dec 21 02:56:44.049: INFO: Waiting for pod pod-c138f011-bfe2-4774-bd03-c0baf4ffd77b to disappear
Dec 21 02:56:44.054: INFO: Pod pod-c138f011-bfe2-4774-bd03-c0baf4ffd77b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:56:44.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5029" for this suite.
Dec 21 02:56:50.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:56:50.150: INFO: namespace emptydir-5029 deletion completed in 6.093543926s

â€¢ [SLOW TEST:8.155 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:56:50.150: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec 21 02:56:50.436: INFO: Pod name wrapped-volume-race-047ca382-deb1-46af-b1fd-a2472e5727fb: Found 3 pods out of 5
Dec 21 02:56:55.441: INFO: Pod name wrapped-volume-race-047ca382-deb1-46af-b1fd-a2472e5727fb: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-047ca382-deb1-46af-b1fd-a2472e5727fb in namespace emptydir-wrapper-8541, will wait for the garbage collector to delete the pods
Dec 21 02:57:05.518: INFO: Deleting ReplicationController wrapped-volume-race-047ca382-deb1-46af-b1fd-a2472e5727fb took: 5.55963ms
Dec 21 02:57:05.918: INFO: Terminating ReplicationController wrapped-volume-race-047ca382-deb1-46af-b1fd-a2472e5727fb pods took: 400.281485ms
STEP: Creating RC which spawns configmap-volume pods
Dec 21 02:57:44.431: INFO: Pod name wrapped-volume-race-d727c433-96a7-4259-96f8-e464554b8bb2: Found 0 pods out of 5
Dec 21 02:57:49.436: INFO: Pod name wrapped-volume-race-d727c433-96a7-4259-96f8-e464554b8bb2: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d727c433-96a7-4259-96f8-e464554b8bb2 in namespace emptydir-wrapper-8541, will wait for the garbage collector to delete the pods
Dec 21 02:57:59.518: INFO: Deleting ReplicationController wrapped-volume-race-d727c433-96a7-4259-96f8-e464554b8bb2 took: 6.806164ms
Dec 21 02:58:00.020: INFO: Terminating ReplicationController wrapped-volume-race-d727c433-96a7-4259-96f8-e464554b8bb2 pods took: 501.556587ms
STEP: Creating RC which spawns configmap-volume pods
Dec 21 02:58:42.072: INFO: Pod name wrapped-volume-race-2e2749b6-4d52-4df0-bf43-6dd657dbf67b: Found 1 pods out of 5
Dec 21 02:58:47.077: INFO: Pod name wrapped-volume-race-2e2749b6-4d52-4df0-bf43-6dd657dbf67b: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-2e2749b6-4d52-4df0-bf43-6dd657dbf67b in namespace emptydir-wrapper-8541, will wait for the garbage collector to delete the pods
Dec 21 02:58:57.270: INFO: Deleting ReplicationController wrapped-volume-race-2e2749b6-4d52-4df0-bf43-6dd657dbf67b took: 91.828936ms
Dec 21 02:58:57.770: INFO: Terminating ReplicationController wrapped-volume-race-2e2749b6-4d52-4df0-bf43-6dd657dbf67b pods took: 500.258238ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 02:59:32.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8541" for this suite.
Dec 21 02:59:38.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 02:59:38.711: INFO: namespace emptydir-wrapper-8541 deletion completed in 6.100896713s

â€¢ [SLOW TEST:168.561 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 02:59:38.711: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:00:38.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2541" for this suite.
Dec 21 03:01:06.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:01:06.837: INFO: namespace container-probe-2541 deletion completed in 28.091243666s

â€¢ [SLOW TEST:88.126 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:01:06.838: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 21 03:01:06.869: INFO: Waiting up to 5m0s for pod "downwardapi-volume-83dd589b-710a-4dd4-94d0-39208938a556" in namespace "projected-8919" to be "success or failure"
Dec 21 03:01:06.872: INFO: Pod "downwardapi-volume-83dd589b-710a-4dd4-94d0-39208938a556": Phase="Pending", Reason="", readiness=false. Elapsed: 2.806916ms
Dec 21 03:01:08.875: INFO: Pod "downwardapi-volume-83dd589b-710a-4dd4-94d0-39208938a556": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006000092s
STEP: Saw pod success
Dec 21 03:01:08.875: INFO: Pod "downwardapi-volume-83dd589b-710a-4dd4-94d0-39208938a556" satisfied condition "success or failure"
Dec 21 03:01:08.878: INFO: Trying to get logs from node ip-172-31-29-169 pod downwardapi-volume-83dd589b-710a-4dd4-94d0-39208938a556 container client-container: <nil>
STEP: delete the pod
Dec 21 03:01:08.897: INFO: Waiting for pod downwardapi-volume-83dd589b-710a-4dd4-94d0-39208938a556 to disappear
Dec 21 03:01:08.899: INFO: Pod downwardapi-volume-83dd589b-710a-4dd4-94d0-39208938a556 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:01:08.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8919" for this suite.
Dec 21 03:01:14.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:01:15.006: INFO: namespace projected-8919 deletion completed in 6.09765998s

â€¢ [SLOW TEST:8.168 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:01:15.006: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 21 03:01:15.032: INFO: PodSpec: initContainers in spec.initContainers
Dec 21 03:01:57.176: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-a34fa8fc-adec-4c4f-9865-90ee4c141ff7", GenerateName:"", Namespace:"init-container-4411", SelfLink:"/api/v1/namespaces/init-container-4411/pods/pod-init-a34fa8fc-adec-4c4f-9865-90ee4c141ff7", UID:"97f428da-e99a-47e5-b23d-c440decc78a9", ResourceVersion:"21885", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63712494075, loc:(*time.Location)(0x84bfb00)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"32677767"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-hfhgc", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00363a5c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hfhgc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hfhgc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hfhgc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0012ccde8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-29-169", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc003b7fce0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0012cce70)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0012cce90)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0012cce98), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0012cce9c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712494075, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712494075, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712494075, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712494075, loc:(*time.Location)(0x84bfb00)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.29.169", PodIP:"10.42.1.236", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.42.1.236"}}, StartTime:(*v1.Time)(0xc0034257e0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0027e4cb0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0027e4d20)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://5d45329ebc3ce0cbbee5146108c515aad576f619f8735d6755d7736ccc4122b5", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003425820), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003425800), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0012ccf4f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:01:57.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4411" for this suite.
Dec 21 03:02:25.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:02:25.267: INFO: namespace init-container-4411 deletion completed in 28.087845959s

â€¢ [SLOW TEST:70.261 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:02:25.267: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 03:02:25.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 create -f - --namespace=kubectl-8980'
Dec 21 03:02:25.495: INFO: stderr: ""
Dec 21 03:02:25.495: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec 21 03:02:25.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 create -f - --namespace=kubectl-8980'
Dec 21 03:02:25.658: INFO: stderr: ""
Dec 21 03:02:25.658: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 21 03:02:26.661: INFO: Selector matched 1 pods for map[app:redis]
Dec 21 03:02:26.661: INFO: Found 0 / 1
Dec 21 03:02:27.661: INFO: Selector matched 1 pods for map[app:redis]
Dec 21 03:02:27.661: INFO: Found 1 / 1
Dec 21 03:02:27.661: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 21 03:02:27.663: INFO: Selector matched 1 pods for map[app:redis]
Dec 21 03:02:27.663: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 21 03:02:27.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 describe pod redis-master-rtzsm --namespace=kubectl-8980'
Dec 21 03:02:27.752: INFO: stderr: ""
Dec 21 03:02:27.752: INFO: stdout: "Name:         redis-master-rtzsm\nNamespace:    kubectl-8980\nPriority:     0\nNode:         ip-172-31-29-169/172.31.29.169\nStart Time:   Sat, 21 Dec 2019 03:02:25 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nStatus:       Running\nIP:           10.42.1.237\nIPs:\n  IP:           10.42.1.237\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://7c064ec0d935c978c05d5a28242be12946f239cb5b597d3cdf176596b9a7a8df\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 21 Dec 2019 03:02:26 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-tmzwq (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-tmzwq:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-tmzwq\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                       Message\n  ----    ------     ----       ----                       -------\n  Normal  Scheduled  <unknown>  default-scheduler          Successfully assigned kubectl-8980/redis-master-rtzsm to ip-172-31-29-169\n  Normal  Pulled     1s         kubelet, ip-172-31-29-169  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    1s         kubelet, ip-172-31-29-169  Created container redis-master\n  Normal  Started    1s         kubelet, ip-172-31-29-169  Started container redis-master\n"
Dec 21 03:02:27.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 describe rc redis-master --namespace=kubectl-8980'
Dec 21 03:02:27.845: INFO: stderr: ""
Dec 21 03:02:27.845: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-8980\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-rtzsm\n"
Dec 21 03:02:27.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 describe service redis-master --namespace=kubectl-8980'
Dec 21 03:02:27.929: INFO: stderr: ""
Dec 21 03:02:27.930: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-8980\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.43.186.128\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.42.1.237:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec 21 03:02:27.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 describe node ip-172-31-25-252'
Dec 21 03:02:28.029: INFO: stderr: ""
Dec 21 03:02:28.029: INFO: stdout: "Name:               ip-172-31-25-252\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=k3s\n                    beta.kubernetes.io/os=linux\n                    k3s.io/hostname=ip-172-31-25-252\n                    k3s.io/internal-ip=172.31.25.252\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-25-252\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=true\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"8a:b8:06:9d:ca:e7\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 172.31.25.252\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 21 Dec 2019 00:41:12 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Sat, 21 Dec 2019 00:41:24 +0000   Sat, 21 Dec 2019 00:41:24 +0000   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Sat, 21 Dec 2019 03:01:44 +0000   Sat, 21 Dec 2019 00:41:12 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sat, 21 Dec 2019 03:01:44 +0000   Sat, 21 Dec 2019 00:41:12 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sat, 21 Dec 2019 03:01:44 +0000   Sat, 21 Dec 2019 00:41:12 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sat, 21 Dec 2019 03:01:44 +0000   Sat, 21 Dec 2019 00:41:12 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.25.252\n  Hostname:    ip-172-31-25-252\nCapacity:\n cpu:                2\n ephemeral-storage:  8065444Ki\n hugepages-2Mi:      0\n memory:             4038260Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  7846063918\n hugepages-2Mi:      0\n memory:             4038260Ki\n pods:               110\nSystem Info:\n Machine ID:                 6a07487a3eb048339619fad13ab3d13b\n System UUID:                EC29873D-6699-7912-D947-6CC39329C71B\n Boot ID:                    6db04a85-6abf-44cc-8715-6d1cd4f79aba\n Kernel Version:             4.15.0-1054-aws\n OS Image:                   Ubuntu 18.04.3 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.3.0-k3s.5\n Kubelet Version:            v1.16.3-k3s.2\n Kube-Proxy Version:         v1.16.3-k3s.2\nPodCIDR:                     10.42.0.0/24\nPodCIDRs:                    10.42.0.0/24\nProviderID:                  k3s://ip-172-31-25-252\nNon-terminated Pods:         (6 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                local-path-provisioner-58fb86bdfd-62kwn                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         141m\n  kube-system                metrics-server-6d684c7b5-t9j6h                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         141m\n  kube-system                coredns-d798c9dd-llwxl                                     100m (5%)     0 (0%)      70Mi (1%)        170Mi (4%)     141m\n  kube-system                svclb-traefik-lnc6c                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         140m\n  kube-system                traefik-65bccdc4bd-xhwzd                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         140m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-be71f149a5064d0d-5z58c    0 (0%)        0 (0%)      0 (0%)           0 (0%)         97m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests   Limits\n  --------           --------   ------\n  cpu                100m (5%)  0 (0%)\n  memory             70Mi (1%)  170Mi (4%)\n  ephemeral-storage  0 (0%)     0 (0%)\nEvents:              <none>\n"
Dec 21 03:02:28.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 describe namespace kubectl-8980'
Dec 21 03:02:28.115: INFO: stderr: ""
Dec 21 03:02:28.115: INFO: stdout: "Name:         kubectl-8980\nLabels:       e2e-framework=kubectl\n              e2e-run=568d324f-6762-4fa7-b52f-35eb163af0a2\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:02:28.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8980" for this suite.
Dec 21 03:02:56.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:02:56.214: INFO: namespace kubectl-8980 deletion completed in 28.096844103s

â€¢ [SLOW TEST:30.947 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:02:56.215: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Dec 21 03:02:56.239: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Dec 21 03:03:08.814: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 03:03:12.344: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:03:23.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9199" for this suite.
Dec 21 03:03:29.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:03:29.604: INFO: namespace crd-publish-openapi-9199 deletion completed in 6.096888473s

â€¢ [SLOW TEST:33.389 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:03:29.605: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-p684
STEP: Creating a pod to test atomic-volume-subpath
Dec 21 03:03:29.639: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-p684" in namespace "subpath-5857" to be "success or failure"
Dec 21 03:03:29.643: INFO: Pod "pod-subpath-test-configmap-p684": Phase="Pending", Reason="", readiness=false. Elapsed: 3.519666ms
Dec 21 03:03:31.648: INFO: Pod "pod-subpath-test-configmap-p684": Phase="Running", Reason="", readiness=true. Elapsed: 2.008698305s
Dec 21 03:03:33.653: INFO: Pod "pod-subpath-test-configmap-p684": Phase="Running", Reason="", readiness=true. Elapsed: 4.013764491s
Dec 21 03:03:35.656: INFO: Pod "pod-subpath-test-configmap-p684": Phase="Running", Reason="", readiness=true. Elapsed: 6.01692842s
Dec 21 03:03:37.659: INFO: Pod "pod-subpath-test-configmap-p684": Phase="Running", Reason="", readiness=true. Elapsed: 8.020148173s
Dec 21 03:03:39.663: INFO: Pod "pod-subpath-test-configmap-p684": Phase="Running", Reason="", readiness=true. Elapsed: 10.023449922s
Dec 21 03:03:41.666: INFO: Pod "pod-subpath-test-configmap-p684": Phase="Running", Reason="", readiness=true. Elapsed: 12.026592118s
Dec 21 03:03:43.669: INFO: Pod "pod-subpath-test-configmap-p684": Phase="Running", Reason="", readiness=true. Elapsed: 14.029801069s
Dec 21 03:03:45.672: INFO: Pod "pod-subpath-test-configmap-p684": Phase="Running", Reason="", readiness=true. Elapsed: 16.033036876s
Dec 21 03:03:47.676: INFO: Pod "pod-subpath-test-configmap-p684": Phase="Running", Reason="", readiness=true. Elapsed: 18.036681486s
Dec 21 03:03:49.679: INFO: Pod "pod-subpath-test-configmap-p684": Phase="Running", Reason="", readiness=true. Elapsed: 20.039923616s
Dec 21 03:03:51.683: INFO: Pod "pod-subpath-test-configmap-p684": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.043322649s
STEP: Saw pod success
Dec 21 03:03:51.683: INFO: Pod "pod-subpath-test-configmap-p684" satisfied condition "success or failure"
Dec 21 03:03:51.685: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-subpath-test-configmap-p684 container test-container-subpath-configmap-p684: <nil>
STEP: delete the pod
Dec 21 03:03:51.701: INFO: Waiting for pod pod-subpath-test-configmap-p684 to disappear
Dec 21 03:03:51.704: INFO: Pod pod-subpath-test-configmap-p684 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-p684
Dec 21 03:03:51.704: INFO: Deleting pod "pod-subpath-test-configmap-p684" in namespace "subpath-5857"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:03:51.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5857" for this suite.
Dec 21 03:03:57.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:03:57.846: INFO: namespace subpath-5857 deletion completed in 6.136589679s

â€¢ [SLOW TEST:28.241 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:03:57.846: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:03:57.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-6883" for this suite.
Dec 21 03:04:03.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:04:03.992: INFO: namespace tables-6883 deletion completed in 6.105034115s

â€¢ [SLOW TEST:6.147 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:04:03.993: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-ff2c5c79-6b9e-4c37-bf5f-6e93d01fd17d
STEP: Creating a pod to test consume secrets
Dec 21 03:04:04.028: INFO: Waiting up to 5m0s for pod "pod-secrets-319d44d6-9631-4aa0-9088-5da9ee942be9" in namespace "secrets-7684" to be "success or failure"
Dec 21 03:04:04.031: INFO: Pod "pod-secrets-319d44d6-9631-4aa0-9088-5da9ee942be9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.940999ms
Dec 21 03:04:06.034: INFO: Pod "pod-secrets-319d44d6-9631-4aa0-9088-5da9ee942be9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006091687s
STEP: Saw pod success
Dec 21 03:04:06.034: INFO: Pod "pod-secrets-319d44d6-9631-4aa0-9088-5da9ee942be9" satisfied condition "success or failure"
Dec 21 03:04:06.036: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-secrets-319d44d6-9631-4aa0-9088-5da9ee942be9 container secret-env-test: <nil>
STEP: delete the pod
Dec 21 03:04:06.047: INFO: Waiting for pod pod-secrets-319d44d6-9631-4aa0-9088-5da9ee942be9 to disappear
Dec 21 03:04:06.051: INFO: Pod pod-secrets-319d44d6-9631-4aa0-9088-5da9ee942be9 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:04:06.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7684" for this suite.
Dec 21 03:04:12.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:04:12.146: INFO: namespace secrets-7684 deletion completed in 6.092062406s

â€¢ [SLOW TEST:8.153 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:04:12.146: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 03:04:12.856: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 21 03:04:14.864: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712494252, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712494252, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712494252, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712494252, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 03:04:17.874: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:04:17.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6616" for this suite.
Dec 21 03:04:23.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:04:23.976: INFO: namespace webhook-6616 deletion completed in 6.093221981s
STEP: Destroying namespace "webhook-6616-markers" for this suite.
Dec 21 03:04:29.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:04:30.077: INFO: namespace webhook-6616-markers deletion completed in 6.100991618s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:17.942 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:04:30.088: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 21 03:04:30.119: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fb2bc153-1f2b-48a5-87ef-da0dbd59cf5b" in namespace "downward-api-311" to be "success or failure"
Dec 21 03:04:30.122: INFO: Pod "downwardapi-volume-fb2bc153-1f2b-48a5-87ef-da0dbd59cf5b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.335202ms
Dec 21 03:04:32.125: INFO: Pod "downwardapi-volume-fb2bc153-1f2b-48a5-87ef-da0dbd59cf5b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006600952s
STEP: Saw pod success
Dec 21 03:04:32.125: INFO: Pod "downwardapi-volume-fb2bc153-1f2b-48a5-87ef-da0dbd59cf5b" satisfied condition "success or failure"
Dec 21 03:04:32.128: INFO: Trying to get logs from node ip-172-31-29-169 pod downwardapi-volume-fb2bc153-1f2b-48a5-87ef-da0dbd59cf5b container client-container: <nil>
STEP: delete the pod
Dec 21 03:04:32.144: INFO: Waiting for pod downwardapi-volume-fb2bc153-1f2b-48a5-87ef-da0dbd59cf5b to disappear
Dec 21 03:04:32.147: INFO: Pod downwardapi-volume-fb2bc153-1f2b-48a5-87ef-da0dbd59cf5b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:04:32.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-311" for this suite.
Dec 21 03:04:38.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:04:38.247: INFO: namespace downward-api-311 deletion completed in 6.097794081s

â€¢ [SLOW TEST:8.159 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:04:38.247: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 21 03:04:38.273: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 21 03:04:38.281: INFO: Waiting for terminating namespaces to be deleted...
Dec 21 03:04:38.283: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-25-252 before test
Dec 21 03:04:38.292: INFO: svclb-traefik-lnc6c from kube-system started at 2019-12-21 00:41:53 +0000 UTC (3 container statuses recorded)
Dec 21 03:04:38.292: INFO: 	Container lb-port-443 ready: true, restart count 0
Dec 21 03:04:38.292: INFO: 	Container lb-port-80 ready: true, restart count 0
Dec 21 03:04:38.292: INFO: 	Container lb-port-8080 ready: true, restart count 0
Dec 21 03:04:38.292: INFO: metrics-server-6d684c7b5-t9j6h from kube-system started at 2019-12-21 00:41:22 +0000 UTC (1 container statuses recorded)
Dec 21 03:04:38.292: INFO: 	Container metrics-server ready: true, restart count 0
Dec 21 03:04:38.292: INFO: local-path-provisioner-58fb86bdfd-62kwn from kube-system started at 2019-12-21 00:41:22 +0000 UTC (1 container statuses recorded)
Dec 21 03:04:38.292: INFO: 	Container local-path-provisioner ready: true, restart count 0
Dec 21 03:04:38.292: INFO: traefik-65bccdc4bd-xhwzd from kube-system started at 2019-12-21 00:41:53 +0000 UTC (1 container statuses recorded)
Dec 21 03:04:38.292: INFO: 	Container traefik ready: true, restart count 0
Dec 21 03:04:38.292: INFO: helm-install-traefik-hhwxg from kube-system started at 2019-12-21 00:41:22 +0000 UTC (1 container statuses recorded)
Dec 21 03:04:38.292: INFO: 	Container helm ready: false, restart count 0
Dec 21 03:04:38.292: INFO: coredns-d798c9dd-llwxl from kube-system started at 2019-12-21 00:41:22 +0000 UTC (1 container statuses recorded)
Dec 21 03:04:38.292: INFO: 	Container coredns ready: true, restart count 0
Dec 21 03:04:38.292: INFO: sonobuoy-systemd-logs-daemon-set-be71f149a5064d0d-5z58c from sonobuoy started at 2019-12-21 01:24:52 +0000 UTC (2 container statuses recorded)
Dec 21 03:04:38.292: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 21 03:04:38.292: INFO: 	Container systemd-logs ready: true, restart count 1
Dec 21 03:04:38.292: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-29-141 before test
Dec 21 03:04:38.300: INFO: sonobuoy-systemd-logs-daemon-set-be71f149a5064d0d-pn2hq from sonobuoy started at 2019-12-21 01:24:53 +0000 UTC (2 container statuses recorded)
Dec 21 03:04:38.300: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 21 03:04:38.300: INFO: 	Container systemd-logs ready: true, restart count 1
Dec 21 03:04:38.300: INFO: svclb-traefik-7ksbn from kube-system started at 2019-12-21 00:42:23 +0000 UTC (3 container statuses recorded)
Dec 21 03:04:38.300: INFO: 	Container lb-port-443 ready: true, restart count 0
Dec 21 03:04:38.301: INFO: 	Container lb-port-80 ready: true, restart count 0
Dec 21 03:04:38.301: INFO: 	Container lb-port-8080 ready: true, restart count 0
Dec 21 03:04:38.301: INFO: sonobuoy-e2e-job-c939600be6994601 from sonobuoy started at 2019-12-21 01:24:52 +0000 UTC (2 container statuses recorded)
Dec 21 03:04:38.301: INFO: 	Container e2e ready: true, restart count 0
Dec 21 03:04:38.301: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 03:04:38.301: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-29-169 before test
Dec 21 03:04:38.305: INFO: sonobuoy-systemd-logs-daemon-set-be71f149a5064d0d-kxt8c from sonobuoy started at 2019-12-21 01:24:53 +0000 UTC (2 container statuses recorded)
Dec 21 03:04:38.305: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 21 03:04:38.305: INFO: 	Container systemd-logs ready: true, restart count 1
Dec 21 03:04:38.305: INFO: svclb-traefik-nnb5s from kube-system started at 2019-12-21 00:42:09 +0000 UTC (3 container statuses recorded)
Dec 21 03:04:38.305: INFO: 	Container lb-port-443 ready: true, restart count 0
Dec 21 03:04:38.305: INFO: 	Container lb-port-80 ready: true, restart count 0
Dec 21 03:04:38.305: INFO: 	Container lb-port-8080 ready: true, restart count 0
Dec 21 03:04:38.305: INFO: sonobuoy from sonobuoy started at 2019-12-21 01:24:48 +0000 UTC (1 container statuses recorded)
Dec 21 03:04:38.305: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-a70af89a-ebed-4808-b092-e008f11176e1 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-a70af89a-ebed-4808-b092-e008f11176e1 off the node ip-172-31-29-169
STEP: verifying the node doesn't have the label kubernetes.io/e2e-a70af89a-ebed-4808-b092-e008f11176e1
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:04:50.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6761" for this suite.
Dec 21 03:04:58.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:04:58.507: INFO: namespace sched-pred-6761 deletion completed in 8.127554369s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

â€¢ [SLOW TEST:20.260 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:04:58.508: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 03:04:59.174: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 03:05:02.196: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:05:03.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7316" for this suite.
Dec 21 03:05:09.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:05:09.422: INFO: namespace webhook-7316 deletion completed in 6.138720983s
STEP: Destroying namespace "webhook-7316-markers" for this suite.
Dec 21 03:05:15.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:05:15.542: INFO: namespace webhook-7316-markers deletion completed in 6.12058436s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:17.045 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:05:15.553: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Dec 21 03:05:15.582: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 03:05:19.089: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:05:31.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3817" for this suite.
Dec 21 03:05:37.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:05:37.272: INFO: namespace crd-publish-openapi-3817 deletion completed in 6.101549369s

â€¢ [SLOW TEST:21.719 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:05:37.272: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:05:40.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3589" for this suite.
Dec 21 03:05:52.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:05:52.500: INFO: namespace replication-controller-3589 deletion completed in 12.123633077s

â€¢ [SLOW TEST:15.229 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:05:52.501: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 21 03:05:52.553: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e8d700e0-317c-4324-a0aa-5e6710895a69" in namespace "projected-1767" to be "success or failure"
Dec 21 03:05:52.557: INFO: Pod "downwardapi-volume-e8d700e0-317c-4324-a0aa-5e6710895a69": Phase="Pending", Reason="", readiness=false. Elapsed: 3.871351ms
Dec 21 03:05:54.560: INFO: Pod "downwardapi-volume-e8d700e0-317c-4324-a0aa-5e6710895a69": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007039549s
STEP: Saw pod success
Dec 21 03:05:54.560: INFO: Pod "downwardapi-volume-e8d700e0-317c-4324-a0aa-5e6710895a69" satisfied condition "success or failure"
Dec 21 03:05:54.562: INFO: Trying to get logs from node ip-172-31-29-169 pod downwardapi-volume-e8d700e0-317c-4324-a0aa-5e6710895a69 container client-container: <nil>
STEP: delete the pod
Dec 21 03:05:54.576: INFO: Waiting for pod downwardapi-volume-e8d700e0-317c-4324-a0aa-5e6710895a69 to disappear
Dec 21 03:05:54.584: INFO: Pod downwardapi-volume-e8d700e0-317c-4324-a0aa-5e6710895a69 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:05:54.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1767" for this suite.
Dec 21 03:06:00.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:06:00.678: INFO: namespace projected-1767 deletion completed in 6.091434334s

â€¢ [SLOW TEST:8.177 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:06:00.678: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-1135
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-1135
STEP: creating replication controller externalsvc in namespace services-1135
I1221 03:06:00.725474      22 runners.go:184] Created replication controller with name: externalsvc, namespace: services-1135, replica count: 2
I1221 03:06:03.776049      22 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Dec 21 03:06:03.791: INFO: Creating new exec pod
Dec 21 03:06:05.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 exec --namespace=services-1135 execpodd7xqz -- /bin/sh -x -c nslookup nodeport-service'
Dec 21 03:06:06.717: INFO: stderr: "+ nslookup nodeport-service\n"
Dec 21 03:06:06.717: INFO: stdout: "Server:\t\t10.43.0.10\nAddress:\t10.43.0.10#53\n\nnodeport-service.services-1135.svc.cluster.local\tcanonical name = externalsvc.services-1135.svc.cluster.local.\nName:\texternalsvc.services-1135.svc.cluster.local\nAddress: 10.43.18.78\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-1135, will wait for the garbage collector to delete the pods
Dec 21 03:06:06.775: INFO: Deleting ReplicationController externalsvc took: 5.164466ms
Dec 21 03:06:06.876: INFO: Terminating ReplicationController externalsvc pods took: 100.284229ms
Dec 21 03:06:19.391: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:06:19.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1135" for this suite.
Dec 21 03:06:25.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:06:25.497: INFO: namespace services-1135 deletion completed in 6.091185995s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:24.819 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:06:25.499: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-e99323ea-2f6c-4280-8888-f335ca88ea8b
STEP: Creating configMap with name cm-test-opt-upd-bcd5ee95-bd19-4431-b328-6e6795ae376a
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-e99323ea-2f6c-4280-8888-f335ca88ea8b
STEP: Updating configmap cm-test-opt-upd-bcd5ee95-bd19-4431-b328-6e6795ae376a
STEP: Creating configMap with name cm-test-opt-create-748ae4b7-5a40-44a4-a734-377790de79ad
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:07:45.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2207" for this suite.
Dec 21 03:08:01.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:08:01.946: INFO: namespace configmap-2207 deletion completed in 16.105812235s

â€¢ [SLOW TEST:96.448 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:08:01.947: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 21 03:08:01.982: INFO: Waiting up to 5m0s for pod "pod-36716dc9-bcbc-4b6f-b4d9-339bb5266179" in namespace "emptydir-266" to be "success or failure"
Dec 21 03:08:01.985: INFO: Pod "pod-36716dc9-bcbc-4b6f-b4d9-339bb5266179": Phase="Pending", Reason="", readiness=false. Elapsed: 3.510951ms
Dec 21 03:08:03.988: INFO: Pod "pod-36716dc9-bcbc-4b6f-b4d9-339bb5266179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006627659s
STEP: Saw pod success
Dec 21 03:08:03.988: INFO: Pod "pod-36716dc9-bcbc-4b6f-b4d9-339bb5266179" satisfied condition "success or failure"
Dec 21 03:08:03.990: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-36716dc9-bcbc-4b6f-b4d9-339bb5266179 container test-container: <nil>
STEP: delete the pod
Dec 21 03:08:04.003: INFO: Waiting for pod pod-36716dc9-bcbc-4b6f-b4d9-339bb5266179 to disappear
Dec 21 03:08:04.005: INFO: Pod pod-36716dc9-bcbc-4b6f-b4d9-339bb5266179 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:08:04.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-266" for this suite.
Dec 21 03:08:10.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:08:10.102: INFO: namespace emptydir-266 deletion completed in 6.094394331s

â€¢ [SLOW TEST:8.156 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:08:10.103: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Dec 21 03:08:10.130: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
Dec 21 03:08:13.144: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:08:25.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2533" for this suite.
Dec 21 03:08:31.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:08:31.798: INFO: namespace crd-publish-openapi-2533 deletion completed in 6.094034887s

â€¢ [SLOW TEST:21.696 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:08:31.798: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Dec 21 03:08:31.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-1862 -- logs-generator --log-lines-total 100 --run-duration 20s'
Dec 21 03:08:31.907: INFO: stderr: ""
Dec 21 03:08:31.907: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Dec 21 03:08:31.907: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Dec 21 03:08:31.907: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-1862" to be "running and ready, or succeeded"
Dec 21 03:08:31.911: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029301ms
Dec 21 03:08:33.914: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.007135053s
Dec 21 03:08:33.914: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Dec 21 03:08:33.914: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Dec 21 03:08:33.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 logs logs-generator logs-generator --namespace=kubectl-1862'
Dec 21 03:08:33.998: INFO: stderr: ""
Dec 21 03:08:33.998: INFO: stdout: "I1221 03:08:32.821095       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/7fs6 536\nI1221 03:08:33.021299       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/896 476\nI1221 03:08:33.221329       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/z56r 498\nI1221 03:08:33.421339       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/m48d 511\nI1221 03:08:33.621313       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/bpk 278\nI1221 03:08:33.821279       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/tkg 300\n"
STEP: limiting log lines
Dec 21 03:08:33.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 logs logs-generator logs-generator --namespace=kubectl-1862 --tail=1'
Dec 21 03:08:34.084: INFO: stderr: ""
Dec 21 03:08:34.084: INFO: stdout: "I1221 03:08:34.021302       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/xzc 575\n"
STEP: limiting log bytes
Dec 21 03:08:34.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 logs logs-generator logs-generator --namespace=kubectl-1862 --limit-bytes=1'
Dec 21 03:08:34.175: INFO: stderr: ""
Dec 21 03:08:34.175: INFO: stdout: "I"
STEP: exposing timestamps
Dec 21 03:08:34.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 logs logs-generator logs-generator --namespace=kubectl-1862 --tail=1 --timestamps'
Dec 21 03:08:34.260: INFO: stderr: ""
Dec 21 03:08:34.260: INFO: stdout: "2019-12-21T03:08:34.221413415Z I1221 03:08:34.221282       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/jrz 528\n"
STEP: restricting to a time range
Dec 21 03:08:36.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 logs logs-generator logs-generator --namespace=kubectl-1862 --since=1s'
Dec 21 03:08:36.844: INFO: stderr: ""
Dec 21 03:08:36.844: INFO: stdout: "I1221 03:08:36.021320       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/2sn 359\nI1221 03:08:36.221307       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/dl59 322\nI1221 03:08:36.421330       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/n2r 263\nI1221 03:08:36.621316       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/td2 388\nI1221 03:08:36.821311       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/49w 551\n"
Dec 21 03:08:36.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 logs logs-generator logs-generator --namespace=kubectl-1862 --since=24h'
Dec 21 03:08:36.929: INFO: stderr: ""
Dec 21 03:08:36.929: INFO: stdout: "I1221 03:08:32.821095       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/7fs6 536\nI1221 03:08:33.021299       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/896 476\nI1221 03:08:33.221329       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/z56r 498\nI1221 03:08:33.421339       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/m48d 511\nI1221 03:08:33.621313       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/bpk 278\nI1221 03:08:33.821279       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/tkg 300\nI1221 03:08:34.021302       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/xzc 575\nI1221 03:08:34.221282       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/jrz 528\nI1221 03:08:34.421340       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/r2f 497\nI1221 03:08:34.621300       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/2lm 227\nI1221 03:08:34.821329       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/kube-system/pods/2rv 277\nI1221 03:08:35.021313       1 logs_generator.go:76] 11 POST /api/v1/namespaces/default/pods/q84x 269\nI1221 03:08:35.221297       1 logs_generator.go:76] 12 POST /api/v1/namespaces/default/pods/22g8 289\nI1221 03:08:35.421335       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/default/pods/p8b 590\nI1221 03:08:35.621307       1 logs_generator.go:76] 14 POST /api/v1/namespaces/ns/pods/gwgd 338\nI1221 03:08:35.821309       1 logs_generator.go:76] 15 GET /api/v1/namespaces/ns/pods/k5qf 493\nI1221 03:08:36.021320       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/2sn 359\nI1221 03:08:36.221307       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/dl59 322\nI1221 03:08:36.421330       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/n2r 263\nI1221 03:08:36.621316       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/td2 388\nI1221 03:08:36.821311       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/49w 551\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Dec 21 03:08:36.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 delete pod logs-generator --namespace=kubectl-1862'
Dec 21 03:08:49.299: INFO: stderr: ""
Dec 21 03:08:49.299: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:08:49.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1862" for this suite.
Dec 21 03:08:55.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:08:55.393: INFO: namespace kubectl-1862 deletion completed in 6.090854971s

â€¢ [SLOW TEST:23.595 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:08:55.394: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-83d67632-fa37-44ab-902a-7cc7d6626415
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:08:55.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3304" for this suite.
Dec 21 03:09:01.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:09:01.519: INFO: namespace configmap-3304 deletion completed in 6.097546159s

â€¢ [SLOW TEST:6.125 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:09:01.519: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Dec 21 03:09:01.546: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 21 03:10:01.557: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 03:10:01.560: INFO: Starting informer...
STEP: Starting pod...
Dec 21 03:10:01.770: INFO: Pod is running on ip-172-31-29-169. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Dec 21 03:10:01.783: INFO: Pod wasn't evicted. Proceeding
Dec 21 03:10:01.783: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Dec 21 03:11:16.809: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:11:16.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-2559" for this suite.
Dec 21 03:11:28.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:11:28.910: INFO: namespace taint-single-pod-2559 deletion completed in 12.098041439s

â€¢ [SLOW TEST:147.391 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:11:28.910: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Dec 21 03:11:28.937: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 21 03:12:28.949: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 03:12:28.951: INFO: Starting informer...
STEP: Starting pods...
Dec 21 03:12:29.167: INFO: Pod1 is running on ip-172-31-29-169. Tainting Node
Dec 21 03:12:31.381: INFO: Pod2 is running on ip-172-31-29-169. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Dec 21 03:12:38.057: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Dec 21 03:12:58.083: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:12:58.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-2421" for this suite.
Dec 21 03:13:04.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:13:04.203: INFO: namespace taint-multiple-pods-2421 deletion completed in 6.105353518s

â€¢ [SLOW TEST:95.292 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:13:04.203: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 21 03:13:04.226: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:13:06.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2243" for this suite.
Dec 21 03:13:12.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:13:12.701: INFO: namespace init-container-2243 deletion completed in 6.086972603s

â€¢ [SLOW TEST:8.498 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:13:12.701: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 21 03:13:15.249: INFO: Successfully updated pod "pod-update-90050d47-568a-4da0-886f-aa2c558dfccc"
STEP: verifying the updated pod is in kubernetes
Dec 21 03:13:15.254: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:13:15.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5853" for this suite.
Dec 21 03:13:43.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:13:43.341: INFO: namespace pods-5853 deletion completed in 28.08455214s

â€¢ [SLOW TEST:30.640 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:13:43.341: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec 21 03:13:43.369: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-56 /api/v1/namespaces/watch-56/configmaps/e2e-watch-test-configmap-a 32f8922f-2e13-47c3-8b78-f1215716e714 23451 0 2019-12-21 03:13:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 21 03:13:43.370: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-56 /api/v1/namespaces/watch-56/configmaps/e2e-watch-test-configmap-a 32f8922f-2e13-47c3-8b78-f1215716e714 23451 0 2019-12-21 03:13:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec 21 03:13:53.375: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-56 /api/v1/namespaces/watch-56/configmaps/e2e-watch-test-configmap-a 32f8922f-2e13-47c3-8b78-f1215716e714 23462 0 2019-12-21 03:13:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 21 03:13:53.375: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-56 /api/v1/namespaces/watch-56/configmaps/e2e-watch-test-configmap-a 32f8922f-2e13-47c3-8b78-f1215716e714 23462 0 2019-12-21 03:13:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec 21 03:14:03.381: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-56 /api/v1/namespaces/watch-56/configmaps/e2e-watch-test-configmap-a 32f8922f-2e13-47c3-8b78-f1215716e714 23473 0 2019-12-21 03:13:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 21 03:14:03.382: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-56 /api/v1/namespaces/watch-56/configmaps/e2e-watch-test-configmap-a 32f8922f-2e13-47c3-8b78-f1215716e714 23473 0 2019-12-21 03:13:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec 21 03:14:13.387: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-56 /api/v1/namespaces/watch-56/configmaps/e2e-watch-test-configmap-a 32f8922f-2e13-47c3-8b78-f1215716e714 23484 0 2019-12-21 03:13:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 21 03:14:13.388: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-56 /api/v1/namespaces/watch-56/configmaps/e2e-watch-test-configmap-a 32f8922f-2e13-47c3-8b78-f1215716e714 23484 0 2019-12-21 03:13:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec 21 03:14:23.393: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-56 /api/v1/namespaces/watch-56/configmaps/e2e-watch-test-configmap-b 0abdd3c4-9369-4389-882f-08506850f5cf 23494 0 2019-12-21 03:14:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 21 03:14:23.393: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-56 /api/v1/namespaces/watch-56/configmaps/e2e-watch-test-configmap-b 0abdd3c4-9369-4389-882f-08506850f5cf 23494 0 2019-12-21 03:14:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec 21 03:14:33.399: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-56 /api/v1/namespaces/watch-56/configmaps/e2e-watch-test-configmap-b 0abdd3c4-9369-4389-882f-08506850f5cf 23504 0 2019-12-21 03:14:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 21 03:14:33.399: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-56 /api/v1/namespaces/watch-56/configmaps/e2e-watch-test-configmap-b 0abdd3c4-9369-4389-882f-08506850f5cf 23504 0 2019-12-21 03:14:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:14:43.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-56" for this suite.
Dec 21 03:14:49.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:14:49.492: INFO: namespace watch-56 deletion completed in 6.088952783s

â€¢ [SLOW TEST:66.151 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:14:49.493: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:14:51.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2875" for this suite.
Dec 21 03:15:41.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:15:41.636: INFO: namespace kubelet-test-2875 deletion completed in 50.095146731s

â€¢ [SLOW TEST:52.143 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:15:41.636: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-3c8c79b9-cba3-49cb-9745-57e5b08c6322
STEP: Creating a pod to test consume secrets
Dec 21 03:15:41.673: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-02f3f567-cea6-4f4c-b164-b22673b570ec" in namespace "projected-5204" to be "success or failure"
Dec 21 03:15:41.677: INFO: Pod "pod-projected-secrets-02f3f567-cea6-4f4c-b164-b22673b570ec": Phase="Pending", Reason="", readiness=false. Elapsed: 3.608743ms
Dec 21 03:15:43.679: INFO: Pod "pod-projected-secrets-02f3f567-cea6-4f4c-b164-b22673b570ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006489123s
STEP: Saw pod success
Dec 21 03:15:43.679: INFO: Pod "pod-projected-secrets-02f3f567-cea6-4f4c-b164-b22673b570ec" satisfied condition "success or failure"
Dec 21 03:15:43.682: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-projected-secrets-02f3f567-cea6-4f4c-b164-b22673b570ec container secret-volume-test: <nil>
STEP: delete the pod
Dec 21 03:15:43.693: INFO: Waiting for pod pod-projected-secrets-02f3f567-cea6-4f4c-b164-b22673b570ec to disappear
Dec 21 03:15:43.696: INFO: Pod pod-projected-secrets-02f3f567-cea6-4f4c-b164-b22673b570ec no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:15:43.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5204" for this suite.
Dec 21 03:15:49.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:15:49.794: INFO: namespace projected-5204 deletion completed in 6.095929384s

â€¢ [SLOW TEST:8.158 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:15:49.796: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 21 03:15:49.841: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0cfd6810-b3c7-409f-bc5c-f4d88497eba6" in namespace "projected-6746" to be "success or failure"
Dec 21 03:15:49.847: INFO: Pod "downwardapi-volume-0cfd6810-b3c7-409f-bc5c-f4d88497eba6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.790778ms
Dec 21 03:15:51.850: INFO: Pod "downwardapi-volume-0cfd6810-b3c7-409f-bc5c-f4d88497eba6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008688898s
STEP: Saw pod success
Dec 21 03:15:51.850: INFO: Pod "downwardapi-volume-0cfd6810-b3c7-409f-bc5c-f4d88497eba6" satisfied condition "success or failure"
Dec 21 03:15:51.852: INFO: Trying to get logs from node ip-172-31-29-169 pod downwardapi-volume-0cfd6810-b3c7-409f-bc5c-f4d88497eba6 container client-container: <nil>
STEP: delete the pod
Dec 21 03:15:51.866: INFO: Waiting for pod downwardapi-volume-0cfd6810-b3c7-409f-bc5c-f4d88497eba6 to disappear
Dec 21 03:15:51.868: INFO: Pod downwardapi-volume-0cfd6810-b3c7-409f-bc5c-f4d88497eba6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:15:51.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6746" for this suite.
Dec 21 03:15:57.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:15:57.959: INFO: namespace projected-6746 deletion completed in 6.085138779s

â€¢ [SLOW TEST:8.163 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:15:57.959: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 21 03:15:58.040: INFO: Waiting up to 5m0s for pod "pod-ea7471b9-f29a-40e5-bfc0-639dd0b44821" in namespace "emptydir-171" to be "success or failure"
Dec 21 03:15:58.042: INFO: Pod "pod-ea7471b9-f29a-40e5-bfc0-639dd0b44821": Phase="Pending", Reason="", readiness=false. Elapsed: 2.594106ms
Dec 21 03:16:00.048: INFO: Pod "pod-ea7471b9-f29a-40e5-bfc0-639dd0b44821": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008450671s
STEP: Saw pod success
Dec 21 03:16:00.048: INFO: Pod "pod-ea7471b9-f29a-40e5-bfc0-639dd0b44821" satisfied condition "success or failure"
Dec 21 03:16:00.051: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-ea7471b9-f29a-40e5-bfc0-639dd0b44821 container test-container: <nil>
STEP: delete the pod
Dec 21 03:16:00.065: INFO: Waiting for pod pod-ea7471b9-f29a-40e5-bfc0-639dd0b44821 to disappear
Dec 21 03:16:00.069: INFO: Pod pod-ea7471b9-f29a-40e5-bfc0-639dd0b44821 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:16:00.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-171" for this suite.
Dec 21 03:16:06.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:16:06.155: INFO: namespace emptydir-171 deletion completed in 6.083631941s

â€¢ [SLOW TEST:8.196 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:16:06.155: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 21 03:16:08.700: INFO: Successfully updated pod "pod-update-activedeadlineseconds-2994dfca-8b8b-413e-ada0-0ab1e0e25633"
Dec 21 03:16:08.700: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-2994dfca-8b8b-413e-ada0-0ab1e0e25633" in namespace "pods-7147" to be "terminated due to deadline exceeded"
Dec 21 03:16:08.702: INFO: Pod "pod-update-activedeadlineseconds-2994dfca-8b8b-413e-ada0-0ab1e0e25633": Phase="Running", Reason="", readiness=true. Elapsed: 1.791446ms
Dec 21 03:16:10.705: INFO: Pod "pod-update-activedeadlineseconds-2994dfca-8b8b-413e-ada0-0ab1e0e25633": Phase="Running", Reason="", readiness=true. Elapsed: 2.004814201s
Dec 21 03:16:12.708: INFO: Pod "pod-update-activedeadlineseconds-2994dfca-8b8b-413e-ada0-0ab1e0e25633": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.007626337s
Dec 21 03:16:12.708: INFO: Pod "pod-update-activedeadlineseconds-2994dfca-8b8b-413e-ada0-0ab1e0e25633" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:16:12.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7147" for this suite.
Dec 21 03:16:18.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:16:18.799: INFO: namespace pods-7147 deletion completed in 6.087853079s

â€¢ [SLOW TEST:12.643 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:16:18.800: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:16:18.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6652" for this suite.
Dec 21 03:16:24.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:16:24.929: INFO: namespace resourcequota-6652 deletion completed in 6.084778583s

â€¢ [SLOW TEST:6.129 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:16:24.930: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 21 03:16:28.989: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 21 03:16:28.992: INFO: Pod pod-with-poststart-http-hook still exists
Dec 21 03:16:30.992: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 21 03:16:30.995: INFO: Pod pod-with-poststart-http-hook still exists
Dec 21 03:16:32.992: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 21 03:16:32.998: INFO: Pod pod-with-poststart-http-hook still exists
Dec 21 03:16:34.992: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 21 03:16:34.996: INFO: Pod pod-with-poststart-http-hook still exists
Dec 21 03:16:36.992: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 21 03:16:36.998: INFO: Pod pod-with-poststart-http-hook still exists
Dec 21 03:16:38.992: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 21 03:16:38.997: INFO: Pod pod-with-poststart-http-hook still exists
Dec 21 03:16:40.992: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 21 03:16:40.995: INFO: Pod pod-with-poststart-http-hook still exists
Dec 21 03:16:42.992: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 21 03:16:42.997: INFO: Pod pod-with-poststart-http-hook still exists
Dec 21 03:16:44.992: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 21 03:16:44.995: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:16:44.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7701" for this suite.
Dec 21 03:16:57.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:16:57.156: INFO: namespace container-lifecycle-hook-7701 deletion completed in 12.157403326s

â€¢ [SLOW TEST:32.226 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:16:57.156: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-d8f57ab9-54f0-4db4-be15-fefd6af23b2d
STEP: Creating a pod to test consume configMaps
Dec 21 03:16:57.199: INFO: Waiting up to 5m0s for pod "pod-configmaps-933cf1b7-79ea-43b8-b24e-9771716a0a55" in namespace "configmap-6390" to be "success or failure"
Dec 21 03:16:57.203: INFO: Pod "pod-configmaps-933cf1b7-79ea-43b8-b24e-9771716a0a55": Phase="Pending", Reason="", readiness=false. Elapsed: 4.51589ms
Dec 21 03:16:59.206: INFO: Pod "pod-configmaps-933cf1b7-79ea-43b8-b24e-9771716a0a55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007533974s
STEP: Saw pod success
Dec 21 03:16:59.206: INFO: Pod "pod-configmaps-933cf1b7-79ea-43b8-b24e-9771716a0a55" satisfied condition "success or failure"
Dec 21 03:16:59.208: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-configmaps-933cf1b7-79ea-43b8-b24e-9771716a0a55 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 03:16:59.234: INFO: Waiting for pod pod-configmaps-933cf1b7-79ea-43b8-b24e-9771716a0a55 to disappear
Dec 21 03:16:59.262: INFO: Pod pod-configmaps-933cf1b7-79ea-43b8-b24e-9771716a0a55 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:16:59.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6390" for this suite.
Dec 21 03:17:05.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:17:05.372: INFO: namespace configmap-6390 deletion completed in 6.096403684s

â€¢ [SLOW TEST:8.216 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:17:05.372: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec 21 03:17:05.403: INFO: Pod name pod-release: Found 0 pods out of 1
Dec 21 03:17:10.407: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:17:10.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1047" for this suite.
Dec 21 03:17:16.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:17:16.661: INFO: namespace replication-controller-1047 deletion completed in 6.210679167s

â€¢ [SLOW TEST:11.288 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:17:16.661: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-4f96e610-f883-4bb8-985a-2b159b2dea93
STEP: Creating a pod to test consume configMaps
Dec 21 03:17:16.705: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-59aa1d0a-aaac-4611-bba6-6f758ff5323f" in namespace "projected-9049" to be "success or failure"
Dec 21 03:17:16.712: INFO: Pod "pod-projected-configmaps-59aa1d0a-aaac-4611-bba6-6f758ff5323f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.773158ms
Dec 21 03:17:18.717: INFO: Pod "pod-projected-configmaps-59aa1d0a-aaac-4611-bba6-6f758ff5323f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012439729s
STEP: Saw pod success
Dec 21 03:17:18.717: INFO: Pod "pod-projected-configmaps-59aa1d0a-aaac-4611-bba6-6f758ff5323f" satisfied condition "success or failure"
Dec 21 03:17:18.721: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-projected-configmaps-59aa1d0a-aaac-4611-bba6-6f758ff5323f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 03:17:18.741: INFO: Waiting for pod pod-projected-configmaps-59aa1d0a-aaac-4611-bba6-6f758ff5323f to disappear
Dec 21 03:17:18.744: INFO: Pod pod-projected-configmaps-59aa1d0a-aaac-4611-bba6-6f758ff5323f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:17:18.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9049" for this suite.
Dec 21 03:17:24.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:17:24.855: INFO: namespace projected-9049 deletion completed in 6.102499241s

â€¢ [SLOW TEST:8.194 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:17:24.855: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Dec 21 03:17:26.956: INFO: Pod pod-hostip-f381b2ab-9184-4c40-9721-dbb6f186b0db has hostIP: 172.31.29.169
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:17:26.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1219" for this suite.
Dec 21 03:17:38.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:17:39.055: INFO: namespace pods-1219 deletion completed in 12.096221436s

â€¢ [SLOW TEST:14.200 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:17:39.056: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6909.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6909.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6909.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6909.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6909.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6909.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6909.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6909.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6909.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6909.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6909.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6909.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6909.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 2.67.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.67.2_udp@PTR;check="$$(dig +tcp +noall +answer +search 2.67.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.67.2_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6909.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6909.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6909.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6909.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6909.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6909.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6909.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6909.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6909.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6909.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6909.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6909.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6909.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 2.67.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.67.2_udp@PTR;check="$$(dig +tcp +noall +answer +search 2.67.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.67.2_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 21 03:17:43.121: INFO: Unable to read wheezy_udp@dns-test-service.dns-6909.svc.cluster.local from pod dns-6909/dns-test-ed97f4cc-ab65-4293-b90d-eb9b4b9d2782: the server could not find the requested resource (get pods dns-test-ed97f4cc-ab65-4293-b90d-eb9b4b9d2782)
Dec 21 03:17:43.123: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6909.svc.cluster.local from pod dns-6909/dns-test-ed97f4cc-ab65-4293-b90d-eb9b4b9d2782: the server could not find the requested resource (get pods dns-test-ed97f4cc-ab65-4293-b90d-eb9b4b9d2782)
Dec 21 03:17:43.125: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6909.svc.cluster.local from pod dns-6909/dns-test-ed97f4cc-ab65-4293-b90d-eb9b4b9d2782: the server could not find the requested resource (get pods dns-test-ed97f4cc-ab65-4293-b90d-eb9b4b9d2782)
Dec 21 03:17:43.128: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6909.svc.cluster.local from pod dns-6909/dns-test-ed97f4cc-ab65-4293-b90d-eb9b4b9d2782: the server could not find the requested resource (get pods dns-test-ed97f4cc-ab65-4293-b90d-eb9b4b9d2782)
Dec 21 03:17:43.152: INFO: Unable to read jessie_udp@dns-test-service.dns-6909.svc.cluster.local from pod dns-6909/dns-test-ed97f4cc-ab65-4293-b90d-eb9b4b9d2782: the server could not find the requested resource (get pods dns-test-ed97f4cc-ab65-4293-b90d-eb9b4b9d2782)
Dec 21 03:17:43.155: INFO: Unable to read jessie_tcp@dns-test-service.dns-6909.svc.cluster.local from pod dns-6909/dns-test-ed97f4cc-ab65-4293-b90d-eb9b4b9d2782: the server could not find the requested resource (get pods dns-test-ed97f4cc-ab65-4293-b90d-eb9b4b9d2782)
Dec 21 03:17:43.158: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6909.svc.cluster.local from pod dns-6909/dns-test-ed97f4cc-ab65-4293-b90d-eb9b4b9d2782: the server could not find the requested resource (get pods dns-test-ed97f4cc-ab65-4293-b90d-eb9b4b9d2782)
Dec 21 03:17:43.160: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6909.svc.cluster.local from pod dns-6909/dns-test-ed97f4cc-ab65-4293-b90d-eb9b4b9d2782: the server could not find the requested resource (get pods dns-test-ed97f4cc-ab65-4293-b90d-eb9b4b9d2782)
Dec 21 03:17:43.182: INFO: Lookups using dns-6909/dns-test-ed97f4cc-ab65-4293-b90d-eb9b4b9d2782 failed for: [wheezy_udp@dns-test-service.dns-6909.svc.cluster.local wheezy_tcp@dns-test-service.dns-6909.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6909.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6909.svc.cluster.local jessie_udp@dns-test-service.dns-6909.svc.cluster.local jessie_tcp@dns-test-service.dns-6909.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6909.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6909.svc.cluster.local]

Dec 21 03:17:48.247: INFO: DNS probes using dns-6909/dns-test-ed97f4cc-ab65-4293-b90d-eb9b4b9d2782 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:17:48.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6909" for this suite.
Dec 21 03:17:54.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:17:54.401: INFO: namespace dns-6909 deletion completed in 6.095764426s

â€¢ [SLOW TEST:15.345 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:17:54.401: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec 21 03:18:00.499: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1221 03:18:00.499004      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:18:00.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3667" for this suite.
Dec 21 03:18:06.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:18:06.597: INFO: namespace gc-3667 deletion completed in 6.095761204s

â€¢ [SLOW TEST:12.195 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:18:06.598: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 21 03:18:06.630: INFO: Waiting up to 5m0s for pod "pod-0dfc8019-dae9-4073-aada-3c3c76a0b25a" in namespace "emptydir-2804" to be "success or failure"
Dec 21 03:18:06.633: INFO: Pod "pod-0dfc8019-dae9-4073-aada-3c3c76a0b25a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.24793ms
Dec 21 03:18:08.638: INFO: Pod "pod-0dfc8019-dae9-4073-aada-3c3c76a0b25a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008265684s
STEP: Saw pod success
Dec 21 03:18:08.638: INFO: Pod "pod-0dfc8019-dae9-4073-aada-3c3c76a0b25a" satisfied condition "success or failure"
Dec 21 03:18:08.640: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-0dfc8019-dae9-4073-aada-3c3c76a0b25a container test-container: <nil>
STEP: delete the pod
Dec 21 03:18:08.655: INFO: Waiting for pod pod-0dfc8019-dae9-4073-aada-3c3c76a0b25a to disappear
Dec 21 03:18:08.658: INFO: Pod pod-0dfc8019-dae9-4073-aada-3c3c76a0b25a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:18:08.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2804" for this suite.
Dec 21 03:18:14.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:18:14.757: INFO: namespace emptydir-2804 deletion completed in 6.096559445s

â€¢ [SLOW TEST:8.160 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:18:14.757: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 03:18:14.787: INFO: Waiting up to 5m0s for pod "busybox-user-65534-ef2262c9-ea4a-4d0d-b6cd-ac229154bdb7" in namespace "security-context-test-308" to be "success or failure"
Dec 21 03:18:14.790: INFO: Pod "busybox-user-65534-ef2262c9-ea4a-4d0d-b6cd-ac229154bdb7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.085228ms
Dec 21 03:18:16.793: INFO: Pod "busybox-user-65534-ef2262c9-ea4a-4d0d-b6cd-ac229154bdb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006114551s
Dec 21 03:18:16.793: INFO: Pod "busybox-user-65534-ef2262c9-ea4a-4d0d-b6cd-ac229154bdb7" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:18:16.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-308" for this suite.
Dec 21 03:18:22.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:18:22.894: INFO: namespace security-context-test-308 deletion completed in 6.097493273s

â€¢ [SLOW TEST:8.137 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:18:22.894: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 21 03:18:26.955: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 21 03:18:26.957: INFO: Pod pod-with-prestop-http-hook still exists
Dec 21 03:18:28.958: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 21 03:18:28.963: INFO: Pod pod-with-prestop-http-hook still exists
Dec 21 03:18:30.958: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 21 03:18:30.961: INFO: Pod pod-with-prestop-http-hook still exists
Dec 21 03:18:32.958: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 21 03:18:32.961: INFO: Pod pod-with-prestop-http-hook still exists
Dec 21 03:18:34.958: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 21 03:18:34.961: INFO: Pod pod-with-prestop-http-hook still exists
Dec 21 03:18:36.958: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 21 03:18:36.961: INFO: Pod pod-with-prestop-http-hook still exists
Dec 21 03:18:38.958: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 21 03:18:38.960: INFO: Pod pod-with-prestop-http-hook still exists
Dec 21 03:18:40.958: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 21 03:18:40.961: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:18:40.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4684" for this suite.
Dec 21 03:18:52.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:18:53.060: INFO: namespace container-lifecycle-hook-4684 deletion completed in 12.090694147s

â€¢ [SLOW TEST:30.166 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:18:53.060: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 03:18:53.085: INFO: Creating ReplicaSet my-hostname-basic-0044a896-87d4-442a-882c-ac907e5355ee
Dec 21 03:18:53.090: INFO: Pod name my-hostname-basic-0044a896-87d4-442a-882c-ac907e5355ee: Found 0 pods out of 1
Dec 21 03:18:58.094: INFO: Pod name my-hostname-basic-0044a896-87d4-442a-882c-ac907e5355ee: Found 1 pods out of 1
Dec 21 03:18:58.094: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-0044a896-87d4-442a-882c-ac907e5355ee" is running
Dec 21 03:18:58.096: INFO: Pod "my-hostname-basic-0044a896-87d4-442a-882c-ac907e5355ee-2dsqv" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-21 03:18:53 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-21 03:18:54 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-21 03:18:54 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-21 03:18:53 +0000 UTC Reason: Message:}])
Dec 21 03:18:58.096: INFO: Trying to dial the pod
Dec 21 03:19:03.106: INFO: Controller my-hostname-basic-0044a896-87d4-442a-882c-ac907e5355ee: Got expected result from replica 1 [my-hostname-basic-0044a896-87d4-442a-882c-ac907e5355ee-2dsqv]: "my-hostname-basic-0044a896-87d4-442a-882c-ac907e5355ee-2dsqv", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:19:03.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3082" for this suite.
Dec 21 03:19:09.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:19:09.200: INFO: namespace replicaset-3082 deletion completed in 6.092241314s

â€¢ [SLOW TEST:16.140 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:19:09.201: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-m8ddz in namespace proxy-6520
I1221 03:19:09.237109      22 runners.go:184] Created replication controller with name: proxy-service-m8ddz, namespace: proxy-6520, replica count: 1
I1221 03:19:10.287551      22 runners.go:184] proxy-service-m8ddz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1221 03:19:11.287808      22 runners.go:184] proxy-service-m8ddz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1221 03:19:12.288081      22 runners.go:184] proxy-service-m8ddz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1221 03:19:13.288368      22 runners.go:184] proxy-service-m8ddz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1221 03:19:14.288657      22 runners.go:184] proxy-service-m8ddz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1221 03:19:15.288922      22 runners.go:184] proxy-service-m8ddz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1221 03:19:16.289245      22 runners.go:184] proxy-service-m8ddz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1221 03:19:17.289544      22 runners.go:184] proxy-service-m8ddz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1221 03:19:18.289807      22 runners.go:184] proxy-service-m8ddz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1221 03:19:19.290071      22 runners.go:184] proxy-service-m8ddz Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 21 03:19:19.292: INFO: setup took 10.068494144s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec 21 03:19:19.315: INFO: (0) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 21.734536ms)
Dec 21 03:19:19.316: INFO: (0) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname1/proxy/: foo (200; 22.784523ms)
Dec 21 03:19:19.315: INFO: (0) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 22.071285ms)
Dec 21 03:19:19.315: INFO: (0) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 21.980405ms)
Dec 21 03:19:19.316: INFO: (0) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/rewriteme">test</a> (200; 22.364304ms)
Dec 21 03:19:19.316: INFO: (0) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 22.063074ms)
Dec 21 03:19:19.316: INFO: (0) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">test<... (200; 21.827629ms)
Dec 21 03:19:19.317: INFO: (0) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:462/proxy/: tls qux (200; 24.194421ms)
Dec 21 03:19:19.318: INFO: (0) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname1/proxy/: foo (200; 24.958815ms)
Dec 21 03:19:19.318: INFO: (0) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname2/proxy/: bar (200; 24.652735ms)
Dec 21 03:19:19.319: INFO: (0) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname2/proxy/: bar (200; 25.523876ms)
Dec 21 03:19:19.321: INFO: (0) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/tlsrewritem... (200; 28.039151ms)
Dec 21 03:19:19.321: INFO: (0) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">... (200; 27.467851ms)
Dec 21 03:19:19.324: INFO: (0) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname2/proxy/: tls qux (200; 31.235027ms)
Dec 21 03:19:19.325: INFO: (0) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:460/proxy/: tls baz (200; 32.419595ms)
Dec 21 03:19:19.326: INFO: (0) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname1/proxy/: tls baz (200; 31.786144ms)
Dec 21 03:19:19.342: INFO: (1) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/tlsrewritem... (200; 15.571409ms)
Dec 21 03:19:19.343: INFO: (1) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">test<... (200; 16.820486ms)
Dec 21 03:19:19.343: INFO: (1) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:460/proxy/: tls baz (200; 16.423697ms)
Dec 21 03:19:19.343: INFO: (1) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 16.377612ms)
Dec 21 03:19:19.343: INFO: (1) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 16.590352ms)
Dec 21 03:19:19.344: INFO: (1) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 17.109041ms)
Dec 21 03:19:19.344: INFO: (1) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/rewriteme">test</a> (200; 17.694128ms)
Dec 21 03:19:19.344: INFO: (1) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname1/proxy/: tls baz (200; 18.669412ms)
Dec 21 03:19:19.349: INFO: (1) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">... (200; 22.15221ms)
Dec 21 03:19:19.349: INFO: (1) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname2/proxy/: bar (200; 22.434178ms)
Dec 21 03:19:19.350: INFO: (1) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname1/proxy/: foo (200; 23.890057ms)
Dec 21 03:19:19.351: INFO: (1) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname2/proxy/: tls qux (200; 24.87111ms)
Dec 21 03:19:19.351: INFO: (1) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:462/proxy/: tls qux (200; 24.485096ms)
Dec 21 03:19:19.351: INFO: (1) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname1/proxy/: foo (200; 25.238289ms)
Dec 21 03:19:19.352: INFO: (1) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname2/proxy/: bar (200; 25.369071ms)
Dec 21 03:19:19.352: INFO: (1) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 26.613538ms)
Dec 21 03:19:19.361: INFO: (2) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 8.365349ms)
Dec 21 03:19:19.366: INFO: (2) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 12.748733ms)
Dec 21 03:19:19.367: INFO: (2) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 14.472044ms)
Dec 21 03:19:19.368: INFO: (2) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 15.112029ms)
Dec 21 03:19:19.371: INFO: (2) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname1/proxy/: foo (200; 18.166625ms)
Dec 21 03:19:19.372: INFO: (2) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:460/proxy/: tls baz (200; 18.980552ms)
Dec 21 03:19:19.373: INFO: (2) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname2/proxy/: bar (200; 20.37885ms)
Dec 21 03:19:19.373: INFO: (2) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:462/proxy/: tls qux (200; 20.501483ms)
Dec 21 03:19:19.375: INFO: (2) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/tlsrewritem... (200; 21.958915ms)
Dec 21 03:19:19.375: INFO: (2) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">test<... (200; 22.548429ms)
Dec 21 03:19:19.376: INFO: (2) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname1/proxy/: foo (200; 23.828323ms)
Dec 21 03:19:19.377: INFO: (2) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">... (200; 24.193821ms)
Dec 21 03:19:19.380: INFO: (2) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname1/proxy/: tls baz (200; 27.45188ms)
Dec 21 03:19:19.380: INFO: (2) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/rewriteme">test</a> (200; 27.416542ms)
Dec 21 03:19:19.380: INFO: (2) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname2/proxy/: bar (200; 27.591185ms)
Dec 21 03:19:19.385: INFO: (2) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname2/proxy/: tls qux (200; 32.895543ms)
Dec 21 03:19:19.396: INFO: (3) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:462/proxy/: tls qux (200; 10.064581ms)
Dec 21 03:19:19.396: INFO: (3) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/tlsrewritem... (200; 10.46372ms)
Dec 21 03:19:19.396: INFO: (3) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 10.146079ms)
Dec 21 03:19:19.396: INFO: (3) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 10.344975ms)
Dec 21 03:19:19.398: INFO: (3) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 11.855511ms)
Dec 21 03:19:19.399: INFO: (3) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:460/proxy/: tls baz (200; 12.866256ms)
Dec 21 03:19:19.399: INFO: (3) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 13.34202ms)
Dec 21 03:19:19.399: INFO: (3) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/rewriteme">test</a> (200; 13.210679ms)
Dec 21 03:19:19.402: INFO: (3) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname2/proxy/: bar (200; 16.207897ms)
Dec 21 03:19:19.403: INFO: (3) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname2/proxy/: bar (200; 16.754979ms)
Dec 21 03:19:19.404: INFO: (3) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">test<... (200; 17.479983ms)
Dec 21 03:19:19.404: INFO: (3) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname1/proxy/: tls baz (200; 17.980333ms)
Dec 21 03:19:19.405: INFO: (3) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname1/proxy/: foo (200; 19.432112ms)
Dec 21 03:19:19.408: INFO: (3) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname1/proxy/: foo (200; 22.094704ms)
Dec 21 03:19:19.409: INFO: (3) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">... (200; 22.386225ms)
Dec 21 03:19:19.409: INFO: (3) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname2/proxy/: tls qux (200; 22.698827ms)
Dec 21 03:19:19.417: INFO: (4) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">... (200; 8.323371ms)
Dec 21 03:19:19.418: INFO: (4) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/rewriteme">test</a> (200; 8.505286ms)
Dec 21 03:19:19.418: INFO: (4) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:460/proxy/: tls baz (200; 8.534511ms)
Dec 21 03:19:19.418: INFO: (4) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 8.895588ms)
Dec 21 03:19:19.421: INFO: (4) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 11.919442ms)
Dec 21 03:19:19.426: INFO: (4) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname1/proxy/: foo (200; 16.570626ms)
Dec 21 03:19:19.426: INFO: (4) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname2/proxy/: bar (200; 16.544161ms)
Dec 21 03:19:19.429: INFO: (4) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:462/proxy/: tls qux (200; 19.287266ms)
Dec 21 03:19:19.430: INFO: (4) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname2/proxy/: tls qux (200; 20.477544ms)
Dec 21 03:19:19.432: INFO: (4) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname1/proxy/: foo (200; 22.165991ms)
Dec 21 03:19:19.433: INFO: (4) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname2/proxy/: bar (200; 23.950402ms)
Dec 21 03:19:19.434: INFO: (4) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 24.821832ms)
Dec 21 03:19:19.435: INFO: (4) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/tlsrewritem... (200; 26.062898ms)
Dec 21 03:19:19.437: INFO: (4) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 27.465875ms)
Dec 21 03:19:19.437: INFO: (4) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname1/proxy/: tls baz (200; 27.803767ms)
Dec 21 03:19:19.437: INFO: (4) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">test<... (200; 28.020153ms)
Dec 21 03:19:19.448: INFO: (5) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:462/proxy/: tls qux (200; 10.63586ms)
Dec 21 03:19:19.451: INFO: (5) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 13.248837ms)
Dec 21 03:19:19.452: INFO: (5) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/rewriteme">test</a> (200; 13.762522ms)
Dec 21 03:19:19.452: INFO: (5) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 13.803792ms)
Dec 21 03:19:19.452: INFO: (5) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:460/proxy/: tls baz (200; 14.317863ms)
Dec 21 03:19:19.452: INFO: (5) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 14.5342ms)
Dec 21 03:19:19.454: INFO: (5) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 16.005563ms)
Dec 21 03:19:19.455: INFO: (5) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/tlsrewritem... (200; 16.272921ms)
Dec 21 03:19:19.458: INFO: (5) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">test<... (200; 19.242537ms)
Dec 21 03:19:19.460: INFO: (5) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname1/proxy/: foo (200; 21.23425ms)
Dec 21 03:19:19.461: INFO: (5) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname2/proxy/: tls qux (200; 23.35109ms)
Dec 21 03:19:19.463: INFO: (5) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname2/proxy/: bar (200; 24.854823ms)
Dec 21 03:19:19.463: INFO: (5) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname1/proxy/: tls baz (200; 24.733304ms)
Dec 21 03:19:19.463: INFO: (5) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname2/proxy/: bar (200; 25.369459ms)
Dec 21 03:19:19.463: INFO: (5) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname1/proxy/: foo (200; 24.705331ms)
Dec 21 03:19:19.463: INFO: (5) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">... (200; 25.352574ms)
Dec 21 03:19:19.475: INFO: (6) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:460/proxy/: tls baz (200; 11.076953ms)
Dec 21 03:19:19.475: INFO: (6) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 10.767651ms)
Dec 21 03:19:19.478: INFO: (6) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/rewriteme">test</a> (200; 14.629309ms)
Dec 21 03:19:19.480: INFO: (6) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">test<... (200; 15.789514ms)
Dec 21 03:19:19.482: INFO: (6) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">... (200; 17.693763ms)
Dec 21 03:19:19.482: INFO: (6) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:462/proxy/: tls qux (200; 18.00201ms)
Dec 21 03:19:19.484: INFO: (6) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname2/proxy/: bar (200; 20.422163ms)
Dec 21 03:19:19.490: INFO: (6) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 25.831484ms)
Dec 21 03:19:19.490: INFO: (6) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 25.896102ms)
Dec 21 03:19:19.490: INFO: (6) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 26.166854ms)
Dec 21 03:19:19.491: INFO: (6) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname1/proxy/: foo (200; 25.949479ms)
Dec 21 03:19:19.491: INFO: (6) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname1/proxy/: foo (200; 26.51926ms)
Dec 21 03:19:19.491: INFO: (6) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname2/proxy/: tls qux (200; 27.823413ms)
Dec 21 03:19:19.491: INFO: (6) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname1/proxy/: tls baz (200; 27.132146ms)
Dec 21 03:19:19.492: INFO: (6) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/tlsrewritem... (200; 28.061952ms)
Dec 21 03:19:19.493: INFO: (6) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname2/proxy/: bar (200; 29.15302ms)
Dec 21 03:19:19.504: INFO: (7) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 10.41728ms)
Dec 21 03:19:19.504: INFO: (7) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 10.863704ms)
Dec 21 03:19:19.504: INFO: (7) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname1/proxy/: foo (200; 11.103373ms)
Dec 21 03:19:19.505: INFO: (7) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:462/proxy/: tls qux (200; 11.161705ms)
Dec 21 03:19:19.513: INFO: (7) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname1/proxy/: tls baz (200; 18.601413ms)
Dec 21 03:19:19.513: INFO: (7) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 19.074043ms)
Dec 21 03:19:19.514: INFO: (7) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:460/proxy/: tls baz (200; 20.434144ms)
Dec 21 03:19:19.514: INFO: (7) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/rewriteme">test</a> (200; 21.009327ms)
Dec 21 03:19:19.516: INFO: (7) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname2/proxy/: bar (200; 22.683078ms)
Dec 21 03:19:19.516: INFO: (7) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">test<... (200; 21.673067ms)
Dec 21 03:19:19.519: INFO: (7) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">... (200; 26.031857ms)
Dec 21 03:19:19.520: INFO: (7) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname2/proxy/: tls qux (200; 25.461237ms)
Dec 21 03:19:19.520: INFO: (7) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 26.52372ms)
Dec 21 03:19:19.520: INFO: (7) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname1/proxy/: foo (200; 25.753841ms)
Dec 21 03:19:19.520: INFO: (7) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/tlsrewritem... (200; 26.071036ms)
Dec 21 03:19:19.520: INFO: (7) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname2/proxy/: bar (200; 25.984797ms)
Dec 21 03:19:19.532: INFO: (8) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 11.940367ms)
Dec 21 03:19:19.533: INFO: (8) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 12.833873ms)
Dec 21 03:19:19.534: INFO: (8) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 13.569169ms)
Dec 21 03:19:19.535: INFO: (8) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">test<... (200; 14.718976ms)
Dec 21 03:19:19.539: INFO: (8) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname1/proxy/: foo (200; 19.005682ms)
Dec 21 03:19:19.539: INFO: (8) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:460/proxy/: tls baz (200; 19.155094ms)
Dec 21 03:19:19.540: INFO: (8) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:462/proxy/: tls qux (200; 20.204283ms)
Dec 21 03:19:19.542: INFO: (8) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/rewriteme">test</a> (200; 21.711132ms)
Dec 21 03:19:19.542: INFO: (8) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 22.051824ms)
Dec 21 03:19:19.544: INFO: (8) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname2/proxy/: bar (200; 23.554756ms)
Dec 21 03:19:19.545: INFO: (8) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname1/proxy/: foo (200; 24.3441ms)
Dec 21 03:19:19.546: INFO: (8) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">... (200; 25.288795ms)
Dec 21 03:19:19.547: INFO: (8) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname2/proxy/: tls qux (200; 26.739733ms)
Dec 21 03:19:19.547: INFO: (8) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/tlsrewritem... (200; 27.261599ms)
Dec 21 03:19:19.548: INFO: (8) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname2/proxy/: bar (200; 27.296835ms)
Dec 21 03:19:19.548: INFO: (8) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname1/proxy/: tls baz (200; 27.55771ms)
Dec 21 03:19:19.554: INFO: (9) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/tlsrewritem... (200; 5.931302ms)
Dec 21 03:19:19.556: INFO: (9) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:460/proxy/: tls baz (200; 8.10343ms)
Dec 21 03:19:19.559: INFO: (9) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">test<... (200; 10.139891ms)
Dec 21 03:19:19.560: INFO: (9) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:462/proxy/: tls qux (200; 11.308309ms)
Dec 21 03:19:19.560: INFO: (9) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 11.636745ms)
Dec 21 03:19:19.564: INFO: (9) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/rewriteme">test</a> (200; 15.228087ms)
Dec 21 03:19:19.567: INFO: (9) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname2/proxy/: bar (200; 18.59516ms)
Dec 21 03:19:19.568: INFO: (9) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname1/proxy/: tls baz (200; 19.644513ms)
Dec 21 03:19:19.570: INFO: (9) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 21.074819ms)
Dec 21 03:19:19.570: INFO: (9) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname2/proxy/: bar (200; 21.582623ms)
Dec 21 03:19:19.571: INFO: (9) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname1/proxy/: foo (200; 22.268346ms)
Dec 21 03:19:19.572: INFO: (9) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname1/proxy/: foo (200; 23.547926ms)
Dec 21 03:19:19.574: INFO: (9) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname2/proxy/: tls qux (200; 25.077584ms)
Dec 21 03:19:19.575: INFO: (9) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 26.001876ms)
Dec 21 03:19:19.575: INFO: (9) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 26.937698ms)
Dec 21 03:19:19.576: INFO: (9) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">... (200; 26.816059ms)
Dec 21 03:19:19.589: INFO: (10) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/tlsrewritem... (200; 13.094858ms)
Dec 21 03:19:19.592: INFO: (10) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 16.389248ms)
Dec 21 03:19:19.593: INFO: (10) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 16.881418ms)
Dec 21 03:19:19.593: INFO: (10) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 16.897057ms)
Dec 21 03:19:19.593: INFO: (10) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:460/proxy/: tls baz (200; 16.421975ms)
Dec 21 03:19:19.593: INFO: (10) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">test<... (200; 16.77895ms)
Dec 21 03:19:19.595: INFO: (10) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname2/proxy/: bar (200; 19.061042ms)
Dec 21 03:19:19.598: INFO: (10) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname1/proxy/: foo (200; 21.824808ms)
Dec 21 03:19:19.598: INFO: (10) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname2/proxy/: tls qux (200; 21.73212ms)
Dec 21 03:19:19.600: INFO: (10) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">... (200; 23.324157ms)
Dec 21 03:19:19.601: INFO: (10) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname1/proxy/: tls baz (200; 24.355868ms)
Dec 21 03:19:19.601: INFO: (10) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname2/proxy/: bar (200; 24.414499ms)
Dec 21 03:19:19.604: INFO: (10) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/rewriteme">test</a> (200; 27.569421ms)
Dec 21 03:19:19.605: INFO: (10) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:462/proxy/: tls qux (200; 28.628866ms)
Dec 21 03:19:19.607: INFO: (10) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname1/proxy/: foo (200; 30.944972ms)
Dec 21 03:19:19.607: INFO: (10) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 31.303121ms)
Dec 21 03:19:19.616: INFO: (11) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/tlsrewritem... (200; 8.752828ms)
Dec 21 03:19:19.617: INFO: (11) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 8.661293ms)
Dec 21 03:19:19.618: INFO: (11) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 10.071729ms)
Dec 21 03:19:19.622: INFO: (11) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">test<... (200; 13.91995ms)
Dec 21 03:19:19.627: INFO: (11) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname1/proxy/: tls baz (200; 18.500948ms)
Dec 21 03:19:19.627: INFO: (11) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname1/proxy/: foo (200; 19.58882ms)
Dec 21 03:19:19.627: INFO: (11) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname2/proxy/: tls qux (200; 19.578181ms)
Dec 21 03:19:19.628: INFO: (11) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 20.235287ms)
Dec 21 03:19:19.629: INFO: (11) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/rewriteme">test</a> (200; 20.676888ms)
Dec 21 03:19:19.629: INFO: (11) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname2/proxy/: bar (200; 21.27555ms)
Dec 21 03:19:19.630: INFO: (11) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">... (200; 21.423885ms)
Dec 21 03:19:19.630: INFO: (11) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:460/proxy/: tls baz (200; 22.082611ms)
Dec 21 03:19:19.632: INFO: (11) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:462/proxy/: tls qux (200; 23.926674ms)
Dec 21 03:19:19.633: INFO: (11) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 24.596818ms)
Dec 21 03:19:19.633: INFO: (11) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname1/proxy/: foo (200; 25.42745ms)
Dec 21 03:19:19.635: INFO: (11) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname2/proxy/: bar (200; 27.505174ms)
Dec 21 03:19:19.650: INFO: (12) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">test<... (200; 13.659179ms)
Dec 21 03:19:19.652: INFO: (12) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname2/proxy/: tls qux (200; 15.470396ms)
Dec 21 03:19:19.654: INFO: (12) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 17.554368ms)
Dec 21 03:19:19.654: INFO: (12) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/rewriteme">test</a> (200; 17.95574ms)
Dec 21 03:19:19.654: INFO: (12) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/tlsrewritem... (200; 17.547959ms)
Dec 21 03:19:19.656: INFO: (12) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:460/proxy/: tls baz (200; 20.569651ms)
Dec 21 03:19:19.657: INFO: (12) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">... (200; 20.752501ms)
Dec 21 03:19:19.658: INFO: (12) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname2/proxy/: bar (200; 21.633783ms)
Dec 21 03:19:19.658: INFO: (12) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname1/proxy/: foo (200; 21.398197ms)
Dec 21 03:19:19.659: INFO: (12) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname2/proxy/: bar (200; 22.660727ms)
Dec 21 03:19:19.663: INFO: (12) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 27.347304ms)
Dec 21 03:19:19.663: INFO: (12) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 26.294728ms)
Dec 21 03:19:19.664: INFO: (12) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname1/proxy/: tls baz (200; 27.339062ms)
Dec 21 03:19:19.665: INFO: (12) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:462/proxy/: tls qux (200; 28.79369ms)
Dec 21 03:19:19.666: INFO: (12) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname1/proxy/: foo (200; 28.968992ms)
Dec 21 03:19:19.666: INFO: (12) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 30.00326ms)
Dec 21 03:19:19.672: INFO: (13) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/tlsrewritem... (200; 5.74426ms)
Dec 21 03:19:19.686: INFO: (13) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 18.608554ms)
Dec 21 03:19:19.686: INFO: (13) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">test<... (200; 19.195943ms)
Dec 21 03:19:19.686: INFO: (13) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:462/proxy/: tls qux (200; 19.820046ms)
Dec 21 03:19:19.687: INFO: (13) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 19.829716ms)
Dec 21 03:19:19.687: INFO: (13) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname1/proxy/: foo (200; 19.654036ms)
Dec 21 03:19:19.688: INFO: (13) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname1/proxy/: foo (200; 20.484287ms)
Dec 21 03:19:19.689: INFO: (13) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname2/proxy/: bar (200; 22.069483ms)
Dec 21 03:19:19.689: INFO: (13) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname1/proxy/: tls baz (200; 22.372033ms)
Dec 21 03:19:19.690: INFO: (13) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname2/proxy/: tls qux (200; 22.163643ms)
Dec 21 03:19:19.691: INFO: (13) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname2/proxy/: bar (200; 23.788616ms)
Dec 21 03:19:19.692: INFO: (13) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/rewriteme">test</a> (200; 24.077942ms)
Dec 21 03:19:19.692: INFO: (13) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 24.725073ms)
Dec 21 03:19:19.692: INFO: (13) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">... (200; 24.742954ms)
Dec 21 03:19:19.692: INFO: (13) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 25.543047ms)
Dec 21 03:19:19.693: INFO: (13) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:460/proxy/: tls baz (200; 26.243982ms)
Dec 21 03:19:19.707: INFO: (14) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 13.771029ms)
Dec 21 03:19:19.707: INFO: (14) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">... (200; 14.102811ms)
Dec 21 03:19:19.707: INFO: (14) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 14.114636ms)
Dec 21 03:19:19.709: INFO: (14) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">test<... (200; 15.516591ms)
Dec 21 03:19:19.709: INFO: (14) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/tlsrewritem... (200; 16.615292ms)
Dec 21 03:19:19.712: INFO: (14) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:462/proxy/: tls qux (200; 18.546392ms)
Dec 21 03:19:19.712: INFO: (14) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/rewriteme">test</a> (200; 18.500808ms)
Dec 21 03:19:19.714: INFO: (14) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:460/proxy/: tls baz (200; 20.44734ms)
Dec 21 03:19:19.715: INFO: (14) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname2/proxy/: tls qux (200; 21.539725ms)
Dec 21 03:19:19.715: INFO: (14) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname1/proxy/: foo (200; 22.176038ms)
Dec 21 03:19:19.716: INFO: (14) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname2/proxy/: bar (200; 23.38363ms)
Dec 21 03:19:19.717: INFO: (14) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 23.848805ms)
Dec 21 03:19:19.717: INFO: (14) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname1/proxy/: tls baz (200; 23.834176ms)
Dec 21 03:19:19.717: INFO: (14) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 24.06924ms)
Dec 21 03:19:19.717: INFO: (14) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname1/proxy/: foo (200; 24.441115ms)
Dec 21 03:19:19.719: INFO: (14) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname2/proxy/: bar (200; 25.313556ms)
Dec 21 03:19:19.730: INFO: (15) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 11.350014ms)
Dec 21 03:19:19.731: INFO: (15) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 11.952791ms)
Dec 21 03:19:19.732: INFO: (15) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 12.591325ms)
Dec 21 03:19:19.732: INFO: (15) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname2/proxy/: bar (200; 13.221296ms)
Dec 21 03:19:19.732: INFO: (15) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/tlsrewritem... (200; 13.029793ms)
Dec 21 03:19:19.733: INFO: (15) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:460/proxy/: tls baz (200; 12.584648ms)
Dec 21 03:19:19.733: INFO: (15) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">test<... (200; 13.909557ms)
Dec 21 03:19:19.733: INFO: (15) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:462/proxy/: tls qux (200; 13.206357ms)
Dec 21 03:19:19.735: INFO: (15) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 15.507473ms)
Dec 21 03:19:19.737: INFO: (15) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/rewriteme">test</a> (200; 16.716936ms)
Dec 21 03:19:19.737: INFO: (15) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname1/proxy/: foo (200; 17.147569ms)
Dec 21 03:19:19.740: INFO: (15) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname1/proxy/: foo (200; 20.215875ms)
Dec 21 03:19:19.741: INFO: (15) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname1/proxy/: tls baz (200; 21.139263ms)
Dec 21 03:19:19.741: INFO: (15) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname2/proxy/: tls qux (200; 21.141058ms)
Dec 21 03:19:19.741: INFO: (15) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">... (200; 21.488262ms)
Dec 21 03:19:19.742: INFO: (15) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname2/proxy/: bar (200; 22.493842ms)
Dec 21 03:19:19.756: INFO: (16) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 13.531221ms)
Dec 21 03:19:19.758: INFO: (16) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname2/proxy/: tls qux (200; 15.7477ms)
Dec 21 03:19:19.758: INFO: (16) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">test<... (200; 15.736876ms)
Dec 21 03:19:19.760: INFO: (16) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 17.104599ms)
Dec 21 03:19:19.761: INFO: (16) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 17.692791ms)
Dec 21 03:19:19.762: INFO: (16) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:462/proxy/: tls qux (200; 19.663073ms)
Dec 21 03:19:19.765: INFO: (16) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname1/proxy/: tls baz (200; 22.640012ms)
Dec 21 03:19:19.766: INFO: (16) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:460/proxy/: tls baz (200; 23.429459ms)
Dec 21 03:19:19.766: INFO: (16) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/rewriteme">test</a> (200; 23.690966ms)
Dec 21 03:19:19.766: INFO: (16) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/tlsrewritem... (200; 24.322428ms)
Dec 21 03:19:19.767: INFO: (16) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname2/proxy/: bar (200; 23.879944ms)
Dec 21 03:19:19.767: INFO: (16) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 24.283975ms)
Dec 21 03:19:19.768: INFO: (16) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname1/proxy/: foo (200; 25.724861ms)
Dec 21 03:19:19.768: INFO: (16) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname1/proxy/: foo (200; 25.745721ms)
Dec 21 03:19:19.770: INFO: (16) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">... (200; 27.981202ms)
Dec 21 03:19:19.772: INFO: (16) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname2/proxy/: bar (200; 28.992997ms)
Dec 21 03:19:19.785: INFO: (17) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">test<... (200; 12.700829ms)
Dec 21 03:19:19.786: INFO: (17) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/tlsrewritem... (200; 13.394457ms)
Dec 21 03:19:19.788: INFO: (17) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/rewriteme">test</a> (200; 15.744797ms)
Dec 21 03:19:19.789: INFO: (17) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:460/proxy/: tls baz (200; 16.42533ms)
Dec 21 03:19:19.789: INFO: (17) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname1/proxy/: foo (200; 16.572878ms)
Dec 21 03:19:19.790: INFO: (17) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">... (200; 17.613783ms)
Dec 21 03:19:19.792: INFO: (17) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname2/proxy/: bar (200; 20.08296ms)
Dec 21 03:19:19.795: INFO: (17) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname2/proxy/: tls qux (200; 22.229281ms)
Dec 21 03:19:19.795: INFO: (17) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 22.411154ms)
Dec 21 03:19:19.795: INFO: (17) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 22.432347ms)
Dec 21 03:19:19.795: INFO: (17) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname1/proxy/: foo (200; 23.054092ms)
Dec 21 03:19:19.797: INFO: (17) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname1/proxy/: tls baz (200; 24.671399ms)
Dec 21 03:19:19.799: INFO: (17) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:462/proxy/: tls qux (200; 26.478589ms)
Dec 21 03:19:19.799: INFO: (17) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 26.420211ms)
Dec 21 03:19:19.799: INFO: (17) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 26.406636ms)
Dec 21 03:19:19.800: INFO: (17) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname2/proxy/: bar (200; 27.237648ms)
Dec 21 03:19:19.815: INFO: (18) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 14.134084ms)
Dec 21 03:19:19.815: INFO: (18) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 14.446398ms)
Dec 21 03:19:19.815: INFO: (18) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 14.620862ms)
Dec 21 03:19:19.816: INFO: (18) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/tlsrewritem... (200; 15.560564ms)
Dec 21 03:19:19.817: INFO: (18) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:460/proxy/: tls baz (200; 16.596763ms)
Dec 21 03:19:19.817: INFO: (18) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:462/proxy/: tls qux (200; 16.635772ms)
Dec 21 03:19:19.818: INFO: (18) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">... (200; 17.162936ms)
Dec 21 03:19:19.818: INFO: (18) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/rewriteme">test</a> (200; 17.749022ms)
Dec 21 03:19:19.819: INFO: (18) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 18.709438ms)
Dec 21 03:19:19.819: INFO: (18) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">test<... (200; 18.872386ms)
Dec 21 03:19:19.821: INFO: (18) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname2/proxy/: tls qux (200; 20.273534ms)
Dec 21 03:19:19.822: INFO: (18) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname1/proxy/: tls baz (200; 22.308482ms)
Dec 21 03:19:19.823: INFO: (18) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname1/proxy/: foo (200; 22.645824ms)
Dec 21 03:19:19.825: INFO: (18) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname1/proxy/: foo (200; 24.604151ms)
Dec 21 03:19:19.826: INFO: (18) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname2/proxy/: bar (200; 25.002159ms)
Dec 21 03:19:19.826: INFO: (18) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname2/proxy/: bar (200; 25.479221ms)
Dec 21 03:19:19.835: INFO: (19) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 9.115675ms)
Dec 21 03:19:19.840: INFO: (19) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:443/proxy/tlsrewritem... (200; 13.40852ms)
Dec 21 03:19:19.840: INFO: (19) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:162/proxy/: bar (200; 13.801256ms)
Dec 21 03:19:19.842: INFO: (19) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 15.484314ms)
Dec 21 03:19:19.842: INFO: (19) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:160/proxy/: foo (200; 15.909971ms)
Dec 21 03:19:19.842: INFO: (19) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname1/proxy/: tls baz (200; 15.87238ms)
Dec 21 03:19:19.843: INFO: (19) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:460/proxy/: tls baz (200; 15.610941ms)
Dec 21 03:19:19.843: INFO: (19) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">test<... (200; 16.602496ms)
Dec 21 03:19:19.848: INFO: (19) /api/v1/namespaces/proxy-6520/pods/https:proxy-service-m8ddz-hzh5r:462/proxy/: tls qux (200; 21.131364ms)
Dec 21 03:19:19.849: INFO: (19) /api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/proxy-service-m8ddz-hzh5r/proxy/rewriteme">test</a> (200; 22.050811ms)
Dec 21 03:19:19.849: INFO: (19) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname2/proxy/: bar (200; 23.057445ms)
Dec 21 03:19:19.849: INFO: (19) /api/v1/namespaces/proxy-6520/services/http:proxy-service-m8ddz:portname1/proxy/: foo (200; 22.635179ms)
Dec 21 03:19:19.849: INFO: (19) /api/v1/namespaces/proxy-6520/services/https:proxy-service-m8ddz:tlsportname2/proxy/: tls qux (200; 22.636394ms)
Dec 21 03:19:19.850: INFO: (19) /api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/: <a href="/api/v1/namespaces/proxy-6520/pods/http:proxy-service-m8ddz-hzh5r:1080/proxy/rewriteme">... (200; 22.408062ms)
Dec 21 03:19:19.850: INFO: (19) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname1/proxy/: foo (200; 23.238334ms)
Dec 21 03:19:19.851: INFO: (19) /api/v1/namespaces/proxy-6520/services/proxy-service-m8ddz:portname2/proxy/: bar (200; 24.428287ms)
STEP: deleting ReplicationController proxy-service-m8ddz in namespace proxy-6520, will wait for the garbage collector to delete the pods
Dec 21 03:19:19.910: INFO: Deleting ReplicationController proxy-service-m8ddz took: 5.995772ms
Dec 21 03:19:20.310: INFO: Terminating ReplicationController proxy-service-m8ddz pods took: 400.24431ms
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:19:21.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6520" for this suite.
Dec 21 03:19:27.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:19:27.857: INFO: namespace proxy-6520 deletion completed in 6.143430067s

â€¢ [SLOW TEST:18.657 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:19:27.857: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Dec 21 03:19:28.944: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1221 03:19:28.944747      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:19:28.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8657" for this suite.
Dec 21 03:19:34.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:19:35.036: INFO: namespace gc-8657 deletion completed in 6.089610386s

â€¢ [SLOW TEST:7.179 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:19:35.037: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 21 03:19:35.078: INFO: Create a RollingUpdate DaemonSet
Dec 21 03:19:35.081: INFO: Check that daemon pods launch on every node of the cluster
Dec 21 03:19:35.086: INFO: Number of nodes with available pods: 0
Dec 21 03:19:35.086: INFO: Node ip-172-31-25-252 is running more than one daemon pod
Dec 21 03:19:36.091: INFO: Number of nodes with available pods: 0
Dec 21 03:19:36.091: INFO: Node ip-172-31-25-252 is running more than one daemon pod
Dec 21 03:19:37.092: INFO: Number of nodes with available pods: 2
Dec 21 03:19:37.092: INFO: Node ip-172-31-29-141 is running more than one daemon pod
Dec 21 03:19:38.092: INFO: Number of nodes with available pods: 3
Dec 21 03:19:38.092: INFO: Number of running nodes: 3, number of available pods: 3
Dec 21 03:19:38.092: INFO: Update the DaemonSet to trigger a rollout
Dec 21 03:19:38.099: INFO: Updating DaemonSet daemon-set
Dec 21 03:19:52.112: INFO: Roll back the DaemonSet before rollout is complete
Dec 21 03:19:52.117: INFO: Updating DaemonSet daemon-set
Dec 21 03:19:52.117: INFO: Make sure DaemonSet rollback is complete
Dec 21 03:19:52.122: INFO: Wrong image for pod: daemon-set-vwhsz. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 21 03:19:52.122: INFO: Pod daemon-set-vwhsz is not available
Dec 21 03:19:53.129: INFO: Wrong image for pod: daemon-set-vwhsz. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 21 03:19:53.129: INFO: Pod daemon-set-vwhsz is not available
Dec 21 03:19:54.129: INFO: Wrong image for pod: daemon-set-vwhsz. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 21 03:19:54.129: INFO: Pod daemon-set-vwhsz is not available
Dec 21 03:19:55.129: INFO: Wrong image for pod: daemon-set-vwhsz. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 21 03:19:55.129: INFO: Pod daemon-set-vwhsz is not available
Dec 21 03:19:56.129: INFO: Pod daemon-set-hpjtf is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8175, will wait for the garbage collector to delete the pods
Dec 21 03:19:56.193: INFO: Deleting DaemonSet.extensions daemon-set took: 5.370966ms
Dec 21 03:19:56.594: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.260213ms
Dec 21 03:20:09.397: INFO: Number of nodes with available pods: 0
Dec 21 03:20:09.397: INFO: Number of running nodes: 0, number of available pods: 0
Dec 21 03:20:09.400: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8175/daemonsets","resourceVersion":"24727"},"items":null}

Dec 21 03:20:09.402: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8175/pods","resourceVersion":"24727"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:20:09.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8175" for this suite.
Dec 21 03:20:15.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:20:15.504: INFO: namespace daemonsets-8175 deletion completed in 6.089674954s

â€¢ [SLOW TEST:40.468 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:20:15.505: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-e734f015-5f7b-4f51-b2bc-15cbfb84b4a9
STEP: Creating a pod to test consume configMaps
Dec 21 03:20:15.538: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5d0f3517-afbe-4997-9c4b-52ee8e80b42f" in namespace "projected-9806" to be "success or failure"
Dec 21 03:20:15.545: INFO: Pod "pod-projected-configmaps-5d0f3517-afbe-4997-9c4b-52ee8e80b42f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.165348ms
Dec 21 03:20:17.548: INFO: Pod "pod-projected-configmaps-5d0f3517-afbe-4997-9c4b-52ee8e80b42f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010499972s
STEP: Saw pod success
Dec 21 03:20:17.548: INFO: Pod "pod-projected-configmaps-5d0f3517-afbe-4997-9c4b-52ee8e80b42f" satisfied condition "success or failure"
Dec 21 03:20:17.550: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-projected-configmaps-5d0f3517-afbe-4997-9c4b-52ee8e80b42f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 03:20:17.593: INFO: Waiting for pod pod-projected-configmaps-5d0f3517-afbe-4997-9c4b-52ee8e80b42f to disappear
Dec 21 03:20:17.596: INFO: Pod pod-projected-configmaps-5d0f3517-afbe-4997-9c4b-52ee8e80b42f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:20:17.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9806" for this suite.
Dec 21 03:20:23.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:20:23.686: INFO: namespace projected-9806 deletion completed in 6.08762573s

â€¢ [SLOW TEST:8.181 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:20:23.686: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2906.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-2906.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2906.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2906.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-2906.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-2906.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-2906.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-2906.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2906.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2906.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-2906.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2906.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-2906.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-2906.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-2906.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-2906.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-2906.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2906.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 21 03:20:25.735: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-2906.svc.cluster.local from pod dns-2906/dns-test-06feb774-725e-40e2-9fb0-81c9dee91b12: the server could not find the requested resource (get pods dns-test-06feb774-725e-40e2-9fb0-81c9dee91b12)
Dec 21 03:20:25.738: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2906.svc.cluster.local from pod dns-2906/dns-test-06feb774-725e-40e2-9fb0-81c9dee91b12: the server could not find the requested resource (get pods dns-test-06feb774-725e-40e2-9fb0-81c9dee91b12)
Dec 21 03:20:25.740: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-2906.svc.cluster.local from pod dns-2906/dns-test-06feb774-725e-40e2-9fb0-81c9dee91b12: the server could not find the requested resource (get pods dns-test-06feb774-725e-40e2-9fb0-81c9dee91b12)
Dec 21 03:20:25.743: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-2906.svc.cluster.local from pod dns-2906/dns-test-06feb774-725e-40e2-9fb0-81c9dee91b12: the server could not find the requested resource (get pods dns-test-06feb774-725e-40e2-9fb0-81c9dee91b12)
Dec 21 03:20:25.752: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-2906.svc.cluster.local from pod dns-2906/dns-test-06feb774-725e-40e2-9fb0-81c9dee91b12: the server could not find the requested resource (get pods dns-test-06feb774-725e-40e2-9fb0-81c9dee91b12)
Dec 21 03:20:25.755: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-2906.svc.cluster.local from pod dns-2906/dns-test-06feb774-725e-40e2-9fb0-81c9dee91b12: the server could not find the requested resource (get pods dns-test-06feb774-725e-40e2-9fb0-81c9dee91b12)
Dec 21 03:20:25.757: INFO: Unable to read jessie_udp@dns-test-service-2.dns-2906.svc.cluster.local from pod dns-2906/dns-test-06feb774-725e-40e2-9fb0-81c9dee91b12: the server could not find the requested resource (get pods dns-test-06feb774-725e-40e2-9fb0-81c9dee91b12)
Dec 21 03:20:25.760: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-2906.svc.cluster.local from pod dns-2906/dns-test-06feb774-725e-40e2-9fb0-81c9dee91b12: the server could not find the requested resource (get pods dns-test-06feb774-725e-40e2-9fb0-81c9dee91b12)
Dec 21 03:20:25.766: INFO: Lookups using dns-2906/dns-test-06feb774-725e-40e2-9fb0-81c9dee91b12 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-2906.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2906.svc.cluster.local wheezy_udp@dns-test-service-2.dns-2906.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-2906.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-2906.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-2906.svc.cluster.local jessie_udp@dns-test-service-2.dns-2906.svc.cluster.local jessie_tcp@dns-test-service-2.dns-2906.svc.cluster.local]

Dec 21 03:20:30.801: INFO: DNS probes using dns-2906/dns-test-06feb774-725e-40e2-9fb0-81c9dee91b12 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:20:30.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2906" for this suite.
Dec 21 03:20:36.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:20:36.965: INFO: namespace dns-2906 deletion completed in 6.102111345s

â€¢ [SLOW TEST:13.278 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:20:36.965: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-f9sq
STEP: Creating a pod to test atomic-volume-subpath
Dec 21 03:20:37.001: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-f9sq" in namespace "subpath-1546" to be "success or failure"
Dec 21 03:20:37.009: INFO: Pod "pod-subpath-test-configmap-f9sq": Phase="Pending", Reason="", readiness=false. Elapsed: 7.926257ms
Dec 21 03:20:39.012: INFO: Pod "pod-subpath-test-configmap-f9sq": Phase="Running", Reason="", readiness=true. Elapsed: 2.011353555s
Dec 21 03:20:41.015: INFO: Pod "pod-subpath-test-configmap-f9sq": Phase="Running", Reason="", readiness=true. Elapsed: 4.0145849s
Dec 21 03:20:43.019: INFO: Pod "pod-subpath-test-configmap-f9sq": Phase="Running", Reason="", readiness=true. Elapsed: 6.01789861s
Dec 21 03:20:45.022: INFO: Pod "pod-subpath-test-configmap-f9sq": Phase="Running", Reason="", readiness=true. Elapsed: 8.021567024s
Dec 21 03:20:47.025: INFO: Pod "pod-subpath-test-configmap-f9sq": Phase="Running", Reason="", readiness=true. Elapsed: 10.024690579s
Dec 21 03:20:49.028: INFO: Pod "pod-subpath-test-configmap-f9sq": Phase="Running", Reason="", readiness=true. Elapsed: 12.027808875s
Dec 21 03:20:51.032: INFO: Pod "pod-subpath-test-configmap-f9sq": Phase="Running", Reason="", readiness=true. Elapsed: 14.031120823s
Dec 21 03:20:53.035: INFO: Pod "pod-subpath-test-configmap-f9sq": Phase="Running", Reason="", readiness=true. Elapsed: 16.034318736s
Dec 21 03:20:55.038: INFO: Pod "pod-subpath-test-configmap-f9sq": Phase="Running", Reason="", readiness=true. Elapsed: 18.037575207s
Dec 21 03:20:57.041: INFO: Pod "pod-subpath-test-configmap-f9sq": Phase="Running", Reason="", readiness=true. Elapsed: 20.040756434s
Dec 21 03:20:59.045: INFO: Pod "pod-subpath-test-configmap-f9sq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.043979156s
STEP: Saw pod success
Dec 21 03:20:59.045: INFO: Pod "pod-subpath-test-configmap-f9sq" satisfied condition "success or failure"
Dec 21 03:20:59.047: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-subpath-test-configmap-f9sq container test-container-subpath-configmap-f9sq: <nil>
STEP: delete the pod
Dec 21 03:20:59.060: INFO: Waiting for pod pod-subpath-test-configmap-f9sq to disappear
Dec 21 03:20:59.063: INFO: Pod pod-subpath-test-configmap-f9sq no longer exists
STEP: Deleting pod pod-subpath-test-configmap-f9sq
Dec 21 03:20:59.063: INFO: Deleting pod "pod-subpath-test-configmap-f9sq" in namespace "subpath-1546"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:20:59.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1546" for this suite.
Dec 21 03:21:05.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:21:05.161: INFO: namespace subpath-1546 deletion completed in 6.091872524s

â€¢ [SLOW TEST:28.196 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:21:05.161: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-ff198f5a-2288-4b49-a259-807dcfba3afa
STEP: Creating a pod to test consume secrets
Dec 21 03:21:05.192: INFO: Waiting up to 5m0s for pod "pod-secrets-1b85733c-c78a-4e9f-a4e4-4a0537292a3b" in namespace "secrets-281" to be "success or failure"
Dec 21 03:21:05.194: INFO: Pod "pod-secrets-1b85733c-c78a-4e9f-a4e4-4a0537292a3b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.592005ms
Dec 21 03:21:07.197: INFO: Pod "pod-secrets-1b85733c-c78a-4e9f-a4e4-4a0537292a3b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005514112s
STEP: Saw pod success
Dec 21 03:21:07.197: INFO: Pod "pod-secrets-1b85733c-c78a-4e9f-a4e4-4a0537292a3b" satisfied condition "success or failure"
Dec 21 03:21:07.200: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-secrets-1b85733c-c78a-4e9f-a4e4-4a0537292a3b container secret-volume-test: <nil>
STEP: delete the pod
Dec 21 03:21:07.212: INFO: Waiting for pod pod-secrets-1b85733c-c78a-4e9f-a4e4-4a0537292a3b to disappear
Dec 21 03:21:07.218: INFO: Pod pod-secrets-1b85733c-c78a-4e9f-a4e4-4a0537292a3b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:21:07.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-281" for this suite.
Dec 21 03:21:13.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:21:13.306: INFO: namespace secrets-281 deletion completed in 6.086065622s

â€¢ [SLOW TEST:8.145 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:21:13.307: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:21:29.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4248" for this suite.
Dec 21 03:21:35.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:21:35.490: INFO: namespace resourcequota-4248 deletion completed in 6.088820401s

â€¢ [SLOW TEST:22.184 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:21:35.491: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-19f4cf21-d3be-4498-af66-b47c70af6367
STEP: Creating configMap with name cm-test-opt-upd-8a28dad6-b232-4aa0-93ab-fbe2812f85fd
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-19f4cf21-d3be-4498-af66-b47c70af6367
STEP: Updating configmap cm-test-opt-upd-8a28dad6-b232-4aa0-93ab-fbe2812f85fd
STEP: Creating configMap with name cm-test-opt-create-41b04be3-f378-4a36-ba62-b8067e4c524d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:23:05.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9165" for this suite.
Dec 21 03:23:21.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:23:21.965: INFO: namespace projected-9165 deletion completed in 16.102825296s

â€¢ [SLOW TEST:106.474 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:23:21.966: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 21 03:23:21.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-4251'
Dec 21 03:23:22.810: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 21 03:23:22.810: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Dec 21 03:23:24.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-448192630 delete deployment e2e-test-httpd-deployment --namespace=kubectl-4251'
Dec 21 03:23:24.903: INFO: stderr: ""
Dec 21 03:23:24.903: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:23:24.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4251" for this suite.
Dec 21 03:23:30.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:23:30.994: INFO: namespace kubectl-4251 deletion completed in 6.088339213s

â€¢ [SLOW TEST:9.028 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:23:30.995: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 21 03:23:31.023: INFO: Waiting up to 5m0s for pod "pod-db860567-047a-4995-98ba-dc506421a0b3" in namespace "emptydir-2572" to be "success or failure"
Dec 21 03:23:31.026: INFO: Pod "pod-db860567-047a-4995-98ba-dc506421a0b3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.552266ms
Dec 21 03:23:33.029: INFO: Pod "pod-db860567-047a-4995-98ba-dc506421a0b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005764675s
STEP: Saw pod success
Dec 21 03:23:33.029: INFO: Pod "pod-db860567-047a-4995-98ba-dc506421a0b3" satisfied condition "success or failure"
Dec 21 03:23:33.031: INFO: Trying to get logs from node ip-172-31-29-169 pod pod-db860567-047a-4995-98ba-dc506421a0b3 container test-container: <nil>
STEP: delete the pod
Dec 21 03:23:33.043: INFO: Waiting for pod pod-db860567-047a-4995-98ba-dc506421a0b3 to disappear
Dec 21 03:23:33.046: INFO: Pod pod-db860567-047a-4995-98ba-dc506421a0b3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:23:33.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2572" for this suite.
Dec 21 03:23:39.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:23:39.161: INFO: namespace emptydir-2572 deletion completed in 6.112713636s

â€¢ [SLOW TEST:8.166 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 21 03:23:39.162: INFO: >>> kubeConfig: /tmp/kubeconfig-448192630
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-269d0973-3158-471c-91d0-b54e4eeef71d
STEP: Creating secret with name s-test-opt-upd-352c9799-afe1-46f2-af47-9f48e2034664
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-269d0973-3158-471c-91d0-b54e4eeef71d
STEP: Updating secret s-test-opt-upd-352c9799-afe1-46f2-af47-9f48e2034664
STEP: Creating secret with name s-test-opt-create-4ae09a14-6a0c-4c94-a453-4596c52c69b2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 21 03:25:03.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8152" for this suite.
Dec 21 03:25:21.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 21 03:25:21.727: INFO: namespace secrets-8152 deletion completed in 18.181003842s

â€¢ [SLOW TEST:102.566 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSDec 21 03:25:21.728: INFO: Running AfterSuite actions on all nodes
Dec 21 03:25:21.729: INFO: Running AfterSuite actions on node 1
Dec 21 03:25:21.729: INFO: Skipping dumping logs from cluster

Ran 276 of 4732 Specs in 7204.704 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Pending | 4456 Skipped
PASS

Ginkgo ran 1 suite in 2h0m6.035204903s
Test Suite Passed
