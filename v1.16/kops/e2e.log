I1217 00:17:07.344484      21 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-505434119
I1217 00:17:07.344597      21 e2e.go:92] Starting e2e run "c6f75d64-3cfd-47fa-88d4-00a930d4d054" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1576541825 - Will randomize all specs
Will run 276 of 4732 specs

Dec 17 00:17:07.355: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
Dec 17 00:17:07.357: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec 17 00:17:07.370: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec 17 00:17:07.401: INFO: 13 / 13 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec 17 00:17:07.401: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Dec 17 00:17:07.401: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec 17 00:17:07.410: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'kops-controller' (0 seconds elapsed)
Dec 17 00:17:07.410: INFO: e2e test version: v1.16.3
Dec 17 00:17:07.411: INFO: kube-apiserver version: v1.16.3
Dec 17 00:17:07.411: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
Dec 17 00:17:07.415: INFO: Cluster IP family: ipv4
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:17:07.415: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename custom-resource-definition
Dec 17 00:17:07.438: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 00:17:07.440: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:17:08.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1981" for this suite.
Dec 17 00:17:14.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:17:14.139: INFO: namespace custom-resource-definition-1981 deletion completed in 6.067105323s

â€¢ [SLOW TEST:6.724 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:17:14.140: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 00:17:14.170: INFO: (0) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 10.44192ms)
Dec 17 00:17:14.172: INFO: (1) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.510103ms)
Dec 17 00:17:14.174: INFO: (2) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.087586ms)
Dec 17 00:17:14.177: INFO: (3) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.224514ms)
Dec 17 00:17:14.179: INFO: (4) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.280481ms)
Dec 17 00:17:14.181: INFO: (5) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.315545ms)
Dec 17 00:17:14.183: INFO: (6) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.082185ms)
Dec 17 00:17:14.185: INFO: (7) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.157851ms)
Dec 17 00:17:14.190: INFO: (8) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.628739ms)
Dec 17 00:17:14.193: INFO: (9) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.757501ms)
Dec 17 00:17:14.195: INFO: (10) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.107246ms)
Dec 17 00:17:14.197: INFO: (11) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.229627ms)
Dec 17 00:17:14.200: INFO: (12) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.273875ms)
Dec 17 00:17:14.202: INFO: (13) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.20344ms)
Dec 17 00:17:14.204: INFO: (14) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.166464ms)
Dec 17 00:17:14.206: INFO: (15) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.172807ms)
Dec 17 00:17:14.209: INFO: (16) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.845716ms)
Dec 17 00:17:14.212: INFO: (17) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.903342ms)
Dec 17 00:17:14.214: INFO: (18) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.217121ms)
Dec 17 00:17:14.217: INFO: (19) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.227168ms)
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:17:14.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3479" for this suite.
Dec 17 00:17:20.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:17:20.275: INFO: namespace proxy-3479 deletion completed in 6.056682019s

â€¢ [SLOW TEST:6.136 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:17:20.276: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Dec 17 00:17:20.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 create -f - --namespace=kubectl-5162'
Dec 17 00:17:20.644: INFO: stderr: ""
Dec 17 00:17:20.645: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 17 00:17:20.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5162'
Dec 17 00:17:20.731: INFO: stderr: ""
Dec 17 00:17:20.731: INFO: stdout: "update-demo-nautilus-789vz update-demo-nautilus-qchvb "
Dec 17 00:17:20.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-nautilus-789vz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5162'
Dec 17 00:17:20.800: INFO: stderr: ""
Dec 17 00:17:20.800: INFO: stdout: ""
Dec 17 00:17:20.800: INFO: update-demo-nautilus-789vz is created but not running
Dec 17 00:17:25.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5162'
Dec 17 00:17:25.873: INFO: stderr: ""
Dec 17 00:17:25.873: INFO: stdout: "update-demo-nautilus-789vz update-demo-nautilus-qchvb "
Dec 17 00:17:25.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-nautilus-789vz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5162'
Dec 17 00:17:25.940: INFO: stderr: ""
Dec 17 00:17:25.940: INFO: stdout: "true"
Dec 17 00:17:25.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-nautilus-789vz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5162'
Dec 17 00:17:26.018: INFO: stderr: ""
Dec 17 00:17:26.018: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 00:17:26.018: INFO: validating pod update-demo-nautilus-789vz
Dec 17 00:17:26.022: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 00:17:26.022: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 00:17:26.022: INFO: update-demo-nautilus-789vz is verified up and running
Dec 17 00:17:26.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-nautilus-qchvb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5162'
Dec 17 00:17:26.091: INFO: stderr: ""
Dec 17 00:17:26.091: INFO: stdout: "true"
Dec 17 00:17:26.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-nautilus-qchvb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5162'
Dec 17 00:17:26.160: INFO: stderr: ""
Dec 17 00:17:26.160: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 00:17:26.160: INFO: validating pod update-demo-nautilus-qchvb
Dec 17 00:17:26.164: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 00:17:26.164: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 00:17:26.164: INFO: update-demo-nautilus-qchvb is verified up and running
STEP: rolling-update to new replication controller
Dec 17 00:17:26.165: INFO: scanned /root for discovery docs: <nil>
Dec 17 00:17:26.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-5162'
Dec 17 00:17:48.472: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 17 00:17:48.473: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 17 00:17:48.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5162'
Dec 17 00:17:48.544: INFO: stderr: ""
Dec 17 00:17:48.544: INFO: stdout: "update-demo-kitten-kvgrm update-demo-kitten-mjhmq "
Dec 17 00:17:48.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-kitten-kvgrm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5162'
Dec 17 00:17:48.614: INFO: stderr: ""
Dec 17 00:17:48.614: INFO: stdout: "true"
Dec 17 00:17:48.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-kitten-kvgrm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5162'
Dec 17 00:17:48.683: INFO: stderr: ""
Dec 17 00:17:48.683: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 17 00:17:48.683: INFO: validating pod update-demo-kitten-kvgrm
Dec 17 00:17:48.686: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 17 00:17:48.686: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 17 00:17:48.686: INFO: update-demo-kitten-kvgrm is verified up and running
Dec 17 00:17:48.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-kitten-mjhmq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5162'
Dec 17 00:17:48.755: INFO: stderr: ""
Dec 17 00:17:48.755: INFO: stdout: "true"
Dec 17 00:17:48.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-kitten-mjhmq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5162'
Dec 17 00:17:48.824: INFO: stderr: ""
Dec 17 00:17:48.824: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 17 00:17:48.824: INFO: validating pod update-demo-kitten-mjhmq
Dec 17 00:17:48.827: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 17 00:17:48.827: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 17 00:17:48.827: INFO: update-demo-kitten-mjhmq is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:17:48.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5162" for this suite.
Dec 17 00:18:12.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:18:12.892: INFO: namespace kubectl-5162 deletion completed in 24.062846735s

â€¢ [SLOW TEST:52.616 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:18:12.893: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-150ee3ce-16eb-4c16-a377-d2e622d68c7d
STEP: Creating a pod to test consume configMaps
Dec 17 00:18:12.922: INFO: Waiting up to 5m0s for pod "pod-configmaps-8401bef9-2a82-4b3a-b413-d8156727f086" in namespace "configmap-1363" to be "success or failure"
Dec 17 00:18:12.925: INFO: Pod "pod-configmaps-8401bef9-2a82-4b3a-b413-d8156727f086": Phase="Pending", Reason="", readiness=false. Elapsed: 2.100151ms
Dec 17 00:18:14.927: INFO: Pod "pod-configmaps-8401bef9-2a82-4b3a-b413-d8156727f086": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004437743s
Dec 17 00:18:16.930: INFO: Pod "pod-configmaps-8401bef9-2a82-4b3a-b413-d8156727f086": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007588226s
STEP: Saw pod success
Dec 17 00:18:16.930: INFO: Pod "pod-configmaps-8401bef9-2a82-4b3a-b413-d8156727f086" satisfied condition "success or failure"
Dec 17 00:18:16.932: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-configmaps-8401bef9-2a82-4b3a-b413-d8156727f086 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 00:18:16.955: INFO: Waiting for pod pod-configmaps-8401bef9-2a82-4b3a-b413-d8156727f086 to disappear
Dec 17 00:18:16.962: INFO: Pod pod-configmaps-8401bef9-2a82-4b3a-b413-d8156727f086 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:18:16.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1363" for this suite.
Dec 17 00:18:22.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:18:23.037: INFO: namespace configmap-1363 deletion completed in 6.072271353s

â€¢ [SLOW TEST:10.144 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:18:23.037: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:18:39.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9253" for this suite.
Dec 17 00:18:45.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:18:45.215: INFO: namespace resourcequota-9253 deletion completed in 6.091194247s

â€¢ [SLOW TEST:22.177 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:18:45.215: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 00:18:45.237: INFO: Creating ReplicaSet my-hostname-basic-1b9ca6a9-d438-4f10-8173-73f0996e2737
Dec 17 00:18:45.243: INFO: Pod name my-hostname-basic-1b9ca6a9-d438-4f10-8173-73f0996e2737: Found 0 pods out of 1
Dec 17 00:18:50.245: INFO: Pod name my-hostname-basic-1b9ca6a9-d438-4f10-8173-73f0996e2737: Found 1 pods out of 1
Dec 17 00:18:50.245: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-1b9ca6a9-d438-4f10-8173-73f0996e2737" is running
Dec 17 00:18:50.246: INFO: Pod "my-hostname-basic-1b9ca6a9-d438-4f10-8173-73f0996e2737-6fqs8" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-17 00:18:45 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-17 00:18:50 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-17 00:18:50 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-17 00:18:45 +0000 UTC Reason: Message:}])
Dec 17 00:18:50.246: INFO: Trying to dial the pod
Dec 17 00:18:55.260: INFO: Controller my-hostname-basic-1b9ca6a9-d438-4f10-8173-73f0996e2737: Got expected result from replica 1 [my-hostname-basic-1b9ca6a9-d438-4f10-8173-73f0996e2737-6fqs8]: "my-hostname-basic-1b9ca6a9-d438-4f10-8173-73f0996e2737-6fqs8", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:18:55.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7995" for this suite.
Dec 17 00:19:01.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:19:01.321: INFO: namespace replicaset-7995 deletion completed in 6.057835749s

â€¢ [SLOW TEST:16.105 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:19:01.321: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-6qml
STEP: Creating a pod to test atomic-volume-subpath
Dec 17 00:19:01.348: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-6qml" in namespace "subpath-475" to be "success or failure"
Dec 17 00:19:01.350: INFO: Pod "pod-subpath-test-configmap-6qml": Phase="Pending", Reason="", readiness=false. Elapsed: 1.960009ms
Dec 17 00:19:03.352: INFO: Pod "pod-subpath-test-configmap-6qml": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004562848s
Dec 17 00:19:05.355: INFO: Pod "pod-subpath-test-configmap-6qml": Phase="Running", Reason="", readiness=true. Elapsed: 4.007356041s
Dec 17 00:19:07.358: INFO: Pod "pod-subpath-test-configmap-6qml": Phase="Running", Reason="", readiness=true. Elapsed: 6.010349961s
Dec 17 00:19:09.368: INFO: Pod "pod-subpath-test-configmap-6qml": Phase="Running", Reason="", readiness=true. Elapsed: 8.019960944s
Dec 17 00:19:11.371: INFO: Pod "pod-subpath-test-configmap-6qml": Phase="Running", Reason="", readiness=true. Elapsed: 10.022984526s
Dec 17 00:19:13.374: INFO: Pod "pod-subpath-test-configmap-6qml": Phase="Running", Reason="", readiness=true. Elapsed: 12.026084842s
Dec 17 00:19:15.376: INFO: Pod "pod-subpath-test-configmap-6qml": Phase="Running", Reason="", readiness=true. Elapsed: 14.028460582s
Dec 17 00:19:17.380: INFO: Pod "pod-subpath-test-configmap-6qml": Phase="Running", Reason="", readiness=true. Elapsed: 16.031813055s
Dec 17 00:19:19.383: INFO: Pod "pod-subpath-test-configmap-6qml": Phase="Running", Reason="", readiness=true. Elapsed: 18.035149793s
Dec 17 00:19:21.386: INFO: Pod "pod-subpath-test-configmap-6qml": Phase="Running", Reason="", readiness=true. Elapsed: 20.038377597s
Dec 17 00:19:23.388: INFO: Pod "pod-subpath-test-configmap-6qml": Phase="Running", Reason="", readiness=true. Elapsed: 22.04050519s
Dec 17 00:19:25.391: INFO: Pod "pod-subpath-test-configmap-6qml": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.042986179s
STEP: Saw pod success
Dec 17 00:19:25.391: INFO: Pod "pod-subpath-test-configmap-6qml" satisfied condition "success or failure"
Dec 17 00:19:25.393: INFO: Trying to get logs from node ip-172-20-34-147.us-east-2.compute.internal pod pod-subpath-test-configmap-6qml container test-container-subpath-configmap-6qml: <nil>
STEP: delete the pod
Dec 17 00:19:25.418: INFO: Waiting for pod pod-subpath-test-configmap-6qml to disappear
Dec 17 00:19:25.420: INFO: Pod pod-subpath-test-configmap-6qml no longer exists
STEP: Deleting pod pod-subpath-test-configmap-6qml
Dec 17 00:19:25.420: INFO: Deleting pod "pod-subpath-test-configmap-6qml" in namespace "subpath-475"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:19:25.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-475" for this suite.
Dec 17 00:19:31.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:19:31.503: INFO: namespace subpath-475 deletion completed in 6.078000933s

â€¢ [SLOW TEST:30.182 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:19:31.503: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 00:19:37.553: INFO: Waiting up to 5m0s for pod "client-envvars-58e14561-b401-425e-b3d8-129b999861ec" in namespace "pods-6077" to be "success or failure"
Dec 17 00:19:37.560: INFO: Pod "client-envvars-58e14561-b401-425e-b3d8-129b999861ec": Phase="Pending", Reason="", readiness=false. Elapsed: 6.699558ms
Dec 17 00:19:39.563: INFO: Pod "client-envvars-58e14561-b401-425e-b3d8-129b999861ec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009726844s
Dec 17 00:19:41.568: INFO: Pod "client-envvars-58e14561-b401-425e-b3d8-129b999861ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014639478s
STEP: Saw pod success
Dec 17 00:19:41.568: INFO: Pod "client-envvars-58e14561-b401-425e-b3d8-129b999861ec" satisfied condition "success or failure"
Dec 17 00:19:41.570: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod client-envvars-58e14561-b401-425e-b3d8-129b999861ec container env3cont: <nil>
STEP: delete the pod
Dec 17 00:19:41.587: INFO: Waiting for pod client-envvars-58e14561-b401-425e-b3d8-129b999861ec to disappear
Dec 17 00:19:41.589: INFO: Pod client-envvars-58e14561-b401-425e-b3d8-129b999861ec no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:19:41.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6077" for this suite.
Dec 17 00:19:53.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:19:53.664: INFO: namespace pods-6077 deletion completed in 12.072775714s

â€¢ [SLOW TEST:22.161 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:19:53.664: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 17 00:19:53.684: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 17 00:19:53.690: INFO: Waiting for terminating namespaces to be deleted...
Dec 17 00:19:53.692: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-34-147.us-east-2.compute.internal before test
Dec 17 00:19:53.696: INFO: sonobuoy-systemd-logs-daemon-set-aa23d16e52f14f6e-l6lh6 from sonobuoy started at 2019-12-17 00:16:40 +0000 UTC (2 container statuses recorded)
Dec 17 00:19:53.696: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 17 00:19:53.696: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 17 00:19:53.696: INFO: kube-proxy-ip-172-20-34-147.us-east-2.compute.internal from kube-system started at 2019-12-17 00:10:42 +0000 UTC (1 container statuses recorded)
Dec 17 00:19:53.696: INFO: 	Container kube-proxy ready: true, restart count 5
Dec 17 00:19:53.696: INFO: kube-dns-bb55d6458-qz7ks from kube-system started at 2019-12-17 00:15:20 +0000 UTC (3 container statuses recorded)
Dec 17 00:19:53.696: INFO: 	Container dnsmasq ready: true, restart count 0
Dec 17 00:19:53.696: INFO: 	Container kubedns ready: true, restart count 0
Dec 17 00:19:53.696: INFO: 	Container sidecar ready: true, restart count 0
Dec 17 00:19:53.696: INFO: sonobuoy from sonobuoy started at 2019-12-17 00:16:34 +0000 UTC (1 container statuses recorded)
Dec 17 00:19:53.696: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 17 00:19:53.696: INFO: sonobuoy-e2e-job-edd513b56d7b4d93 from sonobuoy started at 2019-12-17 00:16:40 +0000 UTC (2 container statuses recorded)
Dec 17 00:19:53.696: INFO: 	Container e2e ready: true, restart count 0
Dec 17 00:19:53.696: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 17 00:19:53.696: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-58-188.us-east-2.compute.internal before test
Dec 17 00:19:53.700: INFO: sonobuoy-systemd-logs-daemon-set-aa23d16e52f14f6e-dk4ms from sonobuoy started at 2019-12-17 00:16:40 +0000 UTC (2 container statuses recorded)
Dec 17 00:19:53.700: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 17 00:19:53.700: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 17 00:19:53.700: INFO: kube-proxy-ip-172-20-58-188.us-east-2.compute.internal from kube-system started at 2019-12-17 00:10:40 +0000 UTC (1 container statuses recorded)
Dec 17 00:19:53.700: INFO: 	Container kube-proxy ready: true, restart count 5
Dec 17 00:19:53.700: INFO: kube-dns-autoscaler-66b775459-vxsv4 from kube-system started at 2019-12-17 00:14:15 +0000 UTC (1 container statuses recorded)
Dec 17 00:19:53.700: INFO: 	Container autoscaler ready: true, restart count 0
Dec 17 00:19:53.700: INFO: kube-dns-bb55d6458-h4rqk from kube-system started at 2019-12-17 00:14:15 +0000 UTC (3 container statuses recorded)
Dec 17 00:19:53.700: INFO: 	Container dnsmasq ready: true, restart count 0
Dec 17 00:19:53.700: INFO: 	Container kubedns ready: true, restart count 1
Dec 17 00:19:53.700: INFO: 	Container sidecar ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-f724737d-fab7-4036-adba-056d6dc7403a 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-f724737d-fab7-4036-adba-056d6dc7403a off the node ip-172-20-34-147.us-east-2.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-f724737d-fab7-4036-adba-056d6dc7403a
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:19:57.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2291" for this suite.
Dec 17 00:20:05.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:20:05.818: INFO: namespace sched-pred-2291 deletion completed in 8.060914563s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

â€¢ [SLOW TEST:12.154 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:20:05.818: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 17 00:20:05.841: INFO: Waiting up to 5m0s for pod "pod-0ca4de0b-80fb-4e3e-bcba-43e09ca947c4" in namespace "emptydir-4405" to be "success or failure"
Dec 17 00:20:05.844: INFO: Pod "pod-0ca4de0b-80fb-4e3e-bcba-43e09ca947c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.612143ms
Dec 17 00:20:07.846: INFO: Pod "pod-0ca4de0b-80fb-4e3e-bcba-43e09ca947c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005356858s
Dec 17 00:20:09.850: INFO: Pod "pod-0ca4de0b-80fb-4e3e-bcba-43e09ca947c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008400846s
STEP: Saw pod success
Dec 17 00:20:09.850: INFO: Pod "pod-0ca4de0b-80fb-4e3e-bcba-43e09ca947c4" satisfied condition "success or failure"
Dec 17 00:20:09.853: INFO: Trying to get logs from node ip-172-20-34-147.us-east-2.compute.internal pod pod-0ca4de0b-80fb-4e3e-bcba-43e09ca947c4 container test-container: <nil>
STEP: delete the pod
Dec 17 00:20:09.868: INFO: Waiting for pod pod-0ca4de0b-80fb-4e3e-bcba-43e09ca947c4 to disappear
Dec 17 00:20:09.870: INFO: Pod pod-0ca4de0b-80fb-4e3e-bcba-43e09ca947c4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:20:09.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4405" for this suite.
Dec 17 00:20:15.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:20:15.943: INFO: namespace emptydir-4405 deletion completed in 6.069826457s

â€¢ [SLOW TEST:10.124 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:20:15.943: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 17 00:20:15.965: INFO: Waiting up to 5m0s for pod "pod-7321de88-88ce-469e-81dc-a825e187707b" in namespace "emptydir-4851" to be "success or failure"
Dec 17 00:20:15.968: INFO: Pod "pod-7321de88-88ce-469e-81dc-a825e187707b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.393344ms
Dec 17 00:20:17.971: INFO: Pod "pod-7321de88-88ce-469e-81dc-a825e187707b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006066141s
STEP: Saw pod success
Dec 17 00:20:17.971: INFO: Pod "pod-7321de88-88ce-469e-81dc-a825e187707b" satisfied condition "success or failure"
Dec 17 00:20:17.973: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-7321de88-88ce-469e-81dc-a825e187707b container test-container: <nil>
STEP: delete the pod
Dec 17 00:20:17.988: INFO: Waiting for pod pod-7321de88-88ce-469e-81dc-a825e187707b to disappear
Dec 17 00:20:17.990: INFO: Pod pod-7321de88-88ce-469e-81dc-a825e187707b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:20:17.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4851" for this suite.
Dec 17 00:20:24.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:20:24.055: INFO: namespace emptydir-4851 deletion completed in 6.062028568s

â€¢ [SLOW TEST:8.112 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:20:24.055: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-5326.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-5326.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5326.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-5326.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-5326.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5326.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 17 00:20:34.113: INFO: DNS probes using dns-5326/dns-test-74494dd0-0b4c-4ed6-abcb-05c75b5ef5d3 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:20:34.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5326" for this suite.
Dec 17 00:20:40.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:20:40.210: INFO: namespace dns-5326 deletion completed in 6.073707376s

â€¢ [SLOW TEST:16.154 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:20:40.210: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:20:40.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1754" for this suite.
Dec 17 00:20:52.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:20:52.360: INFO: namespace pods-1754 deletion completed in 12.069427882s

â€¢ [SLOW TEST:12.151 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:20:52.360: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 00:20:52.404: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"ce7a882c-7af7-41b4-9046-2de1c633ff43", Controller:(*bool)(0xc003641636), BlockOwnerDeletion:(*bool)(0xc003641637)}}
Dec 17 00:20:52.407: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"961cac07-590e-4739-a88b-80d059445aa5", Controller:(*bool)(0xc002b45c26), BlockOwnerDeletion:(*bool)(0xc002b45c27)}}
Dec 17 00:20:52.411: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"de071042-7a2b-418c-b9f4-1dd167be4654", Controller:(*bool)(0xc002b45dc6), BlockOwnerDeletion:(*bool)(0xc002b45dc7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:20:57.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3502" for this suite.
Dec 17 00:21:03.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:21:03.473: INFO: namespace gc-3502 deletion completed in 6.053639421s

â€¢ [SLOW TEST:11.113 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:21:03.474: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:21:14.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3793" for this suite.
Dec 17 00:21:20.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:21:20.587: INFO: namespace resourcequota-3793 deletion completed in 6.071904302s

â€¢ [SLOW TEST:17.113 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:21:20.587: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-01cf07ac-8eb9-46e0-a056-b25312398b4b
STEP: Creating a pod to test consume secrets
Dec 17 00:21:20.613: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-02fdb720-a0f6-439e-ac3d-cea165774a24" in namespace "projected-5596" to be "success or failure"
Dec 17 00:21:20.616: INFO: Pod "pod-projected-secrets-02fdb720-a0f6-439e-ac3d-cea165774a24": Phase="Pending", Reason="", readiness=false. Elapsed: 2.492344ms
Dec 17 00:21:22.619: INFO: Pod "pod-projected-secrets-02fdb720-a0f6-439e-ac3d-cea165774a24": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005522617s
STEP: Saw pod success
Dec 17 00:21:22.619: INFO: Pod "pod-projected-secrets-02fdb720-a0f6-439e-ac3d-cea165774a24" satisfied condition "success or failure"
Dec 17 00:21:22.621: INFO: Trying to get logs from node ip-172-20-34-147.us-east-2.compute.internal pod pod-projected-secrets-02fdb720-a0f6-439e-ac3d-cea165774a24 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 17 00:21:22.634: INFO: Waiting for pod pod-projected-secrets-02fdb720-a0f6-439e-ac3d-cea165774a24 to disappear
Dec 17 00:21:22.636: INFO: Pod pod-projected-secrets-02fdb720-a0f6-439e-ac3d-cea165774a24 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:21:22.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5596" for this suite.
Dec 17 00:21:28.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:21:28.702: INFO: namespace projected-5596 deletion completed in 6.064410978s

â€¢ [SLOW TEST:8.115 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:21:28.703: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 17 00:21:30.735: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:21:30.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8662" for this suite.
Dec 17 00:21:36.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:21:36.820: INFO: namespace container-runtime-8662 deletion completed in 6.070798562s

â€¢ [SLOW TEST:8.118 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:21:36.820: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 17 00:21:36.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-5361'
Dec 17 00:21:36.916: INFO: stderr: ""
Dec 17 00:21:36.916: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Dec 17 00:21:36.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 delete pods e2e-test-httpd-pod --namespace=kubectl-5361'
Dec 17 00:21:50.005: INFO: stderr: ""
Dec 17 00:21:50.005: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:21:50.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5361" for this suite.
Dec 17 00:21:56.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:21:56.081: INFO: namespace kubectl-5361 deletion completed in 6.072125532s

â€¢ [SLOW TEST:19.260 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:21:56.081: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 17 00:21:56.105: INFO: Waiting up to 5m0s for pod "pod-0c941b25-5a2a-46f8-b4a2-e7d357c9a964" in namespace "emptydir-6745" to be "success or failure"
Dec 17 00:21:56.107: INFO: Pod "pod-0c941b25-5a2a-46f8-b4a2-e7d357c9a964": Phase="Pending", Reason="", readiness=false. Elapsed: 2.255367ms
Dec 17 00:21:58.110: INFO: Pod "pod-0c941b25-5a2a-46f8-b4a2-e7d357c9a964": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004529254s
STEP: Saw pod success
Dec 17 00:21:58.110: INFO: Pod "pod-0c941b25-5a2a-46f8-b4a2-e7d357c9a964" satisfied condition "success or failure"
Dec 17 00:21:58.111: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-0c941b25-5a2a-46f8-b4a2-e7d357c9a964 container test-container: <nil>
STEP: delete the pod
Dec 17 00:21:58.133: INFO: Waiting for pod pod-0c941b25-5a2a-46f8-b4a2-e7d357c9a964 to disappear
Dec 17 00:21:58.135: INFO: Pod pod-0c941b25-5a2a-46f8-b4a2-e7d357c9a964 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:21:58.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6745" for this suite.
Dec 17 00:22:04.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:22:04.202: INFO: namespace emptydir-6745 deletion completed in 6.065382899s

â€¢ [SLOW TEST:8.122 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:22:04.202: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-4ec3cf23-4b4e-45d7-ad1d-9c53cdedd37a
STEP: Creating a pod to test consume configMaps
Dec 17 00:22:04.228: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d7561c3c-a974-40ce-bf18-6d5db48412f5" in namespace "projected-4854" to be "success or failure"
Dec 17 00:22:04.230: INFO: Pod "pod-projected-configmaps-d7561c3c-a974-40ce-bf18-6d5db48412f5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.386892ms
Dec 17 00:22:06.233: INFO: Pod "pod-projected-configmaps-d7561c3c-a974-40ce-bf18-6d5db48412f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005604019s
STEP: Saw pod success
Dec 17 00:22:06.234: INFO: Pod "pod-projected-configmaps-d7561c3c-a974-40ce-bf18-6d5db48412f5" satisfied condition "success or failure"
Dec 17 00:22:06.235: INFO: Trying to get logs from node ip-172-20-34-147.us-east-2.compute.internal pod pod-projected-configmaps-d7561c3c-a974-40ce-bf18-6d5db48412f5 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 00:22:06.251: INFO: Waiting for pod pod-projected-configmaps-d7561c3c-a974-40ce-bf18-6d5db48412f5 to disappear
Dec 17 00:22:06.253: INFO: Pod pod-projected-configmaps-d7561c3c-a974-40ce-bf18-6d5db48412f5 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:22:06.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4854" for this suite.
Dec 17 00:22:12.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:22:12.314: INFO: namespace projected-4854 deletion completed in 6.057835109s

â€¢ [SLOW TEST:8.111 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:22:12.314: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-ade5b444-8cad-4e05-b934-5b54f9bdebe3
STEP: Creating a pod to test consume configMaps
Dec 17 00:22:12.338: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a8a362a1-1fe2-4256-88ae-6de9ec1541d0" in namespace "projected-7383" to be "success or failure"
Dec 17 00:22:12.342: INFO: Pod "pod-projected-configmaps-a8a362a1-1fe2-4256-88ae-6de9ec1541d0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.988574ms
Dec 17 00:22:14.345: INFO: Pod "pod-projected-configmaps-a8a362a1-1fe2-4256-88ae-6de9ec1541d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007085462s
STEP: Saw pod success
Dec 17 00:22:14.345: INFO: Pod "pod-projected-configmaps-a8a362a1-1fe2-4256-88ae-6de9ec1541d0" satisfied condition "success or failure"
Dec 17 00:22:14.347: INFO: Trying to get logs from node ip-172-20-34-147.us-east-2.compute.internal pod pod-projected-configmaps-a8a362a1-1fe2-4256-88ae-6de9ec1541d0 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 00:22:14.363: INFO: Waiting for pod pod-projected-configmaps-a8a362a1-1fe2-4256-88ae-6de9ec1541d0 to disappear
Dec 17 00:22:14.365: INFO: Pod pod-projected-configmaps-a8a362a1-1fe2-4256-88ae-6de9ec1541d0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:22:14.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7383" for this suite.
Dec 17 00:22:20.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:22:20.423: INFO: namespace projected-7383 deletion completed in 6.056467139s

â€¢ [SLOW TEST:8.109 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:22:20.424: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 00:22:44.455: INFO: Container started at 2019-12-17 00:22:21 +0000 UTC, pod became ready at 2019-12-17 00:22:44 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:22:44.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1784" for this suite.
Dec 17 00:23:12.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:23:12.539: INFO: namespace container-probe-1784 deletion completed in 28.079066337s

â€¢ [SLOW TEST:52.115 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:23:12.539: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Dec 17 00:23:12.575: INFO: Waiting up to 5m0s for pod "var-expansion-8711cacb-24f1-47a8-b6b0-265c05d3fad6" in namespace "var-expansion-50" to be "success or failure"
Dec 17 00:23:12.581: INFO: Pod "var-expansion-8711cacb-24f1-47a8-b6b0-265c05d3fad6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.689928ms
Dec 17 00:23:14.584: INFO: Pod "var-expansion-8711cacb-24f1-47a8-b6b0-265c05d3fad6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009430542s
STEP: Saw pod success
Dec 17 00:23:14.584: INFO: Pod "var-expansion-8711cacb-24f1-47a8-b6b0-265c05d3fad6" satisfied condition "success or failure"
Dec 17 00:23:14.586: INFO: Trying to get logs from node ip-172-20-34-147.us-east-2.compute.internal pod var-expansion-8711cacb-24f1-47a8-b6b0-265c05d3fad6 container dapi-container: <nil>
STEP: delete the pod
Dec 17 00:23:14.599: INFO: Waiting for pod var-expansion-8711cacb-24f1-47a8-b6b0-265c05d3fad6 to disappear
Dec 17 00:23:14.601: INFO: Pod var-expansion-8711cacb-24f1-47a8-b6b0-265c05d3fad6 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:23:14.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-50" for this suite.
Dec 17 00:23:20.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:23:20.665: INFO: namespace var-expansion-50 deletion completed in 6.061558457s

â€¢ [SLOW TEST:8.126 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:23:20.665: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-8315/configmap-test-ef173220-280a-4200-bd8d-20ff7b55086e
STEP: Creating a pod to test consume configMaps
Dec 17 00:23:20.692: INFO: Waiting up to 5m0s for pod "pod-configmaps-9e000f51-b011-47ad-b6fd-76569f977c6d" in namespace "configmap-8315" to be "success or failure"
Dec 17 00:23:20.695: INFO: Pod "pod-configmaps-9e000f51-b011-47ad-b6fd-76569f977c6d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.977969ms
Dec 17 00:23:22.697: INFO: Pod "pod-configmaps-9e000f51-b011-47ad-b6fd-76569f977c6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005587589s
STEP: Saw pod success
Dec 17 00:23:22.697: INFO: Pod "pod-configmaps-9e000f51-b011-47ad-b6fd-76569f977c6d" satisfied condition "success or failure"
Dec 17 00:23:22.699: INFO: Trying to get logs from node ip-172-20-34-147.us-east-2.compute.internal pod pod-configmaps-9e000f51-b011-47ad-b6fd-76569f977c6d container env-test: <nil>
STEP: delete the pod
Dec 17 00:23:22.710: INFO: Waiting for pod pod-configmaps-9e000f51-b011-47ad-b6fd-76569f977c6d to disappear
Dec 17 00:23:22.712: INFO: Pod pod-configmaps-9e000f51-b011-47ad-b6fd-76569f977c6d no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:23:22.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8315" for this suite.
Dec 17 00:23:28.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:23:28.780: INFO: namespace configmap-8315 deletion completed in 6.065362637s

â€¢ [SLOW TEST:8.114 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:23:28.780: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Dec 17 00:23:28.802: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:23:45.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4695" for this suite.
Dec 17 00:23:51.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:23:51.694: INFO: namespace crd-publish-openapi-4695 deletion completed in 6.059617809s

â€¢ [SLOW TEST:22.914 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:23:51.694: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 00:23:52.176: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 17 00:23:54.184: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712139032, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712139032, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712139032, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712139032, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 00:23:57.193: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Dec 17 00:23:57.207: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:23:57.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2105" for this suite.
Dec 17 00:24:03.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:24:03.276: INFO: namespace webhook-2105 deletion completed in 6.058292236s
STEP: Destroying namespace "webhook-2105-markers" for this suite.
Dec 17 00:24:09.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:24:09.348: INFO: namespace webhook-2105-markers deletion completed in 6.071712839s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:17.662 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:24:09.356: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 00:24:09.380: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3756e121-c30f-4e11-9723-17a33e03a0d0" in namespace "projected-9292" to be "success or failure"
Dec 17 00:24:09.383: INFO: Pod "downwardapi-volume-3756e121-c30f-4e11-9723-17a33e03a0d0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.099487ms
Dec 17 00:24:11.385: INFO: Pod "downwardapi-volume-3756e121-c30f-4e11-9723-17a33e03a0d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005521885s
STEP: Saw pod success
Dec 17 00:24:11.385: INFO: Pod "downwardapi-volume-3756e121-c30f-4e11-9723-17a33e03a0d0" satisfied condition "success or failure"
Dec 17 00:24:11.387: INFO: Trying to get logs from node ip-172-20-34-147.us-east-2.compute.internal pod downwardapi-volume-3756e121-c30f-4e11-9723-17a33e03a0d0 container client-container: <nil>
STEP: delete the pod
Dec 17 00:24:11.400: INFO: Waiting for pod downwardapi-volume-3756e121-c30f-4e11-9723-17a33e03a0d0 to disappear
Dec 17 00:24:11.401: INFO: Pod downwardapi-volume-3756e121-c30f-4e11-9723-17a33e03a0d0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:24:11.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9292" for this suite.
Dec 17 00:24:17.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:24:17.464: INFO: namespace projected-9292 deletion completed in 6.059736952s

â€¢ [SLOW TEST:8.107 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:24:17.464: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-6347
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-6347
I1217 00:24:17.508406      21 runners.go:184] Created replication controller with name: externalname-service, namespace: services-6347, replica count: 2
Dec 17 00:24:20.558: INFO: Creating new exec pod
I1217 00:24:20.558911      21 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 17 00:24:23.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=services-6347 execpodxq8bw -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec 17 00:24:23.738: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 17 00:24:23.738: INFO: stdout: ""
Dec 17 00:24:23.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=services-6347 execpodxq8bw -- /bin/sh -x -c nc -zv -t -w 2 100.65.232.172 80'
Dec 17 00:24:23.904: INFO: stderr: "+ nc -zv -t -w 2 100.65.232.172 80\nConnection to 100.65.232.172 80 port [tcp/http] succeeded!\n"
Dec 17 00:24:23.904: INFO: stdout: ""
Dec 17 00:24:23.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=services-6347 execpodxq8bw -- /bin/sh -x -c nc -zv -t -w 2 172.20.34.147 30835'
Dec 17 00:24:24.071: INFO: stderr: "+ nc -zv -t -w 2 172.20.34.147 30835\nConnection to 172.20.34.147 30835 port [tcp/30835] succeeded!\n"
Dec 17 00:24:24.071: INFO: stdout: ""
Dec 17 00:24:24.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=services-6347 execpodxq8bw -- /bin/sh -x -c nc -zv -t -w 2 172.20.58.188 30835'
Dec 17 00:24:24.246: INFO: stderr: "+ nc -zv -t -w 2 172.20.58.188 30835\nConnection to 172.20.58.188 30835 port [tcp/30835] succeeded!\n"
Dec 17 00:24:24.246: INFO: stdout: ""
Dec 17 00:24:24.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=services-6347 execpodxq8bw -- /bin/sh -x -c nc -zv -t -w 2 3.135.191.120 30835'
Dec 17 00:24:24.411: INFO: stderr: "+ nc -zv -t -w 2 3.135.191.120 30835\nConnection to 3.135.191.120 30835 port [tcp/30835] succeeded!\n"
Dec 17 00:24:24.411: INFO: stdout: ""
Dec 17 00:24:24.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=services-6347 execpodxq8bw -- /bin/sh -x -c nc -zv -t -w 2 3.136.26.172 30835'
Dec 17 00:24:24.584: INFO: stderr: "+ nc -zv -t -w 2 3.136.26.172 30835\nConnection to 3.136.26.172 30835 port [tcp/30835] succeeded!\n"
Dec 17 00:24:24.584: INFO: stdout: ""
Dec 17 00:24:24.584: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:24:24.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6347" for this suite.
Dec 17 00:24:30.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:24:30.670: INFO: namespace services-6347 deletion completed in 6.061485407s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:13.206 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:24:30.670: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec 17 00:24:40.736: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1217 00:24:40.736642      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:24:40.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7829" for this suite.
Dec 17 00:24:46.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:24:46.814: INFO: namespace gc-7829 deletion completed in 6.075132147s

â€¢ [SLOW TEST:16.144 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:24:46.814: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 17 00:24:46.839: INFO: Waiting up to 5m0s for pod "pod-8baaaf0d-9a24-4c0c-a793-49e921a17e6f" in namespace "emptydir-7912" to be "success or failure"
Dec 17 00:24:46.841: INFO: Pod "pod-8baaaf0d-9a24-4c0c-a793-49e921a17e6f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.961388ms
Dec 17 00:24:48.843: INFO: Pod "pod-8baaaf0d-9a24-4c0c-a793-49e921a17e6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00401657s
STEP: Saw pod success
Dec 17 00:24:48.843: INFO: Pod "pod-8baaaf0d-9a24-4c0c-a793-49e921a17e6f" satisfied condition "success or failure"
Dec 17 00:24:48.846: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-8baaaf0d-9a24-4c0c-a793-49e921a17e6f container test-container: <nil>
STEP: delete the pod
Dec 17 00:24:48.866: INFO: Waiting for pod pod-8baaaf0d-9a24-4c0c-a793-49e921a17e6f to disappear
Dec 17 00:24:48.868: INFO: Pod pod-8baaaf0d-9a24-4c0c-a793-49e921a17e6f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:24:48.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7912" for this suite.
Dec 17 00:24:54.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:24:54.926: INFO: namespace emptydir-7912 deletion completed in 6.056365391s

â€¢ [SLOW TEST:8.112 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:24:54.926: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-7272
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-7272
STEP: Creating statefulset with conflicting port in namespace statefulset-7272
STEP: Waiting until pod test-pod will start running in namespace statefulset-7272
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-7272
Dec 17 00:25:02.964: INFO: Observed stateful pod in namespace: statefulset-7272, name: ss-0, uid: 3d3da73b-a6af-445b-b652-cd319b76e1d7, status phase: Pending. Waiting for statefulset controller to delete.
Dec 17 00:25:03.159: INFO: Observed stateful pod in namespace: statefulset-7272, name: ss-0, uid: 3d3da73b-a6af-445b-b652-cd319b76e1d7, status phase: Failed. Waiting for statefulset controller to delete.
Dec 17 00:25:03.165: INFO: Observed stateful pod in namespace: statefulset-7272, name: ss-0, uid: 3d3da73b-a6af-445b-b652-cd319b76e1d7, status phase: Failed. Waiting for statefulset controller to delete.
Dec 17 00:25:03.171: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-7272
STEP: Removing pod with conflicting port in namespace statefulset-7272
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-7272 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 17 00:25:07.194: INFO: Deleting all statefulset in ns statefulset-7272
Dec 17 00:25:07.197: INFO: Scaling statefulset ss to 0
Dec 17 00:25:17.207: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 00:25:17.209: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:25:17.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7272" for this suite.
Dec 17 00:25:23.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:25:23.317: INFO: namespace statefulset-7272 deletion completed in 6.092291776s

â€¢ [SLOW TEST:28.391 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:25:23.318: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 17 00:25:23.336: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 17 00:25:23.343: INFO: Waiting for terminating namespaces to be deleted...
Dec 17 00:25:23.345: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-34-147.us-east-2.compute.internal before test
Dec 17 00:25:23.350: INFO: sonobuoy from sonobuoy started at 2019-12-17 00:16:34 +0000 UTC (1 container statuses recorded)
Dec 17 00:25:23.350: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 17 00:25:23.350: INFO: sonobuoy-e2e-job-edd513b56d7b4d93 from sonobuoy started at 2019-12-17 00:16:40 +0000 UTC (2 container statuses recorded)
Dec 17 00:25:23.350: INFO: 	Container e2e ready: true, restart count 0
Dec 17 00:25:23.350: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 17 00:25:23.350: INFO: sonobuoy-systemd-logs-daemon-set-aa23d16e52f14f6e-l6lh6 from sonobuoy started at 2019-12-17 00:16:40 +0000 UTC (2 container statuses recorded)
Dec 17 00:25:23.350: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 17 00:25:23.350: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 17 00:25:23.350: INFO: kube-proxy-ip-172-20-34-147.us-east-2.compute.internal from kube-system started at 2019-12-17 00:10:42 +0000 UTC (1 container statuses recorded)
Dec 17 00:25:23.350: INFO: 	Container kube-proxy ready: true, restart count 5
Dec 17 00:25:23.350: INFO: kube-dns-bb55d6458-qz7ks from kube-system started at 2019-12-17 00:15:20 +0000 UTC (3 container statuses recorded)
Dec 17 00:25:23.350: INFO: 	Container dnsmasq ready: true, restart count 0
Dec 17 00:25:23.350: INFO: 	Container kubedns ready: true, restart count 0
Dec 17 00:25:23.350: INFO: 	Container sidecar ready: true, restart count 0
Dec 17 00:25:23.350: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-58-188.us-east-2.compute.internal before test
Dec 17 00:25:23.353: INFO: kube-proxy-ip-172-20-58-188.us-east-2.compute.internal from kube-system started at 2019-12-17 00:10:40 +0000 UTC (1 container statuses recorded)
Dec 17 00:25:23.353: INFO: 	Container kube-proxy ready: true, restart count 5
Dec 17 00:25:23.353: INFO: kube-dns-autoscaler-66b775459-vxsv4 from kube-system started at 2019-12-17 00:14:15 +0000 UTC (1 container statuses recorded)
Dec 17 00:25:23.353: INFO: 	Container autoscaler ready: true, restart count 0
Dec 17 00:25:23.354: INFO: sonobuoy-systemd-logs-daemon-set-aa23d16e52f14f6e-dk4ms from sonobuoy started at 2019-12-17 00:16:40 +0000 UTC (2 container statuses recorded)
Dec 17 00:25:23.354: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 17 00:25:23.354: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 17 00:25:23.354: INFO: kube-dns-bb55d6458-h4rqk from kube-system started at 2019-12-17 00:14:15 +0000 UTC (3 container statuses recorded)
Dec 17 00:25:23.354: INFO: 	Container dnsmasq ready: true, restart count 0
Dec 17 00:25:23.354: INFO: 	Container kubedns ready: true, restart count 1
Dec 17 00:25:23.354: INFO: 	Container sidecar ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node ip-172-20-34-147.us-east-2.compute.internal
STEP: verifying the node has the label node ip-172-20-58-188.us-east-2.compute.internal
Dec 17 00:25:23.376: INFO: Pod kube-dns-autoscaler-66b775459-vxsv4 requesting resource cpu=20m on Node ip-172-20-58-188.us-east-2.compute.internal
Dec 17 00:25:23.376: INFO: Pod kube-dns-bb55d6458-h4rqk requesting resource cpu=260m on Node ip-172-20-58-188.us-east-2.compute.internal
Dec 17 00:25:23.376: INFO: Pod kube-dns-bb55d6458-qz7ks requesting resource cpu=260m on Node ip-172-20-34-147.us-east-2.compute.internal
Dec 17 00:25:23.376: INFO: Pod kube-proxy-ip-172-20-34-147.us-east-2.compute.internal requesting resource cpu=100m on Node ip-172-20-34-147.us-east-2.compute.internal
Dec 17 00:25:23.376: INFO: Pod kube-proxy-ip-172-20-58-188.us-east-2.compute.internal requesting resource cpu=100m on Node ip-172-20-58-188.us-east-2.compute.internal
Dec 17 00:25:23.376: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-20-34-147.us-east-2.compute.internal
Dec 17 00:25:23.376: INFO: Pod sonobuoy-e2e-job-edd513b56d7b4d93 requesting resource cpu=0m on Node ip-172-20-34-147.us-east-2.compute.internal
Dec 17 00:25:23.376: INFO: Pod sonobuoy-systemd-logs-daemon-set-aa23d16e52f14f6e-dk4ms requesting resource cpu=0m on Node ip-172-20-58-188.us-east-2.compute.internal
Dec 17 00:25:23.376: INFO: Pod sonobuoy-systemd-logs-daemon-set-aa23d16e52f14f6e-l6lh6 requesting resource cpu=0m on Node ip-172-20-34-147.us-east-2.compute.internal
STEP: Starting Pods to consume most of the cluster CPU.
Dec 17 00:25:23.376: INFO: Creating a pod which consumes cpu=1148m on Node ip-172-20-34-147.us-east-2.compute.internal
Dec 17 00:25:23.380: INFO: Creating a pod which consumes cpu=1134m on Node ip-172-20-58-188.us-east-2.compute.internal
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-83dd9133-6463-462a-8d15-a660ef7066f5.15e100e3e70640ff], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1291/filler-pod-83dd9133-6463-462a-8d15-a660ef7066f5 to ip-172-20-58-188.us-east-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-83dd9133-6463-462a-8d15-a660ef7066f5.15e100e40f409e2b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-83dd9133-6463-462a-8d15-a660ef7066f5.15e100e411e0a5dd], Reason = [Created], Message = [Created container filler-pod-83dd9133-6463-462a-8d15-a660ef7066f5]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-83dd9133-6463-462a-8d15-a660ef7066f5.15e100e41e9f0b05], Reason = [Started], Message = [Started container filler-pod-83dd9133-6463-462a-8d15-a660ef7066f5]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b7e5c1f6-b304-43a4-8188-9efd643c7fb1.15e100e3e6a09c4a], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1291/filler-pod-b7e5c1f6-b304-43a4-8188-9efd643c7fb1 to ip-172-20-34-147.us-east-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b7e5c1f6-b304-43a4-8188-9efd643c7fb1.15e100e410cbe4af], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b7e5c1f6-b304-43a4-8188-9efd643c7fb1.15e100e4133c90ad], Reason = [Created], Message = [Created container filler-pod-b7e5c1f6-b304-43a4-8188-9efd643c7fb1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b7e5c1f6-b304-43a4-8188-9efd643c7fb1.15e100e41d921b49], Reason = [Started], Message = [Started container filler-pod-b7e5c1f6-b304-43a4-8188-9efd643c7fb1]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15e100e45f24e005], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node ip-172-20-34-147.us-east-2.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-20-58-188.us-east-2.compute.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:25:26.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1291" for this suite.
Dec 17 00:25:32.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:25:32.501: INFO: namespace sched-pred-1291 deletion completed in 6.063592131s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

â€¢ [SLOW TEST:9.184 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:25:32.502: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-dc8d4c2d-8e68-4b9a-874b-c6679d25e78b in namespace container-probe-3913
Dec 17 00:25:34.528: INFO: Started pod liveness-dc8d4c2d-8e68-4b9a-874b-c6679d25e78b in namespace container-probe-3913
STEP: checking the pod's current state and verifying that restartCount is present
Dec 17 00:25:34.530: INFO: Initial restart count of pod liveness-dc8d4c2d-8e68-4b9a-874b-c6679d25e78b is 0
Dec 17 00:25:48.551: INFO: Restart count of pod container-probe-3913/liveness-dc8d4c2d-8e68-4b9a-874b-c6679d25e78b is now 1 (14.020565963s elapsed)
Dec 17 00:26:08.580: INFO: Restart count of pod container-probe-3913/liveness-dc8d4c2d-8e68-4b9a-874b-c6679d25e78b is now 2 (34.049861563s elapsed)
Dec 17 00:26:28.607: INFO: Restart count of pod container-probe-3913/liveness-dc8d4c2d-8e68-4b9a-874b-c6679d25e78b is now 3 (54.076921416s elapsed)
Dec 17 00:26:48.637: INFO: Restart count of pod container-probe-3913/liveness-dc8d4c2d-8e68-4b9a-874b-c6679d25e78b is now 4 (1m14.106479896s elapsed)
Dec 17 00:28:00.741: INFO: Restart count of pod container-probe-3913/liveness-dc8d4c2d-8e68-4b9a-874b-c6679d25e78b is now 5 (2m26.210460847s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:28:00.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3913" for this suite.
Dec 17 00:28:06.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:28:06.809: INFO: namespace container-probe-3913 deletion completed in 6.060318023s

â€¢ [SLOW TEST:154.307 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:28:06.809: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 00:28:06.832: INFO: Waiting up to 5m0s for pod "busybox-user-65534-633b9d32-6ea0-4aca-b79a-63f2b0758900" in namespace "security-context-test-1293" to be "success or failure"
Dec 17 00:28:06.835: INFO: Pod "busybox-user-65534-633b9d32-6ea0-4aca-b79a-63f2b0758900": Phase="Pending", Reason="", readiness=false. Elapsed: 2.600526ms
Dec 17 00:28:08.841: INFO: Pod "busybox-user-65534-633b9d32-6ea0-4aca-b79a-63f2b0758900": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008755075s
Dec 17 00:28:08.841: INFO: Pod "busybox-user-65534-633b9d32-6ea0-4aca-b79a-63f2b0758900" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:28:08.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1293" for this suite.
Dec 17 00:28:14.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:28:14.904: INFO: namespace security-context-test-1293 deletion completed in 6.06094126s

â€¢ [SLOW TEST:8.095 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:28:14.904: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-2788a60b-631e-4979-b3c0-267691d68956
STEP: Creating a pod to test consume secrets
Dec 17 00:28:14.929: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-10459b55-5b74-464b-9272-6c609de4617f" in namespace "projected-4886" to be "success or failure"
Dec 17 00:28:14.940: INFO: Pod "pod-projected-secrets-10459b55-5b74-464b-9272-6c609de4617f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.583212ms
Dec 17 00:28:16.942: INFO: Pod "pod-projected-secrets-10459b55-5b74-464b-9272-6c609de4617f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013149654s
STEP: Saw pod success
Dec 17 00:28:16.942: INFO: Pod "pod-projected-secrets-10459b55-5b74-464b-9272-6c609de4617f" satisfied condition "success or failure"
Dec 17 00:28:16.944: INFO: Trying to get logs from node ip-172-20-34-147.us-east-2.compute.internal pod pod-projected-secrets-10459b55-5b74-464b-9272-6c609de4617f container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 17 00:28:16.964: INFO: Waiting for pod pod-projected-secrets-10459b55-5b74-464b-9272-6c609de4617f to disappear
Dec 17 00:28:16.966: INFO: Pod pod-projected-secrets-10459b55-5b74-464b-9272-6c609de4617f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:28:16.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4886" for this suite.
Dec 17 00:28:22.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:28:23.027: INFO: namespace projected-4886 deletion completed in 6.05895333s

â€¢ [SLOW TEST:8.123 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:28:23.027: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 00:28:24.110: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 17 00:28:26.116: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712139304, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712139304, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712139304, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712139304, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 00:28:29.128: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Dec 17 00:28:31.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 attach --namespace=webhook-5417 to-be-attached-pod -i -c=container1'
Dec 17 00:28:31.381: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:28:31.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5417" for this suite.
Dec 17 00:28:43.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:28:43.454: INFO: namespace webhook-5417 deletion completed in 12.063358485s
STEP: Destroying namespace "webhook-5417-markers" for this suite.
Dec 17 00:28:49.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:28:49.511: INFO: namespace webhook-5417-markers deletion completed in 6.057174665s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:26.492 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:28:49.520: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec 17 00:28:49.790: INFO: Pod name wrapped-volume-race-7699ff0d-cfee-4619-8e98-09280f8105c0: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-7699ff0d-cfee-4619-8e98-09280f8105c0 in namespace emptydir-wrapper-1269, will wait for the garbage collector to delete the pods
Dec 17 00:29:03.891: INFO: Deleting ReplicationController wrapped-volume-race-7699ff0d-cfee-4619-8e98-09280f8105c0 took: 4.205063ms
Dec 17 00:29:04.191: INFO: Terminating ReplicationController wrapped-volume-race-7699ff0d-cfee-4619-8e98-09280f8105c0 pods took: 300.340857ms
STEP: Creating RC which spawns configmap-volume pods
Dec 17 00:29:42.105: INFO: Pod name wrapped-volume-race-c2fe8dfd-106c-4ad4-8062-5c411a753e80: Found 0 pods out of 5
Dec 17 00:29:47.111: INFO: Pod name wrapped-volume-race-c2fe8dfd-106c-4ad4-8062-5c411a753e80: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c2fe8dfd-106c-4ad4-8062-5c411a753e80 in namespace emptydir-wrapper-1269, will wait for the garbage collector to delete the pods
Dec 17 00:29:57.185: INFO: Deleting ReplicationController wrapped-volume-race-c2fe8dfd-106c-4ad4-8062-5c411a753e80 took: 5.771108ms
Dec 17 00:29:57.485: INFO: Terminating ReplicationController wrapped-volume-race-c2fe8dfd-106c-4ad4-8062-5c411a753e80 pods took: 300.332941ms
STEP: Creating RC which spawns configmap-volume pods
Dec 17 00:30:42.096: INFO: Pod name wrapped-volume-race-106e3888-2169-4204-b27b-67c2f589886d: Found 0 pods out of 5
Dec 17 00:30:47.100: INFO: Pod name wrapped-volume-race-106e3888-2169-4204-b27b-67c2f589886d: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-106e3888-2169-4204-b27b-67c2f589886d in namespace emptydir-wrapper-1269, will wait for the garbage collector to delete the pods
Dec 17 00:30:57.172: INFO: Deleting ReplicationController wrapped-volume-race-106e3888-2169-4204-b27b-67c2f589886d took: 6.172923ms
Dec 17 00:30:57.473: INFO: Terminating ReplicationController wrapped-volume-race-106e3888-2169-4204-b27b-67c2f589886d pods took: 300.280927ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:31:33.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1269" for this suite.
Dec 17 00:31:39.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:31:39.288: INFO: namespace emptydir-wrapper-1269 deletion completed in 6.055226956s

â€¢ [SLOW TEST:169.768 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:31:39.288: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 00:31:39.320: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:31:40.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5225" for this suite.
Dec 17 00:31:46.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:31:46.408: INFO: namespace custom-resource-definition-5225 deletion completed in 6.069481638s

â€¢ [SLOW TEST:7.120 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:31:46.409: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 17 00:31:47.441: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:31:47.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5389" for this suite.
Dec 17 00:31:53.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:31:53.528: INFO: namespace container-runtime-5389 deletion completed in 6.074750612s

â€¢ [SLOW TEST:7.119 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:31:53.528: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 00:31:53.548: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:31:55.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3587" for this suite.
Dec 17 00:32:41.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:32:41.724: INFO: namespace pods-3587 deletion completed in 46.066806908s

â€¢ [SLOW TEST:48.196 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:32:41.724: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 17 00:32:41.750: INFO: Waiting up to 5m0s for pod "downward-api-eaff0eaa-ca62-4423-b843-c60fd2b72b83" in namespace "downward-api-3983" to be "success or failure"
Dec 17 00:32:41.753: INFO: Pod "downward-api-eaff0eaa-ca62-4423-b843-c60fd2b72b83": Phase="Pending", Reason="", readiness=false. Elapsed: 3.146782ms
Dec 17 00:32:43.755: INFO: Pod "downward-api-eaff0eaa-ca62-4423-b843-c60fd2b72b83": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005621128s
STEP: Saw pod success
Dec 17 00:32:43.755: INFO: Pod "downward-api-eaff0eaa-ca62-4423-b843-c60fd2b72b83" satisfied condition "success or failure"
Dec 17 00:32:43.757: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod downward-api-eaff0eaa-ca62-4423-b843-c60fd2b72b83 container dapi-container: <nil>
STEP: delete the pod
Dec 17 00:32:43.779: INFO: Waiting for pod downward-api-eaff0eaa-ca62-4423-b843-c60fd2b72b83 to disappear
Dec 17 00:32:43.782: INFO: Pod downward-api-eaff0eaa-ca62-4423-b843-c60fd2b72b83 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:32:43.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3983" for this suite.
Dec 17 00:32:49.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:32:49.841: INFO: namespace downward-api-3983 deletion completed in 6.056074503s

â€¢ [SLOW TEST:8.116 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:32:49.841: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-7b830c3c-6676-4c87-99bc-81ce5360e635
STEP: Creating a pod to test consume configMaps
Dec 17 00:32:49.864: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-234fab7f-8891-4533-86c9-bcfc907f1245" in namespace "projected-4844" to be "success or failure"
Dec 17 00:32:49.867: INFO: Pod "pod-projected-configmaps-234fab7f-8891-4533-86c9-bcfc907f1245": Phase="Pending", Reason="", readiness=false. Elapsed: 2.177219ms
Dec 17 00:32:51.869: INFO: Pod "pod-projected-configmaps-234fab7f-8891-4533-86c9-bcfc907f1245": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00483532s
STEP: Saw pod success
Dec 17 00:32:51.869: INFO: Pod "pod-projected-configmaps-234fab7f-8891-4533-86c9-bcfc907f1245" satisfied condition "success or failure"
Dec 17 00:32:51.871: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-projected-configmaps-234fab7f-8891-4533-86c9-bcfc907f1245 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 00:32:51.882: INFO: Waiting for pod pod-projected-configmaps-234fab7f-8891-4533-86c9-bcfc907f1245 to disappear
Dec 17 00:32:51.884: INFO: Pod pod-projected-configmaps-234fab7f-8891-4533-86c9-bcfc907f1245 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:32:51.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4844" for this suite.
Dec 17 00:32:57.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:32:57.951: INFO: namespace projected-4844 deletion completed in 6.065141121s

â€¢ [SLOW TEST:8.110 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:32:57.951: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Dec 17 00:32:58.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 --namespace=kubectl-5657 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec 17 00:33:00.086: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec 17 00:33:00.086: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:33:02.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5657" for this suite.
Dec 17 00:33:12.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:33:12.162: INFO: namespace kubectl-5657 deletion completed in 10.069973161s

â€¢ [SLOW TEST:14.211 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:33:12.162: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 17 00:33:12.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-9580'
Dec 17 00:33:12.260: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 17 00:33:12.260: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Dec 17 00:33:14.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 delete deployment e2e-test-httpd-deployment --namespace=kubectl-9580'
Dec 17 00:33:14.347: INFO: stderr: ""
Dec 17 00:33:14.347: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:33:14.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9580" for this suite.
Dec 17 00:33:20.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:33:20.421: INFO: namespace kubectl-9580 deletion completed in 6.069767968s

â€¢ [SLOW TEST:8.259 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:33:20.421: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Dec 17 00:33:22.967: INFO: Successfully updated pod "adopt-release-5w42h"
STEP: Checking that the Job readopts the Pod
Dec 17 00:33:22.967: INFO: Waiting up to 15m0s for pod "adopt-release-5w42h" in namespace "job-1476" to be "adopted"
Dec 17 00:33:22.971: INFO: Pod "adopt-release-5w42h": Phase="Running", Reason="", readiness=true. Elapsed: 4.111068ms
Dec 17 00:33:24.975: INFO: Pod "adopt-release-5w42h": Phase="Running", Reason="", readiness=true. Elapsed: 2.007897819s
Dec 17 00:33:24.975: INFO: Pod "adopt-release-5w42h" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Dec 17 00:33:25.481: INFO: Successfully updated pod "adopt-release-5w42h"
STEP: Checking that the Job releases the Pod
Dec 17 00:33:25.481: INFO: Waiting up to 15m0s for pod "adopt-release-5w42h" in namespace "job-1476" to be "released"
Dec 17 00:33:25.484: INFO: Pod "adopt-release-5w42h": Phase="Running", Reason="", readiness=true. Elapsed: 3.561006ms
Dec 17 00:33:27.487: INFO: Pod "adopt-release-5w42h": Phase="Running", Reason="", readiness=true. Elapsed: 2.006236296s
Dec 17 00:33:27.487: INFO: Pod "adopt-release-5w42h" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:33:27.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1476" for this suite.
Dec 17 00:34:11.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:34:11.554: INFO: namespace job-1476 deletion completed in 44.06464834s

â€¢ [SLOW TEST:51.133 seconds]
[sig-apps] Job
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:34:11.554: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Dec 17 00:34:11.573: INFO: namespace kubectl-1700
Dec 17 00:34:11.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 create -f - --namespace=kubectl-1700'
Dec 17 00:34:11.770: INFO: stderr: ""
Dec 17 00:34:11.770: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 17 00:34:12.773: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 00:34:12.773: INFO: Found 0 / 1
Dec 17 00:34:13.773: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 00:34:13.773: INFO: Found 0 / 1
Dec 17 00:34:14.781: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 00:34:14.781: INFO: Found 0 / 1
Dec 17 00:34:15.772: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 00:34:15.772: INFO: Found 1 / 1
Dec 17 00:34:15.772: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 17 00:34:15.774: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 00:34:15.774: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 17 00:34:15.774: INFO: wait on redis-master startup in kubectl-1700 
Dec 17 00:34:15.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 logs redis-master-khqbs redis-master --namespace=kubectl-1700'
Dec 17 00:34:15.862: INFO: stderr: ""
Dec 17 00:34:15.862: INFO: stdout: "1:C 17 Dec 2019 00:34:15.046 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 17 Dec 2019 00:34:15.046 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 17 Dec 2019 00:34:15.046 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 17 Dec 2019 00:34:15.049 * Running mode=standalone, port=6379.\n1:M 17 Dec 2019 00:34:15.049 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 17 Dec 2019 00:34:15.049 # Server initialized\n1:M 17 Dec 2019 00:34:15.049 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 17 Dec 2019 00:34:15.049 * Ready to accept connections\n"
STEP: exposing RC
Dec 17 00:34:15.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-1700'
Dec 17 00:34:15.951: INFO: stderr: ""
Dec 17 00:34:15.951: INFO: stdout: "service/rm2 exposed\n"
Dec 17 00:34:15.954: INFO: Service rm2 in namespace kubectl-1700 found.
STEP: exposing service
Dec 17 00:34:17.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-1700'
Dec 17 00:34:18.073: INFO: stderr: ""
Dec 17 00:34:18.073: INFO: stdout: "service/rm3 exposed\n"
Dec 17 00:34:18.076: INFO: Service rm3 in namespace kubectl-1700 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:34:20.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1700" for this suite.
Dec 17 00:34:48.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:34:48.138: INFO: namespace kubectl-1700 deletion completed in 28.055813989s

â€¢ [SLOW TEST:36.584 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:34:48.138: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:34:54.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6304" for this suite.
Dec 17 00:35:00.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:35:00.218: INFO: namespace job-6304 deletion completed in 6.053362908s

â€¢ [SLOW TEST:12.079 seconds]
[sig-apps] Job
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:35:00.218: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Dec 17 00:35:00.242: INFO: Waiting up to 5m0s for pod "client-containers-b09d7820-c8ef-4d88-8ef3-e86a0fdd6d7c" in namespace "containers-6196" to be "success or failure"
Dec 17 00:35:00.245: INFO: Pod "client-containers-b09d7820-c8ef-4d88-8ef3-e86a0fdd6d7c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.137974ms
Dec 17 00:35:02.248: INFO: Pod "client-containers-b09d7820-c8ef-4d88-8ef3-e86a0fdd6d7c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005872394s
STEP: Saw pod success
Dec 17 00:35:02.248: INFO: Pod "client-containers-b09d7820-c8ef-4d88-8ef3-e86a0fdd6d7c" satisfied condition "success or failure"
Dec 17 00:35:02.249: INFO: Trying to get logs from node ip-172-20-34-147.us-east-2.compute.internal pod client-containers-b09d7820-c8ef-4d88-8ef3-e86a0fdd6d7c container test-container: <nil>
STEP: delete the pod
Dec 17 00:35:02.264: INFO: Waiting for pod client-containers-b09d7820-c8ef-4d88-8ef3-e86a0fdd6d7c to disappear
Dec 17 00:35:02.266: INFO: Pod client-containers-b09d7820-c8ef-4d88-8ef3-e86a0fdd6d7c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:35:02.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6196" for this suite.
Dec 17 00:35:08.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:35:08.339: INFO: namespace containers-6196 deletion completed in 6.071412679s

â€¢ [SLOW TEST:8.121 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:35:08.340: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-dd672b53-c401-4b6f-9307-965e40d2fc2a
STEP: Creating a pod to test consume configMaps
Dec 17 00:35:08.416: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-027f48ad-53ed-40c2-b9d4-b52d7afa9199" in namespace "projected-901" to be "success or failure"
Dec 17 00:35:08.419: INFO: Pod "pod-projected-configmaps-027f48ad-53ed-40c2-b9d4-b52d7afa9199": Phase="Pending", Reason="", readiness=false. Elapsed: 2.46993ms
Dec 17 00:35:10.422: INFO: Pod "pod-projected-configmaps-027f48ad-53ed-40c2-b9d4-b52d7afa9199": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005226297s
STEP: Saw pod success
Dec 17 00:35:10.422: INFO: Pod "pod-projected-configmaps-027f48ad-53ed-40c2-b9d4-b52d7afa9199" satisfied condition "success or failure"
Dec 17 00:35:10.424: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-projected-configmaps-027f48ad-53ed-40c2-b9d4-b52d7afa9199 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 00:35:10.446: INFO: Waiting for pod pod-projected-configmaps-027f48ad-53ed-40c2-b9d4-b52d7afa9199 to disappear
Dec 17 00:35:10.448: INFO: Pod pod-projected-configmaps-027f48ad-53ed-40c2-b9d4-b52d7afa9199 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:35:10.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-901" for this suite.
Dec 17 00:35:16.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:35:16.507: INFO: namespace projected-901 deletion completed in 6.056151382s

â€¢ [SLOW TEST:8.168 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:35:16.508: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Dec 17 00:35:16.529: INFO: Waiting up to 5m0s for pod "var-expansion-eab8db51-c34e-40df-8176-1394c449da25" in namespace "var-expansion-5256" to be "success or failure"
Dec 17 00:35:16.532: INFO: Pod "var-expansion-eab8db51-c34e-40df-8176-1394c449da25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.618947ms
Dec 17 00:35:18.534: INFO: Pod "var-expansion-eab8db51-c34e-40df-8176-1394c449da25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005352851s
STEP: Saw pod success
Dec 17 00:35:18.535: INFO: Pod "var-expansion-eab8db51-c34e-40df-8176-1394c449da25" satisfied condition "success or failure"
Dec 17 00:35:18.536: INFO: Trying to get logs from node ip-172-20-34-147.us-east-2.compute.internal pod var-expansion-eab8db51-c34e-40df-8176-1394c449da25 container dapi-container: <nil>
STEP: delete the pod
Dec 17 00:35:18.551: INFO: Waiting for pod var-expansion-eab8db51-c34e-40df-8176-1394c449da25 to disappear
Dec 17 00:35:18.562: INFO: Pod var-expansion-eab8db51-c34e-40df-8176-1394c449da25 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:35:18.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5256" for this suite.
Dec 17 00:35:24.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:35:24.635: INFO: namespace var-expansion-5256 deletion completed in 6.068946751s

â€¢ [SLOW TEST:8.127 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:35:24.635: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Dec 17 00:35:24.655: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Dec 17 00:35:37.043: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
Dec 17 00:35:40.046: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:35:49.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6284" for this suite.
Dec 17 00:35:55.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:35:56.026: INFO: namespace crd-publish-openapi-6284 deletion completed in 6.061662212s

â€¢ [SLOW TEST:31.391 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:35:56.026: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6944
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-6944
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6944
Dec 17 00:35:56.057: INFO: Found 0 stateful pods, waiting for 1
Dec 17 00:36:06.060: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec 17 00:36:06.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-6944 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 17 00:36:06.235: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 17 00:36:06.235: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 17 00:36:06.235: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 17 00:36:06.238: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 17 00:36:16.243: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 00:36:16.243: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 00:36:16.253: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998664s
Dec 17 00:36:17.256: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996486254s
Dec 17 00:36:18.259: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.993597714s
Dec 17 00:36:19.262: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.990985246s
Dec 17 00:36:20.265: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.988171485s
Dec 17 00:36:21.268: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.984822665s
Dec 17 00:36:22.271: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.981909092s
Dec 17 00:36:23.274: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.978982552s
Dec 17 00:36:24.277: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.975835687s
Dec 17 00:36:25.280: INFO: Verifying statefulset ss doesn't scale past 1 for another 972.536125ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6944
Dec 17 00:36:26.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-6944 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:36:26.446: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 17 00:36:26.446: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 17 00:36:26.446: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 17 00:36:26.452: INFO: Found 2 stateful pods, waiting for 3
Dec 17 00:36:36.455: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 00:36:36.455: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 00:36:36.455: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec 17 00:36:36.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-6944 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 17 00:36:36.623: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 17 00:36:36.623: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 17 00:36:36.623: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 17 00:36:36.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-6944 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 17 00:36:36.792: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 17 00:36:36.792: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 17 00:36:36.792: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 17 00:36:36.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-6944 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 17 00:36:36.959: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 17 00:36:36.959: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 17 00:36:36.959: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 17 00:36:36.959: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 00:36:36.961: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec 17 00:36:46.967: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 00:36:46.967: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 00:36:46.967: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 00:36:46.976: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998636s
Dec 17 00:36:47.979: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995875535s
Dec 17 00:36:48.982: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992522397s
Dec 17 00:36:49.986: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989469556s
Dec 17 00:36:50.988: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.98635212s
Dec 17 00:36:51.991: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.983698112s
Dec 17 00:36:52.995: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.980497327s
Dec 17 00:36:53.998: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.977189624s
Dec 17 00:36:55.001: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.973751007s
Dec 17 00:36:56.004: INFO: Verifying statefulset ss doesn't scale past 3 for another 970.716535ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6944
Dec 17 00:36:57.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-6944 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:36:57.174: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 17 00:36:57.174: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 17 00:36:57.174: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 17 00:36:57.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-6944 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:36:57.347: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 17 00:36:57.347: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 17 00:36:57.347: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 17 00:36:57.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-6944 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:36:57.506: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 17 00:36:57.506: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 17 00:36:57.506: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 17 00:36:57.506: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 17 00:37:07.515: INFO: Deleting all statefulset in ns statefulset-6944
Dec 17 00:37:07.517: INFO: Scaling statefulset ss to 0
Dec 17 00:37:07.523: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 00:37:07.525: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:37:07.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6944" for this suite.
Dec 17 00:37:13.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:37:13.593: INFO: namespace statefulset-6944 deletion completed in 6.058833355s

â€¢ [SLOW TEST:77.567 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:37:13.593: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 00:37:14.281: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 00:37:17.299: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:37:17.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7668" for this suite.
Dec 17 00:37:23.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:37:23.524: INFO: namespace webhook-7668 deletion completed in 6.081377148s
STEP: Destroying namespace "webhook-7668-markers" for this suite.
Dec 17 00:37:29.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:37:29.583: INFO: namespace webhook-7668-markers deletion completed in 6.058577077s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:15.998 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:37:29.591: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 00:37:29.609: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:37:35.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2793" for this suite.
Dec 17 00:37:41.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:37:41.593: INFO: namespace custom-resource-definition-2793 deletion completed in 6.18977192s

â€¢ [SLOW TEST:12.002 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:37:41.593: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-d1f87464-5ac3-4fc6-bf2e-1722370391ef
STEP: Creating a pod to test consume configMaps
Dec 17 00:37:41.622: INFO: Waiting up to 5m0s for pod "pod-configmaps-f171449b-6d41-4223-8419-368bc549d51c" in namespace "configmap-4475" to be "success or failure"
Dec 17 00:37:41.624: INFO: Pod "pod-configmaps-f171449b-6d41-4223-8419-368bc549d51c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.681964ms
Dec 17 00:37:43.626: INFO: Pod "pod-configmaps-f171449b-6d41-4223-8419-368bc549d51c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003896195s
STEP: Saw pod success
Dec 17 00:37:43.626: INFO: Pod "pod-configmaps-f171449b-6d41-4223-8419-368bc549d51c" satisfied condition "success or failure"
Dec 17 00:37:43.628: INFO: Trying to get logs from node ip-172-20-34-147.us-east-2.compute.internal pod pod-configmaps-f171449b-6d41-4223-8419-368bc549d51c container configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 00:37:43.648: INFO: Waiting for pod pod-configmaps-f171449b-6d41-4223-8419-368bc549d51c to disappear
Dec 17 00:37:43.650: INFO: Pod pod-configmaps-f171449b-6d41-4223-8419-368bc549d51c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:37:43.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4475" for this suite.
Dec 17 00:37:49.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:37:49.708: INFO: namespace configmap-4475 deletion completed in 6.05621193s

â€¢ [SLOW TEST:8.115 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:37:49.708: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Dec 17 00:37:50.760: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1217 00:37:50.760165      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:37:50.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2860" for this suite.
Dec 17 00:37:56.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:37:56.828: INFO: namespace gc-2860 deletion completed in 6.065797777s

â€¢ [SLOW TEST:7.120 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:37:56.828: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec 17 00:37:57.544: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 00:38:00.557: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 00:38:00.560: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:38:01.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-9423" for this suite.
Dec 17 00:38:07.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:38:07.773: INFO: namespace crd-webhook-9423 deletion completed in 6.056293631s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

â€¢ [SLOW TEST:10.953 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:38:07.782: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-a308e7f1-ddf2-4727-8089-ad594402671b
STEP: Creating a pod to test consume secrets
Dec 17 00:38:07.822: INFO: Waiting up to 5m0s for pod "pod-secrets-25feb5b8-a3de-4977-a8ed-2600e2372aeb" in namespace "secrets-3181" to be "success or failure"
Dec 17 00:38:07.825: INFO: Pod "pod-secrets-25feb5b8-a3de-4977-a8ed-2600e2372aeb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.760401ms
Dec 17 00:38:09.827: INFO: Pod "pod-secrets-25feb5b8-a3de-4977-a8ed-2600e2372aeb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005844007s
STEP: Saw pod success
Dec 17 00:38:09.828: INFO: Pod "pod-secrets-25feb5b8-a3de-4977-a8ed-2600e2372aeb" satisfied condition "success or failure"
Dec 17 00:38:09.829: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-secrets-25feb5b8-a3de-4977-a8ed-2600e2372aeb container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 00:38:09.849: INFO: Waiting for pod pod-secrets-25feb5b8-a3de-4977-a8ed-2600e2372aeb to disappear
Dec 17 00:38:09.851: INFO: Pod pod-secrets-25feb5b8-a3de-4977-a8ed-2600e2372aeb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:38:09.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3181" for this suite.
Dec 17 00:38:15.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:38:15.910: INFO: namespace secrets-3181 deletion completed in 6.056963328s
STEP: Destroying namespace "secret-namespace-6156" for this suite.
Dec 17 00:38:21.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:38:21.976: INFO: namespace secret-namespace-6156 deletion completed in 6.065205833s

â€¢ [SLOW TEST:14.194 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:38:21.976: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-eba1dd26-6bf6-4270-876f-56e788c2fc2f
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-eba1dd26-6bf6-4270-876f-56e788c2fc2f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:38:26.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3576" for this suite.
Dec 17 00:38:38.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:38:38.108: INFO: namespace projected-3576 deletion completed in 12.070390248s

â€¢ [SLOW TEST:16.132 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:38:38.109: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec 17 00:38:38.133: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5906 /api/v1/namespaces/watch-5906/configmaps/e2e-watch-test-configmap-a f8bc6b29-ea2f-4d0b-b487-b07ff0d8b73d 5451 0 2019-12-17 00:38:38 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 17 00:38:38.133: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5906 /api/v1/namespaces/watch-5906/configmaps/e2e-watch-test-configmap-a f8bc6b29-ea2f-4d0b-b487-b07ff0d8b73d 5451 0 2019-12-17 00:38:38 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec 17 00:38:48.138: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5906 /api/v1/namespaces/watch-5906/configmaps/e2e-watch-test-configmap-a f8bc6b29-ea2f-4d0b-b487-b07ff0d8b73d 5471 0 2019-12-17 00:38:38 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 17 00:38:48.138: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5906 /api/v1/namespaces/watch-5906/configmaps/e2e-watch-test-configmap-a f8bc6b29-ea2f-4d0b-b487-b07ff0d8b73d 5471 0 2019-12-17 00:38:38 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec 17 00:38:58.143: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5906 /api/v1/namespaces/watch-5906/configmaps/e2e-watch-test-configmap-a f8bc6b29-ea2f-4d0b-b487-b07ff0d8b73d 5492 0 2019-12-17 00:38:38 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 17 00:38:58.143: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5906 /api/v1/namespaces/watch-5906/configmaps/e2e-watch-test-configmap-a f8bc6b29-ea2f-4d0b-b487-b07ff0d8b73d 5492 0 2019-12-17 00:38:38 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec 17 00:39:08.147: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5906 /api/v1/namespaces/watch-5906/configmaps/e2e-watch-test-configmap-a f8bc6b29-ea2f-4d0b-b487-b07ff0d8b73d 5512 0 2019-12-17 00:38:38 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 17 00:39:08.147: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5906 /api/v1/namespaces/watch-5906/configmaps/e2e-watch-test-configmap-a f8bc6b29-ea2f-4d0b-b487-b07ff0d8b73d 5512 0 2019-12-17 00:38:38 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec 17 00:39:18.152: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5906 /api/v1/namespaces/watch-5906/configmaps/e2e-watch-test-configmap-b fdd9089c-8828-4d98-9379-e06998772f75 5534 0 2019-12-17 00:39:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 17 00:39:18.152: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5906 /api/v1/namespaces/watch-5906/configmaps/e2e-watch-test-configmap-b fdd9089c-8828-4d98-9379-e06998772f75 5534 0 2019-12-17 00:39:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec 17 00:39:28.157: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5906 /api/v1/namespaces/watch-5906/configmaps/e2e-watch-test-configmap-b fdd9089c-8828-4d98-9379-e06998772f75 5554 0 2019-12-17 00:39:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 17 00:39:28.158: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5906 /api/v1/namespaces/watch-5906/configmaps/e2e-watch-test-configmap-b fdd9089c-8828-4d98-9379-e06998772f75 5554 0 2019-12-17 00:39:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:39:38.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5906" for this suite.
Dec 17 00:39:44.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:39:44.219: INFO: namespace watch-5906 deletion completed in 6.058323568s

â€¢ [SLOW TEST:66.111 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:39:44.220: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Dec 17 00:39:44.249: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-505434119 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:39:44.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1800" for this suite.
Dec 17 00:39:50.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:39:50.389: INFO: namespace kubectl-1800 deletion completed in 6.075254904s

â€¢ [SLOW TEST:6.169 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:39:50.389: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:39:56.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2427" for this suite.
Dec 17 00:40:02.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:40:02.525: INFO: namespace namespaces-2427 deletion completed in 6.063312957s
STEP: Destroying namespace "nsdeletetest-1984" for this suite.
Dec 17 00:40:02.527: INFO: Namespace nsdeletetest-1984 was already deleted
STEP: Destroying namespace "nsdeletetest-7604" for this suite.
Dec 17 00:40:08.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:40:08.609: INFO: namespace nsdeletetest-7604 deletion completed in 6.082553712s

â€¢ [SLOW TEST:18.220 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:40:08.609: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Dec 17 00:40:08.628: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Dec 17 00:40:09.909: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Dec 17 00:40:11.939: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140009, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140009, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140009, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140009, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 00:40:13.942: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140009, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140009, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140009, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140009, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 00:40:15.943: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140009, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140009, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140009, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140009, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 00:40:17.942: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140009, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140009, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140009, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140009, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 00:40:19.942: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140009, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140009, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140009, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140009, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 00:40:23.467: INFO: Waited 1.518331773s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:40:23.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-7584" for this suite.
Dec 17 00:40:30.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:40:30.069: INFO: namespace aggregator-7584 deletion completed in 6.162381877s

â€¢ [SLOW TEST:21.460 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:40:30.070: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec 17 00:40:30.671: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Dec 17 00:40:32.677: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140030, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140030, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140030, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140030, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 00:40:35.689: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 00:40:35.691: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:40:36.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-7804" for this suite.
Dec 17 00:40:42.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:40:42.925: INFO: namespace crd-webhook-7804 deletion completed in 6.056518048s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

â€¢ [SLOW TEST:12.864 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:40:42.934: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec 17 00:40:42.955: INFO: Waiting up to 5m0s for pod "pod-0617ae3d-890e-4821-a08d-cd6bc6ec2893" in namespace "emptydir-6551" to be "success or failure"
Dec 17 00:40:42.959: INFO: Pod "pod-0617ae3d-890e-4821-a08d-cd6bc6ec2893": Phase="Pending", Reason="", readiness=false. Elapsed: 3.803937ms
Dec 17 00:40:44.962: INFO: Pod "pod-0617ae3d-890e-4821-a08d-cd6bc6ec2893": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006565478s
STEP: Saw pod success
Dec 17 00:40:44.962: INFO: Pod "pod-0617ae3d-890e-4821-a08d-cd6bc6ec2893" satisfied condition "success or failure"
Dec 17 00:40:44.964: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-0617ae3d-890e-4821-a08d-cd6bc6ec2893 container test-container: <nil>
STEP: delete the pod
Dec 17 00:40:44.984: INFO: Waiting for pod pod-0617ae3d-890e-4821-a08d-cd6bc6ec2893 to disappear
Dec 17 00:40:44.986: INFO: Pod pod-0617ae3d-890e-4821-a08d-cd6bc6ec2893 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:40:44.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6551" for this suite.
Dec 17 00:40:51.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:40:51.057: INFO: namespace emptydir-6551 deletion completed in 6.066883907s

â€¢ [SLOW TEST:8.123 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:40:51.057: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Dec 17 00:40:51.080: INFO: Waiting up to 5m0s for pod "client-containers-0cdd5a59-7814-4398-b950-061a72a33d85" in namespace "containers-845" to be "success or failure"
Dec 17 00:40:51.083: INFO: Pod "client-containers-0cdd5a59-7814-4398-b950-061a72a33d85": Phase="Pending", Reason="", readiness=false. Elapsed: 2.46342ms
Dec 17 00:40:53.085: INFO: Pod "client-containers-0cdd5a59-7814-4398-b950-061a72a33d85": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00457747s
STEP: Saw pod success
Dec 17 00:40:53.085: INFO: Pod "client-containers-0cdd5a59-7814-4398-b950-061a72a33d85" satisfied condition "success or failure"
Dec 17 00:40:53.087: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod client-containers-0cdd5a59-7814-4398-b950-061a72a33d85 container test-container: <nil>
STEP: delete the pod
Dec 17 00:40:53.098: INFO: Waiting for pod client-containers-0cdd5a59-7814-4398-b950-061a72a33d85 to disappear
Dec 17 00:40:53.099: INFO: Pod client-containers-0cdd5a59-7814-4398-b950-061a72a33d85 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:40:53.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-845" for this suite.
Dec 17 00:40:59.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:40:59.163: INFO: namespace containers-845 deletion completed in 6.060934269s

â€¢ [SLOW TEST:8.106 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:40:59.163: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Dec 17 00:40:59.182: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-505434119 proxy --unix-socket=/tmp/kubectl-proxy-unix344451954/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:40:59.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9677" for this suite.
Dec 17 00:41:05.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:41:05.301: INFO: namespace kubectl-9677 deletion completed in 6.061834565s

â€¢ [SLOW TEST:6.138 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:41:05.301: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec 17 00:41:05.335: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5910 /api/v1/namespaces/watch-5910/configmaps/e2e-watch-test-resource-version fd558bf9-69b8-430f-b89a-cf5c02df48fe 5944 0 2019-12-17 00:41:05 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 17 00:41:05.335: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5910 /api/v1/namespaces/watch-5910/configmaps/e2e-watch-test-resource-version fd558bf9-69b8-430f-b89a-cf5c02df48fe 5945 0 2019-12-17 00:41:05 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:41:05.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5910" for this suite.
Dec 17 00:41:11.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:41:11.401: INFO: namespace watch-5910 deletion completed in 6.063108293s

â€¢ [SLOW TEST:6.100 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:41:11.402: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-c6d83e29-c23f-420e-9a98-4e18875aac12
STEP: Creating a pod to test consume secrets
Dec 17 00:41:11.425: INFO: Waiting up to 5m0s for pod "pod-secrets-5bd1dcf8-db77-4a14-a755-3123aa6bacc7" in namespace "secrets-6712" to be "success or failure"
Dec 17 00:41:11.428: INFO: Pod "pod-secrets-5bd1dcf8-db77-4a14-a755-3123aa6bacc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.563899ms
Dec 17 00:41:13.431: INFO: Pod "pod-secrets-5bd1dcf8-db77-4a14-a755-3123aa6bacc7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005574883s
STEP: Saw pod success
Dec 17 00:41:13.431: INFO: Pod "pod-secrets-5bd1dcf8-db77-4a14-a755-3123aa6bacc7" satisfied condition "success or failure"
Dec 17 00:41:13.433: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-secrets-5bd1dcf8-db77-4a14-a755-3123aa6bacc7 container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 00:41:13.448: INFO: Waiting for pod pod-secrets-5bd1dcf8-db77-4a14-a755-3123aa6bacc7 to disappear
Dec 17 00:41:13.450: INFO: Pod pod-secrets-5bd1dcf8-db77-4a14-a755-3123aa6bacc7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:41:13.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6712" for this suite.
Dec 17 00:41:19.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:41:19.511: INFO: namespace secrets-6712 deletion completed in 6.058236506s

â€¢ [SLOW TEST:8.109 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:41:19.511: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:41:19.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2594" for this suite.
Dec 17 00:41:25.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:41:25.602: INFO: namespace services-2594 deletion completed in 6.069340798s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:6.092 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:41:25.603: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-b228c9f2-549c-49e3-9a9e-22d88a4788bf
STEP: Creating secret with name secret-projected-all-test-volume-c6a492d6-fbda-4e63-96e8-508477e240d9
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec 17 00:41:25.631: INFO: Waiting up to 5m0s for pod "projected-volume-7fd3cdab-cfb3-4edf-a804-3213d4623632" in namespace "projected-6431" to be "success or failure"
Dec 17 00:41:25.633: INFO: Pod "projected-volume-7fd3cdab-cfb3-4edf-a804-3213d4623632": Phase="Pending", Reason="", readiness=false. Elapsed: 2.412252ms
Dec 17 00:41:27.637: INFO: Pod "projected-volume-7fd3cdab-cfb3-4edf-a804-3213d4623632": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00566734s
STEP: Saw pod success
Dec 17 00:41:27.637: INFO: Pod "projected-volume-7fd3cdab-cfb3-4edf-a804-3213d4623632" satisfied condition "success or failure"
Dec 17 00:41:27.639: INFO: Trying to get logs from node ip-172-20-34-147.us-east-2.compute.internal pod projected-volume-7fd3cdab-cfb3-4edf-a804-3213d4623632 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec 17 00:41:27.662: INFO: Waiting for pod projected-volume-7fd3cdab-cfb3-4edf-a804-3213d4623632 to disappear
Dec 17 00:41:27.664: INFO: Pod projected-volume-7fd3cdab-cfb3-4edf-a804-3213d4623632 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:41:27.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6431" for this suite.
Dec 17 00:41:33.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:41:33.737: INFO: namespace projected-6431 deletion completed in 6.070110392s

â€¢ [SLOW TEST:8.134 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:41:33.737: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 00:41:33.755: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Dec 17 00:41:35.777: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:41:36.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5505" for this suite.
Dec 17 00:41:42.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:41:42.840: INFO: namespace replication-controller-5505 deletion completed in 6.05659642s

â€¢ [SLOW TEST:9.103 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:41:42.840: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Dec 17 00:41:42.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 cluster-info'
Dec 17 00:41:43.078: INFO: stderr: ""
Dec 17 00:41:43.078: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:41:43.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4893" for this suite.
Dec 17 00:41:49.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:41:49.140: INFO: namespace kubectl-4893 deletion completed in 6.059612628s

â€¢ [SLOW TEST:6.300 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:41:49.140: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 00:41:49.164: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec 17 00:41:54.167: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 17 00:41:54.167: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec 17 00:41:56.170: INFO: Creating deployment "test-rollover-deployment"
Dec 17 00:41:56.175: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec 17 00:41:58.180: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec 17 00:41:58.183: INFO: Ensure that both replica sets have 1 created replica
Dec 17 00:41:58.186: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec 17 00:41:58.192: INFO: Updating deployment test-rollover-deployment
Dec 17 00:41:58.192: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec 17 00:42:00.198: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec 17 00:42:00.202: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec 17 00:42:00.206: INFO: all replica sets need to contain the pod-template-hash label
Dec 17 00:42:00.206: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140116, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140116, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140118, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140116, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 00:42:02.211: INFO: all replica sets need to contain the pod-template-hash label
Dec 17 00:42:02.211: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140116, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140116, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140121, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140116, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 00:42:04.211: INFO: all replica sets need to contain the pod-template-hash label
Dec 17 00:42:04.211: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140116, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140116, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140121, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140116, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 00:42:06.211: INFO: all replica sets need to contain the pod-template-hash label
Dec 17 00:42:06.211: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140116, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140116, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140121, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140116, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 00:42:08.210: INFO: all replica sets need to contain the pod-template-hash label
Dec 17 00:42:08.210: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140116, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140116, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140121, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140116, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 00:42:10.211: INFO: all replica sets need to contain the pod-template-hash label
Dec 17 00:42:10.211: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140116, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140116, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140121, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140116, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 00:42:12.212: INFO: 
Dec 17 00:42:12.212: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 17 00:42:12.218: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-7420 /apis/apps/v1/namespaces/deployment-7420/deployments/test-rollover-deployment 448c7b0e-96ab-4eb0-8c21-76eed45d5269 6228 2 2019-12-17 00:41:56 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002710a48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-17 00:41:56 +0000 UTC,LastTransitionTime:2019-12-17 00:41:56 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2019-12-17 00:42:11 +0000 UTC,LastTransitionTime:2019-12-17 00:41:56 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 17 00:42:12.220: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-7420 /apis/apps/v1/namespaces/deployment-7420/replicasets/test-rollover-deployment-7d7dc6548c ccf2bbd5-6345-4bb2-9552-35897fdc715c 6221 2 2019-12-17 00:41:58 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 448c7b0e-96ab-4eb0-8c21-76eed45d5269 0xc002710ef7 0xc002710ef8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002710f58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 17 00:42:12.220: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec 17 00:42:12.220: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-7420 /apis/apps/v1/namespaces/deployment-7420/replicasets/test-rollover-controller 5907cbac-a969-46dc-8bac-d293ca5ffdbc 6227 2 2019-12-17 00:41:49 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 448c7b0e-96ab-4eb0-8c21-76eed45d5269 0xc002710e1f 0xc002710e30}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002710e98 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 17 00:42:12.220: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-7420 /apis/apps/v1/namespaces/deployment-7420/replicasets/test-rollover-deployment-f6c94f66c cb619133-067f-4fad-b31f-4d8c01baa129 6188 2 2019-12-17 00:41:56 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 448c7b0e-96ab-4eb0-8c21-76eed45d5269 0xc002710fb0 0xc002710fb1}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002711028 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 17 00:42:12.223: INFO: Pod "test-rollover-deployment-7d7dc6548c-hk8qt" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-hk8qt test-rollover-deployment-7d7dc6548c- deployment-7420 /api/v1/namespaces/deployment-7420/pods/test-rollover-deployment-7d7dc6548c-hk8qt f60de0f2-511d-4d54-8729-ca1488978514 6199 0 2019-12-17 00:41:58 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c ccf2bbd5-6345-4bb2-9552-35897fdc715c 0xc002711567 0xc002711568}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4xt5l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4xt5l,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4xt5l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-58-188.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 00:41:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 00:42:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 00:42:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 00:41:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.58.188,PodIP:100.96.1.60,StartTime:2019-12-17 00:41:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 00:42:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://aa922b24b6c052709260204bf737437d45d101c3294fc12210188c02b6051253,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.60,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:42:12.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7420" for this suite.
Dec 17 00:42:18.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:42:18.300: INFO: namespace deployment-7420 deletion completed in 6.074619971s

â€¢ [SLOW TEST:29.160 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:42:18.300: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-7368
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-7368
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7368
Dec 17 00:42:18.332: INFO: Found 0 stateful pods, waiting for 1
Dec 17 00:42:28.334: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec 17 00:42:28.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 17 00:42:28.504: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 17 00:42:28.504: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 17 00:42:28.504: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 17 00:42:28.507: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 17 00:42:38.510: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 00:42:38.510: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 00:42:38.518: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Dec 17 00:42:38.518: INFO: ss-0  ip-172-20-58-188.us-east-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:18 +0000 UTC  }]
Dec 17 00:42:38.518: INFO: 
Dec 17 00:42:38.518: INFO: StatefulSet ss has not reached scale 3, at 1
Dec 17 00:42:39.527: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997789888s
Dec 17 00:42:40.530: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988439893s
Dec 17 00:42:41.538: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985240438s
Dec 17 00:42:42.541: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.977723072s
Dec 17 00:42:43.545: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.974681033s
Dec 17 00:42:44.548: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.97066241s
Dec 17 00:42:45.553: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.967486215s
Dec 17 00:42:46.556: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.962751203s
Dec 17 00:42:47.560: INFO: Verifying statefulset ss doesn't scale past 3 for another 959.063645ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7368
Dec 17 00:42:48.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:42:48.732: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 17 00:42:48.732: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 17 00:42:48.732: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 17 00:42:48.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:42:48.915: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 17 00:42:48.915: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 17 00:42:48.915: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 17 00:42:48.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:42:49.109: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 17 00:42:49.109: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 17 00:42:49.110: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 17 00:42:49.112: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Dec 17 00:42:59.116: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 00:42:59.116: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 00:42:59.116: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec 17 00:42:59.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 17 00:42:59.287: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 17 00:42:59.287: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 17 00:42:59.287: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 17 00:42:59.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 17 00:42:59.470: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 17 00:42:59.470: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 17 00:42:59.470: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 17 00:42:59.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 17 00:42:59.639: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 17 00:42:59.639: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 17 00:42:59.639: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 17 00:42:59.639: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 00:42:59.641: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec 17 00:43:09.648: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 00:43:09.648: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 00:43:09.648: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 00:43:09.656: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Dec 17 00:43:09.656: INFO: ss-0  ip-172-20-58-188.us-east-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:18 +0000 UTC  }]
Dec 17 00:43:09.656: INFO: ss-1  ip-172-20-34-147.us-east-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  }]
Dec 17 00:43:09.656: INFO: ss-2  ip-172-20-58-188.us-east-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  }]
Dec 17 00:43:09.656: INFO: 
Dec 17 00:43:09.656: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 17 00:43:10.659: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Dec 17 00:43:10.659: INFO: ss-0  ip-172-20-58-188.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:18 +0000 UTC  }]
Dec 17 00:43:10.659: INFO: ss-1  ip-172-20-34-147.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  }]
Dec 17 00:43:10.659: INFO: ss-2  ip-172-20-58-188.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  }]
Dec 17 00:43:10.659: INFO: 
Dec 17 00:43:10.659: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 17 00:43:11.662: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Dec 17 00:43:11.662: INFO: ss-0  ip-172-20-58-188.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:18 +0000 UTC  }]
Dec 17 00:43:11.662: INFO: ss-1  ip-172-20-34-147.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  }]
Dec 17 00:43:11.662: INFO: ss-2  ip-172-20-58-188.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  }]
Dec 17 00:43:11.662: INFO: 
Dec 17 00:43:11.662: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 17 00:43:12.665: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Dec 17 00:43:12.665: INFO: ss-0  ip-172-20-58-188.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:18 +0000 UTC  }]
Dec 17 00:43:12.665: INFO: ss-1  ip-172-20-34-147.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  }]
Dec 17 00:43:12.665: INFO: ss-2  ip-172-20-58-188.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  }]
Dec 17 00:43:12.665: INFO: 
Dec 17 00:43:12.665: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 17 00:43:13.668: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Dec 17 00:43:13.668: INFO: ss-0  ip-172-20-58-188.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:18 +0000 UTC  }]
Dec 17 00:43:13.668: INFO: ss-1  ip-172-20-34-147.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  }]
Dec 17 00:43:13.668: INFO: ss-2  ip-172-20-58-188.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  }]
Dec 17 00:43:13.668: INFO: 
Dec 17 00:43:13.668: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 17 00:43:14.672: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Dec 17 00:43:14.672: INFO: ss-0  ip-172-20-58-188.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:18 +0000 UTC  }]
Dec 17 00:43:14.672: INFO: ss-1  ip-172-20-34-147.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  }]
Dec 17 00:43:14.672: INFO: ss-2  ip-172-20-58-188.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  }]
Dec 17 00:43:14.672: INFO: 
Dec 17 00:43:14.672: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 17 00:43:15.676: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Dec 17 00:43:15.676: INFO: ss-0  ip-172-20-58-188.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:18 +0000 UTC  }]
Dec 17 00:43:15.676: INFO: ss-1  ip-172-20-34-147.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  }]
Dec 17 00:43:15.676: INFO: ss-2  ip-172-20-58-188.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  }]
Dec 17 00:43:15.676: INFO: 
Dec 17 00:43:15.676: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 17 00:43:16.679: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Dec 17 00:43:16.679: INFO: ss-0  ip-172-20-58-188.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:18 +0000 UTC  }]
Dec 17 00:43:16.679: INFO: ss-1  ip-172-20-34-147.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  }]
Dec 17 00:43:16.679: INFO: ss-2  ip-172-20-58-188.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  }]
Dec 17 00:43:16.679: INFO: 
Dec 17 00:43:16.679: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 17 00:43:17.682: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Dec 17 00:43:17.682: INFO: ss-0  ip-172-20-58-188.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:18 +0000 UTC  }]
Dec 17 00:43:17.682: INFO: ss-1  ip-172-20-34-147.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  }]
Dec 17 00:43:17.682: INFO: ss-2  ip-172-20-58-188.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  }]
Dec 17 00:43:17.683: INFO: 
Dec 17 00:43:17.683: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 17 00:43:18.686: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Dec 17 00:43:18.687: INFO: ss-0  ip-172-20-58-188.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:18 +0000 UTC  }]
Dec 17 00:43:18.687: INFO: ss-1  ip-172-20-34-147.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  }]
Dec 17 00:43:18.687: INFO: ss-2  ip-172-20-58-188.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 00:42:38 +0000 UTC  }]
Dec 17 00:43:18.687: INFO: 
Dec 17 00:43:18.687: INFO: StatefulSet ss has not reached scale 0, at 3
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7368
Dec 17 00:43:19.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:43:19.787: INFO: rc: 1
Dec 17 00:43:19.787: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  error: unable to upgrade connection: container not found ("webserver")
 [] <nil> 0xc00398da10 exit status 1 <nil> <nil> true [0xc0037ea240 0xc0037ea258 0xc0037ea270] [0xc0037ea240 0xc0037ea258 0xc0037ea270] [0xc0037ea250 0xc0037ea268] [0x10efe30 0x10efe30] 0xc005c6a2a0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Dec 17 00:43:29.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:43:29.897: INFO: rc: 1
Dec 17 00:43:29.897: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0032c2660 exit status 1 <nil> <nil> true [0xc003234298 0xc0032342b0 0xc0032342c8] [0xc003234298 0xc0032342b0 0xc0032342c8] [0xc0032342a8 0xc0032342c0] [0x10efe30 0x10efe30] 0xc0067ce4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:43:39.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:43:39.968: INFO: rc: 1
Dec 17 00:43:39.968: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00398dd70 exit status 1 <nil> <nil> true [0xc0037ea278 0xc0037ea290 0xc0037ea2a8] [0xc0037ea278 0xc0037ea290 0xc0037ea2a8] [0xc0037ea288 0xc0037ea2a0] [0x10efe30 0x10efe30] 0xc005c6a600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:43:49.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:43:50.040: INFO: rc: 1
Dec 17 00:43:50.040: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0032c29c0 exit status 1 <nil> <nil> true [0xc0032342d0 0xc0032342e8 0xc003234300] [0xc0032342d0 0xc0032342e8 0xc003234300] [0xc0032342e0 0xc0032342f8] [0x10efe30 0x10efe30] 0xc0067ce840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:44:00.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:44:00.112: INFO: rc: 1
Dec 17 00:44:00.112: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0032c2cf0 exit status 1 <nil> <nil> true [0xc003234308 0xc003234320 0xc003234338] [0xc003234308 0xc003234320 0xc003234338] [0xc003234318 0xc003234330] [0x10efe30 0x10efe30] 0xc0067ceba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:44:10.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:44:10.183: INFO: rc: 1
Dec 17 00:44:10.183: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0036d4120 exit status 1 <nil> <nil> true [0xc0037ea2b0 0xc0037ea2c8 0xc0037ea2e0] [0xc0037ea2b0 0xc0037ea2c8 0xc0037ea2e0] [0xc0037ea2c0 0xc0037ea2d8] [0x10efe30 0x10efe30] 0xc005c6a960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:44:20.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:44:20.257: INFO: rc: 1
Dec 17 00:44:20.257: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0036d4450 exit status 1 <nil> <nil> true [0xc0037ea2e8 0xc0037ea300 0xc0037ea318] [0xc0037ea2e8 0xc0037ea300 0xc0037ea318] [0xc0037ea2f8 0xc0037ea310] [0x10efe30 0x10efe30] 0xc005c6ad20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:44:30.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:44:30.327: INFO: rc: 1
Dec 17 00:44:30.327: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0032c3080 exit status 1 <nil> <nil> true [0xc003234340 0xc003234358 0xc003234370] [0xc003234340 0xc003234358 0xc003234370] [0xc003234350 0xc003234368] [0x10efe30 0x10efe30] 0xc0067cf080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:44:40.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:44:40.398: INFO: rc: 1
Dec 17 00:44:40.399: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0036d47e0 exit status 1 <nil> <nil> true [0xc0037ea320 0xc0037ea338 0xc0037ea350] [0xc0037ea320 0xc0037ea338 0xc0037ea350] [0xc0037ea330 0xc0037ea348] [0x10efe30 0x10efe30] 0xc005c6b080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:44:50.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:44:50.474: INFO: rc: 1
Dec 17 00:44:50.474: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00398c390 exit status 1 <nil> <nil> true [0xc003234008 0xc003234020 0xc003234038] [0xc003234008 0xc003234020 0xc003234038] [0xc003234018 0xc003234030] [0x10efe30 0x10efe30] 0xc00315a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:45:00.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:45:00.546: INFO: rc: 1
Dec 17 00:45:00.546: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00400e390 exit status 1 <nil> <nil> true [0xc0037ea000 0xc0037ea018 0xc0037ea030] [0xc0037ea000 0xc0037ea018 0xc0037ea030] [0xc0037ea010 0xc0037ea028] [0x10efe30 0x10efe30] 0xc0026762a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:45:10.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:45:10.620: INFO: rc: 1
Dec 17 00:45:10.620: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00398c720 exit status 1 <nil> <nil> true [0xc003234040 0xc003234058 0xc003234070] [0xc003234040 0xc003234058 0xc003234070] [0xc003234050 0xc003234068] [0x10efe30 0x10efe30] 0xc00315a660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:45:20.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:45:20.692: INFO: rc: 1
Dec 17 00:45:20.692: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00398ca50 exit status 1 <nil> <nil> true [0xc003234078 0xc003234090 0xc0032340a8] [0xc003234078 0xc003234090 0xc0032340a8] [0xc003234088 0xc0032340a0] [0x10efe30 0x10efe30] 0xc00315aa20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:45:30.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:45:30.766: INFO: rc: 1
Dec 17 00:45:30.766: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00400e6f0 exit status 1 <nil> <nil> true [0xc0037ea038 0xc0037ea050 0xc0037ea068] [0xc0037ea038 0xc0037ea050 0xc0037ea068] [0xc0037ea048 0xc0037ea060] [0x10efe30 0x10efe30] 0xc002676600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:45:40.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:45:40.838: INFO: rc: 1
Dec 17 00:45:40.838: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00398cdb0 exit status 1 <nil> <nil> true [0xc0032340b0 0xc0032340c8 0xc0032340e0] [0xc0032340b0 0xc0032340c8 0xc0032340e0] [0xc0032340c0 0xc0032340d8] [0x10efe30 0x10efe30] 0xc00315ad80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:45:50.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:45:50.912: INFO: rc: 1
Dec 17 00:45:50.912: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00398d0e0 exit status 1 <nil> <nil> true [0xc0032340e8 0xc003234100 0xc003234118] [0xc0032340e8 0xc003234100 0xc003234118] [0xc0032340f8 0xc003234110] [0x10efe30 0x10efe30] 0xc00315b0e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:46:00.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:46:00.985: INFO: rc: 1
Dec 17 00:46:00.985: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00400ea80 exit status 1 <nil> <nil> true [0xc0037ea070 0xc0037ea088 0xc0037ea0a0] [0xc0037ea070 0xc0037ea088 0xc0037ea0a0] [0xc0037ea080 0xc0037ea098] [0x10efe30 0x10efe30] 0xc002676960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:46:10.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:46:11.058: INFO: rc: 1
Dec 17 00:46:11.058: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00398d980 exit status 1 <nil> <nil> true [0xc003234120 0xc003234138 0xc003234150] [0xc003234120 0xc003234138 0xc003234150] [0xc003234130 0xc003234148] [0x10efe30 0x10efe30] 0xc00315b620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:46:21.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:46:21.131: INFO: rc: 1
Dec 17 00:46:21.131: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00400edb0 exit status 1 <nil> <nil> true [0xc0037ea0a8 0xc0037ea0c0 0xc0037ea0d8] [0xc0037ea0a8 0xc0037ea0c0 0xc0037ea0d8] [0xc0037ea0b8 0xc0037ea0d0] [0x10efe30 0x10efe30] 0xc002676cc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:46:31.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:46:31.202: INFO: rc: 1
Dec 17 00:46:31.202: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00400f0e0 exit status 1 <nil> <nil> true [0xc0037ea0e0 0xc0037ea0f8 0xc0037ea110] [0xc0037ea0e0 0xc0037ea0f8 0xc0037ea110] [0xc0037ea0f0 0xc0037ea108] [0x10efe30 0x10efe30] 0xc002677080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:46:41.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:46:41.278: INFO: rc: 1
Dec 17 00:46:41.278: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00398dd40 exit status 1 <nil> <nil> true [0xc003234158 0xc003234170 0xc003234188] [0xc003234158 0xc003234170 0xc003234188] [0xc003234168 0xc003234180] [0x10efe30 0x10efe30] 0xc00315b980 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:46:51.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:46:51.356: INFO: rc: 1
Dec 17 00:46:51.357: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00398c3c0 exit status 1 <nil> <nil> true [0xc003234008 0xc003234020 0xc003234038] [0xc003234008 0xc003234020 0xc003234038] [0xc003234018 0xc003234030] [0x10efe30 0x10efe30] 0xc00315a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:47:01.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:47:01.427: INFO: rc: 1
Dec 17 00:47:01.427: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00400e3c0 exit status 1 <nil> <nil> true [0xc0037ea000 0xc0037ea018 0xc0037ea030] [0xc0037ea000 0xc0037ea018 0xc0037ea030] [0xc0037ea010 0xc0037ea028] [0x10efe30 0x10efe30] 0xc0026762a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:47:11.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:47:11.499: INFO: rc: 1
Dec 17 00:47:11.499: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00398c750 exit status 1 <nil> <nil> true [0xc003234040 0xc003234058 0xc003234070] [0xc003234040 0xc003234058 0xc003234070] [0xc003234050 0xc003234068] [0x10efe30 0x10efe30] 0xc00315a660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:47:21.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:47:21.571: INFO: rc: 1
Dec 17 00:47:21.571: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00400e750 exit status 1 <nil> <nil> true [0xc0037ea038 0xc0037ea050 0xc0037ea068] [0xc0037ea038 0xc0037ea050 0xc0037ea068] [0xc0037ea048 0xc0037ea060] [0x10efe30 0x10efe30] 0xc002676600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:47:31.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:47:31.642: INFO: rc: 1
Dec 17 00:47:31.642: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00398cae0 exit status 1 <nil> <nil> true [0xc003234078 0xc003234090 0xc0032340a8] [0xc003234078 0xc003234090 0xc0032340a8] [0xc003234088 0xc0032340a0] [0x10efe30 0x10efe30] 0xc00315aa20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:47:41.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:47:41.716: INFO: rc: 1
Dec 17 00:47:41.716: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00398ce70 exit status 1 <nil> <nil> true [0xc0032340b0 0xc0032340c8 0xc0032340e0] [0xc0032340b0 0xc0032340c8 0xc0032340e0] [0xc0032340c0 0xc0032340d8] [0x10efe30 0x10efe30] 0xc00315ad80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:47:51.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:47:51.788: INFO: rc: 1
Dec 17 00:47:51.788: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00398d1d0 exit status 1 <nil> <nil> true [0xc0032340e8 0xc003234100 0xc003234118] [0xc0032340e8 0xc003234100 0xc003234118] [0xc0032340f8 0xc003234110] [0x10efe30 0x10efe30] 0xc00315b0e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:48:01.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:48:01.862: INFO: rc: 1
Dec 17 00:48:01.863: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00398da70 exit status 1 <nil> <nil> true [0xc003234120 0xc003234138 0xc003234150] [0xc003234120 0xc003234138 0xc003234150] [0xc003234130 0xc003234148] [0x10efe30 0x10efe30] 0xc00315b620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:48:11.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:48:11.937: INFO: rc: 1
Dec 17 00:48:11.937: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00398de00 exit status 1 <nil> <nil> true [0xc003234158 0xc003234170 0xc003234188] [0xc003234158 0xc003234170 0xc003234188] [0xc003234168 0xc003234180] [0x10efe30 0x10efe30] 0xc00315b980 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 00:48:21.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-7368 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 00:48:22.013: INFO: rc: 1
Dec 17 00:48:22.013: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: 
Dec 17 00:48:22.013: INFO: Scaling statefulset ss to 0
Dec 17 00:48:22.019: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 17 00:48:22.021: INFO: Deleting all statefulset in ns statefulset-7368
Dec 17 00:48:22.023: INFO: Scaling statefulset ss to 0
Dec 17 00:48:22.028: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 00:48:22.029: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:48:22.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7368" for this suite.
Dec 17 00:48:28.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:48:28.103: INFO: namespace statefulset-7368 deletion completed in 6.06323161s

â€¢ [SLOW TEST:369.803 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:48:28.103: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Dec 17 00:48:28.121: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec 17 00:48:28.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 create -f - --namespace=kubectl-4105'
Dec 17 00:48:28.324: INFO: stderr: ""
Dec 17 00:48:28.324: INFO: stdout: "service/redis-slave created\n"
Dec 17 00:48:28.324: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec 17 00:48:28.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 create -f - --namespace=kubectl-4105'
Dec 17 00:48:28.505: INFO: stderr: ""
Dec 17 00:48:28.505: INFO: stdout: "service/redis-master created\n"
Dec 17 00:48:28.505: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec 17 00:48:28.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 create -f - --namespace=kubectl-4105'
Dec 17 00:48:28.684: INFO: stderr: ""
Dec 17 00:48:28.684: INFO: stdout: "service/frontend created\n"
Dec 17 00:48:28.684: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec 17 00:48:28.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 create -f - --namespace=kubectl-4105'
Dec 17 00:48:28.845: INFO: stderr: ""
Dec 17 00:48:28.845: INFO: stdout: "deployment.apps/frontend created\n"
Dec 17 00:48:28.845: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 17 00:48:28.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 create -f - --namespace=kubectl-4105'
Dec 17 00:48:29.001: INFO: stderr: ""
Dec 17 00:48:29.001: INFO: stdout: "deployment.apps/redis-master created\n"
Dec 17 00:48:29.002: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec 17 00:48:29.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 create -f - --namespace=kubectl-4105'
Dec 17 00:48:29.298: INFO: stderr: ""
Dec 17 00:48:29.298: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Dec 17 00:48:29.298: INFO: Waiting for all frontend pods to be Running.
Dec 17 00:48:44.349: INFO: Waiting for frontend to serve content.
Dec 17 00:48:44.360: INFO: Trying to add a new entry to the guestbook.
Dec 17 00:48:44.370: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec 17 00:48:44.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 delete --grace-period=0 --force -f - --namespace=kubectl-4105'
Dec 17 00:48:44.462: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 00:48:44.462: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec 17 00:48:44.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 delete --grace-period=0 --force -f - --namespace=kubectl-4105'
Dec 17 00:48:44.584: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 00:48:44.584: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 17 00:48:44.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 delete --grace-period=0 --force -f - --namespace=kubectl-4105'
Dec 17 00:48:44.673: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 00:48:44.673: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 17 00:48:44.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 delete --grace-period=0 --force -f - --namespace=kubectl-4105'
Dec 17 00:48:44.754: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 00:48:44.754: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 17 00:48:44.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 delete --grace-period=0 --force -f - --namespace=kubectl-4105'
Dec 17 00:48:44.851: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 00:48:44.851: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 17 00:48:44.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 delete --grace-period=0 --force -f - --namespace=kubectl-4105'
Dec 17 00:48:44.970: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 00:48:44.970: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:48:44.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4105" for this suite.
Dec 17 00:48:56.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:48:57.037: INFO: namespace kubectl-4105 deletion completed in 12.062784511s

â€¢ [SLOW TEST:28.934 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:48:57.037: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec 17 00:48:59.070: INFO: &Pod{ObjectMeta:{send-events-6de2d907-04bb-4820-9f0c-be40e25476fc  events-50 /api/v1/namespaces/events-50/pods/send-events-6de2d907-04bb-4820-9f0c-be40e25476fc 64f1b760-5849-4796-b43d-3138338c1277 7248 0 2019-12-17 00:48:57 +0000 UTC <nil> <nil> map[name:foo time:59179346] map[] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-7q5fg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-7q5fg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-7q5fg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-34-147.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 00:48:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 00:48:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 00:48:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 00:48:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.34.147,PodIP:100.96.2.59,StartTime:2019-12-17 00:48:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 00:48:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:docker://2263d647e106d355cffda34fe7805cab3adb3b30132ef66f93ed823de5588c30,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.59,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Dec 17 00:49:01.072: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec 17 00:49:03.075: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:49:03.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-50" for this suite.
Dec 17 00:49:47.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:49:47.156: INFO: namespace events-50 deletion completed in 44.074739838s

â€¢ [SLOW TEST:50.119 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:49:47.156: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Dec 17 00:49:47.177: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 17 00:50:47.198: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 00:50:47.201: INFO: Starting informer...
STEP: Starting pods...
Dec 17 00:50:47.412: INFO: Pod1 is running on ip-172-20-58-188.us-east-2.compute.internal. Tainting Node
Dec 17 00:50:49.624: INFO: Pod2 is running on ip-172-20-58-188.us-east-2.compute.internal. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Dec 17 00:50:56.610: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Dec 17 00:51:16.726: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:51:16.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-2844" for this suite.
Dec 17 00:51:22.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:51:22.794: INFO: namespace taint-multiple-pods-2844 deletion completed in 6.056776551s

â€¢ [SLOW TEST:95.638 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:51:22.794: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-6m42
STEP: Creating a pod to test atomic-volume-subpath
Dec 17 00:51:22.823: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-6m42" in namespace "subpath-9110" to be "success or failure"
Dec 17 00:51:22.826: INFO: Pod "pod-subpath-test-configmap-6m42": Phase="Pending", Reason="", readiness=false. Elapsed: 3.356587ms
Dec 17 00:51:24.829: INFO: Pod "pod-subpath-test-configmap-6m42": Phase="Running", Reason="", readiness=true. Elapsed: 2.006311142s
Dec 17 00:51:26.831: INFO: Pod "pod-subpath-test-configmap-6m42": Phase="Running", Reason="", readiness=true. Elapsed: 4.008692152s
Dec 17 00:51:28.834: INFO: Pod "pod-subpath-test-configmap-6m42": Phase="Running", Reason="", readiness=true. Elapsed: 6.011216127s
Dec 17 00:51:30.837: INFO: Pod "pod-subpath-test-configmap-6m42": Phase="Running", Reason="", readiness=true. Elapsed: 8.013837122s
Dec 17 00:51:32.839: INFO: Pod "pod-subpath-test-configmap-6m42": Phase="Running", Reason="", readiness=true. Elapsed: 10.016340813s
Dec 17 00:51:34.841: INFO: Pod "pod-subpath-test-configmap-6m42": Phase="Running", Reason="", readiness=true. Elapsed: 12.018677651s
Dec 17 00:51:36.844: INFO: Pod "pod-subpath-test-configmap-6m42": Phase="Running", Reason="", readiness=true. Elapsed: 14.021186464s
Dec 17 00:51:38.847: INFO: Pod "pod-subpath-test-configmap-6m42": Phase="Running", Reason="", readiness=true. Elapsed: 16.023826032s
Dec 17 00:51:40.849: INFO: Pod "pod-subpath-test-configmap-6m42": Phase="Running", Reason="", readiness=true. Elapsed: 18.026660954s
Dec 17 00:51:42.852: INFO: Pod "pod-subpath-test-configmap-6m42": Phase="Running", Reason="", readiness=true. Elapsed: 20.029587752s
Dec 17 00:51:44.866: INFO: Pod "pod-subpath-test-configmap-6m42": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.04348065s
STEP: Saw pod success
Dec 17 00:51:44.866: INFO: Pod "pod-subpath-test-configmap-6m42" satisfied condition "success or failure"
Dec 17 00:51:44.873: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-subpath-test-configmap-6m42 container test-container-subpath-configmap-6m42: <nil>
STEP: delete the pod
Dec 17 00:51:44.900: INFO: Waiting for pod pod-subpath-test-configmap-6m42 to disappear
Dec 17 00:51:44.907: INFO: Pod pod-subpath-test-configmap-6m42 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-6m42
Dec 17 00:51:44.907: INFO: Deleting pod "pod-subpath-test-configmap-6m42" in namespace "subpath-9110"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:51:44.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9110" for this suite.
Dec 17 00:51:50.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:51:50.996: INFO: namespace subpath-9110 deletion completed in 6.063601503s

â€¢ [SLOW TEST:28.202 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:51:50.996: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 00:51:51.470: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 17 00:51:53.479: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140711, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140711, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140711, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712140711, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 00:51:56.489: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:51:56.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4505" for this suite.
Dec 17 00:52:02.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:52:02.597: INFO: namespace webhook-4505 deletion completed in 6.062846431s
STEP: Destroying namespace "webhook-4505-markers" for this suite.
Dec 17 00:52:08.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:52:08.661: INFO: namespace webhook-4505-markers deletion completed in 6.06463422s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:17.674 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:52:08.670: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 17 00:52:08.704: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 00:52:08.706: INFO: Number of nodes with available pods: 0
Dec 17 00:52:08.706: INFO: Node ip-172-20-34-147.us-east-2.compute.internal is running more than one daemon pod
Dec 17 00:52:09.709: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 00:52:09.712: INFO: Number of nodes with available pods: 0
Dec 17 00:52:09.712: INFO: Node ip-172-20-34-147.us-east-2.compute.internal is running more than one daemon pod
Dec 17 00:52:10.710: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 00:52:10.712: INFO: Number of nodes with available pods: 2
Dec 17 00:52:10.712: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec 17 00:52:10.726: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 00:52:10.729: INFO: Number of nodes with available pods: 1
Dec 17 00:52:10.729: INFO: Node ip-172-20-58-188.us-east-2.compute.internal is running more than one daemon pod
Dec 17 00:52:11.732: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 00:52:11.734: INFO: Number of nodes with available pods: 1
Dec 17 00:52:11.734: INFO: Node ip-172-20-58-188.us-east-2.compute.internal is running more than one daemon pod
Dec 17 00:52:12.732: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 00:52:12.734: INFO: Number of nodes with available pods: 2
Dec 17 00:52:12.734: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2624, will wait for the garbage collector to delete the pods
Dec 17 00:52:12.794: INFO: Deleting DaemonSet.extensions daemon-set took: 4.451879ms
Dec 17 00:52:12.894: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.233056ms
Dec 17 00:52:21.996: INFO: Number of nodes with available pods: 0
Dec 17 00:52:21.996: INFO: Number of running nodes: 0, number of available pods: 0
Dec 17 00:52:21.999: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2624/daemonsets","resourceVersion":"7835"},"items":null}

Dec 17 00:52:22.001: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2624/pods","resourceVersion":"7835"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:52:22.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2624" for this suite.
Dec 17 00:52:28.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:52:28.067: INFO: namespace daemonsets-2624 deletion completed in 6.058740619s

â€¢ [SLOW TEST:19.397 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:52:28.068: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 00:52:28.096: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 17 00:52:31.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 --namespace=crd-publish-openapi-935 create -f -'
Dec 17 00:52:31.997: INFO: stderr: ""
Dec 17 00:52:31.997: INFO: stdout: "e2e-test-crd-publish-openapi-4934-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 17 00:52:31.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 --namespace=crd-publish-openapi-935 delete e2e-test-crd-publish-openapi-4934-crds test-cr'
Dec 17 00:52:32.070: INFO: stderr: ""
Dec 17 00:52:32.070: INFO: stdout: "e2e-test-crd-publish-openapi-4934-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Dec 17 00:52:32.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 --namespace=crd-publish-openapi-935 apply -f -'
Dec 17 00:52:32.233: INFO: stderr: ""
Dec 17 00:52:32.233: INFO: stdout: "e2e-test-crd-publish-openapi-4934-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 17 00:52:32.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 --namespace=crd-publish-openapi-935 delete e2e-test-crd-publish-openapi-4934-crds test-cr'
Dec 17 00:52:32.304: INFO: stderr: ""
Dec 17 00:52:32.304: INFO: stdout: "e2e-test-crd-publish-openapi-4934-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec 17 00:52:32.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 explain e2e-test-crd-publish-openapi-4934-crds'
Dec 17 00:52:32.452: INFO: stderr: ""
Dec 17 00:52:32.452: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4934-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:52:35.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-935" for this suite.
Dec 17 00:52:41.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:52:41.499: INFO: namespace crd-publish-openapi-935 deletion completed in 6.057068052s

â€¢ [SLOW TEST:13.431 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:52:41.499: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 00:52:41.521: INFO: Waiting up to 5m0s for pod "downwardapi-volume-02074fd6-c05d-4499-98b1-86d8a443cb88" in namespace "downward-api-2635" to be "success or failure"
Dec 17 00:52:41.524: INFO: Pod "downwardapi-volume-02074fd6-c05d-4499-98b1-86d8a443cb88": Phase="Pending", Reason="", readiness=false. Elapsed: 2.845198ms
Dec 17 00:52:43.527: INFO: Pod "downwardapi-volume-02074fd6-c05d-4499-98b1-86d8a443cb88": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005700564s
STEP: Saw pod success
Dec 17 00:52:43.527: INFO: Pod "downwardapi-volume-02074fd6-c05d-4499-98b1-86d8a443cb88" satisfied condition "success or failure"
Dec 17 00:52:43.528: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod downwardapi-volume-02074fd6-c05d-4499-98b1-86d8a443cb88 container client-container: <nil>
STEP: delete the pod
Dec 17 00:52:43.542: INFO: Waiting for pod downwardapi-volume-02074fd6-c05d-4499-98b1-86d8a443cb88 to disappear
Dec 17 00:52:43.544: INFO: Pod downwardapi-volume-02074fd6-c05d-4499-98b1-86d8a443cb88 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:52:43.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2635" for this suite.
Dec 17 00:52:49.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:52:49.607: INFO: namespace downward-api-2635 deletion completed in 6.061393425s

â€¢ [SLOW TEST:8.108 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:52:49.608: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:52:49.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8691" for this suite.
Dec 17 00:52:55.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:52:55.712: INFO: namespace resourcequota-8691 deletion completed in 6.069255938s

â€¢ [SLOW TEST:6.104 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:52:55.713: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-5f5e6b23-f413-4380-99e3-c0f6cab405d2
STEP: Creating configMap with name cm-test-opt-upd-0cbf372b-18ce-4a07-bf21-f9c4e0a2e485
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-5f5e6b23-f413-4380-99e3-c0f6cab405d2
STEP: Updating configmap cm-test-opt-upd-0cbf372b-18ce-4a07-bf21-f9c4e0a2e485
STEP: Creating configMap with name cm-test-opt-create-7b232651-1c5f-4207-9b47-885d74fdf3fc
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:54:26.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6252" for this suite.
Dec 17 00:54:44.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:54:44.145: INFO: namespace configmap-6252 deletion completed in 18.055644779s

â€¢ [SLOW TEST:108.432 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:54:44.145: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 00:54:44.163: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:54:46.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8531" for this suite.
Dec 17 00:55:32.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:55:32.241: INFO: namespace pods-8531 deletion completed in 46.055945773s

â€¢ [SLOW TEST:48.096 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:55:32.241: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 17 00:55:34.271: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:55:34.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3209" for this suite.
Dec 17 00:55:40.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:55:40.343: INFO: namespace container-runtime-3209 deletion completed in 6.05531995s

â€¢ [SLOW TEST:8.102 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:55:40.343: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 00:55:40.374: INFO: (0) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 9.706317ms)
Dec 17 00:55:40.377: INFO: (1) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.06242ms)
Dec 17 00:55:40.379: INFO: (2) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.236675ms)
Dec 17 00:55:40.381: INFO: (3) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.278143ms)
Dec 17 00:55:40.384: INFO: (4) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.307488ms)
Dec 17 00:55:40.386: INFO: (5) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.37896ms)
Dec 17 00:55:40.389: INFO: (6) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.48046ms)
Dec 17 00:55:40.391: INFO: (7) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.309138ms)
Dec 17 00:55:40.393: INFO: (8) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.422891ms)
Dec 17 00:55:40.396: INFO: (9) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.301153ms)
Dec 17 00:55:40.398: INFO: (10) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.368045ms)
Dec 17 00:55:40.400: INFO: (11) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.24542ms)
Dec 17 00:55:40.403: INFO: (12) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.320797ms)
Dec 17 00:55:40.405: INFO: (13) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.585646ms)
Dec 17 00:55:40.408: INFO: (14) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.447848ms)
Dec 17 00:55:40.410: INFO: (15) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.252812ms)
Dec 17 00:55:40.412: INFO: (16) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.172065ms)
Dec 17 00:55:40.415: INFO: (17) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.165655ms)
Dec 17 00:55:40.417: INFO: (18) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.251578ms)
Dec 17 00:55:40.419: INFO: (19) /api/v1/nodes/ip-172-20-34-147.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.164378ms)
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:55:40.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2179" for this suite.
Dec 17 00:55:46.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:55:46.480: INFO: namespace proxy-2179 deletion completed in 6.059386801s

â€¢ [SLOW TEST:6.137 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:55:46.481: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec 17 00:55:52.518: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2678 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 00:55:52.518: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
Dec 17 00:55:52.604: INFO: Exec stderr: ""
Dec 17 00:55:52.604: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2678 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 00:55:52.604: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
Dec 17 00:55:52.687: INFO: Exec stderr: ""
Dec 17 00:55:52.687: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2678 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 00:55:52.687: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
Dec 17 00:55:52.769: INFO: Exec stderr: ""
Dec 17 00:55:52.769: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2678 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 00:55:52.769: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
Dec 17 00:55:52.852: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec 17 00:55:52.852: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2678 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 00:55:52.852: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
Dec 17 00:55:52.936: INFO: Exec stderr: ""
Dec 17 00:55:52.936: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2678 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 00:55:52.936: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
Dec 17 00:55:53.017: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec 17 00:55:53.017: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2678 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 00:55:53.017: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
Dec 17 00:55:53.096: INFO: Exec stderr: ""
Dec 17 00:55:53.096: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2678 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 00:55:53.097: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
Dec 17 00:55:53.191: INFO: Exec stderr: ""
Dec 17 00:55:53.191: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2678 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 00:55:53.191: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
Dec 17 00:55:53.274: INFO: Exec stderr: ""
Dec 17 00:55:53.274: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2678 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 00:55:53.274: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
Dec 17 00:55:53.359: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:55:53.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-2678" for this suite.
Dec 17 00:56:37.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:56:37.419: INFO: namespace e2e-kubelet-etc-hosts-2678 deletion completed in 44.056637816s

â€¢ [SLOW TEST:50.938 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:56:37.420: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-a85db31d-03f6-4aa6-bcfb-0072cb56bcd8
STEP: Creating a pod to test consume secrets
Dec 17 00:56:37.445: INFO: Waiting up to 5m0s for pod "pod-secrets-13752524-6bdf-4aa4-99e5-67062bd4599e" in namespace "secrets-1775" to be "success or failure"
Dec 17 00:56:37.448: INFO: Pod "pod-secrets-13752524-6bdf-4aa4-99e5-67062bd4599e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.038074ms
Dec 17 00:56:39.450: INFO: Pod "pod-secrets-13752524-6bdf-4aa4-99e5-67062bd4599e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005441604s
STEP: Saw pod success
Dec 17 00:56:39.450: INFO: Pod "pod-secrets-13752524-6bdf-4aa4-99e5-67062bd4599e" satisfied condition "success or failure"
Dec 17 00:56:39.452: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-secrets-13752524-6bdf-4aa4-99e5-67062bd4599e container secret-env-test: <nil>
STEP: delete the pod
Dec 17 00:56:39.471: INFO: Waiting for pod pod-secrets-13752524-6bdf-4aa4-99e5-67062bd4599e to disappear
Dec 17 00:56:39.472: INFO: Pod pod-secrets-13752524-6bdf-4aa4-99e5-67062bd4599e no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:56:39.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1775" for this suite.
Dec 17 00:56:45.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:56:45.541: INFO: namespace secrets-1775 deletion completed in 6.066643253s

â€¢ [SLOW TEST:8.121 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:56:45.541: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 00:56:45.563: INFO: Waiting up to 5m0s for pod "downwardapi-volume-37044805-1cf7-4dbf-80bf-7a962c8bf8cc" in namespace "projected-7995" to be "success or failure"
Dec 17 00:56:45.566: INFO: Pod "downwardapi-volume-37044805-1cf7-4dbf-80bf-7a962c8bf8cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.959103ms
Dec 17 00:56:47.568: INFO: Pod "downwardapi-volume-37044805-1cf7-4dbf-80bf-7a962c8bf8cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00512561s
STEP: Saw pod success
Dec 17 00:56:47.568: INFO: Pod "downwardapi-volume-37044805-1cf7-4dbf-80bf-7a962c8bf8cc" satisfied condition "success or failure"
Dec 17 00:56:47.569: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod downwardapi-volume-37044805-1cf7-4dbf-80bf-7a962c8bf8cc container client-container: <nil>
STEP: delete the pod
Dec 17 00:56:47.583: INFO: Waiting for pod downwardapi-volume-37044805-1cf7-4dbf-80bf-7a962c8bf8cc to disappear
Dec 17 00:56:47.585: INFO: Pod downwardapi-volume-37044805-1cf7-4dbf-80bf-7a962c8bf8cc no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:56:47.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7995" for this suite.
Dec 17 00:56:53.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:56:53.652: INFO: namespace projected-7995 deletion completed in 6.064782813s

â€¢ [SLOW TEST:8.111 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:56:53.652: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-cfjwj in namespace proxy-8199
I1217 00:56:53.707122      21 runners.go:184] Created replication controller with name: proxy-service-cfjwj, namespace: proxy-8199, replica count: 1
I1217 00:56:54.757562      21 runners.go:184] proxy-service-cfjwj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1217 00:56:55.757873      21 runners.go:184] proxy-service-cfjwj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1217 00:56:56.758128      21 runners.go:184] proxy-service-cfjwj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1217 00:56:57.758394      21 runners.go:184] proxy-service-cfjwj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1217 00:56:58.758703      21 runners.go:184] proxy-service-cfjwj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1217 00:56:59.758949      21 runners.go:184] proxy-service-cfjwj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1217 00:57:00.759194      21 runners.go:184] proxy-service-cfjwj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1217 00:57:01.759416      21 runners.go:184] proxy-service-cfjwj Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 17 00:57:01.762: INFO: setup took 8.073237116s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec 17 00:57:01.774: INFO: (0) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/rewriteme">test</a> (200; 10.941736ms)
Dec 17 00:57:01.774: INFO: (0) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">test<... (200; 11.43509ms)
Dec 17 00:57:01.779: INFO: (0) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname1/proxy/: foo (200; 16.388992ms)
Dec 17 00:57:01.780: INFO: (0) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname2/proxy/: bar (200; 17.327427ms)
Dec 17 00:57:01.780: INFO: (0) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 17.234439ms)
Dec 17 00:57:01.785: INFO: (0) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname1/proxy/: foo (200; 22.490081ms)
Dec 17 00:57:01.786: INFO: (0) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 23.21893ms)
Dec 17 00:57:01.786: INFO: (0) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:462/proxy/: tls qux (200; 23.692851ms)
Dec 17 00:57:01.787: INFO: (0) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">... (200; 23.829968ms)
Dec 17 00:57:01.789: INFO: (0) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname2/proxy/: tls qux (200; 25.70897ms)
Dec 17 00:57:01.789: INFO: (0) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:460/proxy/: tls baz (200; 26.261852ms)
Dec 17 00:57:01.789: INFO: (0) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname2/proxy/: bar (200; 26.052046ms)
Dec 17 00:57:01.789: INFO: (0) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 26.041596ms)
Dec 17 00:57:01.789: INFO: (0) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/tlsrewritem... (200; 26.548934ms)
Dec 17 00:57:01.790: INFO: (0) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 26.472242ms)
Dec 17 00:57:01.790: INFO: (0) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname1/proxy/: tls baz (200; 27.247769ms)
Dec 17 00:57:01.796: INFO: (1) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:460/proxy/: tls baz (200; 6.002998ms)
Dec 17 00:57:01.798: INFO: (1) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname2/proxy/: bar (200; 7.700389ms)
Dec 17 00:57:01.798: INFO: (1) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname2/proxy/: tls qux (200; 7.746602ms)
Dec 17 00:57:01.801: INFO: (1) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">... (200; 10.448929ms)
Dec 17 00:57:01.807: INFO: (1) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/tlsrewritem... (200; 16.652042ms)
Dec 17 00:57:01.808: INFO: (1) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 17.378557ms)
Dec 17 00:57:01.808: INFO: (1) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname1/proxy/: foo (200; 17.217926ms)
Dec 17 00:57:01.808: INFO: (1) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 17.11328ms)
Dec 17 00:57:01.808: INFO: (1) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">test<... (200; 17.166073ms)
Dec 17 00:57:01.808: INFO: (1) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname2/proxy/: bar (200; 17.301909ms)
Dec 17 00:57:01.808: INFO: (1) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname1/proxy/: tls baz (200; 17.391602ms)
Dec 17 00:57:01.808: INFO: (1) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/rewriteme">test</a> (200; 17.773471ms)
Dec 17 00:57:01.809: INFO: (1) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:462/proxy/: tls qux (200; 18.201136ms)
Dec 17 00:57:01.809: INFO: (1) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 18.325858ms)
Dec 17 00:57:01.809: INFO: (1) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 18.277677ms)
Dec 17 00:57:01.809: INFO: (1) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname1/proxy/: foo (200; 18.231322ms)
Dec 17 00:57:01.814: INFO: (2) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/rewriteme">test</a> (200; 5.405727ms)
Dec 17 00:57:01.815: INFO: (2) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:460/proxy/: tls baz (200; 5.773631ms)
Dec 17 00:57:01.819: INFO: (2) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 9.955501ms)
Dec 17 00:57:01.819: INFO: (2) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">test<... (200; 10.149216ms)
Dec 17 00:57:01.820: INFO: (2) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname1/proxy/: tls baz (200; 10.580314ms)
Dec 17 00:57:01.820: INFO: (2) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:462/proxy/: tls qux (200; 10.369218ms)
Dec 17 00:57:01.821: INFO: (2) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">... (200; 11.666839ms)
Dec 17 00:57:01.821: INFO: (2) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname2/proxy/: bar (200; 12.519518ms)
Dec 17 00:57:01.822: INFO: (2) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 12.384374ms)
Dec 17 00:57:01.822: INFO: (2) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/tlsrewritem... (200; 12.550201ms)
Dec 17 00:57:01.822: INFO: (2) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 12.57042ms)
Dec 17 00:57:01.822: INFO: (2) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 12.707401ms)
Dec 17 00:57:01.824: INFO: (2) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname1/proxy/: foo (200; 15.396928ms)
Dec 17 00:57:01.825: INFO: (2) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname1/proxy/: foo (200; 15.391505ms)
Dec 17 00:57:01.825: INFO: (2) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname2/proxy/: tls qux (200; 15.679687ms)
Dec 17 00:57:01.825: INFO: (2) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname2/proxy/: bar (200; 15.840266ms)
Dec 17 00:57:01.834: INFO: (3) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 8.549484ms)
Dec 17 00:57:01.835: INFO: (3) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/rewriteme">test</a> (200; 9.601944ms)
Dec 17 00:57:01.836: INFO: (3) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/tlsrewritem... (200; 10.292191ms)
Dec 17 00:57:01.837: INFO: (3) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:460/proxy/: tls baz (200; 11.210747ms)
Dec 17 00:57:01.837: INFO: (3) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">test<... (200; 11.232919ms)
Dec 17 00:57:01.837: INFO: (3) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">... (200; 11.126226ms)
Dec 17 00:57:01.837: INFO: (3) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname1/proxy/: foo (200; 11.730663ms)
Dec 17 00:57:01.837: INFO: (3) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 11.481524ms)
Dec 17 00:57:01.837: INFO: (3) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname1/proxy/: foo (200; 11.546989ms)
Dec 17 00:57:01.838: INFO: (3) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 12.053727ms)
Dec 17 00:57:01.838: INFO: (3) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname2/proxy/: tls qux (200; 12.29584ms)
Dec 17 00:57:01.838: INFO: (3) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:462/proxy/: tls qux (200; 12.223779ms)
Dec 17 00:57:01.838: INFO: (3) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname2/proxy/: bar (200; 12.480104ms)
Dec 17 00:57:01.838: INFO: (3) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 12.606671ms)
Dec 17 00:57:01.838: INFO: (3) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname2/proxy/: bar (200; 12.837026ms)
Dec 17 00:57:01.839: INFO: (3) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname1/proxy/: tls baz (200; 13.069812ms)
Dec 17 00:57:01.844: INFO: (4) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:460/proxy/: tls baz (200; 5.602612ms)
Dec 17 00:57:01.850: INFO: (4) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/rewriteme">test</a> (200; 11.442174ms)
Dec 17 00:57:01.850: INFO: (4) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 10.592418ms)
Dec 17 00:57:01.850: INFO: (4) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 10.518341ms)
Dec 17 00:57:01.850: INFO: (4) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">... (200; 10.910758ms)
Dec 17 00:57:01.850: INFO: (4) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:462/proxy/: tls qux (200; 10.985632ms)
Dec 17 00:57:01.851: INFO: (4) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname2/proxy/: bar (200; 11.910846ms)
Dec 17 00:57:01.851: INFO: (4) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname1/proxy/: foo (200; 12.004679ms)
Dec 17 00:57:01.851: INFO: (4) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname1/proxy/: tls baz (200; 12.01229ms)
Dec 17 00:57:01.851: INFO: (4) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 11.969652ms)
Dec 17 00:57:01.851: INFO: (4) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">test<... (200; 12.277895ms)
Dec 17 00:57:01.852: INFO: (4) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/tlsrewritem... (200; 12.316125ms)
Dec 17 00:57:01.852: INFO: (4) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname2/proxy/: tls qux (200; 12.205503ms)
Dec 17 00:57:01.852: INFO: (4) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 13.109857ms)
Dec 17 00:57:01.852: INFO: (4) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname1/proxy/: foo (200; 12.627295ms)
Dec 17 00:57:01.852: INFO: (4) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname2/proxy/: bar (200; 12.616038ms)
Dec 17 00:57:01.857: INFO: (5) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">... (200; 4.289866ms)
Dec 17 00:57:01.858: INFO: (5) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 5.415064ms)
Dec 17 00:57:01.858: INFO: (5) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:460/proxy/: tls baz (200; 5.603272ms)
Dec 17 00:57:01.860: INFO: (5) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/tlsrewritem... (200; 7.888312ms)
Dec 17 00:57:01.861: INFO: (5) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/rewriteme">test</a> (200; 8.111952ms)
Dec 17 00:57:01.861: INFO: (5) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 8.416867ms)
Dec 17 00:57:01.863: INFO: (5) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 10.414769ms)
Dec 17 00:57:01.863: INFO: (5) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">test<... (200; 10.515235ms)
Dec 17 00:57:01.863: INFO: (5) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname2/proxy/: bar (200; 10.784895ms)
Dec 17 00:57:01.865: INFO: (5) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:462/proxy/: tls qux (200; 12.364783ms)
Dec 17 00:57:01.865: INFO: (5) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 12.556983ms)
Dec 17 00:57:01.865: INFO: (5) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname1/proxy/: foo (200; 12.643324ms)
Dec 17 00:57:01.865: INFO: (5) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname1/proxy/: foo (200; 12.688413ms)
Dec 17 00:57:01.865: INFO: (5) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname2/proxy/: bar (200; 12.679149ms)
Dec 17 00:57:01.866: INFO: (5) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname2/proxy/: tls qux (200; 13.508508ms)
Dec 17 00:57:01.867: INFO: (5) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname1/proxy/: tls baz (200; 14.564323ms)
Dec 17 00:57:01.877: INFO: (6) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname1/proxy/: foo (200; 8.77595ms)
Dec 17 00:57:01.878: INFO: (6) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">test<... (200; 10.151028ms)
Dec 17 00:57:01.878: INFO: (6) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">... (200; 10.256367ms)
Dec 17 00:57:01.878: INFO: (6) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 10.38859ms)
Dec 17 00:57:01.878: INFO: (6) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 10.560617ms)
Dec 17 00:57:01.879: INFO: (6) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/tlsrewritem... (200; 11.695142ms)
Dec 17 00:57:01.880: INFO: (6) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 11.90018ms)
Dec 17 00:57:01.880: INFO: (6) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname1/proxy/: tls baz (200; 11.911429ms)
Dec 17 00:57:01.880: INFO: (6) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 12.278296ms)
Dec 17 00:57:01.880: INFO: (6) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/rewriteme">test</a> (200; 12.232541ms)
Dec 17 00:57:01.880: INFO: (6) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:460/proxy/: tls baz (200; 12.229139ms)
Dec 17 00:57:01.880: INFO: (6) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:462/proxy/: tls qux (200; 12.807993ms)
Dec 17 00:57:01.881: INFO: (6) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname2/proxy/: bar (200; 12.722018ms)
Dec 17 00:57:01.881: INFO: (6) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname2/proxy/: bar (200; 12.812093ms)
Dec 17 00:57:01.881: INFO: (6) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname1/proxy/: foo (200; 13.086443ms)
Dec 17 00:57:01.881: INFO: (6) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname2/proxy/: tls qux (200; 13.405101ms)
Dec 17 00:57:01.885: INFO: (7) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/rewriteme">test</a> (200; 4.217507ms)
Dec 17 00:57:01.887: INFO: (7) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 5.625041ms)
Dec 17 00:57:01.888: INFO: (7) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname2/proxy/: bar (200; 6.406517ms)
Dec 17 00:57:01.888: INFO: (7) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/tlsrewritem... (200; 6.197135ms)
Dec 17 00:57:01.888: INFO: (7) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">test<... (200; 6.576107ms)
Dec 17 00:57:01.891: INFO: (7) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname2/proxy/: bar (200; 9.454055ms)
Dec 17 00:57:01.891: INFO: (7) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">... (200; 9.137504ms)
Dec 17 00:57:01.891: INFO: (7) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:460/proxy/: tls baz (200; 9.355937ms)
Dec 17 00:57:01.891: INFO: (7) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname1/proxy/: tls baz (200; 9.969487ms)
Dec 17 00:57:01.894: INFO: (7) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 11.479921ms)
Dec 17 00:57:01.894: INFO: (7) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:462/proxy/: tls qux (200; 12.029484ms)
Dec 17 00:57:01.895: INFO: (7) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 12.485769ms)
Dec 17 00:57:01.895: INFO: (7) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname2/proxy/: tls qux (200; 12.811315ms)
Dec 17 00:57:01.895: INFO: (7) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 12.908734ms)
Dec 17 00:57:01.895: INFO: (7) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname1/proxy/: foo (200; 13.530713ms)
Dec 17 00:57:01.896: INFO: (7) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname1/proxy/: foo (200; 15.053876ms)
Dec 17 00:57:01.903: INFO: (8) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">... (200; 6.417348ms)
Dec 17 00:57:01.903: INFO: (8) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:462/proxy/: tls qux (200; 6.305347ms)
Dec 17 00:57:01.903: INFO: (8) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 6.451097ms)
Dec 17 00:57:01.903: INFO: (8) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 6.431335ms)
Dec 17 00:57:01.903: INFO: (8) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/rewriteme">test</a> (200; 6.560165ms)
Dec 17 00:57:01.908: INFO: (8) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname2/proxy/: tls qux (200; 11.229614ms)
Dec 17 00:57:01.908: INFO: (8) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/tlsrewritem... (200; 10.878162ms)
Dec 17 00:57:01.908: INFO: (8) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">test<... (200; 11.054541ms)
Dec 17 00:57:01.908: INFO: (8) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 11.668389ms)
Dec 17 00:57:01.908: INFO: (8) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 11.449873ms)
Dec 17 00:57:01.909: INFO: (8) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:460/proxy/: tls baz (200; 11.497185ms)
Dec 17 00:57:01.909: INFO: (8) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname1/proxy/: foo (200; 12.36843ms)
Dec 17 00:57:01.910: INFO: (8) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname1/proxy/: tls baz (200; 12.543401ms)
Dec 17 00:57:01.910: INFO: (8) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname1/proxy/: foo (200; 12.8981ms)
Dec 17 00:57:01.910: INFO: (8) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname2/proxy/: bar (200; 12.991067ms)
Dec 17 00:57:01.910: INFO: (8) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname2/proxy/: bar (200; 12.919415ms)
Dec 17 00:57:01.915: INFO: (9) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/rewriteme">test</a> (200; 4.590171ms)
Dec 17 00:57:01.915: INFO: (9) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:462/proxy/: tls qux (200; 5.046602ms)
Dec 17 00:57:01.916: INFO: (9) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">... (200; 5.527851ms)
Dec 17 00:57:01.918: INFO: (9) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 7.847217ms)
Dec 17 00:57:01.919: INFO: (9) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:460/proxy/: tls baz (200; 8.155645ms)
Dec 17 00:57:01.919: INFO: (9) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 8.776881ms)
Dec 17 00:57:01.921: INFO: (9) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 10.645793ms)
Dec 17 00:57:01.922: INFO: (9) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">test<... (200; 11.618149ms)
Dec 17 00:57:01.922: INFO: (9) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname1/proxy/: tls baz (200; 12.1006ms)
Dec 17 00:57:01.923: INFO: (9) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 12.082529ms)
Dec 17 00:57:01.923: INFO: (9) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/tlsrewritem... (200; 12.059198ms)
Dec 17 00:57:01.923: INFO: (9) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname1/proxy/: foo (200; 13.141378ms)
Dec 17 00:57:01.924: INFO: (9) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname2/proxy/: bar (200; 13.825564ms)
Dec 17 00:57:01.924: INFO: (9) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname1/proxy/: foo (200; 13.798917ms)
Dec 17 00:57:01.925: INFO: (9) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname2/proxy/: bar (200; 14.066729ms)
Dec 17 00:57:01.925: INFO: (9) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname2/proxy/: tls qux (200; 13.951648ms)
Dec 17 00:57:01.930: INFO: (10) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/rewriteme">test</a> (200; 4.987675ms)
Dec 17 00:57:01.931: INFO: (10) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">... (200; 5.79274ms)
Dec 17 00:57:01.931: INFO: (10) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 5.989207ms)
Dec 17 00:57:01.932: INFO: (10) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/tlsrewritem... (200; 6.646492ms)
Dec 17 00:57:01.932: INFO: (10) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 6.977796ms)
Dec 17 00:57:01.932: INFO: (10) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:462/proxy/: tls qux (200; 7.133816ms)
Dec 17 00:57:01.933: INFO: (10) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">test<... (200; 7.597978ms)
Dec 17 00:57:01.935: INFO: (10) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname2/proxy/: bar (200; 10.292408ms)
Dec 17 00:57:01.936: INFO: (10) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname1/proxy/: foo (200; 11.081586ms)
Dec 17 00:57:01.936: INFO: (10) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname1/proxy/: tls baz (200; 11.03774ms)
Dec 17 00:57:01.936: INFO: (10) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname1/proxy/: foo (200; 11.484645ms)
Dec 17 00:57:01.936: INFO: (10) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:460/proxy/: tls baz (200; 11.027409ms)
Dec 17 00:57:01.936: INFO: (10) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 10.906979ms)
Dec 17 00:57:01.937: INFO: (10) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname2/proxy/: tls qux (200; 11.63521ms)
Dec 17 00:57:01.937: INFO: (10) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 11.947967ms)
Dec 17 00:57:01.938: INFO: (10) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname2/proxy/: bar (200; 12.472715ms)
Dec 17 00:57:01.946: INFO: (11) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 6.864819ms)
Dec 17 00:57:01.946: INFO: (11) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:460/proxy/: tls baz (200; 7.670468ms)
Dec 17 00:57:01.946: INFO: (11) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/tlsrewritem... (200; 7.600433ms)
Dec 17 00:57:01.948: INFO: (11) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 8.565796ms)
Dec 17 00:57:01.948: INFO: (11) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/rewriteme">test</a> (200; 9.056632ms)
Dec 17 00:57:01.948: INFO: (11) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:462/proxy/: tls qux (200; 8.907915ms)
Dec 17 00:57:01.948: INFO: (11) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">... (200; 9.136578ms)
Dec 17 00:57:01.948: INFO: (11) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 9.062395ms)
Dec 17 00:57:01.948: INFO: (11) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">test<... (200; 9.559658ms)
Dec 17 00:57:01.948: INFO: (11) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 9.730313ms)
Dec 17 00:57:01.949: INFO: (11) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname1/proxy/: foo (200; 10.974074ms)
Dec 17 00:57:01.949: INFO: (11) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname2/proxy/: bar (200; 10.173717ms)
Dec 17 00:57:01.950: INFO: (11) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname1/proxy/: foo (200; 10.542393ms)
Dec 17 00:57:01.950: INFO: (11) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname1/proxy/: tls baz (200; 11.773848ms)
Dec 17 00:57:01.950: INFO: (11) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname2/proxy/: tls qux (200; 11.206047ms)
Dec 17 00:57:01.950: INFO: (11) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname2/proxy/: bar (200; 11.93902ms)
Dec 17 00:57:01.959: INFO: (12) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/rewriteme">test</a> (200; 8.25562ms)
Dec 17 00:57:01.959: INFO: (12) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 8.597441ms)
Dec 17 00:57:01.960: INFO: (12) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:460/proxy/: tls baz (200; 8.278071ms)
Dec 17 00:57:01.960: INFO: (12) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/tlsrewritem... (200; 8.524574ms)
Dec 17 00:57:01.960: INFO: (12) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 8.805117ms)
Dec 17 00:57:01.960: INFO: (12) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:462/proxy/: tls qux (200; 9.147813ms)
Dec 17 00:57:01.960: INFO: (12) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 9.292552ms)
Dec 17 00:57:01.960: INFO: (12) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 9.375984ms)
Dec 17 00:57:01.960: INFO: (12) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">test<... (200; 9.81567ms)
Dec 17 00:57:01.964: INFO: (12) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname2/proxy/: bar (200; 13.236714ms)
Dec 17 00:57:01.964: INFO: (12) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname2/proxy/: tls qux (200; 13.766065ms)
Dec 17 00:57:01.964: INFO: (12) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname2/proxy/: bar (200; 12.95989ms)
Dec 17 00:57:01.965: INFO: (12) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname1/proxy/: foo (200; 13.546295ms)
Dec 17 00:57:01.965: INFO: (12) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">... (200; 13.899098ms)
Dec 17 00:57:01.964: INFO: (12) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname1/proxy/: tls baz (200; 12.655646ms)
Dec 17 00:57:01.965: INFO: (12) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname1/proxy/: foo (200; 13.08449ms)
Dec 17 00:57:01.970: INFO: (13) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">... (200; 5.043111ms)
Dec 17 00:57:01.970: INFO: (13) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 5.53999ms)
Dec 17 00:57:01.971: INFO: (13) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:460/proxy/: tls baz (200; 5.676524ms)
Dec 17 00:57:01.971: INFO: (13) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/rewriteme">test</a> (200; 6.19515ms)
Dec 17 00:57:01.971: INFO: (13) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/tlsrewritem... (200; 6.289604ms)
Dec 17 00:57:01.975: INFO: (13) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname2/proxy/: bar (200; 9.863745ms)
Dec 17 00:57:01.977: INFO: (13) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname1/proxy/: foo (200; 11.96562ms)
Dec 17 00:57:01.977: INFO: (13) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname1/proxy/: foo (200; 12.099126ms)
Dec 17 00:57:01.978: INFO: (13) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname1/proxy/: tls baz (200; 12.151773ms)
Dec 17 00:57:01.978: INFO: (13) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 12.45183ms)
Dec 17 00:57:01.978: INFO: (13) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">test<... (200; 12.563754ms)
Dec 17 00:57:01.978: INFO: (13) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 12.861708ms)
Dec 17 00:57:01.978: INFO: (13) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 13.107306ms)
Dec 17 00:57:01.978: INFO: (13) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname2/proxy/: bar (200; 13.128632ms)
Dec 17 00:57:01.979: INFO: (13) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:462/proxy/: tls qux (200; 13.361414ms)
Dec 17 00:57:01.979: INFO: (13) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname2/proxy/: tls qux (200; 13.863051ms)
Dec 17 00:57:01.983: INFO: (14) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">test<... (200; 4.368511ms)
Dec 17 00:57:01.987: INFO: (14) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:460/proxy/: tls baz (200; 7.320652ms)
Dec 17 00:57:01.987: INFO: (14) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/rewriteme">test</a> (200; 7.780091ms)
Dec 17 00:57:01.987: INFO: (14) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/tlsrewritem... (200; 7.510161ms)
Dec 17 00:57:01.987: INFO: (14) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:462/proxy/: tls qux (200; 6.867526ms)
Dec 17 00:57:01.987: INFO: (14) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 7.620341ms)
Dec 17 00:57:01.990: INFO: (14) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 10.424684ms)
Dec 17 00:57:01.990: INFO: (14) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname1/proxy/: foo (200; 10.110888ms)
Dec 17 00:57:01.990: INFO: (14) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 10.401231ms)
Dec 17 00:57:01.990: INFO: (14) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">... (200; 10.527083ms)
Dec 17 00:57:01.990: INFO: (14) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 10.105242ms)
Dec 17 00:57:01.993: INFO: (14) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname2/proxy/: tls qux (200; 13.346503ms)
Dec 17 00:57:01.993: INFO: (14) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname2/proxy/: bar (200; 13.607255ms)
Dec 17 00:57:01.993: INFO: (14) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname1/proxy/: foo (200; 13.758903ms)
Dec 17 00:57:01.993: INFO: (14) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname2/proxy/: bar (200; 13.177281ms)
Dec 17 00:57:01.993: INFO: (14) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname1/proxy/: tls baz (200; 13.412566ms)
Dec 17 00:57:01.997: INFO: (15) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/rewriteme">test</a> (200; 3.284713ms)
Dec 17 00:57:02.001: INFO: (15) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 7.460568ms)
Dec 17 00:57:02.002: INFO: (15) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">... (200; 7.928108ms)
Dec 17 00:57:02.002: INFO: (15) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:460/proxy/: tls baz (200; 8.24012ms)
Dec 17 00:57:02.002: INFO: (15) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 8.394096ms)
Dec 17 00:57:02.002: INFO: (15) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 8.623264ms)
Dec 17 00:57:02.003: INFO: (15) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 8.876641ms)
Dec 17 00:57:02.004: INFO: (15) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:462/proxy/: tls qux (200; 10.517588ms)
Dec 17 00:57:02.005: INFO: (15) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname2/proxy/: bar (200; 11.262202ms)
Dec 17 00:57:02.005: INFO: (15) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname1/proxy/: foo (200; 11.71188ms)
Dec 17 00:57:02.006: INFO: (15) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">test<... (200; 11.901779ms)
Dec 17 00:57:02.006: INFO: (15) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname1/proxy/: tls baz (200; 12.013432ms)
Dec 17 00:57:02.006: INFO: (15) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname2/proxy/: bar (200; 12.162085ms)
Dec 17 00:57:02.006: INFO: (15) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname2/proxy/: tls qux (200; 12.549255ms)
Dec 17 00:57:02.006: INFO: (15) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname1/proxy/: foo (200; 12.339101ms)
Dec 17 00:57:02.006: INFO: (15) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/tlsrewritem... (200; 12.196118ms)
Dec 17 00:57:02.014: INFO: (16) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:462/proxy/: tls qux (200; 8.217522ms)
Dec 17 00:57:02.014: INFO: (16) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">test<... (200; 7.975747ms)
Dec 17 00:57:02.015: INFO: (16) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 8.228714ms)
Dec 17 00:57:02.016: INFO: (16) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/rewriteme">test</a> (200; 9.837415ms)
Dec 17 00:57:02.016: INFO: (16) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:460/proxy/: tls baz (200; 10.140293ms)
Dec 17 00:57:02.017: INFO: (16) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 10.643796ms)
Dec 17 00:57:02.017: INFO: (16) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/tlsrewritem... (200; 11.105214ms)
Dec 17 00:57:02.017: INFO: (16) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 10.906029ms)
Dec 17 00:57:02.019: INFO: (16) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname2/proxy/: bar (200; 12.426094ms)
Dec 17 00:57:02.019: INFO: (16) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">... (200; 12.332649ms)
Dec 17 00:57:02.019: INFO: (16) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 12.597126ms)
Dec 17 00:57:02.019: INFO: (16) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname1/proxy/: foo (200; 13.12735ms)
Dec 17 00:57:02.020: INFO: (16) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname2/proxy/: bar (200; 13.306134ms)
Dec 17 00:57:02.020: INFO: (16) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname1/proxy/: foo (200; 13.24195ms)
Dec 17 00:57:02.020: INFO: (16) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname1/proxy/: tls baz (200; 13.700116ms)
Dec 17 00:57:02.020: INFO: (16) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname2/proxy/: tls qux (200; 13.896428ms)
Dec 17 00:57:02.032: INFO: (17) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 10.530307ms)
Dec 17 00:57:02.032: INFO: (17) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">test<... (200; 11.053728ms)
Dec 17 00:57:02.032: INFO: (17) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname1/proxy/: tls baz (200; 11.1919ms)
Dec 17 00:57:02.032: INFO: (17) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/tlsrewritem... (200; 11.067332ms)
Dec 17 00:57:02.032: INFO: (17) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname1/proxy/: foo (200; 11.464974ms)
Dec 17 00:57:02.032: INFO: (17) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:462/proxy/: tls qux (200; 10.665554ms)
Dec 17 00:57:02.032: INFO: (17) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">... (200; 11.214628ms)
Dec 17 00:57:02.032: INFO: (17) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 11.183645ms)
Dec 17 00:57:02.032: INFO: (17) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 11.174413ms)
Dec 17 00:57:02.033: INFO: (17) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/rewriteme">test</a> (200; 13.023529ms)
Dec 17 00:57:02.034: INFO: (17) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname2/proxy/: bar (200; 12.013126ms)
Dec 17 00:57:02.034: INFO: (17) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname2/proxy/: tls qux (200; 12.730922ms)
Dec 17 00:57:02.034: INFO: (17) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 12.963578ms)
Dec 17 00:57:02.034: INFO: (17) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:460/proxy/: tls baz (200; 12.852277ms)
Dec 17 00:57:02.034: INFO: (17) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname2/proxy/: bar (200; 13.31345ms)
Dec 17 00:57:02.034: INFO: (17) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname1/proxy/: foo (200; 12.598962ms)
Dec 17 00:57:02.041: INFO: (18) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 6.107755ms)
Dec 17 00:57:02.041: INFO: (18) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 6.192131ms)
Dec 17 00:57:02.041: INFO: (18) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 6.408075ms)
Dec 17 00:57:02.041: INFO: (18) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/tlsrewritem... (200; 6.406529ms)
Dec 17 00:57:02.041: INFO: (18) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:462/proxy/: tls qux (200; 6.66165ms)
Dec 17 00:57:02.046: INFO: (18) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">test<... (200; 11.103798ms)
Dec 17 00:57:02.047: INFO: (18) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname2/proxy/: tls qux (200; 12.985508ms)
Dec 17 00:57:02.047: INFO: (18) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname1/proxy/: foo (200; 13.197534ms)
Dec 17 00:57:02.047: INFO: (18) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:460/proxy/: tls baz (200; 13.092498ms)
Dec 17 00:57:02.047: INFO: (18) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">... (200; 13.065915ms)
Dec 17 00:57:02.048: INFO: (18) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/rewriteme">test</a> (200; 12.916808ms)
Dec 17 00:57:02.048: INFO: (18) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 13.051949ms)
Dec 17 00:57:02.048: INFO: (18) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname1/proxy/: foo (200; 13.616181ms)
Dec 17 00:57:02.049: INFO: (18) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname1/proxy/: tls baz (200; 14.001951ms)
Dec 17 00:57:02.049: INFO: (18) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname2/proxy/: bar (200; 14.258397ms)
Dec 17 00:57:02.049: INFO: (18) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname2/proxy/: bar (200; 14.916466ms)
Dec 17 00:57:02.058: INFO: (19) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 8.450733ms)
Dec 17 00:57:02.059: INFO: (19) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:162/proxy/: bar (200; 8.883039ms)
Dec 17 00:57:02.059: INFO: (19) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 9.093389ms)
Dec 17 00:57:02.059: INFO: (19) /api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/http:proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">... (200; 9.211425ms)
Dec 17 00:57:02.059: INFO: (19) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:462/proxy/: tls qux (200; 9.809723ms)
Dec 17 00:57:02.061: INFO: (19) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:443/proxy/tlsrewritem... (200; 10.220831ms)
Dec 17 00:57:02.061: INFO: (19) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname1/proxy/: foo (200; 10.332582ms)
Dec 17 00:57:02.061: INFO: (19) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:1080/proxy/rewriteme">test<... (200; 10.401606ms)
Dec 17 00:57:02.061: INFO: (19) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/: <a href="/api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf/proxy/rewriteme">test</a> (200; 11.016492ms)
Dec 17 00:57:02.062: INFO: (19) /api/v1/namespaces/proxy-8199/pods/https:proxy-service-cfjwj-l22wf:460/proxy/: tls baz (200; 11.876892ms)
Dec 17 00:57:02.062: INFO: (19) /api/v1/namespaces/proxy-8199/pods/proxy-service-cfjwj-l22wf:160/proxy/: foo (200; 11.845408ms)
Dec 17 00:57:02.062: INFO: (19) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname2/proxy/: bar (200; 12.305125ms)
Dec 17 00:57:02.063: INFO: (19) /api/v1/namespaces/proxy-8199/services/http:proxy-service-cfjwj:portname2/proxy/: bar (200; 12.311644ms)
Dec 17 00:57:02.063: INFO: (19) /api/v1/namespaces/proxy-8199/services/proxy-service-cfjwj:portname1/proxy/: foo (200; 12.705498ms)
Dec 17 00:57:02.063: INFO: (19) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname1/proxy/: tls baz (200; 12.427576ms)
Dec 17 00:57:02.064: INFO: (19) /api/v1/namespaces/proxy-8199/services/https:proxy-service-cfjwj:tlsportname2/proxy/: tls qux (200; 14.52035ms)
STEP: deleting ReplicationController proxy-service-cfjwj in namespace proxy-8199, will wait for the garbage collector to delete the pods
Dec 17 00:57:02.120: INFO: Deleting ReplicationController proxy-service-cfjwj took: 3.826629ms
Dec 17 00:57:02.421: INFO: Terminating ReplicationController proxy-service-cfjwj pods took: 300.355177ms
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:57:04.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8199" for this suite.
Dec 17 00:57:10.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:57:10.486: INFO: namespace proxy-8199 deletion completed in 6.063171134s

â€¢ [SLOW TEST:16.834 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:57:10.487: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-e3ada6b3-7dd6-4994-b14f-c705c35b7d07
STEP: Creating configMap with name cm-test-opt-upd-ba1395cf-8115-43e7-a071-b55a9e832fb9
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-e3ada6b3-7dd6-4994-b14f-c705c35b7d07
STEP: Updating configmap cm-test-opt-upd-ba1395cf-8115-43e7-a071-b55a9e832fb9
STEP: Creating configMap with name cm-test-opt-create-4151d94c-5cc8-48ec-b502-36703b735832
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:57:16.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6397" for this suite.
Dec 17 00:57:30.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:57:30.633: INFO: namespace projected-6397 deletion completed in 14.054409315s

â€¢ [SLOW TEST:20.146 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:57:30.633: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 00:57:31.129: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 00:57:34.142: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:57:44.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2184" for this suite.
Dec 17 00:57:50.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:57:50.279: INFO: namespace webhook-2184 deletion completed in 6.063313504s
STEP: Destroying namespace "webhook-2184-markers" for this suite.
Dec 17 00:57:56.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:57:56.336: INFO: namespace webhook-2184-markers deletion completed in 6.057439237s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:25.711 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:57:56.344: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:58:56.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-784" for this suite.
Dec 17 00:59:24.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:59:24.445: INFO: namespace container-probe-784 deletion completed in 28.074117744s

â€¢ [SLOW TEST:88.100 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:59:24.445: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 00:59:24.470: INFO: Waiting up to 5m0s for pod "downwardapi-volume-822241c7-e01a-4fc4-8815-9fba4673329b" in namespace "projected-5204" to be "success or failure"
Dec 17 00:59:24.473: INFO: Pod "downwardapi-volume-822241c7-e01a-4fc4-8815-9fba4673329b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.997605ms
Dec 17 00:59:26.477: INFO: Pod "downwardapi-volume-822241c7-e01a-4fc4-8815-9fba4673329b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007534411s
STEP: Saw pod success
Dec 17 00:59:26.477: INFO: Pod "downwardapi-volume-822241c7-e01a-4fc4-8815-9fba4673329b" satisfied condition "success or failure"
Dec 17 00:59:26.484: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod downwardapi-volume-822241c7-e01a-4fc4-8815-9fba4673329b container client-container: <nil>
STEP: delete the pod
Dec 17 00:59:26.508: INFO: Waiting for pod downwardapi-volume-822241c7-e01a-4fc4-8815-9fba4673329b to disappear
Dec 17 00:59:26.510: INFO: Pod downwardapi-volume-822241c7-e01a-4fc4-8815-9fba4673329b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:59:26.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5204" for this suite.
Dec 17 00:59:32.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:59:32.580: INFO: namespace projected-5204 deletion completed in 6.067613098s

â€¢ [SLOW TEST:8.135 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:59:32.581: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-288f54aa-0e42-4ba5-a6d4-992f4b53044e
STEP: Creating a pod to test consume configMaps
Dec 17 00:59:32.610: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3e375829-24d0-4391-ab0d-4947a08a7338" in namespace "projected-2716" to be "success or failure"
Dec 17 00:59:32.613: INFO: Pod "pod-projected-configmaps-3e375829-24d0-4391-ab0d-4947a08a7338": Phase="Pending", Reason="", readiness=false. Elapsed: 3.421125ms
Dec 17 00:59:34.616: INFO: Pod "pod-projected-configmaps-3e375829-24d0-4391-ab0d-4947a08a7338": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006475764s
STEP: Saw pod success
Dec 17 00:59:34.616: INFO: Pod "pod-projected-configmaps-3e375829-24d0-4391-ab0d-4947a08a7338" satisfied condition "success or failure"
Dec 17 00:59:34.618: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-projected-configmaps-3e375829-24d0-4391-ab0d-4947a08a7338 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 00:59:34.636: INFO: Waiting for pod pod-projected-configmaps-3e375829-24d0-4391-ab0d-4947a08a7338 to disappear
Dec 17 00:59:34.638: INFO: Pod pod-projected-configmaps-3e375829-24d0-4391-ab0d-4947a08a7338 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 00:59:34.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2716" for this suite.
Dec 17 00:59:40.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 00:59:40.697: INFO: namespace projected-2716 deletion completed in 6.056265332s

â€¢ [SLOW TEST:8.117 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 00:59:40.698: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-7a614cd1-2f79-407f-bba7-e93019dd2abb in namespace container-probe-3299
Dec 17 00:59:42.726: INFO: Started pod liveness-7a614cd1-2f79-407f-bba7-e93019dd2abb in namespace container-probe-3299
STEP: checking the pod's current state and verifying that restartCount is present
Dec 17 00:59:42.728: INFO: Initial restart count of pod liveness-7a614cd1-2f79-407f-bba7-e93019dd2abb is 0
Dec 17 01:00:00.754: INFO: Restart count of pod container-probe-3299/liveness-7a614cd1-2f79-407f-bba7-e93019dd2abb is now 1 (18.026180015s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:00:00.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3299" for this suite.
Dec 17 01:00:06.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:00:06.825: INFO: namespace container-probe-3299 deletion completed in 6.061412134s

â€¢ [SLOW TEST:26.127 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:00:06.825: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-6ea1de61-4a8f-4b00-a6ae-8afe73f5267b
STEP: Creating secret with name s-test-opt-upd-a43cb70f-5d79-4103-bd51-4cfb948f33f3
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-6ea1de61-4a8f-4b00-a6ae-8afe73f5267b
STEP: Updating secret s-test-opt-upd-a43cb70f-5d79-4103-bd51-4cfb948f33f3
STEP: Creating secret with name s-test-opt-create-19c68e9d-65b3-4827-9573-3fcc4fa80068
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:00:10.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8768" for this suite.
Dec 17 01:00:22.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:00:23.019: INFO: namespace projected-8768 deletion completed in 12.103069403s

â€¢ [SLOW TEST:16.194 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:00:23.019: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:00:39.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2965" for this suite.
Dec 17 01:00:45.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:00:45.203: INFO: namespace resourcequota-2965 deletion completed in 6.069475898s

â€¢ [SLOW TEST:22.184 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:00:45.204: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 17 01:00:45.231: INFO: Waiting up to 5m0s for pod "pod-fefaf8e6-2547-45c3-a2d9-036143acb2f9" in namespace "emptydir-7172" to be "success or failure"
Dec 17 01:00:45.234: INFO: Pod "pod-fefaf8e6-2547-45c3-a2d9-036143acb2f9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.624662ms
Dec 17 01:00:47.237: INFO: Pod "pod-fefaf8e6-2547-45c3-a2d9-036143acb2f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006181689s
Dec 17 01:00:49.248: INFO: Pod "pod-fefaf8e6-2547-45c3-a2d9-036143acb2f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017396885s
STEP: Saw pod success
Dec 17 01:00:49.248: INFO: Pod "pod-fefaf8e6-2547-45c3-a2d9-036143acb2f9" satisfied condition "success or failure"
Dec 17 01:00:49.253: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-fefaf8e6-2547-45c3-a2d9-036143acb2f9 container test-container: <nil>
STEP: delete the pod
Dec 17 01:00:49.265: INFO: Waiting for pod pod-fefaf8e6-2547-45c3-a2d9-036143acb2f9 to disappear
Dec 17 01:00:49.268: INFO: Pod pod-fefaf8e6-2547-45c3-a2d9-036143acb2f9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:00:49.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7172" for this suite.
Dec 17 01:00:55.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:00:55.339: INFO: namespace emptydir-7172 deletion completed in 6.068966556s

â€¢ [SLOW TEST:10.135 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:00:55.339: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 01:00:55.357: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 17 01:00:58.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 --namespace=crd-publish-openapi-6070 create -f -'
Dec 17 01:00:58.714: INFO: stderr: ""
Dec 17 01:00:58.714: INFO: stdout: "e2e-test-crd-publish-openapi-8278-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 17 01:00:58.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 --namespace=crd-publish-openapi-6070 delete e2e-test-crd-publish-openapi-8278-crds test-cr'
Dec 17 01:00:58.789: INFO: stderr: ""
Dec 17 01:00:58.789: INFO: stdout: "e2e-test-crd-publish-openapi-8278-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Dec 17 01:00:58.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 --namespace=crd-publish-openapi-6070 apply -f -'
Dec 17 01:00:58.946: INFO: stderr: ""
Dec 17 01:00:58.946: INFO: stdout: "e2e-test-crd-publish-openapi-8278-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 17 01:00:58.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 --namespace=crd-publish-openapi-6070 delete e2e-test-crd-publish-openapi-8278-crds test-cr'
Dec 17 01:00:59.023: INFO: stderr: ""
Dec 17 01:00:59.023: INFO: stdout: "e2e-test-crd-publish-openapi-8278-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Dec 17 01:00:59.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 explain e2e-test-crd-publish-openapi-8278-crds'
Dec 17 01:00:59.171: INFO: stderr: ""
Dec 17 01:00:59.171: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8278-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:01:02.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6070" for this suite.
Dec 17 01:01:08.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:01:08.220: INFO: namespace crd-publish-openapi-6070 deletion completed in 6.06168188s

â€¢ [SLOW TEST:12.881 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:01:08.221: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 01:01:08.669: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 01:01:11.683: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 01:01:11.686: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2989-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:01:13.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8952" for this suite.
Dec 17 01:01:19.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:01:19.204: INFO: namespace webhook-8952 deletion completed in 6.059865221s
STEP: Destroying namespace "webhook-8952-markers" for this suite.
Dec 17 01:01:25.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:01:25.280: INFO: namespace webhook-8952-markers deletion completed in 6.076046249s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:17.068 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:01:25.289: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec 17 01:01:31.331: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1217 01:01:31.331563      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:01:31.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5126" for this suite.
Dec 17 01:01:37.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:01:37.400: INFO: namespace gc-5126 deletion completed in 6.066187314s

â€¢ [SLOW TEST:12.111 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:01:37.400: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-7399
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7399 to expose endpoints map[]
Dec 17 01:01:37.445: INFO: successfully validated that service multi-endpoint-test in namespace services-7399 exposes endpoints map[] (4.196905ms elapsed)
STEP: Creating pod pod1 in namespace services-7399
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7399 to expose endpoints map[pod1:[100]]
Dec 17 01:01:39.471: INFO: successfully validated that service multi-endpoint-test in namespace services-7399 exposes endpoints map[pod1:[100]] (2.018902442s elapsed)
STEP: Creating pod pod2 in namespace services-7399
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7399 to expose endpoints map[pod1:[100] pod2:[101]]
Dec 17 01:01:41.501: INFO: successfully validated that service multi-endpoint-test in namespace services-7399 exposes endpoints map[pod1:[100] pod2:[101]] (2.024679391s elapsed)
STEP: Deleting pod pod1 in namespace services-7399
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7399 to expose endpoints map[pod2:[101]]
Dec 17 01:01:42.518: INFO: successfully validated that service multi-endpoint-test in namespace services-7399 exposes endpoints map[pod2:[101]] (1.01211043s elapsed)
STEP: Deleting pod pod2 in namespace services-7399
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7399 to expose endpoints map[]
Dec 17 01:01:42.528: INFO: successfully validated that service multi-endpoint-test in namespace services-7399 exposes endpoints map[] (5.800322ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:01:42.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7399" for this suite.
Dec 17 01:01:54.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:01:54.629: INFO: namespace services-7399 deletion completed in 12.07094396s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:17.229 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:01:54.630: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Dec 17 01:02:04.666: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1217 01:02:04.665997      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:02:04.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4733" for this suite.
Dec 17 01:02:10.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:02:10.731: INFO: namespace gc-4733 deletion completed in 6.063341272s

â€¢ [SLOW TEST:16.102 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:02:10.732: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-1882
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 17 01:02:10.759: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 17 01:02:30.811: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.1.102:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1882 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 01:02:30.811: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
Dec 17 01:02:30.899: INFO: Found all expected endpoints: [netserver-0]
Dec 17 01:02:30.901: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.2.66:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1882 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 01:02:30.901: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
Dec 17 01:02:30.989: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:02:30.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1882" for this suite.
Dec 17 01:02:43.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:02:43.071: INFO: namespace pod-network-test-1882 deletion completed in 12.079569209s

â€¢ [SLOW TEST:32.340 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:02:43.072: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 01:02:43.099: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e3461f30-954d-4662-9507-123e6dfd9178" in namespace "projected-9821" to be "success or failure"
Dec 17 01:02:43.102: INFO: Pod "downwardapi-volume-e3461f30-954d-4662-9507-123e6dfd9178": Phase="Pending", Reason="", readiness=false. Elapsed: 3.578651ms
Dec 17 01:02:45.105: INFO: Pod "downwardapi-volume-e3461f30-954d-4662-9507-123e6dfd9178": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006475462s
STEP: Saw pod success
Dec 17 01:02:45.105: INFO: Pod "downwardapi-volume-e3461f30-954d-4662-9507-123e6dfd9178" satisfied condition "success or failure"
Dec 17 01:02:45.107: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod downwardapi-volume-e3461f30-954d-4662-9507-123e6dfd9178 container client-container: <nil>
STEP: delete the pod
Dec 17 01:02:45.134: INFO: Waiting for pod downwardapi-volume-e3461f30-954d-4662-9507-123e6dfd9178 to disappear
Dec 17 01:02:45.146: INFO: Pod downwardapi-volume-e3461f30-954d-4662-9507-123e6dfd9178 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:02:45.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9821" for this suite.
Dec 17 01:02:51.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:02:51.214: INFO: namespace projected-9821 deletion completed in 6.063303668s

â€¢ [SLOW TEST:8.142 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:02:51.214: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 17 01:02:51.253: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:02:51.255: INFO: Number of nodes with available pods: 0
Dec 17 01:02:51.255: INFO: Node ip-172-20-34-147.us-east-2.compute.internal is running more than one daemon pod
Dec 17 01:02:52.259: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:02:52.261: INFO: Number of nodes with available pods: 0
Dec 17 01:02:52.261: INFO: Node ip-172-20-34-147.us-east-2.compute.internal is running more than one daemon pod
Dec 17 01:02:53.259: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:02:53.261: INFO: Number of nodes with available pods: 2
Dec 17 01:02:53.261: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec 17 01:02:53.272: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:02:53.274: INFO: Number of nodes with available pods: 1
Dec 17 01:02:53.274: INFO: Node ip-172-20-58-188.us-east-2.compute.internal is running more than one daemon pod
Dec 17 01:02:54.277: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:02:54.280: INFO: Number of nodes with available pods: 1
Dec 17 01:02:54.280: INFO: Node ip-172-20-58-188.us-east-2.compute.internal is running more than one daemon pod
Dec 17 01:02:55.277: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:02:55.280: INFO: Number of nodes with available pods: 1
Dec 17 01:02:55.280: INFO: Node ip-172-20-58-188.us-east-2.compute.internal is running more than one daemon pod
Dec 17 01:02:56.277: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:02:56.280: INFO: Number of nodes with available pods: 1
Dec 17 01:02:56.280: INFO: Node ip-172-20-58-188.us-east-2.compute.internal is running more than one daemon pod
Dec 17 01:02:57.278: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:02:57.280: INFO: Number of nodes with available pods: 1
Dec 17 01:02:57.280: INFO: Node ip-172-20-58-188.us-east-2.compute.internal is running more than one daemon pod
Dec 17 01:02:58.277: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:02:58.279: INFO: Number of nodes with available pods: 2
Dec 17 01:02:58.280: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9459, will wait for the garbage collector to delete the pods
Dec 17 01:02:58.337: INFO: Deleting DaemonSet.extensions daemon-set took: 3.984878ms
Dec 17 01:02:58.638: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.208436ms
Dec 17 01:03:10.040: INFO: Number of nodes with available pods: 0
Dec 17 01:03:10.040: INFO: Number of running nodes: 0, number of available pods: 0
Dec 17 01:03:10.042: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9459/daemonsets","resourceVersion":"9863"},"items":null}

Dec 17 01:03:10.043: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9459/pods","resourceVersion":"9863"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:03:10.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9459" for this suite.
Dec 17 01:03:16.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:03:16.110: INFO: namespace daemonsets-9459 deletion completed in 6.057263226s

â€¢ [SLOW TEST:24.896 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:03:16.110: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 01:03:16.137: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec 17 01:03:16.143: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 17 01:03:21.146: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 17 01:03:21.146: INFO: Creating deployment "test-rolling-update-deployment"
Dec 17 01:03:21.149: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec 17 01:03:21.155: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec 17 01:03:23.160: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec 17 01:03:23.161: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 17 01:03:23.167: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-123 /apis/apps/v1/namespaces/deployment-123/deployments/test-rolling-update-deployment 7e0c23e3-4bc7-4561-afff-cef9cb617393 9925 1 2019-12-17 01:03:21 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006284b78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-17 01:03:21 +0000 UTC,LastTransitionTime:2019-12-17 01:03:21 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2019-12-17 01:03:22 +0000 UTC,LastTransitionTime:2019-12-17 01:03:21 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 17 01:03:23.169: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-123 /apis/apps/v1/namespaces/deployment-123/replicasets/test-rolling-update-deployment-55d946486 84759e14-fb07-4d9d-a173-06c0d9d7c736 9918 1 2019-12-17 01:03:21 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 7e0c23e3-4bc7-4561-afff-cef9cb617393 0xc006285030 0xc006285031}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006285098 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 17 01:03:23.169: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec 17 01:03:23.169: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-123 /apis/apps/v1/namespaces/deployment-123/replicasets/test-rolling-update-controller 0878ef6c-ae56-4f95-a5ca-63d21f44edb6 9924 2 2019-12-17 01:03:16 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 7e0c23e3-4bc7-4561-afff-cef9cb617393 0xc006284f77 0xc006284f78}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc006284fd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 17 01:03:23.171: INFO: Pod "test-rolling-update-deployment-55d946486-fflrw" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-fflrw test-rolling-update-deployment-55d946486- deployment-123 /api/v1/namespaces/deployment-123/pods/test-rolling-update-deployment-55d946486-fflrw d78d1d4e-72c2-43e3-ae78-3d69a4ca477c 9917 0 2019-12-17 01:03:21 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 84759e14-fb07-4d9d-a173-06c0d9d7c736 0xc0062854f0 0xc0062854f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-f8tjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-f8tjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-f8tjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-58-188.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:03:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:03:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:03:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:03:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.58.188,PodIP:100.96.1.108,StartTime:2019-12-17 01:03:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 01:03:21 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://1419ff746f7a5386206cbdbfa47c01938996114921484bf49ea535f6f1c7c8ea,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.108,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:03:23.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-123" for this suite.
Dec 17 01:03:29.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:03:29.228: INFO: namespace deployment-123 deletion completed in 6.054389555s

â€¢ [SLOW TEST:13.118 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:03:29.228: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 17 01:03:31.769: INFO: Successfully updated pod "annotationupdatebf18e83a-0fa1-467a-80a5-a509873e8c27"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:03:35.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-539" for this suite.
Dec 17 01:04:03.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:04:03.865: INFO: namespace projected-539 deletion completed in 28.0710849s

â€¢ [SLOW TEST:34.637 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:04:03.865: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8093.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8093.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8093.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8093.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8093.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8093.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8093.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8093.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8093.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8093.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8093.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8093.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8093.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 5.195.69.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.69.195.5_udp@PTR;check="$$(dig +tcp +noall +answer +search 5.195.69.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.69.195.5_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8093.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8093.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8093.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8093.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8093.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8093.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8093.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8093.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8093.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8093.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8093.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8093.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8093.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 5.195.69.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.69.195.5_udp@PTR;check="$$(dig +tcp +noall +answer +search 5.195.69.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.69.195.5_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 17 01:04:05.920: INFO: Unable to read wheezy_udp@dns-test-service.dns-8093.svc.cluster.local from pod dns-8093/dns-test-1b5b0f17-83a6-4b67-aba3-94d201683826: the server could not find the requested resource (get pods dns-test-1b5b0f17-83a6-4b67-aba3-94d201683826)
Dec 17 01:04:05.922: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8093.svc.cluster.local from pod dns-8093/dns-test-1b5b0f17-83a6-4b67-aba3-94d201683826: the server could not find the requested resource (get pods dns-test-1b5b0f17-83a6-4b67-aba3-94d201683826)
Dec 17 01:04:05.925: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8093.svc.cluster.local from pod dns-8093/dns-test-1b5b0f17-83a6-4b67-aba3-94d201683826: the server could not find the requested resource (get pods dns-test-1b5b0f17-83a6-4b67-aba3-94d201683826)
Dec 17 01:04:05.927: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8093.svc.cluster.local from pod dns-8093/dns-test-1b5b0f17-83a6-4b67-aba3-94d201683826: the server could not find the requested resource (get pods dns-test-1b5b0f17-83a6-4b67-aba3-94d201683826)
Dec 17 01:04:05.945: INFO: Unable to read jessie_udp@dns-test-service.dns-8093.svc.cluster.local from pod dns-8093/dns-test-1b5b0f17-83a6-4b67-aba3-94d201683826: the server could not find the requested resource (get pods dns-test-1b5b0f17-83a6-4b67-aba3-94d201683826)
Dec 17 01:04:05.947: INFO: Unable to read jessie_tcp@dns-test-service.dns-8093.svc.cluster.local from pod dns-8093/dns-test-1b5b0f17-83a6-4b67-aba3-94d201683826: the server could not find the requested resource (get pods dns-test-1b5b0f17-83a6-4b67-aba3-94d201683826)
Dec 17 01:04:05.950: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8093.svc.cluster.local from pod dns-8093/dns-test-1b5b0f17-83a6-4b67-aba3-94d201683826: the server could not find the requested resource (get pods dns-test-1b5b0f17-83a6-4b67-aba3-94d201683826)
Dec 17 01:04:05.952: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8093.svc.cluster.local from pod dns-8093/dns-test-1b5b0f17-83a6-4b67-aba3-94d201683826: the server could not find the requested resource (get pods dns-test-1b5b0f17-83a6-4b67-aba3-94d201683826)
Dec 17 01:04:05.972: INFO: Lookups using dns-8093/dns-test-1b5b0f17-83a6-4b67-aba3-94d201683826 failed for: [wheezy_udp@dns-test-service.dns-8093.svc.cluster.local wheezy_tcp@dns-test-service.dns-8093.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8093.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8093.svc.cluster.local jessie_udp@dns-test-service.dns-8093.svc.cluster.local jessie_tcp@dns-test-service.dns-8093.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8093.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8093.svc.cluster.local]

Dec 17 01:04:11.022: INFO: DNS probes using dns-8093/dns-test-1b5b0f17-83a6-4b67-aba3-94d201683826 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:04:11.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8093" for this suite.
Dec 17 01:04:17.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:04:17.159: INFO: namespace dns-8093 deletion completed in 6.076540751s

â€¢ [SLOW TEST:13.294 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:04:17.160: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 17 01:04:19.699: INFO: Successfully updated pod "pod-update-activedeadlineseconds-02b30830-94b6-41ca-b9b5-66502c87d157"
Dec 17 01:04:19.699: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-02b30830-94b6-41ca-b9b5-66502c87d157" in namespace "pods-4814" to be "terminated due to deadline exceeded"
Dec 17 01:04:19.701: INFO: Pod "pod-update-activedeadlineseconds-02b30830-94b6-41ca-b9b5-66502c87d157": Phase="Running", Reason="", readiness=true. Elapsed: 2.137733ms
Dec 17 01:04:21.703: INFO: Pod "pod-update-activedeadlineseconds-02b30830-94b6-41ca-b9b5-66502c87d157": Phase="Running", Reason="", readiness=true. Elapsed: 2.004524061s
Dec 17 01:04:23.706: INFO: Pod "pod-update-activedeadlineseconds-02b30830-94b6-41ca-b9b5-66502c87d157": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.006941973s
Dec 17 01:04:23.706: INFO: Pod "pod-update-activedeadlineseconds-02b30830-94b6-41ca-b9b5-66502c87d157" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:04:23.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4814" for this suite.
Dec 17 01:04:29.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:04:29.787: INFO: namespace pods-4814 deletion completed in 6.07826589s

â€¢ [SLOW TEST:12.627 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:04:29.787: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Dec 17 01:04:32.333: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5908 pod-service-account-ebbb315d-2972-48ab-9f19-2329b661d14f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Dec 17 01:04:32.490: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5908 pod-service-account-ebbb315d-2972-48ab-9f19-2329b661d14f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Dec 17 01:04:32.651: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5908 pod-service-account-ebbb315d-2972-48ab-9f19-2329b661d14f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:04:32.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5908" for this suite.
Dec 17 01:04:38.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:04:38.878: INFO: namespace svcaccounts-5908 deletion completed in 6.062144377s

â€¢ [SLOW TEST:9.091 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:04:38.878: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-a6d3cbe1-5230-4bb8-9090-fd462505f0c0
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:04:38.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7252" for this suite.
Dec 17 01:04:44.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:04:44.966: INFO: namespace configmap-7252 deletion completed in 6.064925058s

â€¢ [SLOW TEST:6.087 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:04:44.966: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 01:04:44.987: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Dec 17 01:04:48.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 --namespace=crd-publish-openapi-2345 create -f -'
Dec 17 01:04:48.406: INFO: stderr: ""
Dec 17 01:04:48.406: INFO: stdout: "e2e-test-crd-publish-openapi-572-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 17 01:04:48.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 --namespace=crd-publish-openapi-2345 delete e2e-test-crd-publish-openapi-572-crds test-foo'
Dec 17 01:04:48.480: INFO: stderr: ""
Dec 17 01:04:48.480: INFO: stdout: "e2e-test-crd-publish-openapi-572-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Dec 17 01:04:48.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 --namespace=crd-publish-openapi-2345 apply -f -'
Dec 17 01:04:48.641: INFO: stderr: ""
Dec 17 01:04:48.641: INFO: stdout: "e2e-test-crd-publish-openapi-572-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 17 01:04:48.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 --namespace=crd-publish-openapi-2345 delete e2e-test-crd-publish-openapi-572-crds test-foo'
Dec 17 01:04:48.718: INFO: stderr: ""
Dec 17 01:04:48.718: INFO: stdout: "e2e-test-crd-publish-openapi-572-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Dec 17 01:04:48.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 --namespace=crd-publish-openapi-2345 create -f -'
Dec 17 01:04:48.863: INFO: rc: 1
Dec 17 01:04:48.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 --namespace=crd-publish-openapi-2345 apply -f -'
Dec 17 01:04:49.013: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Dec 17 01:04:49.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 --namespace=crd-publish-openapi-2345 create -f -'
Dec 17 01:04:49.161: INFO: rc: 1
Dec 17 01:04:49.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 --namespace=crd-publish-openapi-2345 apply -f -'
Dec 17 01:04:49.310: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Dec 17 01:04:49.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 explain e2e-test-crd-publish-openapi-572-crds'
Dec 17 01:04:49.461: INFO: stderr: ""
Dec 17 01:04:49.461: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-572-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Dec 17 01:04:49.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 explain e2e-test-crd-publish-openapi-572-crds.metadata'
Dec 17 01:04:49.629: INFO: stderr: ""
Dec 17 01:04:49.629: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-572-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Dec 17 01:04:49.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 explain e2e-test-crd-publish-openapi-572-crds.spec'
Dec 17 01:04:49.782: INFO: stderr: ""
Dec 17 01:04:49.782: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-572-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Dec 17 01:04:49.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 explain e2e-test-crd-publish-openapi-572-crds.spec.bars'
Dec 17 01:04:49.934: INFO: stderr: ""
Dec 17 01:04:49.934: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-572-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Dec 17 01:04:49.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 explain e2e-test-crd-publish-openapi-572-crds.spec.bars2'
Dec 17 01:04:50.100: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:04:53.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2345" for this suite.
Dec 17 01:04:59.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:04:59.127: INFO: namespace crd-publish-openapi-2345 deletion completed in 6.068100574s

â€¢ [SLOW TEST:14.161 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:04:59.127: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 01:04:59.551: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 17 01:05:01.557: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712141499, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712141499, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712141499, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712141499, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 01:05:04.569: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:05:04.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1769" for this suite.
Dec 17 01:05:10.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:05:10.657: INFO: namespace webhook-1769 deletion completed in 6.057774307s
STEP: Destroying namespace "webhook-1769-markers" for this suite.
Dec 17 01:05:16.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:05:16.712: INFO: namespace webhook-1769-markers deletion completed in 6.055797537s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:17.594 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:05:16.721: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 01:05:16.743: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8b402383-6c9f-4568-bf97-cf3510bfe968" in namespace "projected-6129" to be "success or failure"
Dec 17 01:05:16.746: INFO: Pod "downwardapi-volume-8b402383-6c9f-4568-bf97-cf3510bfe968": Phase="Pending", Reason="", readiness=false. Elapsed: 2.827148ms
Dec 17 01:05:18.749: INFO: Pod "downwardapi-volume-8b402383-6c9f-4568-bf97-cf3510bfe968": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005461422s
STEP: Saw pod success
Dec 17 01:05:18.749: INFO: Pod "downwardapi-volume-8b402383-6c9f-4568-bf97-cf3510bfe968" satisfied condition "success or failure"
Dec 17 01:05:18.750: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod downwardapi-volume-8b402383-6c9f-4568-bf97-cf3510bfe968 container client-container: <nil>
STEP: delete the pod
Dec 17 01:05:18.770: INFO: Waiting for pod downwardapi-volume-8b402383-6c9f-4568-bf97-cf3510bfe968 to disappear
Dec 17 01:05:18.772: INFO: Pod downwardapi-volume-8b402383-6c9f-4568-bf97-cf3510bfe968 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:05:18.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6129" for this suite.
Dec 17 01:05:24.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:05:24.850: INFO: namespace projected-6129 deletion completed in 6.076010134s

â€¢ [SLOW TEST:8.130 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:05:24.851: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 17 01:05:24.871: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:05:27.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1978" for this suite.
Dec 17 01:05:33.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:05:33.682: INFO: namespace init-container-1978 deletion completed in 6.060933556s

â€¢ [SLOW TEST:8.831 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:05:33.683: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-289eef56-4161-47df-a06b-0e4f442d1751
STEP: Creating a pod to test consume secrets
Dec 17 01:05:33.714: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5eca6f78-40ac-46c5-baf9-308d391be64b" in namespace "projected-6123" to be "success or failure"
Dec 17 01:05:33.719: INFO: Pod "pod-projected-secrets-5eca6f78-40ac-46c5-baf9-308d391be64b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.429571ms
Dec 17 01:05:35.722: INFO: Pod "pod-projected-secrets-5eca6f78-40ac-46c5-baf9-308d391be64b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007661226s
STEP: Saw pod success
Dec 17 01:05:35.722: INFO: Pod "pod-projected-secrets-5eca6f78-40ac-46c5-baf9-308d391be64b" satisfied condition "success or failure"
Dec 17 01:05:35.723: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-projected-secrets-5eca6f78-40ac-46c5-baf9-308d391be64b container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 17 01:05:35.736: INFO: Waiting for pod pod-projected-secrets-5eca6f78-40ac-46c5-baf9-308d391be64b to disappear
Dec 17 01:05:35.738: INFO: Pod pod-projected-secrets-5eca6f78-40ac-46c5-baf9-308d391be64b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:05:35.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6123" for this suite.
Dec 17 01:05:41.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:05:41.809: INFO: namespace projected-6123 deletion completed in 6.068661162s

â€¢ [SLOW TEST:8.126 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:05:41.809: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Dec 17 01:05:41.836: INFO: Waiting up to 5m0s for pod "var-expansion-9b99d108-23e8-4d7d-85ee-29ea4078a3cc" in namespace "var-expansion-3971" to be "success or failure"
Dec 17 01:05:41.840: INFO: Pod "var-expansion-9b99d108-23e8-4d7d-85ee-29ea4078a3cc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.940864ms
Dec 17 01:05:43.842: INFO: Pod "var-expansion-9b99d108-23e8-4d7d-85ee-29ea4078a3cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006198504s
STEP: Saw pod success
Dec 17 01:05:43.842: INFO: Pod "var-expansion-9b99d108-23e8-4d7d-85ee-29ea4078a3cc" satisfied condition "success or failure"
Dec 17 01:05:43.844: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod var-expansion-9b99d108-23e8-4d7d-85ee-29ea4078a3cc container dapi-container: <nil>
STEP: delete the pod
Dec 17 01:05:43.855: INFO: Waiting for pod var-expansion-9b99d108-23e8-4d7d-85ee-29ea4078a3cc to disappear
Dec 17 01:05:43.857: INFO: Pod var-expansion-9b99d108-23e8-4d7d-85ee-29ea4078a3cc no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:05:43.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3971" for this suite.
Dec 17 01:05:49.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:05:49.917: INFO: namespace var-expansion-3971 deletion completed in 6.058204219s

â€¢ [SLOW TEST:8.108 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:05:49.917: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:05:56.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-705" for this suite.
Dec 17 01:06:02.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:06:03.005: INFO: namespace resourcequota-705 deletion completed in 6.059679406s

â€¢ [SLOW TEST:13.088 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:06:03.006: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-24h8
STEP: Creating a pod to test atomic-volume-subpath
Dec 17 01:06:03.034: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-24h8" in namespace "subpath-2328" to be "success or failure"
Dec 17 01:06:03.038: INFO: Pod "pod-subpath-test-projected-24h8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.55696ms
Dec 17 01:06:05.041: INFO: Pod "pod-subpath-test-projected-24h8": Phase="Running", Reason="", readiness=true. Elapsed: 2.006427663s
Dec 17 01:06:07.043: INFO: Pod "pod-subpath-test-projected-24h8": Phase="Running", Reason="", readiness=true. Elapsed: 4.008784992s
Dec 17 01:06:09.046: INFO: Pod "pod-subpath-test-projected-24h8": Phase="Running", Reason="", readiness=true. Elapsed: 6.011260452s
Dec 17 01:06:11.048: INFO: Pod "pod-subpath-test-projected-24h8": Phase="Running", Reason="", readiness=true. Elapsed: 8.01381231s
Dec 17 01:06:13.051: INFO: Pod "pod-subpath-test-projected-24h8": Phase="Running", Reason="", readiness=true. Elapsed: 10.016909637s
Dec 17 01:06:15.055: INFO: Pod "pod-subpath-test-projected-24h8": Phase="Running", Reason="", readiness=true. Elapsed: 12.020255185s
Dec 17 01:06:17.057: INFO: Pod "pod-subpath-test-projected-24h8": Phase="Running", Reason="", readiness=true. Elapsed: 14.022762596s
Dec 17 01:06:19.060: INFO: Pod "pod-subpath-test-projected-24h8": Phase="Running", Reason="", readiness=true. Elapsed: 16.025803044s
Dec 17 01:06:21.063: INFO: Pod "pod-subpath-test-projected-24h8": Phase="Running", Reason="", readiness=true. Elapsed: 18.028652302s
Dec 17 01:06:23.066: INFO: Pod "pod-subpath-test-projected-24h8": Phase="Running", Reason="", readiness=true. Elapsed: 20.031374857s
Dec 17 01:06:25.068: INFO: Pod "pod-subpath-test-projected-24h8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.033608744s
STEP: Saw pod success
Dec 17 01:06:25.068: INFO: Pod "pod-subpath-test-projected-24h8" satisfied condition "success or failure"
Dec 17 01:06:25.070: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-subpath-test-projected-24h8 container test-container-subpath-projected-24h8: <nil>
STEP: delete the pod
Dec 17 01:06:25.102: INFO: Waiting for pod pod-subpath-test-projected-24h8 to disappear
Dec 17 01:06:25.105: INFO: Pod pod-subpath-test-projected-24h8 no longer exists
STEP: Deleting pod pod-subpath-test-projected-24h8
Dec 17 01:06:25.105: INFO: Deleting pod "pod-subpath-test-projected-24h8" in namespace "subpath-2328"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:06:25.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2328" for this suite.
Dec 17 01:06:31.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:06:31.177: INFO: namespace subpath-2328 deletion completed in 6.068004977s

â€¢ [SLOW TEST:28.171 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:06:31.177: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 01:06:31.865: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 01:06:34.883: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 01:06:34.885: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:06:35.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5460" for this suite.
Dec 17 01:06:41.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:06:42.044: INFO: namespace webhook-5460 deletion completed in 6.057425447s
STEP: Destroying namespace "webhook-5460-markers" for this suite.
Dec 17 01:06:48.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:06:48.119: INFO: namespace webhook-5460-markers deletion completed in 6.075223992s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:16.951 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:06:48.128: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 17 01:06:48.149: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 17 01:06:48.155: INFO: Waiting for terminating namespaces to be deleted...
Dec 17 01:06:48.157: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-34-147.us-east-2.compute.internal before test
Dec 17 01:06:48.170: INFO: sonobuoy-e2e-job-edd513b56d7b4d93 from sonobuoy started at 2019-12-17 00:16:40 +0000 UTC (2 container statuses recorded)
Dec 17 01:06:48.170: INFO: 	Container e2e ready: true, restart count 0
Dec 17 01:06:48.170: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 17 01:06:48.170: INFO: sonobuoy-systemd-logs-daemon-set-aa23d16e52f14f6e-l6lh6 from sonobuoy started at 2019-12-17 00:16:40 +0000 UTC (2 container statuses recorded)
Dec 17 01:06:48.170: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 17 01:06:48.170: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 17 01:06:48.170: INFO: kube-proxy-ip-172-20-34-147.us-east-2.compute.internal from kube-system started at 2019-12-17 00:10:42 +0000 UTC (1 container statuses recorded)
Dec 17 01:06:48.170: INFO: 	Container kube-proxy ready: true, restart count 5
Dec 17 01:06:48.170: INFO: kube-dns-bb55d6458-qz7ks from kube-system started at 2019-12-17 00:15:20 +0000 UTC (3 container statuses recorded)
Dec 17 01:06:48.170: INFO: 	Container dnsmasq ready: true, restart count 0
Dec 17 01:06:48.170: INFO: 	Container kubedns ready: true, restart count 0
Dec 17 01:06:48.170: INFO: 	Container sidecar ready: true, restart count 0
Dec 17 01:06:48.170: INFO: kube-dns-autoscaler-66b775459-2bh8z from kube-system started at 2019-12-17 00:50:49 +0000 UTC (1 container statuses recorded)
Dec 17 01:06:48.170: INFO: 	Container autoscaler ready: true, restart count 0
Dec 17 01:06:48.170: INFO: sonobuoy from sonobuoy started at 2019-12-17 00:16:34 +0000 UTC (1 container statuses recorded)
Dec 17 01:06:48.170: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 17 01:06:48.170: INFO: kube-dns-bb55d6458-982k4 from kube-system started at 2019-12-17 00:50:49 +0000 UTC (3 container statuses recorded)
Dec 17 01:06:48.170: INFO: 	Container dnsmasq ready: true, restart count 0
Dec 17 01:06:48.170: INFO: 	Container kubedns ready: true, restart count 0
Dec 17 01:06:48.170: INFO: 	Container sidecar ready: true, restart count 0
Dec 17 01:06:48.170: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-58-188.us-east-2.compute.internal before test
Dec 17 01:06:48.173: INFO: kube-proxy-ip-172-20-58-188.us-east-2.compute.internal from kube-system started at 2019-12-17 00:10:40 +0000 UTC (1 container statuses recorded)
Dec 17 01:06:48.173: INFO: 	Container kube-proxy ready: true, restart count 5
Dec 17 01:06:48.173: INFO: sonobuoy-systemd-logs-daemon-set-aa23d16e52f14f6e-dk4ms from sonobuoy started at 2019-12-17 00:16:40 +0000 UTC (2 container statuses recorded)
Dec 17 01:06:48.173: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 17 01:06:48.173: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-d79f249c-f940-4b7d-bb74-b12a84eb472f 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-d79f249c-f940-4b7d-bb74-b12a84eb472f off the node ip-172-20-58-188.us-east-2.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-d79f249c-f940-4b7d-bb74-b12a84eb472f
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:06:56.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7959" for this suite.
Dec 17 01:07:14.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:07:14.329: INFO: namespace sched-pred-7959 deletion completed in 18.084015941s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

â€¢ [SLOW TEST:26.200 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:07:14.329: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 17 01:07:14.400: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:07:18.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-696" for this suite.
Dec 17 01:07:46.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:07:46.454: INFO: namespace init-container-696 deletion completed in 28.065724179s

â€¢ [SLOW TEST:32.125 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:07:46.454: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 01:07:46.993: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 01:07:50.017: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:07:50.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5213" for this suite.
Dec 17 01:07:56.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:07:56.121: INFO: namespace webhook-5213 deletion completed in 6.056287156s
STEP: Destroying namespace "webhook-5213-markers" for this suite.
Dec 17 01:08:02.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:08:02.179: INFO: namespace webhook-5213-markers deletion completed in 6.057886921s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:15.734 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:08:02.188: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:08:15.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5275" for this suite.
Dec 17 01:08:21.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:08:21.322: INFO: namespace namespaces-5275 deletion completed in 6.053168091s
STEP: Destroying namespace "nsdeletetest-5000" for this suite.
Dec 17 01:08:21.324: INFO: Namespace nsdeletetest-5000 was already deleted
STEP: Destroying namespace "nsdeletetest-4058" for this suite.
Dec 17 01:08:27.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:08:27.383: INFO: namespace nsdeletetest-4058 deletion completed in 6.059113598s

â€¢ [SLOW TEST:25.194 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:08:27.383: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-5971
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-5971
Dec 17 01:08:27.410: INFO: Found 0 stateful pods, waiting for 1
Dec 17 01:08:37.412: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 17 01:08:37.424: INFO: Deleting all statefulset in ns statefulset-5971
Dec 17 01:08:37.426: INFO: Scaling statefulset ss to 0
Dec 17 01:08:47.451: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 01:08:47.453: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:08:47.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5971" for this suite.
Dec 17 01:08:53.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:08:53.526: INFO: namespace statefulset-5971 deletion completed in 6.060972972s

â€¢ [SLOW TEST:26.143 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:08:53.526: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:08:57.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-716" for this suite.
Dec 17 01:09:03.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:09:03.618: INFO: namespace kubelet-test-716 deletion completed in 6.061304315s

â€¢ [SLOW TEST:10.091 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:09:03.618: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 01:09:04.442: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 17 01:09:06.448: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712141744, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712141744, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712141744, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712141744, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 01:09:09.460: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 01:09:09.462: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1223-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:09:10.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1452" for this suite.
Dec 17 01:09:16.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:09:16.848: INFO: namespace webhook-1452 deletion completed in 6.061478856s
STEP: Destroying namespace "webhook-1452-markers" for this suite.
Dec 17 01:09:22.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:09:22.907: INFO: namespace webhook-1452-markers deletion completed in 6.057997348s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:19.297 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:09:22.915: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-3632, will wait for the garbage collector to delete the pods
Dec 17 01:09:24.995: INFO: Deleting Job.batch foo took: 3.799285ms
Dec 17 01:09:25.295: INFO: Terminating Job.batch foo pods took: 300.316283ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:10:00.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3632" for this suite.
Dec 17 01:10:06.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:10:06.167: INFO: namespace job-3632 deletion completed in 6.066378273s

â€¢ [SLOW TEST:43.252 seconds]
[sig-apps] Job
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:10:06.167: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 01:10:06.196: INFO: Create a RollingUpdate DaemonSet
Dec 17 01:10:06.199: INFO: Check that daemon pods launch on every node of the cluster
Dec 17 01:10:06.201: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:10:06.204: INFO: Number of nodes with available pods: 0
Dec 17 01:10:06.204: INFO: Node ip-172-20-34-147.us-east-2.compute.internal is running more than one daemon pod
Dec 17 01:10:07.209: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:10:07.214: INFO: Number of nodes with available pods: 0
Dec 17 01:10:07.214: INFO: Node ip-172-20-34-147.us-east-2.compute.internal is running more than one daemon pod
Dec 17 01:10:08.207: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:10:08.209: INFO: Number of nodes with available pods: 2
Dec 17 01:10:08.209: INFO: Number of running nodes: 2, number of available pods: 2
Dec 17 01:10:08.209: INFO: Update the DaemonSet to trigger a rollout
Dec 17 01:10:08.215: INFO: Updating DaemonSet daemon-set
Dec 17 01:10:22.226: INFO: Roll back the DaemonSet before rollout is complete
Dec 17 01:10:22.229: INFO: Updating DaemonSet daemon-set
Dec 17 01:10:22.230: INFO: Make sure DaemonSet rollback is complete
Dec 17 01:10:22.232: INFO: Wrong image for pod: daemon-set-c9dxb. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 17 01:10:22.232: INFO: Pod daemon-set-c9dxb is not available
Dec 17 01:10:22.234: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:10:23.237: INFO: Wrong image for pod: daemon-set-c9dxb. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 17 01:10:23.237: INFO: Pod daemon-set-c9dxb is not available
Dec 17 01:10:23.239: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:10:24.243: INFO: Wrong image for pod: daemon-set-c9dxb. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 17 01:10:24.243: INFO: Pod daemon-set-c9dxb is not available
Dec 17 01:10:24.245: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:10:25.237: INFO: Wrong image for pod: daemon-set-c9dxb. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 17 01:10:25.237: INFO: Pod daemon-set-c9dxb is not available
Dec 17 01:10:25.239: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:10:26.238: INFO: Wrong image for pod: daemon-set-c9dxb. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 17 01:10:26.238: INFO: Pod daemon-set-c9dxb is not available
Dec 17 01:10:26.240: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:10:27.246: INFO: Pod daemon-set-5zn8l is not available
Dec 17 01:10:27.256: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-224, will wait for the garbage collector to delete the pods
Dec 17 01:10:27.317: INFO: Deleting DaemonSet.extensions daemon-set took: 4.421192ms
Dec 17 01:10:27.617: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.256585ms
Dec 17 01:10:42.019: INFO: Number of nodes with available pods: 0
Dec 17 01:10:42.019: INFO: Number of running nodes: 0, number of available pods: 0
Dec 17 01:10:42.021: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-224/daemonsets","resourceVersion":"11495"},"items":null}

Dec 17 01:10:42.022: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-224/pods","resourceVersion":"11495"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:10:42.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-224" for this suite.
Dec 17 01:10:48.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:10:48.121: INFO: namespace daemonsets-224 deletion completed in 6.090169298s

â€¢ [SLOW TEST:41.954 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:10:48.121: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 01:10:48.147: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c7572300-7a7c-4b11-9ef2-562480482998" in namespace "downward-api-3163" to be "success or failure"
Dec 17 01:10:48.152: INFO: Pod "downwardapi-volume-c7572300-7a7c-4b11-9ef2-562480482998": Phase="Pending", Reason="", readiness=false. Elapsed: 5.030859ms
Dec 17 01:10:50.155: INFO: Pod "downwardapi-volume-c7572300-7a7c-4b11-9ef2-562480482998": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007580338s
STEP: Saw pod success
Dec 17 01:10:50.155: INFO: Pod "downwardapi-volume-c7572300-7a7c-4b11-9ef2-562480482998" satisfied condition "success or failure"
Dec 17 01:10:50.156: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod downwardapi-volume-c7572300-7a7c-4b11-9ef2-562480482998 container client-container: <nil>
STEP: delete the pod
Dec 17 01:10:50.185: INFO: Waiting for pod downwardapi-volume-c7572300-7a7c-4b11-9ef2-562480482998 to disappear
Dec 17 01:10:50.187: INFO: Pod downwardapi-volume-c7572300-7a7c-4b11-9ef2-562480482998 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:10:50.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3163" for this suite.
Dec 17 01:10:56.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:10:56.270: INFO: namespace downward-api-3163 deletion completed in 6.080352804s

â€¢ [SLOW TEST:8.148 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:10:56.270: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-e45747eb-daa6-4a94-a7c1-9460a94994c5
STEP: Creating a pod to test consume secrets
Dec 17 01:10:56.296: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5a849e19-5ac8-4659-bae2-08daee3ab5fc" in namespace "projected-9698" to be "success or failure"
Dec 17 01:10:56.300: INFO: Pod "pod-projected-secrets-5a849e19-5ac8-4659-bae2-08daee3ab5fc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.263683ms
Dec 17 01:10:58.303: INFO: Pod "pod-projected-secrets-5a849e19-5ac8-4659-bae2-08daee3ab5fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006371487s
STEP: Saw pod success
Dec 17 01:10:58.303: INFO: Pod "pod-projected-secrets-5a849e19-5ac8-4659-bae2-08daee3ab5fc" satisfied condition "success or failure"
Dec 17 01:10:58.304: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-projected-secrets-5a849e19-5ac8-4659-bae2-08daee3ab5fc container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 17 01:10:58.316: INFO: Waiting for pod pod-projected-secrets-5a849e19-5ac8-4659-bae2-08daee3ab5fc to disappear
Dec 17 01:10:58.317: INFO: Pod pod-projected-secrets-5a849e19-5ac8-4659-bae2-08daee3ab5fc no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:10:58.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9698" for this suite.
Dec 17 01:11:04.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:11:04.382: INFO: namespace projected-9698 deletion completed in 6.062555063s

â€¢ [SLOW TEST:8.113 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:11:04.382: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-7620
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 17 01:11:04.402: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 17 01:11:20.444: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.137:8080/dial?request=hostName&protocol=udp&host=100.96.1.136&port=8081&tries=1'] Namespace:pod-network-test-7620 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 01:11:20.444: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
Dec 17 01:11:20.529: INFO: Waiting for endpoints: map[]
Dec 17 01:11:20.531: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.137:8080/dial?request=hostName&protocol=udp&host=100.96.2.71&port=8081&tries=1'] Namespace:pod-network-test-7620 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 01:11:20.531: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
Dec 17 01:11:20.618: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:11:20.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7620" for this suite.
Dec 17 01:11:32.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:11:32.678: INFO: namespace pod-network-test-7620 deletion completed in 12.057848285s

â€¢ [SLOW TEST:28.296 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:11:32.679: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 01:11:32.707: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec 17 01:11:32.712: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:11:32.714: INFO: Number of nodes with available pods: 0
Dec 17 01:11:32.714: INFO: Node ip-172-20-34-147.us-east-2.compute.internal is running more than one daemon pod
Dec 17 01:11:33.717: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:11:33.719: INFO: Number of nodes with available pods: 0
Dec 17 01:11:33.719: INFO: Node ip-172-20-34-147.us-east-2.compute.internal is running more than one daemon pod
Dec 17 01:11:34.717: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:11:34.719: INFO: Number of nodes with available pods: 2
Dec 17 01:11:34.719: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec 17 01:11:34.737: INFO: Wrong image for pod: daemon-set-cs2vs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 01:11:34.737: INFO: Wrong image for pod: daemon-set-zwwzh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 01:11:34.741: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:11:35.744: INFO: Wrong image for pod: daemon-set-cs2vs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 01:11:35.744: INFO: Wrong image for pod: daemon-set-zwwzh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 01:11:35.746: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:11:36.744: INFO: Wrong image for pod: daemon-set-cs2vs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 01:11:36.744: INFO: Wrong image for pod: daemon-set-zwwzh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 01:11:36.746: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:11:37.743: INFO: Wrong image for pod: daemon-set-cs2vs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 01:11:37.743: INFO: Wrong image for pod: daemon-set-zwwzh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 01:11:37.743: INFO: Pod daemon-set-zwwzh is not available
Dec 17 01:11:37.745: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:11:38.744: INFO: Wrong image for pod: daemon-set-cs2vs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 01:11:38.744: INFO: Pod daemon-set-mg2bd is not available
Dec 17 01:11:38.746: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:11:39.743: INFO: Wrong image for pod: daemon-set-cs2vs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 01:11:39.746: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:11:40.743: INFO: Wrong image for pod: daemon-set-cs2vs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 01:11:40.743: INFO: Pod daemon-set-cs2vs is not available
Dec 17 01:11:40.746: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:11:41.743: INFO: Wrong image for pod: daemon-set-cs2vs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 01:11:41.743: INFO: Pod daemon-set-cs2vs is not available
Dec 17 01:11:41.745: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:11:42.743: INFO: Wrong image for pod: daemon-set-cs2vs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 01:11:42.743: INFO: Pod daemon-set-cs2vs is not available
Dec 17 01:11:42.746: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:11:43.744: INFO: Wrong image for pod: daemon-set-cs2vs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 01:11:43.744: INFO: Pod daemon-set-cs2vs is not available
Dec 17 01:11:43.746: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:11:44.743: INFO: Wrong image for pod: daemon-set-cs2vs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 01:11:44.743: INFO: Pod daemon-set-cs2vs is not available
Dec 17 01:11:44.745: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:11:45.744: INFO: Wrong image for pod: daemon-set-cs2vs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 01:11:45.744: INFO: Pod daemon-set-cs2vs is not available
Dec 17 01:11:45.747: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:11:46.743: INFO: Wrong image for pod: daemon-set-cs2vs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 01:11:46.743: INFO: Pod daemon-set-cs2vs is not available
Dec 17 01:11:46.745: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:11:47.744: INFO: Wrong image for pod: daemon-set-cs2vs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 01:11:47.744: INFO: Pod daemon-set-cs2vs is not available
Dec 17 01:11:47.746: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:11:48.743: INFO: Wrong image for pod: daemon-set-cs2vs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 01:11:48.743: INFO: Pod daemon-set-cs2vs is not available
Dec 17 01:11:48.745: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:11:49.743: INFO: Wrong image for pod: daemon-set-cs2vs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 01:11:49.743: INFO: Pod daemon-set-cs2vs is not available
Dec 17 01:11:49.745: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:11:50.743: INFO: Wrong image for pod: daemon-set-cs2vs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 01:11:50.744: INFO: Pod daemon-set-cs2vs is not available
Dec 17 01:11:50.746: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:11:51.744: INFO: Wrong image for pod: daemon-set-cs2vs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 01:11:51.744: INFO: Pod daemon-set-cs2vs is not available
Dec 17 01:11:51.747: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:11:52.746: INFO: Pod daemon-set-f5wzk is not available
Dec 17 01:11:52.756: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Dec 17 01:11:52.762: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:11:52.765: INFO: Number of nodes with available pods: 1
Dec 17 01:11:52.765: INFO: Node ip-172-20-34-147.us-east-2.compute.internal is running more than one daemon pod
Dec 17 01:11:53.768: INFO: DaemonSet pods can't tolerate node ip-172-20-48-32.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 17 01:11:53.770: INFO: Number of nodes with available pods: 2
Dec 17 01:11:53.770: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6988, will wait for the garbage collector to delete the pods
Dec 17 01:11:53.835: INFO: Deleting DaemonSet.extensions daemon-set took: 3.95422ms
Dec 17 01:11:54.135: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.253245ms
Dec 17 01:12:02.038: INFO: Number of nodes with available pods: 0
Dec 17 01:12:02.038: INFO: Number of running nodes: 0, number of available pods: 0
Dec 17 01:12:02.040: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6988/daemonsets","resourceVersion":"11778"},"items":null}

Dec 17 01:12:02.042: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6988/pods","resourceVersion":"11778"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:12:02.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6988" for this suite.
Dec 17 01:12:08.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:12:08.125: INFO: namespace daemonsets-6988 deletion completed in 6.075186788s

â€¢ [SLOW TEST:35.447 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:12:08.126: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-3199
I1217 01:12:08.149274      21 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-3199, replica count: 1
I1217 01:12:09.199868      21 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1217 01:12:10.200158      21 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 17 01:12:10.307: INFO: Created: latency-svc-74fc2
Dec 17 01:12:10.316: INFO: Got endpoints: latency-svc-74fc2 [15.864762ms]
Dec 17 01:12:10.332: INFO: Created: latency-svc-rht8f
Dec 17 01:12:10.341: INFO: Created: latency-svc-mkscm
Dec 17 01:12:10.343: INFO: Got endpoints: latency-svc-rht8f [26.893763ms]
Dec 17 01:12:10.353: INFO: Created: latency-svc-ptdxf
Dec 17 01:12:10.353: INFO: Got endpoints: latency-svc-mkscm [37.252456ms]
Dec 17 01:12:10.361: INFO: Created: latency-svc-ftwlp
Dec 17 01:12:10.363: INFO: Got endpoints: latency-svc-ptdxf [46.385241ms]
Dec 17 01:12:10.368: INFO: Created: latency-svc-2hg8b
Dec 17 01:12:10.371: INFO: Got endpoints: latency-svc-ftwlp [54.420322ms]
Dec 17 01:12:10.380: INFO: Got endpoints: latency-svc-2hg8b [63.209058ms]
Dec 17 01:12:10.380: INFO: Created: latency-svc-rqmjd
Dec 17 01:12:10.395: INFO: Got endpoints: latency-svc-rqmjd [78.072941ms]
Dec 17 01:12:10.397: INFO: Created: latency-svc-vphjs
Dec 17 01:12:10.402: INFO: Got endpoints: latency-svc-vphjs [85.109742ms]
Dec 17 01:12:10.410: INFO: Created: latency-svc-8znc8
Dec 17 01:12:10.417: INFO: Created: latency-svc-b76jf
Dec 17 01:12:10.420: INFO: Got endpoints: latency-svc-8znc8 [102.558503ms]
Dec 17 01:12:10.422: INFO: Got endpoints: latency-svc-b76jf [103.986236ms]
Dec 17 01:12:10.427: INFO: Created: latency-svc-wj59g
Dec 17 01:12:10.450: INFO: Created: latency-svc-7nmfs
Dec 17 01:12:10.450: INFO: Got endpoints: latency-svc-wj59g [132.532226ms]
Dec 17 01:12:10.458: INFO: Got endpoints: latency-svc-7nmfs [37.956191ms]
Dec 17 01:12:10.463: INFO: Created: latency-svc-l6bn5
Dec 17 01:12:10.470: INFO: Got endpoints: latency-svc-l6bn5 [151.559866ms]
Dec 17 01:12:10.473: INFO: Created: latency-svc-4jnkn
Dec 17 01:12:10.480: INFO: Created: latency-svc-d8kcz
Dec 17 01:12:10.486: INFO: Got endpoints: latency-svc-4jnkn [168.125455ms]
Dec 17 01:12:10.489: INFO: Created: latency-svc-4fmxh
Dec 17 01:12:10.489: INFO: Got endpoints: latency-svc-d8kcz [170.045627ms]
Dec 17 01:12:10.497: INFO: Got endpoints: latency-svc-4fmxh [178.193382ms]
Dec 17 01:12:10.501: INFO: Created: latency-svc-2rfqg
Dec 17 01:12:10.508: INFO: Created: latency-svc-49k2s
Dec 17 01:12:10.510: INFO: Got endpoints: latency-svc-2rfqg [191.541375ms]
Dec 17 01:12:10.515: INFO: Got endpoints: latency-svc-49k2s [172.152361ms]
Dec 17 01:12:10.521: INFO: Created: latency-svc-mbxsn
Dec 17 01:12:10.526: INFO: Got endpoints: latency-svc-mbxsn [172.750964ms]
Dec 17 01:12:10.532: INFO: Created: latency-svc-7lsmh
Dec 17 01:12:10.537: INFO: Got endpoints: latency-svc-7lsmh [174.107518ms]
Dec 17 01:12:10.541: INFO: Created: latency-svc-dw946
Dec 17 01:12:10.548: INFO: Created: latency-svc-xqmwp
Dec 17 01:12:10.548: INFO: Got endpoints: latency-svc-dw946 [176.718809ms]
Dec 17 01:12:10.561: INFO: Created: latency-svc-6bspq
Dec 17 01:12:10.565: INFO: Got endpoints: latency-svc-xqmwp [184.916379ms]
Dec 17 01:12:10.575: INFO: Got endpoints: latency-svc-6bspq [179.420059ms]
Dec 17 01:12:10.584: INFO: Created: latency-svc-gmp5f
Dec 17 01:12:10.616: INFO: Got endpoints: latency-svc-gmp5f [213.3948ms]
Dec 17 01:12:10.635: INFO: Created: latency-svc-9n6fr
Dec 17 01:12:10.651: INFO: Got endpoints: latency-svc-9n6fr [229.086391ms]
Dec 17 01:12:10.670: INFO: Created: latency-svc-h886z
Dec 17 01:12:10.689: INFO: Got endpoints: latency-svc-h886z [238.117649ms]
Dec 17 01:12:10.719: INFO: Created: latency-svc-mqvww
Dec 17 01:12:10.719: INFO: Got endpoints: latency-svc-mqvww [260.568521ms]
Dec 17 01:12:10.742: INFO: Created: latency-svc-2bf5h
Dec 17 01:12:10.758: INFO: Got endpoints: latency-svc-2bf5h [287.91483ms]
Dec 17 01:12:10.772: INFO: Created: latency-svc-88r4h
Dec 17 01:12:10.798: INFO: Got endpoints: latency-svc-88r4h [311.924742ms]
Dec 17 01:12:10.807: INFO: Created: latency-svc-jzmsd
Dec 17 01:12:10.831: INFO: Got endpoints: latency-svc-jzmsd [342.246816ms]
Dec 17 01:12:10.898: INFO: Created: latency-svc-t5mtr
Dec 17 01:12:10.903: INFO: Got endpoints: latency-svc-t5mtr [405.363903ms]
Dec 17 01:12:10.914: INFO: Created: latency-svc-b5sqg
Dec 17 01:12:10.920: INFO: Created: latency-svc-kdbwd
Dec 17 01:12:10.922: INFO: Got endpoints: latency-svc-b5sqg [411.550101ms]
Dec 17 01:12:10.952: INFO: Created: latency-svc-fhbm9
Dec 17 01:12:10.955: INFO: Got endpoints: latency-svc-kdbwd [439.415414ms]
Dec 17 01:12:10.960: INFO: Got endpoints: latency-svc-fhbm9 [434.16782ms]
Dec 17 01:12:10.969: INFO: Created: latency-svc-9jkz5
Dec 17 01:12:10.972: INFO: Created: latency-svc-tlx7j
Dec 17 01:12:10.973: INFO: Got endpoints: latency-svc-9jkz5 [435.461195ms]
Dec 17 01:12:10.985: INFO: Got endpoints: latency-svc-tlx7j [437.24619ms]
Dec 17 01:12:10.989: INFO: Created: latency-svc-whzg4
Dec 17 01:12:10.989: INFO: Got endpoints: latency-svc-whzg4 [424.118781ms]
Dec 17 01:12:10.989: INFO: Created: latency-svc-qqwrd
Dec 17 01:12:10.995: INFO: Got endpoints: latency-svc-qqwrd [417.277825ms]
Dec 17 01:12:10.997: INFO: Created: latency-svc-knbcv
Dec 17 01:12:11.005: INFO: Created: latency-svc-nfrbb
Dec 17 01:12:11.005: INFO: Got endpoints: latency-svc-knbcv [389.116844ms]
Dec 17 01:12:11.018: INFO: Created: latency-svc-znwzr
Dec 17 01:12:11.019: INFO: Got endpoints: latency-svc-nfrbb [368.31962ms]
Dec 17 01:12:11.024: INFO: Got endpoints: latency-svc-znwzr [335.328266ms]
Dec 17 01:12:11.031: INFO: Created: latency-svc-67rg4
Dec 17 01:12:11.031: INFO: Got endpoints: latency-svc-67rg4 [311.796531ms]
Dec 17 01:12:11.038: INFO: Created: latency-svc-z79xj
Dec 17 01:12:11.038: INFO: Got endpoints: latency-svc-z79xj [280.498144ms]
Dec 17 01:12:11.046: INFO: Created: latency-svc-wllb5
Dec 17 01:12:11.060: INFO: Got endpoints: latency-svc-wllb5 [261.101953ms]
Dec 17 01:12:11.060: INFO: Created: latency-svc-5s4bv
Dec 17 01:12:11.065: INFO: Got endpoints: latency-svc-5s4bv [233.578989ms]
Dec 17 01:12:11.072: INFO: Created: latency-svc-mdvc6
Dec 17 01:12:11.075: INFO: Created: latency-svc-nwl52
Dec 17 01:12:11.081: INFO: Created: latency-svc-cprnq
Dec 17 01:12:11.087: INFO: Created: latency-svc-rmhgx
Dec 17 01:12:11.093: INFO: Created: latency-svc-sxj7q
Dec 17 01:12:11.099: INFO: Created: latency-svc-xfb65
Dec 17 01:12:11.106: INFO: Created: latency-svc-x5977
Dec 17 01:12:11.113: INFO: Created: latency-svc-4v7w5
Dec 17 01:12:11.115: INFO: Got endpoints: latency-svc-mdvc6 [211.922689ms]
Dec 17 01:12:11.120: INFO: Created: latency-svc-895dz
Dec 17 01:12:11.129: INFO: Created: latency-svc-jwmhj
Dec 17 01:12:11.136: INFO: Created: latency-svc-pzbt7
Dec 17 01:12:11.143: INFO: Created: latency-svc-698fx
Dec 17 01:12:11.153: INFO: Created: latency-svc-kl7qp
Dec 17 01:12:11.164: INFO: Created: latency-svc-t522x
Dec 17 01:12:11.177: INFO: Got endpoints: latency-svc-nwl52 [255.730367ms]
Dec 17 01:12:11.178: INFO: Created: latency-svc-25glt
Dec 17 01:12:11.183: INFO: Created: latency-svc-dxks5
Dec 17 01:12:11.188: INFO: Created: latency-svc-vcdfq
Dec 17 01:12:11.217: INFO: Got endpoints: latency-svc-cprnq [261.932491ms]
Dec 17 01:12:11.234: INFO: Created: latency-svc-9lhw8
Dec 17 01:12:11.264: INFO: Got endpoints: latency-svc-rmhgx [303.86787ms]
Dec 17 01:12:11.284: INFO: Created: latency-svc-shkmg
Dec 17 01:12:11.313: INFO: Got endpoints: latency-svc-sxj7q [340.441804ms]
Dec 17 01:12:11.325: INFO: Created: latency-svc-zcs8n
Dec 17 01:12:11.364: INFO: Got endpoints: latency-svc-xfb65 [375.909836ms]
Dec 17 01:12:11.372: INFO: Created: latency-svc-x5mbz
Dec 17 01:12:11.412: INFO: Got endpoints: latency-svc-x5977 [422.094786ms]
Dec 17 01:12:11.419: INFO: Created: latency-svc-wlvhv
Dec 17 01:12:11.462: INFO: Got endpoints: latency-svc-4v7w5 [466.373066ms]
Dec 17 01:12:11.471: INFO: Created: latency-svc-8pjnc
Dec 17 01:12:11.511: INFO: Got endpoints: latency-svc-895dz [505.626748ms]
Dec 17 01:12:11.526: INFO: Created: latency-svc-nnb44
Dec 17 01:12:11.562: INFO: Got endpoints: latency-svc-jwmhj [540.416637ms]
Dec 17 01:12:11.571: INFO: Created: latency-svc-99fd6
Dec 17 01:12:11.611: INFO: Got endpoints: latency-svc-pzbt7 [579.665016ms]
Dec 17 01:12:11.621: INFO: Created: latency-svc-2cds2
Dec 17 01:12:11.663: INFO: Got endpoints: latency-svc-698fx [638.459231ms]
Dec 17 01:12:11.673: INFO: Created: latency-svc-sbr5f
Dec 17 01:12:11.711: INFO: Got endpoints: latency-svc-kl7qp [672.987808ms]
Dec 17 01:12:11.720: INFO: Created: latency-svc-5fc58
Dec 17 01:12:11.763: INFO: Got endpoints: latency-svc-t522x [703.072012ms]
Dec 17 01:12:11.776: INFO: Created: latency-svc-88m66
Dec 17 01:12:11.813: INFO: Got endpoints: latency-svc-25glt [747.702436ms]
Dec 17 01:12:11.822: INFO: Created: latency-svc-jnczc
Dec 17 01:12:11.861: INFO: Got endpoints: latency-svc-dxks5 [746.299082ms]
Dec 17 01:12:11.870: INFO: Created: latency-svc-f6kgb
Dec 17 01:12:11.913: INFO: Got endpoints: latency-svc-vcdfq [735.112384ms]
Dec 17 01:12:11.921: INFO: Created: latency-svc-j6dp2
Dec 17 01:12:11.962: INFO: Got endpoints: latency-svc-9lhw8 [737.548734ms]
Dec 17 01:12:11.970: INFO: Created: latency-svc-2fh82
Dec 17 01:12:12.013: INFO: Got endpoints: latency-svc-shkmg [748.638683ms]
Dec 17 01:12:12.023: INFO: Created: latency-svc-778r6
Dec 17 01:12:12.062: INFO: Got endpoints: latency-svc-zcs8n [748.930977ms]
Dec 17 01:12:12.073: INFO: Created: latency-svc-z8gr4
Dec 17 01:12:12.111: INFO: Got endpoints: latency-svc-x5mbz [746.625268ms]
Dec 17 01:12:12.126: INFO: Created: latency-svc-2nvhd
Dec 17 01:12:12.163: INFO: Got endpoints: latency-svc-wlvhv [751.078615ms]
Dec 17 01:12:12.170: INFO: Created: latency-svc-xj2tv
Dec 17 01:12:12.216: INFO: Got endpoints: latency-svc-8pjnc [753.403054ms]
Dec 17 01:12:12.224: INFO: Created: latency-svc-p2hkj
Dec 17 01:12:12.263: INFO: Got endpoints: latency-svc-nnb44 [751.245328ms]
Dec 17 01:12:12.273: INFO: Created: latency-svc-ppzdg
Dec 17 01:12:12.313: INFO: Got endpoints: latency-svc-99fd6 [750.144793ms]
Dec 17 01:12:12.321: INFO: Created: latency-svc-7pd57
Dec 17 01:12:12.362: INFO: Got endpoints: latency-svc-2cds2 [750.693749ms]
Dec 17 01:12:12.371: INFO: Created: latency-svc-kz5qv
Dec 17 01:12:12.411: INFO: Got endpoints: latency-svc-sbr5f [748.216218ms]
Dec 17 01:12:12.420: INFO: Created: latency-svc-bxmgz
Dec 17 01:12:12.462: INFO: Got endpoints: latency-svc-5fc58 [749.970728ms]
Dec 17 01:12:12.470: INFO: Created: latency-svc-mmlb8
Dec 17 01:12:12.512: INFO: Got endpoints: latency-svc-88m66 [749.041924ms]
Dec 17 01:12:12.521: INFO: Created: latency-svc-zfkr4
Dec 17 01:12:12.573: INFO: Got endpoints: latency-svc-jnczc [760.1532ms]
Dec 17 01:12:12.582: INFO: Created: latency-svc-6slb6
Dec 17 01:12:12.615: INFO: Got endpoints: latency-svc-f6kgb [753.21077ms]
Dec 17 01:12:12.626: INFO: Created: latency-svc-fwww6
Dec 17 01:12:12.663: INFO: Got endpoints: latency-svc-j6dp2 [750.197665ms]
Dec 17 01:12:12.673: INFO: Created: latency-svc-pgvrw
Dec 17 01:12:12.712: INFO: Got endpoints: latency-svc-2fh82 [749.416708ms]
Dec 17 01:12:12.737: INFO: Created: latency-svc-xrx5h
Dec 17 01:12:12.763: INFO: Got endpoints: latency-svc-778r6 [749.222833ms]
Dec 17 01:12:12.773: INFO: Created: latency-svc-dl75n
Dec 17 01:12:12.812: INFO: Got endpoints: latency-svc-z8gr4 [748.975414ms]
Dec 17 01:12:12.820: INFO: Created: latency-svc-zjh92
Dec 17 01:12:12.862: INFO: Got endpoints: latency-svc-2nvhd [749.714444ms]
Dec 17 01:12:12.871: INFO: Created: latency-svc-lkk7m
Dec 17 01:12:12.916: INFO: Got endpoints: latency-svc-xj2tv [752.642122ms]
Dec 17 01:12:12.926: INFO: Created: latency-svc-nb7z4
Dec 17 01:12:12.962: INFO: Got endpoints: latency-svc-p2hkj [745.635984ms]
Dec 17 01:12:12.973: INFO: Created: latency-svc-n5t6z
Dec 17 01:12:13.012: INFO: Got endpoints: latency-svc-ppzdg [748.872082ms]
Dec 17 01:12:13.019: INFO: Created: latency-svc-tnp8m
Dec 17 01:12:13.063: INFO: Got endpoints: latency-svc-7pd57 [750.272354ms]
Dec 17 01:12:13.085: INFO: Created: latency-svc-mp542
Dec 17 01:12:13.118: INFO: Got endpoints: latency-svc-kz5qv [755.690266ms]
Dec 17 01:12:13.139: INFO: Created: latency-svc-chd22
Dec 17 01:12:13.162: INFO: Got endpoints: latency-svc-bxmgz [750.279996ms]
Dec 17 01:12:13.177: INFO: Created: latency-svc-jmxzk
Dec 17 01:12:13.213: INFO: Got endpoints: latency-svc-mmlb8 [750.606935ms]
Dec 17 01:12:13.225: INFO: Created: latency-svc-rwm8s
Dec 17 01:12:13.263: INFO: Got endpoints: latency-svc-zfkr4 [750.613203ms]
Dec 17 01:12:13.275: INFO: Created: latency-svc-cl82f
Dec 17 01:12:13.313: INFO: Got endpoints: latency-svc-6slb6 [739.912998ms]
Dec 17 01:12:13.324: INFO: Created: latency-svc-w7sjl
Dec 17 01:12:13.364: INFO: Got endpoints: latency-svc-fwww6 [749.851142ms]
Dec 17 01:12:13.374: INFO: Created: latency-svc-j22mf
Dec 17 01:12:13.412: INFO: Got endpoints: latency-svc-pgvrw [748.381122ms]
Dec 17 01:12:13.422: INFO: Created: latency-svc-b77t9
Dec 17 01:12:13.463: INFO: Got endpoints: latency-svc-xrx5h [750.81332ms]
Dec 17 01:12:13.473: INFO: Created: latency-svc-2rjnj
Dec 17 01:12:13.511: INFO: Got endpoints: latency-svc-dl75n [748.5009ms]
Dec 17 01:12:13.522: INFO: Created: latency-svc-8rswc
Dec 17 01:12:13.562: INFO: Got endpoints: latency-svc-zjh92 [750.3233ms]
Dec 17 01:12:13.579: INFO: Created: latency-svc-zmr6d
Dec 17 01:12:13.612: INFO: Got endpoints: latency-svc-lkk7m [749.925935ms]
Dec 17 01:12:13.620: INFO: Created: latency-svc-d6zlx
Dec 17 01:12:13.663: INFO: Got endpoints: latency-svc-nb7z4 [747.097221ms]
Dec 17 01:12:13.672: INFO: Created: latency-svc-6xhsb
Dec 17 01:12:13.718: INFO: Got endpoints: latency-svc-n5t6z [755.197243ms]
Dec 17 01:12:13.739: INFO: Created: latency-svc-lmv9s
Dec 17 01:12:13.764: INFO: Got endpoints: latency-svc-tnp8m [752.030365ms]
Dec 17 01:12:13.776: INFO: Created: latency-svc-gh47k
Dec 17 01:12:13.812: INFO: Got endpoints: latency-svc-mp542 [748.231894ms]
Dec 17 01:12:13.821: INFO: Created: latency-svc-zgltc
Dec 17 01:12:13.863: INFO: Got endpoints: latency-svc-chd22 [745.025923ms]
Dec 17 01:12:13.872: INFO: Created: latency-svc-fskw8
Dec 17 01:12:13.915: INFO: Got endpoints: latency-svc-jmxzk [753.30302ms]
Dec 17 01:12:13.926: INFO: Created: latency-svc-mqmkt
Dec 17 01:12:13.962: INFO: Got endpoints: latency-svc-rwm8s [749.414341ms]
Dec 17 01:12:13.974: INFO: Created: latency-svc-pzphj
Dec 17 01:12:14.013: INFO: Got endpoints: latency-svc-cl82f [749.36714ms]
Dec 17 01:12:14.026: INFO: Created: latency-svc-8m54t
Dec 17 01:12:14.063: INFO: Got endpoints: latency-svc-w7sjl [749.221877ms]
Dec 17 01:12:14.073: INFO: Created: latency-svc-kzgvz
Dec 17 01:12:14.112: INFO: Got endpoints: latency-svc-j22mf [747.577059ms]
Dec 17 01:12:14.125: INFO: Created: latency-svc-pflkr
Dec 17 01:12:14.164: INFO: Got endpoints: latency-svc-b77t9 [752.607523ms]
Dec 17 01:12:14.174: INFO: Created: latency-svc-gn5kh
Dec 17 01:12:14.222: INFO: Got endpoints: latency-svc-2rjnj [759.129534ms]
Dec 17 01:12:14.246: INFO: Created: latency-svc-p57xz
Dec 17 01:12:14.261: INFO: Got endpoints: latency-svc-8rswc [749.537425ms]
Dec 17 01:12:14.290: INFO: Created: latency-svc-g6wnc
Dec 17 01:12:14.313: INFO: Got endpoints: latency-svc-zmr6d [750.958535ms]
Dec 17 01:12:14.323: INFO: Created: latency-svc-9zzb9
Dec 17 01:12:14.362: INFO: Got endpoints: latency-svc-d6zlx [749.892792ms]
Dec 17 01:12:14.376: INFO: Created: latency-svc-klw89
Dec 17 01:12:14.412: INFO: Got endpoints: latency-svc-6xhsb [748.320951ms]
Dec 17 01:12:14.422: INFO: Created: latency-svc-x5kl2
Dec 17 01:12:14.463: INFO: Got endpoints: latency-svc-lmv9s [744.551915ms]
Dec 17 01:12:14.470: INFO: Created: latency-svc-t8t9g
Dec 17 01:12:14.514: INFO: Got endpoints: latency-svc-gh47k [748.00416ms]
Dec 17 01:12:14.527: INFO: Created: latency-svc-4wjw5
Dec 17 01:12:14.572: INFO: Got endpoints: latency-svc-zgltc [759.834728ms]
Dec 17 01:12:14.580: INFO: Created: latency-svc-8vmtt
Dec 17 01:12:14.612: INFO: Got endpoints: latency-svc-fskw8 [748.10312ms]
Dec 17 01:12:14.621: INFO: Created: latency-svc-ft8hk
Dec 17 01:12:14.665: INFO: Got endpoints: latency-svc-mqmkt [749.589752ms]
Dec 17 01:12:14.675: INFO: Created: latency-svc-j9gtq
Dec 17 01:12:14.714: INFO: Got endpoints: latency-svc-pzphj [751.393407ms]
Dec 17 01:12:14.727: INFO: Created: latency-svc-tpc96
Dec 17 01:12:14.766: INFO: Got endpoints: latency-svc-8m54t [752.998105ms]
Dec 17 01:12:14.783: INFO: Created: latency-svc-dvhvg
Dec 17 01:12:14.814: INFO: Got endpoints: latency-svc-kzgvz [751.239081ms]
Dec 17 01:12:14.832: INFO: Created: latency-svc-dqn5p
Dec 17 01:12:14.862: INFO: Got endpoints: latency-svc-pflkr [749.704824ms]
Dec 17 01:12:14.872: INFO: Created: latency-svc-sxxn4
Dec 17 01:12:14.916: INFO: Got endpoints: latency-svc-gn5kh [751.50012ms]
Dec 17 01:12:14.942: INFO: Created: latency-svc-xkb74
Dec 17 01:12:14.965: INFO: Got endpoints: latency-svc-p57xz [742.975107ms]
Dec 17 01:12:14.973: INFO: Created: latency-svc-vszfr
Dec 17 01:12:15.013: INFO: Got endpoints: latency-svc-g6wnc [750.947321ms]
Dec 17 01:12:15.024: INFO: Created: latency-svc-cwg4p
Dec 17 01:12:15.062: INFO: Got endpoints: latency-svc-9zzb9 [749.137406ms]
Dec 17 01:12:15.071: INFO: Created: latency-svc-9djtb
Dec 17 01:12:15.117: INFO: Got endpoints: latency-svc-klw89 [754.467347ms]
Dec 17 01:12:15.126: INFO: Created: latency-svc-g7fww
Dec 17 01:12:15.163: INFO: Got endpoints: latency-svc-x5kl2 [751.0385ms]
Dec 17 01:12:15.173: INFO: Created: latency-svc-bd8sn
Dec 17 01:12:15.215: INFO: Got endpoints: latency-svc-t8t9g [752.558271ms]
Dec 17 01:12:15.226: INFO: Created: latency-svc-6zr44
Dec 17 01:12:15.263: INFO: Got endpoints: latency-svc-4wjw5 [748.528592ms]
Dec 17 01:12:15.275: INFO: Created: latency-svc-6gnfp
Dec 17 01:12:15.313: INFO: Got endpoints: latency-svc-8vmtt [740.768737ms]
Dec 17 01:12:15.324: INFO: Created: latency-svc-fx9hc
Dec 17 01:12:15.366: INFO: Got endpoints: latency-svc-ft8hk [754.154764ms]
Dec 17 01:12:15.389: INFO: Created: latency-svc-8d96c
Dec 17 01:12:15.413: INFO: Got endpoints: latency-svc-j9gtq [748.091595ms]
Dec 17 01:12:15.424: INFO: Created: latency-svc-kpgl5
Dec 17 01:12:15.463: INFO: Got endpoints: latency-svc-tpc96 [748.247678ms]
Dec 17 01:12:15.471: INFO: Created: latency-svc-7jxl9
Dec 17 01:12:15.513: INFO: Got endpoints: latency-svc-dvhvg [746.650016ms]
Dec 17 01:12:15.525: INFO: Created: latency-svc-gcmlw
Dec 17 01:12:15.562: INFO: Got endpoints: latency-svc-dqn5p [747.688179ms]
Dec 17 01:12:15.573: INFO: Created: latency-svc-s2v7n
Dec 17 01:12:15.616: INFO: Got endpoints: latency-svc-sxxn4 [753.148751ms]
Dec 17 01:12:15.623: INFO: Created: latency-svc-7v7pt
Dec 17 01:12:15.666: INFO: Got endpoints: latency-svc-xkb74 [747.931766ms]
Dec 17 01:12:15.679: INFO: Created: latency-svc-c54rz
Dec 17 01:12:15.713: INFO: Got endpoints: latency-svc-vszfr [747.752715ms]
Dec 17 01:12:15.722: INFO: Created: latency-svc-6rsjb
Dec 17 01:12:15.766: INFO: Got endpoints: latency-svc-cwg4p [753.331742ms]
Dec 17 01:12:15.795: INFO: Created: latency-svc-kkmt6
Dec 17 01:12:15.813: INFO: Got endpoints: latency-svc-9djtb [750.694788ms]
Dec 17 01:12:15.823: INFO: Created: latency-svc-28tfh
Dec 17 01:12:15.862: INFO: Got endpoints: latency-svc-g7fww [744.734089ms]
Dec 17 01:12:15.872: INFO: Created: latency-svc-q9lwl
Dec 17 01:12:15.918: INFO: Got endpoints: latency-svc-bd8sn [754.845747ms]
Dec 17 01:12:15.942: INFO: Created: latency-svc-lhxtn
Dec 17 01:12:15.966: INFO: Got endpoints: latency-svc-6zr44 [750.661315ms]
Dec 17 01:12:15.974: INFO: Created: latency-svc-8j2gx
Dec 17 01:12:16.014: INFO: Got endpoints: latency-svc-6gnfp [751.280835ms]
Dec 17 01:12:16.025: INFO: Created: latency-svc-pdvn2
Dec 17 01:12:16.063: INFO: Got endpoints: latency-svc-fx9hc [749.67536ms]
Dec 17 01:12:16.072: INFO: Created: latency-svc-5skw5
Dec 17 01:12:16.112: INFO: Got endpoints: latency-svc-8d96c [745.585863ms]
Dec 17 01:12:16.122: INFO: Created: latency-svc-wxn5c
Dec 17 01:12:16.163: INFO: Got endpoints: latency-svc-kpgl5 [749.148028ms]
Dec 17 01:12:16.176: INFO: Created: latency-svc-vj5x8
Dec 17 01:12:16.213: INFO: Got endpoints: latency-svc-7jxl9 [749.995689ms]
Dec 17 01:12:16.229: INFO: Created: latency-svc-bhnz2
Dec 17 01:12:16.262: INFO: Got endpoints: latency-svc-gcmlw [749.057991ms]
Dec 17 01:12:16.272: INFO: Created: latency-svc-k56z9
Dec 17 01:12:16.315: INFO: Got endpoints: latency-svc-s2v7n [752.796074ms]
Dec 17 01:12:16.350: INFO: Created: latency-svc-xlwnq
Dec 17 01:12:16.368: INFO: Got endpoints: latency-svc-7v7pt [752.215471ms]
Dec 17 01:12:16.381: INFO: Created: latency-svc-mm4jk
Dec 17 01:12:16.413: INFO: Got endpoints: latency-svc-c54rz [745.785347ms]
Dec 17 01:12:16.421: INFO: Created: latency-svc-pb2tk
Dec 17 01:12:16.463: INFO: Got endpoints: latency-svc-6rsjb [750.035799ms]
Dec 17 01:12:16.474: INFO: Created: latency-svc-2r6fd
Dec 17 01:12:16.515: INFO: Got endpoints: latency-svc-kkmt6 [748.380646ms]
Dec 17 01:12:16.531: INFO: Created: latency-svc-n7vjb
Dec 17 01:12:16.569: INFO: Got endpoints: latency-svc-28tfh [755.379808ms]
Dec 17 01:12:16.580: INFO: Created: latency-svc-g6wwv
Dec 17 01:12:16.612: INFO: Got endpoints: latency-svc-q9lwl [750.27238ms]
Dec 17 01:12:16.625: INFO: Created: latency-svc-lhqm7
Dec 17 01:12:16.670: INFO: Got endpoints: latency-svc-lhxtn [751.915444ms]
Dec 17 01:12:16.681: INFO: Created: latency-svc-9fzqg
Dec 17 01:12:16.712: INFO: Got endpoints: latency-svc-8j2gx [745.90651ms]
Dec 17 01:12:16.722: INFO: Created: latency-svc-crmmg
Dec 17 01:12:16.778: INFO: Got endpoints: latency-svc-pdvn2 [763.921583ms]
Dec 17 01:12:16.789: INFO: Created: latency-svc-fzvv2
Dec 17 01:12:16.812: INFO: Got endpoints: latency-svc-5skw5 [748.851972ms]
Dec 17 01:12:16.820: INFO: Created: latency-svc-rqn2f
Dec 17 01:12:16.864: INFO: Got endpoints: latency-svc-wxn5c [752.501879ms]
Dec 17 01:12:16.874: INFO: Created: latency-svc-fvtjd
Dec 17 01:12:16.926: INFO: Got endpoints: latency-svc-vj5x8 [763.170968ms]
Dec 17 01:12:16.939: INFO: Created: latency-svc-2tb79
Dec 17 01:12:16.968: INFO: Got endpoints: latency-svc-bhnz2 [754.69665ms]
Dec 17 01:12:17.002: INFO: Created: latency-svc-gf7x4
Dec 17 01:12:17.016: INFO: Got endpoints: latency-svc-k56z9 [753.547354ms]
Dec 17 01:12:17.034: INFO: Created: latency-svc-hfm2l
Dec 17 01:12:17.064: INFO: Got endpoints: latency-svc-xlwnq [747.948173ms]
Dec 17 01:12:17.077: INFO: Created: latency-svc-f86sh
Dec 17 01:12:17.117: INFO: Got endpoints: latency-svc-mm4jk [748.547454ms]
Dec 17 01:12:17.132: INFO: Created: latency-svc-x2l5z
Dec 17 01:12:17.165: INFO: Got endpoints: latency-svc-pb2tk [751.998192ms]
Dec 17 01:12:17.184: INFO: Created: latency-svc-m9hd6
Dec 17 01:12:17.213: INFO: Got endpoints: latency-svc-2r6fd [749.444928ms]
Dec 17 01:12:17.226: INFO: Created: latency-svc-hjh79
Dec 17 01:12:17.269: INFO: Got endpoints: latency-svc-n7vjb [753.897871ms]
Dec 17 01:12:17.287: INFO: Created: latency-svc-27v4t
Dec 17 01:12:17.314: INFO: Got endpoints: latency-svc-g6wwv [745.115912ms]
Dec 17 01:12:17.324: INFO: Created: latency-svc-fgxc5
Dec 17 01:12:17.385: INFO: Got endpoints: latency-svc-lhqm7 [772.751443ms]
Dec 17 01:12:17.395: INFO: Created: latency-svc-7klbg
Dec 17 01:12:17.412: INFO: Got endpoints: latency-svc-9fzqg [741.330277ms]
Dec 17 01:12:17.422: INFO: Created: latency-svc-44ng4
Dec 17 01:12:17.462: INFO: Got endpoints: latency-svc-crmmg [749.693581ms]
Dec 17 01:12:17.492: INFO: Created: latency-svc-64ns7
Dec 17 01:12:17.518: INFO: Got endpoints: latency-svc-fzvv2 [739.034977ms]
Dec 17 01:12:17.526: INFO: Created: latency-svc-jwjwn
Dec 17 01:12:17.564: INFO: Got endpoints: latency-svc-rqn2f [751.481675ms]
Dec 17 01:12:17.645: INFO: Got endpoints: latency-svc-fvtjd [780.415407ms]
Dec 17 01:12:17.652: INFO: Created: latency-svc-dd7n5
Dec 17 01:12:17.667: INFO: Got endpoints: latency-svc-2tb79 [740.625882ms]
Dec 17 01:12:17.673: INFO: Created: latency-svc-zlx4t
Dec 17 01:12:17.689: INFO: Created: latency-svc-ttzzr
Dec 17 01:12:17.713: INFO: Got endpoints: latency-svc-gf7x4 [744.843978ms]
Dec 17 01:12:17.734: INFO: Created: latency-svc-w97mr
Dec 17 01:12:17.764: INFO: Got endpoints: latency-svc-hfm2l [748.562381ms]
Dec 17 01:12:17.779: INFO: Created: latency-svc-zqh2r
Dec 17 01:12:17.818: INFO: Got endpoints: latency-svc-f86sh [754.345813ms]
Dec 17 01:12:17.840: INFO: Created: latency-svc-s6z6f
Dec 17 01:12:17.866: INFO: Got endpoints: latency-svc-x2l5z [748.585632ms]
Dec 17 01:12:17.881: INFO: Created: latency-svc-zxnn6
Dec 17 01:12:17.912: INFO: Got endpoints: latency-svc-m9hd6 [747.326099ms]
Dec 17 01:12:17.930: INFO: Created: latency-svc-zxktd
Dec 17 01:12:17.963: INFO: Got endpoints: latency-svc-hjh79 [748.545708ms]
Dec 17 01:12:17.972: INFO: Created: latency-svc-2nxsl
Dec 17 01:12:18.013: INFO: Got endpoints: latency-svc-27v4t [744.535686ms]
Dec 17 01:12:18.028: INFO: Created: latency-svc-sd44v
Dec 17 01:12:18.064: INFO: Got endpoints: latency-svc-fgxc5 [749.450074ms]
Dec 17 01:12:18.076: INFO: Created: latency-svc-69gkc
Dec 17 01:12:18.112: INFO: Got endpoints: latency-svc-7klbg [726.548149ms]
Dec 17 01:12:18.123: INFO: Created: latency-svc-rl44r
Dec 17 01:12:18.162: INFO: Got endpoints: latency-svc-44ng4 [749.80676ms]
Dec 17 01:12:18.217: INFO: Got endpoints: latency-svc-64ns7 [754.49983ms]
Dec 17 01:12:18.262: INFO: Got endpoints: latency-svc-jwjwn [744.111783ms]
Dec 17 01:12:18.313: INFO: Got endpoints: latency-svc-dd7n5 [749.107692ms]
Dec 17 01:12:18.362: INFO: Got endpoints: latency-svc-zlx4t [716.862224ms]
Dec 17 01:12:18.411: INFO: Got endpoints: latency-svc-ttzzr [744.152932ms]
Dec 17 01:12:18.466: INFO: Got endpoints: latency-svc-w97mr [752.534468ms]
Dec 17 01:12:18.512: INFO: Got endpoints: latency-svc-zqh2r [747.145993ms]
Dec 17 01:12:18.562: INFO: Got endpoints: latency-svc-s6z6f [744.165313ms]
Dec 17 01:12:18.613: INFO: Got endpoints: latency-svc-zxnn6 [746.739336ms]
Dec 17 01:12:18.662: INFO: Got endpoints: latency-svc-zxktd [749.788154ms]
Dec 17 01:12:18.711: INFO: Got endpoints: latency-svc-2nxsl [748.566736ms]
Dec 17 01:12:18.761: INFO: Got endpoints: latency-svc-sd44v [747.753043ms]
Dec 17 01:12:18.814: INFO: Got endpoints: latency-svc-69gkc [748.908386ms]
Dec 17 01:12:18.862: INFO: Got endpoints: latency-svc-rl44r [749.393065ms]
Dec 17 01:12:18.862: INFO: Latencies: [26.893763ms 37.252456ms 37.956191ms 46.385241ms 54.420322ms 63.209058ms 78.072941ms 85.109742ms 102.558503ms 103.986236ms 132.532226ms 151.559866ms 168.125455ms 170.045627ms 172.152361ms 172.750964ms 174.107518ms 176.718809ms 178.193382ms 179.420059ms 184.916379ms 191.541375ms 211.922689ms 213.3948ms 229.086391ms 233.578989ms 238.117649ms 255.730367ms 260.568521ms 261.101953ms 261.932491ms 280.498144ms 287.91483ms 303.86787ms 311.796531ms 311.924742ms 335.328266ms 340.441804ms 342.246816ms 368.31962ms 375.909836ms 389.116844ms 405.363903ms 411.550101ms 417.277825ms 422.094786ms 424.118781ms 434.16782ms 435.461195ms 437.24619ms 439.415414ms 466.373066ms 505.626748ms 540.416637ms 579.665016ms 638.459231ms 672.987808ms 703.072012ms 716.862224ms 726.548149ms 735.112384ms 737.548734ms 739.034977ms 739.912998ms 740.625882ms 740.768737ms 741.330277ms 742.975107ms 744.111783ms 744.152932ms 744.165313ms 744.535686ms 744.551915ms 744.734089ms 744.843978ms 745.025923ms 745.115912ms 745.585863ms 745.635984ms 745.785347ms 745.90651ms 746.299082ms 746.625268ms 746.650016ms 746.739336ms 747.097221ms 747.145993ms 747.326099ms 747.577059ms 747.688179ms 747.702436ms 747.752715ms 747.753043ms 747.931766ms 747.948173ms 748.00416ms 748.091595ms 748.10312ms 748.216218ms 748.231894ms 748.247678ms 748.320951ms 748.380646ms 748.381122ms 748.5009ms 748.528592ms 748.545708ms 748.547454ms 748.562381ms 748.566736ms 748.585632ms 748.638683ms 748.851972ms 748.872082ms 748.908386ms 748.930977ms 748.975414ms 749.041924ms 749.057991ms 749.107692ms 749.137406ms 749.148028ms 749.221877ms 749.222833ms 749.36714ms 749.393065ms 749.414341ms 749.416708ms 749.444928ms 749.450074ms 749.537425ms 749.589752ms 749.67536ms 749.693581ms 749.704824ms 749.714444ms 749.788154ms 749.80676ms 749.851142ms 749.892792ms 749.925935ms 749.970728ms 749.995689ms 750.035799ms 750.144793ms 750.197665ms 750.272354ms 750.27238ms 750.279996ms 750.3233ms 750.606935ms 750.613203ms 750.661315ms 750.693749ms 750.694788ms 750.81332ms 750.947321ms 750.958535ms 751.0385ms 751.078615ms 751.239081ms 751.245328ms 751.280835ms 751.393407ms 751.481675ms 751.50012ms 751.915444ms 751.998192ms 752.030365ms 752.215471ms 752.501879ms 752.534468ms 752.558271ms 752.607523ms 752.642122ms 752.796074ms 752.998105ms 753.148751ms 753.21077ms 753.30302ms 753.331742ms 753.403054ms 753.547354ms 753.897871ms 754.154764ms 754.345813ms 754.467347ms 754.49983ms 754.69665ms 754.845747ms 755.197243ms 755.379808ms 755.690266ms 759.129534ms 759.834728ms 760.1532ms 763.170968ms 763.921583ms 772.751443ms 780.415407ms]
Dec 17 01:12:18.863: INFO: 50 %ile: 748.247678ms
Dec 17 01:12:18.863: INFO: 90 %ile: 753.331742ms
Dec 17 01:12:18.863: INFO: 99 %ile: 772.751443ms
Dec 17 01:12:18.863: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:12:18.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-3199" for this suite.
Dec 17 01:12:32.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:12:32.925: INFO: namespace svc-latency-3199 deletion completed in 14.058655634s

â€¢ [SLOW TEST:24.799 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:12:32.925: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 17 01:12:32.954: INFO: Waiting up to 5m0s for pod "pod-baf9ec20-c12e-46ca-8cf3-0b5f3450a04a" in namespace "emptydir-9626" to be "success or failure"
Dec 17 01:12:32.957: INFO: Pod "pod-baf9ec20-c12e-46ca-8cf3-0b5f3450a04a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.619787ms
Dec 17 01:12:34.959: INFO: Pod "pod-baf9ec20-c12e-46ca-8cf3-0b5f3450a04a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004826851s
STEP: Saw pod success
Dec 17 01:12:34.959: INFO: Pod "pod-baf9ec20-c12e-46ca-8cf3-0b5f3450a04a" satisfied condition "success or failure"
Dec 17 01:12:34.961: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-baf9ec20-c12e-46ca-8cf3-0b5f3450a04a container test-container: <nil>
STEP: delete the pod
Dec 17 01:12:34.978: INFO: Waiting for pod pod-baf9ec20-c12e-46ca-8cf3-0b5f3450a04a to disappear
Dec 17 01:12:34.980: INFO: Pod pod-baf9ec20-c12e-46ca-8cf3-0b5f3450a04a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:12:34.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9626" for this suite.
Dec 17 01:12:40.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:12:41.049: INFO: namespace emptydir-9626 deletion completed in 6.066848778s

â€¢ [SLOW TEST:8.124 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:12:41.050: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:12:41.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4924" for this suite.
Dec 17 01:12:47.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:12:47.136: INFO: namespace custom-resource-definition-4924 deletion completed in 6.06085025s

â€¢ [SLOW TEST:6.086 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:12:47.136: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 17 01:12:49.678: INFO: Successfully updated pod "labelsupdateb564d1b6-d477-49ef-81d7-bc1f8ec6a03f"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:12:53.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2563" for this suite.
Dec 17 01:13:13.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:13:13.781: INFO: namespace downward-api-2563 deletion completed in 20.080317127s

â€¢ [SLOW TEST:26.645 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:13:13.781: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3184.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-3184.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3184.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3184.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-3184.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-3184.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-3184.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-3184.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3184.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3184.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-3184.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3184.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-3184.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-3184.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-3184.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-3184.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-3184.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3184.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 17 01:13:15.830: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3184.svc.cluster.local from pod dns-3184/dns-test-cb882e31-53fb-428c-942a-d3fc03707527: the server could not find the requested resource (get pods dns-test-cb882e31-53fb-428c-942a-d3fc03707527)
Dec 17 01:13:15.832: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3184.svc.cluster.local from pod dns-3184/dns-test-cb882e31-53fb-428c-942a-d3fc03707527: the server could not find the requested resource (get pods dns-test-cb882e31-53fb-428c-942a-d3fc03707527)
Dec 17 01:13:15.835: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-3184.svc.cluster.local from pod dns-3184/dns-test-cb882e31-53fb-428c-942a-d3fc03707527: the server could not find the requested resource (get pods dns-test-cb882e31-53fb-428c-942a-d3fc03707527)
Dec 17 01:13:15.844: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3184.svc.cluster.local from pod dns-3184/dns-test-cb882e31-53fb-428c-942a-d3fc03707527: the server could not find the requested resource (get pods dns-test-cb882e31-53fb-428c-942a-d3fc03707527)
Dec 17 01:13:15.846: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3184.svc.cluster.local from pod dns-3184/dns-test-cb882e31-53fb-428c-942a-d3fc03707527: the server could not find the requested resource (get pods dns-test-cb882e31-53fb-428c-942a-d3fc03707527)
Dec 17 01:13:15.854: INFO: Lookups using dns-3184/dns-test-cb882e31-53fb-428c-942a-d3fc03707527 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3184.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3184.svc.cluster.local wheezy_udp@dns-test-service-2.dns-3184.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3184.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3184.svc.cluster.local]

Dec 17 01:13:20.893: INFO: DNS probes using dns-3184/dns-test-cb882e31-53fb-428c-942a-d3fc03707527 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:13:20.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3184" for this suite.
Dec 17 01:13:26.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:13:26.984: INFO: namespace dns-3184 deletion completed in 6.063323701s

â€¢ [SLOW TEST:13.203 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:13:26.985: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-9qmw
STEP: Creating a pod to test atomic-volume-subpath
Dec 17 01:13:27.010: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-9qmw" in namespace "subpath-2745" to be "success or failure"
Dec 17 01:13:27.014: INFO: Pod "pod-subpath-test-secret-9qmw": Phase="Pending", Reason="", readiness=false. Elapsed: 3.366293ms
Dec 17 01:13:29.016: INFO: Pod "pod-subpath-test-secret-9qmw": Phase="Running", Reason="", readiness=true. Elapsed: 2.005760815s
Dec 17 01:13:31.019: INFO: Pod "pod-subpath-test-secret-9qmw": Phase="Running", Reason="", readiness=true. Elapsed: 4.008207914s
Dec 17 01:13:33.021: INFO: Pod "pod-subpath-test-secret-9qmw": Phase="Running", Reason="", readiness=true. Elapsed: 6.011001536s
Dec 17 01:13:35.024: INFO: Pod "pod-subpath-test-secret-9qmw": Phase="Running", Reason="", readiness=true. Elapsed: 8.013762342s
Dec 17 01:13:37.026: INFO: Pod "pod-subpath-test-secret-9qmw": Phase="Running", Reason="", readiness=true. Elapsed: 10.015997487s
Dec 17 01:13:39.029: INFO: Pod "pod-subpath-test-secret-9qmw": Phase="Running", Reason="", readiness=true. Elapsed: 12.018801042s
Dec 17 01:13:41.031: INFO: Pod "pod-subpath-test-secret-9qmw": Phase="Running", Reason="", readiness=true. Elapsed: 14.020935796s
Dec 17 01:13:43.034: INFO: Pod "pod-subpath-test-secret-9qmw": Phase="Running", Reason="", readiness=true. Elapsed: 16.023753417s
Dec 17 01:13:45.037: INFO: Pod "pod-subpath-test-secret-9qmw": Phase="Running", Reason="", readiness=true. Elapsed: 18.02677021s
Dec 17 01:13:47.039: INFO: Pod "pod-subpath-test-secret-9qmw": Phase="Running", Reason="", readiness=true. Elapsed: 20.029007514s
Dec 17 01:13:49.042: INFO: Pod "pod-subpath-test-secret-9qmw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.031201968s
STEP: Saw pod success
Dec 17 01:13:49.042: INFO: Pod "pod-subpath-test-secret-9qmw" satisfied condition "success or failure"
Dec 17 01:13:49.043: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-subpath-test-secret-9qmw container test-container-subpath-secret-9qmw: <nil>
STEP: delete the pod
Dec 17 01:13:49.055: INFO: Waiting for pod pod-subpath-test-secret-9qmw to disappear
Dec 17 01:13:49.057: INFO: Pod pod-subpath-test-secret-9qmw no longer exists
STEP: Deleting pod pod-subpath-test-secret-9qmw
Dec 17 01:13:49.057: INFO: Deleting pod "pod-subpath-test-secret-9qmw" in namespace "subpath-2745"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:13:49.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2745" for this suite.
Dec 17 01:13:55.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:13:55.127: INFO: namespace subpath-2745 deletion completed in 6.065976762s

â€¢ [SLOW TEST:28.142 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:13:55.127: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Dec 17 01:13:55.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 create -f - --namespace=kubectl-7376'
Dec 17 01:13:55.350: INFO: stderr: ""
Dec 17 01:13:55.350: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 17 01:13:55.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7376'
Dec 17 01:13:55.421: INFO: stderr: ""
Dec 17 01:13:55.421: INFO: stdout: "update-demo-nautilus-jp9rt update-demo-nautilus-q4pld "
Dec 17 01:13:55.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-nautilus-jp9rt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7376'
Dec 17 01:13:55.492: INFO: stderr: ""
Dec 17 01:13:55.492: INFO: stdout: ""
Dec 17 01:13:55.492: INFO: update-demo-nautilus-jp9rt is created but not running
Dec 17 01:14:00.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7376'
Dec 17 01:14:00.568: INFO: stderr: ""
Dec 17 01:14:00.568: INFO: stdout: "update-demo-nautilus-jp9rt update-demo-nautilus-q4pld "
Dec 17 01:14:00.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-nautilus-jp9rt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7376'
Dec 17 01:14:00.637: INFO: stderr: ""
Dec 17 01:14:00.637: INFO: stdout: "true"
Dec 17 01:14:00.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-nautilus-jp9rt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7376'
Dec 17 01:14:00.707: INFO: stderr: ""
Dec 17 01:14:00.707: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 01:14:00.707: INFO: validating pod update-demo-nautilus-jp9rt
Dec 17 01:14:00.711: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 01:14:00.711: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 01:14:00.711: INFO: update-demo-nautilus-jp9rt is verified up and running
Dec 17 01:14:00.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-nautilus-q4pld -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7376'
Dec 17 01:14:00.785: INFO: stderr: ""
Dec 17 01:14:00.785: INFO: stdout: "true"
Dec 17 01:14:00.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-nautilus-q4pld -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7376'
Dec 17 01:14:00.854: INFO: stderr: ""
Dec 17 01:14:00.854: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 01:14:00.854: INFO: validating pod update-demo-nautilus-q4pld
Dec 17 01:14:00.858: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 01:14:00.858: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 01:14:00.858: INFO: update-demo-nautilus-q4pld is verified up and running
STEP: scaling down the replication controller
Dec 17 01:14:00.859: INFO: scanned /root for discovery docs: <nil>
Dec 17 01:14:00.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-7376'
Dec 17 01:14:01.952: INFO: stderr: ""
Dec 17 01:14:01.953: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 17 01:14:01.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7376'
Dec 17 01:14:02.035: INFO: stderr: ""
Dec 17 01:14:02.035: INFO: stdout: "update-demo-nautilus-jp9rt update-demo-nautilus-q4pld "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 17 01:14:07.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7376'
Dec 17 01:14:07.109: INFO: stderr: ""
Dec 17 01:14:07.109: INFO: stdout: "update-demo-nautilus-q4pld "
Dec 17 01:14:07.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-nautilus-q4pld -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7376'
Dec 17 01:14:07.185: INFO: stderr: ""
Dec 17 01:14:07.185: INFO: stdout: "true"
Dec 17 01:14:07.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-nautilus-q4pld -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7376'
Dec 17 01:14:07.255: INFO: stderr: ""
Dec 17 01:14:07.255: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 01:14:07.255: INFO: validating pod update-demo-nautilus-q4pld
Dec 17 01:14:07.258: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 01:14:07.258: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 01:14:07.258: INFO: update-demo-nautilus-q4pld is verified up and running
STEP: scaling up the replication controller
Dec 17 01:14:07.260: INFO: scanned /root for discovery docs: <nil>
Dec 17 01:14:07.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-7376'
Dec 17 01:14:08.352: INFO: stderr: ""
Dec 17 01:14:08.352: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 17 01:14:08.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7376'
Dec 17 01:14:08.429: INFO: stderr: ""
Dec 17 01:14:08.429: INFO: stdout: "update-demo-nautilus-246zt update-demo-nautilus-q4pld "
Dec 17 01:14:08.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-nautilus-246zt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7376'
Dec 17 01:14:08.500: INFO: stderr: ""
Dec 17 01:14:08.500: INFO: stdout: ""
Dec 17 01:14:08.500: INFO: update-demo-nautilus-246zt is created but not running
Dec 17 01:14:13.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7376'
Dec 17 01:14:13.574: INFO: stderr: ""
Dec 17 01:14:13.574: INFO: stdout: "update-demo-nautilus-246zt update-demo-nautilus-q4pld "
Dec 17 01:14:13.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-nautilus-246zt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7376'
Dec 17 01:14:13.644: INFO: stderr: ""
Dec 17 01:14:13.644: INFO: stdout: "true"
Dec 17 01:14:13.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-nautilus-246zt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7376'
Dec 17 01:14:13.718: INFO: stderr: ""
Dec 17 01:14:13.719: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 01:14:13.719: INFO: validating pod update-demo-nautilus-246zt
Dec 17 01:14:13.722: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 01:14:13.722: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 01:14:13.722: INFO: update-demo-nautilus-246zt is verified up and running
Dec 17 01:14:13.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-nautilus-q4pld -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7376'
Dec 17 01:14:13.795: INFO: stderr: ""
Dec 17 01:14:13.795: INFO: stdout: "true"
Dec 17 01:14:13.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-nautilus-q4pld -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7376'
Dec 17 01:14:13.865: INFO: stderr: ""
Dec 17 01:14:13.865: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 01:14:13.865: INFO: validating pod update-demo-nautilus-q4pld
Dec 17 01:14:13.867: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 01:14:13.867: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 01:14:13.867: INFO: update-demo-nautilus-q4pld is verified up and running
STEP: using delete to clean up resources
Dec 17 01:14:13.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 delete --grace-period=0 --force -f - --namespace=kubectl-7376'
Dec 17 01:14:13.937: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 01:14:13.937: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 17 01:14:13.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7376'
Dec 17 01:14:14.020: INFO: stderr: "No resources found in kubectl-7376 namespace.\n"
Dec 17 01:14:14.020: INFO: stdout: ""
Dec 17 01:14:14.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods -l name=update-demo --namespace=kubectl-7376 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 17 01:14:14.096: INFO: stderr: ""
Dec 17 01:14:14.096: INFO: stdout: "update-demo-nautilus-246zt\nupdate-demo-nautilus-q4pld\n"
Dec 17 01:14:14.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7376'
Dec 17 01:14:14.673: INFO: stderr: "No resources found in kubectl-7376 namespace.\n"
Dec 17 01:14:14.673: INFO: stdout: ""
Dec 17 01:14:14.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods -l name=update-demo --namespace=kubectl-7376 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 17 01:14:14.746: INFO: stderr: ""
Dec 17 01:14:14.746: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:14:14.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7376" for this suite.
Dec 17 01:14:26.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:14:26.831: INFO: namespace kubectl-7376 deletion completed in 12.082365814s

â€¢ [SLOW TEST:31.704 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:14:26.831: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-aa74e8ff-3335-417a-afc4-1f60b261bb84
STEP: Creating secret with name s-test-opt-upd-25137e34-9de2-4a68-80c5-9931c32f35cc
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-aa74e8ff-3335-417a-afc4-1f60b261bb84
STEP: Updating secret s-test-opt-upd-25137e34-9de2-4a68-80c5-9931c32f35cc
STEP: Creating secret with name s-test-opt-create-ee568041-1571-4aba-9b39-c7ef773a9f20
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:14:32.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7796" for this suite.
Dec 17 01:14:54.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:14:54.990: INFO: namespace secrets-7796 deletion completed in 22.063097226s

â€¢ [SLOW TEST:28.159 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:14:54.990: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Dec 17 01:14:55.009: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 17 01:15:55.022: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 01:15:55.024: INFO: Starting informer...
STEP: Starting pod...
Dec 17 01:15:55.235: INFO: Pod is running on ip-172-20-58-188.us-east-2.compute.internal. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Dec 17 01:15:55.245: INFO: Pod wasn't evicted. Proceeding
Dec 17 01:15:55.245: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Dec 17 01:17:10.257: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:17:10.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-525" for this suite.
Dec 17 01:17:22.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:17:22.322: INFO: namespace taint-single-pod-525 deletion completed in 12.061576438s

â€¢ [SLOW TEST:147.332 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:17:22.322: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 01:17:23.083: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 01:17:26.097: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:17:26.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6006" for this suite.
Dec 17 01:17:32.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:17:32.222: INFO: namespace webhook-6006 deletion completed in 6.075514406s
STEP: Destroying namespace "webhook-6006-markers" for this suite.
Dec 17 01:17:38.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:17:38.282: INFO: namespace webhook-6006-markers deletion completed in 6.059909625s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:15.969 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:17:38.291: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Dec 17 01:17:38.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 create -f - --namespace=kubectl-5657'
Dec 17 01:17:38.609: INFO: stderr: ""
Dec 17 01:17:38.609: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 17 01:17:39.611: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 01:17:39.611: INFO: Found 1 / 1
Dec 17 01:17:39.611: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec 17 01:17:39.613: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 01:17:39.613: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 17 01:17:39.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 patch pod redis-master-8lw6d --namespace=kubectl-5657 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec 17 01:17:39.685: INFO: stderr: ""
Dec 17 01:17:39.685: INFO: stdout: "pod/redis-master-8lw6d patched\n"
STEP: checking annotations
Dec 17 01:17:39.688: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 01:17:39.688: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:17:39.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5657" for this suite.
Dec 17 01:17:51.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:17:51.754: INFO: namespace kubectl-5657 deletion completed in 12.064509223s

â€¢ [SLOW TEST:13.463 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:17:51.755: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 17 01:17:55.805: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 17 01:17:55.809: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 17 01:17:57.810: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 17 01:17:57.812: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 17 01:17:59.810: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 17 01:17:59.812: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 17 01:18:01.810: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 17 01:18:01.812: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 17 01:18:03.810: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 17 01:18:03.813: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 17 01:18:05.810: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 17 01:18:05.813: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 17 01:18:07.810: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 17 01:18:07.812: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 17 01:18:09.810: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 17 01:18:09.814: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 17 01:18:11.810: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 17 01:18:11.812: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:18:11.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8116" for this suite.
Dec 17 01:18:23.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:18:23.901: INFO: namespace container-lifecycle-hook-8116 deletion completed in 12.073896933s

â€¢ [SLOW TEST:32.146 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:18:23.901: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8728.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8728.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 17 01:18:25.954: INFO: DNS probes using dns-8728/dns-test-1539f03d-87e8-4ce2-ab6b-ff9916a4d9c5 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:18:25.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8728" for this suite.
Dec 17 01:18:31.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:18:32.033: INFO: namespace dns-8728 deletion completed in 6.069202657s

â€¢ [SLOW TEST:8.131 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:18:32.033: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec 17 01:18:32.064: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8321 /api/v1/namespaces/watch-8321/configmaps/e2e-watch-test-label-changed c56c99ad-24ea-480b-9760-7aa4fa99af8b 14161 0 2019-12-17 01:18:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 17 01:18:32.064: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8321 /api/v1/namespaces/watch-8321/configmaps/e2e-watch-test-label-changed c56c99ad-24ea-480b-9760-7aa4fa99af8b 14162 0 2019-12-17 01:18:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 17 01:18:32.064: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8321 /api/v1/namespaces/watch-8321/configmaps/e2e-watch-test-label-changed c56c99ad-24ea-480b-9760-7aa4fa99af8b 14163 0 2019-12-17 01:18:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec 17 01:18:42.090: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8321 /api/v1/namespaces/watch-8321/configmaps/e2e-watch-test-label-changed c56c99ad-24ea-480b-9760-7aa4fa99af8b 14184 0 2019-12-17 01:18:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 17 01:18:42.090: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8321 /api/v1/namespaces/watch-8321/configmaps/e2e-watch-test-label-changed c56c99ad-24ea-480b-9760-7aa4fa99af8b 14185 0 2019-12-17 01:18:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec 17 01:18:42.091: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8321 /api/v1/namespaces/watch-8321/configmaps/e2e-watch-test-label-changed c56c99ad-24ea-480b-9760-7aa4fa99af8b 14186 0 2019-12-17 01:18:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:18:42.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8321" for this suite.
Dec 17 01:18:48.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:18:48.163: INFO: namespace watch-8321 deletion completed in 6.069140998s

â€¢ [SLOW TEST:16.130 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:18:48.163: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 01:18:48.186: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-532b0e17-0335-4a1c-9692-dd9ec8f4ad2f" in namespace "security-context-test-1050" to be "success or failure"
Dec 17 01:18:48.188: INFO: Pod "busybox-privileged-false-532b0e17-0335-4a1c-9692-dd9ec8f4ad2f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.184486ms
Dec 17 01:18:50.191: INFO: Pod "busybox-privileged-false-532b0e17-0335-4a1c-9692-dd9ec8f4ad2f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004959597s
Dec 17 01:18:50.191: INFO: Pod "busybox-privileged-false-532b0e17-0335-4a1c-9692-dd9ec8f4ad2f" satisfied condition "success or failure"
Dec 17 01:18:50.196: INFO: Got logs for pod "busybox-privileged-false-532b0e17-0335-4a1c-9692-dd9ec8f4ad2f": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:18:50.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1050" for this suite.
Dec 17 01:18:56.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:18:56.282: INFO: namespace security-context-test-1050 deletion completed in 6.083035652s

â€¢ [SLOW TEST:8.118 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:18:56.282: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-5e1b32b9-751c-4b81-9536-0e39560048d8
STEP: Creating a pod to test consume secrets
Dec 17 01:18:56.309: INFO: Waiting up to 5m0s for pod "pod-secrets-f42b8209-c07d-4c53-9f33-3613118273f2" in namespace "secrets-721" to be "success or failure"
Dec 17 01:18:56.313: INFO: Pod "pod-secrets-f42b8209-c07d-4c53-9f33-3613118273f2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.44184ms
Dec 17 01:18:58.315: INFO: Pod "pod-secrets-f42b8209-c07d-4c53-9f33-3613118273f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005826566s
STEP: Saw pod success
Dec 17 01:18:58.315: INFO: Pod "pod-secrets-f42b8209-c07d-4c53-9f33-3613118273f2" satisfied condition "success or failure"
Dec 17 01:18:58.317: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-secrets-f42b8209-c07d-4c53-9f33-3613118273f2 container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 01:18:58.331: INFO: Waiting for pod pod-secrets-f42b8209-c07d-4c53-9f33-3613118273f2 to disappear
Dec 17 01:18:58.334: INFO: Pod pod-secrets-f42b8209-c07d-4c53-9f33-3613118273f2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:18:58.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-721" for this suite.
Dec 17 01:19:04.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:19:04.416: INFO: namespace secrets-721 deletion completed in 6.079514711s

â€¢ [SLOW TEST:8.135 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:19:04.417: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 17 01:19:04.441: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:19:08.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4065" for this suite.
Dec 17 01:19:14.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:19:14.402: INFO: namespace init-container-4065 deletion completed in 6.073636003s

â€¢ [SLOW TEST:9.986 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:19:14.403: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:19:30.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7316" for this suite.
Dec 17 01:19:36.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:19:36.565: INFO: namespace resourcequota-7316 deletion completed in 6.073459331s

â€¢ [SLOW TEST:22.163 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:19:36.565: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Dec 17 01:19:36.588: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:19:50.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7075" for this suite.
Dec 17 01:19:56.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:19:56.069: INFO: namespace pods-7075 deletion completed in 6.056297448s

â€¢ [SLOW TEST:19.504 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:19:56.070: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 17 01:19:56.091: INFO: Waiting up to 5m0s for pod "downward-api-371e276b-08f3-4495-85cf-252bfb8e7cd8" in namespace "downward-api-6299" to be "success or failure"
Dec 17 01:19:56.094: INFO: Pod "downward-api-371e276b-08f3-4495-85cf-252bfb8e7cd8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.013058ms
Dec 17 01:19:58.097: INFO: Pod "downward-api-371e276b-08f3-4495-85cf-252bfb8e7cd8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006343398s
STEP: Saw pod success
Dec 17 01:19:58.097: INFO: Pod "downward-api-371e276b-08f3-4495-85cf-252bfb8e7cd8" satisfied condition "success or failure"
Dec 17 01:19:58.099: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod downward-api-371e276b-08f3-4495-85cf-252bfb8e7cd8 container dapi-container: <nil>
STEP: delete the pod
Dec 17 01:19:58.118: INFO: Waiting for pod downward-api-371e276b-08f3-4495-85cf-252bfb8e7cd8 to disappear
Dec 17 01:19:58.121: INFO: Pod downward-api-371e276b-08f3-4495-85cf-252bfb8e7cd8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:19:58.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6299" for this suite.
Dec 17 01:20:04.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:20:04.196: INFO: namespace downward-api-6299 deletion completed in 6.071959779s

â€¢ [SLOW TEST:8.126 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:20:04.196: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-bc1b5871-b8a5-45cd-8c67-08326a52962a
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:20:06.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4787" for this suite.
Dec 17 01:20:18.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:20:18.334: INFO: namespace configmap-4787 deletion completed in 12.08357386s

â€¢ [SLOW TEST:14.138 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:20:18.334: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 01:20:18.355: INFO: Creating deployment "webserver-deployment"
Dec 17 01:20:18.358: INFO: Waiting for observed generation 1
Dec 17 01:20:20.362: INFO: Waiting for all required pods to come up
Dec 17 01:20:20.365: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec 17 01:20:24.373: INFO: Waiting for deployment "webserver-deployment" to complete
Dec 17 01:20:24.378: INFO: Updating deployment "webserver-deployment" with a non-existent image
Dec 17 01:20:24.384: INFO: Updating deployment webserver-deployment
Dec 17 01:20:24.384: INFO: Waiting for observed generation 2
Dec 17 01:20:26.389: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec 17 01:20:26.391: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec 17 01:20:26.393: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 17 01:20:26.400: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec 17 01:20:26.400: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec 17 01:20:26.402: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 17 01:20:26.406: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Dec 17 01:20:26.406: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Dec 17 01:20:26.411: INFO: Updating deployment webserver-deployment
Dec 17 01:20:26.411: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Dec 17 01:20:26.424: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec 17 01:20:26.431: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 17 01:20:26.465: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-9404 /apis/apps/v1/namespaces/deployment-9404/deployments/webserver-deployment 9d3456fb-bc60-4d35-a44f-c1001bc460cb 14643 3 2019-12-17 01:20:18 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00164eee8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2019-12-17 01:20:24 +0000 UTC,LastTransitionTime:2019-12-17 01:20:18 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-12-17 01:20:26 +0000 UTC,LastTransitionTime:2019-12-17 01:20:26 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Dec 17 01:20:26.482: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-9404 /apis/apps/v1/namespaces/deployment-9404/replicasets/webserver-deployment-c7997dcc8 f1f597f2-4b68-4b0e-a0b0-81460f465b0a 14640 3 2019-12-17 01:20:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 9d3456fb-bc60-4d35-a44f-c1001bc460cb 0xc00180e637 0xc00180e638}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00180e6a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 17 01:20:26.482: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Dec 17 01:20:26.482: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-9404 /apis/apps/v1/namespaces/deployment-9404/replicasets/webserver-deployment-595b5b9587 e74d3bc5-0be0-4804-9e50-3c5a1fbce37c 14637 3 2019-12-17 01:20:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 9d3456fb-bc60-4d35-a44f-c1001bc460cb 0xc00180e577 0xc00180e578}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00180e5d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Dec 17 01:20:26.519: INFO: Pod "webserver-deployment-595b5b9587-6t9cg" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6t9cg webserver-deployment-595b5b9587- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-595b5b9587-6t9cg 6d89b92b-e0e4-48d4-bbd9-9118d8f495cc 14566 0 2019-12-17 01:20:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e74d3bc5-0be0-4804-9e50-3c5a1fbce37c 0xc00180eb97 0xc00180eb98}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-58-188.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.58.188,PodIP:100.96.1.168,StartTime:2019-12-17 01:20:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 01:20:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://69a37071be9c9d0c7894691baeb42d65fa0265aeccb2995a550aaf88d147dd35,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.168,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.519: INFO: Pod "webserver-deployment-595b5b9587-9djq8" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-9djq8 webserver-deployment-595b5b9587- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-595b5b9587-9djq8 275ddc83-e48d-4355-8aa6-25e1feedd601 14558 0 2019-12-17 01:20:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e74d3bc5-0be0-4804-9e50-3c5a1fbce37c 0xc00180ed07 0xc00180ed08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-34-147.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.34.147,PodIP:100.96.2.74,StartTime:2019-12-17 01:20:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 01:20:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://6cc37e91dea7fafb1774b759f7b432a7cc759a82175a46cff25f4814a71eb91e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.74,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.519: INFO: Pod "webserver-deployment-595b5b9587-cfvqb" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-cfvqb webserver-deployment-595b5b9587- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-595b5b9587-cfvqb f4ce4d2f-4b33-455e-ae85-bd21e290ae08 14669 0 2019-12-17 01:20:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e74d3bc5-0be0-4804-9e50-3c5a1fbce37c 0xc00180ee70 0xc00180ee71}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-34-147.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.34.147,PodIP:,StartTime:2019-12-17 01:20:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.520: INFO: Pod "webserver-deployment-595b5b9587-dhttd" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-dhttd webserver-deployment-595b5b9587- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-595b5b9587-dhttd 0a50081d-edf7-42a8-9eaf-1414f4f83fd9 14660 0 2019-12-17 01:20:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e74d3bc5-0be0-4804-9e50-3c5a1fbce37c 0xc00180efb7 0xc00180efb8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.520: INFO: Pod "webserver-deployment-595b5b9587-dpd9p" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-dpd9p webserver-deployment-595b5b9587- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-595b5b9587-dpd9p 93d4dd29-69a3-43b4-bd17-1625b3599729 14579 0 2019-12-17 01:20:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e74d3bc5-0be0-4804-9e50-3c5a1fbce37c 0xc00180f0a7 0xc00180f0a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-58-188.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.58.188,PodIP:100.96.1.166,StartTime:2019-12-17 01:20:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 01:20:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://ba0a7b11144e2a8ae588ac56bff3e4b00d0974673e90681184df4eb8116e6151,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.166,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.520: INFO: Pod "webserver-deployment-595b5b9587-gmnbk" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gmnbk webserver-deployment-595b5b9587- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-595b5b9587-gmnbk 736d991c-daf8-42f4-a90d-44792d6b1e95 14591 0 2019-12-17 01:20:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e74d3bc5-0be0-4804-9e50-3c5a1fbce37c 0xc00180f217 0xc00180f218}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-58-188.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.58.188,PodIP:100.96.1.169,StartTime:2019-12-17 01:20:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 01:20:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://fef12f10bde71ed19b5757220d13b17b6d3c54db6fd24a9619f16f4a78262636,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.169,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.520: INFO: Pod "webserver-deployment-595b5b9587-hgjgr" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-hgjgr webserver-deployment-595b5b9587- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-595b5b9587-hgjgr fb443cd7-a69b-4e06-a156-2704dbee3855 14656 0 2019-12-17 01:20:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e74d3bc5-0be0-4804-9e50-3c5a1fbce37c 0xc00180f387 0xc00180f388}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-58-188.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.520: INFO: Pod "webserver-deployment-595b5b9587-k9v7p" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-k9v7p webserver-deployment-595b5b9587- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-595b5b9587-k9v7p f8943c23-7afb-4fe3-950e-d4405ae6e8e4 14661 0 2019-12-17 01:20:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e74d3bc5-0be0-4804-9e50-3c5a1fbce37c 0xc00180f490 0xc00180f491}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.521: INFO: Pod "webserver-deployment-595b5b9587-kqh5m" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-kqh5m webserver-deployment-595b5b9587- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-595b5b9587-kqh5m ee61f9c7-c282-41f7-8960-0ba46c9d1caf 14667 0 2019-12-17 01:20:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e74d3bc5-0be0-4804-9e50-3c5a1fbce37c 0xc00180f577 0xc00180f578}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-34-147.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.521: INFO: Pod "webserver-deployment-595b5b9587-l2g47" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-l2g47 webserver-deployment-595b5b9587- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-595b5b9587-l2g47 d7bb3698-dec8-4267-aa3a-aa0fd9a626eb 14659 0 2019-12-17 01:20:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e74d3bc5-0be0-4804-9e50-3c5a1fbce37c 0xc00180f680 0xc00180f681}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.521: INFO: Pod "webserver-deployment-595b5b9587-lx4t9" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-lx4t9 webserver-deployment-595b5b9587- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-595b5b9587-lx4t9 28b1fd8b-a62d-4949-bb3d-ffae0ce42761 14575 0 2019-12-17 01:20:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e74d3bc5-0be0-4804-9e50-3c5a1fbce37c 0xc00180f767 0xc00180f768}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-58-188.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.58.188,PodIP:100.96.1.163,StartTime:2019-12-17 01:20:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 01:20:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://a52295ac78efaad140b5478105e7b7836b0b15083d0a46611f88118c44801ddf,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.163,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.521: INFO: Pod "webserver-deployment-595b5b9587-pzpdk" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pzpdk webserver-deployment-595b5b9587- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-595b5b9587-pzpdk 0ce3ec73-a66b-48dd-a4dd-541b114a02ae 14583 0 2019-12-17 01:20:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e74d3bc5-0be0-4804-9e50-3c5a1fbce37c 0xc00180f8e7 0xc00180f8e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-58-188.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.58.188,PodIP:100.96.1.165,StartTime:2019-12-17 01:20:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 01:20:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://5859b4088d9043c8c34753a8a506eba6f5b11c1c361c8969f7881b6d6794224b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.165,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.521: INFO: Pod "webserver-deployment-595b5b9587-sd5xl" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-sd5xl webserver-deployment-595b5b9587- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-595b5b9587-sd5xl e4882c3f-94a4-4278-bbf7-33ab741a247b 14646 0 2019-12-17 01:20:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e74d3bc5-0be0-4804-9e50-3c5a1fbce37c 0xc00180fa57 0xc00180fa58}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-34-147.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.34.147,PodIP:,StartTime:2019-12-17 01:20:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.522: INFO: Pod "webserver-deployment-595b5b9587-sj7fl" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-sj7fl webserver-deployment-595b5b9587- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-595b5b9587-sj7fl db5c288a-5d54-41ae-8c96-7104a7f7a139 14569 0 2019-12-17 01:20:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e74d3bc5-0be0-4804-9e50-3c5a1fbce37c 0xc00180fba7 0xc00180fba8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-58-188.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.58.188,PodIP:100.96.1.167,StartTime:2019-12-17 01:20:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 01:20:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://0da22613d5651a9599464339f5c303c214900dcd88ac97b7fe3e267294bb3df3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.167,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.522: INFO: Pod "webserver-deployment-595b5b9587-slvnw" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-slvnw webserver-deployment-595b5b9587- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-595b5b9587-slvnw 1d25d46e-df20-43f9-8e6a-78efb80d2abd 14658 0 2019-12-17 01:20:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e74d3bc5-0be0-4804-9e50-3c5a1fbce37c 0xc00180fd17 0xc00180fd18}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.522: INFO: Pod "webserver-deployment-595b5b9587-sm8fw" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-sm8fw webserver-deployment-595b5b9587- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-595b5b9587-sm8fw 594ca85e-e853-46d0-ae5e-70f1ae69cc8f 14666 0 2019-12-17 01:20:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e74d3bc5-0be0-4804-9e50-3c5a1fbce37c 0xc00180fe07 0xc00180fe08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-34-147.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.522: INFO: Pod "webserver-deployment-595b5b9587-vhq2h" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-vhq2h webserver-deployment-595b5b9587- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-595b5b9587-vhq2h ebcdc241-cb5e-45eb-8e03-f80b5cfe2869 14657 0 2019-12-17 01:20:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e74d3bc5-0be0-4804-9e50-3c5a1fbce37c 0xc00180ff10 0xc00180ff11}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.522: INFO: Pod "webserver-deployment-595b5b9587-wksbr" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-wksbr webserver-deployment-595b5b9587- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-595b5b9587-wksbr 1e0789a7-6982-4214-baa5-7a0fb69c90b7 14668 0 2019-12-17 01:20:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e74d3bc5-0be0-4804-9e50-3c5a1fbce37c 0xc00180fff7 0xc00180fff8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-58-188.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.522: INFO: Pod "webserver-deployment-595b5b9587-zgsbn" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-zgsbn webserver-deployment-595b5b9587- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-595b5b9587-zgsbn 87625d7e-83d5-499d-8ea8-71f7736e6515 14672 0 2019-12-17 01:20:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e74d3bc5-0be0-4804-9e50-3c5a1fbce37c 0xc006636100 0xc006636101}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-58-188.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.58.188,PodIP:,StartTime:2019-12-17 01:20:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.522: INFO: Pod "webserver-deployment-595b5b9587-zkfzb" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-zkfzb webserver-deployment-595b5b9587- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-595b5b9587-zkfzb 6b856e30-df95-4ab1-8730-8577998d7303 14555 0 2019-12-17 01:20:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e74d3bc5-0be0-4804-9e50-3c5a1fbce37c 0xc006636247 0xc006636248}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-34-147.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.34.147,PodIP:100.96.2.75,StartTime:2019-12-17 01:20:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 01:20:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://c227c2fa18cc93da9e5ca4251b69d5ee305bf8984df21d802029ca671a044a90,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.75,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.523: INFO: Pod "webserver-deployment-c7997dcc8-2prf7" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-2prf7 webserver-deployment-c7997dcc8- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-c7997dcc8-2prf7 6c401fb5-ad7f-496e-8a42-3b5df9b58faa 14630 0 2019-12-17 01:20:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f1f597f2-4b68-4b0e-a0b0-81460f465b0a 0xc0066363b0 0xc0066363b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-58-188.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.58.188,PodIP:,StartTime:2019-12-17 01:20:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.523: INFO: Pod "webserver-deployment-c7997dcc8-445j8" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-445j8 webserver-deployment-c7997dcc8- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-c7997dcc8-445j8 ba749f32-4fc8-4243-8810-2bd9429fc07d 14662 0 2019-12-17 01:20:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f1f597f2-4b68-4b0e-a0b0-81460f465b0a 0xc006636517 0xc006636518}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.523: INFO: Pod "webserver-deployment-c7997dcc8-56mms" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-56mms webserver-deployment-c7997dcc8- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-c7997dcc8-56mms 3a0b20a7-a0e2-44b3-8146-b7160874786d 14665 0 2019-12-17 01:20:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f1f597f2-4b68-4b0e-a0b0-81460f465b0a 0xc006636617 0xc006636618}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.523: INFO: Pod "webserver-deployment-c7997dcc8-5vhrk" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-5vhrk webserver-deployment-c7997dcc8- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-c7997dcc8-5vhrk cbe92ed1-cff6-4c6e-bfe9-c8567b8ae349 14632 0 2019-12-17 01:20:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f1f597f2-4b68-4b0e-a0b0-81460f465b0a 0xc006636717 0xc006636718}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-58-188.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.58.188,PodIP:100.96.1.171,StartTime:2019-12-17 01:20:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login',},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.171,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.523: INFO: Pod "webserver-deployment-c7997dcc8-66kkl" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-66kkl webserver-deployment-c7997dcc8- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-c7997dcc8-66kkl 42066020-5612-44f9-b121-79d7c886e611 14664 0 2019-12-17 01:20:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f1f597f2-4b68-4b0e-a0b0-81460f465b0a 0xc0066368b7 0xc0066368b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.524: INFO: Pod "webserver-deployment-c7997dcc8-99q8n" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-99q8n webserver-deployment-c7997dcc8- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-c7997dcc8-99q8n 964b5505-3b5a-4a15-8c2c-8f115e67f613 14631 0 2019-12-17 01:20:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f1f597f2-4b68-4b0e-a0b0-81460f465b0a 0xc0066369c7 0xc0066369c8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-34-147.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.34.147,PodIP:100.96.2.76,StartTime:2019-12-17 01:20:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login',},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.76,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.524: INFO: Pod "webserver-deployment-c7997dcc8-9jzfr" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-9jzfr webserver-deployment-c7997dcc8- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-c7997dcc8-9jzfr 9a146a6d-7637-4535-b3d4-d5eecaa67399 14629 0 2019-12-17 01:20:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f1f597f2-4b68-4b0e-a0b0-81460f465b0a 0xc006636b60 0xc006636b61}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-34-147.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.34.147,PodIP:,StartTime:2019-12-17 01:20:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.524: INFO: Pod "webserver-deployment-c7997dcc8-kxzqc" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-kxzqc webserver-deployment-c7997dcc8- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-c7997dcc8-kxzqc 6f4f18be-df35-42ef-bad9-d0758ada7337 14663 0 2019-12-17 01:20:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f1f597f2-4b68-4b0e-a0b0-81460f465b0a 0xc006636cc7 0xc006636cc8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.524: INFO: Pod "webserver-deployment-c7997dcc8-qb4r4" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-qb4r4 webserver-deployment-c7997dcc8- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-c7997dcc8-qb4r4 31cc5752-981f-4045-99f5-0e401171e915 14649 0 2019-12-17 01:20:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f1f597f2-4b68-4b0e-a0b0-81460f465b0a 0xc006636dc7 0xc006636dc8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-58-188.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.524: INFO: Pod "webserver-deployment-c7997dcc8-snb2f" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-snb2f webserver-deployment-c7997dcc8- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-c7997dcc8-snb2f 70054e17-9512-4dfc-8c68-9e3cad296518 14671 0 2019-12-17 01:20:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f1f597f2-4b68-4b0e-a0b0-81460f465b0a 0xc006636ee0 0xc006636ee1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-58-188.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.525: INFO: Pod "webserver-deployment-c7997dcc8-vbkxd" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-vbkxd webserver-deployment-c7997dcc8- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-c7997dcc8-vbkxd d9d8f183-ef8c-40fd-8a21-ec9eaf26dc3b 14633 0 2019-12-17 01:20:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f1f597f2-4b68-4b0e-a0b0-81460f465b0a 0xc006636ff0 0xc006636ff1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-58-188.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.58.188,PodIP:100.96.1.172,StartTime:2019-12-17 01:20:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login',},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.172,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 01:20:26.525: INFO: Pod "webserver-deployment-c7997dcc8-wkvlk" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-wkvlk webserver-deployment-c7997dcc8- deployment-9404 /api/v1/namespaces/deployment-9404/pods/webserver-deployment-c7997dcc8-wkvlk 4818be62-267f-4aa0-a818-35e8948596ea 14670 0 2019-12-17 01:20:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f1f597f2-4b68-4b0e-a0b0-81460f465b0a 0xc006637187 0xc006637188}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j4v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j4v49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j4v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-58-188.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:20:26.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9404" for this suite.
Dec 17 01:20:32.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:20:32.651: INFO: namespace deployment-9404 deletion completed in 6.106588565s

â€¢ [SLOW TEST:14.317 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:20:32.651: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 01:20:32.668: INFO: Creating deployment "test-recreate-deployment"
Dec 17 01:20:32.671: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec 17 01:20:32.685: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Dec 17 01:20:34.689: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec 17 01:20:34.691: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712142432, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712142432, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712142432, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712142432, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-68fc85c7bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 01:20:36.693: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712142432, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712142432, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712142432, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712142432, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-68fc85c7bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 01:20:38.693: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712142432, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712142432, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712142432, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712142432, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-68fc85c7bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 01:20:40.694: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec 17 01:20:40.698: INFO: Updating deployment test-recreate-deployment
Dec 17 01:20:40.698: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 17 01:20:40.763: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-5568 /apis/apps/v1/namespaces/deployment-5568/deployments/test-recreate-deployment 98b1677c-ee51-464d-81e7-db93ddc5d2d5 14873 2 2019-12-17 01:20:32 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00403a438 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-12-17 01:20:40 +0000 UTC,LastTransitionTime:2019-12-17 01:20:40 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2019-12-17 01:20:40 +0000 UTC,LastTransitionTime:2019-12-17 01:20:32 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Dec 17 01:20:40.765: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-5568 /apis/apps/v1/namespaces/deployment-5568/replicasets/test-recreate-deployment-5f94c574ff baa13d05-a3b5-45db-945a-308ef036464e 14872 1 2019-12-17 01:20:40 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 98b1677c-ee51-464d-81e7-db93ddc5d2d5 0xc00672bdf7 0xc00672bdf8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00672be58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 17 01:20:40.765: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec 17 01:20:40.765: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-5568 /apis/apps/v1/namespaces/deployment-5568/replicasets/test-recreate-deployment-68fc85c7bb 3139ccda-4ba9-4133-ba2b-907a65959671 14864 2 2019-12-17 01:20:32 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 98b1677c-ee51-464d-81e7-db93ddc5d2d5 0xc00672bed7 0xc00672bed8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00672bf38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 17 01:20:40.767: INFO: Pod "test-recreate-deployment-5f94c574ff-mm2fr" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-mm2fr test-recreate-deployment-5f94c574ff- deployment-5568 /api/v1/namespaces/deployment-5568/pods/test-recreate-deployment-5f94c574ff-mm2fr 6282f4c9-faad-42ed-8d1c-adf7b7e1e7f0 14871 0 2019-12-17 01:20:40 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff baa13d05-a3b5-45db-945a-308ef036464e 0xc00403a807 0xc00403a808}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jwfl5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jwfl5,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jwfl5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-58-188.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 01:20:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.58.188,PodIP:,StartTime:2019-12-17 01:20:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:20:40.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5568" for this suite.
Dec 17 01:20:46.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:20:46.838: INFO: namespace deployment-5568 deletion completed in 6.068600627s

â€¢ [SLOW TEST:14.187 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:20:46.839: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 17 01:20:46.875: INFO: Waiting up to 5m0s for pod "pod-026c4e06-9f33-4394-bc29-c98b59641ec1" in namespace "emptydir-4741" to be "success or failure"
Dec 17 01:20:46.879: INFO: Pod "pod-026c4e06-9f33-4394-bc29-c98b59641ec1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.206185ms
Dec 17 01:20:48.882: INFO: Pod "pod-026c4e06-9f33-4394-bc29-c98b59641ec1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006449231s
STEP: Saw pod success
Dec 17 01:20:48.882: INFO: Pod "pod-026c4e06-9f33-4394-bc29-c98b59641ec1" satisfied condition "success or failure"
Dec 17 01:20:48.884: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-026c4e06-9f33-4394-bc29-c98b59641ec1 container test-container: <nil>
STEP: delete the pod
Dec 17 01:20:48.898: INFO: Waiting for pod pod-026c4e06-9f33-4394-bc29-c98b59641ec1 to disappear
Dec 17 01:20:48.901: INFO: Pod pod-026c4e06-9f33-4394-bc29-c98b59641ec1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:20:48.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4741" for this suite.
Dec 17 01:20:54.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:20:54.973: INFO: namespace emptydir-4741 deletion completed in 6.068979079s

â€¢ [SLOW TEST:8.134 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:20:54.973: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 01:20:55.017: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 17 01:20:58.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 --namespace=crd-publish-openapi-1055 create -f -'
Dec 17 01:20:58.447: INFO: stderr: ""
Dec 17 01:20:58.447: INFO: stdout: "e2e-test-crd-publish-openapi-863-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 17 01:20:58.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 --namespace=crd-publish-openapi-1055 delete e2e-test-crd-publish-openapi-863-crds test-cr'
Dec 17 01:20:58.578: INFO: stderr: ""
Dec 17 01:20:58.578: INFO: stdout: "e2e-test-crd-publish-openapi-863-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Dec 17 01:20:58.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 --namespace=crd-publish-openapi-1055 apply -f -'
Dec 17 01:20:58.784: INFO: stderr: ""
Dec 17 01:20:58.784: INFO: stdout: "e2e-test-crd-publish-openapi-863-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 17 01:20:58.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 --namespace=crd-publish-openapi-1055 delete e2e-test-crd-publish-openapi-863-crds test-cr'
Dec 17 01:20:58.862: INFO: stderr: ""
Dec 17 01:20:58.862: INFO: stdout: "e2e-test-crd-publish-openapi-863-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec 17 01:20:58.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 explain e2e-test-crd-publish-openapi-863-crds'
Dec 17 01:20:59.009: INFO: stderr: ""
Dec 17 01:20:59.009: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-863-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:21:00.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1055" for this suite.
Dec 17 01:21:06.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:21:07.060: INFO: namespace crd-publish-openapi-1055 deletion completed in 6.069756508s

â€¢ [SLOW TEST:12.087 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:21:07.060: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 01:21:07.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 create -f - --namespace=kubectl-267'
Dec 17 01:21:07.282: INFO: stderr: ""
Dec 17 01:21:07.282: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec 17 01:21:07.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 create -f - --namespace=kubectl-267'
Dec 17 01:21:07.464: INFO: stderr: ""
Dec 17 01:21:07.464: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 17 01:21:08.467: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 01:21:08.467: INFO: Found 1 / 1
Dec 17 01:21:08.467: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 17 01:21:08.468: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 01:21:08.468: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 17 01:21:08.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 describe pod redis-master-ml9s4 --namespace=kubectl-267'
Dec 17 01:21:08.566: INFO: stderr: ""
Dec 17 01:21:08.566: INFO: stdout: "Name:         redis-master-ml9s4\nNamespace:    kubectl-267\nPriority:     0\nNode:         ip-172-20-58-188.us-east-2.compute.internal/172.20.58.188\nStart Time:   Tue, 17 Dec 2019 01:21:07 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nStatus:       Running\nIP:           100.96.1.187\nIPs:\n  IP:           100.96.1.187\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://348c94a13297c9fc28f3527bd996ca24d13f726a815efbba4264cf1279a6901b\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 17 Dec 2019 01:21:08 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-kkzzm (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-kkzzm:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-kkzzm\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                  Message\n  ----    ------     ----  ----                                                  -------\n  Normal  Scheduled  1s    default-scheduler                                     Successfully assigned kubectl-267/redis-master-ml9s4 to ip-172-20-58-188.us-east-2.compute.internal\n  Normal  Pulled     1s    kubelet, ip-172-20-58-188.us-east-2.compute.internal  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    1s    kubelet, ip-172-20-58-188.us-east-2.compute.internal  Created container redis-master\n  Normal  Started    0s    kubelet, ip-172-20-58-188.us-east-2.compute.internal  Started container redis-master\n"
Dec 17 01:21:08.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 describe rc redis-master --namespace=kubectl-267'
Dec 17 01:21:08.661: INFO: stderr: ""
Dec 17 01:21:08.661: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-267\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: redis-master-ml9s4\n"
Dec 17 01:21:08.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 describe service redis-master --namespace=kubectl-267'
Dec 17 01:21:08.740: INFO: stderr: ""
Dec 17 01:21:08.741: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-267\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                100.66.122.58\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         100.96.1.187:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec 17 01:21:08.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 describe node ip-172-20-34-147.us-east-2.compute.internal'
Dec 17 01:21:08.837: INFO: stderr: ""
Dec 17 01:21:08.837: INFO: stdout: "Name:               ip-172-20-34-147.us-east-2.compute.internal\nRoles:              node\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=t2.medium\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-east-2\n                    failure-domain.beta.kubernetes.io/zone=us-east-2a\n                    kops.k8s.io/instancegroup=nodes\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-20-34-147.us-east-2.compute.internal\n                    kubernetes.io/os=linux\n                    kubernetes.io/role=node\n                    node-role.kubernetes.io/node=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 17 Dec 2019 00:14:19 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 17 Dec 2019 00:14:24 +0000   Tue, 17 Dec 2019 00:14:24 +0000   RouteCreated                 RouteController created a route\n  MemoryPressure       False   Tue, 17 Dec 2019 01:20:21 +0000   Tue, 17 Dec 2019 00:14:19 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 17 Dec 2019 01:20:21 +0000   Tue, 17 Dec 2019 00:14:19 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 17 Dec 2019 01:20:21 +0000   Tue, 17 Dec 2019 00:14:19 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 17 Dec 2019 01:20:21 +0000   Tue, 17 Dec 2019 00:14:19 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:   172.20.34.147\n  ExternalIP:   3.135.191.120\n  Hostname:     ip-172-20-34-147.us-east-2.compute.internal\n  InternalDNS:  ip-172-20-34-147.us-east-2.compute.internal\n  ExternalDNS:  ec2-3-135-191-120.us-east-2.compute.amazonaws.com\nCapacity:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           125753328Ki\n hugepages-2Mi:               0\n memory:                      4049088Ki\n pods:                        110\nAllocatable:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           115894266893\n hugepages-2Mi:               0\n memory:                      3946688Ki\n pods:                        110\nSystem Info:\n Machine ID:                 3a7e3b4a4c354926b4d0a6c3e8527758\n System UUID:                EC2488FC-29EB-0FBD-E8D5-B0F0C846527B\n Boot ID:                    2a407003-4a92-467a-abc7-720344bf3a1a\n Kernel Version:             4.9.0-11-amd64\n OS Image:                   Debian GNU/Linux 9 (stretch)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.16.3\n Kube-Proxy Version:         v1.16.3\nPodCIDR:                     100.96.2.0/24\nPodCIDRs:                    100.96.2.0/24\nProviderID:                  aws:///us-east-2a/i-0936e250a637f2e5f\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                kube-dns-autoscaler-66b775459-2bh8z                        20m (1%)      0 (0%)      10Mi (0%)        0 (0%)         30m\n  kube-system                kube-dns-bb55d6458-982k4                                   260m (13%)    0 (0%)      110Mi (2%)       170Mi (4%)     30m\n  kube-system                kube-dns-bb55d6458-qz7ks                                   260m (13%)    0 (0%)      110Mi (2%)       170Mi (4%)     65m\n  kube-system                kube-proxy-ip-172-20-34-147.us-east-2.compute.internal     100m (5%)     0 (0%)      0 (0%)           0 (0%)         66m\n  sonobuoy                   sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         64m\n  sonobuoy                   sonobuoy-e2e-job-edd513b56d7b4d93                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         64m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-aa23d16e52f14f6e-l6lh6    0 (0%)        0 (0%)      0 (0%)           0 (0%)         64m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                    Requests    Limits\n  --------                    --------    ------\n  cpu                         640m (32%)  0 (0%)\n  memory                      230Mi (5%)  340Mi (8%)\n  ephemeral-storage           0 (0%)      0 (0%)\n  attachable-volumes-aws-ebs  0           0\nEvents:                       <none>\n"
Dec 17 01:21:08.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 describe namespace kubectl-267'
Dec 17 01:21:08.923: INFO: stderr: ""
Dec 17 01:21:08.923: INFO: stdout: "Name:         kubectl-267\nLabels:       e2e-framework=kubectl\n              e2e-run=c6f75d64-3cfd-47fa-88d4-00a930d4d054\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:21:08.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-267" for this suite.
Dec 17 01:21:20.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:21:20.982: INFO: namespace kubectl-267 deletion completed in 12.057081475s

â€¢ [SLOW TEST:13.922 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:21:20.983: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 17 01:21:21.005: INFO: Waiting up to 5m0s for pod "downward-api-6cfe67b5-4785-4d61-bfca-8d85b57f4177" in namespace "downward-api-9414" to be "success or failure"
Dec 17 01:21:21.007: INFO: Pod "downward-api-6cfe67b5-4785-4d61-bfca-8d85b57f4177": Phase="Pending", Reason="", readiness=false. Elapsed: 2.091753ms
Dec 17 01:21:23.010: INFO: Pod "downward-api-6cfe67b5-4785-4d61-bfca-8d85b57f4177": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004816244s
STEP: Saw pod success
Dec 17 01:21:23.010: INFO: Pod "downward-api-6cfe67b5-4785-4d61-bfca-8d85b57f4177" satisfied condition "success or failure"
Dec 17 01:21:23.014: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod downward-api-6cfe67b5-4785-4d61-bfca-8d85b57f4177 container dapi-container: <nil>
STEP: delete the pod
Dec 17 01:21:23.028: INFO: Waiting for pod downward-api-6cfe67b5-4785-4d61-bfca-8d85b57f4177 to disappear
Dec 17 01:21:23.030: INFO: Pod downward-api-6cfe67b5-4785-4d61-bfca-8d85b57f4177 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:21:23.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9414" for this suite.
Dec 17 01:21:29.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:21:29.096: INFO: namespace downward-api-9414 deletion completed in 6.063960993s

â€¢ [SLOW TEST:8.113 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:21:29.096: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 01:21:29.123: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec 17 01:21:29.129: INFO: Number of nodes with available pods: 0
Dec 17 01:21:29.129: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec 17 01:21:29.142: INFO: Number of nodes with available pods: 0
Dec 17 01:21:29.142: INFO: Node ip-172-20-34-147.us-east-2.compute.internal is running more than one daemon pod
Dec 17 01:21:30.144: INFO: Number of nodes with available pods: 0
Dec 17 01:21:30.144: INFO: Node ip-172-20-34-147.us-east-2.compute.internal is running more than one daemon pod
Dec 17 01:21:31.144: INFO: Number of nodes with available pods: 1
Dec 17 01:21:31.144: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec 17 01:21:31.156: INFO: Number of nodes with available pods: 1
Dec 17 01:21:31.156: INFO: Number of running nodes: 0, number of available pods: 1
Dec 17 01:21:32.158: INFO: Number of nodes with available pods: 0
Dec 17 01:21:32.158: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec 17 01:21:32.163: INFO: Number of nodes with available pods: 0
Dec 17 01:21:32.163: INFO: Node ip-172-20-34-147.us-east-2.compute.internal is running more than one daemon pod
Dec 17 01:21:33.165: INFO: Number of nodes with available pods: 0
Dec 17 01:21:33.165: INFO: Node ip-172-20-34-147.us-east-2.compute.internal is running more than one daemon pod
Dec 17 01:21:34.166: INFO: Number of nodes with available pods: 0
Dec 17 01:21:34.166: INFO: Node ip-172-20-34-147.us-east-2.compute.internal is running more than one daemon pod
Dec 17 01:21:35.166: INFO: Number of nodes with available pods: 0
Dec 17 01:21:35.166: INFO: Node ip-172-20-34-147.us-east-2.compute.internal is running more than one daemon pod
Dec 17 01:21:36.166: INFO: Number of nodes with available pods: 1
Dec 17 01:21:36.166: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8785, will wait for the garbage collector to delete the pods
Dec 17 01:21:36.224: INFO: Deleting DaemonSet.extensions daemon-set took: 3.513139ms
Dec 17 01:21:36.525: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.34279ms
Dec 17 01:21:42.027: INFO: Number of nodes with available pods: 0
Dec 17 01:21:42.027: INFO: Number of running nodes: 0, number of available pods: 0
Dec 17 01:21:42.029: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8785/daemonsets","resourceVersion":"15128"},"items":null}

Dec 17 01:21:42.031: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8785/pods","resourceVersion":"15128"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:21:42.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8785" for this suite.
Dec 17 01:21:48.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:21:48.104: INFO: namespace daemonsets-8785 deletion completed in 6.057907793s

â€¢ [SLOW TEST:19.008 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:21:48.105: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:21:48.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8844" for this suite.
Dec 17 01:21:54.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:21:54.215: INFO: namespace kubelet-test-8844 deletion completed in 6.073376703s

â€¢ [SLOW TEST:6.111 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:21:54.216: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-5757/configmap-test-3a62b3e2-0bb7-4500-8bfb-d916a853d172
STEP: Creating a pod to test consume configMaps
Dec 17 01:21:54.240: INFO: Waiting up to 5m0s for pod "pod-configmaps-e3afce21-833b-4b3d-a13b-686a6f79ec9f" in namespace "configmap-5757" to be "success or failure"
Dec 17 01:21:54.243: INFO: Pod "pod-configmaps-e3afce21-833b-4b3d-a13b-686a6f79ec9f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.847792ms
Dec 17 01:21:56.245: INFO: Pod "pod-configmaps-e3afce21-833b-4b3d-a13b-686a6f79ec9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004861999s
STEP: Saw pod success
Dec 17 01:21:56.245: INFO: Pod "pod-configmaps-e3afce21-833b-4b3d-a13b-686a6f79ec9f" satisfied condition "success or failure"
Dec 17 01:21:56.246: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-configmaps-e3afce21-833b-4b3d-a13b-686a6f79ec9f container env-test: <nil>
STEP: delete the pod
Dec 17 01:21:56.258: INFO: Waiting for pod pod-configmaps-e3afce21-833b-4b3d-a13b-686a6f79ec9f to disappear
Dec 17 01:21:56.260: INFO: Pod pod-configmaps-e3afce21-833b-4b3d-a13b-686a6f79ec9f no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:21:56.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5757" for this suite.
Dec 17 01:22:02.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:22:02.322: INFO: namespace configmap-5757 deletion completed in 6.059740034s

â€¢ [SLOW TEST:8.106 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:22:02.322: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec 17 01:22:05.361: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:22:06.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4217" for this suite.
Dec 17 01:22:34.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:22:34.429: INFO: namespace replicaset-4217 deletion completed in 28.057064975s

â€¢ [SLOW TEST:32.107 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:22:34.430: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-3df65b91-43f4-4275-b1d9-f8aa3a966700
STEP: Creating a pod to test consume secrets
Dec 17 01:22:34.453: INFO: Waiting up to 5m0s for pod "pod-secrets-2e063e3f-c78b-4943-a33b-c0ffe3d56ae0" in namespace "secrets-9597" to be "success or failure"
Dec 17 01:22:34.456: INFO: Pod "pod-secrets-2e063e3f-c78b-4943-a33b-c0ffe3d56ae0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.445412ms
Dec 17 01:22:36.459: INFO: Pod "pod-secrets-2e063e3f-c78b-4943-a33b-c0ffe3d56ae0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005953731s
STEP: Saw pod success
Dec 17 01:22:36.459: INFO: Pod "pod-secrets-2e063e3f-c78b-4943-a33b-c0ffe3d56ae0" satisfied condition "success or failure"
Dec 17 01:22:36.461: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-secrets-2e063e3f-c78b-4943-a33b-c0ffe3d56ae0 container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 01:22:36.475: INFO: Waiting for pod pod-secrets-2e063e3f-c78b-4943-a33b-c0ffe3d56ae0 to disappear
Dec 17 01:22:36.477: INFO: Pod pod-secrets-2e063e3f-c78b-4943-a33b-c0ffe3d56ae0 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:22:36.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9597" for this suite.
Dec 17 01:22:42.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:22:42.539: INFO: namespace secrets-9597 deletion completed in 6.059947916s

â€¢ [SLOW TEST:8.110 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:22:42.540: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 17 01:22:42.571: INFO: Waiting up to 5m0s for pod "pod-40349054-0bbd-4ca3-b72c-83a0a5508d78" in namespace "emptydir-4658" to be "success or failure"
Dec 17 01:22:42.575: INFO: Pod "pod-40349054-0bbd-4ca3-b72c-83a0a5508d78": Phase="Pending", Reason="", readiness=false. Elapsed: 3.452087ms
Dec 17 01:22:44.577: INFO: Pod "pod-40349054-0bbd-4ca3-b72c-83a0a5508d78": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005682026s
STEP: Saw pod success
Dec 17 01:22:44.577: INFO: Pod "pod-40349054-0bbd-4ca3-b72c-83a0a5508d78" satisfied condition "success or failure"
Dec 17 01:22:44.579: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-40349054-0bbd-4ca3-b72c-83a0a5508d78 container test-container: <nil>
STEP: delete the pod
Dec 17 01:22:44.591: INFO: Waiting for pod pod-40349054-0bbd-4ca3-b72c-83a0a5508d78 to disappear
Dec 17 01:22:44.593: INFO: Pod pod-40349054-0bbd-4ca3-b72c-83a0a5508d78 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:22:44.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4658" for this suite.
Dec 17 01:22:50.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:22:50.649: INFO: namespace emptydir-4658 deletion completed in 6.054215336s

â€¢ [SLOW TEST:8.109 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:22:50.649: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Dec 17 01:23:21.187: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1217 01:23:21.187496      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:23:21.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5241" for this suite.
Dec 17 01:23:27.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:23:27.248: INFO: namespace gc-5241 deletion completed in 6.05835269s

â€¢ [SLOW TEST:36.598 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:23:27.248: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 17 01:23:31.303: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 17 01:23:31.305: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 17 01:23:33.306: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 17 01:23:33.309: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 17 01:23:35.306: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 17 01:23:35.308: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:23:35.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3217" for this suite.
Dec 17 01:24:03.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:24:03.370: INFO: namespace container-lifecycle-hook-3217 deletion completed in 28.060221113s

â€¢ [SLOW TEST:36.123 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:24:03.371: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 01:24:03.394: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5749671a-8d36-4201-9b25-2d09705578d9" in namespace "downward-api-527" to be "success or failure"
Dec 17 01:24:03.397: INFO: Pod "downwardapi-volume-5749671a-8d36-4201-9b25-2d09705578d9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.958999ms
Dec 17 01:24:05.400: INFO: Pod "downwardapi-volume-5749671a-8d36-4201-9b25-2d09705578d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006466412s
STEP: Saw pod success
Dec 17 01:24:05.400: INFO: Pod "downwardapi-volume-5749671a-8d36-4201-9b25-2d09705578d9" satisfied condition "success or failure"
Dec 17 01:24:05.402: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod downwardapi-volume-5749671a-8d36-4201-9b25-2d09705578d9 container client-container: <nil>
STEP: delete the pod
Dec 17 01:24:05.413: INFO: Waiting for pod downwardapi-volume-5749671a-8d36-4201-9b25-2d09705578d9 to disappear
Dec 17 01:24:05.415: INFO: Pod downwardapi-volume-5749671a-8d36-4201-9b25-2d09705578d9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:24:05.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-527" for this suite.
Dec 17 01:24:11.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:24:11.476: INFO: namespace downward-api-527 deletion completed in 6.059108784s

â€¢ [SLOW TEST:8.105 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:24:11.476: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1217 01:24:51.516063      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 17 01:24:51.516: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:24:51.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4378" for this suite.
Dec 17 01:24:57.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:24:57.581: INFO: namespace gc-4378 deletion completed in 6.062828302s

â€¢ [SLOW TEST:46.105 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:24:57.581: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Dec 17 01:24:59.620: INFO: Pod pod-hostip-a665af9b-e0a4-4fa8-9a5a-541b0f5659c0 has hostIP: 172.20.58.188
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:24:59.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9955" for this suite.
Dec 17 01:25:27.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:25:27.683: INFO: namespace pods-9955 deletion completed in 28.060388969s

â€¢ [SLOW TEST:30.102 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:25:27.683: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 17 01:25:27.706: INFO: Waiting up to 5m0s for pod "downward-api-32aa2d61-29e9-47d8-a84b-70f6452830e5" in namespace "downward-api-6594" to be "success or failure"
Dec 17 01:25:27.709: INFO: Pod "downward-api-32aa2d61-29e9-47d8-a84b-70f6452830e5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.628569ms
Dec 17 01:25:29.711: INFO: Pod "downward-api-32aa2d61-29e9-47d8-a84b-70f6452830e5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005005392s
STEP: Saw pod success
Dec 17 01:25:29.711: INFO: Pod "downward-api-32aa2d61-29e9-47d8-a84b-70f6452830e5" satisfied condition "success or failure"
Dec 17 01:25:29.713: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod downward-api-32aa2d61-29e9-47d8-a84b-70f6452830e5 container dapi-container: <nil>
STEP: delete the pod
Dec 17 01:25:29.737: INFO: Waiting for pod downward-api-32aa2d61-29e9-47d8-a84b-70f6452830e5 to disappear
Dec 17 01:25:29.739: INFO: Pod downward-api-32aa2d61-29e9-47d8-a84b-70f6452830e5 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:25:29.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6594" for this suite.
Dec 17 01:25:35.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:25:35.811: INFO: namespace downward-api-6594 deletion completed in 6.070115452s

â€¢ [SLOW TEST:8.128 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:25:35.811: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 01:25:35.835: INFO: Waiting up to 5m0s for pod "downwardapi-volume-594bb1d6-d1fb-4d59-99b0-dcfe8f4e9a98" in namespace "downward-api-3835" to be "success or failure"
Dec 17 01:25:35.839: INFO: Pod "downwardapi-volume-594bb1d6-d1fb-4d59-99b0-dcfe8f4e9a98": Phase="Pending", Reason="", readiness=false. Elapsed: 3.874748ms
Dec 17 01:25:37.842: INFO: Pod "downwardapi-volume-594bb1d6-d1fb-4d59-99b0-dcfe8f4e9a98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006654335s
STEP: Saw pod success
Dec 17 01:25:37.842: INFO: Pod "downwardapi-volume-594bb1d6-d1fb-4d59-99b0-dcfe8f4e9a98" satisfied condition "success or failure"
Dec 17 01:25:37.843: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod downwardapi-volume-594bb1d6-d1fb-4d59-99b0-dcfe8f4e9a98 container client-container: <nil>
STEP: delete the pod
Dec 17 01:25:37.856: INFO: Waiting for pod downwardapi-volume-594bb1d6-d1fb-4d59-99b0-dcfe8f4e9a98 to disappear
Dec 17 01:25:37.858: INFO: Pod downwardapi-volume-594bb1d6-d1fb-4d59-99b0-dcfe8f4e9a98 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:25:37.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3835" for this suite.
Dec 17 01:25:43.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:25:43.920: INFO: namespace downward-api-3835 deletion completed in 6.059932613s

â€¢ [SLOW TEST:8.109 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:25:43.920: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-a1f1f004-9aab-436c-bcbe-b26058729562
STEP: Creating a pod to test consume secrets
Dec 17 01:25:43.945: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fbb79528-3f55-4802-9457-6a39db460877" in namespace "projected-8747" to be "success or failure"
Dec 17 01:25:43.947: INFO: Pod "pod-projected-secrets-fbb79528-3f55-4802-9457-6a39db460877": Phase="Pending", Reason="", readiness=false. Elapsed: 2.11826ms
Dec 17 01:25:45.950: INFO: Pod "pod-projected-secrets-fbb79528-3f55-4802-9457-6a39db460877": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004494766s
STEP: Saw pod success
Dec 17 01:25:45.950: INFO: Pod "pod-projected-secrets-fbb79528-3f55-4802-9457-6a39db460877" satisfied condition "success or failure"
Dec 17 01:25:45.951: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-projected-secrets-fbb79528-3f55-4802-9457-6a39db460877 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 17 01:25:45.965: INFO: Waiting for pod pod-projected-secrets-fbb79528-3f55-4802-9457-6a39db460877 to disappear
Dec 17 01:25:45.967: INFO: Pod pod-projected-secrets-fbb79528-3f55-4802-9457-6a39db460877 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:25:45.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8747" for this suite.
Dec 17 01:25:51.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:25:52.034: INFO: namespace projected-8747 deletion completed in 6.064957866s

â€¢ [SLOW TEST:8.113 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:25:52.034: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-7425
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7425 to expose endpoints map[]
Dec 17 01:25:52.060: INFO: Get endpoints failed (3.042759ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Dec 17 01:25:53.062: INFO: successfully validated that service endpoint-test2 in namespace services-7425 exposes endpoints map[] (1.005250945s elapsed)
STEP: Creating pod pod1 in namespace services-7425
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7425 to expose endpoints map[pod1:[80]]
Dec 17 01:25:55.082: INFO: successfully validated that service endpoint-test2 in namespace services-7425 exposes endpoints map[pod1:[80]] (2.014864859s elapsed)
STEP: Creating pod pod2 in namespace services-7425
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7425 to expose endpoints map[pod1:[80] pod2:[80]]
Dec 17 01:25:57.108: INFO: successfully validated that service endpoint-test2 in namespace services-7425 exposes endpoints map[pod1:[80] pod2:[80]] (2.023704779s elapsed)
STEP: Deleting pod pod1 in namespace services-7425
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7425 to expose endpoints map[pod2:[80]]
Dec 17 01:25:58.125: INFO: successfully validated that service endpoint-test2 in namespace services-7425 exposes endpoints map[pod2:[80]] (1.013648404s elapsed)
STEP: Deleting pod pod2 in namespace services-7425
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7425 to expose endpoints map[]
Dec 17 01:25:58.132: INFO: successfully validated that service endpoint-test2 in namespace services-7425 exposes endpoints map[] (2.067412ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:25:58.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7425" for this suite.
Dec 17 01:26:26.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:26:26.214: INFO: namespace services-7425 deletion completed in 28.062289345s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:34.180 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:26:26.215: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:26:28.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1872" for this suite.
Dec 17 01:27:12.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:27:12.321: INFO: namespace kubelet-test-1872 deletion completed in 44.067351612s

â€¢ [SLOW TEST:46.107 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:27:12.321: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec 17 01:27:12.355: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7405 /api/v1/namespaces/watch-7405/configmaps/e2e-watch-test-watch-closed 20222026-7caa-49c9-89c0-2bb6333de7c0 16177 0 2019-12-17 01:27:12 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 17 01:27:12.355: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7405 /api/v1/namespaces/watch-7405/configmaps/e2e-watch-test-watch-closed 20222026-7caa-49c9-89c0-2bb6333de7c0 16178 0 2019-12-17 01:27:12 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec 17 01:27:12.363: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7405 /api/v1/namespaces/watch-7405/configmaps/e2e-watch-test-watch-closed 20222026-7caa-49c9-89c0-2bb6333de7c0 16179 0 2019-12-17 01:27:12 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 17 01:27:12.363: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7405 /api/v1/namespaces/watch-7405/configmaps/e2e-watch-test-watch-closed 20222026-7caa-49c9-89c0-2bb6333de7c0 16180 0 2019-12-17 01:27:12 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:27:12.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7405" for this suite.
Dec 17 01:27:18.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:27:18.429: INFO: namespace watch-7405 deletion completed in 6.063415211s

â€¢ [SLOW TEST:6.107 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:27:18.429: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Dec 17 01:27:18.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 create -f - --namespace=kubectl-1470'
Dec 17 01:27:18.599: INFO: stderr: ""
Dec 17 01:27:18.599: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 17 01:27:18.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1470'
Dec 17 01:27:18.672: INFO: stderr: ""
Dec 17 01:27:18.672: INFO: stdout: "update-demo-nautilus-4r8ws update-demo-nautilus-vq22r "
Dec 17 01:27:18.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-nautilus-4r8ws -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1470'
Dec 17 01:27:18.741: INFO: stderr: ""
Dec 17 01:27:18.741: INFO: stdout: ""
Dec 17 01:27:18.741: INFO: update-demo-nautilus-4r8ws is created but not running
Dec 17 01:27:23.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1470'
Dec 17 01:27:23.817: INFO: stderr: ""
Dec 17 01:27:23.817: INFO: stdout: "update-demo-nautilus-4r8ws update-demo-nautilus-vq22r "
Dec 17 01:27:23.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-nautilus-4r8ws -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1470'
Dec 17 01:27:23.887: INFO: stderr: ""
Dec 17 01:27:23.887: INFO: stdout: "true"
Dec 17 01:27:23.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-nautilus-4r8ws -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1470'
Dec 17 01:27:23.955: INFO: stderr: ""
Dec 17 01:27:23.955: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 01:27:23.955: INFO: validating pod update-demo-nautilus-4r8ws
Dec 17 01:27:23.958: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 01:27:23.958: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 01:27:23.958: INFO: update-demo-nautilus-4r8ws is verified up and running
Dec 17 01:27:23.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-nautilus-vq22r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1470'
Dec 17 01:27:24.033: INFO: stderr: ""
Dec 17 01:27:24.033: INFO: stdout: "true"
Dec 17 01:27:24.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods update-demo-nautilus-vq22r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1470'
Dec 17 01:27:24.101: INFO: stderr: ""
Dec 17 01:27:24.101: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 01:27:24.101: INFO: validating pod update-demo-nautilus-vq22r
Dec 17 01:27:24.104: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 01:27:24.104: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 01:27:24.104: INFO: update-demo-nautilus-vq22r is verified up and running
STEP: using delete to clean up resources
Dec 17 01:27:24.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 delete --grace-period=0 --force -f - --namespace=kubectl-1470'
Dec 17 01:27:24.176: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 01:27:24.176: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 17 01:27:24.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1470'
Dec 17 01:27:24.249: INFO: stderr: "No resources found in kubectl-1470 namespace.\n"
Dec 17 01:27:24.249: INFO: stdout: ""
Dec 17 01:27:24.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods -l name=update-demo --namespace=kubectl-1470 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 17 01:27:24.323: INFO: stderr: ""
Dec 17 01:27:24.323: INFO: stdout: "update-demo-nautilus-4r8ws\nupdate-demo-nautilus-vq22r\n"
Dec 17 01:27:24.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1470'
Dec 17 01:27:24.899: INFO: stderr: "No resources found in kubectl-1470 namespace.\n"
Dec 17 01:27:24.899: INFO: stdout: ""
Dec 17 01:27:24.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods -l name=update-demo --namespace=kubectl-1470 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 17 01:27:24.970: INFO: stderr: ""
Dec 17 01:27:24.970: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:27:24.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1470" for this suite.
Dec 17 01:27:30.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:27:31.028: INFO: namespace kubectl-1470 deletion completed in 6.055036505s

â€¢ [SLOW TEST:12.599 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:27:31.028: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-c980028c-8368-484a-9671-065a8708f9fb
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-c980028c-8368-484a-9671-065a8708f9fb
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:27:37.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9551" for this suite.
Dec 17 01:27:51.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:27:51.147: INFO: namespace configmap-9551 deletion completed in 14.058121472s

â€¢ [SLOW TEST:20.119 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:27:51.147: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 17 01:27:51.168: INFO: Waiting up to 5m0s for pod "pod-5c77daf4-7641-4048-bf90-70775ccc6d5b" in namespace "emptydir-5220" to be "success or failure"
Dec 17 01:27:51.170: INFO: Pod "pod-5c77daf4-7641-4048-bf90-70775ccc6d5b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.391342ms
Dec 17 01:27:53.172: INFO: Pod "pod-5c77daf4-7641-4048-bf90-70775ccc6d5b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004484817s
STEP: Saw pod success
Dec 17 01:27:53.173: INFO: Pod "pod-5c77daf4-7641-4048-bf90-70775ccc6d5b" satisfied condition "success or failure"
Dec 17 01:27:53.174: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-5c77daf4-7641-4048-bf90-70775ccc6d5b container test-container: <nil>
STEP: delete the pod
Dec 17 01:27:53.187: INFO: Waiting for pod pod-5c77daf4-7641-4048-bf90-70775ccc6d5b to disappear
Dec 17 01:27:53.189: INFO: Pod pod-5c77daf4-7641-4048-bf90-70775ccc6d5b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:27:53.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5220" for this suite.
Dec 17 01:27:59.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:27:59.250: INFO: namespace emptydir-5220 deletion completed in 6.059133545s

â€¢ [SLOW TEST:8.103 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:27:59.251: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-da5b5bd3-d2b0-41f5-b7d7-6ebcf7f2999f in namespace container-probe-3899
Dec 17 01:28:01.275: INFO: Started pod busybox-da5b5bd3-d2b0-41f5-b7d7-6ebcf7f2999f in namespace container-probe-3899
STEP: checking the pod's current state and verifying that restartCount is present
Dec 17 01:28:01.277: INFO: Initial restart count of pod busybox-da5b5bd3-d2b0-41f5-b7d7-6ebcf7f2999f is 0
Dec 17 01:28:53.338: INFO: Restart count of pod container-probe-3899/busybox-da5b5bd3-d2b0-41f5-b7d7-6ebcf7f2999f is now 1 (52.061187028s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:28:53.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3899" for this suite.
Dec 17 01:28:59.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:28:59.405: INFO: namespace container-probe-3899 deletion completed in 6.058200426s

â€¢ [SLOW TEST:60.155 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:28:59.406: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 17 01:28:59.427: INFO: Waiting up to 5m0s for pod "pod-1079ec2b-26c7-41b2-a20f-d46656a185da" in namespace "emptydir-6364" to be "success or failure"
Dec 17 01:28:59.431: INFO: Pod "pod-1079ec2b-26c7-41b2-a20f-d46656a185da": Phase="Pending", Reason="", readiness=false. Elapsed: 3.935255ms
Dec 17 01:29:01.433: INFO: Pod "pod-1079ec2b-26c7-41b2-a20f-d46656a185da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006763649s
STEP: Saw pod success
Dec 17 01:29:01.434: INFO: Pod "pod-1079ec2b-26c7-41b2-a20f-d46656a185da" satisfied condition "success or failure"
Dec 17 01:29:01.435: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-1079ec2b-26c7-41b2-a20f-d46656a185da container test-container: <nil>
STEP: delete the pod
Dec 17 01:29:01.448: INFO: Waiting for pod pod-1079ec2b-26c7-41b2-a20f-d46656a185da to disappear
Dec 17 01:29:01.449: INFO: Pod pod-1079ec2b-26c7-41b2-a20f-d46656a185da no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:29:01.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6364" for this suite.
Dec 17 01:29:07.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:29:07.513: INFO: namespace emptydir-6364 deletion completed in 6.061152289s

â€¢ [SLOW TEST:8.108 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:29:07.514: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 17 01:29:07.531: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 17 01:29:07.538: INFO: Waiting for terminating namespaces to be deleted...
Dec 17 01:29:07.539: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-34-147.us-east-2.compute.internal before test
Dec 17 01:29:07.553: INFO: sonobuoy-systemd-logs-daemon-set-aa23d16e52f14f6e-l6lh6 from sonobuoy started at 2019-12-17 00:16:40 +0000 UTC (2 container statuses recorded)
Dec 17 01:29:07.553: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 17 01:29:07.553: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 17 01:29:07.553: INFO: kube-dns-bb55d6458-qz7ks from kube-system started at 2019-12-17 00:15:20 +0000 UTC (3 container statuses recorded)
Dec 17 01:29:07.553: INFO: 	Container dnsmasq ready: true, restart count 0
Dec 17 01:29:07.553: INFO: 	Container kubedns ready: true, restart count 0
Dec 17 01:29:07.553: INFO: 	Container sidecar ready: true, restart count 0
Dec 17 01:29:07.553: INFO: sonobuoy-e2e-job-edd513b56d7b4d93 from sonobuoy started at 2019-12-17 00:16:40 +0000 UTC (2 container statuses recorded)
Dec 17 01:29:07.553: INFO: 	Container e2e ready: true, restart count 0
Dec 17 01:29:07.553: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 17 01:29:07.553: INFO: sonobuoy from sonobuoy started at 2019-12-17 00:16:34 +0000 UTC (1 container statuses recorded)
Dec 17 01:29:07.553: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 17 01:29:07.553: INFO: kube-proxy-ip-172-20-34-147.us-east-2.compute.internal from kube-system started at 2019-12-17 00:10:42 +0000 UTC (1 container statuses recorded)
Dec 17 01:29:07.553: INFO: 	Container kube-proxy ready: true, restart count 5
Dec 17 01:29:07.553: INFO: kube-dns-bb55d6458-982k4 from kube-system started at 2019-12-17 00:50:49 +0000 UTC (3 container statuses recorded)
Dec 17 01:29:07.553: INFO: 	Container dnsmasq ready: true, restart count 0
Dec 17 01:29:07.553: INFO: 	Container kubedns ready: true, restart count 0
Dec 17 01:29:07.553: INFO: 	Container sidecar ready: true, restart count 0
Dec 17 01:29:07.553: INFO: kube-dns-autoscaler-66b775459-2bh8z from kube-system started at 2019-12-17 00:50:49 +0000 UTC (1 container statuses recorded)
Dec 17 01:29:07.553: INFO: 	Container autoscaler ready: true, restart count 0
Dec 17 01:29:07.553: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-58-188.us-east-2.compute.internal before test
Dec 17 01:29:07.557: INFO: kube-proxy-ip-172-20-58-188.us-east-2.compute.internal from kube-system started at 2019-12-17 00:10:40 +0000 UTC (1 container statuses recorded)
Dec 17 01:29:07.557: INFO: 	Container kube-proxy ready: true, restart count 5
Dec 17 01:29:07.557: INFO: sonobuoy-systemd-logs-daemon-set-aa23d16e52f14f6e-dk4ms from sonobuoy started at 2019-12-17 00:16:40 +0000 UTC (2 container statuses recorded)
Dec 17 01:29:07.557: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 17 01:29:07.557: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-8f7a1753-c1d2-413a-b34a-a5ae17e3a5b4 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-8f7a1753-c1d2-413a-b34a-a5ae17e3a5b4 off the node ip-172-20-58-188.us-east-2.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-8f7a1753-c1d2-413a-b34a-a5ae17e3a5b4
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:34:11.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2711" for this suite.
Dec 17 01:34:19.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:34:19.691: INFO: namespace sched-pred-2711 deletion completed in 8.066495343s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

â€¢ [SLOW TEST:312.178 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:34:19.692: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-e9bc4ed8-5f84-49bb-837c-a6ebeb6b2311
STEP: Creating a pod to test consume secrets
Dec 17 01:34:19.729: INFO: Waiting up to 5m0s for pod "pod-secrets-a0d7f121-e834-4d44-a68e-d2a923f6d7df" in namespace "secrets-3435" to be "success or failure"
Dec 17 01:34:19.732: INFO: Pod "pod-secrets-a0d7f121-e834-4d44-a68e-d2a923f6d7df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.698746ms
Dec 17 01:34:21.743: INFO: Pod "pod-secrets-a0d7f121-e834-4d44-a68e-d2a923f6d7df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014344254s
STEP: Saw pod success
Dec 17 01:34:21.743: INFO: Pod "pod-secrets-a0d7f121-e834-4d44-a68e-d2a923f6d7df" satisfied condition "success or failure"
Dec 17 01:34:21.746: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-secrets-a0d7f121-e834-4d44-a68e-d2a923f6d7df container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 01:34:21.769: INFO: Waiting for pod pod-secrets-a0d7f121-e834-4d44-a68e-d2a923f6d7df to disappear
Dec 17 01:34:21.772: INFO: Pod pod-secrets-a0d7f121-e834-4d44-a68e-d2a923f6d7df no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:34:21.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3435" for this suite.
Dec 17 01:34:27.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:34:27.843: INFO: namespace secrets-3435 deletion completed in 6.068154282s

â€¢ [SLOW TEST:8.151 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:34:27.843: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-78d331b5-26f4-4fc2-8a40-7d071e49a7a1
STEP: Creating a pod to test consume configMaps
Dec 17 01:34:27.869: INFO: Waiting up to 5m0s for pod "pod-configmaps-da9b4d8f-23b9-4ec3-9e38-f1c9e988e15e" in namespace "configmap-946" to be "success or failure"
Dec 17 01:34:27.872: INFO: Pod "pod-configmaps-da9b4d8f-23b9-4ec3-9e38-f1c9e988e15e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.344264ms
Dec 17 01:34:29.875: INFO: Pod "pod-configmaps-da9b4d8f-23b9-4ec3-9e38-f1c9e988e15e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005871865s
STEP: Saw pod success
Dec 17 01:34:29.875: INFO: Pod "pod-configmaps-da9b4d8f-23b9-4ec3-9e38-f1c9e988e15e" satisfied condition "success or failure"
Dec 17 01:34:29.878: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-configmaps-da9b4d8f-23b9-4ec3-9e38-f1c9e988e15e container configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 01:34:29.894: INFO: Waiting for pod pod-configmaps-da9b4d8f-23b9-4ec3-9e38-f1c9e988e15e to disappear
Dec 17 01:34:29.896: INFO: Pod pod-configmaps-da9b4d8f-23b9-4ec3-9e38-f1c9e988e15e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:34:29.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-946" for this suite.
Dec 17 01:34:35.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:34:35.965: INFO: namespace configmap-946 deletion completed in 6.066389336s

â€¢ [SLOW TEST:8.123 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:34:35.966: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:34:41.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5006" for this suite.
Dec 17 01:34:47.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:34:47.533: INFO: namespace watch-5006 deletion completed in 6.163428391s

â€¢ [SLOW TEST:11.568 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:34:47.534: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 17 01:34:47.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-4150'
Dec 17 01:34:47.785: INFO: stderr: ""
Dec 17 01:34:47.785: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Dec 17 01:34:52.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pod e2e-test-httpd-pod --namespace=kubectl-4150 -o json'
Dec 17 01:34:52.907: INFO: stderr: ""
Dec 17 01:34:52.907: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-12-17T01:34:47Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-4150\",\n        \"resourceVersion\": \"17377\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-4150/pods/e2e-test-httpd-pod\",\n        \"uid\": \"f86ab119-10d1-4ece-bcb3-4ca660655d36\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-7mfzn\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-20-58-188.us-east-2.compute.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-7mfzn\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-7mfzn\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-17T01:34:47Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-17T01:34:48Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-17T01:34:48Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-17T01:34:47Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://8eb0000446ff650a1829bcc70b7c941d6fd3f57a625a679721b806973f19cd4a\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-12-17T01:34:48Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.20.58.188\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.96.1.224\",\n        \"podIPs\": [\n            {\n                \"ip\": \"100.96.1.224\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-12-17T01:34:47Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec 17 01:34:52.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 replace -f - --namespace=kubectl-4150'
Dec 17 01:34:53.070: INFO: stderr: ""
Dec 17 01:34:53.070: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Dec 17 01:34:53.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 delete pods e2e-test-httpd-pod --namespace=kubectl-4150'
Dec 17 01:34:54.911: INFO: stderr: ""
Dec 17 01:34:54.911: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:34:54.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4150" for this suite.
Dec 17 01:35:00.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:35:00.978: INFO: namespace kubectl-4150 deletion completed in 6.06441562s

â€¢ [SLOW TEST:13.445 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:35:00.979: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:35:03.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5862" for this suite.
Dec 17 01:35:47.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:35:47.106: INFO: namespace kubelet-test-5862 deletion completed in 44.072397189s

â€¢ [SLOW TEST:46.128 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:35:47.107: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 01:35:47.132: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-39c3bed1-7593-48ca-9b00-188311803a45" in namespace "security-context-test-7654" to be "success or failure"
Dec 17 01:35:47.135: INFO: Pod "alpine-nnp-false-39c3bed1-7593-48ca-9b00-188311803a45": Phase="Pending", Reason="", readiness=false. Elapsed: 3.608062ms
Dec 17 01:35:49.138: INFO: Pod "alpine-nnp-false-39c3bed1-7593-48ca-9b00-188311803a45": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00636056s
Dec 17 01:35:51.141: INFO: Pod "alpine-nnp-false-39c3bed1-7593-48ca-9b00-188311803a45": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009326528s
Dec 17 01:35:51.141: INFO: Pod "alpine-nnp-false-39c3bed1-7593-48ca-9b00-188311803a45" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:35:51.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7654" for this suite.
Dec 17 01:35:57.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:35:57.221: INFO: namespace security-context-test-7654 deletion completed in 6.071980703s

â€¢ [SLOW TEST:10.114 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:35:57.221: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 17 01:35:57.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-4175'
Dec 17 01:35:57.316: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 17 01:35:57.316: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Dec 17 01:35:59.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 delete deployment e2e-test-httpd-deployment --namespace=kubectl-4175'
Dec 17 01:35:59.409: INFO: stderr: ""
Dec 17 01:35:59.409: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:35:59.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4175" for this suite.
Dec 17 01:36:05.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:36:05.481: INFO: namespace kubectl-4175 deletion completed in 6.0678802s

â€¢ [SLOW TEST:8.260 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:36:05.481: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 01:36:05.504: INFO: Waiting up to 5m0s for pod "downwardapi-volume-122dd08f-ac2f-4d2c-a6c3-c3c85531f7f8" in namespace "downward-api-76" to be "success or failure"
Dec 17 01:36:05.507: INFO: Pod "downwardapi-volume-122dd08f-ac2f-4d2c-a6c3-c3c85531f7f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.738963ms
Dec 17 01:36:07.510: INFO: Pod "downwardapi-volume-122dd08f-ac2f-4d2c-a6c3-c3c85531f7f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006023566s
STEP: Saw pod success
Dec 17 01:36:07.510: INFO: Pod "downwardapi-volume-122dd08f-ac2f-4d2c-a6c3-c3c85531f7f8" satisfied condition "success or failure"
Dec 17 01:36:07.513: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod downwardapi-volume-122dd08f-ac2f-4d2c-a6c3-c3c85531f7f8 container client-container: <nil>
STEP: delete the pod
Dec 17 01:36:07.526: INFO: Waiting for pod downwardapi-volume-122dd08f-ac2f-4d2c-a6c3-c3c85531f7f8 to disappear
Dec 17 01:36:07.530: INFO: Pod downwardapi-volume-122dd08f-ac2f-4d2c-a6c3-c3c85531f7f8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:36:07.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-76" for this suite.
Dec 17 01:36:13.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:36:13.599: INFO: namespace downward-api-76 deletion completed in 6.066137438s

â€¢ [SLOW TEST:8.117 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:36:13.599: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Dec 17 01:36:13.619: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
Dec 17 01:36:17.119: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:36:29.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1172" for this suite.
Dec 17 01:36:35.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:36:35.111: INFO: namespace crd-publish-openapi-1172 deletion completed in 6.061439681s

â€¢ [SLOW TEST:21.512 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:36:35.111: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Dec 17 01:36:37.147: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-505434119 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec 17 01:36:42.224: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:36:42.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9311" for this suite.
Dec 17 01:36:48.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:36:48.305: INFO: namespace pods-9311 deletion completed in 6.076508225s

â€¢ [SLOW TEST:13.194 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:36:48.306: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Dec 17 01:36:48.331: INFO: Waiting up to 5m0s for pod "pod-0c127a5d-7090-42f4-ac8f-987bc13b52a7" in namespace "emptydir-2930" to be "success or failure"
Dec 17 01:36:48.333: INFO: Pod "pod-0c127a5d-7090-42f4-ac8f-987bc13b52a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.363626ms
Dec 17 01:36:50.341: INFO: Pod "pod-0c127a5d-7090-42f4-ac8f-987bc13b52a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010332164s
STEP: Saw pod success
Dec 17 01:36:50.341: INFO: Pod "pod-0c127a5d-7090-42f4-ac8f-987bc13b52a7" satisfied condition "success or failure"
Dec 17 01:36:50.343: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-0c127a5d-7090-42f4-ac8f-987bc13b52a7 container test-container: <nil>
STEP: delete the pod
Dec 17 01:36:50.357: INFO: Waiting for pod pod-0c127a5d-7090-42f4-ac8f-987bc13b52a7 to disappear
Dec 17 01:36:50.359: INFO: Pod pod-0c127a5d-7090-42f4-ac8f-987bc13b52a7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:36:50.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2930" for this suite.
Dec 17 01:36:56.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:36:56.428: INFO: namespace emptydir-2930 deletion completed in 6.067039705s

â€¢ [SLOW TEST:8.122 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:36:56.428: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Dec 17 01:36:58.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec pod-sharedvolume-795e72b4-f2c8-4ae6-a5cf-c724862cdb15 -c busybox-main-container --namespace=emptydir-5315 -- cat /usr/share/volumeshare/shareddata.txt'
Dec 17 01:36:58.673: INFO: stderr: ""
Dec 17 01:36:58.673: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:36:58.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5315" for this suite.
Dec 17 01:37:04.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:37:04.745: INFO: namespace emptydir-5315 deletion completed in 6.068551052s

â€¢ [SLOW TEST:8.317 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:37:04.745: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 01:37:04.764: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Creating first CR 
Dec 17 01:37:05.321: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-17T01:37:05Z generation:1 name:name1 resourceVersion:17815 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:8466fa87-2061-4140-8f6c-76dadb2d6322] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Dec 17 01:37:15.325: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-17T01:37:15Z generation:1 name:name2 resourceVersion:17836 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:44ef1739-2d02-4f45-8a7c-283405a74c60] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Dec 17 01:37:25.329: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-17T01:37:05Z generation:2 name:name1 resourceVersion:17858 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:8466fa87-2061-4140-8f6c-76dadb2d6322] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Dec 17 01:37:35.333: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-17T01:37:15Z generation:2 name:name2 resourceVersion:17878 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:44ef1739-2d02-4f45-8a7c-283405a74c60] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Dec 17 01:37:45.340: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-17T01:37:05Z generation:2 name:name1 resourceVersion:17899 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:8466fa87-2061-4140-8f6c-76dadb2d6322] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Dec 17 01:37:55.344: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-17T01:37:15Z generation:2 name:name2 resourceVersion:17919 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:44ef1739-2d02-4f45-8a7c-283405a74c60] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:38:05.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-2834" for this suite.
Dec 17 01:38:11.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:38:11.941: INFO: namespace crd-watch-2834 deletion completed in 6.085442698s

â€¢ [SLOW TEST:67.196 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:38:11.942: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:38:23.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6796" for this suite.
Dec 17 01:38:29.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:38:29.093: INFO: namespace resourcequota-6796 deletion completed in 6.089504067s

â€¢ [SLOW TEST:17.151 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:38:29.093: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:38:53.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-577" for this suite.
Dec 17 01:38:59.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:38:59.336: INFO: namespace container-runtime-577 deletion completed in 6.06795437s

â€¢ [SLOW TEST:30.243 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:38:59.336: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Dec 17 01:38:59.357: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:39:15.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7556" for this suite.
Dec 17 01:39:21.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:39:21.264: INFO: namespace crd-publish-openapi-7556 deletion completed in 6.060341533s

â€¢ [SLOW TEST:21.928 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:39:21.265: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-de79e184-791f-4e01-b23b-6a761be844b9
STEP: Creating a pod to test consume secrets
Dec 17 01:39:21.289: INFO: Waiting up to 5m0s for pod "pod-secrets-48fee389-1672-413c-913e-f991708aae9d" in namespace "secrets-8201" to be "success or failure"
Dec 17 01:39:21.292: INFO: Pod "pod-secrets-48fee389-1672-413c-913e-f991708aae9d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.137339ms
Dec 17 01:39:23.294: INFO: Pod "pod-secrets-48fee389-1672-413c-913e-f991708aae9d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004985057s
STEP: Saw pod success
Dec 17 01:39:23.295: INFO: Pod "pod-secrets-48fee389-1672-413c-913e-f991708aae9d" satisfied condition "success or failure"
Dec 17 01:39:23.296: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-secrets-48fee389-1672-413c-913e-f991708aae9d container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 01:39:23.317: INFO: Waiting for pod pod-secrets-48fee389-1672-413c-913e-f991708aae9d to disappear
Dec 17 01:39:23.318: INFO: Pod pod-secrets-48fee389-1672-413c-913e-f991708aae9d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:39:23.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8201" for this suite.
Dec 17 01:39:29.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:39:29.386: INFO: namespace secrets-8201 deletion completed in 6.065409751s

â€¢ [SLOW TEST:8.121 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:39:29.386: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 01:39:29.412: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9f25b648-9da7-43db-a42e-58e2dbadef35" in namespace "downward-api-3727" to be "success or failure"
Dec 17 01:39:29.414: INFO: Pod "downwardapi-volume-9f25b648-9da7-43db-a42e-58e2dbadef35": Phase="Pending", Reason="", readiness=false. Elapsed: 1.935106ms
Dec 17 01:39:31.416: INFO: Pod "downwardapi-volume-9f25b648-9da7-43db-a42e-58e2dbadef35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004232695s
STEP: Saw pod success
Dec 17 01:39:31.416: INFO: Pod "downwardapi-volume-9f25b648-9da7-43db-a42e-58e2dbadef35" satisfied condition "success or failure"
Dec 17 01:39:31.418: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod downwardapi-volume-9f25b648-9da7-43db-a42e-58e2dbadef35 container client-container: <nil>
STEP: delete the pod
Dec 17 01:39:31.431: INFO: Waiting for pod downwardapi-volume-9f25b648-9da7-43db-a42e-58e2dbadef35 to disappear
Dec 17 01:39:31.432: INFO: Pod downwardapi-volume-9f25b648-9da7-43db-a42e-58e2dbadef35 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:39:31.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3727" for this suite.
Dec 17 01:39:37.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:39:37.503: INFO: namespace downward-api-3727 deletion completed in 6.068176732s

â€¢ [SLOW TEST:8.117 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:39:37.503: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 17 01:39:41.556: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 17 01:39:41.558: INFO: Pod pod-with-prestop-http-hook still exists
Dec 17 01:39:43.558: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 17 01:39:43.561: INFO: Pod pod-with-prestop-http-hook still exists
Dec 17 01:39:45.558: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 17 01:39:45.561: INFO: Pod pod-with-prestop-http-hook still exists
Dec 17 01:39:47.558: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 17 01:39:47.560: INFO: Pod pod-with-prestop-http-hook still exists
Dec 17 01:39:49.558: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 17 01:39:49.561: INFO: Pod pod-with-prestop-http-hook still exists
Dec 17 01:39:51.558: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 17 01:39:51.561: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:39:51.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2748" for this suite.
Dec 17 01:40:03.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:40:03.638: INFO: namespace container-lifecycle-hook-2748 deletion completed in 12.068654249s

â€¢ [SLOW TEST:26.136 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:40:03.639: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-f01a0e75-88d0-4d6c-8efb-cecc988c51ac
STEP: Creating a pod to test consume configMaps
Dec 17 01:40:03.662: INFO: Waiting up to 5m0s for pod "pod-configmaps-82fb9904-a2d9-40b4-ba2a-7b575e284bec" in namespace "configmap-1632" to be "success or failure"
Dec 17 01:40:03.665: INFO: Pod "pod-configmaps-82fb9904-a2d9-40b4-ba2a-7b575e284bec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.167226ms
Dec 17 01:40:05.667: INFO: Pod "pod-configmaps-82fb9904-a2d9-40b4-ba2a-7b575e284bec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004298287s
STEP: Saw pod success
Dec 17 01:40:05.667: INFO: Pod "pod-configmaps-82fb9904-a2d9-40b4-ba2a-7b575e284bec" satisfied condition "success or failure"
Dec 17 01:40:05.669: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-configmaps-82fb9904-a2d9-40b4-ba2a-7b575e284bec container configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 01:40:05.680: INFO: Waiting for pod pod-configmaps-82fb9904-a2d9-40b4-ba2a-7b575e284bec to disappear
Dec 17 01:40:05.682: INFO: Pod pod-configmaps-82fb9904-a2d9-40b4-ba2a-7b575e284bec no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:40:05.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1632" for this suite.
Dec 17 01:40:11.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:40:11.756: INFO: namespace configmap-1632 deletion completed in 6.071803531s

â€¢ [SLOW TEST:8.117 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:40:11.756: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2023.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-2023.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2023.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2023.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-2023.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2023.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 17 01:40:13.807: INFO: DNS probes using dns-2023/dns-test-7bf35738-b0e1-4e14-992b-192ee1b32ad7 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:40:13.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2023" for this suite.
Dec 17 01:40:19.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:40:19.882: INFO: namespace dns-2023 deletion completed in 6.06555255s

â€¢ [SLOW TEST:8.126 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:40:19.882: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-5428
STEP: creating replication controller nodeport-test in namespace services-5428
I1217 01:40:19.915125      21 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-5428, replica count: 2
I1217 01:40:22.965582      21 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 17 01:40:22.965: INFO: Creating new exec pod
Dec 17 01:40:25.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=services-5428 execpodmptn7 -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Dec 17 01:40:26.155: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Dec 17 01:40:26.155: INFO: stdout: ""
Dec 17 01:40:26.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=services-5428 execpodmptn7 -- /bin/sh -x -c nc -zv -t -w 2 100.71.80.170 80'
Dec 17 01:40:26.320: INFO: stderr: "+ nc -zv -t -w 2 100.71.80.170 80\nConnection to 100.71.80.170 80 port [tcp/http] succeeded!\n"
Dec 17 01:40:26.320: INFO: stdout: ""
Dec 17 01:40:26.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=services-5428 execpodmptn7 -- /bin/sh -x -c nc -zv -t -w 2 172.20.34.147 32561'
Dec 17 01:40:26.481: INFO: stderr: "+ nc -zv -t -w 2 172.20.34.147 32561\nConnection to 172.20.34.147 32561 port [tcp/32561] succeeded!\n"
Dec 17 01:40:26.481: INFO: stdout: ""
Dec 17 01:40:26.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=services-5428 execpodmptn7 -- /bin/sh -x -c nc -zv -t -w 2 172.20.58.188 32561'
Dec 17 01:40:26.665: INFO: stderr: "+ nc -zv -t -w 2 172.20.58.188 32561\nConnection to 172.20.58.188 32561 port [tcp/32561] succeeded!\n"
Dec 17 01:40:26.665: INFO: stdout: ""
Dec 17 01:40:26.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=services-5428 execpodmptn7 -- /bin/sh -x -c nc -zv -t -w 2 3.135.191.120 32561'
Dec 17 01:40:26.835: INFO: stderr: "+ nc -zv -t -w 2 3.135.191.120 32561\nConnection to 3.135.191.120 32561 port [tcp/32561] succeeded!\n"
Dec 17 01:40:26.835: INFO: stdout: ""
Dec 17 01:40:26.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=services-5428 execpodmptn7 -- /bin/sh -x -c nc -zv -t -w 2 3.136.26.172 32561'
Dec 17 01:40:26.995: INFO: stderr: "+ nc -zv -t -w 2 3.136.26.172 32561\nConnection to 3.136.26.172 32561 port [tcp/32561] succeeded!\n"
Dec 17 01:40:26.995: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:40:26.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5428" for this suite.
Dec 17 01:40:33.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:40:33.064: INFO: namespace services-5428 deletion completed in 6.065957083s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:13.182 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:40:33.064: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:40:35.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3287" for this suite.
Dec 17 01:40:41.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:40:41.187: INFO: namespace emptydir-wrapper-3287 deletion completed in 6.064200368s

â€¢ [SLOW TEST:8.123 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:40:41.188: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Dec 17 01:40:41.722: INFO: created pod pod-service-account-defaultsa
Dec 17 01:40:41.722: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec 17 01:40:41.731: INFO: created pod pod-service-account-mountsa
Dec 17 01:40:41.731: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec 17 01:40:41.739: INFO: created pod pod-service-account-nomountsa
Dec 17 01:40:41.739: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec 17 01:40:41.744: INFO: created pod pod-service-account-defaultsa-mountspec
Dec 17 01:40:41.744: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec 17 01:40:41.760: INFO: created pod pod-service-account-mountsa-mountspec
Dec 17 01:40:41.760: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec 17 01:40:41.775: INFO: created pod pod-service-account-nomountsa-mountspec
Dec 17 01:40:41.775: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec 17 01:40:41.784: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec 17 01:40:41.784: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec 17 01:40:41.793: INFO: created pod pod-service-account-mountsa-nomountspec
Dec 17 01:40:41.793: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec 17 01:40:41.802: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec 17 01:40:41.802: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:40:41.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7405" for this suite.
Dec 17 01:42:15.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:42:15.870: INFO: namespace svcaccounts-7405 deletion completed in 1m34.059109727s

â€¢ [SLOW TEST:94.682 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:42:15.870: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 01:42:15.892: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bdb11a7d-d30c-4735-8077-484686f93b7f" in namespace "downward-api-9101" to be "success or failure"
Dec 17 01:42:15.897: INFO: Pod "downwardapi-volume-bdb11a7d-d30c-4735-8077-484686f93b7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.752756ms
Dec 17 01:42:17.900: INFO: Pod "downwardapi-volume-bdb11a7d-d30c-4735-8077-484686f93b7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007476751s
STEP: Saw pod success
Dec 17 01:42:17.900: INFO: Pod "downwardapi-volume-bdb11a7d-d30c-4735-8077-484686f93b7f" satisfied condition "success or failure"
Dec 17 01:42:17.902: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod downwardapi-volume-bdb11a7d-d30c-4735-8077-484686f93b7f container client-container: <nil>
STEP: delete the pod
Dec 17 01:42:17.925: INFO: Waiting for pod downwardapi-volume-bdb11a7d-d30c-4735-8077-484686f93b7f to disappear
Dec 17 01:42:17.927: INFO: Pod downwardapi-volume-bdb11a7d-d30c-4735-8077-484686f93b7f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:42:17.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9101" for this suite.
Dec 17 01:42:23.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:42:23.997: INFO: namespace downward-api-9101 deletion completed in 6.067696185s

â€¢ [SLOW TEST:8.127 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:42:23.998: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 17 01:42:24.023: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 17 01:42:24.030: INFO: Waiting for terminating namespaces to be deleted...
Dec 17 01:42:24.032: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-34-147.us-east-2.compute.internal before test
Dec 17 01:42:24.044: INFO: sonobuoy from sonobuoy started at 2019-12-17 00:16:34 +0000 UTC (1 container statuses recorded)
Dec 17 01:42:24.044: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 17 01:42:24.044: INFO: kube-proxy-ip-172-20-34-147.us-east-2.compute.internal from kube-system started at 2019-12-17 00:10:42 +0000 UTC (1 container statuses recorded)
Dec 17 01:42:24.044: INFO: 	Container kube-proxy ready: true, restart count 5
Dec 17 01:42:24.044: INFO: kube-dns-bb55d6458-982k4 from kube-system started at 2019-12-17 00:50:49 +0000 UTC (3 container statuses recorded)
Dec 17 01:42:24.044: INFO: 	Container dnsmasq ready: true, restart count 0
Dec 17 01:42:24.044: INFO: 	Container kubedns ready: true, restart count 0
Dec 17 01:42:24.044: INFO: 	Container sidecar ready: true, restart count 0
Dec 17 01:42:24.044: INFO: kube-dns-autoscaler-66b775459-2bh8z from kube-system started at 2019-12-17 00:50:49 +0000 UTC (1 container statuses recorded)
Dec 17 01:42:24.044: INFO: 	Container autoscaler ready: true, restart count 0
Dec 17 01:42:24.044: INFO: kube-dns-bb55d6458-qz7ks from kube-system started at 2019-12-17 00:15:20 +0000 UTC (3 container statuses recorded)
Dec 17 01:42:24.044: INFO: 	Container dnsmasq ready: true, restart count 0
Dec 17 01:42:24.044: INFO: 	Container kubedns ready: true, restart count 0
Dec 17 01:42:24.044: INFO: 	Container sidecar ready: true, restart count 0
Dec 17 01:42:24.044: INFO: sonobuoy-e2e-job-edd513b56d7b4d93 from sonobuoy started at 2019-12-17 00:16:40 +0000 UTC (2 container statuses recorded)
Dec 17 01:42:24.044: INFO: 	Container e2e ready: true, restart count 0
Dec 17 01:42:24.044: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 17 01:42:24.044: INFO: sonobuoy-systemd-logs-daemon-set-aa23d16e52f14f6e-l6lh6 from sonobuoy started at 2019-12-17 00:16:40 +0000 UTC (2 container statuses recorded)
Dec 17 01:42:24.044: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 17 01:42:24.044: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 17 01:42:24.044: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-58-188.us-east-2.compute.internal before test
Dec 17 01:42:24.048: INFO: sonobuoy-systemd-logs-daemon-set-aa23d16e52f14f6e-dk4ms from sonobuoy started at 2019-12-17 00:16:40 +0000 UTC (2 container statuses recorded)
Dec 17 01:42:24.048: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 17 01:42:24.048: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 17 01:42:24.048: INFO: kube-proxy-ip-172-20-58-188.us-east-2.compute.internal from kube-system started at 2019-12-17 00:10:40 +0000 UTC (1 container statuses recorded)
Dec 17 01:42:24.048: INFO: 	Container kube-proxy ready: true, restart count 5
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15e10517bc2d0968], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:42:25.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4361" for this suite.
Dec 17 01:42:31.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:42:31.126: INFO: namespace sched-pred-4361 deletion completed in 6.061835427s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

â€¢ [SLOW TEST:7.128 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:42:31.126: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 01:42:31.952: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 01:42:34.968: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:42:35.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7818" for this suite.
Dec 17 01:42:47.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:42:47.068: INFO: namespace webhook-7818 deletion completed in 12.061330369s
STEP: Destroying namespace "webhook-7818-markers" for this suite.
Dec 17 01:42:53.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:42:53.133: INFO: namespace webhook-7818-markers deletion completed in 6.065630503s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:22.015 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:42:53.142: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 01:42:53.930: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 17 01:42:55.938: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712143773, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712143773, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712143773, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712143773, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 01:42:58.948: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:42:58.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5273" for this suite.
Dec 17 01:43:04.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:43:05.013: INFO: namespace webhook-5273 deletion completed in 6.056389465s
STEP: Destroying namespace "webhook-5273-markers" for this suite.
Dec 17 01:43:11.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:43:11.080: INFO: namespace webhook-5273-markers deletion completed in 6.066197912s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:17.947 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:43:11.089: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Dec 17 01:43:11.112: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-8584" to be "success or failure"
Dec 17 01:43:11.119: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 6.650629ms
Dec 17 01:43:13.121: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009103575s
STEP: Saw pod success
Dec 17 01:43:13.121: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec 17 01:43:13.123: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec 17 01:43:13.140: INFO: Waiting for pod pod-host-path-test to disappear
Dec 17 01:43:13.143: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:43:13.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-8584" for this suite.
Dec 17 01:43:19.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:43:19.218: INFO: namespace hostpath-8584 deletion completed in 6.072712189s

â€¢ [SLOW TEST:8.130 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:43:19.219: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-b4c686c7-1262-4f29-8e42-8e84ac42c69c
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:43:19.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2717" for this suite.
Dec 17 01:43:25.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:43:25.301: INFO: namespace secrets-2717 deletion completed in 6.058130533s

â€¢ [SLOW TEST:6.082 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:43:25.301: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9177.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9177.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9177.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9177.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 17 01:43:27.337: INFO: File wheezy_udp@dns-test-service-3.dns-9177.svc.cluster.local from pod  dns-9177/dns-test-8c7ece6b-1ff6-458c-bd2a-16b7368d8694 contains '' instead of 'foo.example.com.'
Dec 17 01:43:27.339: INFO: Lookups using dns-9177/dns-test-8c7ece6b-1ff6-458c-bd2a-16b7368d8694 failed for: [wheezy_udp@dns-test-service-3.dns-9177.svc.cluster.local]

Dec 17 01:43:32.344: INFO: DNS probes using dns-test-8c7ece6b-1ff6-458c-bd2a-16b7368d8694 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9177.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9177.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9177.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9177.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 17 01:43:34.373: INFO: File wheezy_udp@dns-test-service-3.dns-9177.svc.cluster.local from pod  dns-9177/dns-test-34bd439a-df82-43ab-97bb-b999dd3ecac0 contains '' instead of 'bar.example.com.'
Dec 17 01:43:34.376: INFO: Lookups using dns-9177/dns-test-34bd439a-df82-43ab-97bb-b999dd3ecac0 failed for: [wheezy_udp@dns-test-service-3.dns-9177.svc.cluster.local]

Dec 17 01:43:39.383: INFO: DNS probes using dns-test-34bd439a-df82-43ab-97bb-b999dd3ecac0 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9177.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-9177.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9177.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-9177.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 17 01:43:41.438: INFO: DNS probes using dns-test-1408a346-9030-4565-85e7-9c893e8494f2 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:43:41.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9177" for this suite.
Dec 17 01:43:47.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:43:47.518: INFO: namespace dns-9177 deletion completed in 6.057312283s

â€¢ [SLOW TEST:22.217 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:43:47.518: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2226
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Dec 17 01:43:47.547: INFO: Found 0 stateful pods, waiting for 3
Dec 17 01:43:57.550: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 01:43:57.550: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 01:43:57.550: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 01:43:57.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-2226 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 17 01:43:57.727: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 17 01:43:57.727: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 17 01:43:57.727: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec 17 01:44:07.751: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec 17 01:44:17.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-2226 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 01:44:17.932: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 17 01:44:17.932: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 17 01:44:17.932: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

STEP: Rolling back to a previous revision
Dec 17 01:44:37.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-2226 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 17 01:44:38.123: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 17 01:44:38.123: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 17 01:44:38.123: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 17 01:44:48.154: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec 17 01:44:58.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=statefulset-2226 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 01:44:58.495: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 17 01:44:58.495: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 17 01:44:58.495: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 17 01:45:18.510: INFO: Waiting for StatefulSet statefulset-2226/ss2 to complete update
Dec 17 01:45:18.510: INFO: Waiting for Pod statefulset-2226/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 17 01:45:28.515: INFO: Deleting all statefulset in ns statefulset-2226
Dec 17 01:45:28.516: INFO: Scaling statefulset ss2 to 0
Dec 17 01:45:38.526: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 01:45:38.527: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:45:38.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2226" for this suite.
Dec 17 01:45:44.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:45:44.612: INFO: namespace statefulset-2226 deletion completed in 6.075399554s

â€¢ [SLOW TEST:117.094 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:45:44.613: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-ljpp
STEP: Creating a pod to test atomic-volume-subpath
Dec 17 01:45:44.644: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-ljpp" in namespace "subpath-3406" to be "success or failure"
Dec 17 01:45:44.652: INFO: Pod "pod-subpath-test-downwardapi-ljpp": Phase="Pending", Reason="", readiness=false. Elapsed: 7.842247ms
Dec 17 01:45:46.654: INFO: Pod "pod-subpath-test-downwardapi-ljpp": Phase="Running", Reason="", readiness=true. Elapsed: 2.010340499s
Dec 17 01:45:48.661: INFO: Pod "pod-subpath-test-downwardapi-ljpp": Phase="Running", Reason="", readiness=true. Elapsed: 4.016899914s
Dec 17 01:45:50.664: INFO: Pod "pod-subpath-test-downwardapi-ljpp": Phase="Running", Reason="", readiness=true. Elapsed: 6.019957621s
Dec 17 01:45:52.666: INFO: Pod "pod-subpath-test-downwardapi-ljpp": Phase="Running", Reason="", readiness=true. Elapsed: 8.02227293s
Dec 17 01:45:54.669: INFO: Pod "pod-subpath-test-downwardapi-ljpp": Phase="Running", Reason="", readiness=true. Elapsed: 10.024659969s
Dec 17 01:45:56.672: INFO: Pod "pod-subpath-test-downwardapi-ljpp": Phase="Running", Reason="", readiness=true. Elapsed: 12.027969093s
Dec 17 01:45:58.675: INFO: Pod "pod-subpath-test-downwardapi-ljpp": Phase="Running", Reason="", readiness=true. Elapsed: 14.030938293s
Dec 17 01:46:00.677: INFO: Pod "pod-subpath-test-downwardapi-ljpp": Phase="Running", Reason="", readiness=true. Elapsed: 16.033640074s
Dec 17 01:46:02.680: INFO: Pod "pod-subpath-test-downwardapi-ljpp": Phase="Running", Reason="", readiness=true. Elapsed: 18.036325645s
Dec 17 01:46:04.683: INFO: Pod "pod-subpath-test-downwardapi-ljpp": Phase="Running", Reason="", readiness=true. Elapsed: 20.038791975s
Dec 17 01:46:06.685: INFO: Pod "pod-subpath-test-downwardapi-ljpp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.041539202s
STEP: Saw pod success
Dec 17 01:46:06.685: INFO: Pod "pod-subpath-test-downwardapi-ljpp" satisfied condition "success or failure"
Dec 17 01:46:06.687: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-subpath-test-downwardapi-ljpp container test-container-subpath-downwardapi-ljpp: <nil>
STEP: delete the pod
Dec 17 01:46:06.708: INFO: Waiting for pod pod-subpath-test-downwardapi-ljpp to disappear
Dec 17 01:46:06.717: INFO: Pod pod-subpath-test-downwardapi-ljpp no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-ljpp
Dec 17 01:46:06.717: INFO: Deleting pod "pod-subpath-test-downwardapi-ljpp" in namespace "subpath-3406"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:46:06.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3406" for this suite.
Dec 17 01:46:12.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:46:12.796: INFO: namespace subpath-3406 deletion completed in 6.074057591s

â€¢ [SLOW TEST:28.184 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:46:12.796: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-e7c3943d-08e5-44f6-aadc-da70a85a1c40
STEP: Creating a pod to test consume configMaps
Dec 17 01:46:12.823: INFO: Waiting up to 5m0s for pod "pod-configmaps-4ffa7866-9ab9-4d8c-b580-6d4dc948b817" in namespace "configmap-1345" to be "success or failure"
Dec 17 01:46:12.827: INFO: Pod "pod-configmaps-4ffa7866-9ab9-4d8c-b580-6d4dc948b817": Phase="Pending", Reason="", readiness=false. Elapsed: 3.763289ms
Dec 17 01:46:14.830: INFO: Pod "pod-configmaps-4ffa7866-9ab9-4d8c-b580-6d4dc948b817": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006587265s
STEP: Saw pod success
Dec 17 01:46:14.830: INFO: Pod "pod-configmaps-4ffa7866-9ab9-4d8c-b580-6d4dc948b817" satisfied condition "success or failure"
Dec 17 01:46:14.832: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-configmaps-4ffa7866-9ab9-4d8c-b580-6d4dc948b817 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 01:46:14.847: INFO: Waiting for pod pod-configmaps-4ffa7866-9ab9-4d8c-b580-6d4dc948b817 to disappear
Dec 17 01:46:14.850: INFO: Pod pod-configmaps-4ffa7866-9ab9-4d8c-b580-6d4dc948b817 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:46:14.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1345" for this suite.
Dec 17 01:46:20.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:46:20.923: INFO: namespace configmap-1345 deletion completed in 6.07027979s

â€¢ [SLOW TEST:8.126 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:46:20.923: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-2d091b4b-85d7-4964-b288-ba1e987d3c2c
STEP: Creating a pod to test consume configMaps
Dec 17 01:46:20.948: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d34e80a1-dc77-4c70-8be2-9c99987cea7d" in namespace "projected-2911" to be "success or failure"
Dec 17 01:46:20.951: INFO: Pod "pod-projected-configmaps-d34e80a1-dc77-4c70-8be2-9c99987cea7d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.611026ms
Dec 17 01:46:22.958: INFO: Pod "pod-projected-configmaps-d34e80a1-dc77-4c70-8be2-9c99987cea7d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01025715s
STEP: Saw pod success
Dec 17 01:46:22.959: INFO: Pod "pod-projected-configmaps-d34e80a1-dc77-4c70-8be2-9c99987cea7d" satisfied condition "success or failure"
Dec 17 01:46:22.960: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-projected-configmaps-d34e80a1-dc77-4c70-8be2-9c99987cea7d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 01:46:22.975: INFO: Waiting for pod pod-projected-configmaps-d34e80a1-dc77-4c70-8be2-9c99987cea7d to disappear
Dec 17 01:46:22.977: INFO: Pod pod-projected-configmaps-d34e80a1-dc77-4c70-8be2-9c99987cea7d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:46:22.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2911" for this suite.
Dec 17 01:46:28.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:46:29.051: INFO: namespace projected-2911 deletion completed in 6.071286943s

â€¢ [SLOW TEST:8.128 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:46:29.051: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-2d5702c1-98ef-435d-83ef-594a4c06d219
STEP: Creating a pod to test consume configMaps
Dec 17 01:46:29.127: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7a8fe3cd-3fb9-4e1a-a33c-fee6fa2e6aa9" in namespace "projected-6232" to be "success or failure"
Dec 17 01:46:29.130: INFO: Pod "pod-projected-configmaps-7a8fe3cd-3fb9-4e1a-a33c-fee6fa2e6aa9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.319639ms
Dec 17 01:46:31.133: INFO: Pod "pod-projected-configmaps-7a8fe3cd-3fb9-4e1a-a33c-fee6fa2e6aa9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005957898s
STEP: Saw pod success
Dec 17 01:46:31.133: INFO: Pod "pod-projected-configmaps-7a8fe3cd-3fb9-4e1a-a33c-fee6fa2e6aa9" satisfied condition "success or failure"
Dec 17 01:46:31.135: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-projected-configmaps-7a8fe3cd-3fb9-4e1a-a33c-fee6fa2e6aa9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 01:46:31.150: INFO: Waiting for pod pod-projected-configmaps-7a8fe3cd-3fb9-4e1a-a33c-fee6fa2e6aa9 to disappear
Dec 17 01:46:31.154: INFO: Pod pod-projected-configmaps-7a8fe3cd-3fb9-4e1a-a33c-fee6fa2e6aa9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:46:31.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6232" for this suite.
Dec 17 01:46:37.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:46:37.233: INFO: namespace projected-6232 deletion completed in 6.076360371s

â€¢ [SLOW TEST:8.182 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:46:37.233: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 01:46:37.258: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d753e494-b3f8-4c9c-a14a-396296f512b3" in namespace "projected-4834" to be "success or failure"
Dec 17 01:46:37.274: INFO: Pod "downwardapi-volume-d753e494-b3f8-4c9c-a14a-396296f512b3": Phase="Pending", Reason="", readiness=false. Elapsed: 16.757665ms
Dec 17 01:46:39.277: INFO: Pod "downwardapi-volume-d753e494-b3f8-4c9c-a14a-396296f512b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01948604s
STEP: Saw pod success
Dec 17 01:46:39.277: INFO: Pod "downwardapi-volume-d753e494-b3f8-4c9c-a14a-396296f512b3" satisfied condition "success or failure"
Dec 17 01:46:39.279: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod downwardapi-volume-d753e494-b3f8-4c9c-a14a-396296f512b3 container client-container: <nil>
STEP: delete the pod
Dec 17 01:46:39.295: INFO: Waiting for pod downwardapi-volume-d753e494-b3f8-4c9c-a14a-396296f512b3 to disappear
Dec 17 01:46:39.297: INFO: Pod downwardapi-volume-d753e494-b3f8-4c9c-a14a-396296f512b3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:46:39.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4834" for this suite.
Dec 17 01:46:45.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:46:45.369: INFO: namespace projected-4834 deletion completed in 6.070396271s

â€¢ [SLOW TEST:8.136 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:46:45.369: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-a72b530e-b6e5-4609-a8ed-3ac02d396153 in namespace container-probe-8950
Dec 17 01:46:47.401: INFO: Started pod busybox-a72b530e-b6e5-4609-a8ed-3ac02d396153 in namespace container-probe-8950
STEP: checking the pod's current state and verifying that restartCount is present
Dec 17 01:46:47.402: INFO: Initial restart count of pod busybox-a72b530e-b6e5-4609-a8ed-3ac02d396153 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:50:47.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8950" for this suite.
Dec 17 01:50:53.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:50:53.819: INFO: namespace container-probe-8950 deletion completed in 6.067429041s

â€¢ [SLOW TEST:248.450 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:50:53.819: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 01:50:53.842: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-34c89ddc-f0f6-4c64-b36e-24b0eb616481" in namespace "security-context-test-3776" to be "success or failure"
Dec 17 01:50:53.844: INFO: Pod "busybox-readonly-false-34c89ddc-f0f6-4c64-b36e-24b0eb616481": Phase="Pending", Reason="", readiness=false. Elapsed: 2.267566ms
Dec 17 01:50:55.848: INFO: Pod "busybox-readonly-false-34c89ddc-f0f6-4c64-b36e-24b0eb616481": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005348267s
Dec 17 01:50:55.848: INFO: Pod "busybox-readonly-false-34c89ddc-f0f6-4c64-b36e-24b0eb616481" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:50:55.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3776" for this suite.
Dec 17 01:51:01.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:51:01.911: INFO: namespace security-context-test-3776 deletion completed in 6.061043935s

â€¢ [SLOW TEST:8.092 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:51:01.912: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 01:51:02.476: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 01:51:05.489: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 01:51:05.491: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-839-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:51:06.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4722" for this suite.
Dec 17 01:51:12.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:51:12.155: INFO: namespace webhook-4722 deletion completed in 6.06830454s
STEP: Destroying namespace "webhook-4722-markers" for this suite.
Dec 17 01:51:18.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:51:18.224: INFO: namespace webhook-4722-markers deletion completed in 6.069059315s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:16.321 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:51:18.232: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 17 01:51:20.784: INFO: Successfully updated pod "pod-update-d5bf1ee2-001f-45a4-a279-3f8264570a85"
STEP: verifying the updated pod is in kubernetes
Dec 17 01:51:20.788: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:51:20.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3986" for this suite.
Dec 17 01:51:32.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:51:32.848: INFO: namespace pods-3986 deletion completed in 12.057545155s

â€¢ [SLOW TEST:14.616 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:51:32.849: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 17 01:51:32.877: INFO: PodSpec: initContainers in spec.initContainers
Dec 17 01:52:17.859: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-e0499399-cbee-4128-8f70-f547c063d0d9", GenerateName:"", Namespace:"init-container-7342", SelfLink:"/api/v1/namespaces/init-container-7342/pods/pod-init-e0499399-cbee-4128-8f70-f547c063d0d9", UID:"126adcf9-b820-4ddd-a3b2-6f9c39b655a4", ResourceVersion:"20527", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63712144292, loc:(*time.Location)(0x84bfb00)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"877880178"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-tvqmf", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc003d55c40), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-tvqmf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-tvqmf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-tvqmf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc004166838), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-20-58-188.us-east-2.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0030e8840), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0041668b0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0041668d0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0041668d8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0041668dc), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712144292, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712144292, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712144292, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712144292, loc:(*time.Location)(0x84bfb00)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.20.58.188", PodIP:"100.96.1.28", PodIPs:[]v1.PodIP{v1.PodIP{IP:"100.96.1.28"}}, StartTime:(*v1.Time)(0xc00302bb20), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001ba4700)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001ba47e0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://87e2b2643a344b926ea6f2687afbd7354eb3e98c2cc75821b963e52170f16929", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00302bb60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00302bb40), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc00416695f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:52:17.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7342" for this suite.
Dec 17 01:52:45.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:52:45.925: INFO: namespace init-container-7342 deletion completed in 28.062558457s

â€¢ [SLOW TEST:73.077 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:52:45.926: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Dec 17 01:52:45.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-633 -- logs-generator --log-lines-total 100 --run-duration 20s'
Dec 17 01:52:46.031: INFO: stderr: ""
Dec 17 01:52:46.031: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Dec 17 01:52:46.031: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Dec 17 01:52:46.031: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-633" to be "running and ready, or succeeded"
Dec 17 01:52:46.033: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.144135ms
Dec 17 01:52:48.036: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.004747767s
Dec 17 01:52:48.036: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Dec 17 01:52:48.036: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Dec 17 01:52:48.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 logs logs-generator logs-generator --namespace=kubectl-633'
Dec 17 01:52:48.122: INFO: stderr: ""
Dec 17 01:52:48.122: INFO: stdout: "I1217 01:52:46.830164       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/wgc 549\nI1217 01:52:47.030454       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/955w 403\nI1217 01:52:47.230421       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/4f49 221\nI1217 01:52:47.430367       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/qjdt 374\nI1217 01:52:47.630444       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/c6p 441\nI1217 01:52:47.830474       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/m2m 411\nI1217 01:52:48.030442       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/kcq 324\n"
STEP: limiting log lines
Dec 17 01:52:48.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 logs logs-generator logs-generator --namespace=kubectl-633 --tail=1'
Dec 17 01:52:48.200: INFO: stderr: ""
Dec 17 01:52:48.200: INFO: stdout: "I1217 01:52:48.030442       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/kcq 324\n"
STEP: limiting log bytes
Dec 17 01:52:48.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 logs logs-generator logs-generator --namespace=kubectl-633 --limit-bytes=1'
Dec 17 01:52:48.280: INFO: stderr: ""
Dec 17 01:52:48.280: INFO: stdout: "I"
STEP: exposing timestamps
Dec 17 01:52:48.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 logs logs-generator logs-generator --namespace=kubectl-633 --tail=1 --timestamps'
Dec 17 01:52:48.358: INFO: stderr: ""
Dec 17 01:52:48.358: INFO: stdout: "2019-12-17T01:52:48.230577493Z I1217 01:52:48.230431       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/brc 392\n"
STEP: restricting to a time range
Dec 17 01:52:50.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 logs logs-generator logs-generator --namespace=kubectl-633 --since=1s'
Dec 17 01:52:50.947: INFO: stderr: ""
Dec 17 01:52:50.947: INFO: stdout: "I1217 01:52:50.030407       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/7n5 227\nI1217 01:52:50.230416       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/gvzb 294\nI1217 01:52:50.430436       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/bv4k 503\nI1217 01:52:50.630419       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/mjb 327\nI1217 01:52:50.830419       1 logs_generator.go:76] 20 POST /api/v1/namespaces/ns/pods/plq6 508\n"
Dec 17 01:52:50.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 logs logs-generator logs-generator --namespace=kubectl-633 --since=24h'
Dec 17 01:52:51.032: INFO: stderr: ""
Dec 17 01:52:51.032: INFO: stdout: "I1217 01:52:46.830164       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/wgc 549\nI1217 01:52:47.030454       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/955w 403\nI1217 01:52:47.230421       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/4f49 221\nI1217 01:52:47.430367       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/qjdt 374\nI1217 01:52:47.630444       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/c6p 441\nI1217 01:52:47.830474       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/m2m 411\nI1217 01:52:48.030442       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/kcq 324\nI1217 01:52:48.230431       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/brc 392\nI1217 01:52:48.430403       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/ts8v 414\nI1217 01:52:48.630390       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/drd2 487\nI1217 01:52:48.830394       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/kube-system/pods/j6xg 344\nI1217 01:52:49.030385       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/m2n 547\nI1217 01:52:49.230389       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/g2k 503\nI1217 01:52:49.430401       1 logs_generator.go:76] 13 GET /api/v1/namespaces/default/pods/9pw 417\nI1217 01:52:49.630410       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/default/pods/cg5 571\nI1217 01:52:49.830422       1 logs_generator.go:76] 15 GET /api/v1/namespaces/ns/pods/98d9 275\nI1217 01:52:50.030407       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/7n5 227\nI1217 01:52:50.230416       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/gvzb 294\nI1217 01:52:50.430436       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/bv4k 503\nI1217 01:52:50.630419       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/mjb 327\nI1217 01:52:50.830419       1 logs_generator.go:76] 20 POST /api/v1/namespaces/ns/pods/plq6 508\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Dec 17 01:52:51.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 delete pod logs-generator --namespace=kubectl-633'
Dec 17 01:53:00.011: INFO: stderr: ""
Dec 17 01:53:00.011: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:53:00.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-633" for this suite.
Dec 17 01:53:06.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:53:06.081: INFO: namespace kubectl-633 deletion completed in 6.067626325s

â€¢ [SLOW TEST:20.156 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:53:06.082: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-3054
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-3054
STEP: Deleting pre-stop pod
Dec 17 01:53:15.132: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:53:15.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-3054" for this suite.
Dec 17 01:53:59.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:53:59.206: INFO: namespace prestop-3054 deletion completed in 44.066847604s

â€¢ [SLOW TEST:53.124 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:53:59.206: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:53:59.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-4826" for this suite.
Dec 17 01:54:05.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:54:05.295: INFO: namespace tables-4826 deletion completed in 6.064627463s

â€¢ [SLOW TEST:6.088 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:54:05.296: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:54:16.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6371" for this suite.
Dec 17 01:54:22.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:54:22.397: INFO: namespace resourcequota-6371 deletion completed in 6.057258978s

â€¢ [SLOW TEST:17.102 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:54:22.398: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 17 01:54:24.950: INFO: Successfully updated pod "labelsupdate20e130e7-a372-4636-9346-aa81505ee729"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:54:28.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7061" for this suite.
Dec 17 01:54:40.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:54:41.044: INFO: namespace projected-7061 deletion completed in 12.060174337s

â€¢ [SLOW TEST:18.646 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:54:41.044: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 01:54:41.528: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 01:54:44.548: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:54:44.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6972" for this suite.
Dec 17 01:54:50.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:54:50.745: INFO: namespace webhook-6972 deletion completed in 6.055955445s
STEP: Destroying namespace "webhook-6972-markers" for this suite.
Dec 17 01:54:56.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:54:56.803: INFO: namespace webhook-6972-markers deletion completed in 6.058076058s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:15.767 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:54:56.811: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 01:54:57.232: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 17 01:54:59.246: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712144497, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712144497, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712144497, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712144497, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 01:55:02.262: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:55:14.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3641" for this suite.
Dec 17 01:55:20.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:55:20.429: INFO: namespace webhook-3641 deletion completed in 6.060574923s
STEP: Destroying namespace "webhook-3641-markers" for this suite.
Dec 17 01:55:26.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:55:26.497: INFO: namespace webhook-3641-markers deletion completed in 6.068444068s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:29.697 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:55:26.508: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:55:28.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5486" for this suite.
Dec 17 01:55:46.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:55:46.636: INFO: namespace containers-5486 deletion completed in 18.088174478s

â€¢ [SLOW TEST:20.128 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:55:46.636: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:55:48.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7355" for this suite.
Dec 17 01:56:32.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:56:32.745: INFO: namespace kubelet-test-7355 deletion completed in 44.058967559s

â€¢ [SLOW TEST:46.109 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:56:32.746: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Dec 17 01:56:32.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 create -f - --namespace=kubectl-6598'
Dec 17 01:56:33.136: INFO: stderr: ""
Dec 17 01:56:33.136: INFO: stdout: "pod/pause created\n"
Dec 17 01:56:33.136: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec 17 01:56:33.136: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-6598" to be "running and ready"
Dec 17 01:56:33.142: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 6.025713ms
Dec 17 01:56:35.147: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.010484927s
Dec 17 01:56:35.147: INFO: Pod "pause" satisfied condition "running and ready"
Dec 17 01:56:35.147: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Dec 17 01:56:35.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 label pods pause testing-label=testing-label-value --namespace=kubectl-6598'
Dec 17 01:56:35.220: INFO: stderr: ""
Dec 17 01:56:35.220: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec 17 01:56:35.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pod pause -L testing-label --namespace=kubectl-6598'
Dec 17 01:56:35.286: INFO: stderr: ""
Dec 17 01:56:35.286: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec 17 01:56:35.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 label pods pause testing-label- --namespace=kubectl-6598'
Dec 17 01:56:35.358: INFO: stderr: ""
Dec 17 01:56:35.358: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec 17 01:56:35.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pod pause -L testing-label --namespace=kubectl-6598'
Dec 17 01:56:35.426: INFO: stderr: ""
Dec 17 01:56:35.426: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Dec 17 01:56:35.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 delete --grace-period=0 --force -f - --namespace=kubectl-6598'
Dec 17 01:56:35.502: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 01:56:35.502: INFO: stdout: "pod \"pause\" force deleted\n"
Dec 17 01:56:35.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get rc,svc -l name=pause --no-headers --namespace=kubectl-6598'
Dec 17 01:56:35.579: INFO: stderr: "No resources found in kubectl-6598 namespace.\n"
Dec 17 01:56:35.579: INFO: stdout: ""
Dec 17 01:56:35.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods -l name=pause --namespace=kubectl-6598 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 17 01:56:35.650: INFO: stderr: ""
Dec 17 01:56:35.650: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:56:35.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6598" for this suite.
Dec 17 01:56:41.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:56:41.719: INFO: namespace kubectl-6598 deletion completed in 6.066405412s

â€¢ [SLOW TEST:8.973 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:56:41.719: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-1790
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-1790
STEP: creating replication controller externalsvc in namespace services-1790
I1217 01:56:41.765293      21 runners.go:184] Created replication controller with name: externalsvc, namespace: services-1790, replica count: 2
I1217 01:56:44.815762      21 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Dec 17 01:56:44.828: INFO: Creating new exec pod
Dec 17 01:56:46.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=services-1790 execpod7jzmv -- /bin/sh -x -c nslookup clusterip-service'
Dec 17 01:56:47.019: INFO: stderr: "+ nslookup clusterip-service\n"
Dec 17 01:56:47.019: INFO: stdout: "Server:\t\t100.64.0.10\nAddress:\t100.64.0.10#53\n\nclusterip-service.services-1790.svc.cluster.local\tcanonical name = externalsvc.services-1790.svc.cluster.local.\nName:\texternalsvc.services-1790.svc.cluster.local\nAddress: 100.68.162.9\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-1790, will wait for the garbage collector to delete the pods
Dec 17 01:56:47.075: INFO: Deleting ReplicationController externalsvc took: 3.760104ms
Dec 17 01:56:47.375: INFO: Terminating ReplicationController externalsvc pods took: 300.289287ms
Dec 17 01:57:00.090: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:57:00.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1790" for this suite.
Dec 17 01:57:06.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:57:06.172: INFO: namespace services-1790 deletion completed in 6.059555352s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:24.453 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:57:06.172: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 17 01:57:06.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-4668'
Dec 17 01:57:06.265: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 17 01:57:06.265: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Dec 17 01:57:06.274: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-fgdx5]
Dec 17 01:57:06.274: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-fgdx5" in namespace "kubectl-4668" to be "running and ready"
Dec 17 01:57:06.277: INFO: Pod "e2e-test-httpd-rc-fgdx5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.089363ms
Dec 17 01:57:08.279: INFO: Pod "e2e-test-httpd-rc-fgdx5": Phase="Running", Reason="", readiness=true. Elapsed: 2.005486237s
Dec 17 01:57:08.279: INFO: Pod "e2e-test-httpd-rc-fgdx5" satisfied condition "running and ready"
Dec 17 01:57:08.279: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-fgdx5]
Dec 17 01:57:08.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 logs rc/e2e-test-httpd-rc --namespace=kubectl-4668'
Dec 17 01:57:08.368: INFO: stderr: ""
Dec 17 01:57:08.368: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 100.96.1.42. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 100.96.1.42. Set the 'ServerName' directive globally to suppress this message\n[Tue Dec 17 01:57:07.124305 2019] [mpm_event:notice] [pid 1:tid 140190219344744] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Tue Dec 17 01:57:07.124624 2019] [core:notice] [pid 1:tid 140190219344744] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Dec 17 01:57:08.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 delete rc e2e-test-httpd-rc --namespace=kubectl-4668'
Dec 17 01:57:08.445: INFO: stderr: ""
Dec 17 01:57:08.445: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:57:08.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4668" for this suite.
Dec 17 01:57:36.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:57:36.523: INFO: namespace kubectl-4668 deletion completed in 28.075059574s

â€¢ [SLOW TEST:30.351 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:57:36.523: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 01:57:36.550: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ba1c35c6-0bcd-4aea-bf6e-a96fdcfbbe21" in namespace "downward-api-1993" to be "success or failure"
Dec 17 01:57:36.556: INFO: Pod "downwardapi-volume-ba1c35c6-0bcd-4aea-bf6e-a96fdcfbbe21": Phase="Pending", Reason="", readiness=false. Elapsed: 5.748721ms
Dec 17 01:57:38.559: INFO: Pod "downwardapi-volume-ba1c35c6-0bcd-4aea-bf6e-a96fdcfbbe21": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009393027s
STEP: Saw pod success
Dec 17 01:57:38.559: INFO: Pod "downwardapi-volume-ba1c35c6-0bcd-4aea-bf6e-a96fdcfbbe21" satisfied condition "success or failure"
Dec 17 01:57:38.561: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod downwardapi-volume-ba1c35c6-0bcd-4aea-bf6e-a96fdcfbbe21 container client-container: <nil>
STEP: delete the pod
Dec 17 01:57:38.574: INFO: Waiting for pod downwardapi-volume-ba1c35c6-0bcd-4aea-bf6e-a96fdcfbbe21 to disappear
Dec 17 01:57:38.577: INFO: Pod downwardapi-volume-ba1c35c6-0bcd-4aea-bf6e-a96fdcfbbe21 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:57:38.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1993" for this suite.
Dec 17 01:57:44.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:57:44.644: INFO: namespace downward-api-1993 deletion completed in 6.065301029s

â€¢ [SLOW TEST:8.122 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:57:44.646: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-4221
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-4221
I1217 01:57:44.691712      21 runners.go:184] Created replication controller with name: externalname-service, namespace: services-4221, replica count: 2
Dec 17 01:57:47.742: INFO: Creating new exec pod
I1217 01:57:47.742279      21 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 17 01:57:50.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=services-4221 execpodctdz6 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec 17 01:57:50.915: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 17 01:57:50.915: INFO: stdout: ""
Dec 17 01:57:50.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=services-4221 execpodctdz6 -- /bin/sh -x -c nc -zv -t -w 2 100.67.139.1 80'
Dec 17 01:57:51.077: INFO: stderr: "+ nc -zv -t -w 2 100.67.139.1 80\nConnection to 100.67.139.1 80 port [tcp/http] succeeded!\n"
Dec 17 01:57:51.077: INFO: stdout: ""
Dec 17 01:57:51.077: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:57:51.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4221" for this suite.
Dec 17 01:57:57.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:57:57.162: INFO: namespace services-4221 deletion completed in 6.064043886s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:12.516 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:57:57.163: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 17 01:57:57.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-1752'
Dec 17 01:57:57.256: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 17 01:57:57.256: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Dec 17 01:57:57.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 delete jobs e2e-test-httpd-job --namespace=kubectl-1752'
Dec 17 01:57:57.346: INFO: stderr: ""
Dec 17 01:57:57.346: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 01:57:57.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1752" for this suite.
Dec 17 01:58:25.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 01:58:25.425: INFO: namespace kubectl-1752 deletion completed in 28.075887403s

â€¢ [SLOW TEST:28.262 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 01:58:25.425: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-e6b112c3-072e-4280-b47d-b876aa591aed in namespace container-probe-6888
Dec 17 01:58:27.455: INFO: Started pod test-webserver-e6b112c3-072e-4280-b47d-b876aa591aed in namespace container-probe-6888
STEP: checking the pod's current state and verifying that restartCount is present
Dec 17 01:58:27.457: INFO: Initial restart count of pod test-webserver-e6b112c3-072e-4280-b47d-b876aa591aed is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:02:27.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6888" for this suite.
Dec 17 02:02:33.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:02:33.859: INFO: namespace container-probe-6888 deletion completed in 6.062807356s

â€¢ [SLOW TEST:248.433 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:02:33.859: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-3865
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 17 02:02:33.879: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 17 02:02:51.920: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.2.93 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3865 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 02:02:51.920: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
Dec 17 02:02:53.005: INFO: Found all expected endpoints: [netserver-0]
Dec 17 02:02:53.008: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.1.49 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3865 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 02:02:53.008: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
Dec 17 02:02:54.094: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:02:54.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3865" for this suite.
Dec 17 02:03:06.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:03:06.159: INFO: namespace pod-network-test-3865 deletion completed in 12.062322846s

â€¢ [SLOW TEST:32.300 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:03:06.160: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Dec 17 02:03:06.178: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
Dec 17 02:03:09.179: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:03:21.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3150" for this suite.
Dec 17 02:03:27.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:03:27.673: INFO: namespace crd-publish-openapi-3150 deletion completed in 6.070315618s

â€¢ [SLOW TEST:21.514 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:03:27.674: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec 17 02:03:27.701: INFO: Pod name pod-release: Found 0 pods out of 1
Dec 17 02:03:32.704: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:03:33.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6480" for this suite.
Dec 17 02:03:39.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:03:39.778: INFO: namespace replication-controller-6480 deletion completed in 6.061626848s

â€¢ [SLOW TEST:12.104 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:03:39.778: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-97ec005f-f38d-4211-b0ec-ca212bc18609
STEP: Creating a pod to test consume configMaps
Dec 17 02:03:39.803: INFO: Waiting up to 5m0s for pod "pod-configmaps-7506a752-fb75-4236-8854-ad6558f2f4dd" in namespace "configmap-4287" to be "success or failure"
Dec 17 02:03:39.805: INFO: Pod "pod-configmaps-7506a752-fb75-4236-8854-ad6558f2f4dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.473132ms
Dec 17 02:03:41.808: INFO: Pod "pod-configmaps-7506a752-fb75-4236-8854-ad6558f2f4dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004964282s
STEP: Saw pod success
Dec 17 02:03:41.808: INFO: Pod "pod-configmaps-7506a752-fb75-4236-8854-ad6558f2f4dd" satisfied condition "success or failure"
Dec 17 02:03:41.810: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-configmaps-7506a752-fb75-4236-8854-ad6558f2f4dd container configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 02:03:41.831: INFO: Waiting for pod pod-configmaps-7506a752-fb75-4236-8854-ad6558f2f4dd to disappear
Dec 17 02:03:41.833: INFO: Pod pod-configmaps-7506a752-fb75-4236-8854-ad6558f2f4dd no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:03:41.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4287" for this suite.
Dec 17 02:03:47.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:03:47.901: INFO: namespace configmap-4287 deletion completed in 6.065785641s

â€¢ [SLOW TEST:8.123 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:03:47.901: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-bfc15e4a-537b-4013-8ed9-923ed9483efc
STEP: Creating a pod to test consume secrets
Dec 17 02:03:47.932: INFO: Waiting up to 5m0s for pod "pod-secrets-bb32f7ee-ad60-4862-9cac-a89d892a62ba" in namespace "secrets-4209" to be "success or failure"
Dec 17 02:03:47.934: INFO: Pod "pod-secrets-bb32f7ee-ad60-4862-9cac-a89d892a62ba": Phase="Pending", Reason="", readiness=false. Elapsed: 1.948243ms
Dec 17 02:03:49.937: INFO: Pod "pod-secrets-bb32f7ee-ad60-4862-9cac-a89d892a62ba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004747725s
STEP: Saw pod success
Dec 17 02:03:49.937: INFO: Pod "pod-secrets-bb32f7ee-ad60-4862-9cac-a89d892a62ba" satisfied condition "success or failure"
Dec 17 02:03:49.939: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-secrets-bb32f7ee-ad60-4862-9cac-a89d892a62ba container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 02:03:49.954: INFO: Waiting for pod pod-secrets-bb32f7ee-ad60-4862-9cac-a89d892a62ba to disappear
Dec 17 02:03:49.956: INFO: Pod pod-secrets-bb32f7ee-ad60-4862-9cac-a89d892a62ba no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:03:49.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4209" for this suite.
Dec 17 02:03:55.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:03:56.020: INFO: namespace secrets-4209 deletion completed in 6.061179803s

â€¢ [SLOW TEST:8.119 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:03:56.020: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 02:03:56.047: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec 17 02:04:01.050: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 17 02:04:01.051: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 17 02:04:01.063: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-323 /apis/apps/v1/namespaces/deployment-323/deployments/test-cleanup-deployment af69c93c-6c8f-4dd6-bdc1-8b68e09defe8 22499 1 2019-12-17 02:04:01 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00495afb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Dec 17 02:04:01.069: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-323 /apis/apps/v1/namespaces/deployment-323/replicasets/test-cleanup-deployment-65db99849b b8f80a65-a2a3-4e41-996f-83634674e69c 22501 1 2019-12-17 02:04:01 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment af69c93c-6c8f-4dd6-bdc1-8b68e09defe8 0xc00495b717 0xc00495b718}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00495b778 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 17 02:04:01.069: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Dec 17 02:04:01.069: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-323 /apis/apps/v1/namespaces/deployment-323/replicasets/test-cleanup-controller b5560290-1f51-4e5c-ac10-17464b115f56 22500 1 2019-12-17 02:03:56 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment af69c93c-6c8f-4dd6-bdc1-8b68e09defe8 0xc00495b637 0xc00495b638}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00495b6a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 17 02:04:01.077: INFO: Pod "test-cleanup-controller-2c2d7" is available:
&Pod{ObjectMeta:{test-cleanup-controller-2c2d7 test-cleanup-controller- deployment-323 /api/v1/namespaces/deployment-323/pods/test-cleanup-controller-2c2d7 38d1ed9d-68ed-4636-8efe-91a649c52ae9 22488 0 2019-12-17 02:03:56 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller b5560290-1f51-4e5c-ac10-17464b115f56 0xc0050abc77 0xc0050abc78}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4d6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4d6,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4d6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-58-188.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 02:03:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 02:03:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 02:03:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 02:03:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.58.188,PodIP:100.96.1.55,StartTime:2019-12-17 02:03:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 02:03:56 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://1ef73c6542a62fce74c36012aa9d115a5e4cadcc4b0398d03b575f981e642d38,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.55,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 02:04:01.077: INFO: Pod "test-cleanup-deployment-65db99849b-4hg56" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-65db99849b-4hg56 test-cleanup-deployment-65db99849b- deployment-323 /api/v1/namespaces/deployment-323/pods/test-cleanup-deployment-65db99849b-4hg56 62402d63-9590-48bc-9208-92289fb878d6 22503 0 2019-12-17 02:04:01 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-65db99849b b8f80a65-a2a3-4e41-996f-83634674e69c 0xc0050abec7 0xc0050abec8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4d6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4d6,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4d6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:04:01.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-323" for this suite.
Dec 17 02:04:07.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:04:07.161: INFO: namespace deployment-323 deletion completed in 6.073821815s

â€¢ [SLOW TEST:11.140 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:04:07.161: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 17 02:04:07.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-4332'
Dec 17 02:04:07.257: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 17 02:04:07.257: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Dec 17 02:04:07.264: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec 17 02:04:07.270: INFO: scanned /root for discovery docs: <nil>
Dec 17 02:04:07.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-4332'
Dec 17 02:04:23.034: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 17 02:04:23.034: INFO: stdout: "Created e2e-test-httpd-rc-d6802bffbbb447cb7d17ac745fc460dc\nScaling up e2e-test-httpd-rc-d6802bffbbb447cb7d17ac745fc460dc from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-d6802bffbbb447cb7d17ac745fc460dc up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-d6802bffbbb447cb7d17ac745fc460dc to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Dec 17 02:04:23.034: INFO: stdout: "Created e2e-test-httpd-rc-d6802bffbbb447cb7d17ac745fc460dc\nScaling up e2e-test-httpd-rc-d6802bffbbb447cb7d17ac745fc460dc from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-d6802bffbbb447cb7d17ac745fc460dc up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-d6802bffbbb447cb7d17ac745fc460dc to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Dec 17 02:04:23.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-4332'
Dec 17 02:04:23.112: INFO: stderr: ""
Dec 17 02:04:23.112: INFO: stdout: "e2e-test-httpd-rc-d6802bffbbb447cb7d17ac745fc460dc-krf96 "
Dec 17 02:04:23.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods e2e-test-httpd-rc-d6802bffbbb447cb7d17ac745fc460dc-krf96 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4332'
Dec 17 02:04:23.186: INFO: stderr: ""
Dec 17 02:04:23.186: INFO: stdout: "true"
Dec 17 02:04:23.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 get pods e2e-test-httpd-rc-d6802bffbbb447cb7d17ac745fc460dc-krf96 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4332'
Dec 17 02:04:23.258: INFO: stderr: ""
Dec 17 02:04:23.258: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Dec 17 02:04:23.258: INFO: e2e-test-httpd-rc-d6802bffbbb447cb7d17ac745fc460dc-krf96 is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Dec 17 02:04:23.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 delete rc e2e-test-httpd-rc --namespace=kubectl-4332'
Dec 17 02:04:23.344: INFO: stderr: ""
Dec 17 02:04:23.344: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:04:23.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4332" for this suite.
Dec 17 02:04:35.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:04:35.418: INFO: namespace kubectl-4332 deletion completed in 12.071111232s

â€¢ [SLOW TEST:28.258 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:04:35.419: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:04:38.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4315" for this suite.
Dec 17 02:05:06.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:05:06.541: INFO: namespace replication-controller-4315 deletion completed in 28.062672157s

â€¢ [SLOW TEST:31.123 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:05:06.541: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-ec7d9d63-c04b-44b9-a3da-e2c755faf1d3
Dec 17 02:05:06.571: INFO: Pod name my-hostname-basic-ec7d9d63-c04b-44b9-a3da-e2c755faf1d3: Found 0 pods out of 1
Dec 17 02:05:11.575: INFO: Pod name my-hostname-basic-ec7d9d63-c04b-44b9-a3da-e2c755faf1d3: Found 1 pods out of 1
Dec 17 02:05:11.575: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-ec7d9d63-c04b-44b9-a3da-e2c755faf1d3" are running
Dec 17 02:05:11.577: INFO: Pod "my-hostname-basic-ec7d9d63-c04b-44b9-a3da-e2c755faf1d3-drlns" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-17 02:05:06 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-17 02:05:08 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-17 02:05:08 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-17 02:05:06 +0000 UTC Reason: Message:}])
Dec 17 02:05:11.577: INFO: Trying to dial the pod
Dec 17 02:05:16.584: INFO: Controller my-hostname-basic-ec7d9d63-c04b-44b9-a3da-e2c755faf1d3: Got expected result from replica 1 [my-hostname-basic-ec7d9d63-c04b-44b9-a3da-e2c755faf1d3-drlns]: "my-hostname-basic-ec7d9d63-c04b-44b9-a3da-e2c755faf1d3-drlns", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:05:16.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6894" for this suite.
Dec 17 02:05:22.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:05:22.664: INFO: namespace replication-controller-6894 deletion completed in 6.076935046s

â€¢ [SLOW TEST:16.122 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:05:22.664: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 17 02:05:25.215: INFO: Successfully updated pod "annotationupdated7ca5bbc-4c0f-4c25-8c8c-05462a9e9aeb"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:05:27.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4971" for this suite.
Dec 17 02:05:55.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:05:55.300: INFO: namespace downward-api-4971 deletion completed in 28.069001169s

â€¢ [SLOW TEST:32.636 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:05:55.300: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Dec 17 02:05:55.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 api-versions'
Dec 17 02:05:55.390: INFO: stderr: ""
Dec 17 02:05:55.390: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:05:55.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-66" for this suite.
Dec 17 02:06:01.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:06:01.453: INFO: namespace kubectl-66 deletion completed in 6.060628612s

â€¢ [SLOW TEST:6.153 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:06:01.453: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 17 02:06:01.477: INFO: Waiting up to 5m0s for pod "pod-948bf65b-2c6a-4410-b7e1-970b3854045e" in namespace "emptydir-5688" to be "success or failure"
Dec 17 02:06:01.480: INFO: Pod "pod-948bf65b-2c6a-4410-b7e1-970b3854045e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.377394ms
Dec 17 02:06:03.483: INFO: Pod "pod-948bf65b-2c6a-4410-b7e1-970b3854045e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005264884s
STEP: Saw pod success
Dec 17 02:06:03.483: INFO: Pod "pod-948bf65b-2c6a-4410-b7e1-970b3854045e" satisfied condition "success or failure"
Dec 17 02:06:03.486: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-948bf65b-2c6a-4410-b7e1-970b3854045e container test-container: <nil>
STEP: delete the pod
Dec 17 02:06:03.503: INFO: Waiting for pod pod-948bf65b-2c6a-4410-b7e1-970b3854045e to disappear
Dec 17 02:06:03.505: INFO: Pod pod-948bf65b-2c6a-4410-b7e1-970b3854045e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:06:03.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5688" for this suite.
Dec 17 02:06:09.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:06:09.563: INFO: namespace emptydir-5688 deletion completed in 6.055544018s

â€¢ [SLOW TEST:8.109 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:06:09.563: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 02:06:09.586: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6c06237d-802a-4928-97dd-7c91f33b6a20" in namespace "projected-7645" to be "success or failure"
Dec 17 02:06:09.588: INFO: Pod "downwardapi-volume-6c06237d-802a-4928-97dd-7c91f33b6a20": Phase="Pending", Reason="", readiness=false. Elapsed: 2.369102ms
Dec 17 02:06:11.591: INFO: Pod "downwardapi-volume-6c06237d-802a-4928-97dd-7c91f33b6a20": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005383705s
STEP: Saw pod success
Dec 17 02:06:11.591: INFO: Pod "downwardapi-volume-6c06237d-802a-4928-97dd-7c91f33b6a20" satisfied condition "success or failure"
Dec 17 02:06:11.593: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod downwardapi-volume-6c06237d-802a-4928-97dd-7c91f33b6a20 container client-container: <nil>
STEP: delete the pod
Dec 17 02:06:11.621: INFO: Waiting for pod downwardapi-volume-6c06237d-802a-4928-97dd-7c91f33b6a20 to disappear
Dec 17 02:06:11.639: INFO: Pod downwardapi-volume-6c06237d-802a-4928-97dd-7c91f33b6a20 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:06:11.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7645" for this suite.
Dec 17 02:06:17.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:06:17.720: INFO: namespace projected-7645 deletion completed in 6.075958271s

â€¢ [SLOW TEST:8.157 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:06:17.722: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 17 02:06:17.748: INFO: Waiting up to 5m0s for pod "downward-api-0e189e2c-3cbc-4105-a875-7f28dd73139c" in namespace "downward-api-594" to be "success or failure"
Dec 17 02:06:17.751: INFO: Pod "downward-api-0e189e2c-3cbc-4105-a875-7f28dd73139c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.055615ms
Dec 17 02:06:19.753: INFO: Pod "downward-api-0e189e2c-3cbc-4105-a875-7f28dd73139c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005128443s
STEP: Saw pod success
Dec 17 02:06:19.753: INFO: Pod "downward-api-0e189e2c-3cbc-4105-a875-7f28dd73139c" satisfied condition "success or failure"
Dec 17 02:06:19.755: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod downward-api-0e189e2c-3cbc-4105-a875-7f28dd73139c container dapi-container: <nil>
STEP: delete the pod
Dec 17 02:06:19.769: INFO: Waiting for pod downward-api-0e189e2c-3cbc-4105-a875-7f28dd73139c to disappear
Dec 17 02:06:19.771: INFO: Pod downward-api-0e189e2c-3cbc-4105-a875-7f28dd73139c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:06:19.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-594" for this suite.
Dec 17 02:06:25.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:06:25.830: INFO: namespace downward-api-594 deletion completed in 6.056878674s

â€¢ [SLOW TEST:8.108 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:06:25.831: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Dec 17 02:06:25.853: INFO: Waiting up to 5m0s for pod "client-containers-fb0bb232-e5b0-4214-bf98-9e7bdbd8dd59" in namespace "containers-3961" to be "success or failure"
Dec 17 02:06:25.857: INFO: Pod "client-containers-fb0bb232-e5b0-4214-bf98-9e7bdbd8dd59": Phase="Pending", Reason="", readiness=false. Elapsed: 4.326962ms
Dec 17 02:06:27.860: INFO: Pod "client-containers-fb0bb232-e5b0-4214-bf98-9e7bdbd8dd59": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007237263s
STEP: Saw pod success
Dec 17 02:06:27.860: INFO: Pod "client-containers-fb0bb232-e5b0-4214-bf98-9e7bdbd8dd59" satisfied condition "success or failure"
Dec 17 02:06:27.862: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod client-containers-fb0bb232-e5b0-4214-bf98-9e7bdbd8dd59 container test-container: <nil>
STEP: delete the pod
Dec 17 02:06:27.876: INFO: Waiting for pod client-containers-fb0bb232-e5b0-4214-bf98-9e7bdbd8dd59 to disappear
Dec 17 02:06:27.878: INFO: Pod client-containers-fb0bb232-e5b0-4214-bf98-9e7bdbd8dd59 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:06:27.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3961" for this suite.
Dec 17 02:06:33.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:06:33.938: INFO: namespace containers-3961 deletion completed in 6.057107123s

â€¢ [SLOW TEST:8.107 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:06:33.938: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-4d854936-ef4f-4cec-8a5b-7fe958e7e19a
STEP: Creating a pod to test consume configMaps
Dec 17 02:06:33.963: INFO: Waiting up to 5m0s for pod "pod-configmaps-dfe06333-89c0-4a4f-891f-b0fd9412bef0" in namespace "configmap-3489" to be "success or failure"
Dec 17 02:06:33.965: INFO: Pod "pod-configmaps-dfe06333-89c0-4a4f-891f-b0fd9412bef0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.106355ms
Dec 17 02:06:35.968: INFO: Pod "pod-configmaps-dfe06333-89c0-4a4f-891f-b0fd9412bef0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005206228s
STEP: Saw pod success
Dec 17 02:06:35.968: INFO: Pod "pod-configmaps-dfe06333-89c0-4a4f-891f-b0fd9412bef0" satisfied condition "success or failure"
Dec 17 02:06:35.970: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-configmaps-dfe06333-89c0-4a4f-891f-b0fd9412bef0 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 02:06:35.986: INFO: Waiting for pod pod-configmaps-dfe06333-89c0-4a4f-891f-b0fd9412bef0 to disappear
Dec 17 02:06:35.989: INFO: Pod pod-configmaps-dfe06333-89c0-4a4f-891f-b0fd9412bef0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:06:35.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3489" for this suite.
Dec 17 02:06:41.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:06:42.051: INFO: namespace configmap-3489 deletion completed in 6.05996754s

â€¢ [SLOW TEST:8.113 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:06:42.051: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 17 02:06:46.102: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 17 02:06:46.105: INFO: Pod pod-with-poststart-http-hook still exists
Dec 17 02:06:48.105: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 17 02:06:48.107: INFO: Pod pod-with-poststart-http-hook still exists
Dec 17 02:06:50.105: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 17 02:06:50.107: INFO: Pod pod-with-poststart-http-hook still exists
Dec 17 02:06:52.105: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 17 02:06:52.108: INFO: Pod pod-with-poststart-http-hook still exists
Dec 17 02:06:54.105: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 17 02:06:54.108: INFO: Pod pod-with-poststart-http-hook still exists
Dec 17 02:06:56.105: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 17 02:06:56.108: INFO: Pod pod-with-poststart-http-hook still exists
Dec 17 02:06:58.105: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 17 02:06:58.108: INFO: Pod pod-with-poststart-http-hook still exists
Dec 17 02:07:00.105: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 17 02:07:00.108: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:07:00.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2902" for this suite.
Dec 17 02:07:12.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:07:12.177: INFO: namespace container-lifecycle-hook-2902 deletion completed in 12.066621179s

â€¢ [SLOW TEST:30.125 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:07:12.177: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 17 02:07:12.201: INFO: Waiting up to 5m0s for pod "pod-c6acfc32-49df-4aba-840b-4c60b7745f0e" in namespace "emptydir-7798" to be "success or failure"
Dec 17 02:07:12.206: INFO: Pod "pod-c6acfc32-49df-4aba-840b-4c60b7745f0e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.537847ms
Dec 17 02:07:14.209: INFO: Pod "pod-c6acfc32-49df-4aba-840b-4c60b7745f0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008397475s
STEP: Saw pod success
Dec 17 02:07:14.209: INFO: Pod "pod-c6acfc32-49df-4aba-840b-4c60b7745f0e" satisfied condition "success or failure"
Dec 17 02:07:14.211: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-c6acfc32-49df-4aba-840b-4c60b7745f0e container test-container: <nil>
STEP: delete the pod
Dec 17 02:07:14.225: INFO: Waiting for pod pod-c6acfc32-49df-4aba-840b-4c60b7745f0e to disappear
Dec 17 02:07:14.227: INFO: Pod pod-c6acfc32-49df-4aba-840b-4c60b7745f0e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:07:14.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7798" for this suite.
Dec 17 02:07:20.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:07:20.293: INFO: namespace emptydir-7798 deletion completed in 6.063053899s

â€¢ [SLOW TEST:8.116 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:07:20.293: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-6361
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-6361
STEP: creating replication controller externalsvc in namespace services-6361
I1217 02:07:20.340024      21 runners.go:184] Created replication controller with name: externalsvc, namespace: services-6361, replica count: 2
I1217 02:07:23.390585      21 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Dec 17 02:07:23.404: INFO: Creating new exec pod
Dec 17 02:07:25.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 exec --namespace=services-6361 execpodk8n5n -- /bin/sh -x -c nslookup nodeport-service'
Dec 17 02:07:25.810: INFO: stderr: "+ nslookup nodeport-service\n"
Dec 17 02:07:25.810: INFO: stdout: "Server:\t\t100.64.0.10\nAddress:\t100.64.0.10#53\n\nnodeport-service.services-6361.svc.cluster.local\tcanonical name = externalsvc.services-6361.svc.cluster.local.\nName:\texternalsvc.services-6361.svc.cluster.local\nAddress: 100.65.7.46\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-6361, will wait for the garbage collector to delete the pods
Dec 17 02:07:25.869: INFO: Deleting ReplicationController externalsvc took: 6.143288ms
Dec 17 02:07:26.169: INFO: Terminating ReplicationController externalsvc pods took: 300.265072ms
Dec 17 02:07:30.386: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:07:30.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6361" for this suite.
Dec 17 02:07:36.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:07:36.465: INFO: namespace services-6361 deletion completed in 6.058423351s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:16.172 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:07:36.466: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 17 02:07:37.493: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:07:37.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6866" for this suite.
Dec 17 02:07:43.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:07:43.561: INFO: namespace container-runtime-6866 deletion completed in 6.056875679s

â€¢ [SLOW TEST:7.095 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:07:43.561: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 02:07:43.585: INFO: Waiting up to 5m0s for pod "downwardapi-volume-21bfafd2-a4ac-41a6-a539-c9aad71b5f08" in namespace "projected-2282" to be "success or failure"
Dec 17 02:07:43.588: INFO: Pod "downwardapi-volume-21bfafd2-a4ac-41a6-a539-c9aad71b5f08": Phase="Pending", Reason="", readiness=false. Elapsed: 2.766613ms
Dec 17 02:07:45.590: INFO: Pod "downwardapi-volume-21bfafd2-a4ac-41a6-a539-c9aad71b5f08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005182808s
STEP: Saw pod success
Dec 17 02:07:45.590: INFO: Pod "downwardapi-volume-21bfafd2-a4ac-41a6-a539-c9aad71b5f08" satisfied condition "success or failure"
Dec 17 02:07:45.592: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod downwardapi-volume-21bfafd2-a4ac-41a6-a539-c9aad71b5f08 container client-container: <nil>
STEP: delete the pod
Dec 17 02:07:45.604: INFO: Waiting for pod downwardapi-volume-21bfafd2-a4ac-41a6-a539-c9aad71b5f08 to disappear
Dec 17 02:07:45.606: INFO: Pod downwardapi-volume-21bfafd2-a4ac-41a6-a539-c9aad71b5f08 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:07:45.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2282" for this suite.
Dec 17 02:07:51.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:07:51.676: INFO: namespace projected-2282 deletion completed in 6.068132855s

â€¢ [SLOW TEST:8.115 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:07:51.677: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 02:07:51.699: INFO: Waiting up to 5m0s for pod "downwardapi-volume-95a6c18b-af5f-4cd5-8049-02d4589c2c01" in namespace "downward-api-5353" to be "success or failure"
Dec 17 02:07:51.703: INFO: Pod "downwardapi-volume-95a6c18b-af5f-4cd5-8049-02d4589c2c01": Phase="Pending", Reason="", readiness=false. Elapsed: 3.572717ms
Dec 17 02:07:53.705: INFO: Pod "downwardapi-volume-95a6c18b-af5f-4cd5-8049-02d4589c2c01": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005842702s
STEP: Saw pod success
Dec 17 02:07:53.705: INFO: Pod "downwardapi-volume-95a6c18b-af5f-4cd5-8049-02d4589c2c01" satisfied condition "success or failure"
Dec 17 02:07:53.707: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod downwardapi-volume-95a6c18b-af5f-4cd5-8049-02d4589c2c01 container client-container: <nil>
STEP: delete the pod
Dec 17 02:07:53.725: INFO: Waiting for pod downwardapi-volume-95a6c18b-af5f-4cd5-8049-02d4589c2c01 to disappear
Dec 17 02:07:53.727: INFO: Pod downwardapi-volume-95a6c18b-af5f-4cd5-8049-02d4589c2c01 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:07:53.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5353" for this suite.
Dec 17 02:07:59.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:07:59.784: INFO: namespace downward-api-5353 deletion completed in 6.054360922s

â€¢ [SLOW TEST:8.107 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:07:59.784: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-8437
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Dec 17 02:07:59.813: INFO: Found 0 stateful pods, waiting for 3
Dec 17 02:08:09.815: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 02:08:09.815: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 02:08:09.815: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec 17 02:08:09.835: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec 17 02:08:19.859: INFO: Updating stateful set ss2
Dec 17 02:08:19.864: INFO: Waiting for Pod statefulset-8437/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 17 02:08:29.868: INFO: Waiting for Pod statefulset-8437/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Dec 17 02:08:39.895: INFO: Found 1 stateful pods, waiting for 3
Dec 17 02:08:49.898: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 02:08:49.898: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 02:08:49.898: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec 17 02:08:49.917: INFO: Updating stateful set ss2
Dec 17 02:08:49.924: INFO: Waiting for Pod statefulset-8437/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 17 02:08:59.928: INFO: Waiting for Pod statefulset-8437/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 17 02:09:09.944: INFO: Updating stateful set ss2
Dec 17 02:09:09.948: INFO: Waiting for StatefulSet statefulset-8437/ss2 to complete update
Dec 17 02:09:09.948: INFO: Waiting for Pod statefulset-8437/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 17 02:09:19.952: INFO: Deleting all statefulset in ns statefulset-8437
Dec 17 02:09:19.954: INFO: Scaling statefulset ss2 to 0
Dec 17 02:09:29.964: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 02:09:29.965: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:09:29.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8437" for this suite.
Dec 17 02:09:35.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:09:36.035: INFO: namespace statefulset-8437 deletion completed in 6.05935839s

â€¢ [SLOW TEST:96.251 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:09:36.035: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 02:09:36.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505434119 version'
Dec 17 02:09:36.120: INFO: stderr: ""
Dec 17 02:09:36.120: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.3\", GitCommit:\"b3cbbae08ec52a7fc73d334838e18d17e8512749\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T11:23:11Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.3\", GitCommit:\"b3cbbae08ec52a7fc73d334838e18d17e8512749\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T11:13:49Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:09:36.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3642" for this suite.
Dec 17 02:09:42.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:09:42.179: INFO: namespace kubectl-3642 deletion completed in 6.05669484s

â€¢ [SLOW TEST:6.144 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:09:42.180: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 02:09:42.568: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 17 02:09:44.575: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712145382, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712145382, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712145382, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712145382, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 02:09:47.587: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:09:47.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4311" for this suite.
Dec 17 02:09:53.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:09:53.762: INFO: namespace webhook-4311 deletion completed in 6.0676623s
STEP: Destroying namespace "webhook-4311-markers" for this suite.
Dec 17 02:09:59.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:09:59.828: INFO: namespace webhook-4311-markers deletion completed in 6.066458566s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:17.657 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:09:59.837: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:10:12.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9127" for this suite.
Dec 17 02:10:18.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:10:18.962: INFO: namespace resourcequota-9127 deletion completed in 6.061146706s

â€¢ [SLOW TEST:19.126 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:10:18.963: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 02:10:18.986: INFO: Waiting up to 5m0s for pod "downwardapi-volume-47142825-f9b7-4e8c-914e-b2ffe63857e4" in namespace "projected-8285" to be "success or failure"
Dec 17 02:10:18.988: INFO: Pod "downwardapi-volume-47142825-f9b7-4e8c-914e-b2ffe63857e4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.505041ms
Dec 17 02:10:20.991: INFO: Pod "downwardapi-volume-47142825-f9b7-4e8c-914e-b2ffe63857e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004756073s
STEP: Saw pod success
Dec 17 02:10:20.991: INFO: Pod "downwardapi-volume-47142825-f9b7-4e8c-914e-b2ffe63857e4" satisfied condition "success or failure"
Dec 17 02:10:20.993: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod downwardapi-volume-47142825-f9b7-4e8c-914e-b2ffe63857e4 container client-container: <nil>
STEP: delete the pod
Dec 17 02:10:21.012: INFO: Waiting for pod downwardapi-volume-47142825-f9b7-4e8c-914e-b2ffe63857e4 to disappear
Dec 17 02:10:21.015: INFO: Pod downwardapi-volume-47142825-f9b7-4e8c-914e-b2ffe63857e4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:10:21.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8285" for this suite.
Dec 17 02:10:27.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:10:27.086: INFO: namespace projected-8285 deletion completed in 6.068785328s

â€¢ [SLOW TEST:8.123 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:10:27.086: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:10:44.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7607" for this suite.
Dec 17 02:10:50.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:10:50.195: INFO: namespace resourcequota-7607 deletion completed in 6.05931809s

â€¢ [SLOW TEST:23.109 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:10:50.195: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-30899268-fb49-492c-84b9-967ad34ef2a0
STEP: Creating a pod to test consume secrets
Dec 17 02:10:50.226: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a73c2deb-70ab-4311-b7d2-d9e1a4aa61d8" in namespace "projected-9934" to be "success or failure"
Dec 17 02:10:50.228: INFO: Pod "pod-projected-secrets-a73c2deb-70ab-4311-b7d2-d9e1a4aa61d8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.946777ms
Dec 17 02:10:52.231: INFO: Pod "pod-projected-secrets-a73c2deb-70ab-4311-b7d2-d9e1a4aa61d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004433478s
STEP: Saw pod success
Dec 17 02:10:52.231: INFO: Pod "pod-projected-secrets-a73c2deb-70ab-4311-b7d2-d9e1a4aa61d8" satisfied condition "success or failure"
Dec 17 02:10:52.232: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-projected-secrets-a73c2deb-70ab-4311-b7d2-d9e1a4aa61d8 container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 02:10:52.245: INFO: Waiting for pod pod-projected-secrets-a73c2deb-70ab-4311-b7d2-d9e1a4aa61d8 to disappear
Dec 17 02:10:52.247: INFO: Pod pod-projected-secrets-a73c2deb-70ab-4311-b7d2-d9e1a4aa61d8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:10:52.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9934" for this suite.
Dec 17 02:10:58.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:10:58.318: INFO: namespace projected-9934 deletion completed in 6.068108588s

â€¢ [SLOW TEST:8.123 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:10:58.318: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-3351/secret-test-d99235a7-645c-4c74-b053-ce5515c3c729
STEP: Creating a pod to test consume secrets
Dec 17 02:10:58.345: INFO: Waiting up to 5m0s for pod "pod-configmaps-b35bd6dc-96f7-4a09-a13b-4bae5c310f83" in namespace "secrets-3351" to be "success or failure"
Dec 17 02:10:58.347: INFO: Pod "pod-configmaps-b35bd6dc-96f7-4a09-a13b-4bae5c310f83": Phase="Pending", Reason="", readiness=false. Elapsed: 2.256471ms
Dec 17 02:11:00.350: INFO: Pod "pod-configmaps-b35bd6dc-96f7-4a09-a13b-4bae5c310f83": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004751905s
STEP: Saw pod success
Dec 17 02:11:00.350: INFO: Pod "pod-configmaps-b35bd6dc-96f7-4a09-a13b-4bae5c310f83" satisfied condition "success or failure"
Dec 17 02:11:00.351: INFO: Trying to get logs from node ip-172-20-58-188.us-east-2.compute.internal pod pod-configmaps-b35bd6dc-96f7-4a09-a13b-4bae5c310f83 container env-test: <nil>
STEP: delete the pod
Dec 17 02:11:00.365: INFO: Waiting for pod pod-configmaps-b35bd6dc-96f7-4a09-a13b-4bae5c310f83 to disappear
Dec 17 02:11:00.367: INFO: Pod pod-configmaps-b35bd6dc-96f7-4a09-a13b-4bae5c310f83 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:11:00.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3351" for this suite.
Dec 17 02:11:06.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:11:06.440: INFO: namespace secrets-3351 deletion completed in 6.070993145s

â€¢ [SLOW TEST:8.122 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 02:11:06.441: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-5602
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 17 02:11:06.461: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 17 02:11:26.508: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.87:8080/dial?request=hostName&protocol=http&host=100.96.1.86&port=8080&tries=1'] Namespace:pod-network-test-5602 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 02:11:26.508: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
Dec 17 02:11:26.598: INFO: Waiting for endpoints: map[]
Dec 17 02:11:26.600: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.87:8080/dial?request=hostName&protocol=http&host=100.96.2.96&port=8080&tries=1'] Namespace:pod-network-test-5602 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 02:11:26.600: INFO: >>> kubeConfig: /tmp/kubeconfig-505434119
Dec 17 02:11:26.691: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 02:11:26.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5602" for this suite.
Dec 17 02:11:38.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 02:11:38.756: INFO: namespace pod-network-test-5602 deletion completed in 12.061727588s

â€¢ [SLOW TEST:32.315 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSDec 17 02:11:38.756: INFO: Running AfterSuite actions on all nodes
Dec 17 02:11:38.756: INFO: Running AfterSuite actions on node 1
Dec 17 02:11:38.756: INFO: Skipping dumping logs from cluster

Ran 276 of 4732 Specs in 6871.406 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Pending | 4456 Skipped
PASS

Ginkgo ran 1 suite in 1h54m32.868970207s
Test Suite Passed
