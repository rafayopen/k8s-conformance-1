I1011 17:28:30.808845      19 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-158339303
I1011 17:28:30.809079      19 e2e.go:92] Starting e2e run "a199f19c-3e49-46f6-8dc9-dda61b9c246e" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1570814908 - Will randomize all specs
Will run 276 of 4897 specs

Oct 11 17:28:30.824: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 17:28:30.826: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Oct 11 17:28:30.844: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Oct 11 17:28:30.899: INFO: 29 / 29 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Oct 11 17:28:30.899: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
Oct 11 17:28:30.899: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Oct 11 17:28:30.910: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
Oct 11 17:28:30.910: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Oct 11 17:28:30.910: INFO: e2e test version: v1.16.1
Oct 11 17:28:30.912: INFO: kube-apiserver version: v1.16.1
Oct 11 17:28:30.912: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 17:28:30.920: INFO: Cluster IP family: ipv4
SSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:28:30.920: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename services
Oct 11 17:28:30.958: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-1959
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1959 to expose endpoints map[]
Oct 11 17:28:30.980: INFO: successfully validated that service endpoint-test2 in namespace services-1959 exposes endpoints map[] (5.674427ms elapsed)
STEP: Creating pod pod1 in namespace services-1959
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1959 to expose endpoints map[pod1:[80]]
Oct 11 17:28:35.046: INFO: Unexpected endpoints: found map[], expected map[pod1:[80]] (4.053185927s elapsed, will retry)
Oct 11 17:28:37.062: INFO: successfully validated that service endpoint-test2 in namespace services-1959 exposes endpoints map[pod1:[80]] (6.069322565s elapsed)
STEP: Creating pod pod2 in namespace services-1959
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1959 to expose endpoints map[pod1:[80] pod2:[80]]
Oct 11 17:28:41.131: INFO: Unexpected endpoints: found map[026fea21-562c-4a65-bf39-12a978f34b05:[80]], expected map[pod1:[80] pod2:[80]] (4.063362111s elapsed, will retry)
Oct 11 17:28:42.143: INFO: successfully validated that service endpoint-test2 in namespace services-1959 exposes endpoints map[pod1:[80] pod2:[80]] (5.075376451s elapsed)
STEP: Deleting pod pod1 in namespace services-1959
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1959 to expose endpoints map[pod2:[80]]
Oct 11 17:28:42.162: INFO: successfully validated that service endpoint-test2 in namespace services-1959 exposes endpoints map[pod2:[80]] (10.119504ms elapsed)
STEP: Deleting pod pod2 in namespace services-1959
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1959 to expose endpoints map[]
Oct 11 17:28:42.183: INFO: successfully validated that service endpoint-test2 in namespace services-1959 exposes endpoints map[] (7.941939ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:28:42.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1959" for this suite.
Oct 11 17:28:54.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:28:54.369: INFO: namespace services-1959 deletion completed in 12.13855937s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:23.449 seconds]
[sig-network] Services
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:28:54.369: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-8471016a-eca5-4cd8-82c2-7dd2433f3aeb
STEP: Creating a pod to test consume configMaps
Oct 11 17:28:54.419: INFO: Waiting up to 5m0s for pod "pod-configmaps-d00d4798-6ca3-4e93-af7b-d5cbb225a8eb" in namespace "configmap-8790" to be "success or failure"
Oct 11 17:28:54.424: INFO: Pod "pod-configmaps-d00d4798-6ca3-4e93-af7b-d5cbb225a8eb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.23294ms
Oct 11 17:28:56.429: INFO: Pod "pod-configmaps-d00d4798-6ca3-4e93-af7b-d5cbb225a8eb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009744633s
Oct 11 17:28:58.433: INFO: Pod "pod-configmaps-d00d4798-6ca3-4e93-af7b-d5cbb225a8eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014162995s
STEP: Saw pod success
Oct 11 17:28:58.433: INFO: Pod "pod-configmaps-d00d4798-6ca3-4e93-af7b-d5cbb225a8eb" satisfied condition "success or failure"
Oct 11 17:28:58.437: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-configmaps-d00d4798-6ca3-4e93-af7b-d5cbb225a8eb container configmap-volume-test: <nil>
STEP: delete the pod
Oct 11 17:28:58.469: INFO: Waiting for pod pod-configmaps-d00d4798-6ca3-4e93-af7b-d5cbb225a8eb to disappear
Oct 11 17:28:58.472: INFO: Pod pod-configmaps-d00d4798-6ca3-4e93-af7b-d5cbb225a8eb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:28:58.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8790" for this suite.
Oct 11 17:29:04.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:29:04.620: INFO: namespace configmap-8790 deletion completed in 6.143050035s

• [SLOW TEST:10.251 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:29:04.621: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 11 17:29:10.720: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 11 17:29:10.723: INFO: Pod pod-with-poststart-http-hook still exists
Oct 11 17:29:12.723: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 11 17:29:12.728: INFO: Pod pod-with-poststart-http-hook still exists
Oct 11 17:29:14.723: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 11 17:29:14.728: INFO: Pod pod-with-poststart-http-hook still exists
Oct 11 17:29:16.724: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 11 17:29:16.728: INFO: Pod pod-with-poststart-http-hook still exists
Oct 11 17:29:18.723: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 11 17:29:18.728: INFO: Pod pod-with-poststart-http-hook still exists
Oct 11 17:29:20.723: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 11 17:29:20.728: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:29:20.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1748" for this suite.
Oct 11 17:29:48.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:29:48.874: INFO: namespace container-lifecycle-hook-1748 deletion completed in 28.141318408s

• [SLOW TEST:44.254 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:29:48.875: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Oct 11 17:29:49.152: INFO: Pod name wrapped-volume-race-64c93897-6c3c-4ce1-b506-d0684d06d59c: Found 0 pods out of 5
Oct 11 17:29:54.159: INFO: Pod name wrapped-volume-race-64c93897-6c3c-4ce1-b506-d0684d06d59c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-64c93897-6c3c-4ce1-b506-d0684d06d59c in namespace emptydir-wrapper-49, will wait for the garbage collector to delete the pods
Oct 11 17:30:12.252: INFO: Deleting ReplicationController wrapped-volume-race-64c93897-6c3c-4ce1-b506-d0684d06d59c took: 10.200267ms
Oct 11 17:30:12.672: INFO: Terminating ReplicationController wrapped-volume-race-64c93897-6c3c-4ce1-b506-d0684d06d59c pods took: 419.886431ms
STEP: Creating RC which spawns configmap-volume pods
Oct 11 17:30:51.494: INFO: Pod name wrapped-volume-race-d72f9f02-7375-410f-b0f2-41278979bdff: Found 0 pods out of 5
Oct 11 17:30:56.500: INFO: Pod name wrapped-volume-race-d72f9f02-7375-410f-b0f2-41278979bdff: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d72f9f02-7375-410f-b0f2-41278979bdff in namespace emptydir-wrapper-49, will wait for the garbage collector to delete the pods
Oct 11 17:31:08.590: INFO: Deleting ReplicationController wrapped-volume-race-d72f9f02-7375-410f-b0f2-41278979bdff took: 11.734158ms
Oct 11 17:31:09.091: INFO: Terminating ReplicationController wrapped-volume-race-d72f9f02-7375-410f-b0f2-41278979bdff pods took: 500.464659ms
STEP: Creating RC which spawns configmap-volume pods
Oct 11 17:31:51.811: INFO: Pod name wrapped-volume-race-562a5e3a-fff1-406c-9a87-e8f4c57bcf0a: Found 0 pods out of 5
Oct 11 17:31:56.817: INFO: Pod name wrapped-volume-race-562a5e3a-fff1-406c-9a87-e8f4c57bcf0a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-562a5e3a-fff1-406c-9a87-e8f4c57bcf0a in namespace emptydir-wrapper-49, will wait for the garbage collector to delete the pods
Oct 11 17:32:08.915: INFO: Deleting ReplicationController wrapped-volume-race-562a5e3a-fff1-406c-9a87-e8f4c57bcf0a took: 10.581269ms
Oct 11 17:32:09.315: INFO: Terminating ReplicationController wrapped-volume-race-562a5e3a-fff1-406c-9a87-e8f4c57bcf0a pods took: 400.147249ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:32:51.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-49" for this suite.
Oct 11 17:33:00.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:33:00.141: INFO: namespace emptydir-wrapper-49 deletion completed in 8.14506208s

• [SLOW TEST:191.266 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:33:00.141: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-7366
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-7366
STEP: Creating statefulset with conflicting port in namespace statefulset-7366
STEP: Waiting until pod test-pod will start running in namespace statefulset-7366
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-7366
Oct 11 17:33:08.220: INFO: Observed stateful pod in namespace: statefulset-7366, name: ss-0, uid: 670514b1-5c33-461a-a789-8e981887c078, status phase: Pending. Waiting for statefulset controller to delete.
Oct 11 17:33:08.806: INFO: Observed stateful pod in namespace: statefulset-7366, name: ss-0, uid: 670514b1-5c33-461a-a789-8e981887c078, status phase: Failed. Waiting for statefulset controller to delete.
Oct 11 17:33:08.814: INFO: Observed stateful pod in namespace: statefulset-7366, name: ss-0, uid: 670514b1-5c33-461a-a789-8e981887c078, status phase: Failed. Waiting for statefulset controller to delete.
Oct 11 17:33:08.821: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-7366
STEP: Removing pod with conflicting port in namespace statefulset-7366
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-7366 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct 11 17:33:12.868: INFO: Deleting all statefulset in ns statefulset-7366
Oct 11 17:33:12.872: INFO: Scaling statefulset ss to 0
Oct 11 17:33:22.889: INFO: Waiting for statefulset status.replicas updated to 0
Oct 11 17:33:22.893: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:33:22.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7366" for this suite.
Oct 11 17:33:28.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:33:29.058: INFO: namespace statefulset-7366 deletion completed in 6.143529001s

• [SLOW TEST:28.918 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:33:29.059: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 11 17:33:29.659: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 11 17:33:31.673: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706412009, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706412009, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706412009, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706412009, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 11 17:33:34.696: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Oct 11 17:33:34.717: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:33:34.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1748" for this suite.
Oct 11 17:33:40.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:33:40.890: INFO: namespace webhook-1748 deletion completed in 6.150566204s
STEP: Destroying namespace "webhook-1748-markers" for this suite.
Oct 11 17:33:46.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:33:47.040: INFO: namespace webhook-1748-markers deletion completed in 6.149840678s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.000 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:33:47.059: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:34:00.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1046" for this suite.
Oct 11 17:34:28.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:34:28.293: INFO: namespace replication-controller-1046 deletion completed in 28.158993606s

• [SLOW TEST:41.233 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:34:28.293: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Oct 11 17:34:28.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 api-versions'
Oct 11 17:34:28.398: INFO: stderr: ""
Oct 11 17:34:28.398: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncluster.k8s.io/v1alpha1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:34:28.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7943" for this suite.
Oct 11 17:34:34.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:34:34.536: INFO: namespace kubectl-7943 deletion completed in 6.132966885s

• [SLOW TEST:6.243 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:34:34.536: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-be5c2b14-44e1-4fa9-ae77-47512c627d83
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-be5c2b14-44e1-4fa9-ae77-47512c627d83
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:35:43.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4563" for this suite.
Oct 11 17:35:55.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:35:55.209: INFO: namespace configmap-4563 deletion completed in 12.14288491s

• [SLOW TEST:80.673 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:35:55.210: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 11 17:35:55.563: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 11 17:35:57.575: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706412155, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706412155, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706412155, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706412155, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 11 17:36:00.609: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Oct 11 17:36:04.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 attach --namespace=webhook-9020 to-be-attached-pod -i -c=container1'
Oct 11 17:36:04.867: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:36:04.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9020" for this suite.
Oct 11 17:36:16.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:36:17.037: INFO: namespace webhook-9020 deletion completed in 12.151423645s
STEP: Destroying namespace "webhook-9020-markers" for this suite.
Oct 11 17:36:23.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:36:23.175: INFO: namespace webhook-9020-markers deletion completed in 6.13856721s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:27.984 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:36:23.194: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Oct 11 17:36:25.255: INFO: Pod pod-hostip-fc0e7740-e38e-4967-a22d-625ab1fd57f9 has hostIP: 172.31.5.54
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:36:25.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5914" for this suite.
Oct 11 17:36:37.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:36:37.411: INFO: namespace pods-5914 deletion completed in 12.151380336s

• [SLOW TEST:14.217 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:36:37.412: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Oct 11 17:36:37.462: INFO: Waiting up to 5m0s for pod "downward-api-6b550c9b-1de4-433e-b403-85282e06a6e4" in namespace "downward-api-4182" to be "success or failure"
Oct 11 17:36:37.466: INFO: Pod "downward-api-6b550c9b-1de4-433e-b403-85282e06a6e4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.449934ms
Oct 11 17:36:39.470: INFO: Pod "downward-api-6b550c9b-1de4-433e-b403-85282e06a6e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00881765s
Oct 11 17:36:41.475: INFO: Pod "downward-api-6b550c9b-1de4-433e-b403-85282e06a6e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013508749s
STEP: Saw pod success
Oct 11 17:36:41.475: INFO: Pod "downward-api-6b550c9b-1de4-433e-b403-85282e06a6e4" satisfied condition "success or failure"
Oct 11 17:36:41.479: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod downward-api-6b550c9b-1de4-433e-b403-85282e06a6e4 container dapi-container: <nil>
STEP: delete the pod
Oct 11 17:36:41.504: INFO: Waiting for pod downward-api-6b550c9b-1de4-433e-b403-85282e06a6e4 to disappear
Oct 11 17:36:41.507: INFO: Pod downward-api-6b550c9b-1de4-433e-b403-85282e06a6e4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:36:41.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4182" for this suite.
Oct 11 17:36:47.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:36:47.730: INFO: namespace downward-api-4182 deletion completed in 6.217549483s

• [SLOW TEST:10.318 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:36:47.730: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 11 17:36:48.089: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 11 17:36:50.106: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706412207, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706412207, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706412208, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706412207, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 11 17:36:53.131: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:36:53.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2121" for this suite.
Oct 11 17:36:59.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:36:59.344: INFO: namespace webhook-2121 deletion completed in 6.14002242s
STEP: Destroying namespace "webhook-2121-markers" for this suite.
Oct 11 17:37:05.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:37:05.506: INFO: namespace webhook-2121-markers deletion completed in 6.161606894s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.796 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:37:05.526: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Oct 11 17:37:05.569: INFO: Waiting up to 5m0s for pod "client-containers-0ae58988-8479-4bcb-9701-bb0067f19543" in namespace "containers-1815" to be "success or failure"
Oct 11 17:37:05.576: INFO: Pod "client-containers-0ae58988-8479-4bcb-9701-bb0067f19543": Phase="Pending", Reason="", readiness=false. Elapsed: 6.859056ms
Oct 11 17:37:07.581: INFO: Pod "client-containers-0ae58988-8479-4bcb-9701-bb0067f19543": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011288116s
Oct 11 17:37:09.585: INFO: Pod "client-containers-0ae58988-8479-4bcb-9701-bb0067f19543": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015739738s
STEP: Saw pod success
Oct 11 17:37:09.585: INFO: Pod "client-containers-0ae58988-8479-4bcb-9701-bb0067f19543" satisfied condition "success or failure"
Oct 11 17:37:09.589: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod client-containers-0ae58988-8479-4bcb-9701-bb0067f19543 container test-container: <nil>
STEP: delete the pod
Oct 11 17:37:09.615: INFO: Waiting for pod client-containers-0ae58988-8479-4bcb-9701-bb0067f19543 to disappear
Oct 11 17:37:09.619: INFO: Pod client-containers-0ae58988-8479-4bcb-9701-bb0067f19543 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:37:09.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1815" for this suite.
Oct 11 17:37:15.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:37:15.758: INFO: namespace containers-1815 deletion completed in 6.134059401s

• [SLOW TEST:10.232 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:37:15.758: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 17:37:15.793: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:37:16.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3383" for this suite.
Oct 11 17:37:22.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:37:22.463: INFO: namespace custom-resource-definition-3383 deletion completed in 6.134795146s

• [SLOW TEST:6.705 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:37:22.464: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-a8b6d959-e5fa-4df3-b6dd-479dcf9ec895
STEP: Creating a pod to test consume secrets
Oct 11 17:37:22.511: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1e1792ed-70c2-4bd0-91e0-2ed274191226" in namespace "projected-389" to be "success or failure"
Oct 11 17:37:22.516: INFO: Pod "pod-projected-secrets-1e1792ed-70c2-4bd0-91e0-2ed274191226": Phase="Pending", Reason="", readiness=false. Elapsed: 5.239153ms
Oct 11 17:37:24.521: INFO: Pod "pod-projected-secrets-1e1792ed-70c2-4bd0-91e0-2ed274191226": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009978047s
Oct 11 17:37:26.525: INFO: Pod "pod-projected-secrets-1e1792ed-70c2-4bd0-91e0-2ed274191226": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014557775s
STEP: Saw pod success
Oct 11 17:37:26.525: INFO: Pod "pod-projected-secrets-1e1792ed-70c2-4bd0-91e0-2ed274191226" satisfied condition "success or failure"
Oct 11 17:37:26.529: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-projected-secrets-1e1792ed-70c2-4bd0-91e0-2ed274191226 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 11 17:37:26.555: INFO: Waiting for pod pod-projected-secrets-1e1792ed-70c2-4bd0-91e0-2ed274191226 to disappear
Oct 11 17:37:26.559: INFO: Pod pod-projected-secrets-1e1792ed-70c2-4bd0-91e0-2ed274191226 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:37:26.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-389" for this suite.
Oct 11 17:37:32.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:37:32.700: INFO: namespace projected-389 deletion completed in 6.136166538s

• [SLOW TEST:10.237 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:37:32.701: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-3c2180f5-d167-454f-9920-6d3e7edffcac in namespace container-probe-7461
Oct 11 17:37:36.754: INFO: Started pod busybox-3c2180f5-d167-454f-9920-6d3e7edffcac in namespace container-probe-7461
STEP: checking the pod's current state and verifying that restartCount is present
Oct 11 17:37:36.757: INFO: Initial restart count of pod busybox-3c2180f5-d167-454f-9920-6d3e7edffcac is 0
Oct 11 17:38:24.877: INFO: Restart count of pod container-probe-7461/busybox-3c2180f5-d167-454f-9920-6d3e7edffcac is now 1 (48.119631729s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:38:24.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7461" for this suite.
Oct 11 17:38:30.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:38:31.049: INFO: namespace container-probe-7461 deletion completed in 6.150355173s

• [SLOW TEST:58.348 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:38:31.049: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 11 17:38:31.095: INFO: Waiting up to 5m0s for pod "pod-e814dd3c-900a-4b51-9aea-70c301ef5e98" in namespace "emptydir-1906" to be "success or failure"
Oct 11 17:38:31.101: INFO: Pod "pod-e814dd3c-900a-4b51-9aea-70c301ef5e98": Phase="Pending", Reason="", readiness=false. Elapsed: 6.35697ms
Oct 11 17:38:33.105: INFO: Pod "pod-e814dd3c-900a-4b51-9aea-70c301ef5e98": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010478049s
Oct 11 17:38:35.110: INFO: Pod "pod-e814dd3c-900a-4b51-9aea-70c301ef5e98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015327257s
STEP: Saw pod success
Oct 11 17:38:35.110: INFO: Pod "pod-e814dd3c-900a-4b51-9aea-70c301ef5e98" satisfied condition "success or failure"
Oct 11 17:38:35.114: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-e814dd3c-900a-4b51-9aea-70c301ef5e98 container test-container: <nil>
STEP: delete the pod
Oct 11 17:38:35.140: INFO: Waiting for pod pod-e814dd3c-900a-4b51-9aea-70c301ef5e98 to disappear
Oct 11 17:38:35.145: INFO: Pod pod-e814dd3c-900a-4b51-9aea-70c301ef5e98 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:38:35.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1906" for this suite.
Oct 11 17:38:41.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:38:41.286: INFO: namespace emptydir-1906 deletion completed in 6.135395733s

• [SLOW TEST:10.237 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:38:41.286: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 11 17:38:41.328: INFO: Waiting up to 5m0s for pod "pod-6fa06df9-4321-4904-8334-7eb97aba5f14" in namespace "emptydir-8260" to be "success or failure"
Oct 11 17:38:41.334: INFO: Pod "pod-6fa06df9-4321-4904-8334-7eb97aba5f14": Phase="Pending", Reason="", readiness=false. Elapsed: 5.05271ms
Oct 11 17:38:43.338: INFO: Pod "pod-6fa06df9-4321-4904-8334-7eb97aba5f14": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009163726s
STEP: Saw pod success
Oct 11 17:38:43.338: INFO: Pod "pod-6fa06df9-4321-4904-8334-7eb97aba5f14" satisfied condition "success or failure"
Oct 11 17:38:43.341: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-6fa06df9-4321-4904-8334-7eb97aba5f14 container test-container: <nil>
STEP: delete the pod
Oct 11 17:38:43.366: INFO: Waiting for pod pod-6fa06df9-4321-4904-8334-7eb97aba5f14 to disappear
Oct 11 17:38:43.369: INFO: Pod pod-6fa06df9-4321-4904-8334-7eb97aba5f14 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:38:43.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8260" for this suite.
Oct 11 17:38:49.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:38:49.513: INFO: namespace emptydir-8260 deletion completed in 6.139012491s

• [SLOW TEST:8.227 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:38:49.514: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-2ee6e7b7-9a24-4b98-8d81-c7ca64e1348f
STEP: Creating a pod to test consume secrets
Oct 11 17:38:49.562: INFO: Waiting up to 5m0s for pod "pod-secrets-02475e12-ffd4-47b9-8aec-322b3230c131" in namespace "secrets-1319" to be "success or failure"
Oct 11 17:38:49.567: INFO: Pod "pod-secrets-02475e12-ffd4-47b9-8aec-322b3230c131": Phase="Pending", Reason="", readiness=false. Elapsed: 5.011992ms
Oct 11 17:38:51.572: INFO: Pod "pod-secrets-02475e12-ffd4-47b9-8aec-322b3230c131": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009374605s
STEP: Saw pod success
Oct 11 17:38:51.572: INFO: Pod "pod-secrets-02475e12-ffd4-47b9-8aec-322b3230c131" satisfied condition "success or failure"
Oct 11 17:38:51.575: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-secrets-02475e12-ffd4-47b9-8aec-322b3230c131 container secret-volume-test: <nil>
STEP: delete the pod
Oct 11 17:38:51.601: INFO: Waiting for pod pod-secrets-02475e12-ffd4-47b9-8aec-322b3230c131 to disappear
Oct 11 17:38:51.604: INFO: Pod pod-secrets-02475e12-ffd4-47b9-8aec-322b3230c131 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:38:51.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1319" for this suite.
Oct 11 17:38:57.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:38:57.747: INFO: namespace secrets-1319 deletion completed in 6.137746199s

• [SLOW TEST:8.233 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:38:57.747: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-6093, will wait for the garbage collector to delete the pods
Oct 11 17:39:07.856: INFO: Deleting Job.batch foo took: 9.64424ms
Oct 11 17:39:08.256: INFO: Terminating Job.batch foo pods took: 400.3045ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:39:50.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6093" for this suite.
Oct 11 17:39:56.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:39:56.508: INFO: namespace job-6093 deletion completed in 6.143091797s

• [SLOW TEST:58.761 seconds]
[sig-apps] Job
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:39:56.508: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-1205
I1011 17:39:56.546657      19 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-1205, replica count: 1
I1011 17:39:57.596965      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1011 17:39:58.597221      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 11 17:39:58.712: INFO: Created: latency-svc-gdtxx
Oct 11 17:39:58.720: INFO: Got endpoints: latency-svc-gdtxx [22.848647ms]
Oct 11 17:39:58.739: INFO: Created: latency-svc-v4wnz
Oct 11 17:39:58.744: INFO: Got endpoints: latency-svc-v4wnz [24.143933ms]
Oct 11 17:39:58.758: INFO: Created: latency-svc-c8l65
Oct 11 17:39:58.759: INFO: Got endpoints: latency-svc-c8l65 [39.086423ms]
Oct 11 17:39:58.772: INFO: Created: latency-svc-mq5kh
Oct 11 17:39:58.777: INFO: Got endpoints: latency-svc-mq5kh [56.34834ms]
Oct 11 17:39:58.794: INFO: Created: latency-svc-bwst2
Oct 11 17:39:58.800: INFO: Got endpoints: latency-svc-bwst2 [79.849795ms]
Oct 11 17:39:58.805: INFO: Created: latency-svc-rqp8c
Oct 11 17:39:58.820: INFO: Got endpoints: latency-svc-rqp8c [99.934173ms]
Oct 11 17:39:58.836: INFO: Created: latency-svc-nx5b6
Oct 11 17:39:58.842: INFO: Got endpoints: latency-svc-nx5b6 [121.073496ms]
Oct 11 17:39:58.856: INFO: Created: latency-svc-ntxlz
Oct 11 17:39:58.866: INFO: Got endpoints: latency-svc-ntxlz [144.931889ms]
Oct 11 17:39:58.875: INFO: Created: latency-svc-4zrpj
Oct 11 17:39:58.877: INFO: Got endpoints: latency-svc-4zrpj [155.612363ms]
Oct 11 17:39:58.895: INFO: Created: latency-svc-jftrm
Oct 11 17:39:58.903: INFO: Got endpoints: latency-svc-jftrm [182.189468ms]
Oct 11 17:39:58.917: INFO: Created: latency-svc-zxlkp
Oct 11 17:39:58.918: INFO: Got endpoints: latency-svc-zxlkp [196.979974ms]
Oct 11 17:39:59.070: INFO: Created: latency-svc-mnfc4
Oct 11 17:39:59.073: INFO: Got endpoints: latency-svc-mnfc4 [351.820948ms]
Oct 11 17:39:59.088: INFO: Created: latency-svc-6p8d7
Oct 11 17:39:59.097: INFO: Got endpoints: latency-svc-6p8d7 [375.839277ms]
Oct 11 17:39:59.105: INFO: Created: latency-svc-6qtvn
Oct 11 17:39:59.115: INFO: Got endpoints: latency-svc-6qtvn [393.416479ms]
Oct 11 17:39:59.115: INFO: Created: latency-svc-hszk4
Oct 11 17:39:59.126: INFO: Got endpoints: latency-svc-hszk4 [405.050069ms]
Oct 11 17:39:59.148: INFO: Created: latency-svc-gkdlb
Oct 11 17:39:59.150: INFO: Got endpoints: latency-svc-gkdlb [428.597228ms]
Oct 11 17:39:59.161: INFO: Created: latency-svc-qghv9
Oct 11 17:39:59.168: INFO: Got endpoints: latency-svc-qghv9 [424.236348ms]
Oct 11 17:39:59.185: INFO: Created: latency-svc-wjh87
Oct 11 17:39:59.198: INFO: Got endpoints: latency-svc-wjh87 [439.072269ms]
Oct 11 17:39:59.209: INFO: Created: latency-svc-tstls
Oct 11 17:39:59.213: INFO: Got endpoints: latency-svc-tstls [435.560162ms]
Oct 11 17:39:59.221: INFO: Created: latency-svc-xfdl8
Oct 11 17:39:59.228: INFO: Got endpoints: latency-svc-xfdl8 [427.888841ms]
Oct 11 17:39:59.241: INFO: Created: latency-svc-bw2bg
Oct 11 17:39:59.250: INFO: Got endpoints: latency-svc-bw2bg [429.506578ms]
Oct 11 17:39:59.263: INFO: Created: latency-svc-hmc6m
Oct 11 17:39:59.269: INFO: Got endpoints: latency-svc-hmc6m [427.366375ms]
Oct 11 17:39:59.276: INFO: Created: latency-svc-5x8tr
Oct 11 17:39:59.288: INFO: Got endpoints: latency-svc-5x8tr [422.035288ms]
Oct 11 17:39:59.315: INFO: Created: latency-svc-th5qd
Oct 11 17:39:59.319: INFO: Got endpoints: latency-svc-th5qd [442.015938ms]
Oct 11 17:39:59.329: INFO: Created: latency-svc-24qn8
Oct 11 17:39:59.338: INFO: Got endpoints: latency-svc-24qn8 [433.911834ms]
Oct 11 17:39:59.344: INFO: Created: latency-svc-227fv
Oct 11 17:39:59.350: INFO: Got endpoints: latency-svc-227fv [431.731617ms]
Oct 11 17:39:59.362: INFO: Created: latency-svc-jhmr5
Oct 11 17:39:59.368: INFO: Got endpoints: latency-svc-jhmr5 [295.170527ms]
Oct 11 17:39:59.386: INFO: Created: latency-svc-xcdfr
Oct 11 17:39:59.402: INFO: Got endpoints: latency-svc-xcdfr [304.844807ms]
Oct 11 17:39:59.409: INFO: Created: latency-svc-72v8t
Oct 11 17:39:59.415: INFO: Got endpoints: latency-svc-72v8t [299.939526ms]
Oct 11 17:39:59.432: INFO: Created: latency-svc-lf7f9
Oct 11 17:39:59.441: INFO: Got endpoints: latency-svc-lf7f9 [314.878879ms]
Oct 11 17:39:59.449: INFO: Created: latency-svc-4hxgv
Oct 11 17:39:59.457: INFO: Got endpoints: latency-svc-4hxgv [306.979509ms]
Oct 11 17:39:59.469: INFO: Created: latency-svc-g562l
Oct 11 17:39:59.476: INFO: Got endpoints: latency-svc-g562l [307.333091ms]
Oct 11 17:39:59.490: INFO: Created: latency-svc-7xhxw
Oct 11 17:39:59.505: INFO: Got endpoints: latency-svc-7xhxw [306.706816ms]
Oct 11 17:39:59.509: INFO: Created: latency-svc-qj7b6
Oct 11 17:39:59.509: INFO: Got endpoints: latency-svc-qj7b6 [296.246968ms]
Oct 11 17:39:59.548: INFO: Created: latency-svc-rcz9d
Oct 11 17:39:59.554: INFO: Got endpoints: latency-svc-rcz9d [325.219195ms]
Oct 11 17:39:59.573: INFO: Created: latency-svc-h7prf
Oct 11 17:39:59.575: INFO: Got endpoints: latency-svc-h7prf [324.910444ms]
Oct 11 17:39:59.601: INFO: Created: latency-svc-k4wzx
Oct 11 17:39:59.612: INFO: Got endpoints: latency-svc-k4wzx [342.18706ms]
Oct 11 17:39:59.623: INFO: Created: latency-svc-kh7gc
Oct 11 17:39:59.627: INFO: Got endpoints: latency-svc-kh7gc [339.133889ms]
Oct 11 17:39:59.642: INFO: Created: latency-svc-zwslz
Oct 11 17:39:59.650: INFO: Got endpoints: latency-svc-zwslz [330.354676ms]
Oct 11 17:39:59.662: INFO: Created: latency-svc-v7gfs
Oct 11 17:39:59.678: INFO: Got endpoints: latency-svc-v7gfs [339.548727ms]
Oct 11 17:39:59.706: INFO: Created: latency-svc-t9872
Oct 11 17:39:59.716: INFO: Got endpoints: latency-svc-t9872 [365.697671ms]
Oct 11 17:39:59.725: INFO: Created: latency-svc-jg5xx
Oct 11 17:39:59.731: INFO: Got endpoints: latency-svc-jg5xx [362.574143ms]
Oct 11 17:39:59.781: INFO: Created: latency-svc-zrbx5
Oct 11 17:39:59.788: INFO: Got endpoints: latency-svc-zrbx5 [386.330861ms]
Oct 11 17:39:59.799: INFO: Created: latency-svc-8wg45
Oct 11 17:39:59.807: INFO: Got endpoints: latency-svc-8wg45 [391.554599ms]
Oct 11 17:39:59.831: INFO: Created: latency-svc-wrtvs
Oct 11 17:39:59.831: INFO: Got endpoints: latency-svc-wrtvs [389.97563ms]
Oct 11 17:39:59.843: INFO: Created: latency-svc-qv8f9
Oct 11 17:39:59.851: INFO: Got endpoints: latency-svc-qv8f9 [393.844883ms]
Oct 11 17:39:59.868: INFO: Created: latency-svc-wptv6
Oct 11 17:39:59.874: INFO: Got endpoints: latency-svc-wptv6 [397.897494ms]
Oct 11 17:39:59.887: INFO: Created: latency-svc-q6q7s
Oct 11 17:39:59.894: INFO: Got endpoints: latency-svc-q6q7s [388.31294ms]
Oct 11 17:39:59.914: INFO: Created: latency-svc-z272x
Oct 11 17:39:59.933: INFO: Got endpoints: latency-svc-z272x [423.369568ms]
Oct 11 17:39:59.942: INFO: Created: latency-svc-t5gk5
Oct 11 17:39:59.943: INFO: Got endpoints: latency-svc-t5gk5 [389.299088ms]
Oct 11 17:39:59.956: INFO: Created: latency-svc-c5kzp
Oct 11 17:39:59.966: INFO: Got endpoints: latency-svc-c5kzp [391.087359ms]
Oct 11 17:39:59.986: INFO: Created: latency-svc-m2zzc
Oct 11 17:39:59.988: INFO: Got endpoints: latency-svc-m2zzc [375.933223ms]
Oct 11 17:40:00.004: INFO: Created: latency-svc-826t9
Oct 11 17:40:00.011: INFO: Got endpoints: latency-svc-826t9 [383.661085ms]
Oct 11 17:40:00.030: INFO: Created: latency-svc-42c7g
Oct 11 17:40:00.045: INFO: Got endpoints: latency-svc-42c7g [394.805993ms]
Oct 11 17:40:00.066: INFO: Created: latency-svc-sp77c
Oct 11 17:40:00.069: INFO: Got endpoints: latency-svc-sp77c [390.99654ms]
Oct 11 17:40:00.080: INFO: Created: latency-svc-g9dw4
Oct 11 17:40:00.087: INFO: Got endpoints: latency-svc-g9dw4 [371.071663ms]
Oct 11 17:40:00.118: INFO: Created: latency-svc-l8nnf
Oct 11 17:40:00.121: INFO: Got endpoints: latency-svc-l8nnf [390.188083ms]
Oct 11 17:40:00.152: INFO: Created: latency-svc-98kbp
Oct 11 17:40:00.170: INFO: Got endpoints: latency-svc-98kbp [381.654204ms]
Oct 11 17:40:00.187: INFO: Created: latency-svc-9pqvb
Oct 11 17:40:00.194: INFO: Got endpoints: latency-svc-9pqvb [387.32941ms]
Oct 11 17:40:00.211: INFO: Created: latency-svc-758s4
Oct 11 17:40:00.221: INFO: Got endpoints: latency-svc-758s4 [389.287125ms]
Oct 11 17:40:00.227: INFO: Created: latency-svc-4t9dv
Oct 11 17:40:00.248: INFO: Created: latency-svc-2nkcl
Oct 11 17:40:00.267: INFO: Created: latency-svc-mtbpw
Oct 11 17:40:00.273: INFO: Got endpoints: latency-svc-4t9dv [422.169569ms]
Oct 11 17:40:00.289: INFO: Created: latency-svc-cg72h
Oct 11 17:40:00.306: INFO: Created: latency-svc-fmqkg
Oct 11 17:40:00.320: INFO: Got endpoints: latency-svc-2nkcl [445.361123ms]
Oct 11 17:40:00.332: INFO: Created: latency-svc-sxbks
Oct 11 17:40:00.353: INFO: Created: latency-svc-89xrj
Oct 11 17:40:00.373: INFO: Got endpoints: latency-svc-mtbpw [479.043219ms]
Oct 11 17:40:00.381: INFO: Created: latency-svc-n9qxg
Oct 11 17:40:00.402: INFO: Created: latency-svc-n7rrv
Oct 11 17:40:00.423: INFO: Got endpoints: latency-svc-cg72h [490.261187ms]
Oct 11 17:40:00.427: INFO: Created: latency-svc-cp62t
Oct 11 17:40:00.450: INFO: Created: latency-svc-2wprx
Oct 11 17:40:00.464: INFO: Created: latency-svc-dhhtg
Oct 11 17:40:00.472: INFO: Got endpoints: latency-svc-fmqkg [529.260297ms]
Oct 11 17:40:00.491: INFO: Created: latency-svc-tgfmf
Oct 11 17:40:00.508: INFO: Created: latency-svc-6ttpd
Oct 11 17:40:00.521: INFO: Got endpoints: latency-svc-sxbks [554.357294ms]
Oct 11 17:40:00.526: INFO: Created: latency-svc-rxk5b
Oct 11 17:40:00.547: INFO: Created: latency-svc-t6zwl
Oct 11 17:40:00.572: INFO: Created: latency-svc-6tb94
Oct 11 17:40:00.574: INFO: Got endpoints: latency-svc-89xrj [585.886655ms]
Oct 11 17:40:00.592: INFO: Created: latency-svc-5jmx4
Oct 11 17:40:00.607: INFO: Created: latency-svc-c4rzf
Oct 11 17:40:00.623: INFO: Got endpoints: latency-svc-n9qxg [612.175314ms]
Oct 11 17:40:00.636: INFO: Created: latency-svc-g9j4q
Oct 11 17:40:00.663: INFO: Created: latency-svc-55k2r
Oct 11 17:40:00.677: INFO: Got endpoints: latency-svc-n7rrv [631.051343ms]
Oct 11 17:40:00.690: INFO: Created: latency-svc-5lmh5
Oct 11 17:40:00.718: INFO: Created: latency-svc-cqdhq
Oct 11 17:40:00.729: INFO: Got endpoints: latency-svc-cp62t [659.978909ms]
Oct 11 17:40:00.740: INFO: Created: latency-svc-t9hzx
Oct 11 17:40:00.757: INFO: Created: latency-svc-pg2jr
Oct 11 17:40:00.768: INFO: Got endpoints: latency-svc-2wprx [681.031517ms]
Oct 11 17:40:00.795: INFO: Created: latency-svc-sr2z8
Oct 11 17:40:00.819: INFO: Got endpoints: latency-svc-dhhtg [697.064873ms]
Oct 11 17:40:00.845: INFO: Created: latency-svc-x2nhv
Oct 11 17:40:00.872: INFO: Got endpoints: latency-svc-tgfmf [702.125033ms]
Oct 11 17:40:00.897: INFO: Created: latency-svc-p6769
Oct 11 17:40:00.920: INFO: Got endpoints: latency-svc-6ttpd [725.307943ms]
Oct 11 17:40:00.946: INFO: Created: latency-svc-ttb5k
Oct 11 17:40:00.969: INFO: Got endpoints: latency-svc-rxk5b [748.31346ms]
Oct 11 17:40:00.992: INFO: Created: latency-svc-cbwv7
Oct 11 17:40:01.020: INFO: Got endpoints: latency-svc-t6zwl [746.278657ms]
Oct 11 17:40:01.050: INFO: Created: latency-svc-vxdk5
Oct 11 17:40:01.069: INFO: Got endpoints: latency-svc-6tb94 [749.621097ms]
Oct 11 17:40:01.091: INFO: Created: latency-svc-2twbq
Oct 11 17:40:01.123: INFO: Got endpoints: latency-svc-5jmx4 [750.363639ms]
Oct 11 17:40:01.145: INFO: Created: latency-svc-mttrr
Oct 11 17:40:01.170: INFO: Got endpoints: latency-svc-c4rzf [746.548282ms]
Oct 11 17:40:01.194: INFO: Created: latency-svc-msqzf
Oct 11 17:40:01.219: INFO: Got endpoints: latency-svc-g9j4q [746.275916ms]
Oct 11 17:40:01.249: INFO: Created: latency-svc-klllj
Oct 11 17:40:01.272: INFO: Got endpoints: latency-svc-55k2r [750.964226ms]
Oct 11 17:40:01.294: INFO: Created: latency-svc-sm2r4
Oct 11 17:40:01.319: INFO: Got endpoints: latency-svc-5lmh5 [744.459535ms]
Oct 11 17:40:01.462: INFO: Got endpoints: latency-svc-cqdhq [837.891281ms]
Oct 11 17:40:01.463: INFO: Got endpoints: latency-svc-t9hzx [785.751113ms]
Oct 11 17:40:01.471: INFO: Got endpoints: latency-svc-pg2jr [741.495028ms]
Oct 11 17:40:01.478: INFO: Created: latency-svc-8sdgs
Oct 11 17:40:01.493: INFO: Created: latency-svc-95tmv
Oct 11 17:40:01.507: INFO: Created: latency-svc-s5rf4
Oct 11 17:40:01.526: INFO: Got endpoints: latency-svc-sr2z8 [756.911268ms]
Oct 11 17:40:01.540: INFO: Created: latency-svc-zgp8m
Oct 11 17:40:01.551: INFO: Created: latency-svc-djrnd
Oct 11 17:40:01.570: INFO: Got endpoints: latency-svc-x2nhv [751.528145ms]
Oct 11 17:40:01.596: INFO: Created: latency-svc-pmnw2
Oct 11 17:40:01.620: INFO: Got endpoints: latency-svc-ttb5k [699.372261ms]
Oct 11 17:40:01.646: INFO: Created: latency-svc-9prdq
Oct 11 17:40:01.669: INFO: Got endpoints: latency-svc-p6769 [796.426154ms]
Oct 11 17:40:01.694: INFO: Created: latency-svc-8zp6r
Oct 11 17:40:01.721: INFO: Got endpoints: latency-svc-cbwv7 [751.210102ms]
Oct 11 17:40:01.742: INFO: Created: latency-svc-zk56w
Oct 11 17:40:01.771: INFO: Got endpoints: latency-svc-vxdk5 [750.623676ms]
Oct 11 17:40:01.822: INFO: Created: latency-svc-4brm4
Oct 11 17:40:01.823: INFO: Got endpoints: latency-svc-2twbq [753.471578ms]
Oct 11 17:40:01.845: INFO: Created: latency-svc-2r4fk
Oct 11 17:40:01.871: INFO: Got endpoints: latency-svc-mttrr [747.670635ms]
Oct 11 17:40:01.897: INFO: Created: latency-svc-plppk
Oct 11 17:40:01.920: INFO: Got endpoints: latency-svc-msqzf [749.758588ms]
Oct 11 17:40:01.947: INFO: Created: latency-svc-hwgdq
Oct 11 17:40:01.970: INFO: Got endpoints: latency-svc-klllj [750.95613ms]
Oct 11 17:40:01.998: INFO: Created: latency-svc-bns68
Oct 11 17:40:02.021: INFO: Got endpoints: latency-svc-sm2r4 [748.471486ms]
Oct 11 17:40:02.045: INFO: Created: latency-svc-mg9bm
Oct 11 17:40:02.070: INFO: Got endpoints: latency-svc-8sdgs [750.582633ms]
Oct 11 17:40:02.100: INFO: Created: latency-svc-nq6qw
Oct 11 17:40:02.120: INFO: Got endpoints: latency-svc-95tmv [657.743205ms]
Oct 11 17:40:02.147: INFO: Created: latency-svc-hqv8n
Oct 11 17:40:02.170: INFO: Got endpoints: latency-svc-s5rf4 [707.403658ms]
Oct 11 17:40:02.195: INFO: Created: latency-svc-4vc7h
Oct 11 17:40:02.219: INFO: Got endpoints: latency-svc-zgp8m [747.855911ms]
Oct 11 17:40:02.243: INFO: Created: latency-svc-qncn9
Oct 11 17:40:02.271: INFO: Got endpoints: latency-svc-djrnd [744.587815ms]
Oct 11 17:40:02.292: INFO: Created: latency-svc-47vdc
Oct 11 17:40:02.324: INFO: Got endpoints: latency-svc-pmnw2 [752.658273ms]
Oct 11 17:40:02.351: INFO: Created: latency-svc-6jntv
Oct 11 17:40:02.369: INFO: Got endpoints: latency-svc-9prdq [749.083303ms]
Oct 11 17:40:02.393: INFO: Created: latency-svc-bzjsk
Oct 11 17:40:02.419: INFO: Got endpoints: latency-svc-8zp6r [749.253415ms]
Oct 11 17:40:02.442: INFO: Created: latency-svc-zd42n
Oct 11 17:40:02.469: INFO: Got endpoints: latency-svc-zk56w [748.842434ms]
Oct 11 17:40:02.500: INFO: Created: latency-svc-2bb2d
Oct 11 17:40:02.521: INFO: Got endpoints: latency-svc-4brm4 [750.371165ms]
Oct 11 17:40:02.554: INFO: Created: latency-svc-w6dvm
Oct 11 17:40:02.570: INFO: Got endpoints: latency-svc-2r4fk [746.948106ms]
Oct 11 17:40:02.593: INFO: Created: latency-svc-wtbvx
Oct 11 17:40:02.619: INFO: Got endpoints: latency-svc-plppk [747.780876ms]
Oct 11 17:40:02.642: INFO: Created: latency-svc-nsp6d
Oct 11 17:40:02.670: INFO: Got endpoints: latency-svc-hwgdq [749.260071ms]
Oct 11 17:40:02.701: INFO: Created: latency-svc-fqqnn
Oct 11 17:40:02.719: INFO: Got endpoints: latency-svc-bns68 [747.936041ms]
Oct 11 17:40:02.741: INFO: Created: latency-svc-vkt5c
Oct 11 17:40:02.769: INFO: Got endpoints: latency-svc-mg9bm [747.813597ms]
Oct 11 17:40:02.794: INFO: Created: latency-svc-tsdpd
Oct 11 17:40:02.819: INFO: Got endpoints: latency-svc-nq6qw [748.933077ms]
Oct 11 17:40:02.844: INFO: Created: latency-svc-x2f6j
Oct 11 17:40:02.870: INFO: Got endpoints: latency-svc-hqv8n [750.401886ms]
Oct 11 17:40:02.893: INFO: Created: latency-svc-bxv8j
Oct 11 17:40:02.920: INFO: Got endpoints: latency-svc-4vc7h [750.109462ms]
Oct 11 17:40:02.953: INFO: Created: latency-svc-6ll7s
Oct 11 17:40:02.970: INFO: Got endpoints: latency-svc-qncn9 [751.059065ms]
Oct 11 17:40:02.993: INFO: Created: latency-svc-rt44z
Oct 11 17:40:03.020: INFO: Got endpoints: latency-svc-47vdc [748.874439ms]
Oct 11 17:40:03.060: INFO: Created: latency-svc-cbml4
Oct 11 17:40:03.071: INFO: Got endpoints: latency-svc-6jntv [746.862261ms]
Oct 11 17:40:03.094: INFO: Created: latency-svc-kbfwt
Oct 11 17:40:03.120: INFO: Got endpoints: latency-svc-bzjsk [751.282509ms]
Oct 11 17:40:03.176: INFO: Got endpoints: latency-svc-zd42n [756.771192ms]
Oct 11 17:40:03.185: INFO: Created: latency-svc-ls67r
Oct 11 17:40:03.201: INFO: Created: latency-svc-xhd4j
Oct 11 17:40:03.223: INFO: Got endpoints: latency-svc-2bb2d [752.695261ms]
Oct 11 17:40:03.246: INFO: Created: latency-svc-wpj7j
Oct 11 17:40:03.270: INFO: Got endpoints: latency-svc-w6dvm [748.204123ms]
Oct 11 17:40:03.290: INFO: Created: latency-svc-ssggx
Oct 11 17:40:03.320: INFO: Got endpoints: latency-svc-wtbvx [749.628499ms]
Oct 11 17:40:03.345: INFO: Created: latency-svc-blq4l
Oct 11 17:40:03.373: INFO: Got endpoints: latency-svc-nsp6d [753.654738ms]
Oct 11 17:40:03.397: INFO: Created: latency-svc-xfgsz
Oct 11 17:40:03.421: INFO: Got endpoints: latency-svc-fqqnn [750.900754ms]
Oct 11 17:40:03.444: INFO: Created: latency-svc-qxw4j
Oct 11 17:40:03.473: INFO: Got endpoints: latency-svc-vkt5c [753.755699ms]
Oct 11 17:40:03.498: INFO: Created: latency-svc-db2z7
Oct 11 17:40:03.520: INFO: Got endpoints: latency-svc-tsdpd [750.932826ms]
Oct 11 17:40:03.542: INFO: Created: latency-svc-rttkn
Oct 11 17:40:03.572: INFO: Got endpoints: latency-svc-x2f6j [751.974543ms]
Oct 11 17:40:03.596: INFO: Created: latency-svc-5w2dz
Oct 11 17:40:03.621: INFO: Got endpoints: latency-svc-bxv8j [749.823765ms]
Oct 11 17:40:03.642: INFO: Created: latency-svc-nkzcs
Oct 11 17:40:03.672: INFO: Got endpoints: latency-svc-6ll7s [751.221642ms]
Oct 11 17:40:03.699: INFO: Created: latency-svc-glwn2
Oct 11 17:40:03.719: INFO: Got endpoints: latency-svc-rt44z [748.790425ms]
Oct 11 17:40:03.747: INFO: Created: latency-svc-9b952
Oct 11 17:40:03.771: INFO: Got endpoints: latency-svc-cbml4 [750.96412ms]
Oct 11 17:40:03.798: INFO: Created: latency-svc-4b5kd
Oct 11 17:40:03.819: INFO: Got endpoints: latency-svc-kbfwt [748.564528ms]
Oct 11 17:40:03.843: INFO: Created: latency-svc-8qvbb
Oct 11 17:40:03.873: INFO: Got endpoints: latency-svc-ls67r [752.345515ms]
Oct 11 17:40:03.894: INFO: Created: latency-svc-csd4n
Oct 11 17:40:03.923: INFO: Got endpoints: latency-svc-xhd4j [746.946126ms]
Oct 11 17:40:03.946: INFO: Created: latency-svc-9wnct
Oct 11 17:40:03.970: INFO: Got endpoints: latency-svc-wpj7j [746.804854ms]
Oct 11 17:40:03.992: INFO: Created: latency-svc-5h5xp
Oct 11 17:40:04.023: INFO: Got endpoints: latency-svc-ssggx [752.913821ms]
Oct 11 17:40:04.041: INFO: Created: latency-svc-cqffh
Oct 11 17:40:04.071: INFO: Got endpoints: latency-svc-blq4l [750.913725ms]
Oct 11 17:40:04.093: INFO: Created: latency-svc-xrw9n
Oct 11 17:40:04.121: INFO: Got endpoints: latency-svc-xfgsz [747.27001ms]
Oct 11 17:40:04.146: INFO: Created: latency-svc-d778k
Oct 11 17:40:04.170: INFO: Got endpoints: latency-svc-qxw4j [748.799003ms]
Oct 11 17:40:04.194: INFO: Created: latency-svc-nh9sl
Oct 11 17:40:04.221: INFO: Got endpoints: latency-svc-db2z7 [747.933879ms]
Oct 11 17:40:04.245: INFO: Created: latency-svc-hvtlz
Oct 11 17:40:04.270: INFO: Got endpoints: latency-svc-rttkn [750.20004ms]
Oct 11 17:40:04.294: INFO: Created: latency-svc-hrrfp
Oct 11 17:40:04.338: INFO: Got endpoints: latency-svc-5w2dz [766.452025ms]
Oct 11 17:40:04.369: INFO: Created: latency-svc-r8qff
Oct 11 17:40:04.375: INFO: Got endpoints: latency-svc-nkzcs [754.388589ms]
Oct 11 17:40:04.400: INFO: Created: latency-svc-scxln
Oct 11 17:40:04.422: INFO: Got endpoints: latency-svc-glwn2 [749.96076ms]
Oct 11 17:40:04.455: INFO: Created: latency-svc-5bkdd
Oct 11 17:40:04.477: INFO: Got endpoints: latency-svc-9b952 [757.012614ms]
Oct 11 17:40:04.502: INFO: Created: latency-svc-6xz7v
Oct 11 17:40:04.522: INFO: Got endpoints: latency-svc-4b5kd [750.441724ms]
Oct 11 17:40:04.548: INFO: Created: latency-svc-cr75g
Oct 11 17:40:04.571: INFO: Got endpoints: latency-svc-8qvbb [751.157071ms]
Oct 11 17:40:04.593: INFO: Created: latency-svc-9wwb8
Oct 11 17:40:04.621: INFO: Got endpoints: latency-svc-csd4n [748.026242ms]
Oct 11 17:40:04.648: INFO: Created: latency-svc-4vmc8
Oct 11 17:40:04.670: INFO: Got endpoints: latency-svc-9wnct [746.528775ms]
Oct 11 17:40:04.710: INFO: Created: latency-svc-92mk4
Oct 11 17:40:04.720: INFO: Got endpoints: latency-svc-5h5xp [748.657676ms]
Oct 11 17:40:04.748: INFO: Created: latency-svc-kmn5s
Oct 11 17:40:04.772: INFO: Got endpoints: latency-svc-cqffh [748.990668ms]
Oct 11 17:40:04.798: INFO: Created: latency-svc-szrbj
Oct 11 17:40:04.820: INFO: Got endpoints: latency-svc-xrw9n [748.811753ms]
Oct 11 17:40:04.845: INFO: Created: latency-svc-59knw
Oct 11 17:40:04.874: INFO: Got endpoints: latency-svc-d778k [752.785206ms]
Oct 11 17:40:04.902: INFO: Created: latency-svc-cddcs
Oct 11 17:40:04.920: INFO: Got endpoints: latency-svc-nh9sl [749.552906ms]
Oct 11 17:40:04.941: INFO: Created: latency-svc-sx4wj
Oct 11 17:40:04.976: INFO: Got endpoints: latency-svc-hvtlz [754.622867ms]
Oct 11 17:40:05.005: INFO: Created: latency-svc-d5bcs
Oct 11 17:40:05.022: INFO: Got endpoints: latency-svc-hrrfp [750.890469ms]
Oct 11 17:40:05.049: INFO: Created: latency-svc-w6ft5
Oct 11 17:40:05.071: INFO: Got endpoints: latency-svc-r8qff [731.885954ms]
Oct 11 17:40:05.093: INFO: Created: latency-svc-vgljb
Oct 11 17:40:05.123: INFO: Got endpoints: latency-svc-scxln [747.728425ms]
Oct 11 17:40:05.144: INFO: Created: latency-svc-9rzjm
Oct 11 17:40:05.185: INFO: Got endpoints: latency-svc-5bkdd [760.648825ms]
Oct 11 17:40:05.212: INFO: Created: latency-svc-dbm4b
Oct 11 17:40:05.220: INFO: Got endpoints: latency-svc-6xz7v [742.795351ms]
Oct 11 17:40:05.242: INFO: Created: latency-svc-hnjdj
Oct 11 17:40:05.274: INFO: Got endpoints: latency-svc-cr75g [751.548542ms]
Oct 11 17:40:05.300: INFO: Created: latency-svc-tbvq7
Oct 11 17:40:05.320: INFO: Got endpoints: latency-svc-9wwb8 [748.353654ms]
Oct 11 17:40:05.344: INFO: Created: latency-svc-vk9zb
Oct 11 17:40:05.370: INFO: Got endpoints: latency-svc-4vmc8 [748.162522ms]
Oct 11 17:40:05.514: INFO: Got endpoints: latency-svc-92mk4 [843.667209ms]
Oct 11 17:40:05.519: INFO: Got endpoints: latency-svc-kmn5s [798.994178ms]
Oct 11 17:40:05.532: INFO: Got endpoints: latency-svc-szrbj [760.022214ms]
Oct 11 17:40:05.534: INFO: Created: latency-svc-d9bpq
Oct 11 17:40:05.541: INFO: Created: latency-svc-zm4q4
Oct 11 17:40:05.558: INFO: Created: latency-svc-qp6nw
Oct 11 17:40:05.570: INFO: Got endpoints: latency-svc-59knw [748.990442ms]
Oct 11 17:40:05.580: INFO: Created: latency-svc-6fvbn
Oct 11 17:40:05.596: INFO: Created: latency-svc-dxmsw
Oct 11 17:40:05.621: INFO: Got endpoints: latency-svc-cddcs [746.901342ms]
Oct 11 17:40:05.650: INFO: Created: latency-svc-crwkh
Oct 11 17:40:05.669: INFO: Got endpoints: latency-svc-sx4wj [748.570625ms]
Oct 11 17:40:05.700: INFO: Created: latency-svc-csw4b
Oct 11 17:40:05.722: INFO: Got endpoints: latency-svc-d5bcs [745.910717ms]
Oct 11 17:40:05.746: INFO: Created: latency-svc-b4vrm
Oct 11 17:40:05.772: INFO: Got endpoints: latency-svc-w6ft5 [750.179336ms]
Oct 11 17:40:05.795: INFO: Created: latency-svc-pn4sz
Oct 11 17:40:05.822: INFO: Got endpoints: latency-svc-vgljb [750.789818ms]
Oct 11 17:40:05.843: INFO: Created: latency-svc-df5vz
Oct 11 17:40:05.871: INFO: Got endpoints: latency-svc-9rzjm [747.134641ms]
Oct 11 17:40:05.889: INFO: Created: latency-svc-z6jk8
Oct 11 17:40:05.921: INFO: Got endpoints: latency-svc-dbm4b [735.657309ms]
Oct 11 17:40:05.942: INFO: Created: latency-svc-kptk4
Oct 11 17:40:05.970: INFO: Got endpoints: latency-svc-hnjdj [750.133475ms]
Oct 11 17:40:05.991: INFO: Created: latency-svc-859vp
Oct 11 17:40:06.021: INFO: Got endpoints: latency-svc-tbvq7 [747.633778ms]
Oct 11 17:40:06.050: INFO: Created: latency-svc-dd6f7
Oct 11 17:40:06.072: INFO: Got endpoints: latency-svc-vk9zb [751.490481ms]
Oct 11 17:40:06.095: INFO: Created: latency-svc-4gzlx
Oct 11 17:40:06.120: INFO: Got endpoints: latency-svc-d9bpq [749.559229ms]
Oct 11 17:40:06.152: INFO: Created: latency-svc-czll6
Oct 11 17:40:06.171: INFO: Got endpoints: latency-svc-zm4q4 [657.275676ms]
Oct 11 17:40:06.194: INFO: Created: latency-svc-7q9wv
Oct 11 17:40:06.221: INFO: Got endpoints: latency-svc-qp6nw [701.876913ms]
Oct 11 17:40:06.247: INFO: Created: latency-svc-xlnln
Oct 11 17:40:06.274: INFO: Got endpoints: latency-svc-6fvbn [741.760999ms]
Oct 11 17:40:06.301: INFO: Created: latency-svc-4trss
Oct 11 17:40:06.324: INFO: Got endpoints: latency-svc-dxmsw [754.165085ms]
Oct 11 17:40:06.350: INFO: Created: latency-svc-mcxgq
Oct 11 17:40:06.370: INFO: Got endpoints: latency-svc-crwkh [748.475282ms]
Oct 11 17:40:06.403: INFO: Created: latency-svc-jz5wl
Oct 11 17:40:06.421: INFO: Got endpoints: latency-svc-csw4b [751.909029ms]
Oct 11 17:40:06.445: INFO: Created: latency-svc-zpmzt
Oct 11 17:40:06.470: INFO: Got endpoints: latency-svc-b4vrm [747.806276ms]
Oct 11 17:40:06.496: INFO: Created: latency-svc-tmfnf
Oct 11 17:40:06.520: INFO: Got endpoints: latency-svc-pn4sz [747.561955ms]
Oct 11 17:40:06.549: INFO: Created: latency-svc-8g5zr
Oct 11 17:40:06.571: INFO: Got endpoints: latency-svc-df5vz [749.316213ms]
Oct 11 17:40:06.620: INFO: Got endpoints: latency-svc-z6jk8 [748.946209ms]
Oct 11 17:40:06.670: INFO: Got endpoints: latency-svc-kptk4 [748.659762ms]
Oct 11 17:40:06.721: INFO: Got endpoints: latency-svc-859vp [751.133222ms]
Oct 11 17:40:06.774: INFO: Got endpoints: latency-svc-dd6f7 [752.068727ms]
Oct 11 17:40:06.821: INFO: Got endpoints: latency-svc-4gzlx [748.976341ms]
Oct 11 17:40:06.876: INFO: Got endpoints: latency-svc-czll6 [755.702505ms]
Oct 11 17:40:06.925: INFO: Got endpoints: latency-svc-7q9wv [752.868027ms]
Oct 11 17:40:06.972: INFO: Got endpoints: latency-svc-xlnln [750.362337ms]
Oct 11 17:40:07.020: INFO: Got endpoints: latency-svc-4trss [745.529254ms]
Oct 11 17:40:07.071: INFO: Got endpoints: latency-svc-mcxgq [746.06199ms]
Oct 11 17:40:07.121: INFO: Got endpoints: latency-svc-jz5wl [750.357455ms]
Oct 11 17:40:07.178: INFO: Got endpoints: latency-svc-zpmzt [755.54871ms]
Oct 11 17:40:07.221: INFO: Got endpoints: latency-svc-tmfnf [750.485809ms]
Oct 11 17:40:07.276: INFO: Got endpoints: latency-svc-8g5zr [755.045478ms]
Oct 11 17:40:07.276: INFO: Latencies: [24.143933ms 39.086423ms 56.34834ms 79.849795ms 99.934173ms 121.073496ms 144.931889ms 155.612363ms 182.189468ms 196.979974ms 295.170527ms 296.246968ms 299.939526ms 304.844807ms 306.706816ms 306.979509ms 307.333091ms 314.878879ms 324.910444ms 325.219195ms 330.354676ms 339.133889ms 339.548727ms 342.18706ms 351.820948ms 362.574143ms 365.697671ms 371.071663ms 375.839277ms 375.933223ms 381.654204ms 383.661085ms 386.330861ms 387.32941ms 388.31294ms 389.287125ms 389.299088ms 389.97563ms 390.188083ms 390.99654ms 391.087359ms 391.554599ms 393.416479ms 393.844883ms 394.805993ms 397.897494ms 405.050069ms 422.035288ms 422.169569ms 423.369568ms 424.236348ms 427.366375ms 427.888841ms 428.597228ms 429.506578ms 431.731617ms 433.911834ms 435.560162ms 439.072269ms 442.015938ms 445.361123ms 479.043219ms 490.261187ms 529.260297ms 554.357294ms 585.886655ms 612.175314ms 631.051343ms 657.275676ms 657.743205ms 659.978909ms 681.031517ms 697.064873ms 699.372261ms 701.876913ms 702.125033ms 707.403658ms 725.307943ms 731.885954ms 735.657309ms 741.495028ms 741.760999ms 742.795351ms 744.459535ms 744.587815ms 745.529254ms 745.910717ms 746.06199ms 746.275916ms 746.278657ms 746.528775ms 746.548282ms 746.804854ms 746.862261ms 746.901342ms 746.946126ms 746.948106ms 747.134641ms 747.27001ms 747.561955ms 747.633778ms 747.670635ms 747.728425ms 747.780876ms 747.806276ms 747.813597ms 747.855911ms 747.933879ms 747.936041ms 748.026242ms 748.162522ms 748.204123ms 748.31346ms 748.353654ms 748.471486ms 748.475282ms 748.564528ms 748.570625ms 748.657676ms 748.659762ms 748.790425ms 748.799003ms 748.811753ms 748.842434ms 748.874439ms 748.933077ms 748.946209ms 748.976341ms 748.990442ms 748.990668ms 749.083303ms 749.253415ms 749.260071ms 749.316213ms 749.552906ms 749.559229ms 749.621097ms 749.628499ms 749.758588ms 749.823765ms 749.96076ms 750.109462ms 750.133475ms 750.179336ms 750.20004ms 750.357455ms 750.362337ms 750.363639ms 750.371165ms 750.401886ms 750.441724ms 750.485809ms 750.582633ms 750.623676ms 750.789818ms 750.890469ms 750.900754ms 750.913725ms 750.932826ms 750.95613ms 750.96412ms 750.964226ms 751.059065ms 751.133222ms 751.157071ms 751.210102ms 751.221642ms 751.282509ms 751.490481ms 751.528145ms 751.548542ms 751.909029ms 751.974543ms 752.068727ms 752.345515ms 752.658273ms 752.695261ms 752.785206ms 752.868027ms 752.913821ms 753.471578ms 753.654738ms 753.755699ms 754.165085ms 754.388589ms 754.622867ms 755.045478ms 755.54871ms 755.702505ms 756.771192ms 756.911268ms 757.012614ms 760.022214ms 760.648825ms 766.452025ms 785.751113ms 796.426154ms 798.994178ms 837.891281ms 843.667209ms]
Oct 11 17:40:07.276: INFO: 50 %ile: 747.633778ms
Oct 11 17:40:07.276: INFO: 90 %ile: 753.471578ms
Oct 11 17:40:07.276: INFO: 99 %ile: 837.891281ms
Oct 11 17:40:07.276: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:40:07.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-1205" for this suite.
Oct 11 17:40:35.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:40:35.432: INFO: namespace svc-latency-1205 deletion completed in 28.14734721s

• [SLOW TEST:38.924 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:40:35.434: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 11 17:40:35.480: INFO: Waiting up to 5m0s for pod "pod-e23ab941-06c4-4021-8282-6a36872d7166" in namespace "emptydir-8350" to be "success or failure"
Oct 11 17:40:35.484: INFO: Pod "pod-e23ab941-06c4-4021-8282-6a36872d7166": Phase="Pending", Reason="", readiness=false. Elapsed: 4.458625ms
Oct 11 17:40:37.489: INFO: Pod "pod-e23ab941-06c4-4021-8282-6a36872d7166": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008721852s
Oct 11 17:40:39.493: INFO: Pod "pod-e23ab941-06c4-4021-8282-6a36872d7166": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013240592s
STEP: Saw pod success
Oct 11 17:40:39.493: INFO: Pod "pod-e23ab941-06c4-4021-8282-6a36872d7166" satisfied condition "success or failure"
Oct 11 17:40:39.497: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod pod-e23ab941-06c4-4021-8282-6a36872d7166 container test-container: <nil>
STEP: delete the pod
Oct 11 17:40:39.529: INFO: Waiting for pod pod-e23ab941-06c4-4021-8282-6a36872d7166 to disappear
Oct 11 17:40:39.533: INFO: Pod pod-e23ab941-06c4-4021-8282-6a36872d7166 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:40:39.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8350" for this suite.
Oct 11 17:40:45.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:40:45.677: INFO: namespace emptydir-8350 deletion completed in 6.13903501s

• [SLOW TEST:10.244 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:40:45.678: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:40:49.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-6772" for this suite.
Oct 11 17:40:55.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:40:55.916: INFO: namespace emptydir-wrapper-6772 deletion completed in 6.135366556s

• [SLOW TEST:10.238 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:40:55.916: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:41:12.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4831" for this suite.
Oct 11 17:41:18.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:41:18.213: INFO: namespace resourcequota-4831 deletion completed in 6.147594596s

• [SLOW TEST:22.296 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:41:18.213: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-9881/secret-test-0b0ab480-b6a3-4cc8-8fc2-e0e7ec10d5bf
STEP: Creating a pod to test consume secrets
Oct 11 17:41:18.262: INFO: Waiting up to 5m0s for pod "pod-configmaps-85a8936d-1232-4244-a23d-ebb0d5cdfaaf" in namespace "secrets-9881" to be "success or failure"
Oct 11 17:41:18.268: INFO: Pod "pod-configmaps-85a8936d-1232-4244-a23d-ebb0d5cdfaaf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.128197ms
Oct 11 17:41:20.277: INFO: Pod "pod-configmaps-85a8936d-1232-4244-a23d-ebb0d5cdfaaf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014678882s
STEP: Saw pod success
Oct 11 17:41:20.277: INFO: Pod "pod-configmaps-85a8936d-1232-4244-a23d-ebb0d5cdfaaf" satisfied condition "success or failure"
Oct 11 17:41:20.281: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-configmaps-85a8936d-1232-4244-a23d-ebb0d5cdfaaf container env-test: <nil>
STEP: delete the pod
Oct 11 17:41:20.315: INFO: Waiting for pod pod-configmaps-85a8936d-1232-4244-a23d-ebb0d5cdfaaf to disappear
Oct 11 17:41:20.319: INFO: Pod pod-configmaps-85a8936d-1232-4244-a23d-ebb0d5cdfaaf no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:41:20.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9881" for this suite.
Oct 11 17:41:26.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:41:26.461: INFO: namespace secrets-9881 deletion completed in 6.136022222s

• [SLOW TEST:8.247 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:41:26.461: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Oct 11 17:41:26.545: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 11 17:41:26.558: INFO: Waiting for terminating namespaces to be deleted...
Oct 11 17:41:26.562: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-1-25.eu-west-3.compute.internal before test
Oct 11 17:41:26.576: INFO: canal-jn9ph from kube-system started at 2019-10-11 17:26:31 +0000 UTC (2 container statuses recorded)
Oct 11 17:41:26.576: INFO: 	Container calico-node ready: true, restart count 0
Oct 11 17:41:26.576: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 11 17:41:26.576: INFO: sonobuoy-e2e-job-56f76d39d0764ff1 from sonobuoy started at 2019-10-11 17:28:08 +0000 UTC (2 container statuses recorded)
Oct 11 17:41:26.576: INFO: 	Container e2e ready: true, restart count 0
Oct 11 17:41:26.576: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 11 17:41:26.577: INFO: sonobuoy-systemd-logs-daemon-set-8223689078594c46-86r77 from sonobuoy started at 2019-10-11 17:28:08 +0000 UTC (2 container statuses recorded)
Oct 11 17:41:26.577: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 11 17:41:26.577: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 11 17:41:26.577: INFO: kube-proxy-m86rm from kube-system started at 2019-10-11 17:26:31 +0000 UTC (1 container statuses recorded)
Oct 11 17:41:26.577: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 11 17:41:26.577: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-5-54.eu-west-3.compute.internal before test
Oct 11 17:41:26.585: INFO: canal-hdnlb from kube-system started at 2019-10-11 17:26:30 +0000 UTC (2 container statuses recorded)
Oct 11 17:41:26.585: INFO: 	Container calico-node ready: true, restart count 0
Oct 11 17:41:26.585: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 11 17:41:26.585: INFO: sonobuoy from sonobuoy started at 2019-10-11 17:28:02 +0000 UTC (1 container statuses recorded)
Oct 11 17:41:26.585: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 11 17:41:26.585: INFO: sonobuoy-systemd-logs-daemon-set-8223689078594c46-wrftl from sonobuoy started at 2019-10-11 17:28:08 +0000 UTC (2 container statuses recorded)
Oct 11 17:41:26.585: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 11 17:41:26.585: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 11 17:41:26.585: INFO: kube-proxy-gczvl from kube-system started at 2019-10-11 17:26:30 +0000 UTC (1 container statuses recorded)
Oct 11 17:41:26.585: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 11 17:41:26.585: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-6-233.eu-west-3.compute.internal before test
Oct 11 17:41:26.591: INFO: kube-proxy-qw2gl from kube-system started at 2019-10-11 17:24:22 +0000 UTC (1 container statuses recorded)
Oct 11 17:41:26.591: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 11 17:41:26.591: INFO: canal-2xwdt from kube-system started at 2019-10-11 17:24:22 +0000 UTC (2 container statuses recorded)
Oct 11 17:41:26.591: INFO: 	Container calico-node ready: true, restart count 0
Oct 11 17:41:26.591: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 11 17:41:26.591: INFO: metrics-server-59bb664678-prm7v from kube-system started at 2019-10-11 17:24:41 +0000 UTC (1 container statuses recorded)
Oct 11 17:41:26.591: INFO: 	Container metrics-server ready: true, restart count 0
Oct 11 17:41:26.591: INFO: sonobuoy-systemd-logs-daemon-set-8223689078594c46-lhhdq from sonobuoy started at 2019-10-11 17:28:08 +0000 UTC (2 container statuses recorded)
Oct 11 17:41:26.591: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 11 17:41:26.591: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node ip-172-31-1-25.eu-west-3.compute.internal
STEP: verifying the node has the label node ip-172-31-5-54.eu-west-3.compute.internal
STEP: verifying the node has the label node ip-172-31-6-233.eu-west-3.compute.internal
Oct 11 17:41:26.642: INFO: Pod canal-2xwdt requesting resource cpu=250m on Node ip-172-31-6-233.eu-west-3.compute.internal
Oct 11 17:41:26.643: INFO: Pod canal-hdnlb requesting resource cpu=250m on Node ip-172-31-5-54.eu-west-3.compute.internal
Oct 11 17:41:26.643: INFO: Pod canal-jn9ph requesting resource cpu=250m on Node ip-172-31-1-25.eu-west-3.compute.internal
Oct 11 17:41:26.643: INFO: Pod kube-proxy-gczvl requesting resource cpu=0m on Node ip-172-31-5-54.eu-west-3.compute.internal
Oct 11 17:41:26.643: INFO: Pod kube-proxy-m86rm requesting resource cpu=0m on Node ip-172-31-1-25.eu-west-3.compute.internal
Oct 11 17:41:26.643: INFO: Pod kube-proxy-qw2gl requesting resource cpu=0m on Node ip-172-31-6-233.eu-west-3.compute.internal
Oct 11 17:41:26.643: INFO: Pod metrics-server-59bb664678-prm7v requesting resource cpu=0m on Node ip-172-31-6-233.eu-west-3.compute.internal
Oct 11 17:41:26.643: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-5-54.eu-west-3.compute.internal
Oct 11 17:41:26.643: INFO: Pod sonobuoy-e2e-job-56f76d39d0764ff1 requesting resource cpu=0m on Node ip-172-31-1-25.eu-west-3.compute.internal
Oct 11 17:41:26.643: INFO: Pod sonobuoy-systemd-logs-daemon-set-8223689078594c46-86r77 requesting resource cpu=0m on Node ip-172-31-1-25.eu-west-3.compute.internal
Oct 11 17:41:26.643: INFO: Pod sonobuoy-systemd-logs-daemon-set-8223689078594c46-lhhdq requesting resource cpu=0m on Node ip-172-31-6-233.eu-west-3.compute.internal
Oct 11 17:41:26.643: INFO: Pod sonobuoy-systemd-logs-daemon-set-8223689078594c46-wrftl requesting resource cpu=0m on Node ip-172-31-5-54.eu-west-3.compute.internal
STEP: Starting Pods to consume most of the cluster CPU.
Oct 11 17:41:26.643: INFO: Creating a pod which consumes cpu=1085m on Node ip-172-31-5-54.eu-west-3.compute.internal
Oct 11 17:41:26.651: INFO: Creating a pod which consumes cpu=1085m on Node ip-172-31-6-233.eu-west-3.compute.internal
Oct 11 17:41:26.658: INFO: Creating a pod which consumes cpu=1085m on Node ip-172-31-1-25.eu-west-3.compute.internal
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3b45f803-b60e-416d-8e14-899c1b572dda.15cca88b589f0dc9], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5395/filler-pod-3b45f803-b60e-416d-8e14-899c1b572dda to ip-172-31-1-25.eu-west-3.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3b45f803-b60e-416d-8e14-899c1b572dda.15cca88ba3365d84], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3b45f803-b60e-416d-8e14-899c1b572dda.15cca88ba7d4f9bc], Reason = [Created], Message = [Created container filler-pod-3b45f803-b60e-416d-8e14-899c1b572dda]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3b45f803-b60e-416d-8e14-899c1b572dda.15cca88bb89faabd], Reason = [Started], Message = [Started container filler-pod-3b45f803-b60e-416d-8e14-899c1b572dda]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a15aa8f1-9877-4f13-bfc3-249de060c88b.15cca88b583322a2], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5395/filler-pod-a15aa8f1-9877-4f13-bfc3-249de060c88b to ip-172-31-6-233.eu-west-3.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a15aa8f1-9877-4f13-bfc3-249de060c88b.15cca88b960dbe08], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a15aa8f1-9877-4f13-bfc3-249de060c88b.15cca88b9add38d6], Reason = [Created], Message = [Created container filler-pod-a15aa8f1-9877-4f13-bfc3-249de060c88b]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a15aa8f1-9877-4f13-bfc3-249de060c88b.15cca88bab37a778], Reason = [Started], Message = [Started container filler-pod-a15aa8f1-9877-4f13-bfc3-249de060c88b]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ceec3112-901a-451b-a614-54e801d284ee.15cca88b57b5481d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5395/filler-pod-ceec3112-901a-451b-a614-54e801d284ee to ip-172-31-5-54.eu-west-3.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ceec3112-901a-451b-a614-54e801d284ee.15cca88b96804b6e], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ceec3112-901a-451b-a614-54e801d284ee.15cca88b9ab53764], Reason = [Created], Message = [Created container filler-pod-ceec3112-901a-451b-a614-54e801d284ee]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ceec3112-901a-451b-a614-54e801d284ee.15cca88ba9b75daf], Reason = [Started], Message = [Started container filler-pod-ceec3112-901a-451b-a614-54e801d284ee]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15cca88c48ae3982], Reason = [FailedScheduling], Message = [0/6 nodes are available: 3 Insufficient cpu, 3 node(s) had taints that the pod didn't tolerate.]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15cca88c495421fa], Reason = [FailedScheduling], Message = [0/6 nodes are available: 3 Insufficient cpu, 3 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node ip-172-31-6-233.eu-west-3.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-31-1-25.eu-west-3.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-31-5-54.eu-west-3.compute.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:41:31.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5395" for this suite.
Oct 11 17:41:37.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:41:37.915: INFO: namespace sched-pred-5395 deletion completed in 6.154264842s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:11.454 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:41:37.915: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Oct 11 17:41:37.951: INFO: Waiting up to 1m0s for all nodes to be ready
Oct 11 17:42:37.969: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 17:42:37.973: INFO: Starting informer...
STEP: Starting pod...
Oct 11 17:42:38.187: INFO: Pod is running on ip-172-31-5-54.eu-west-3.compute.internal. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Oct 11 17:42:38.204: INFO: Pod wasn't evicted. Proceeding
Oct 11 17:42:38.204: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Oct 11 17:43:53.219: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:43:53.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-9609" for this suite.
Oct 11 17:44:05.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:44:05.366: INFO: namespace taint-single-pod-9609 deletion completed in 12.141079672s

• [SLOW TEST:147.451 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:44:05.366: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 11 17:44:05.414: INFO: Waiting up to 5m0s for pod "pod-9dd42f22-ae6d-42c9-ad88-42ec105a705e" in namespace "emptydir-6164" to be "success or failure"
Oct 11 17:44:05.419: INFO: Pod "pod-9dd42f22-ae6d-42c9-ad88-42ec105a705e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.871334ms
Oct 11 17:44:07.423: INFO: Pod "pod-9dd42f22-ae6d-42c9-ad88-42ec105a705e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009839911s
Oct 11 17:44:09.428: INFO: Pod "pod-9dd42f22-ae6d-42c9-ad88-42ec105a705e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014615549s
STEP: Saw pod success
Oct 11 17:44:09.428: INFO: Pod "pod-9dd42f22-ae6d-42c9-ad88-42ec105a705e" satisfied condition "success or failure"
Oct 11 17:44:09.432: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-9dd42f22-ae6d-42c9-ad88-42ec105a705e container test-container: <nil>
STEP: delete the pod
Oct 11 17:44:09.465: INFO: Waiting for pod pod-9dd42f22-ae6d-42c9-ad88-42ec105a705e to disappear
Oct 11 17:44:09.468: INFO: Pod pod-9dd42f22-ae6d-42c9-ad88-42ec105a705e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:44:09.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6164" for this suite.
Oct 11 17:44:15.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:44:15.609: INFO: namespace emptydir-6164 deletion completed in 6.13586907s

• [SLOW TEST:10.243 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:44:15.609: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Oct 11 17:44:15.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 cluster-info'
Oct 11 17:44:15.706: INFO: stderr: ""
Oct 11 17:44:15.706: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:44:15.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4251" for this suite.
Oct 11 17:44:21.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:44:21.858: INFO: namespace kubectl-4251 deletion completed in 6.147004063s

• [SLOW TEST:6.249 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:44:21.859: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-2892f2ec-1e8e-4b56-8d8d-2f6ce890d949
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:44:25.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3154" for this suite.
Oct 11 17:44:43.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:44:44.113: INFO: namespace configmap-3154 deletion completed in 18.141117196s

• [SLOW TEST:22.254 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:44:44.113: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Oct 11 17:44:44.155: INFO: Waiting up to 5m0s for pod "downward-api-131bfc4e-b430-4f46-8db5-a6df801ae3de" in namespace "downward-api-3423" to be "success or failure"
Oct 11 17:44:44.160: INFO: Pod "downward-api-131bfc4e-b430-4f46-8db5-a6df801ae3de": Phase="Pending", Reason="", readiness=false. Elapsed: 4.38236ms
Oct 11 17:44:46.165: INFO: Pod "downward-api-131bfc4e-b430-4f46-8db5-a6df801ae3de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009165132s
STEP: Saw pod success
Oct 11 17:44:46.165: INFO: Pod "downward-api-131bfc4e-b430-4f46-8db5-a6df801ae3de" satisfied condition "success or failure"
Oct 11 17:44:46.170: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod downward-api-131bfc4e-b430-4f46-8db5-a6df801ae3de container dapi-container: <nil>
STEP: delete the pod
Oct 11 17:44:46.197: INFO: Waiting for pod downward-api-131bfc4e-b430-4f46-8db5-a6df801ae3de to disappear
Oct 11 17:44:46.204: INFO: Pod downward-api-131bfc4e-b430-4f46-8db5-a6df801ae3de no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:44:46.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3423" for this suite.
Oct 11 17:44:52.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:44:52.355: INFO: namespace downward-api-3423 deletion completed in 6.142505939s

• [SLOW TEST:8.242 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:44:52.355: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-247b376a-8045-4e9a-91cb-44e02f40f4b2
STEP: Creating a pod to test consume configMaps
Oct 11 17:44:52.453: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-35259be9-6746-4951-80bf-9368447ed461" in namespace "projected-911" to be "success or failure"
Oct 11 17:44:52.459: INFO: Pod "pod-projected-configmaps-35259be9-6746-4951-80bf-9368447ed461": Phase="Pending", Reason="", readiness=false. Elapsed: 5.930802ms
Oct 11 17:44:54.464: INFO: Pod "pod-projected-configmaps-35259be9-6746-4951-80bf-9368447ed461": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010461284s
STEP: Saw pod success
Oct 11 17:44:54.464: INFO: Pod "pod-projected-configmaps-35259be9-6746-4951-80bf-9368447ed461" satisfied condition "success or failure"
Oct 11 17:44:54.467: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod pod-projected-configmaps-35259be9-6746-4951-80bf-9368447ed461 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 11 17:44:54.500: INFO: Waiting for pod pod-projected-configmaps-35259be9-6746-4951-80bf-9368447ed461 to disappear
Oct 11 17:44:54.503: INFO: Pod pod-projected-configmaps-35259be9-6746-4951-80bf-9368447ed461 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:44:54.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-911" for this suite.
Oct 11 17:45:00.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:45:00.644: INFO: namespace projected-911 deletion completed in 6.136318374s

• [SLOW TEST:8.289 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:45:00.645: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 11 17:45:00.740: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3babf783-b267-4c82-944c-c9757c0fbcb6" in namespace "downward-api-8738" to be "success or failure"
Oct 11 17:45:00.745: INFO: Pod "downwardapi-volume-3babf783-b267-4c82-944c-c9757c0fbcb6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.585538ms
Oct 11 17:45:02.750: INFO: Pod "downwardapi-volume-3babf783-b267-4c82-944c-c9757c0fbcb6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010550752s
STEP: Saw pod success
Oct 11 17:45:02.750: INFO: Pod "downwardapi-volume-3babf783-b267-4c82-944c-c9757c0fbcb6" satisfied condition "success or failure"
Oct 11 17:45:02.754: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod downwardapi-volume-3babf783-b267-4c82-944c-c9757c0fbcb6 container client-container: <nil>
STEP: delete the pod
Oct 11 17:45:02.781: INFO: Waiting for pod downwardapi-volume-3babf783-b267-4c82-944c-c9757c0fbcb6 to disappear
Oct 11 17:45:02.785: INFO: Pod downwardapi-volume-3babf783-b267-4c82-944c-c9757c0fbcb6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:45:02.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8738" for this suite.
Oct 11 17:45:08.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:45:08.926: INFO: namespace downward-api-8738 deletion completed in 6.135928443s

• [SLOW TEST:8.281 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:45:08.926: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 11 17:45:08.969: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ba93c7ce-517d-4707-9335-ca94630d874d" in namespace "downward-api-9509" to be "success or failure"
Oct 11 17:45:08.975: INFO: Pod "downwardapi-volume-ba93c7ce-517d-4707-9335-ca94630d874d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.999803ms
Oct 11 17:45:10.979: INFO: Pod "downwardapi-volume-ba93c7ce-517d-4707-9335-ca94630d874d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010449815s
Oct 11 17:45:12.984: INFO: Pod "downwardapi-volume-ba93c7ce-517d-4707-9335-ca94630d874d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015045182s
STEP: Saw pod success
Oct 11 17:45:12.984: INFO: Pod "downwardapi-volume-ba93c7ce-517d-4707-9335-ca94630d874d" satisfied condition "success or failure"
Oct 11 17:45:12.988: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod downwardapi-volume-ba93c7ce-517d-4707-9335-ca94630d874d container client-container: <nil>
STEP: delete the pod
Oct 11 17:45:13.012: INFO: Waiting for pod downwardapi-volume-ba93c7ce-517d-4707-9335-ca94630d874d to disappear
Oct 11 17:45:13.020: INFO: Pod downwardapi-volume-ba93c7ce-517d-4707-9335-ca94630d874d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:45:13.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9509" for this suite.
Oct 11 17:45:19.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:45:19.160: INFO: namespace downward-api-9509 deletion completed in 6.132232302s

• [SLOW TEST:10.233 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:45:19.160: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 11 17:45:19.203: INFO: Waiting up to 5m0s for pod "downwardapi-volume-25816489-6683-4d05-9d33-84fb1112656c" in namespace "projected-7365" to be "success or failure"
Oct 11 17:45:19.210: INFO: Pod "downwardapi-volume-25816489-6683-4d05-9d33-84fb1112656c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.399156ms
Oct 11 17:45:21.214: INFO: Pod "downwardapi-volume-25816489-6683-4d05-9d33-84fb1112656c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010941599s
Oct 11 17:45:23.218: INFO: Pod "downwardapi-volume-25816489-6683-4d05-9d33-84fb1112656c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015180953s
STEP: Saw pod success
Oct 11 17:45:23.218: INFO: Pod "downwardapi-volume-25816489-6683-4d05-9d33-84fb1112656c" satisfied condition "success or failure"
Oct 11 17:45:23.223: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod downwardapi-volume-25816489-6683-4d05-9d33-84fb1112656c container client-container: <nil>
STEP: delete the pod
Oct 11 17:45:23.247: INFO: Waiting for pod downwardapi-volume-25816489-6683-4d05-9d33-84fb1112656c to disappear
Oct 11 17:45:23.250: INFO: Pod downwardapi-volume-25816489-6683-4d05-9d33-84fb1112656c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:45:23.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7365" for this suite.
Oct 11 17:45:29.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:45:29.395: INFO: namespace projected-7365 deletion completed in 6.140201632s

• [SLOW TEST:10.236 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:45:29.396: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 11 17:45:35.560: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 11 17:45:35.564: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 11 17:45:37.564: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 11 17:45:37.569: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 11 17:45:39.564: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 11 17:45:39.569: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 11 17:45:41.564: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 11 17:45:41.569: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 11 17:45:43.564: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 11 17:45:43.573: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:45:43.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3969" for this suite.
Oct 11 17:45:55.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:45:55.735: INFO: namespace container-lifecycle-hook-3969 deletion completed in 12.15791569s

• [SLOW TEST:26.340 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:45:55.736: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-9649
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 11 17:45:55.773: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 11 17:46:19.873: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.5.23:8080/dial?request=hostName&protocol=http&host=10.244.5.22&port=8080&tries=1'] Namespace:pod-network-test-9649 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 11 17:46:19.873: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 17:46:20.078: INFO: Waiting for endpoints: map[]
Oct 11 17:46:20.082: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.5.23:8080/dial?request=hostName&protocol=http&host=10.244.3.29&port=8080&tries=1'] Namespace:pod-network-test-9649 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 11 17:46:20.082: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 17:46:20.332: INFO: Waiting for endpoints: map[]
Oct 11 17:46:20.336: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.5.23:8080/dial?request=hostName&protocol=http&host=10.244.4.15&port=8080&tries=1'] Namespace:pod-network-test-9649 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 11 17:46:20.336: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 17:46:20.632: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:46:20.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9649" for this suite.
Oct 11 17:46:32.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:46:32.774: INFO: namespace pod-network-test-9649 deletion completed in 12.136519586s

• [SLOW TEST:37.038 seconds]
[sig-network] Networking
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:46:32.776: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-2de2e4f7-bc87-4e6e-b6c6-abbef1616ed8
STEP: Creating configMap with name cm-test-opt-upd-827a5d4b-e5ae-4806-b440-0783f635c82b
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-2de2e4f7-bc87-4e6e-b6c6-abbef1616ed8
STEP: Updating configmap cm-test-opt-upd-827a5d4b-e5ae-4806-b440-0783f635c82b
STEP: Creating configMap with name cm-test-opt-create-21043e1a-ff6f-4e7b-87bc-9df9abfa4dbf
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:47:43.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5019" for this suite.
Oct 11 17:47:55.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:47:55.468: INFO: namespace configmap-5019 deletion completed in 12.135714762s

• [SLOW TEST:82.692 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:47:55.470: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3243.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3243.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 11 17:48:07.571: INFO: DNS probes using dns-3243/dns-test-36e39b1e-cd1a-45dc-8d89-d84c0c6984ca succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:48:07.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3243" for this suite.
Oct 11 17:48:13.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:48:13.742: INFO: namespace dns-3243 deletion completed in 6.138547624s

• [SLOW TEST:18.272 seconds]
[sig-network] DNS
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:48:13.742: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 11 17:48:13.800: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fb64d206-215a-4cc1-baf6-356af9e88d1f" in namespace "downward-api-5163" to be "success or failure"
Oct 11 17:48:13.805: INFO: Pod "downwardapi-volume-fb64d206-215a-4cc1-baf6-356af9e88d1f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.237391ms
Oct 11 17:48:15.809: INFO: Pod "downwardapi-volume-fb64d206-215a-4cc1-baf6-356af9e88d1f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009785236s
Oct 11 17:48:17.814: INFO: Pod "downwardapi-volume-fb64d206-215a-4cc1-baf6-356af9e88d1f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014231607s
STEP: Saw pod success
Oct 11 17:48:17.814: INFO: Pod "downwardapi-volume-fb64d206-215a-4cc1-baf6-356af9e88d1f" satisfied condition "success or failure"
Oct 11 17:48:17.818: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod downwardapi-volume-fb64d206-215a-4cc1-baf6-356af9e88d1f container client-container: <nil>
STEP: delete the pod
Oct 11 17:48:17.842: INFO: Waiting for pod downwardapi-volume-fb64d206-215a-4cc1-baf6-356af9e88d1f to disappear
Oct 11 17:48:17.845: INFO: Pod downwardapi-volume-fb64d206-215a-4cc1-baf6-356af9e88d1f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:48:17.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5163" for this suite.
Oct 11 17:48:23.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:48:23.988: INFO: namespace downward-api-5163 deletion completed in 6.137946582s

• [SLOW TEST:10.246 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:48:23.989: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1539.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-1539.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1539.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1539.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-1539.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1539.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 11 17:48:34.085: INFO: DNS probes using dns-1539/dns-test-27594ab8-fcd2-4bc8-b0f7-60c4d8304a77 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:48:34.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1539" for this suite.
Oct 11 17:48:40.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:48:40.248: INFO: namespace dns-1539 deletion completed in 6.140038555s

• [SLOW TEST:16.258 seconds]
[sig-network] DNS
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:48:40.249: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Oct 11 17:48:40.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 --namespace=kubectl-5938 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Oct 11 17:48:42.797: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Oct 11 17:48:42.797: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:48:44.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5938" for this suite.
Oct 11 17:48:50.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:48:50.947: INFO: namespace kubectl-5938 deletion completed in 6.136679747s

• [SLOW TEST:10.697 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:48:50.947: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 11 17:48:51.023: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:51.023: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:51.024: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:51.030: INFO: Number of nodes with available pods: 0
Oct 11 17:48:51.030: INFO: Node ip-172-31-1-25.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 17:48:52.036: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:52.036: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:52.036: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:52.040: INFO: Number of nodes with available pods: 0
Oct 11 17:48:52.040: INFO: Node ip-172-31-1-25.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 17:48:53.037: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:53.037: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:53.037: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:53.041: INFO: Number of nodes with available pods: 1
Oct 11 17:48:53.041: INFO: Node ip-172-31-5-54.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 17:48:54.036: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:54.036: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:54.036: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:54.040: INFO: Number of nodes with available pods: 2
Oct 11 17:48:54.040: INFO: Node ip-172-31-5-54.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 17:48:55.036: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:55.036: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:55.036: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:55.040: INFO: Number of nodes with available pods: 2
Oct 11 17:48:55.040: INFO: Node ip-172-31-5-54.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 17:48:56.036: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:56.036: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:56.036: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:56.040: INFO: Number of nodes with available pods: 2
Oct 11 17:48:56.040: INFO: Node ip-172-31-5-54.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 17:48:57.036: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:57.037: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:57.037: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:57.041: INFO: Number of nodes with available pods: 2
Oct 11 17:48:57.041: INFO: Node ip-172-31-5-54.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 17:48:58.036: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:58.036: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:58.036: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:58.040: INFO: Number of nodes with available pods: 2
Oct 11 17:48:58.041: INFO: Node ip-172-31-5-54.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 17:48:59.039: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:59.039: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:59.039: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:59.043: INFO: Number of nodes with available pods: 3
Oct 11 17:48:59.044: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Oct 11 17:48:59.071: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:59.071: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:59.071: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:48:59.080: INFO: Number of nodes with available pods: 2
Oct 11 17:48:59.080: INFO: Node ip-172-31-6-233.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 17:49:00.085: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:49:00.085: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:49:00.085: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:49:00.090: INFO: Number of nodes with available pods: 2
Oct 11 17:49:00.090: INFO: Node ip-172-31-6-233.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 17:49:01.087: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:49:01.088: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:49:01.088: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:49:01.091: INFO: Number of nodes with available pods: 2
Oct 11 17:49:01.091: INFO: Node ip-172-31-6-233.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 17:49:02.086: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:49:02.086: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:49:02.086: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 17:49:02.090: INFO: Number of nodes with available pods: 3
Oct 11 17:49:02.090: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7298, will wait for the garbage collector to delete the pods
Oct 11 17:49:02.163: INFO: Deleting DaemonSet.extensions daemon-set took: 11.518412ms
Oct 11 17:49:02.264: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.278409ms
Oct 11 17:49:10.468: INFO: Number of nodes with available pods: 0
Oct 11 17:49:10.468: INFO: Number of running nodes: 0, number of available pods: 0
Oct 11 17:49:10.473: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7298/daemonsets","resourceVersion":"9197"},"items":null}

Oct 11 17:49:10.477: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7298/pods","resourceVersion":"9197"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:49:10.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7298" for this suite.
Oct 11 17:49:16.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:49:16.635: INFO: namespace daemonsets-7298 deletion completed in 6.136999955s

• [SLOW TEST:25.688 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:49:16.635: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Oct 11 17:49:16.672: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Oct 11 17:49:16.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 create -f - --namespace=kubectl-2338'
Oct 11 17:49:16.864: INFO: stderr: ""
Oct 11 17:49:16.864: INFO: stdout: "service/redis-slave created\n"
Oct 11 17:49:16.864: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Oct 11 17:49:16.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 create -f - --namespace=kubectl-2338'
Oct 11 17:49:17.055: INFO: stderr: ""
Oct 11 17:49:17.055: INFO: stdout: "service/redis-master created\n"
Oct 11 17:49:17.055: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Oct 11 17:49:17.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 create -f - --namespace=kubectl-2338'
Oct 11 17:49:17.283: INFO: stderr: ""
Oct 11 17:49:17.283: INFO: stdout: "service/frontend created\n"
Oct 11 17:49:17.283: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Oct 11 17:49:17.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 create -f - --namespace=kubectl-2338'
Oct 11 17:49:17.515: INFO: stderr: ""
Oct 11 17:49:17.515: INFO: stdout: "deployment.apps/frontend created\n"
Oct 11 17:49:17.516: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Oct 11 17:49:17.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 create -f - --namespace=kubectl-2338'
Oct 11 17:49:17.728: INFO: stderr: ""
Oct 11 17:49:17.728: INFO: stdout: "deployment.apps/redis-master created\n"
Oct 11 17:49:17.728: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Oct 11 17:49:17.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 create -f - --namespace=kubectl-2338'
Oct 11 17:49:17.959: INFO: stderr: ""
Oct 11 17:49:17.959: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Oct 11 17:49:17.959: INFO: Waiting for all frontend pods to be Running.
Oct 11 17:49:33.009: INFO: Waiting for frontend to serve content.
Oct 11 17:49:33.024: INFO: Trying to add a new entry to the guestbook.
Oct 11 17:49:33.038: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Oct 11 17:49:33.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 delete --grace-period=0 --force -f - --namespace=kubectl-2338'
Oct 11 17:49:33.145: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 11 17:49:33.145: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Oct 11 17:49:33.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 delete --grace-period=0 --force -f - --namespace=kubectl-2338'
Oct 11 17:49:33.249: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 11 17:49:33.249: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 11 17:49:33.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 delete --grace-period=0 --force -f - --namespace=kubectl-2338'
Oct 11 17:49:33.351: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 11 17:49:33.351: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 11 17:49:33.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 delete --grace-period=0 --force -f - --namespace=kubectl-2338'
Oct 11 17:49:33.462: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 11 17:49:33.463: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 11 17:49:33.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 delete --grace-period=0 --force -f - --namespace=kubectl-2338'
Oct 11 17:49:33.530: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 11 17:49:33.530: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 11 17:49:33.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 delete --grace-period=0 --force -f - --namespace=kubectl-2338'
Oct 11 17:49:33.603: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 11 17:49:33.603: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:49:33.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2338" for this suite.
Oct 11 17:49:45.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:49:45.743: INFO: namespace kubectl-2338 deletion completed in 12.134941008s

• [SLOW TEST:29.108 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:49:45.743: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Oct 11 17:49:50.311: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8536 pod-service-account-ce94aab4-d1dd-4e07-b1fd-899c7f3096d3 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Oct 11 17:49:50.619: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8536 pod-service-account-ce94aab4-d1dd-4e07-b1fd-899c7f3096d3 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Oct 11 17:49:50.879: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8536 pod-service-account-ce94aab4-d1dd-4e07-b1fd-899c7f3096d3 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:49:51.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8536" for this suite.
Oct 11 17:49:57.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:49:57.306: INFO: namespace svcaccounts-8536 deletion completed in 6.138353023s

• [SLOW TEST:11.563 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:49:57.307: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-19e6f2bd-10cc-47eb-90ee-db6b1e896d0e
STEP: Creating secret with name secret-projected-all-test-volume-a826930a-319f-45b7-b150-0686eca572d2
STEP: Creating a pod to test Check all projections for projected volume plugin
Oct 11 17:49:57.359: INFO: Waiting up to 5m0s for pod "projected-volume-62984b88-ae77-4810-84a8-38a74b129281" in namespace "projected-6329" to be "success or failure"
Oct 11 17:49:57.364: INFO: Pod "projected-volume-62984b88-ae77-4810-84a8-38a74b129281": Phase="Pending", Reason="", readiness=false. Elapsed: 4.246593ms
Oct 11 17:49:59.368: INFO: Pod "projected-volume-62984b88-ae77-4810-84a8-38a74b129281": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008295222s
STEP: Saw pod success
Oct 11 17:49:59.368: INFO: Pod "projected-volume-62984b88-ae77-4810-84a8-38a74b129281" satisfied condition "success or failure"
Oct 11 17:49:59.371: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod projected-volume-62984b88-ae77-4810-84a8-38a74b129281 container projected-all-volume-test: <nil>
STEP: delete the pod
Oct 11 17:49:59.410: INFO: Waiting for pod projected-volume-62984b88-ae77-4810-84a8-38a74b129281 to disappear
Oct 11 17:49:59.414: INFO: Pod projected-volume-62984b88-ae77-4810-84a8-38a74b129281 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:49:59.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6329" for this suite.
Oct 11 17:50:05.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:50:05.561: INFO: namespace projected-6329 deletion completed in 6.142777413s

• [SLOW TEST:8.254 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:50:05.563: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Oct 11 17:50:05.599: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 17:50:09.162: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:50:21.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4548" for this suite.
Oct 11 17:50:27.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:50:27.847: INFO: namespace crd-publish-openapi-4548 deletion completed in 6.139118586s

• [SLOW TEST:22.284 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:50:27.847: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 11 17:50:28.515: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 11 17:50:30.527: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706413028, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706413028, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706413028, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706413028, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 11 17:50:33.547: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:50:33.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6476" for this suite.
Oct 11 17:50:39.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:50:39.835: INFO: namespace webhook-6476 deletion completed in 6.161783201s
STEP: Destroying namespace "webhook-6476-markers" for this suite.
Oct 11 17:50:45.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:50:45.967: INFO: namespace webhook-6476-markers deletion completed in 6.131975108s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.146 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:50:45.993: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Oct 11 17:50:46.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 create -f - --namespace=kubectl-8028'
Oct 11 17:50:46.222: INFO: stderr: ""
Oct 11 17:50:46.222: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 11 17:50:46.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8028'
Oct 11 17:50:46.293: INFO: stderr: ""
Oct 11 17:50:46.293: INFO: stdout: "update-demo-nautilus-jcs9b update-demo-nautilus-n5vkc "
Oct 11 17:50:46.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-jcs9b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8028'
Oct 11 17:50:46.360: INFO: stderr: ""
Oct 11 17:50:46.361: INFO: stdout: ""
Oct 11 17:50:46.361: INFO: update-demo-nautilus-jcs9b is created but not running
Oct 11 17:50:51.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8028'
Oct 11 17:50:51.430: INFO: stderr: ""
Oct 11 17:50:51.430: INFO: stdout: "update-demo-nautilus-jcs9b update-demo-nautilus-n5vkc "
Oct 11 17:50:51.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-jcs9b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8028'
Oct 11 17:50:51.497: INFO: stderr: ""
Oct 11 17:50:51.497: INFO: stdout: "true"
Oct 11 17:50:51.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-jcs9b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8028'
Oct 11 17:50:51.567: INFO: stderr: ""
Oct 11 17:50:51.567: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 11 17:50:51.567: INFO: validating pod update-demo-nautilus-jcs9b
Oct 11 17:50:51.573: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 11 17:50:51.573: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 11 17:50:51.573: INFO: update-demo-nautilus-jcs9b is verified up and running
Oct 11 17:50:51.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-n5vkc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8028'
Oct 11 17:50:51.640: INFO: stderr: ""
Oct 11 17:50:51.640: INFO: stdout: "true"
Oct 11 17:50:51.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-n5vkc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8028'
Oct 11 17:50:51.705: INFO: stderr: ""
Oct 11 17:50:51.705: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 11 17:50:51.705: INFO: validating pod update-demo-nautilus-n5vkc
Oct 11 17:50:51.712: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 11 17:50:51.712: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 11 17:50:51.712: INFO: update-demo-nautilus-n5vkc is verified up and running
STEP: rolling-update to new replication controller
Oct 11 17:50:51.714: INFO: scanned /root for discovery docs: <nil>
Oct 11 17:50:51.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-8028'
Oct 11 17:51:15.162: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 11 17:51:15.162: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 11 17:51:15.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8028'
Oct 11 17:51:15.242: INFO: stderr: ""
Oct 11 17:51:15.242: INFO: stdout: "update-demo-kitten-hmw6x update-demo-kitten-hv864 "
Oct 11 17:51:15.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-kitten-hmw6x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8028'
Oct 11 17:51:15.307: INFO: stderr: ""
Oct 11 17:51:15.307: INFO: stdout: "true"
Oct 11 17:51:15.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-kitten-hmw6x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8028'
Oct 11 17:51:15.383: INFO: stderr: ""
Oct 11 17:51:15.383: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 11 17:51:15.383: INFO: validating pod update-demo-kitten-hmw6x
Oct 11 17:51:15.390: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 11 17:51:15.390: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 11 17:51:15.390: INFO: update-demo-kitten-hmw6x is verified up and running
Oct 11 17:51:15.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-kitten-hv864 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8028'
Oct 11 17:51:15.455: INFO: stderr: ""
Oct 11 17:51:15.455: INFO: stdout: "true"
Oct 11 17:51:15.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-kitten-hv864 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8028'
Oct 11 17:51:15.520: INFO: stderr: ""
Oct 11 17:51:15.520: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 11 17:51:15.520: INFO: validating pod update-demo-kitten-hv864
Oct 11 17:51:15.526: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 11 17:51:15.526: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 11 17:51:15.526: INFO: update-demo-kitten-hv864 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:51:15.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8028" for this suite.
Oct 11 17:51:43.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:51:43.668: INFO: namespace kubectl-8028 deletion completed in 28.136450279s

• [SLOW TEST:57.674 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:51:43.668: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Oct 11 17:51:43.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 create -f - --namespace=kubectl-3234'
Oct 11 17:51:43.897: INFO: stderr: ""
Oct 11 17:51:43.898: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 11 17:51:43.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3234'
Oct 11 17:51:43.977: INFO: stderr: ""
Oct 11 17:51:43.977: INFO: stdout: "update-demo-nautilus-2mxbm update-demo-nautilus-52sdd "
Oct 11 17:51:43.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-2mxbm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3234'
Oct 11 17:51:44.046: INFO: stderr: ""
Oct 11 17:51:44.046: INFO: stdout: ""
Oct 11 17:51:44.046: INFO: update-demo-nautilus-2mxbm is created but not running
Oct 11 17:51:49.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3234'
Oct 11 17:51:49.117: INFO: stderr: ""
Oct 11 17:51:49.117: INFO: stdout: "update-demo-nautilus-2mxbm update-demo-nautilus-52sdd "
Oct 11 17:51:49.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-2mxbm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3234'
Oct 11 17:51:49.195: INFO: stderr: ""
Oct 11 17:51:49.195: INFO: stdout: "true"
Oct 11 17:51:49.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-2mxbm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3234'
Oct 11 17:51:49.263: INFO: stderr: ""
Oct 11 17:51:49.263: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 11 17:51:49.263: INFO: validating pod update-demo-nautilus-2mxbm
Oct 11 17:51:49.270: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 11 17:51:49.270: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 11 17:51:49.270: INFO: update-demo-nautilus-2mxbm is verified up and running
Oct 11 17:51:49.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-52sdd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3234'
Oct 11 17:51:49.335: INFO: stderr: ""
Oct 11 17:51:49.335: INFO: stdout: "true"
Oct 11 17:51:49.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-52sdd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3234'
Oct 11 17:51:49.421: INFO: stderr: ""
Oct 11 17:51:49.421: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 11 17:51:49.421: INFO: validating pod update-demo-nautilus-52sdd
Oct 11 17:51:49.428: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 11 17:51:49.428: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 11 17:51:49.428: INFO: update-demo-nautilus-52sdd is verified up and running
STEP: scaling down the replication controller
Oct 11 17:51:49.429: INFO: scanned /root for discovery docs: <nil>
Oct 11 17:51:49.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-3234'
Oct 11 17:51:50.513: INFO: stderr: ""
Oct 11 17:51:50.513: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 11 17:51:50.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3234'
Oct 11 17:51:50.578: INFO: stderr: ""
Oct 11 17:51:50.578: INFO: stdout: "update-demo-nautilus-2mxbm update-demo-nautilus-52sdd "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct 11 17:51:55.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3234'
Oct 11 17:51:55.697: INFO: stderr: ""
Oct 11 17:51:55.697: INFO: stdout: "update-demo-nautilus-2mxbm update-demo-nautilus-52sdd "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct 11 17:52:00.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3234'
Oct 11 17:52:00.768: INFO: stderr: ""
Oct 11 17:52:00.768: INFO: stdout: "update-demo-nautilus-2mxbm update-demo-nautilus-52sdd "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct 11 17:52:05.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3234'
Oct 11 17:52:05.836: INFO: stderr: ""
Oct 11 17:52:05.837: INFO: stdout: "update-demo-nautilus-2mxbm "
Oct 11 17:52:05.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-2mxbm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3234'
Oct 11 17:52:05.901: INFO: stderr: ""
Oct 11 17:52:05.901: INFO: stdout: "true"
Oct 11 17:52:05.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-2mxbm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3234'
Oct 11 17:52:05.965: INFO: stderr: ""
Oct 11 17:52:05.965: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 11 17:52:05.965: INFO: validating pod update-demo-nautilus-2mxbm
Oct 11 17:52:05.971: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 11 17:52:05.971: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 11 17:52:05.971: INFO: update-demo-nautilus-2mxbm is verified up and running
STEP: scaling up the replication controller
Oct 11 17:52:05.972: INFO: scanned /root for discovery docs: <nil>
Oct 11 17:52:05.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-3234'
Oct 11 17:52:07.069: INFO: stderr: ""
Oct 11 17:52:07.069: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 11 17:52:07.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3234'
Oct 11 17:52:07.143: INFO: stderr: ""
Oct 11 17:52:07.143: INFO: stdout: "update-demo-nautilus-2mxbm update-demo-nautilus-f559r "
Oct 11 17:52:07.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-2mxbm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3234'
Oct 11 17:52:07.212: INFO: stderr: ""
Oct 11 17:52:07.212: INFO: stdout: "true"
Oct 11 17:52:07.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-2mxbm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3234'
Oct 11 17:52:07.288: INFO: stderr: ""
Oct 11 17:52:07.288: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 11 17:52:07.288: INFO: validating pod update-demo-nautilus-2mxbm
Oct 11 17:52:07.294: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 11 17:52:07.294: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 11 17:52:07.294: INFO: update-demo-nautilus-2mxbm is verified up and running
Oct 11 17:52:07.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-f559r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3234'
Oct 11 17:52:07.363: INFO: stderr: ""
Oct 11 17:52:07.363: INFO: stdout: ""
Oct 11 17:52:07.363: INFO: update-demo-nautilus-f559r is created but not running
Oct 11 17:52:12.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3234'
Oct 11 17:52:12.430: INFO: stderr: ""
Oct 11 17:52:12.430: INFO: stdout: "update-demo-nautilus-2mxbm update-demo-nautilus-f559r "
Oct 11 17:52:12.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-2mxbm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3234'
Oct 11 17:52:12.502: INFO: stderr: ""
Oct 11 17:52:12.502: INFO: stdout: "true"
Oct 11 17:52:12.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-2mxbm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3234'
Oct 11 17:52:12.571: INFO: stderr: ""
Oct 11 17:52:12.571: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 11 17:52:12.571: INFO: validating pod update-demo-nautilus-2mxbm
Oct 11 17:52:12.576: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 11 17:52:12.576: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 11 17:52:12.576: INFO: update-demo-nautilus-2mxbm is verified up and running
Oct 11 17:52:12.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-f559r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3234'
Oct 11 17:52:12.642: INFO: stderr: ""
Oct 11 17:52:12.642: INFO: stdout: "true"
Oct 11 17:52:12.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-f559r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3234'
Oct 11 17:52:12.711: INFO: stderr: ""
Oct 11 17:52:12.711: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 11 17:52:12.711: INFO: validating pod update-demo-nautilus-f559r
Oct 11 17:52:12.718: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 11 17:52:12.718: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 11 17:52:12.718: INFO: update-demo-nautilus-f559r is verified up and running
STEP: using delete to clean up resources
Oct 11 17:52:12.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 delete --grace-period=0 --force -f - --namespace=kubectl-3234'
Oct 11 17:52:12.788: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 11 17:52:12.788: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 11 17:52:12.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3234'
Oct 11 17:52:12.863: INFO: stderr: "No resources found in kubectl-3234 namespace.\n"
Oct 11 17:52:12.863: INFO: stdout: ""
Oct 11 17:52:12.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods -l name=update-demo --namespace=kubectl-3234 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 11 17:52:12.931: INFO: stderr: ""
Oct 11 17:52:12.931: INFO: stdout: "update-demo-nautilus-2mxbm\nupdate-demo-nautilus-f559r\n"
Oct 11 17:52:13.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3234'
Oct 11 17:52:13.508: INFO: stderr: "No resources found in kubectl-3234 namespace.\n"
Oct 11 17:52:13.508: INFO: stdout: ""
Oct 11 17:52:13.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods -l name=update-demo --namespace=kubectl-3234 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 11 17:52:13.577: INFO: stderr: ""
Oct 11 17:52:13.577: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:52:13.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3234" for this suite.
Oct 11 17:52:19.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:52:19.726: INFO: namespace kubectl-3234 deletion completed in 6.142591761s

• [SLOW TEST:36.058 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:52:19.726: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Oct 11 17:52:19.769: INFO: Waiting up to 5m0s for pod "downward-api-a52a0018-a8b7-422a-9484-b6358af7cb7f" in namespace "downward-api-1061" to be "success or failure"
Oct 11 17:52:19.774: INFO: Pod "downward-api-a52a0018-a8b7-422a-9484-b6358af7cb7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.788346ms
Oct 11 17:52:21.779: INFO: Pod "downward-api-a52a0018-a8b7-422a-9484-b6358af7cb7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009651544s
STEP: Saw pod success
Oct 11 17:52:21.779: INFO: Pod "downward-api-a52a0018-a8b7-422a-9484-b6358af7cb7f" satisfied condition "success or failure"
Oct 11 17:52:21.783: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod downward-api-a52a0018-a8b7-422a-9484-b6358af7cb7f container dapi-container: <nil>
STEP: delete the pod
Oct 11 17:52:21.818: INFO: Waiting for pod downward-api-a52a0018-a8b7-422a-9484-b6358af7cb7f to disappear
Oct 11 17:52:21.822: INFO: Pod downward-api-a52a0018-a8b7-422a-9484-b6358af7cb7f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:52:21.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1061" for this suite.
Oct 11 17:52:27.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:52:27.965: INFO: namespace downward-api-1061 deletion completed in 6.137534738s

• [SLOW TEST:8.239 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:52:27.965: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 17:52:28.010: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-06c2ddc7-e71c-41cd-9a6e-4e9c90f5894a" in namespace "security-context-test-27" to be "success or failure"
Oct 11 17:52:28.019: INFO: Pod "alpine-nnp-false-06c2ddc7-e71c-41cd-9a6e-4e9c90f5894a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.301551ms
Oct 11 17:52:30.023: INFO: Pod "alpine-nnp-false-06c2ddc7-e71c-41cd-9a6e-4e9c90f5894a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012670536s
Oct 11 17:52:32.035: INFO: Pod "alpine-nnp-false-06c2ddc7-e71c-41cd-9a6e-4e9c90f5894a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024324917s
Oct 11 17:52:32.035: INFO: Pod "alpine-nnp-false-06c2ddc7-e71c-41cd-9a6e-4e9c90f5894a" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:52:32.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-27" for this suite.
Oct 11 17:52:38.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:52:38.195: INFO: namespace security-context-test-27 deletion completed in 6.135192574s

• [SLOW TEST:10.230 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:52:38.195: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 17:52:38.229: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:52:38.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8887" for this suite.
Oct 11 17:52:44.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:52:44.947: INFO: namespace custom-resource-definition-8887 deletion completed in 6.141439726s

• [SLOW TEST:6.752 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:52:44.947: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 11 17:52:44.991: INFO: Waiting up to 5m0s for pod "pod-ab526393-8efa-4ecb-9eab-753d7db59a07" in namespace "emptydir-8810" to be "success or failure"
Oct 11 17:52:44.996: INFO: Pod "pod-ab526393-8efa-4ecb-9eab-753d7db59a07": Phase="Pending", Reason="", readiness=false. Elapsed: 5.809474ms
Oct 11 17:52:47.001: INFO: Pod "pod-ab526393-8efa-4ecb-9eab-753d7db59a07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01010409s
STEP: Saw pod success
Oct 11 17:52:47.001: INFO: Pod "pod-ab526393-8efa-4ecb-9eab-753d7db59a07" satisfied condition "success or failure"
Oct 11 17:52:47.005: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-ab526393-8efa-4ecb-9eab-753d7db59a07 container test-container: <nil>
STEP: delete the pod
Oct 11 17:52:47.038: INFO: Waiting for pod pod-ab526393-8efa-4ecb-9eab-753d7db59a07 to disappear
Oct 11 17:52:47.042: INFO: Pod pod-ab526393-8efa-4ecb-9eab-753d7db59a07 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:52:47.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8810" for this suite.
Oct 11 17:52:53.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:52:53.190: INFO: namespace emptydir-8810 deletion completed in 6.142646036s

• [SLOW TEST:8.243 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:52:53.191: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:53:06.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2335" for this suite.
Oct 11 17:53:12.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:53:12.458: INFO: namespace resourcequota-2335 deletion completed in 6.145265063s

• [SLOW TEST:19.267 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:53:12.458: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 11 17:53:12.502: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7d03e25d-f325-4972-bbf7-0377ea9054f8" in namespace "downward-api-3586" to be "success or failure"
Oct 11 17:53:12.508: INFO: Pod "downwardapi-volume-7d03e25d-f325-4972-bbf7-0377ea9054f8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.031735ms
Oct 11 17:53:14.513: INFO: Pod "downwardapi-volume-7d03e25d-f325-4972-bbf7-0377ea9054f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01058067s
STEP: Saw pod success
Oct 11 17:53:14.513: INFO: Pod "downwardapi-volume-7d03e25d-f325-4972-bbf7-0377ea9054f8" satisfied condition "success or failure"
Oct 11 17:53:14.519: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod downwardapi-volume-7d03e25d-f325-4972-bbf7-0377ea9054f8 container client-container: <nil>
STEP: delete the pod
Oct 11 17:53:14.546: INFO: Waiting for pod downwardapi-volume-7d03e25d-f325-4972-bbf7-0377ea9054f8 to disappear
Oct 11 17:53:14.550: INFO: Pod downwardapi-volume-7d03e25d-f325-4972-bbf7-0377ea9054f8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:53:14.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3586" for this suite.
Oct 11 17:53:20.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:53:20.823: INFO: namespace downward-api-3586 deletion completed in 6.264657981s

• [SLOW TEST:8.365 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:53:20.824: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 11 17:53:21.154: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 11 17:53:23.167: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706413200, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706413200, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706413200, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706413200, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 11 17:53:26.190: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 17:53:26.195: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-275-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:53:27.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-30" for this suite.
Oct 11 17:53:33.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:53:33.154: INFO: namespace webhook-30 deletion completed in 6.145917095s
STEP: Destroying namespace "webhook-30-markers" for this suite.
Oct 11 17:53:39.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:53:39.304: INFO: namespace webhook-30-markers deletion completed in 6.150156926s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.501 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:53:39.326: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 11 17:53:39.374: INFO: Waiting up to 5m0s for pod "pod-ce88b2dd-6547-45e5-87a1-9ea96915b70c" in namespace "emptydir-9300" to be "success or failure"
Oct 11 17:53:39.383: INFO: Pod "pod-ce88b2dd-6547-45e5-87a1-9ea96915b70c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.931907ms
Oct 11 17:53:41.388: INFO: Pod "pod-ce88b2dd-6547-45e5-87a1-9ea96915b70c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013941698s
STEP: Saw pod success
Oct 11 17:53:41.388: INFO: Pod "pod-ce88b2dd-6547-45e5-87a1-9ea96915b70c" satisfied condition "success or failure"
Oct 11 17:53:41.392: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod pod-ce88b2dd-6547-45e5-87a1-9ea96915b70c container test-container: <nil>
STEP: delete the pod
Oct 11 17:53:41.432: INFO: Waiting for pod pod-ce88b2dd-6547-45e5-87a1-9ea96915b70c to disappear
Oct 11 17:53:41.436: INFO: Pod pod-ce88b2dd-6547-45e5-87a1-9ea96915b70c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:53:41.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9300" for this suite.
Oct 11 17:53:47.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:53:47.607: INFO: namespace emptydir-9300 deletion completed in 6.164588022s

• [SLOW TEST:8.281 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:53:47.608: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Oct 11 17:53:47.650: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:54:02.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1441" for this suite.
Oct 11 17:54:08.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:54:09.175: INFO: namespace pods-1441 deletion completed in 6.229026426s

• [SLOW TEST:21.567 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:54:09.175: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-5677
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-5677
I1011 17:54:09.258002      19 runners.go:184] Created replication controller with name: externalname-service, namespace: services-5677, replica count: 2
I1011 17:54:12.308329      19 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 11 17:54:12.308: INFO: Creating new exec pod
Oct 11 17:54:15.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=services-5677 execpodqfspx -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Oct 11 17:54:15.630: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Oct 11 17:54:15.630: INFO: stdout: ""
Oct 11 17:54:15.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=services-5677 execpodqfspx -- /bin/sh -x -c nc -zv -t -w 2 10.105.102.56 80'
Oct 11 17:54:15.911: INFO: stderr: "+ nc -zv -t -w 2 10.105.102.56 80\nConnection to 10.105.102.56 80 port [tcp/http] succeeded!\n"
Oct 11 17:54:15.911: INFO: stdout: ""
Oct 11 17:54:15.911: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:54:15.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5677" for this suite.
Oct 11 17:54:21.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:54:22.108: INFO: namespace services-5677 deletion completed in 6.154608933s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:12.933 seconds]
[sig-network] Services
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:54:22.108: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 11 17:54:22.155: INFO: Waiting up to 5m0s for pod "pod-29e63499-4392-4c15-9979-cb421c798d41" in namespace "emptydir-131" to be "success or failure"
Oct 11 17:54:22.159: INFO: Pod "pod-29e63499-4392-4c15-9979-cb421c798d41": Phase="Pending", Reason="", readiness=false. Elapsed: 4.161109ms
Oct 11 17:54:24.164: INFO: Pod "pod-29e63499-4392-4c15-9979-cb421c798d41": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0092001s
Oct 11 17:54:26.169: INFO: Pod "pod-29e63499-4392-4c15-9979-cb421c798d41": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0138998s
STEP: Saw pod success
Oct 11 17:54:26.169: INFO: Pod "pod-29e63499-4392-4c15-9979-cb421c798d41" satisfied condition "success or failure"
Oct 11 17:54:26.172: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-29e63499-4392-4c15-9979-cb421c798d41 container test-container: <nil>
STEP: delete the pod
Oct 11 17:54:26.197: INFO: Waiting for pod pod-29e63499-4392-4c15-9979-cb421c798d41 to disappear
Oct 11 17:54:26.200: INFO: Pod pod-29e63499-4392-4c15-9979-cb421c798d41 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:54:26.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-131" for this suite.
Oct 11 17:54:32.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:54:32.353: INFO: namespace emptydir-131 deletion completed in 6.147454312s

• [SLOW TEST:10.245 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:54:32.353: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Oct 11 17:54:32.441: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 11 17:54:32.458: INFO: Waiting for terminating namespaces to be deleted...
Oct 11 17:54:32.462: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-1-25.eu-west-3.compute.internal before test
Oct 11 17:54:32.479: INFO: canal-jn9ph from kube-system started at 2019-10-11 17:26:31 +0000 UTC (2 container statuses recorded)
Oct 11 17:54:32.479: INFO: 	Container calico-node ready: true, restart count 0
Oct 11 17:54:32.479: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 11 17:54:32.479: INFO: sonobuoy-e2e-job-56f76d39d0764ff1 from sonobuoy started at 2019-10-11 17:28:08 +0000 UTC (2 container statuses recorded)
Oct 11 17:54:32.479: INFO: 	Container e2e ready: true, restart count 0
Oct 11 17:54:32.479: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 11 17:54:32.479: INFO: sonobuoy-systemd-logs-daemon-set-8223689078594c46-86r77 from sonobuoy started at 2019-10-11 17:28:08 +0000 UTC (2 container statuses recorded)
Oct 11 17:54:32.479: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 11 17:54:32.479: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 11 17:54:32.479: INFO: kube-proxy-m86rm from kube-system started at 2019-10-11 17:26:31 +0000 UTC (1 container statuses recorded)
Oct 11 17:54:32.479: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 11 17:54:32.479: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-5-54.eu-west-3.compute.internal before test
Oct 11 17:54:32.486: INFO: kube-proxy-gczvl from kube-system started at 2019-10-11 17:26:30 +0000 UTC (1 container statuses recorded)
Oct 11 17:54:32.486: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 11 17:54:32.486: INFO: canal-hdnlb from kube-system started at 2019-10-11 17:26:30 +0000 UTC (2 container statuses recorded)
Oct 11 17:54:32.486: INFO: 	Container calico-node ready: true, restart count 0
Oct 11 17:54:32.486: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 11 17:54:32.486: INFO: sonobuoy from sonobuoy started at 2019-10-11 17:28:02 +0000 UTC (1 container statuses recorded)
Oct 11 17:54:32.486: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 11 17:54:32.486: INFO: sonobuoy-systemd-logs-daemon-set-8223689078594c46-wrftl from sonobuoy started at 2019-10-11 17:28:08 +0000 UTC (2 container statuses recorded)
Oct 11 17:54:32.486: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 11 17:54:32.486: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 11 17:54:32.486: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-6-233.eu-west-3.compute.internal before test
Oct 11 17:54:32.493: INFO: sonobuoy-systemd-logs-daemon-set-8223689078594c46-lhhdq from sonobuoy started at 2019-10-11 17:28:08 +0000 UTC (2 container statuses recorded)
Oct 11 17:54:32.493: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 11 17:54:32.493: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 11 17:54:32.493: INFO: kube-proxy-qw2gl from kube-system started at 2019-10-11 17:24:22 +0000 UTC (1 container statuses recorded)
Oct 11 17:54:32.493: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 11 17:54:32.493: INFO: canal-2xwdt from kube-system started at 2019-10-11 17:24:22 +0000 UTC (2 container statuses recorded)
Oct 11 17:54:32.493: INFO: 	Container calico-node ready: true, restart count 0
Oct 11 17:54:32.493: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 11 17:54:32.493: INFO: metrics-server-59bb664678-prm7v from kube-system started at 2019-10-11 17:24:41 +0000 UTC (1 container statuses recorded)
Oct 11 17:54:32.493: INFO: 	Container metrics-server ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-40f52c5b-05f3-49ba-9724-6a48466776c8 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-40f52c5b-05f3-49ba-9724-6a48466776c8 off the node ip-172-31-6-233.eu-west-3.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-40f52c5b-05f3-49ba-9724-6a48466776c8
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:54:38.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4852" for this suite.
Oct 11 17:54:46.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:54:46.758: INFO: namespace sched-pred-4852 deletion completed in 8.151488178s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:14.404 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:54:46.758: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 17:54:46.793: INFO: Creating deployment "webserver-deployment"
Oct 11 17:54:46.802: INFO: Waiting for observed generation 1
Oct 11 17:54:48.817: INFO: Waiting for all required pods to come up
Oct 11 17:54:48.823: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Oct 11 17:54:50.838: INFO: Waiting for deployment "webserver-deployment" to complete
Oct 11 17:54:50.846: INFO: Updating deployment "webserver-deployment" with a non-existent image
Oct 11 17:54:50.855: INFO: Updating deployment webserver-deployment
Oct 11 17:54:50.855: INFO: Waiting for observed generation 2
Oct 11 17:54:52.863: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Oct 11 17:54:52.868: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Oct 11 17:54:52.871: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Oct 11 17:54:52.883: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Oct 11 17:54:52.883: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Oct 11 17:54:52.886: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Oct 11 17:54:52.894: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Oct 11 17:54:52.894: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Oct 11 17:54:52.903: INFO: Updating deployment webserver-deployment
Oct 11 17:54:52.903: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Oct 11 17:54:52.913: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Oct 11 17:54:54.925: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Oct 11 17:54:54.935: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-3080 /apis/apps/v1/namespaces/deployment-3080/deployments/webserver-deployment 41a43fa5-3988-481d-b6f8-0ffded6872ee 11381 3 2019-10-11 17:54:46 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000451c08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-10-11 17:54:52 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2019-10-11 17:54:52 +0000 UTC,LastTransitionTime:2019-10-11 17:54:46 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Oct 11 17:54:54.939: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-3080 /apis/apps/v1/namespaces/deployment-3080/replicasets/webserver-deployment-c7997dcc8 962e9f6c-8402-4d8b-8f24-fe2828f68781 11371 3 2019-10-11 17:54:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 41a43fa5-3988-481d-b6f8-0ffded6872ee 0xc0010bc837 0xc0010bc838}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0010bc8a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 11 17:54:54.939: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Oct 11 17:54:54.939: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-3080 /apis/apps/v1/namespaces/deployment-3080/replicasets/webserver-deployment-595b5b9587 74091823-61d8-492e-9b94-a213d3917cc5 11378 3 2019-10-11 17:54:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 41a43fa5-3988-481d-b6f8-0ffded6872ee 0xc0010bc777 0xc0010bc778}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0010bc7d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Oct 11 17:54:54.947: INFO: Pod "webserver-deployment-595b5b9587-42p7v" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-42p7v webserver-deployment-595b5b9587- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-595b5b9587-42p7v e28d5334-5b71-4b5f-8c94-736ecbb48134 11196 0 2019-10-11 17:54:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.244.5.30/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 74091823-61d8-492e-9b94-a213d3917cc5 0xc0010bcd77 0xc0010bcd78}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-25.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.25,PodIP:10.244.5.30,StartTime:2019-10-11 17:54:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-11 17:54:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://bab9e8b4c49ace33b5a0da62ffcb7eb63463322e38ba4e82c4526c0c6b6d1099,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.5.30,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.947: INFO: Pod "webserver-deployment-595b5b9587-5xz5m" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-5xz5m webserver-deployment-595b5b9587- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-595b5b9587-5xz5m effacef2-62ae-4fb2-b3e7-2c8f58617f7d 11407 0 2019-10-11 17:54:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 74091823-61d8-492e-9b94-a213d3917cc5 0xc0010bcee0 0xc0010bcee1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-5-54.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.5.54,PodIP:,StartTime:2019-10-11 17:54:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.947: INFO: Pod "webserver-deployment-595b5b9587-76gvx" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-76gvx webserver-deployment-595b5b9587- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-595b5b9587-76gvx 363c6d86-00db-450c-b233-35efda81a41f 11416 0 2019-10-11 17:54:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 74091823-61d8-492e-9b94-a213d3917cc5 0xc0010bd037 0xc0010bd038}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-25.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.25,PodIP:,StartTime:2019-10-11 17:54:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.948: INFO: Pod "webserver-deployment-595b5b9587-bl2rc" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-bl2rc webserver-deployment-595b5b9587- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-595b5b9587-bl2rc 14dbcc11-3b90-4b15-ade8-f1e926d108d1 11415 0 2019-10-11 17:54:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 74091823-61d8-492e-9b94-a213d3917cc5 0xc0010bd187 0xc0010bd188}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-6-233.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.6.233,PodIP:,StartTime:2019-10-11 17:54:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.948: INFO: Pod "webserver-deployment-595b5b9587-cl7bd" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-cl7bd webserver-deployment-595b5b9587- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-595b5b9587-cl7bd 7b134e8b-7555-4d28-bdc6-549cf7e675ae 11390 0 2019-10-11 17:54:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 74091823-61d8-492e-9b94-a213d3917cc5 0xc0010bd2d7 0xc0010bd2d8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-25.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.25,PodIP:,StartTime:2019-10-11 17:54:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.948: INFO: Pod "webserver-deployment-595b5b9587-dxhmd" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-dxhmd webserver-deployment-595b5b9587- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-595b5b9587-dxhmd f0f9abc3-9bfd-431f-91b0-3382cdc1dfa2 11439 0 2019-10-11 17:54:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.244.4.39/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 74091823-61d8-492e-9b94-a213d3917cc5 0xc0010bd447 0xc0010bd448}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-5-54.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.5.54,PodIP:,StartTime:2019-10-11 17:54:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.948: INFO: Pod "webserver-deployment-595b5b9587-fphbz" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-fphbz webserver-deployment-595b5b9587- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-595b5b9587-fphbz 83627dfd-26d3-476c-8c78-cc04099e585c 11429 0 2019-10-11 17:54:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.244.3.53/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 74091823-61d8-492e-9b94-a213d3917cc5 0xc0010bd5b7 0xc0010bd5b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-6-233.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.6.233,PodIP:,StartTime:2019-10-11 17:54:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.949: INFO: Pod "webserver-deployment-595b5b9587-fwrkq" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-fwrkq webserver-deployment-595b5b9587- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-595b5b9587-fwrkq e7fd87d6-2979-443b-8974-2dc7ec6c6826 11212 0 2019-10-11 17:54:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.244.4.33/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 74091823-61d8-492e-9b94-a213d3917cc5 0xc0010bd717 0xc0010bd718}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-5-54.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.5.54,PodIP:10.244.4.33,StartTime:2019-10-11 17:54:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-11 17:54:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://2daa64fdf38678182a2baff3139f71fc85b453103da69a09060054b52a7b1ae1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.33,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.949: INFO: Pod "webserver-deployment-595b5b9587-hzfsc" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-hzfsc webserver-deployment-595b5b9587- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-595b5b9587-hzfsc abd961dc-bc00-4f7f-9768-8d92701448fa 11431 0 2019-10-11 17:54:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.244.4.38/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 74091823-61d8-492e-9b94-a213d3917cc5 0xc0010bd8a0 0xc0010bd8a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-5-54.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.5.54,PodIP:,StartTime:2019-10-11 17:54:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.949: INFO: Pod "webserver-deployment-595b5b9587-l5js2" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-l5js2 webserver-deployment-595b5b9587- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-595b5b9587-l5js2 13096c68-6ecc-47d0-b357-625a45f7172c 11364 0 2019-10-11 17:54:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 74091823-61d8-492e-9b94-a213d3917cc5 0xc0010bd9e7 0xc0010bd9e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-6-233.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.6.233,PodIP:,StartTime:2019-10-11 17:54:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.949: INFO: Pod "webserver-deployment-595b5b9587-ncw9z" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-ncw9z webserver-deployment-595b5b9587- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-595b5b9587-ncw9z 4e259236-35f6-419f-91ba-833fad65179e 11209 0 2019-10-11 17:54:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.244.4.35/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 74091823-61d8-492e-9b94-a213d3917cc5 0xc0010bdb67 0xc0010bdb68}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-5-54.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.5.54,PodIP:10.244.4.35,StartTime:2019-10-11 17:54:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-11 17:54:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://82b8b9b85f5bfa31b99a4d98ca511da4ba2e68dabd433b0ffff8bd8a12d0a910,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.35,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.949: INFO: Pod "webserver-deployment-595b5b9587-p6fs2" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-p6fs2 webserver-deployment-595b5b9587- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-595b5b9587-p6fs2 6bb3d5c3-704c-4990-8267-c290b064bb34 11417 0 2019-10-11 17:54:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 74091823-61d8-492e-9b94-a213d3917cc5 0xc0010bdce0 0xc0010bdce1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-5-54.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.5.54,PodIP:,StartTime:2019-10-11 17:54:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.950: INFO: Pod "webserver-deployment-595b5b9587-r7d4j" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-r7d4j webserver-deployment-595b5b9587- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-595b5b9587-r7d4j ffb5ca31-9762-4d33-8b3f-ceeae55c81eb 11203 0 2019-10-11 17:54:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.244.5.28/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 74091823-61d8-492e-9b94-a213d3917cc5 0xc0010bde57 0xc0010bde58}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-25.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.25,PodIP:10.244.5.28,StartTime:2019-10-11 17:54:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-11 17:54:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://14f787839cb649f102ef5922f9b76bf50d90a80bbbfc6540496693d6110879f3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.5.28,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.950: INFO: Pod "webserver-deployment-595b5b9587-sm6k2" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-sm6k2 webserver-deployment-595b5b9587- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-595b5b9587-sm6k2 0d0abe90-f76a-49e0-a5f9-6f31941bf2ca 11405 0 2019-10-11 17:54:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 74091823-61d8-492e-9b94-a213d3917cc5 0xc0010bdfd0 0xc0010bdfd1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-6-233.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.6.233,PodIP:,StartTime:2019-10-11 17:54:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.950: INFO: Pod "webserver-deployment-595b5b9587-t597l" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-t597l webserver-deployment-595b5b9587- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-595b5b9587-t597l 1f99a7cc-4f9f-426f-b7e4-0a2d9bd3c8ab 11200 0 2019-10-11 17:54:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.244.5.29/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 74091823-61d8-492e-9b94-a213d3917cc5 0xc003300207 0xc003300208}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-25.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.25,PodIP:10.244.5.29,StartTime:2019-10-11 17:54:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-11 17:54:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://7dcb0ae8499d2a63919571c1b480ecf87977a2d4c1a2493ff8074cc7df9b58e9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.5.29,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.950: INFO: Pod "webserver-deployment-595b5b9587-tg9ct" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-tg9ct webserver-deployment-595b5b9587- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-595b5b9587-tg9ct 2e7b0b56-141c-40d9-901a-b838baf59145 11388 0 2019-10-11 17:54:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 74091823-61d8-492e-9b94-a213d3917cc5 0xc003300530 0xc003300531}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-5-54.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.5.54,PodIP:,StartTime:2019-10-11 17:54:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.950: INFO: Pod "webserver-deployment-595b5b9587-tqgq7" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-tqgq7 webserver-deployment-595b5b9587- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-595b5b9587-tqgq7 5cdbe901-7942-4e2f-9af6-a8813283ee9a 11225 0 2019-10-11 17:54:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.244.3.48/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 74091823-61d8-492e-9b94-a213d3917cc5 0xc0033007d7 0xc0033007d8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-6-233.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.6.233,PodIP:10.244.3.48,StartTime:2019-10-11 17:54:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-11 17:54:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://721758e2e4fd9e61adcbaa699c676463d7f388aaa037b432b4030bafcd4d1544,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.48,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.950: INFO: Pod "webserver-deployment-595b5b9587-v6m9p" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-v6m9p webserver-deployment-595b5b9587- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-595b5b9587-v6m9p c1fa6efe-1794-4385-be80-a465b67a7426 11206 0 2019-10-11 17:54:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.244.4.34/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 74091823-61d8-492e-9b94-a213d3917cc5 0xc003300b40 0xc003300b41}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-5-54.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.5.54,PodIP:10.244.4.34,StartTime:2019-10-11 17:54:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-11 17:54:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://0b0dfde5f84255d3a3000b1d1477d152049d08b80fd440f18a0a8461a0f3da96,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.34,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.950: INFO: Pod "webserver-deployment-595b5b9587-xbh99" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-xbh99 webserver-deployment-595b5b9587- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-595b5b9587-xbh99 5962fc77-6fad-4c43-ae7c-0ed680a8b8f0 11406 0 2019-10-11 17:54:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 74091823-61d8-492e-9b94-a213d3917cc5 0xc001cb40b0 0xc001cb40b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-25.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.25,PodIP:,StartTime:2019-10-11 17:54:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.951: INFO: Pod "webserver-deployment-595b5b9587-xznx5" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-xznx5 webserver-deployment-595b5b9587- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-595b5b9587-xznx5 87c59514-315f-47f0-b4e9-9870a6633120 11185 0 2019-10-11 17:54:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.244.3.47/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 74091823-61d8-492e-9b94-a213d3917cc5 0xc001cb4207 0xc001cb4208}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-6-233.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.6.233,PodIP:10.244.3.47,StartTime:2019-10-11 17:54:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-11 17:54:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://a15ab7ba5932992a3d4df66283666c6166d1af20473cffb9723b7a8fd1e336c6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.47,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.951: INFO: Pod "webserver-deployment-c7997dcc8-292qv" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-292qv webserver-deployment-c7997dcc8- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-c7997dcc8-292qv 10fe7c48-50d5-4cd1-8fc6-7907d34b9597 11385 0 2019-10-11 17:54:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 962e9f6c-8402-4d8b-8f24-fe2828f68781 0xc001cb4370 0xc001cb4371}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-6-233.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.6.233,PodIP:,StartTime:2019-10-11 17:54:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.951: INFO: Pod "webserver-deployment-c7997dcc8-4lm25" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-4lm25 webserver-deployment-c7997dcc8- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-c7997dcc8-4lm25 32350937-1b91-4e99-bc1c-e3ab7cd2599e 11284 0 2019-10-11 17:54:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.244.5.31/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 962e9f6c-8402-4d8b-8f24-fe2828f68781 0xc001cb44e7 0xc001cb44e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-25.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.25,PodIP:,StartTime:2019-10-11 17:54:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.951: INFO: Pod "webserver-deployment-c7997dcc8-7fzg9" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-7fzg9 webserver-deployment-c7997dcc8- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-c7997dcc8-7fzg9 67957b7e-11fa-4643-8784-5b926100335e 11433 0 2019-10-11 17:54:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.244.5.33/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 962e9f6c-8402-4d8b-8f24-fe2828f68781 0xc001cb4660 0xc001cb4661}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-25.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.25,PodIP:,StartTime:2019-10-11 17:54:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.952: INFO: Pod "webserver-deployment-c7997dcc8-cjgvm" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-cjgvm webserver-deployment-c7997dcc8- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-c7997dcc8-cjgvm 1207d56a-ecc3-4caf-bdca-e2ef168adbb2 11287 0 2019-10-11 17:54:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.244.3.51/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 962e9f6c-8402-4d8b-8f24-fe2828f68781 0xc001cb47d0 0xc001cb47d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-6-233.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.6.233,PodIP:,StartTime:2019-10-11 17:54:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.952: INFO: Pod "webserver-deployment-c7997dcc8-cqs46" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-cqs46 webserver-deployment-c7997dcc8- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-c7997dcc8-cqs46 1bb24fd7-a32d-45b7-964c-313c5d2a711c 11437 0 2019-10-11 17:54:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.244.3.54/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 962e9f6c-8402-4d8b-8f24-fe2828f68781 0xc001cb4947 0xc001cb4948}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-6-233.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.6.233,PodIP:,StartTime:2019-10-11 17:54:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.952: INFO: Pod "webserver-deployment-c7997dcc8-f4224" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-f4224 webserver-deployment-c7997dcc8- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-c7997dcc8-f4224 a72702fa-6ef5-48ec-8fe7-cfb7379546a1 11290 0 2019-10-11 17:54:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.244.3.52/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 962e9f6c-8402-4d8b-8f24-fe2828f68781 0xc001cb4ac7 0xc001cb4ac8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-6-233.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.6.233,PodIP:,StartTime:2019-10-11 17:54:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.952: INFO: Pod "webserver-deployment-c7997dcc8-llxmr" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-llxmr webserver-deployment-c7997dcc8- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-c7997dcc8-llxmr 689bd35a-d23a-4ffb-b9f5-0ef01c54b2c6 11384 0 2019-10-11 17:54:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 962e9f6c-8402-4d8b-8f24-fe2828f68781 0xc001cb4c37 0xc001cb4c38}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-5-54.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.5.54,PodIP:,StartTime:2019-10-11 17:54:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.952: INFO: Pod "webserver-deployment-c7997dcc8-lz7s5" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-lz7s5 webserver-deployment-c7997dcc8- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-c7997dcc8-lz7s5 c4ab6897-a4e2-4985-9541-ff0b2b2acd64 11422 0 2019-10-11 17:54:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.244.4.36/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 962e9f6c-8402-4d8b-8f24-fe2828f68781 0xc001cb4db0 0xc001cb4db1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-5-54.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.5.54,PodIP:10.244.4.36,StartTime:2019-10-11 17:54:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login',},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.36,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.952: INFO: Pod "webserver-deployment-c7997dcc8-mc7r2" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-mc7r2 webserver-deployment-c7997dcc8- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-c7997dcc8-mc7r2 7fe8cfa0-a54a-4712-947e-18e83b0842b7 11380 0 2019-10-11 17:54:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 962e9f6c-8402-4d8b-8f24-fe2828f68781 0xc001cb4f40 0xc001cb4f41}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-25.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.25,PodIP:,StartTime:2019-10-11 17:54:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.953: INFO: Pod "webserver-deployment-c7997dcc8-p4ldq" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-p4ldq webserver-deployment-c7997dcc8- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-c7997dcc8-p4ldq fcdff9a8-ab67-4ff2-910b-54e4b7950067 11292 0 2019-10-11 17:54:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.244.4.37/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 962e9f6c-8402-4d8b-8f24-fe2828f68781 0xc001cb50b0 0xc001cb50b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-5-54.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.5.54,PodIP:,StartTime:2019-10-11 17:54:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.953: INFO: Pod "webserver-deployment-c7997dcc8-pw7gg" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-pw7gg webserver-deployment-c7997dcc8- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-c7997dcc8-pw7gg f07baaf1-abee-4b1f-a846-bef9644e7ea6 11425 0 2019-10-11 17:54:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.244.5.32/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 962e9f6c-8402-4d8b-8f24-fe2828f68781 0xc001cb5220 0xc001cb5221}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-25.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.25,PodIP:,StartTime:2019-10-11 17:54:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.953: INFO: Pod "webserver-deployment-c7997dcc8-qdn4r" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-qdn4r webserver-deployment-c7997dcc8- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-c7997dcc8-qdn4r 39d0b043-5f64-46e1-81ca-14d37e380b3a 11392 0 2019-10-11 17:54:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 962e9f6c-8402-4d8b-8f24-fe2828f68781 0xc001cb5380 0xc001cb5381}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-25.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.25,PodIP:,StartTime:2019-10-11 17:54:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 17:54:54.953: INFO: Pod "webserver-deployment-c7997dcc8-zwlcw" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-zwlcw webserver-deployment-c7997dcc8- deployment-3080 /api/v1/namespaces/deployment-3080/pods/webserver-deployment-c7997dcc8-zwlcw c0b0d64a-963c-4553-a28b-ccc909f7ff1a 11368 0 2019-10-11 17:54:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 962e9f6c-8402-4d8b-8f24-fe2828f68781 0xc001cb54e0 0xc001cb54e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jgjm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jgjm4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jgjm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-5-54.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 17:54:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.5.54,PodIP:,StartTime:2019-10-11 17:54:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:54:54.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3080" for this suite.
Oct 11 17:55:02.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:55:03.125: INFO: namespace deployment-3080 deletion completed in 8.16715926s

• [SLOW TEST:16.367 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:55:03.125: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 17:55:03.165: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:55:07.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6799" for this suite.
Oct 11 17:55:51.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:55:51.565: INFO: namespace pods-6799 deletion completed in 44.148872895s

• [SLOW TEST:48.440 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:55:51.566: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Oct 11 17:55:52.138: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Oct 11 17:55:54.154: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706413351, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706413351, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706413351, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706413351, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 11 17:55:57.176: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 17:55:57.181: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:55:58.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-9365" for this suite.
Oct 11 17:56:04.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:56:04.466: INFO: namespace crd-webhook-9365 deletion completed in 6.148265243s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:12.921 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:56:04.487: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-b6ef5e84-650b-4600-b8e6-54b514b0e5b9
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:56:04.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8356" for this suite.
Oct 11 17:56:10.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:56:10.682: INFO: namespace configmap-8356 deletion completed in 6.150149963s

• [SLOW TEST:6.195 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:56:10.683: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct 11 17:56:10.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-1501'
Oct 11 17:56:10.787: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 11 17:56:10.787: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Oct 11 17:56:10.799: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-kzjc5]
Oct 11 17:56:10.799: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-kzjc5" in namespace "kubectl-1501" to be "running and ready"
Oct 11 17:56:10.804: INFO: Pod "e2e-test-httpd-rc-kzjc5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.395611ms
Oct 11 17:56:12.809: INFO: Pod "e2e-test-httpd-rc-kzjc5": Phase="Running", Reason="", readiness=true. Elapsed: 2.009255821s
Oct 11 17:56:12.809: INFO: Pod "e2e-test-httpd-rc-kzjc5" satisfied condition "running and ready"
Oct 11 17:56:12.809: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-kzjc5]
Oct 11 17:56:12.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 logs rc/e2e-test-httpd-rc --namespace=kubectl-1501'
Oct 11 17:56:12.903: INFO: stderr: ""
Oct 11 17:56:12.903: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.244.3.60. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.244.3.60. Set the 'ServerName' directive globally to suppress this message\n[Fri Oct 11 17:56:11.728669 2019] [mpm_event:notice] [pid 1:tid 139997134859112] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Fri Oct 11 17:56:11.730926 2019] [core:notice] [pid 1:tid 139997134859112] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Oct 11 17:56:12.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 delete rc e2e-test-httpd-rc --namespace=kubectl-1501'
Oct 11 17:56:12.976: INFO: stderr: ""
Oct 11 17:56:12.976: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 17:56:12.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1501" for this suite.
Oct 11 17:56:25.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 17:56:25.145: INFO: namespace kubectl-1501 deletion completed in 12.163161877s

• [SLOW TEST:14.463 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 17:56:25.145: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Oct 11 17:56:25.182: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 11 17:56:25.196: INFO: Waiting for terminating namespaces to be deleted...
Oct 11 17:56:25.200: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-1-25.eu-west-3.compute.internal before test
Oct 11 17:56:25.215: INFO: sonobuoy-e2e-job-56f76d39d0764ff1 from sonobuoy started at 2019-10-11 17:28:08 +0000 UTC (2 container statuses recorded)
Oct 11 17:56:25.215: INFO: 	Container e2e ready: true, restart count 0
Oct 11 17:56:25.215: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 11 17:56:25.215: INFO: kube-proxy-m86rm from kube-system started at 2019-10-11 17:26:31 +0000 UTC (1 container statuses recorded)
Oct 11 17:56:25.215: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 11 17:56:25.215: INFO: canal-jn9ph from kube-system started at 2019-10-11 17:26:31 +0000 UTC (2 container statuses recorded)
Oct 11 17:56:25.215: INFO: 	Container calico-node ready: true, restart count 0
Oct 11 17:56:25.215: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 11 17:56:25.215: INFO: sonobuoy-systemd-logs-daemon-set-8223689078594c46-86r77 from sonobuoy started at 2019-10-11 17:28:08 +0000 UTC (2 container statuses recorded)
Oct 11 17:56:25.215: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 11 17:56:25.215: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 11 17:56:25.215: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-5-54.eu-west-3.compute.internal before test
Oct 11 17:56:25.230: INFO: sonobuoy from sonobuoy started at 2019-10-11 17:28:02 +0000 UTC (1 container statuses recorded)
Oct 11 17:56:25.230: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 11 17:56:25.230: INFO: sonobuoy-systemd-logs-daemon-set-8223689078594c46-wrftl from sonobuoy started at 2019-10-11 17:28:08 +0000 UTC (2 container statuses recorded)
Oct 11 17:56:25.230: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 11 17:56:25.230: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 11 17:56:25.230: INFO: kube-proxy-gczvl from kube-system started at 2019-10-11 17:26:30 +0000 UTC (1 container statuses recorded)
Oct 11 17:56:25.230: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 11 17:56:25.230: INFO: canal-hdnlb from kube-system started at 2019-10-11 17:26:30 +0000 UTC (2 container statuses recorded)
Oct 11 17:56:25.230: INFO: 	Container calico-node ready: true, restart count 0
Oct 11 17:56:25.230: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 11 17:56:25.230: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-6-233.eu-west-3.compute.internal before test
Oct 11 17:56:25.244: INFO: metrics-server-59bb664678-prm7v from kube-system started at 2019-10-11 17:24:41 +0000 UTC (1 container statuses recorded)
Oct 11 17:56:25.244: INFO: 	Container metrics-server ready: true, restart count 0
Oct 11 17:56:25.244: INFO: sonobuoy-systemd-logs-daemon-set-8223689078594c46-lhhdq from sonobuoy started at 2019-10-11 17:28:08 +0000 UTC (2 container statuses recorded)
Oct 11 17:56:25.244: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 11 17:56:25.244: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 11 17:56:25.244: INFO: kube-proxy-qw2gl from kube-system started at 2019-10-11 17:24:22 +0000 UTC (1 container statuses recorded)
Oct 11 17:56:25.244: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 11 17:56:25.244: INFO: canal-2xwdt from kube-system started at 2019-10-11 17:24:22 +0000 UTC (2 container statuses recorded)
Oct 11 17:56:25.244: INFO: 	Container calico-node ready: true, restart count 0
Oct 11 17:56:25.244: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-d74a210f-12b9-454a-b836-6f2393bf2467 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-d74a210f-12b9-454a-b836-6f2393bf2467 off the node ip-172-31-6-233.eu-west-3.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-d74a210f-12b9-454a-b836-6f2393bf2467
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:01:29.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2830" for this suite.
Oct 11 18:01:39.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:01:39.520: INFO: namespace sched-pred-2830 deletion completed in 10.150418494s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:314.375 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:01:39.521: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 18:01:39.557: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Oct 11 18:01:42.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 --namespace=crd-publish-openapi-3774 create -f -'
Oct 11 18:01:43.048: INFO: stderr: ""
Oct 11 18:01:43.048: INFO: stdout: "e2e-test-crd-publish-openapi-4650-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Oct 11 18:01:43.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 --namespace=crd-publish-openapi-3774 delete e2e-test-crd-publish-openapi-4650-crds test-foo'
Oct 11 18:01:43.128: INFO: stderr: ""
Oct 11 18:01:43.129: INFO: stdout: "e2e-test-crd-publish-openapi-4650-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Oct 11 18:01:43.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 --namespace=crd-publish-openapi-3774 apply -f -'
Oct 11 18:01:43.348: INFO: stderr: ""
Oct 11 18:01:43.348: INFO: stdout: "e2e-test-crd-publish-openapi-4650-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Oct 11 18:01:43.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 --namespace=crd-publish-openapi-3774 delete e2e-test-crd-publish-openapi-4650-crds test-foo'
Oct 11 18:01:43.424: INFO: stderr: ""
Oct 11 18:01:43.424: INFO: stdout: "e2e-test-crd-publish-openapi-4650-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Oct 11 18:01:43.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 --namespace=crd-publish-openapi-3774 create -f -'
Oct 11 18:01:43.603: INFO: rc: 1
Oct 11 18:01:43.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 --namespace=crd-publish-openapi-3774 apply -f -'
Oct 11 18:01:43.743: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Oct 11 18:01:43.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 --namespace=crd-publish-openapi-3774 create -f -'
Oct 11 18:01:43.924: INFO: rc: 1
Oct 11 18:01:43.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 --namespace=crd-publish-openapi-3774 apply -f -'
Oct 11 18:01:44.072: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Oct 11 18:01:44.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 explain e2e-test-crd-publish-openapi-4650-crds'
Oct 11 18:01:44.262: INFO: stderr: ""
Oct 11 18:01:44.262: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4650-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Oct 11 18:01:44.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 explain e2e-test-crd-publish-openapi-4650-crds.metadata'
Oct 11 18:01:44.461: INFO: stderr: ""
Oct 11 18:01:44.461: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4650-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Oct 11 18:01:44.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 explain e2e-test-crd-publish-openapi-4650-crds.spec'
Oct 11 18:01:44.652: INFO: stderr: ""
Oct 11 18:01:44.652: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4650-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Oct 11 18:01:44.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 explain e2e-test-crd-publish-openapi-4650-crds.spec.bars'
Oct 11 18:01:44.842: INFO: stderr: ""
Oct 11 18:01:44.842: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4650-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Oct 11 18:01:44.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 explain e2e-test-crd-publish-openapi-4650-crds.spec.bars2'
Oct 11 18:01:44.987: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:01:46.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3774" for this suite.
Oct 11 18:01:52.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:01:53.139: INFO: namespace crd-publish-openapi-3774 deletion completed in 6.158111413s

• [SLOW TEST:13.619 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:01:53.140: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-5855
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 11 18:01:53.177: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 11 18:02:17.281: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.5.39 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5855 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 11 18:02:17.281: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 18:02:18.443: INFO: Found all expected endpoints: [netserver-0]
Oct 11 18:02:18.448: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.4.46 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5855 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 11 18:02:18.448: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 18:02:19.686: INFO: Found all expected endpoints: [netserver-1]
Oct 11 18:02:19.691: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.3.63 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5855 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 11 18:02:19.691: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 18:02:20.927: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:02:20.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5855" for this suite.
Oct 11 18:02:32.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:02:33.089: INFO: namespace pod-network-test-5855 deletion completed in 12.155962879s

• [SLOW TEST:39.949 seconds]
[sig-network] Networking
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:02:33.089: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-w4dnd in namespace proxy-284
I1011 18:02:33.153164      19 runners.go:184] Created replication controller with name: proxy-service-w4dnd, namespace: proxy-284, replica count: 1
I1011 18:02:34.203621      19 runners.go:184] proxy-service-w4dnd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1011 18:02:35.203966      19 runners.go:184] proxy-service-w4dnd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1011 18:02:36.204141      19 runners.go:184] proxy-service-w4dnd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1011 18:02:37.204326      19 runners.go:184] proxy-service-w4dnd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1011 18:02:38.204494      19 runners.go:184] proxy-service-w4dnd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1011 18:02:39.204780      19 runners.go:184] proxy-service-w4dnd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1011 18:02:40.205027      19 runners.go:184] proxy-service-w4dnd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1011 18:02:41.205182      19 runners.go:184] proxy-service-w4dnd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1011 18:02:42.205347      19 runners.go:184] proxy-service-w4dnd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1011 18:02:43.205645      19 runners.go:184] proxy-service-w4dnd Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 11 18:02:43.211: INFO: setup took 10.086220171s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Oct 11 18:02:43.223: INFO: (0) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">t... (200; 11.854405ms)
Oct 11 18:02:43.227: INFO: (0) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname2/proxy/: bar (200; 15.125622ms)
Oct 11 18:02:43.227: INFO: (0) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/rewriteme">test</a> (200; 15.290837ms)
Oct 11 18:02:43.227: INFO: (0) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 15.617811ms)
Oct 11 18:02:43.227: INFO: (0) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 15.207101ms)
Oct 11 18:02:43.227: INFO: (0) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 15.534177ms)
Oct 11 18:02:43.227: INFO: (0) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname1/proxy/: foo (200; 16.331467ms)
Oct 11 18:02:43.228: INFO: (0) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">test</... (200; 16.565882ms)
Oct 11 18:02:43.228: INFO: (0) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname1/proxy/: foo (200; 16.854426ms)
Oct 11 18:02:43.229: INFO: (0) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname2/proxy/: bar (200; 17.547325ms)
Oct 11 18:02:43.229: INFO: (0) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 16.952893ms)
Oct 11 18:02:43.233: INFO: (0) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/tlsrewriteme... (200; 22.302281ms)
Oct 11 18:02:43.233: INFO: (0) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:462/proxy/: tls qux (200; 21.801021ms)
Oct 11 18:02:43.234: INFO: (0) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:460/proxy/: tls baz (200; 22.685067ms)
Oct 11 18:02:43.234: INFO: (0) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname1/proxy/: tls baz (200; 23.329312ms)
Oct 11 18:02:43.237: INFO: (0) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname2/proxy/: tls qux (200; 25.297517ms)
Oct 11 18:02:43.247: INFO: (1) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">test</... (200; 9.946412ms)
Oct 11 18:02:43.247: INFO: (1) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/rewriteme">test</a> (200; 10.13448ms)
Oct 11 18:02:43.248: INFO: (1) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 10.138106ms)
Oct 11 18:02:43.248: INFO: (1) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/tlsrewriteme... (200; 10.795861ms)
Oct 11 18:02:43.248: INFO: (1) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">t... (200; 11.135169ms)
Oct 11 18:02:43.249: INFO: (1) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname2/proxy/: tls qux (200; 12.096105ms)
Oct 11 18:02:43.249: INFO: (1) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:460/proxy/: tls baz (200; 11.773332ms)
Oct 11 18:02:43.249: INFO: (1) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:462/proxy/: tls qux (200; 12.391403ms)
Oct 11 18:02:43.250: INFO: (1) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 12.634258ms)
Oct 11 18:02:43.250: INFO: (1) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 12.414343ms)
Oct 11 18:02:43.251: INFO: (1) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 13.916336ms)
Oct 11 18:02:43.251: INFO: (1) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname1/proxy/: foo (200; 14.230113ms)
Oct 11 18:02:43.252: INFO: (1) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname1/proxy/: tls baz (200; 14.480546ms)
Oct 11 18:02:43.252: INFO: (1) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname2/proxy/: bar (200; 14.225554ms)
Oct 11 18:02:43.252: INFO: (1) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname2/proxy/: bar (200; 14.556815ms)
Oct 11 18:02:43.252: INFO: (1) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname1/proxy/: foo (200; 14.934574ms)
Oct 11 18:02:43.259: INFO: (2) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/tlsrewriteme... (200; 6.724961ms)
Oct 11 18:02:43.262: INFO: (2) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">t... (200; 9.51338ms)
Oct 11 18:02:43.262: INFO: (2) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:462/proxy/: tls qux (200; 9.685003ms)
Oct 11 18:02:43.262: INFO: (2) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 10.064124ms)
Oct 11 18:02:43.263: INFO: (2) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 10.400298ms)
Oct 11 18:02:43.263: INFO: (2) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/rewriteme">test</a> (200; 10.589975ms)
Oct 11 18:02:43.263: INFO: (2) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 10.566662ms)
Oct 11 18:02:43.263: INFO: (2) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 10.785398ms)
Oct 11 18:02:43.263: INFO: (2) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">test</... (200; 10.930792ms)
Oct 11 18:02:43.263: INFO: (2) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:460/proxy/: tls baz (200; 10.830686ms)
Oct 11 18:02:43.266: INFO: (2) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname1/proxy/: foo (200; 14.001454ms)
Oct 11 18:02:43.268: INFO: (2) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname2/proxy/: bar (200; 15.833987ms)
Oct 11 18:02:43.268: INFO: (2) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname2/proxy/: bar (200; 15.586101ms)
Oct 11 18:02:43.268: INFO: (2) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname2/proxy/: tls qux (200; 15.78354ms)
Oct 11 18:02:43.269: INFO: (2) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname1/proxy/: foo (200; 16.263967ms)
Oct 11 18:02:43.269: INFO: (2) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname1/proxy/: tls baz (200; 16.401864ms)
Oct 11 18:02:43.280: INFO: (3) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 10.922275ms)
Oct 11 18:02:43.280: INFO: (3) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 10.951646ms)
Oct 11 18:02:43.280: INFO: (3) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">test</... (200; 11.086968ms)
Oct 11 18:02:43.280: INFO: (3) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 11.104728ms)
Oct 11 18:02:43.281: INFO: (3) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:462/proxy/: tls qux (200; 11.793007ms)
Oct 11 18:02:43.281: INFO: (3) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/rewriteme">test</a> (200; 12.121093ms)
Oct 11 18:02:43.281: INFO: (3) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 12.25131ms)
Oct 11 18:02:43.281: INFO: (3) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/tlsrewriteme... (200; 12.377684ms)
Oct 11 18:02:43.281: INFO: (3) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:460/proxy/: tls baz (200; 12.274482ms)
Oct 11 18:02:43.282: INFO: (3) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">t... (200; 12.288875ms)
Oct 11 18:02:43.282: INFO: (3) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname1/proxy/: foo (200; 13.192566ms)
Oct 11 18:02:43.283: INFO: (3) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname1/proxy/: tls baz (200; 13.356695ms)
Oct 11 18:02:43.283: INFO: (3) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname2/proxy/: bar (200; 13.522078ms)
Oct 11 18:02:43.283: INFO: (3) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname2/proxy/: bar (200; 13.531272ms)
Oct 11 18:02:43.283: INFO: (3) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname2/proxy/: tls qux (200; 13.786954ms)
Oct 11 18:02:43.283: INFO: (3) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname1/proxy/: foo (200; 13.753382ms)
Oct 11 18:02:43.289: INFO: (4) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/tlsrewriteme... (200; 6.086402ms)
Oct 11 18:02:43.294: INFO: (4) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:462/proxy/: tls qux (200; 10.629493ms)
Oct 11 18:02:43.294: INFO: (4) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">test</... (200; 10.451637ms)
Oct 11 18:02:43.294: INFO: (4) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/rewriteme">test</a> (200; 11.009311ms)
Oct 11 18:02:43.295: INFO: (4) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:460/proxy/: tls baz (200; 10.878326ms)
Oct 11 18:02:43.295: INFO: (4) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 10.698379ms)
Oct 11 18:02:43.295: INFO: (4) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">t... (200; 10.851387ms)
Oct 11 18:02:43.295: INFO: (4) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 11.54124ms)
Oct 11 18:02:43.295: INFO: (4) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 11.617018ms)
Oct 11 18:02:43.295: INFO: (4) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 11.83008ms)
Oct 11 18:02:43.296: INFO: (4) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname2/proxy/: bar (200; 12.739014ms)
Oct 11 18:02:43.298: INFO: (4) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname1/proxy/: tls baz (200; 14.387767ms)
Oct 11 18:02:43.298: INFO: (4) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname2/proxy/: bar (200; 14.636598ms)
Oct 11 18:02:43.299: INFO: (4) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname1/proxy/: foo (200; 15.24826ms)
Oct 11 18:02:43.299: INFO: (4) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname2/proxy/: tls qux (200; 15.074962ms)
Oct 11 18:02:43.299: INFO: (4) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname1/proxy/: foo (200; 15.166786ms)
Oct 11 18:02:43.308: INFO: (5) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:462/proxy/: tls qux (200; 9.100678ms)
Oct 11 18:02:43.308: INFO: (5) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/tlsrewriteme... (200; 9.276755ms)
Oct 11 18:02:43.313: INFO: (5) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 14.453278ms)
Oct 11 18:02:43.316: INFO: (5) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">t... (200; 16.604349ms)
Oct 11 18:02:43.316: INFO: (5) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 16.666943ms)
Oct 11 18:02:43.316: INFO: (5) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/rewriteme">test</a> (200; 16.735306ms)
Oct 11 18:02:43.316: INFO: (5) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 16.774426ms)
Oct 11 18:02:43.316: INFO: (5) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">test</... (200; 17.472851ms)
Oct 11 18:02:43.317: INFO: (5) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 17.367021ms)
Oct 11 18:02:43.317: INFO: (5) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:460/proxy/: tls baz (200; 17.459289ms)
Oct 11 18:02:43.317: INFO: (5) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname1/proxy/: tls baz (200; 18.053285ms)
Oct 11 18:02:43.317: INFO: (5) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname1/proxy/: foo (200; 18.178944ms)
Oct 11 18:02:43.319: INFO: (5) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname2/proxy/: bar (200; 20.076626ms)
Oct 11 18:02:43.319: INFO: (5) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname2/proxy/: bar (200; 20.072291ms)
Oct 11 18:02:43.320: INFO: (5) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname2/proxy/: tls qux (200; 20.376291ms)
Oct 11 18:02:43.320: INFO: (5) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname1/proxy/: foo (200; 20.407736ms)
Oct 11 18:02:43.329: INFO: (6) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/tlsrewriteme... (200; 9.107659ms)
Oct 11 18:02:43.329: INFO: (6) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">t... (200; 9.353184ms)
Oct 11 18:02:43.330: INFO: (6) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">test</... (200; 9.554124ms)
Oct 11 18:02:43.330: INFO: (6) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/rewriteme">test</a> (200; 9.796252ms)
Oct 11 18:02:43.330: INFO: (6) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 10.200789ms)
Oct 11 18:02:43.330: INFO: (6) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 10.249372ms)
Oct 11 18:02:43.330: INFO: (6) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 9.970744ms)
Oct 11 18:02:43.331: INFO: (6) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 10.844183ms)
Oct 11 18:02:43.331: INFO: (6) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:460/proxy/: tls baz (200; 11.04245ms)
Oct 11 18:02:43.331: INFO: (6) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:462/proxy/: tls qux (200; 11.034959ms)
Oct 11 18:02:43.332: INFO: (6) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname2/proxy/: tls qux (200; 12.551236ms)
Oct 11 18:02:43.334: INFO: (6) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname1/proxy/: foo (200; 14.039326ms)
Oct 11 18:02:43.336: INFO: (6) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname1/proxy/: tls baz (200; 16.155021ms)
Oct 11 18:02:43.336: INFO: (6) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname2/proxy/: bar (200; 16.075961ms)
Oct 11 18:02:43.336: INFO: (6) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname2/proxy/: bar (200; 16.412368ms)
Oct 11 18:02:43.337: INFO: (6) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname1/proxy/: foo (200; 16.822851ms)
Oct 11 18:02:43.348: INFO: (7) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 10.961561ms)
Oct 11 18:02:43.348: INFO: (7) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:462/proxy/: tls qux (200; 10.602096ms)
Oct 11 18:02:43.348: INFO: (7) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 11.094876ms)
Oct 11 18:02:43.349: INFO: (7) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">t... (200; 11.625616ms)
Oct 11 18:02:43.349: INFO: (7) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/tlsrewriteme... (200; 12.00588ms)
Oct 11 18:02:43.349: INFO: (7) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">test</... (200; 12.114401ms)
Oct 11 18:02:43.349: INFO: (7) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:460/proxy/: tls baz (200; 12.455042ms)
Oct 11 18:02:43.350: INFO: (7) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 13.255711ms)
Oct 11 18:02:43.350: INFO: (7) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname2/proxy/: tls qux (200; 13.634089ms)
Oct 11 18:02:43.350: INFO: (7) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/rewriteme">test</a> (200; 13.249899ms)
Oct 11 18:02:43.351: INFO: (7) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 13.209202ms)
Oct 11 18:02:43.351: INFO: (7) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname1/proxy/: foo (200; 13.795141ms)
Oct 11 18:02:43.351: INFO: (7) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname1/proxy/: tls baz (200; 13.663777ms)
Oct 11 18:02:43.351: INFO: (7) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname2/proxy/: bar (200; 13.921829ms)
Oct 11 18:02:43.352: INFO: (7) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname1/proxy/: foo (200; 14.277161ms)
Oct 11 18:02:43.352: INFO: (7) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname2/proxy/: bar (200; 14.98272ms)
Oct 11 18:02:43.363: INFO: (8) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">t... (200; 9.500928ms)
Oct 11 18:02:43.363: INFO: (8) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 9.901012ms)
Oct 11 18:02:43.363: INFO: (8) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 10.167783ms)
Oct 11 18:02:43.363: INFO: (8) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">test</... (200; 10.362444ms)
Oct 11 18:02:43.363: INFO: (8) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/tlsrewriteme... (200; 10.409222ms)
Oct 11 18:02:43.363: INFO: (8) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/rewriteme">test</a> (200; 10.250193ms)
Oct 11 18:02:43.364: INFO: (8) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:460/proxy/: tls baz (200; 10.891587ms)
Oct 11 18:02:43.364: INFO: (8) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 11.743639ms)
Oct 11 18:02:43.365: INFO: (8) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname1/proxy/: tls baz (200; 12.377145ms)
Oct 11 18:02:43.365: INFO: (8) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:462/proxy/: tls qux (200; 12.452518ms)
Oct 11 18:02:43.365: INFO: (8) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 12.341876ms)
Oct 11 18:02:43.366: INFO: (8) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname2/proxy/: bar (200; 13.212008ms)
Oct 11 18:02:43.368: INFO: (8) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname2/proxy/: bar (200; 14.78711ms)
Oct 11 18:02:43.368: INFO: (8) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname1/proxy/: foo (200; 14.877643ms)
Oct 11 18:02:43.368: INFO: (8) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname2/proxy/: tls qux (200; 15.277455ms)
Oct 11 18:02:43.368: INFO: (8) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname1/proxy/: foo (200; 15.627401ms)
Oct 11 18:02:43.379: INFO: (9) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:460/proxy/: tls baz (200; 9.797502ms)
Oct 11 18:02:43.379: INFO: (9) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:462/proxy/: tls qux (200; 10.75714ms)
Oct 11 18:02:43.379: INFO: (9) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/tlsrewriteme... (200; 10.493854ms)
Oct 11 18:02:43.379: INFO: (9) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 10.427068ms)
Oct 11 18:02:43.379: INFO: (9) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 10.521441ms)
Oct 11 18:02:43.379: INFO: (9) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">test</... (200; 10.8111ms)
Oct 11 18:02:43.379: INFO: (9) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 10.716861ms)
Oct 11 18:02:43.380: INFO: (9) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 10.705024ms)
Oct 11 18:02:43.380: INFO: (9) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">t... (200; 10.902252ms)
Oct 11 18:02:43.380: INFO: (9) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/rewriteme">test</a> (200; 10.836098ms)
Oct 11 18:02:43.381: INFO: (9) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname1/proxy/: tls baz (200; 12.815446ms)
Oct 11 18:02:43.383: INFO: (9) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname2/proxy/: bar (200; 14.503815ms)
Oct 11 18:02:43.383: INFO: (9) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname2/proxy/: tls qux (200; 14.69198ms)
Oct 11 18:02:43.385: INFO: (9) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname1/proxy/: foo (200; 16.25665ms)
Oct 11 18:02:43.385: INFO: (9) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname1/proxy/: foo (200; 16.635903ms)
Oct 11 18:02:43.385: INFO: (9) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname2/proxy/: bar (200; 16.561752ms)
Oct 11 18:02:43.393: INFO: (10) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 7.557142ms)
Oct 11 18:02:43.396: INFO: (10) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:460/proxy/: tls baz (200; 10.367419ms)
Oct 11 18:02:43.398: INFO: (10) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 11.990418ms)
Oct 11 18:02:43.398: INFO: (10) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">t... (200; 12.30049ms)
Oct 11 18:02:43.398: INFO: (10) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 12.217283ms)
Oct 11 18:02:43.398: INFO: (10) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">test</... (200; 12.097141ms)
Oct 11 18:02:43.398: INFO: (10) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:462/proxy/: tls qux (200; 12.082249ms)
Oct 11 18:02:43.398: INFO: (10) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/rewriteme">test</a> (200; 12.460723ms)
Oct 11 18:02:43.398: INFO: (10) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 12.284617ms)
Oct 11 18:02:43.398: INFO: (10) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/tlsrewriteme... (200; 12.319112ms)
Oct 11 18:02:43.400: INFO: (10) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname1/proxy/: tls baz (200; 13.934464ms)
Oct 11 18:02:43.402: INFO: (10) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname1/proxy/: foo (200; 16.032292ms)
Oct 11 18:02:43.402: INFO: (10) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname2/proxy/: tls qux (200; 16.463305ms)
Oct 11 18:02:43.402: INFO: (10) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname2/proxy/: bar (200; 16.590406ms)
Oct 11 18:02:43.403: INFO: (10) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname1/proxy/: foo (200; 16.978341ms)
Oct 11 18:02:43.403: INFO: (10) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname2/proxy/: bar (200; 16.99257ms)
Oct 11 18:02:43.413: INFO: (11) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/rewriteme">test</a> (200; 10.62001ms)
Oct 11 18:02:43.413: INFO: (11) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 10.246038ms)
Oct 11 18:02:43.414: INFO: (11) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/tlsrewriteme... (200; 10.799844ms)
Oct 11 18:02:43.414: INFO: (11) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">test</... (200; 11.311531ms)
Oct 11 18:02:43.415: INFO: (11) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 11.998983ms)
Oct 11 18:02:43.415: INFO: (11) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:462/proxy/: tls qux (200; 12.269024ms)
Oct 11 18:02:43.416: INFO: (11) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname2/proxy/: bar (200; 12.799185ms)
Oct 11 18:02:43.416: INFO: (11) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 12.760459ms)
Oct 11 18:02:43.416: INFO: (11) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 13.033129ms)
Oct 11 18:02:43.416: INFO: (11) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:460/proxy/: tls baz (200; 12.825846ms)
Oct 11 18:02:43.417: INFO: (11) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname1/proxy/: foo (200; 13.839222ms)
Oct 11 18:02:43.418: INFO: (11) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">t... (200; 14.88684ms)
Oct 11 18:02:43.418: INFO: (11) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname1/proxy/: foo (200; 15.176005ms)
Oct 11 18:02:43.418: INFO: (11) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname1/proxy/: tls baz (200; 15.622237ms)
Oct 11 18:02:43.419: INFO: (11) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname2/proxy/: bar (200; 15.777581ms)
Oct 11 18:02:43.419: INFO: (11) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname2/proxy/: tls qux (200; 15.576743ms)
Oct 11 18:02:43.429: INFO: (12) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 10.472779ms)
Oct 11 18:02:43.430: INFO: (12) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">t... (200; 10.764045ms)
Oct 11 18:02:43.430: INFO: (12) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:462/proxy/: tls qux (200; 10.931024ms)
Oct 11 18:02:43.430: INFO: (12) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 11.210908ms)
Oct 11 18:02:43.431: INFO: (12) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 11.682566ms)
Oct 11 18:02:43.431: INFO: (12) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:460/proxy/: tls baz (200; 11.583861ms)
Oct 11 18:02:43.431: INFO: (12) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/rewriteme">test</a> (200; 11.961723ms)
Oct 11 18:02:43.431: INFO: (12) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">test</... (200; 12.109577ms)
Oct 11 18:02:43.431: INFO: (12) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/tlsrewriteme... (200; 12.315614ms)
Oct 11 18:02:43.431: INFO: (12) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 12.115751ms)
Oct 11 18:02:43.432: INFO: (12) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname1/proxy/: tls baz (200; 13.188009ms)
Oct 11 18:02:43.433: INFO: (12) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname1/proxy/: foo (200; 14.454038ms)
Oct 11 18:02:43.434: INFO: (12) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname2/proxy/: bar (200; 14.753323ms)
Oct 11 18:02:43.434: INFO: (12) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname1/proxy/: foo (200; 15.047712ms)
Oct 11 18:02:43.434: INFO: (12) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname2/proxy/: tls qux (200; 15.157326ms)
Oct 11 18:02:43.436: INFO: (12) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname2/proxy/: bar (200; 16.522306ms)
Oct 11 18:02:43.442: INFO: (13) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/tlsrewriteme... (200; 6.152478ms)
Oct 11 18:02:43.444: INFO: (13) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 7.859008ms)
Oct 11 18:02:43.444: INFO: (13) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">test</... (200; 7.947744ms)
Oct 11 18:02:43.448: INFO: (13) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:460/proxy/: tls baz (200; 11.862743ms)
Oct 11 18:02:43.448: INFO: (13) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 12.854976ms)
Oct 11 18:02:43.449: INFO: (13) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 12.466884ms)
Oct 11 18:02:43.449: INFO: (13) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:462/proxy/: tls qux (200; 12.443598ms)
Oct 11 18:02:43.449: INFO: (13) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">t... (200; 12.555889ms)
Oct 11 18:02:43.449: INFO: (13) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/rewriteme">test</a> (200; 12.451683ms)
Oct 11 18:02:43.448: INFO: (13) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 12.167354ms)
Oct 11 18:02:43.449: INFO: (13) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname1/proxy/: foo (200; 12.693259ms)
Oct 11 18:02:43.450: INFO: (13) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname1/proxy/: foo (200; 13.614318ms)
Oct 11 18:02:43.451: INFO: (13) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname2/proxy/: bar (200; 14.667496ms)
Oct 11 18:02:43.451: INFO: (13) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname2/proxy/: bar (200; 15.286799ms)
Oct 11 18:02:43.451: INFO: (13) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname1/proxy/: tls baz (200; 15.257714ms)
Oct 11 18:02:43.453: INFO: (13) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname2/proxy/: tls qux (200; 16.213177ms)
Oct 11 18:02:43.464: INFO: (14) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 11.134402ms)
Oct 11 18:02:43.465: INFO: (14) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/tlsrewriteme... (200; 11.934784ms)
Oct 11 18:02:43.465: INFO: (14) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:462/proxy/: tls qux (200; 11.539973ms)
Oct 11 18:02:43.465: INFO: (14) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 12.3099ms)
Oct 11 18:02:43.466: INFO: (14) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">test</... (200; 12.676172ms)
Oct 11 18:02:43.466: INFO: (14) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 12.803976ms)
Oct 11 18:02:43.466: INFO: (14) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 12.791047ms)
Oct 11 18:02:43.465: INFO: (14) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/rewriteme">test</a> (200; 12.44333ms)
Oct 11 18:02:43.466: INFO: (14) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:460/proxy/: tls baz (200; 12.850291ms)
Oct 11 18:02:43.466: INFO: (14) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">t... (200; 13.067797ms)
Oct 11 18:02:43.467: INFO: (14) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname1/proxy/: foo (200; 13.524316ms)
Oct 11 18:02:43.467: INFO: (14) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname1/proxy/: foo (200; 13.714425ms)
Oct 11 18:02:43.469: INFO: (14) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname2/proxy/: tls qux (200; 15.71504ms)
Oct 11 18:02:43.469: INFO: (14) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname2/proxy/: bar (200; 15.921968ms)
Oct 11 18:02:43.469: INFO: (14) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname2/proxy/: bar (200; 15.810265ms)
Oct 11 18:02:43.469: INFO: (14) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname1/proxy/: tls baz (200; 16.072607ms)
Oct 11 18:02:43.480: INFO: (15) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 10.806571ms)
Oct 11 18:02:43.481: INFO: (15) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 11.146403ms)
Oct 11 18:02:43.481: INFO: (15) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">test</... (200; 10.87929ms)
Oct 11 18:02:43.481: INFO: (15) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/rewriteme">test</a> (200; 11.782243ms)
Oct 11 18:02:43.481: INFO: (15) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:460/proxy/: tls baz (200; 11.928258ms)
Oct 11 18:02:43.481: INFO: (15) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:462/proxy/: tls qux (200; 12.223994ms)
Oct 11 18:02:43.482: INFO: (15) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">t... (200; 12.401774ms)
Oct 11 18:02:43.482: INFO: (15) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/tlsrewriteme... (200; 12.492436ms)
Oct 11 18:02:43.482: INFO: (15) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 12.503435ms)
Oct 11 18:02:43.482: INFO: (15) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 11.985614ms)
Oct 11 18:02:43.484: INFO: (15) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname2/proxy/: bar (200; 15.133678ms)
Oct 11 18:02:43.486: INFO: (15) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname1/proxy/: foo (200; 16.348801ms)
Oct 11 18:02:43.486: INFO: (15) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname2/proxy/: bar (200; 16.313165ms)
Oct 11 18:02:43.486: INFO: (15) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname2/proxy/: tls qux (200; 16.456761ms)
Oct 11 18:02:43.486: INFO: (15) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname1/proxy/: foo (200; 16.451361ms)
Oct 11 18:02:43.486: INFO: (15) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname1/proxy/: tls baz (200; 16.585102ms)
Oct 11 18:02:43.499: INFO: (16) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname1/proxy/: foo (200; 12.389032ms)
Oct 11 18:02:43.499: INFO: (16) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/tlsrewriteme... (200; 12.121425ms)
Oct 11 18:02:43.499: INFO: (16) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:462/proxy/: tls qux (200; 12.084544ms)
Oct 11 18:02:43.499: INFO: (16) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">t... (200; 12.33731ms)
Oct 11 18:02:43.499: INFO: (16) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:460/proxy/: tls baz (200; 12.981355ms)
Oct 11 18:02:43.499: INFO: (16) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 12.232998ms)
Oct 11 18:02:43.499: INFO: (16) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 12.707211ms)
Oct 11 18:02:43.499: INFO: (16) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 12.351147ms)
Oct 11 18:02:43.499: INFO: (16) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/rewriteme">test</a> (200; 12.593666ms)
Oct 11 18:02:43.500: INFO: (16) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">test</... (200; 12.943743ms)
Oct 11 18:02:43.500: INFO: (16) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 12.964655ms)
Oct 11 18:02:43.501: INFO: (16) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname1/proxy/: foo (200; 14.558833ms)
Oct 11 18:02:43.502: INFO: (16) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname2/proxy/: bar (200; 15.183854ms)
Oct 11 18:02:43.502: INFO: (16) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname2/proxy/: bar (200; 14.988455ms)
Oct 11 18:02:43.504: INFO: (16) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname2/proxy/: tls qux (200; 16.605108ms)
Oct 11 18:02:43.504: INFO: (16) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname1/proxy/: tls baz (200; 17.073746ms)
Oct 11 18:02:43.511: INFO: (17) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">t... (200; 6.912249ms)
Oct 11 18:02:43.514: INFO: (17) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">test</... (200; 9.351886ms)
Oct 11 18:02:43.514: INFO: (17) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 10.30483ms)
Oct 11 18:02:43.515: INFO: (17) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 10.460049ms)
Oct 11 18:02:43.515: INFO: (17) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:462/proxy/: tls qux (200; 10.610976ms)
Oct 11 18:02:43.515: INFO: (17) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/rewriteme">test</a> (200; 10.876658ms)
Oct 11 18:02:43.515: INFO: (17) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/tlsrewriteme... (200; 11.416571ms)
Oct 11 18:02:43.516: INFO: (17) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 12.132295ms)
Oct 11 18:02:43.516: INFO: (17) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 12.126995ms)
Oct 11 18:02:43.517: INFO: (17) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:460/proxy/: tls baz (200; 12.605587ms)
Oct 11 18:02:43.519: INFO: (17) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname1/proxy/: foo (200; 14.980598ms)
Oct 11 18:02:43.521: INFO: (17) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname2/proxy/: bar (200; 17.043472ms)
Oct 11 18:02:43.521: INFO: (17) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname2/proxy/: bar (200; 17.159999ms)
Oct 11 18:02:43.522: INFO: (17) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname1/proxy/: foo (200; 17.711652ms)
Oct 11 18:02:43.522: INFO: (17) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname2/proxy/: tls qux (200; 18.055892ms)
Oct 11 18:02:43.522: INFO: (17) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname1/proxy/: tls baz (200; 17.848434ms)
Oct 11 18:02:43.533: INFO: (18) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 10.685451ms)
Oct 11 18:02:43.533: INFO: (18) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 11.014701ms)
Oct 11 18:02:43.534: INFO: (18) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">t... (200; 10.840852ms)
Oct 11 18:02:43.534: INFO: (18) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/rewriteme">test</a> (200; 10.830791ms)
Oct 11 18:02:43.534: INFO: (18) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 10.866875ms)
Oct 11 18:02:43.534: INFO: (18) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">test</... (200; 11.55194ms)
Oct 11 18:02:43.534: INFO: (18) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 11.816659ms)
Oct 11 18:02:43.534: INFO: (18) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/tlsrewriteme... (200; 11.517622ms)
Oct 11 18:02:43.534: INFO: (18) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:462/proxy/: tls qux (200; 11.383027ms)
Oct 11 18:02:43.534: INFO: (18) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:460/proxy/: tls baz (200; 11.977939ms)
Oct 11 18:02:43.536: INFO: (18) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname1/proxy/: foo (200; 13.913489ms)
Oct 11 18:02:43.538: INFO: (18) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname2/proxy/: tls qux (200; 16.001724ms)
Oct 11 18:02:43.538: INFO: (18) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname2/proxy/: bar (200; 15.975019ms)
Oct 11 18:02:43.539: INFO: (18) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname1/proxy/: foo (200; 16.078496ms)
Oct 11 18:02:43.539: INFO: (18) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname1/proxy/: tls baz (200; 16.242879ms)
Oct 11 18:02:43.539: INFO: (18) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname2/proxy/: bar (200; 16.323833ms)
Oct 11 18:02:43.550: INFO: (19) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 10.647881ms)
Oct 11 18:02:43.550: INFO: (19) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:462/proxy/: tls qux (200; 11.359253ms)
Oct 11 18:02:43.550: INFO: (19) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:443/proxy/tlsrewriteme... (200; 10.849458ms)
Oct 11 18:02:43.551: INFO: (19) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">test</... (200; 11.406507ms)
Oct 11 18:02:43.551: INFO: (19) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:1080/proxy/rewriteme">t... (200; 11.386397ms)
Oct 11 18:02:43.551: INFO: (19) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/: <a href="/api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8/proxy/rewriteme">test</a> (200; 11.292203ms)
Oct 11 18:02:43.551: INFO: (19) /api/v1/namespaces/proxy-284/pods/http:proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 11.270171ms)
Oct 11 18:02:43.551: INFO: (19) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:162/proxy/: bar (200; 11.784957ms)
Oct 11 18:02:43.551: INFO: (19) /api/v1/namespaces/proxy-284/pods/proxy-service-w4dnd-wmxz8:160/proxy/: foo (200; 11.522246ms)
Oct 11 18:02:43.551: INFO: (19) /api/v1/namespaces/proxy-284/pods/https:proxy-service-w4dnd-wmxz8:460/proxy/: tls baz (200; 11.734479ms)
Oct 11 18:02:43.552: INFO: (19) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname2/proxy/: bar (200; 13.391919ms)
Oct 11 18:02:43.555: INFO: (19) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname2/proxy/: bar (200; 15.382153ms)
Oct 11 18:02:43.555: INFO: (19) /api/v1/namespaces/proxy-284/services/http:proxy-service-w4dnd:portname1/proxy/: foo (200; 15.705251ms)
Oct 11 18:02:43.556: INFO: (19) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname1/proxy/: tls baz (200; 16.443734ms)
Oct 11 18:02:43.556: INFO: (19) /api/v1/namespaces/proxy-284/services/https:proxy-service-w4dnd:tlsportname2/proxy/: tls qux (200; 16.733296ms)
Oct 11 18:02:43.556: INFO: (19) /api/v1/namespaces/proxy-284/services/proxy-service-w4dnd:portname1/proxy/: foo (200; 16.58182ms)
STEP: deleting ReplicationController proxy-service-w4dnd in namespace proxy-284, will wait for the garbage collector to delete the pods
Oct 11 18:02:43.621: INFO: Deleting ReplicationController proxy-service-w4dnd took: 10.584172ms
Oct 11 18:02:44.021: INFO: Terminating ReplicationController proxy-service-w4dnd pods took: 400.173659ms
[AfterEach] version v1
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:02:50.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-284" for this suite.
Oct 11 18:02:56.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:02:56.910: INFO: namespace proxy-284 deletion completed in 6.175864184s

• [SLOW TEST:23.821 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:02:56.910: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-45b86741-d392-47f1-84c2-d15456dfe067
STEP: Creating a pod to test consume secrets
Oct 11 18:02:56.965: INFO: Waiting up to 5m0s for pod "pod-secrets-bf1a2586-1abe-461f-8b03-874ad912add2" in namespace "secrets-9487" to be "success or failure"
Oct 11 18:02:56.970: INFO: Pod "pod-secrets-bf1a2586-1abe-461f-8b03-874ad912add2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.045063ms
Oct 11 18:02:58.975: INFO: Pod "pod-secrets-bf1a2586-1abe-461f-8b03-874ad912add2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009742334s
Oct 11 18:03:00.980: INFO: Pod "pod-secrets-bf1a2586-1abe-461f-8b03-874ad912add2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014461337s
STEP: Saw pod success
Oct 11 18:03:00.980: INFO: Pod "pod-secrets-bf1a2586-1abe-461f-8b03-874ad912add2" satisfied condition "success or failure"
Oct 11 18:03:00.984: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod pod-secrets-bf1a2586-1abe-461f-8b03-874ad912add2 container secret-volume-test: <nil>
STEP: delete the pod
Oct 11 18:03:01.019: INFO: Waiting for pod pod-secrets-bf1a2586-1abe-461f-8b03-874ad912add2 to disappear
Oct 11 18:03:01.023: INFO: Pod pod-secrets-bf1a2586-1abe-461f-8b03-874ad912add2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:03:01.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9487" for this suite.
Oct 11 18:03:07.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:03:07.185: INFO: namespace secrets-9487 deletion completed in 6.156510711s

• [SLOW TEST:10.275 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:03:07.186: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Oct 11 18:03:09.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec pod-sharedvolume-529e3de6-64b7-4482-b683-1dcbad4deee3 -c busybox-main-container --namespace=emptydir-6976 -- cat /usr/share/volumeshare/shareddata.txt'
Oct 11 18:03:09.560: INFO: stderr: ""
Oct 11 18:03:09.560: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:03:09.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6976" for this suite.
Oct 11 18:03:15.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:03:15.720: INFO: namespace emptydir-6976 deletion completed in 6.154096592s

• [SLOW TEST:8.534 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:03:15.720: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-5212
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-5212
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5212
Oct 11 18:03:15.777: INFO: Found 0 stateful pods, waiting for 1
Oct 11 18:03:25.783: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Oct 11 18:03:25.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-5212 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 11 18:03:26.043: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 11 18:03:26.043: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 11 18:03:26.043: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 11 18:03:26.049: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 11 18:03:36.054: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 11 18:03:36.054: INFO: Waiting for statefulset status.replicas updated to 0
Oct 11 18:03:36.073: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999741s
Oct 11 18:03:37.079: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.99375082s
Oct 11 18:03:38.084: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.988265115s
Oct 11 18:03:39.089: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.982945782s
Oct 11 18:03:40.093: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.978249438s
Oct 11 18:03:41.099: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.973352675s
Oct 11 18:03:42.104: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.968351999s
Oct 11 18:03:43.109: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.963291245s
Oct 11 18:03:44.114: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.957795517s
Oct 11 18:03:45.119: INFO: Verifying statefulset ss doesn't scale past 1 for another 952.525605ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5212
Oct 11 18:03:46.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-5212 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:03:46.398: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 11 18:03:46.398: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 11 18:03:46.398: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 11 18:03:46.403: INFO: Found 1 stateful pods, waiting for 3
Oct 11 18:03:56.408: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 11 18:03:56.408: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 11 18:03:56.408: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Oct 11 18:03:56.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-5212 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 11 18:03:56.746: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 11 18:03:56.746: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 11 18:03:56.746: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 11 18:03:56.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-5212 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 11 18:03:56.992: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 11 18:03:56.992: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 11 18:03:56.992: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 11 18:03:56.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-5212 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 11 18:03:57.251: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 11 18:03:57.251: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 11 18:03:57.251: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 11 18:03:57.251: INFO: Waiting for statefulset status.replicas updated to 0
Oct 11 18:03:57.256: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Oct 11 18:04:07.265: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 11 18:04:07.265: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 11 18:04:07.265: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 11 18:04:07.279: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999816s
Oct 11 18:04:08.284: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995594569s
Oct 11 18:04:09.291: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990297697s
Oct 11 18:04:10.296: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.983056249s
Oct 11 18:04:11.301: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.978039769s
Oct 11 18:04:12.309: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.973019571s
Oct 11 18:04:13.314: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.965643021s
Oct 11 18:04:14.319: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.960255897s
Oct 11 18:04:15.324: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.955100589s
Oct 11 18:04:16.331: INFO: Verifying statefulset ss doesn't scale past 3 for another 949.985689ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5212
Oct 11 18:04:17.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-5212 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:04:17.633: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 11 18:04:17.633: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 11 18:04:17.633: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 11 18:04:17.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-5212 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:04:17.885: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 11 18:04:17.885: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 11 18:04:17.885: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 11 18:04:17.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-5212 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:04:18.135: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 11 18:04:18.135: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 11 18:04:18.135: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 11 18:04:18.135: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct 11 18:04:38.153: INFO: Deleting all statefulset in ns statefulset-5212
Oct 11 18:04:38.157: INFO: Scaling statefulset ss to 0
Oct 11 18:04:38.169: INFO: Waiting for statefulset status.replicas updated to 0
Oct 11 18:04:38.173: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:04:38.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5212" for this suite.
Oct 11 18:04:44.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:04:44.345: INFO: namespace statefulset-5212 deletion completed in 6.149521375s

• [SLOW TEST:88.625 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:04:44.346: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-d59d4640-91d6-408b-9212-198b39ac05ed
STEP: Creating a pod to test consume secrets
Oct 11 18:04:44.397: INFO: Waiting up to 5m0s for pod "pod-secrets-99d140d2-b1ee-47bf-8e3b-11d28678f38d" in namespace "secrets-915" to be "success or failure"
Oct 11 18:04:44.402: INFO: Pod "pod-secrets-99d140d2-b1ee-47bf-8e3b-11d28678f38d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.187819ms
Oct 11 18:04:46.406: INFO: Pod "pod-secrets-99d140d2-b1ee-47bf-8e3b-11d28678f38d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008781807s
STEP: Saw pod success
Oct 11 18:04:46.406: INFO: Pod "pod-secrets-99d140d2-b1ee-47bf-8e3b-11d28678f38d" satisfied condition "success or failure"
Oct 11 18:04:46.410: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod pod-secrets-99d140d2-b1ee-47bf-8e3b-11d28678f38d container secret-env-test: <nil>
STEP: delete the pod
Oct 11 18:04:46.446: INFO: Waiting for pod pod-secrets-99d140d2-b1ee-47bf-8e3b-11d28678f38d to disappear
Oct 11 18:04:46.450: INFO: Pod pod-secrets-99d140d2-b1ee-47bf-8e3b-11d28678f38d no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:04:46.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-915" for this suite.
Oct 11 18:04:52.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:04:52.603: INFO: namespace secrets-915 deletion completed in 6.146791798s

• [SLOW TEST:8.257 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:04:52.603: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 11 18:04:56.693: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 11 18:04:56.698: INFO: Pod pod-with-prestop-http-hook still exists
Oct 11 18:04:58.698: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 11 18:04:58.703: INFO: Pod pod-with-prestop-http-hook still exists
Oct 11 18:05:00.698: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 11 18:05:00.703: INFO: Pod pod-with-prestop-http-hook still exists
Oct 11 18:05:02.698: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 11 18:05:02.703: INFO: Pod pod-with-prestop-http-hook still exists
Oct 11 18:05:04.698: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 11 18:05:04.703: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:05:04.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8608" for this suite.
Oct 11 18:05:32.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:05:32.877: INFO: namespace container-lifecycle-hook-8608 deletion completed in 28.156811569s

• [SLOW TEST:40.274 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:05:32.877: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 11 18:05:33.204: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 11 18:05:35.219: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706413932, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706413932, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706413932, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706413932, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 11 18:05:38.242: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:05:38.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7763" for this suite.
Oct 11 18:05:44.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:05:44.619: INFO: namespace webhook-7763 deletion completed in 6.144458234s
STEP: Destroying namespace "webhook-7763-markers" for this suite.
Oct 11 18:05:50.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:05:50.813: INFO: namespace webhook-7763-markers deletion completed in 6.194166849s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.980 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:05:50.858: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Oct 11 18:05:50.895: INFO: namespace kubectl-9357
Oct 11 18:05:50.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 create -f - --namespace=kubectl-9357'
Oct 11 18:05:51.086: INFO: stderr: ""
Oct 11 18:05:51.086: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 11 18:05:52.091: INFO: Selector matched 1 pods for map[app:redis]
Oct 11 18:05:52.091: INFO: Found 0 / 1
Oct 11 18:05:53.091: INFO: Selector matched 1 pods for map[app:redis]
Oct 11 18:05:53.091: INFO: Found 0 / 1
Oct 11 18:05:54.091: INFO: Selector matched 1 pods for map[app:redis]
Oct 11 18:05:54.091: INFO: Found 1 / 1
Oct 11 18:05:54.091: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 11 18:05:54.096: INFO: Selector matched 1 pods for map[app:redis]
Oct 11 18:05:54.096: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 11 18:05:54.096: INFO: wait on redis-master startup in kubectl-9357 
Oct 11 18:05:54.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 logs redis-master-nk48z redis-master --namespace=kubectl-9357'
Oct 11 18:05:54.192: INFO: stderr: ""
Oct 11 18:05:54.192: INFO: stdout: "1:C 11 Oct 2019 18:05:51.861 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 11 Oct 2019 18:05:51.861 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 11 Oct 2019 18:05:51.861 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 11 Oct 2019 18:05:51.862 * Running mode=standalone, port=6379.\n1:M 11 Oct 2019 18:05:51.862 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 11 Oct 2019 18:05:51.862 # Server initialized\n1:M 11 Oct 2019 18:05:51.862 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 11 Oct 2019 18:05:51.862 * Ready to accept connections\n"
STEP: exposing RC
Oct 11 18:05:54.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-9357'
Oct 11 18:05:54.293: INFO: stderr: ""
Oct 11 18:05:54.293: INFO: stdout: "service/rm2 exposed\n"
Oct 11 18:05:54.298: INFO: Service rm2 in namespace kubectl-9357 found.
STEP: exposing service
Oct 11 18:05:56.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-9357'
Oct 11 18:05:56.433: INFO: stderr: ""
Oct 11 18:05:56.433: INFO: stdout: "service/rm3 exposed\n"
Oct 11 18:05:56.439: INFO: Service rm3 in namespace kubectl-9357 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:05:58.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9357" for this suite.
Oct 11 18:06:22.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:06:22.600: INFO: namespace kubectl-9357 deletion completed in 24.147037213s

• [SLOW TEST:31.742 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:06:22.600: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:06:26.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2089" for this suite.
Oct 11 18:07:14.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:07:14.235: INFO: namespace kubelet-test-2089 deletion completed in 48.145653022s

• [SLOW TEST:52.235 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:07:14.235: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 11 18:07:20.332: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 11 18:07:20.342: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 11 18:07:22.342: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 11 18:07:22.347: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 11 18:07:24.342: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 11 18:07:24.347: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 11 18:07:26.342: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 11 18:07:26.347: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 11 18:07:28.342: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 11 18:07:28.347: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 11 18:07:30.342: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 11 18:07:30.347: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 11 18:07:32.342: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 11 18:07:32.347: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 11 18:07:34.342: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 11 18:07:34.347: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:07:34.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5323" for this suite.
Oct 11 18:08:02.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:08:02.521: INFO: namespace container-lifecycle-hook-5323 deletion completed in 28.149770385s

• [SLOW TEST:48.286 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:08:02.521: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-68adf496-c027-436f-b8a0-8d34e832875e
STEP: Creating a pod to test consume secrets
Oct 11 18:08:02.581: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-07bf1c38-3b94-4cb3-8ef2-587e9168c785" in namespace "projected-7273" to be "success or failure"
Oct 11 18:08:02.597: INFO: Pod "pod-projected-secrets-07bf1c38-3b94-4cb3-8ef2-587e9168c785": Phase="Pending", Reason="", readiness=false. Elapsed: 16.311613ms
Oct 11 18:08:04.603: INFO: Pod "pod-projected-secrets-07bf1c38-3b94-4cb3-8ef2-587e9168c785": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021760914s
Oct 11 18:08:06.607: INFO: Pod "pod-projected-secrets-07bf1c38-3b94-4cb3-8ef2-587e9168c785": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02621221s
STEP: Saw pod success
Oct 11 18:08:06.607: INFO: Pod "pod-projected-secrets-07bf1c38-3b94-4cb3-8ef2-587e9168c785" satisfied condition "success or failure"
Oct 11 18:08:06.611: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod pod-projected-secrets-07bf1c38-3b94-4cb3-8ef2-587e9168c785 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 11 18:08:06.640: INFO: Waiting for pod pod-projected-secrets-07bf1c38-3b94-4cb3-8ef2-587e9168c785 to disappear
Oct 11 18:08:06.644: INFO: Pod pod-projected-secrets-07bf1c38-3b94-4cb3-8ef2-587e9168c785 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:08:06.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7273" for this suite.
Oct 11 18:08:12.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:08:12.987: INFO: namespace projected-7273 deletion completed in 6.338119325s

• [SLOW TEST:10.466 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:08:12.988: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:08:24.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6180" for this suite.
Oct 11 18:08:30.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:08:30.280: INFO: namespace resourcequota-6180 deletion completed in 6.157408141s

• [SLOW TEST:17.292 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:08:30.280: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-bf6ac080-a2b7-473b-af65-480eab098bcd in namespace container-probe-7781
Oct 11 18:08:32.339: INFO: Started pod liveness-bf6ac080-a2b7-473b-af65-480eab098bcd in namespace container-probe-7781
STEP: checking the pod's current state and verifying that restartCount is present
Oct 11 18:08:32.343: INFO: Initial restart count of pod liveness-bf6ac080-a2b7-473b-af65-480eab098bcd is 0
Oct 11 18:08:52.396: INFO: Restart count of pod container-probe-7781/liveness-bf6ac080-a2b7-473b-af65-480eab098bcd is now 1 (20.053129985s elapsed)
Oct 11 18:09:12.447: INFO: Restart count of pod container-probe-7781/liveness-bf6ac080-a2b7-473b-af65-480eab098bcd is now 2 (40.103625686s elapsed)
Oct 11 18:09:32.495: INFO: Restart count of pod container-probe-7781/liveness-bf6ac080-a2b7-473b-af65-480eab098bcd is now 3 (1m0.152041871s elapsed)
Oct 11 18:09:52.552: INFO: Restart count of pod container-probe-7781/liveness-bf6ac080-a2b7-473b-af65-480eab098bcd is now 4 (1m20.208455371s elapsed)
Oct 11 18:11:04.737: INFO: Restart count of pod container-probe-7781/liveness-bf6ac080-a2b7-473b-af65-480eab098bcd is now 5 (2m32.39346799s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:11:04.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7781" for this suite.
Oct 11 18:11:10.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:11:10.919: INFO: namespace container-probe-7781 deletion completed in 6.154325147s

• [SLOW TEST:160.639 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:11:10.919: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 18:11:10.954: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Creating first CR 
Oct 11 18:11:11.540: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-11T18:11:11Z generation:1 name:name1 resourceVersion:15176 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:ff5ae1e6-6fd2-4eb4-933c-2f951a2b5f72] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Oct 11 18:11:21.546: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-11T18:11:21Z generation:1 name:name2 resourceVersion:15201 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:69e530d2-1ece-4125-87fe-aa53316a1598] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Oct 11 18:11:31.553: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-11T18:11:11Z generation:2 name:name1 resourceVersion:15227 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:ff5ae1e6-6fd2-4eb4-933c-2f951a2b5f72] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Oct 11 18:11:41.559: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-11T18:11:21Z generation:2 name:name2 resourceVersion:15254 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:69e530d2-1ece-4125-87fe-aa53316a1598] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Oct 11 18:11:51.571: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-11T18:11:11Z generation:2 name:name1 resourceVersion:15279 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:ff5ae1e6-6fd2-4eb4-933c-2f951a2b5f72] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Oct 11 18:12:01.582: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-11T18:11:21Z generation:2 name:name2 resourceVersion:15306 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:69e530d2-1ece-4125-87fe-aa53316a1598] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:12:12.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-4344" for this suite.
Oct 11 18:12:18.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:12:18.255: INFO: namespace crd-watch-4344 deletion completed in 6.150235502s

• [SLOW TEST:67.336 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:12:18.255: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Oct 11 18:12:24.343: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4667 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 11 18:12:24.343: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 18:12:24.540: INFO: Exec stderr: ""
Oct 11 18:12:24.540: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4667 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 11 18:12:24.540: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 18:12:24.803: INFO: Exec stderr: ""
Oct 11 18:12:24.803: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4667 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 11 18:12:24.803: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 18:12:25.035: INFO: Exec stderr: ""
Oct 11 18:12:25.035: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4667 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 11 18:12:25.035: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 18:12:25.267: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Oct 11 18:12:25.267: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4667 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 11 18:12:25.267: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 18:12:25.473: INFO: Exec stderr: ""
Oct 11 18:12:25.474: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4667 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 11 18:12:25.474: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 18:12:25.707: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Oct 11 18:12:25.707: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4667 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 11 18:12:25.707: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 18:12:25.881: INFO: Exec stderr: ""
Oct 11 18:12:25.881: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4667 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 11 18:12:25.881: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 18:12:26.122: INFO: Exec stderr: ""
Oct 11 18:12:26.122: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4667 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 11 18:12:26.122: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 18:12:26.334: INFO: Exec stderr: ""
Oct 11 18:12:26.334: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4667 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 11 18:12:26.334: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 18:12:26.562: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:12:26.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-4667" for this suite.
Oct 11 18:13:12.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:13:12.720: INFO: namespace e2e-kubelet-etc-hosts-4667 deletion completed in 46.150482087s

• [SLOW TEST:54.465 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:13:12.720: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 11 18:13:12.773: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f0e94b7f-f61a-4519-894c-e54cf48e3a88" in namespace "downward-api-9249" to be "success or failure"
Oct 11 18:13:12.779: INFO: Pod "downwardapi-volume-f0e94b7f-f61a-4519-894c-e54cf48e3a88": Phase="Pending", Reason="", readiness=false. Elapsed: 5.809473ms
Oct 11 18:13:14.783: INFO: Pod "downwardapi-volume-f0e94b7f-f61a-4519-894c-e54cf48e3a88": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010387735s
STEP: Saw pod success
Oct 11 18:13:14.783: INFO: Pod "downwardapi-volume-f0e94b7f-f61a-4519-894c-e54cf48e3a88" satisfied condition "success or failure"
Oct 11 18:13:14.787: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod downwardapi-volume-f0e94b7f-f61a-4519-894c-e54cf48e3a88 container client-container: <nil>
STEP: delete the pod
Oct 11 18:13:14.821: INFO: Waiting for pod downwardapi-volume-f0e94b7f-f61a-4519-894c-e54cf48e3a88 to disappear
Oct 11 18:13:14.824: INFO: Pod downwardapi-volume-f0e94b7f-f61a-4519-894c-e54cf48e3a88 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:13:14.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9249" for this suite.
Oct 11 18:13:20.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:13:20.978: INFO: namespace downward-api-9249 deletion completed in 6.146547364s

• [SLOW TEST:8.258 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:13:20.978: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Oct 11 18:13:21.064: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:13:25.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6743" for this suite.
Oct 11 18:13:31.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:13:31.249: INFO: namespace init-container-6743 deletion completed in 6.152925639s

• [SLOW TEST:10.271 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:13:31.250: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Oct 11 18:13:31.285: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 11 18:13:31.300: INFO: Waiting for terminating namespaces to be deleted...
Oct 11 18:13:31.304: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-1-25.eu-west-3.compute.internal before test
Oct 11 18:13:31.320: INFO: kube-proxy-m86rm from kube-system started at 2019-10-11 17:26:31 +0000 UTC (1 container statuses recorded)
Oct 11 18:13:31.320: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 11 18:13:31.320: INFO: sonobuoy-systemd-logs-daemon-set-8223689078594c46-86r77 from sonobuoy started at 2019-10-11 17:28:08 +0000 UTC (2 container statuses recorded)
Oct 11 18:13:31.320: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 11 18:13:31.320: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 11 18:13:31.320: INFO: canal-jn9ph from kube-system started at 2019-10-11 17:26:31 +0000 UTC (2 container statuses recorded)
Oct 11 18:13:31.320: INFO: 	Container calico-node ready: true, restart count 0
Oct 11 18:13:31.320: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 11 18:13:31.320: INFO: sonobuoy-e2e-job-56f76d39d0764ff1 from sonobuoy started at 2019-10-11 17:28:08 +0000 UTC (2 container statuses recorded)
Oct 11 18:13:31.320: INFO: 	Container e2e ready: true, restart count 0
Oct 11 18:13:31.320: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 11 18:13:31.320: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-5-54.eu-west-3.compute.internal before test
Oct 11 18:13:31.335: INFO: kube-proxy-gczvl from kube-system started at 2019-10-11 17:26:30 +0000 UTC (1 container statuses recorded)
Oct 11 18:13:31.335: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 11 18:13:31.335: INFO: canal-hdnlb from kube-system started at 2019-10-11 17:26:30 +0000 UTC (2 container statuses recorded)
Oct 11 18:13:31.335: INFO: 	Container calico-node ready: true, restart count 0
Oct 11 18:13:31.335: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 11 18:13:31.335: INFO: sonobuoy from sonobuoy started at 2019-10-11 17:28:02 +0000 UTC (1 container statuses recorded)
Oct 11 18:13:31.335: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 11 18:13:31.335: INFO: sonobuoy-systemd-logs-daemon-set-8223689078594c46-wrftl from sonobuoy started at 2019-10-11 17:28:08 +0000 UTC (2 container statuses recorded)
Oct 11 18:13:31.335: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 11 18:13:31.335: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 11 18:13:31.335: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-6-233.eu-west-3.compute.internal before test
Oct 11 18:13:31.342: INFO: canal-2xwdt from kube-system started at 2019-10-11 17:24:22 +0000 UTC (2 container statuses recorded)
Oct 11 18:13:31.342: INFO: 	Container calico-node ready: true, restart count 0
Oct 11 18:13:31.342: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 11 18:13:31.342: INFO: metrics-server-59bb664678-prm7v from kube-system started at 2019-10-11 17:24:41 +0000 UTC (1 container statuses recorded)
Oct 11 18:13:31.342: INFO: 	Container metrics-server ready: true, restart count 0
Oct 11 18:13:31.342: INFO: kube-proxy-qw2gl from kube-system started at 2019-10-11 17:24:22 +0000 UTC (1 container statuses recorded)
Oct 11 18:13:31.342: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 11 18:13:31.342: INFO: sonobuoy-systemd-logs-daemon-set-8223689078594c46-lhhdq from sonobuoy started at 2019-10-11 17:28:08 +0000 UTC (2 container statuses recorded)
Oct 11 18:13:31.342: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 11 18:13:31.342: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15ccaa4b8280ea5c], Reason = [FailedScheduling], Message = [0/6 nodes are available: 6 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:13:32.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5837" for this suite.
Oct 11 18:13:38.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:13:38.528: INFO: namespace sched-pred-5837 deletion completed in 6.148432129s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:7.278 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:13:38.528: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:13:49.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4761" for this suite.
Oct 11 18:13:55.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:13:55.773: INFO: namespace resourcequota-4761 deletion completed in 6.154571368s

• [SLOW TEST:17.245 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:13:55.774: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:13:59.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4960" for this suite.
Oct 11 18:14:05.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:14:05.999: INFO: namespace kubelet-test-4960 deletion completed in 6.152156453s

• [SLOW TEST:10.225 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:14:06.000: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Oct 11 18:14:06.634: INFO: created pod pod-service-account-defaultsa
Oct 11 18:14:06.634: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Oct 11 18:14:06.642: INFO: created pod pod-service-account-mountsa
Oct 11 18:14:06.642: INFO: pod pod-service-account-mountsa service account token volume mount: true
Oct 11 18:14:06.649: INFO: created pod pod-service-account-nomountsa
Oct 11 18:14:06.649: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Oct 11 18:14:06.665: INFO: created pod pod-service-account-defaultsa-mountspec
Oct 11 18:14:06.665: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Oct 11 18:14:06.673: INFO: created pod pod-service-account-mountsa-mountspec
Oct 11 18:14:06.673: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Oct 11 18:14:06.689: INFO: created pod pod-service-account-nomountsa-mountspec
Oct 11 18:14:06.689: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Oct 11 18:14:06.702: INFO: created pod pod-service-account-defaultsa-nomountspec
Oct 11 18:14:06.702: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Oct 11 18:14:06.712: INFO: created pod pod-service-account-mountsa-nomountspec
Oct 11 18:14:06.712: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Oct 11 18:14:06.720: INFO: created pod pod-service-account-nomountsa-nomountspec
Oct 11 18:14:06.720: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:14:06.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4196" for this suite.
Oct 11 18:14:12.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:14:12.882: INFO: namespace svcaccounts-4196 deletion completed in 6.15246468s

• [SLOW TEST:6.882 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:14:12.883: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Oct 11 18:14:12.930: INFO: Waiting up to 5m0s for pod "var-expansion-c865bf9d-8d66-459d-93b6-422fbd314e76" in namespace "var-expansion-4473" to be "success or failure"
Oct 11 18:14:12.936: INFO: Pod "var-expansion-c865bf9d-8d66-459d-93b6-422fbd314e76": Phase="Pending", Reason="", readiness=false. Elapsed: 5.844291ms
Oct 11 18:14:14.941: INFO: Pod "var-expansion-c865bf9d-8d66-459d-93b6-422fbd314e76": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010771513s
Oct 11 18:14:16.946: INFO: Pod "var-expansion-c865bf9d-8d66-459d-93b6-422fbd314e76": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015604307s
STEP: Saw pod success
Oct 11 18:14:16.946: INFO: Pod "var-expansion-c865bf9d-8d66-459d-93b6-422fbd314e76" satisfied condition "success or failure"
Oct 11 18:14:16.950: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod var-expansion-c865bf9d-8d66-459d-93b6-422fbd314e76 container dapi-container: <nil>
STEP: delete the pod
Oct 11 18:14:16.977: INFO: Waiting for pod var-expansion-c865bf9d-8d66-459d-93b6-422fbd314e76 to disappear
Oct 11 18:14:16.981: INFO: Pod var-expansion-c865bf9d-8d66-459d-93b6-422fbd314e76 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:14:16.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4473" for this suite.
Oct 11 18:14:23.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:14:23.131: INFO: namespace var-expansion-4473 deletion completed in 6.144595575s

• [SLOW TEST:10.249 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:14:23.132: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 18:14:23.167: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Oct 11 18:14:26.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 --namespace=crd-publish-openapi-5809 create -f -'
Oct 11 18:14:27.031: INFO: stderr: ""
Oct 11 18:14:27.031: INFO: stdout: "e2e-test-crd-publish-openapi-2383-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Oct 11 18:14:27.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 --namespace=crd-publish-openapi-5809 delete e2e-test-crd-publish-openapi-2383-crds test-cr'
Oct 11 18:14:27.101: INFO: stderr: ""
Oct 11 18:14:27.101: INFO: stdout: "e2e-test-crd-publish-openapi-2383-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Oct 11 18:14:27.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 --namespace=crd-publish-openapi-5809 apply -f -'
Oct 11 18:14:27.258: INFO: stderr: ""
Oct 11 18:14:27.258: INFO: stdout: "e2e-test-crd-publish-openapi-2383-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Oct 11 18:14:27.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 --namespace=crd-publish-openapi-5809 delete e2e-test-crd-publish-openapi-2383-crds test-cr'
Oct 11 18:14:27.364: INFO: stderr: ""
Oct 11 18:14:27.364: INFO: stdout: "e2e-test-crd-publish-openapi-2383-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Oct 11 18:14:27.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 explain e2e-test-crd-publish-openapi-2383-crds'
Oct 11 18:14:27.596: INFO: stderr: ""
Oct 11 18:14:27.596: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2383-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:14:31.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5809" for this suite.
Oct 11 18:14:37.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:14:37.258: INFO: namespace crd-publish-openapi-5809 deletion completed in 6.144896728s

• [SLOW TEST:14.126 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:14:37.258: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Oct 11 18:14:37.306: INFO: Waiting up to 5m0s for pod "downward-api-3d0c8613-9f13-4b2f-9f85-7b7a754d920a" in namespace "downward-api-9689" to be "success or failure"
Oct 11 18:14:37.314: INFO: Pod "downward-api-3d0c8613-9f13-4b2f-9f85-7b7a754d920a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.498873ms
Oct 11 18:14:39.319: INFO: Pod "downward-api-3d0c8613-9f13-4b2f-9f85-7b7a754d920a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013422947s
Oct 11 18:14:41.324: INFO: Pod "downward-api-3d0c8613-9f13-4b2f-9f85-7b7a754d920a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018242659s
STEP: Saw pod success
Oct 11 18:14:41.324: INFO: Pod "downward-api-3d0c8613-9f13-4b2f-9f85-7b7a754d920a" satisfied condition "success or failure"
Oct 11 18:14:41.328: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod downward-api-3d0c8613-9f13-4b2f-9f85-7b7a754d920a container dapi-container: <nil>
STEP: delete the pod
Oct 11 18:14:41.354: INFO: Waiting for pod downward-api-3d0c8613-9f13-4b2f-9f85-7b7a754d920a to disappear
Oct 11 18:14:41.358: INFO: Pod downward-api-3d0c8613-9f13-4b2f-9f85-7b7a754d920a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:14:41.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9689" for this suite.
Oct 11 18:14:47.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:14:47.521: INFO: namespace downward-api-9689 deletion completed in 6.158295473s

• [SLOW TEST:10.263 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:14:47.521: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:14:49.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5619" for this suite.
Oct 11 18:15:33.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:15:33.751: INFO: namespace kubelet-test-5619 deletion completed in 44.153150369s

• [SLOW TEST:46.230 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:15:33.752: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 11 18:15:33.803: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b89458ec-ffec-4c2a-82ef-8bf40868fefa" in namespace "projected-7286" to be "success or failure"
Oct 11 18:15:33.811: INFO: Pod "downwardapi-volume-b89458ec-ffec-4c2a-82ef-8bf40868fefa": Phase="Pending", Reason="", readiness=false. Elapsed: 8.483847ms
Oct 11 18:15:35.816: INFO: Pod "downwardapi-volume-b89458ec-ffec-4c2a-82ef-8bf40868fefa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013551407s
Oct 11 18:15:37.821: INFO: Pod "downwardapi-volume-b89458ec-ffec-4c2a-82ef-8bf40868fefa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018102753s
STEP: Saw pod success
Oct 11 18:15:37.821: INFO: Pod "downwardapi-volume-b89458ec-ffec-4c2a-82ef-8bf40868fefa" satisfied condition "success or failure"
Oct 11 18:15:37.825: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod downwardapi-volume-b89458ec-ffec-4c2a-82ef-8bf40868fefa container client-container: <nil>
STEP: delete the pod
Oct 11 18:15:37.852: INFO: Waiting for pod downwardapi-volume-b89458ec-ffec-4c2a-82ef-8bf40868fefa to disappear
Oct 11 18:15:37.858: INFO: Pod downwardapi-volume-b89458ec-ffec-4c2a-82ef-8bf40868fefa no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:15:37.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7286" for this suite.
Oct 11 18:15:43.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:15:44.040: INFO: namespace projected-7286 deletion completed in 6.176096446s

• [SLOW TEST:10.288 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:15:44.040: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 11 18:15:44.088: INFO: Waiting up to 5m0s for pod "pod-8eee4c10-29c8-4833-bbf9-71def6f27cfc" in namespace "emptydir-5388" to be "success or failure"
Oct 11 18:15:44.094: INFO: Pod "pod-8eee4c10-29c8-4833-bbf9-71def6f27cfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.700752ms
Oct 11 18:15:46.099: INFO: Pod "pod-8eee4c10-29c8-4833-bbf9-71def6f27cfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010154786s
STEP: Saw pod success
Oct 11 18:15:46.099: INFO: Pod "pod-8eee4c10-29c8-4833-bbf9-71def6f27cfc" satisfied condition "success or failure"
Oct 11 18:15:46.103: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod pod-8eee4c10-29c8-4833-bbf9-71def6f27cfc container test-container: <nil>
STEP: delete the pod
Oct 11 18:15:46.129: INFO: Waiting for pod pod-8eee4c10-29c8-4833-bbf9-71def6f27cfc to disappear
Oct 11 18:15:46.132: INFO: Pod pod-8eee4c10-29c8-4833-bbf9-71def6f27cfc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:15:46.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5388" for this suite.
Oct 11 18:15:52.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:15:52.286: INFO: namespace emptydir-5388 deletion completed in 6.148574257s

• [SLOW TEST:8.246 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:15:52.287: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Oct 11 18:15:52.333: INFO: Waiting up to 5m0s for pod "var-expansion-78b2dd9d-54b3-43dd-97fd-890f1232c317" in namespace "var-expansion-1965" to be "success or failure"
Oct 11 18:15:52.339: INFO: Pod "var-expansion-78b2dd9d-54b3-43dd-97fd-890f1232c317": Phase="Pending", Reason="", readiness=false. Elapsed: 5.642146ms
Oct 11 18:15:54.343: INFO: Pod "var-expansion-78b2dd9d-54b3-43dd-97fd-890f1232c317": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01036768s
Oct 11 18:15:56.349: INFO: Pod "var-expansion-78b2dd9d-54b3-43dd-97fd-890f1232c317": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015696103s
STEP: Saw pod success
Oct 11 18:15:56.349: INFO: Pod "var-expansion-78b2dd9d-54b3-43dd-97fd-890f1232c317" satisfied condition "success or failure"
Oct 11 18:15:56.353: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod var-expansion-78b2dd9d-54b3-43dd-97fd-890f1232c317 container dapi-container: <nil>
STEP: delete the pod
Oct 11 18:15:56.391: INFO: Waiting for pod var-expansion-78b2dd9d-54b3-43dd-97fd-890f1232c317 to disappear
Oct 11 18:15:56.396: INFO: Pod var-expansion-78b2dd9d-54b3-43dd-97fd-890f1232c317 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:15:56.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1965" for this suite.
Oct 11 18:16:02.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:16:02.552: INFO: namespace var-expansion-1965 deletion completed in 6.151603137s

• [SLOW TEST:10.267 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:16:02.554: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5002.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-5002.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5002.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-5002.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5002.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5002.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-5002.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5002.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-5002.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5002.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 11 18:16:08.647: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:08.653: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:08.658: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:08.663: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:08.679: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:08.684: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:08.689: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:08.695: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:08.706: INFO: Lookups using dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5002.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5002.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local jessie_udp@dns-test-service-2.dns-5002.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5002.svc.cluster.local]

Oct 11 18:16:13.713: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:13.718: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:13.723: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:13.728: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:13.743: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:13.748: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:13.753: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:13.758: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:13.775: INFO: Lookups using dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5002.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5002.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local jessie_udp@dns-test-service-2.dns-5002.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5002.svc.cluster.local]

Oct 11 18:16:18.720: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:18.729: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:18.758: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:18.768: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:18.801: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:18.806: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:18.811: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:18.816: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:18.826: INFO: Lookups using dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5002.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5002.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local jessie_udp@dns-test-service-2.dns-5002.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5002.svc.cluster.local]

Oct 11 18:16:23.713: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:23.718: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:23.723: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:23.730: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:23.745: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:23.750: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:23.755: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:23.760: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:23.770: INFO: Lookups using dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5002.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5002.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local jessie_udp@dns-test-service-2.dns-5002.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5002.svc.cluster.local]

Oct 11 18:16:28.713: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:28.718: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:28.723: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:28.728: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:28.743: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:28.750: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:28.757: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:28.763: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:28.775: INFO: Lookups using dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5002.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5002.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local jessie_udp@dns-test-service-2.dns-5002.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5002.svc.cluster.local]

Oct 11 18:16:33.713: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:33.718: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:33.723: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:33.729: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:33.744: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:33.749: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:33.754: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:33.759: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5002.svc.cluster.local from pod dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de: the server could not find the requested resource (get pods dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de)
Oct 11 18:16:33.773: INFO: Lookups using dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5002.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5002.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5002.svc.cluster.local jessie_udp@dns-test-service-2.dns-5002.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5002.svc.cluster.local]

Oct 11 18:16:38.777: INFO: DNS probes using dns-5002/dns-test-583219f8-cf1e-437a-9f89-3097ff9ad0de succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:16:38.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5002" for this suite.
Oct 11 18:16:44.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:16:44.987: INFO: namespace dns-5002 deletion completed in 6.148751913s

• [SLOW TEST:42.434 seconds]
[sig-network] DNS
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:16:44.988: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Oct 11 18:16:45.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 create -f - --namespace=kubectl-2611'
Oct 11 18:16:45.259: INFO: stderr: ""
Oct 11 18:16:45.259: INFO: stdout: "pod/pause created\n"
Oct 11 18:16:45.259: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Oct 11 18:16:45.259: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-2611" to be "running and ready"
Oct 11 18:16:45.265: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.803726ms
Oct 11 18:16:47.271: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.012047083s
Oct 11 18:16:47.271: INFO: Pod "pause" satisfied condition "running and ready"
Oct 11 18:16:47.271: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Oct 11 18:16:47.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 label pods pause testing-label=testing-label-value --namespace=kubectl-2611'
Oct 11 18:16:47.366: INFO: stderr: ""
Oct 11 18:16:47.366: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Oct 11 18:16:47.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pod pause -L testing-label --namespace=kubectl-2611'
Oct 11 18:16:47.447: INFO: stderr: ""
Oct 11 18:16:47.447: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Oct 11 18:16:47.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 label pods pause testing-label- --namespace=kubectl-2611'
Oct 11 18:16:47.539: INFO: stderr: ""
Oct 11 18:16:47.539: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Oct 11 18:16:47.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pod pause -L testing-label --namespace=kubectl-2611'
Oct 11 18:16:47.606: INFO: stderr: ""
Oct 11 18:16:47.606: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Oct 11 18:16:47.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 delete --grace-period=0 --force -f - --namespace=kubectl-2611'
Oct 11 18:16:47.681: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 11 18:16:47.681: INFO: stdout: "pod \"pause\" force deleted\n"
Oct 11 18:16:47.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get rc,svc -l name=pause --no-headers --namespace=kubectl-2611'
Oct 11 18:16:47.783: INFO: stderr: "No resources found in kubectl-2611 namespace.\n"
Oct 11 18:16:47.783: INFO: stdout: ""
Oct 11 18:16:47.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods -l name=pause --namespace=kubectl-2611 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 11 18:16:47.852: INFO: stderr: ""
Oct 11 18:16:47.852: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:16:47.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2611" for this suite.
Oct 11 18:16:53.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:16:54.020: INFO: namespace kubectl-2611 deletion completed in 6.158384018s

• [SLOW TEST:9.032 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:16:54.020: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-11e26aec-7c95-4d5c-80c0-a269ebc8d2ff
STEP: Creating a pod to test consume configMaps
Oct 11 18:16:54.126: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c005d290-aac4-4dae-81da-5504b570e510" in namespace "projected-5171" to be "success or failure"
Oct 11 18:16:54.141: INFO: Pod "pod-projected-configmaps-c005d290-aac4-4dae-81da-5504b570e510": Phase="Pending", Reason="", readiness=false. Elapsed: 14.772427ms
Oct 11 18:16:56.146: INFO: Pod "pod-projected-configmaps-c005d290-aac4-4dae-81da-5504b570e510": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019893629s
Oct 11 18:16:58.151: INFO: Pod "pod-projected-configmaps-c005d290-aac4-4dae-81da-5504b570e510": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024975622s
STEP: Saw pod success
Oct 11 18:16:58.151: INFO: Pod "pod-projected-configmaps-c005d290-aac4-4dae-81da-5504b570e510" satisfied condition "success or failure"
Oct 11 18:16:58.155: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod pod-projected-configmaps-c005d290-aac4-4dae-81da-5504b570e510 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 11 18:16:58.182: INFO: Waiting for pod pod-projected-configmaps-c005d290-aac4-4dae-81da-5504b570e510 to disappear
Oct 11 18:16:58.186: INFO: Pod pod-projected-configmaps-c005d290-aac4-4dae-81da-5504b570e510 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:16:58.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5171" for this suite.
Oct 11 18:17:04.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:17:04.357: INFO: namespace projected-5171 deletion completed in 6.165544125s

• [SLOW TEST:10.337 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:17:04.357: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Oct 11 18:17:04.432: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8074 /api/v1/namespaces/watch-8074/configmaps/e2e-watch-test-resource-version 8273b410-28c3-4650-a9d2-f81923758638 16645 0 2019-10-11 18:17:04 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 11 18:17:04.432: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8074 /api/v1/namespaces/watch-8074/configmaps/e2e-watch-test-resource-version 8273b410-28c3-4650-a9d2-f81923758638 16646 0 2019-10-11 18:17:04 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:17:04.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8074" for this suite.
Oct 11 18:17:10.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:17:10.624: INFO: namespace watch-8074 deletion completed in 6.186845504s

• [SLOW TEST:6.267 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:17:10.624: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Oct 11 18:17:10.673: INFO: Pod name pod-release: Found 0 pods out of 1
Oct 11 18:17:15.679: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:17:16.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9500" for this suite.
Oct 11 18:17:22.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:17:22.866: INFO: namespace replication-controller-9500 deletion completed in 6.161601678s

• [SLOW TEST:12.241 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:17:22.866: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-1848/configmap-test-515c11bf-bd97-485f-8636-5b51b5113e4b
STEP: Creating a pod to test consume configMaps
Oct 11 18:17:22.919: INFO: Waiting up to 5m0s for pod "pod-configmaps-7b9baf4e-a4f4-42eb-85fd-121965d31cd8" in namespace "configmap-1848" to be "success or failure"
Oct 11 18:17:22.926: INFO: Pod "pod-configmaps-7b9baf4e-a4f4-42eb-85fd-121965d31cd8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.232307ms
Oct 11 18:17:24.931: INFO: Pod "pod-configmaps-7b9baf4e-a4f4-42eb-85fd-121965d31cd8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011712657s
STEP: Saw pod success
Oct 11 18:17:24.931: INFO: Pod "pod-configmaps-7b9baf4e-a4f4-42eb-85fd-121965d31cd8" satisfied condition "success or failure"
Oct 11 18:17:24.935: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-configmaps-7b9baf4e-a4f4-42eb-85fd-121965d31cd8 container env-test: <nil>
STEP: delete the pod
Oct 11 18:17:24.964: INFO: Waiting for pod pod-configmaps-7b9baf4e-a4f4-42eb-85fd-121965d31cd8 to disappear
Oct 11 18:17:24.969: INFO: Pod pod-configmaps-7b9baf4e-a4f4-42eb-85fd-121965d31cd8 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:17:24.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1848" for this suite.
Oct 11 18:17:30.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:17:31.136: INFO: namespace configmap-1848 deletion completed in 6.161631929s

• [SLOW TEST:8.270 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:17:31.139: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:17:47.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9769" for this suite.
Oct 11 18:17:53.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:17:53.438: INFO: namespace resourcequota-9769 deletion completed in 6.148123852s

• [SLOW TEST:22.300 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:17:53.439: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 11 18:17:53.904: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 11 18:17:55.917: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706414673, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706414673, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706414673, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706414673, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 11 18:17:58.939: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 18:17:58.944: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6991-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:17:59.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7934" for this suite.
Oct 11 18:18:05.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:18:05.853: INFO: namespace webhook-7934 deletion completed in 6.150035757s
STEP: Destroying namespace "webhook-7934-markers" for this suite.
Oct 11 18:18:11.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:18:11.998: INFO: namespace webhook-7934-markers deletion completed in 6.144306856s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.580 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:18:12.018: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct 11 18:18:12.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-8592'
Oct 11 18:18:12.218: INFO: stderr: ""
Oct 11 18:18:12.218: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Oct 11 18:18:17.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pod e2e-test-httpd-pod --namespace=kubectl-8592 -o json'
Oct 11 18:18:17.347: INFO: stderr: ""
Oct 11 18:18:17.347: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.244.4.72/32\"\n        },\n        \"creationTimestamp\": \"2019-10-11T18:18:12Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-8592\",\n        \"resourceVersion\": \"17046\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-8592/pods/e2e-test-httpd-pod\",\n        \"uid\": \"1a179f89-384f-4696-86e5-57b9e017caf3\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-vrf4t\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-5-54.eu-west-3.compute.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-vrf4t\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-vrf4t\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-11T18:18:12Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-11T18:18:14Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-11T18:18:14Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-11T18:18:12Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://c80867acd13fd00644cf11efef4514fccad7dd63fa0fb8a92d239b38302c86d6\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-10-11T18:18:13Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.5.54\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.4.72\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.244.4.72\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-10-11T18:18:12Z\"\n    }\n}\n"
STEP: replace the image in the pod
Oct 11 18:18:17.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 replace -f - --namespace=kubectl-8592'
Oct 11 18:18:17.538: INFO: stderr: ""
Oct 11 18:18:17.538: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Oct 11 18:18:17.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 delete pods e2e-test-httpd-pod --namespace=kubectl-8592'
Oct 11 18:18:30.262: INFO: stderr: ""
Oct 11 18:18:30.262: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:18:30.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8592" for this suite.
Oct 11 18:18:36.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:18:36.466: INFO: namespace kubectl-8592 deletion completed in 6.193697152s

• [SLOW TEST:24.447 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:18:36.466: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 11 18:18:36.518: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c7001df5-2469-46d2-8fbc-ad66b63e5cb8" in namespace "projected-9200" to be "success or failure"
Oct 11 18:18:36.525: INFO: Pod "downwardapi-volume-c7001df5-2469-46d2-8fbc-ad66b63e5cb8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.47514ms
Oct 11 18:18:38.531: INFO: Pod "downwardapi-volume-c7001df5-2469-46d2-8fbc-ad66b63e5cb8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013874672s
STEP: Saw pod success
Oct 11 18:18:38.531: INFO: Pod "downwardapi-volume-c7001df5-2469-46d2-8fbc-ad66b63e5cb8" satisfied condition "success or failure"
Oct 11 18:18:38.536: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod downwardapi-volume-c7001df5-2469-46d2-8fbc-ad66b63e5cb8 container client-container: <nil>
STEP: delete the pod
Oct 11 18:18:38.567: INFO: Waiting for pod downwardapi-volume-c7001df5-2469-46d2-8fbc-ad66b63e5cb8 to disappear
Oct 11 18:18:38.571: INFO: Pod downwardapi-volume-c7001df5-2469-46d2-8fbc-ad66b63e5cb8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:18:38.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9200" for this suite.
Oct 11 18:18:44.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:18:44.736: INFO: namespace projected-9200 deletion completed in 6.158938154s

• [SLOW TEST:8.269 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:18:44.736: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-3789
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-3789
STEP: creating replication controller externalsvc in namespace services-3789
I1011 18:18:44.825915      19 runners.go:184] Created replication controller with name: externalsvc, namespace: services-3789, replica count: 2
I1011 18:18:47.876251      19 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Oct 11 18:18:47.912: INFO: Creating new exec pod
Oct 11 18:18:49.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=services-3789 execpodlr977 -- /bin/sh -x -c nslookup nodeport-service'
Oct 11 18:18:50.194: INFO: stderr: "+ nslookup nodeport-service\n"
Oct 11 18:18:50.195: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-3789.svc.cluster.local\tcanonical name = externalsvc.services-3789.svc.cluster.local.\nName:\texternalsvc.services-3789.svc.cluster.local\nAddress: 10.105.13.180\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-3789, will wait for the garbage collector to delete the pods
Oct 11 18:18:50.261: INFO: Deleting ReplicationController externalsvc took: 11.187936ms
Oct 11 18:18:50.661: INFO: Terminating ReplicationController externalsvc pods took: 400.181377ms
Oct 11 18:18:55.097: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:18:55.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3789" for this suite.
Oct 11 18:19:01.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:19:01.286: INFO: namespace services-3789 deletion completed in 6.160473004s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:16.549 seconds]
[sig-network] Services
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:19:01.286: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-881.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-881.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-881.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-881.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-881.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-881.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 11 18:19:05.400: INFO: DNS probes using dns-881/dns-test-a18a870e-9d4f-4301-b21f-f7dae80fc695 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:19:05.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-881" for this suite.
Oct 11 18:19:11.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:19:11.605: INFO: namespace dns-881 deletion completed in 6.152826394s

• [SLOW TEST:10.319 seconds]
[sig-network] DNS
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:19:11.605: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 18:19:11.641: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:19:15.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6742" for this suite.
Oct 11 18:20:01.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:20:01.908: INFO: namespace pods-6742 deletion completed in 46.210410366s

• [SLOW TEST:50.303 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:20:01.909: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-7f7dd7fb-096d-453b-bdc1-f023ff32b076
STEP: Creating a pod to test consume configMaps
Oct 11 18:20:01.972: INFO: Waiting up to 5m0s for pod "pod-configmaps-8922af93-8e98-4758-89fd-934591f80262" in namespace "configmap-3123" to be "success or failure"
Oct 11 18:20:01.977: INFO: Pod "pod-configmaps-8922af93-8e98-4758-89fd-934591f80262": Phase="Pending", Reason="", readiness=false. Elapsed: 4.966025ms
Oct 11 18:20:03.982: INFO: Pod "pod-configmaps-8922af93-8e98-4758-89fd-934591f80262": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009317432s
STEP: Saw pod success
Oct 11 18:20:03.982: INFO: Pod "pod-configmaps-8922af93-8e98-4758-89fd-934591f80262" satisfied condition "success or failure"
Oct 11 18:20:03.986: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-configmaps-8922af93-8e98-4758-89fd-934591f80262 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 11 18:20:04.011: INFO: Waiting for pod pod-configmaps-8922af93-8e98-4758-89fd-934591f80262 to disappear
Oct 11 18:20:04.014: INFO: Pod pod-configmaps-8922af93-8e98-4758-89fd-934591f80262 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:20:04.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3123" for this suite.
Oct 11 18:20:10.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:20:10.213: INFO: namespace configmap-3123 deletion completed in 6.193106525s

• [SLOW TEST:8.304 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:20:10.214: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Oct 11 18:20:10.262: INFO: Waiting up to 5m0s for pod "pod-8359885a-f883-4f5d-a33a-7bdfbd4c166f" in namespace "emptydir-3924" to be "success or failure"
Oct 11 18:20:10.267: INFO: Pod "pod-8359885a-f883-4f5d-a33a-7bdfbd4c166f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.050416ms
Oct 11 18:20:12.273: INFO: Pod "pod-8359885a-f883-4f5d-a33a-7bdfbd4c166f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010422412s
Oct 11 18:20:14.278: INFO: Pod "pod-8359885a-f883-4f5d-a33a-7bdfbd4c166f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015450427s
STEP: Saw pod success
Oct 11 18:20:14.278: INFO: Pod "pod-8359885a-f883-4f5d-a33a-7bdfbd4c166f" satisfied condition "success or failure"
Oct 11 18:20:14.282: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-8359885a-f883-4f5d-a33a-7bdfbd4c166f container test-container: <nil>
STEP: delete the pod
Oct 11 18:20:14.334: INFO: Waiting for pod pod-8359885a-f883-4f5d-a33a-7bdfbd4c166f to disappear
Oct 11 18:20:14.344: INFO: Pod pod-8359885a-f883-4f5d-a33a-7bdfbd4c166f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:20:14.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3924" for this suite.
Oct 11 18:20:20.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:20:20.506: INFO: namespace emptydir-3924 deletion completed in 6.150314096s

• [SLOW TEST:10.293 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:20:20.507: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Oct 11 18:20:20.542: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:20:38.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2192" for this suite.
Oct 11 18:20:44.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:20:44.273: INFO: namespace crd-publish-openapi-2192 deletion completed in 6.153644615s

• [SLOW TEST:23.766 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:20:44.273: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-82kg
STEP: Creating a pod to test atomic-volume-subpath
Oct 11 18:20:44.331: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-82kg" in namespace "subpath-1305" to be "success or failure"
Oct 11 18:20:44.337: INFO: Pod "pod-subpath-test-configmap-82kg": Phase="Pending", Reason="", readiness=false. Elapsed: 6.708049ms
Oct 11 18:20:46.342: INFO: Pod "pod-subpath-test-configmap-82kg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011661001s
Oct 11 18:20:48.347: INFO: Pod "pod-subpath-test-configmap-82kg": Phase="Running", Reason="", readiness=true. Elapsed: 4.016471649s
Oct 11 18:20:50.352: INFO: Pod "pod-subpath-test-configmap-82kg": Phase="Running", Reason="", readiness=true. Elapsed: 6.021335084s
Oct 11 18:20:52.357: INFO: Pod "pod-subpath-test-configmap-82kg": Phase="Running", Reason="", readiness=true. Elapsed: 8.026169165s
Oct 11 18:20:54.362: INFO: Pod "pod-subpath-test-configmap-82kg": Phase="Running", Reason="", readiness=true. Elapsed: 10.031043433s
Oct 11 18:20:56.368: INFO: Pod "pod-subpath-test-configmap-82kg": Phase="Running", Reason="", readiness=true. Elapsed: 12.036931809s
Oct 11 18:20:58.373: INFO: Pod "pod-subpath-test-configmap-82kg": Phase="Running", Reason="", readiness=true. Elapsed: 14.041946655s
Oct 11 18:21:00.378: INFO: Pod "pod-subpath-test-configmap-82kg": Phase="Running", Reason="", readiness=true. Elapsed: 16.046993107s
Oct 11 18:21:02.383: INFO: Pod "pod-subpath-test-configmap-82kg": Phase="Running", Reason="", readiness=true. Elapsed: 18.051742453s
Oct 11 18:21:04.388: INFO: Pod "pod-subpath-test-configmap-82kg": Phase="Running", Reason="", readiness=true. Elapsed: 20.056874117s
Oct 11 18:21:06.392: INFO: Pod "pod-subpath-test-configmap-82kg": Phase="Running", Reason="", readiness=true. Elapsed: 22.061317697s
Oct 11 18:21:08.397: INFO: Pod "pod-subpath-test-configmap-82kg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.066413316s
STEP: Saw pod success
Oct 11 18:21:08.397: INFO: Pod "pod-subpath-test-configmap-82kg" satisfied condition "success or failure"
Oct 11 18:21:08.402: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-subpath-test-configmap-82kg container test-container-subpath-configmap-82kg: <nil>
STEP: delete the pod
Oct 11 18:21:08.428: INFO: Waiting for pod pod-subpath-test-configmap-82kg to disappear
Oct 11 18:21:08.433: INFO: Pod pod-subpath-test-configmap-82kg no longer exists
STEP: Deleting pod pod-subpath-test-configmap-82kg
Oct 11 18:21:08.433: INFO: Deleting pod "pod-subpath-test-configmap-82kg" in namespace "subpath-1305"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:21:08.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1305" for this suite.
Oct 11 18:21:14.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:21:14.597: INFO: namespace subpath-1305 deletion completed in 6.15378867s

• [SLOW TEST:30.323 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:21:14.597: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-3194442e-3297-4534-a1ea-d05dab346243
STEP: Creating a pod to test consume configMaps
Oct 11 18:21:14.661: INFO: Waiting up to 5m0s for pod "pod-configmaps-e5f0ff00-6e7a-4ce4-b0a4-426e1b64308a" in namespace "configmap-6283" to be "success or failure"
Oct 11 18:21:14.669: INFO: Pod "pod-configmaps-e5f0ff00-6e7a-4ce4-b0a4-426e1b64308a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.672014ms
Oct 11 18:21:16.674: INFO: Pod "pod-configmaps-e5f0ff00-6e7a-4ce4-b0a4-426e1b64308a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012440581s
Oct 11 18:21:18.679: INFO: Pod "pod-configmaps-e5f0ff00-6e7a-4ce4-b0a4-426e1b64308a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017634262s
STEP: Saw pod success
Oct 11 18:21:18.679: INFO: Pod "pod-configmaps-e5f0ff00-6e7a-4ce4-b0a4-426e1b64308a" satisfied condition "success or failure"
Oct 11 18:21:18.683: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod pod-configmaps-e5f0ff00-6e7a-4ce4-b0a4-426e1b64308a container configmap-volume-test: <nil>
STEP: delete the pod
Oct 11 18:21:18.716: INFO: Waiting for pod pod-configmaps-e5f0ff00-6e7a-4ce4-b0a4-426e1b64308a to disappear
Oct 11 18:21:18.720: INFO: Pod pod-configmaps-e5f0ff00-6e7a-4ce4-b0a4-426e1b64308a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:21:18.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6283" for this suite.
Oct 11 18:21:24.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:21:24.878: INFO: namespace configmap-6283 deletion completed in 6.151566841s

• [SLOW TEST:10.281 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:21:24.878: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-hx9v
STEP: Creating a pod to test atomic-volume-subpath
Oct 11 18:21:24.939: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-hx9v" in namespace "subpath-8975" to be "success or failure"
Oct 11 18:21:24.945: INFO: Pod "pod-subpath-test-downwardapi-hx9v": Phase="Pending", Reason="", readiness=false. Elapsed: 5.203534ms
Oct 11 18:21:26.949: INFO: Pod "pod-subpath-test-downwardapi-hx9v": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009918001s
Oct 11 18:21:28.954: INFO: Pod "pod-subpath-test-downwardapi-hx9v": Phase="Running", Reason="", readiness=true. Elapsed: 4.01461721s
Oct 11 18:21:30.959: INFO: Pod "pod-subpath-test-downwardapi-hx9v": Phase="Running", Reason="", readiness=true. Elapsed: 6.019620613s
Oct 11 18:21:32.964: INFO: Pod "pod-subpath-test-downwardapi-hx9v": Phase="Running", Reason="", readiness=true. Elapsed: 8.024366252s
Oct 11 18:21:34.969: INFO: Pod "pod-subpath-test-downwardapi-hx9v": Phase="Running", Reason="", readiness=true. Elapsed: 10.029754428s
Oct 11 18:21:36.974: INFO: Pod "pod-subpath-test-downwardapi-hx9v": Phase="Running", Reason="", readiness=true. Elapsed: 12.034571027s
Oct 11 18:21:38.982: INFO: Pod "pod-subpath-test-downwardapi-hx9v": Phase="Running", Reason="", readiness=true. Elapsed: 14.042966717s
Oct 11 18:21:40.987: INFO: Pod "pod-subpath-test-downwardapi-hx9v": Phase="Running", Reason="", readiness=true. Elapsed: 16.04789091s
Oct 11 18:21:42.992: INFO: Pod "pod-subpath-test-downwardapi-hx9v": Phase="Running", Reason="", readiness=true. Elapsed: 18.052834599s
Oct 11 18:21:44.997: INFO: Pod "pod-subpath-test-downwardapi-hx9v": Phase="Running", Reason="", readiness=true. Elapsed: 20.057686453s
Oct 11 18:21:47.002: INFO: Pod "pod-subpath-test-downwardapi-hx9v": Phase="Running", Reason="", readiness=true. Elapsed: 22.062521418s
Oct 11 18:21:49.007: INFO: Pod "pod-subpath-test-downwardapi-hx9v": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.067283695s
STEP: Saw pod success
Oct 11 18:21:49.007: INFO: Pod "pod-subpath-test-downwardapi-hx9v" satisfied condition "success or failure"
Oct 11 18:21:49.011: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-subpath-test-downwardapi-hx9v container test-container-subpath-downwardapi-hx9v: <nil>
STEP: delete the pod
Oct 11 18:21:49.039: INFO: Waiting for pod pod-subpath-test-downwardapi-hx9v to disappear
Oct 11 18:21:49.044: INFO: Pod pod-subpath-test-downwardapi-hx9v no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-hx9v
Oct 11 18:21:49.045: INFO: Deleting pod "pod-subpath-test-downwardapi-hx9v" in namespace "subpath-8975"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:21:49.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8975" for this suite.
Oct 11 18:21:55.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:21:55.204: INFO: namespace subpath-8975 deletion completed in 6.150928211s

• [SLOW TEST:30.326 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:21:55.205: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 11 18:21:55.883: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 11 18:21:57.896: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706414915, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706414915, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706414915, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706414915, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 11 18:22:00.918: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 18:22:00.923: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:22:02.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1569" for this suite.
Oct 11 18:22:08.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:22:08.279: INFO: namespace webhook-1569 deletion completed in 6.159165367s
STEP: Destroying namespace "webhook-1569-markers" for this suite.
Oct 11 18:22:14.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:22:14.440: INFO: namespace webhook-1569-markers deletion completed in 6.160717103s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.256 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:22:14.461: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Oct 11 18:22:14.498: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Oct 11 18:22:14.831: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Oct 11 18:22:16.885: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706414934, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706414934, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706414934, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706414934, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 11 18:22:18.891: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706414934, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706414934, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706414934, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706414934, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 11 18:22:20.890: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706414934, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706414934, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706414934, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706414934, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 11 18:22:24.027: INFO: Waited 1.123592658s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:22:24.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-5356" for this suite.
Oct 11 18:22:30.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:22:30.907: INFO: namespace aggregator-5356 deletion completed in 6.209015695s

• [SLOW TEST:16.446 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:22:30.907: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Oct 11 18:22:31.513: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1011 18:22:31.513469      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:22:31.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1836" for this suite.
Oct 11 18:22:37.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:22:37.670: INFO: namespace gc-1836 deletion completed in 6.151550387s

• [SLOW TEST:6.763 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:22:37.670: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-1678
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-1678
I1011 18:22:37.757187      19 runners.go:184] Created replication controller with name: externalname-service, namespace: services-1678, replica count: 2
I1011 18:22:40.807836      19 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 11 18:22:40.807: INFO: Creating new exec pod
Oct 11 18:22:43.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=services-1678 execpodfvg79 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Oct 11 18:22:44.104: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Oct 11 18:22:44.104: INFO: stdout: ""
Oct 11 18:22:44.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=services-1678 execpodfvg79 -- /bin/sh -x -c nc -zv -t -w 2 10.97.50.141 80'
Oct 11 18:22:44.391: INFO: stderr: "+ nc -zv -t -w 2 10.97.50.141 80\nConnection to 10.97.50.141 80 port [tcp/http] succeeded!\n"
Oct 11 18:22:44.391: INFO: stdout: ""
Oct 11 18:22:44.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=services-1678 execpodfvg79 -- /bin/sh -x -c nc -zv -t -w 2 172.31.1.25 31231'
Oct 11 18:22:44.639: INFO: stderr: "+ nc -zv -t -w 2 172.31.1.25 31231\nConnection to 172.31.1.25 31231 port [tcp/31231] succeeded!\n"
Oct 11 18:22:44.639: INFO: stdout: ""
Oct 11 18:22:44.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=services-1678 execpodfvg79 -- /bin/sh -x -c nc -zv -t -w 2 172.31.5.54 31231'
Oct 11 18:22:44.888: INFO: stderr: "+ nc -zv -t -w 2 172.31.5.54 31231\nConnection to 172.31.5.54 31231 port [tcp/31231] succeeded!\n"
Oct 11 18:22:44.888: INFO: stdout: ""
Oct 11 18:22:44.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=services-1678 execpodfvg79 -- /bin/sh -x -c nc -zv -t -w 2 35.180.123.192 31231'
Oct 11 18:22:45.146: INFO: stderr: "+ nc -zv -t -w 2 35.180.123.192 31231\nConnection to 35.180.123.192 31231 port [tcp/31231] succeeded!\n"
Oct 11 18:22:45.146: INFO: stdout: ""
Oct 11 18:22:45.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=services-1678 execpodfvg79 -- /bin/sh -x -c nc -zv -t -w 2 35.180.210.201 31231'
Oct 11 18:22:45.408: INFO: stderr: "+ nc -zv -t -w 2 35.180.210.201 31231\nConnection to 35.180.210.201 31231 port [tcp/31231] succeeded!\n"
Oct 11 18:22:45.409: INFO: stdout: ""
Oct 11 18:22:45.409: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:22:45.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1678" for this suite.
Oct 11 18:22:51.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:22:51.617: INFO: namespace services-1678 deletion completed in 6.154231501s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.947 seconds]
[sig-network] Services
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:22:51.617: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 18:22:51.695: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"a2fc2376-50c4-40e7-a5ea-8f06f4198f26", Controller:(*bool)(0xc007f6caca), BlockOwnerDeletion:(*bool)(0xc007f6cacb)}}
Oct 11 18:22:51.704: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"ccc6919f-edb5-44e7-9f6f-5e2fe17fc9ad", Controller:(*bool)(0xc007f6ccda), BlockOwnerDeletion:(*bool)(0xc007f6ccdb)}}
Oct 11 18:22:51.711: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b6c5961d-40c2-4200-b015-32d8412df6c8", Controller:(*bool)(0xc00772b1b6), BlockOwnerDeletion:(*bool)(0xc00772b1b7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:22:56.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9028" for this suite.
Oct 11 18:23:02.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:23:02.887: INFO: namespace gc-9028 deletion completed in 6.154028037s

• [SLOW TEST:11.270 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:23:02.888: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Oct 11 18:23:07.453: INFO: Successfully updated pod "adopt-release-92895"
STEP: Checking that the Job readopts the Pod
Oct 11 18:23:07.453: INFO: Waiting up to 15m0s for pod "adopt-release-92895" in namespace "job-5014" to be "adopted"
Oct 11 18:23:07.458: INFO: Pod "adopt-release-92895": Phase="Running", Reason="", readiness=true. Elapsed: 4.725916ms
Oct 11 18:23:09.463: INFO: Pod "adopt-release-92895": Phase="Running", Reason="", readiness=true. Elapsed: 2.009419839s
Oct 11 18:23:09.463: INFO: Pod "adopt-release-92895" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Oct 11 18:23:09.979: INFO: Successfully updated pod "adopt-release-92895"
STEP: Checking that the Job releases the Pod
Oct 11 18:23:09.979: INFO: Waiting up to 15m0s for pod "adopt-release-92895" in namespace "job-5014" to be "released"
Oct 11 18:23:09.983: INFO: Pod "adopt-release-92895": Phase="Running", Reason="", readiness=true. Elapsed: 4.015546ms
Oct 11 18:23:11.989: INFO: Pod "adopt-release-92895": Phase="Running", Reason="", readiness=true. Elapsed: 2.009730748s
Oct 11 18:23:11.989: INFO: Pod "adopt-release-92895" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:23:11.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5014" for this suite.
Oct 11 18:24:04.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:24:04.148: INFO: namespace job-5014 deletion completed in 52.153203337s

• [SLOW TEST:61.260 seconds]
[sig-apps] Job
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:24:04.148: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 18:24:04.202: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Oct 11 18:24:09.207: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 11 18:24:09.207: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Oct 11 18:24:09.240: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-561 /apis/apps/v1/namespaces/deployment-561/deployments/test-cleanup-deployment a0806f71-4f32-494e-87a4-21060b0486fc 18732 1 2019-10-11 18:24:09 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0042739b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Oct 11 18:24:09.248: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-561 /apis/apps/v1/namespaces/deployment-561/replicasets/test-cleanup-deployment-65db99849b 47a760da-536c-4255-a4ec-64e998df8642 18739 1 2019-10-11 18:24:09 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment a0806f71-4f32-494e-87a4-21060b0486fc 0xc004273e17 0xc004273e18}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004273e78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 11 18:24:09.248: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Oct 11 18:24:09.249: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-561 /apis/apps/v1/namespaces/deployment-561/replicasets/test-cleanup-controller 7e8b1d90-5493-4b44-babe-5dd6d92b7ff7 18733 1 2019-10-11 18:24:04 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment a0806f71-4f32-494e-87a4-21060b0486fc 0xc004273d47 0xc004273d48}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004273da8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct 11 18:24:09.254: INFO: Pod "test-cleanup-controller-nfc8v" is available:
&Pod{ObjectMeta:{test-cleanup-controller-nfc8v test-cleanup-controller- deployment-561 /api/v1/namespaces/deployment-561/pods/test-cleanup-controller-nfc8v 9eac868a-3bb2-4a50-836c-9b74c780da03 18723 0 2019-10-11 18:24:04 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/podIP:10.244.4.79/32] [{apps/v1 ReplicaSet test-cleanup-controller 7e8b1d90-5493-4b44-babe-5dd6d92b7ff7 0xc006d902e7 0xc006d902e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2mrmm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2mrmm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2mrmm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-5-54.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 18:24:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 18:24:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 18:24:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 18:24:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.5.54,PodIP:10.244.4.79,StartTime:2019-10-11 18:24:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-11 18:24:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://4f3de0a932582f90cb5b149bb5b54baeadf43752edde04c2a6d21c20e3e13a52,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.79,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 11 18:24:09.254: INFO: Pod "test-cleanup-deployment-65db99849b-rzljz" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-65db99849b-rzljz test-cleanup-deployment-65db99849b- deployment-561 /api/v1/namespaces/deployment-561/pods/test-cleanup-deployment-65db99849b-rzljz 6df416b8-e5f9-4f1a-b879-dd73e7e02cfe 18738 0 2019-10-11 18:24:09 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-65db99849b 47a760da-536c-4255-a4ec-64e998df8642 0xc006d90457 0xc006d90458}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2mrmm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2mrmm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2mrmm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-6-233.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 18:24:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:24:09.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-561" for this suite.
Oct 11 18:24:15.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:24:15.411: INFO: namespace deployment-561 deletion completed in 6.148305889s

• [SLOW TEST:11.263 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:24:15.412: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 11 18:24:15.464: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b4ce16ba-bc4e-4f5a-b5de-9ef8ef92aad3" in namespace "projected-6488" to be "success or failure"
Oct 11 18:24:15.470: INFO: Pod "downwardapi-volume-b4ce16ba-bc4e-4f5a-b5de-9ef8ef92aad3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.718084ms
Oct 11 18:24:17.475: INFO: Pod "downwardapi-volume-b4ce16ba-bc4e-4f5a-b5de-9ef8ef92aad3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010722454s
Oct 11 18:24:19.480: INFO: Pod "downwardapi-volume-b4ce16ba-bc4e-4f5a-b5de-9ef8ef92aad3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015815434s
STEP: Saw pod success
Oct 11 18:24:19.480: INFO: Pod "downwardapi-volume-b4ce16ba-bc4e-4f5a-b5de-9ef8ef92aad3" satisfied condition "success or failure"
Oct 11 18:24:19.484: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod downwardapi-volume-b4ce16ba-bc4e-4f5a-b5de-9ef8ef92aad3 container client-container: <nil>
STEP: delete the pod
Oct 11 18:24:19.532: INFO: Waiting for pod downwardapi-volume-b4ce16ba-bc4e-4f5a-b5de-9ef8ef92aad3 to disappear
Oct 11 18:24:19.537: INFO: Pod downwardapi-volume-b4ce16ba-bc4e-4f5a-b5de-9ef8ef92aad3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:24:19.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6488" for this suite.
Oct 11 18:24:25.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:24:25.699: INFO: namespace projected-6488 deletion completed in 6.150863765s

• [SLOW TEST:10.287 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:24:25.699: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-1650
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1650 to expose endpoints map[]
Oct 11 18:24:25.759: INFO: Get endpoints failed (4.732118ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Oct 11 18:24:26.764: INFO: successfully validated that service multi-endpoint-test in namespace services-1650 exposes endpoints map[] (1.009830191s elapsed)
STEP: Creating pod pod1 in namespace services-1650
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1650 to expose endpoints map[pod1:[100]]
Oct 11 18:24:28.801: INFO: successfully validated that service multi-endpoint-test in namespace services-1650 exposes endpoints map[pod1:[100]] (2.02736006s elapsed)
STEP: Creating pod pod2 in namespace services-1650
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1650 to expose endpoints map[pod1:[100] pod2:[101]]
Oct 11 18:24:31.858: INFO: successfully validated that service multi-endpoint-test in namespace services-1650 exposes endpoints map[pod1:[100] pod2:[101]] (3.051659214s elapsed)
STEP: Deleting pod pod1 in namespace services-1650
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1650 to expose endpoints map[pod2:[101]]
Oct 11 18:24:31.884: INFO: successfully validated that service multi-endpoint-test in namespace services-1650 exposes endpoints map[pod2:[101]] (14.724951ms elapsed)
STEP: Deleting pod pod2 in namespace services-1650
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1650 to expose endpoints map[]
Oct 11 18:24:31.902: INFO: successfully validated that service multi-endpoint-test in namespace services-1650 exposes endpoints map[] (5.747715ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:24:31.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1650" for this suite.
Oct 11 18:24:59.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:25:00.102: INFO: namespace services-1650 deletion completed in 28.150447329s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:34.403 seconds]
[sig-network] Services
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:25:00.102: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Oct 11 18:25:00.192: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 11 18:25:00.207: INFO: Waiting for terminating namespaces to be deleted...
Oct 11 18:25:00.211: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-1-25.eu-west-3.compute.internal before test
Oct 11 18:25:00.227: INFO: canal-jn9ph from kube-system started at 2019-10-11 17:26:31 +0000 UTC (2 container statuses recorded)
Oct 11 18:25:00.227: INFO: 	Container calico-node ready: true, restart count 0
Oct 11 18:25:00.227: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 11 18:25:00.227: INFO: sonobuoy-systemd-logs-daemon-set-8223689078594c46-86r77 from sonobuoy started at 2019-10-11 17:28:08 +0000 UTC (2 container statuses recorded)
Oct 11 18:25:00.227: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 11 18:25:00.227: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 11 18:25:00.227: INFO: sonobuoy-e2e-job-56f76d39d0764ff1 from sonobuoy started at 2019-10-11 17:28:08 +0000 UTC (2 container statuses recorded)
Oct 11 18:25:00.227: INFO: 	Container e2e ready: true, restart count 0
Oct 11 18:25:00.227: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 11 18:25:00.227: INFO: kube-proxy-m86rm from kube-system started at 2019-10-11 17:26:31 +0000 UTC (1 container statuses recorded)
Oct 11 18:25:00.227: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 11 18:25:00.227: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-5-54.eu-west-3.compute.internal before test
Oct 11 18:25:00.248: INFO: sonobuoy from sonobuoy started at 2019-10-11 17:28:02 +0000 UTC (1 container statuses recorded)
Oct 11 18:25:00.248: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 11 18:25:00.248: INFO: sonobuoy-systemd-logs-daemon-set-8223689078594c46-wrftl from sonobuoy started at 2019-10-11 17:28:08 +0000 UTC (2 container statuses recorded)
Oct 11 18:25:00.248: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 11 18:25:00.248: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 11 18:25:00.248: INFO: kube-proxy-gczvl from kube-system started at 2019-10-11 17:26:30 +0000 UTC (1 container statuses recorded)
Oct 11 18:25:00.248: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 11 18:25:00.248: INFO: canal-hdnlb from kube-system started at 2019-10-11 17:26:30 +0000 UTC (2 container statuses recorded)
Oct 11 18:25:00.248: INFO: 	Container calico-node ready: true, restart count 0
Oct 11 18:25:00.248: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 11 18:25:00.248: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-6-233.eu-west-3.compute.internal before test
Oct 11 18:25:00.265: INFO: metrics-server-59bb664678-prm7v from kube-system started at 2019-10-11 17:24:41 +0000 UTC (1 container statuses recorded)
Oct 11 18:25:00.265: INFO: 	Container metrics-server ready: true, restart count 0
Oct 11 18:25:00.265: INFO: kube-proxy-qw2gl from kube-system started at 2019-10-11 17:24:22 +0000 UTC (1 container statuses recorded)
Oct 11 18:25:00.265: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 11 18:25:00.265: INFO: sonobuoy-systemd-logs-daemon-set-8223689078594c46-lhhdq from sonobuoy started at 2019-10-11 17:28:08 +0000 UTC (2 container statuses recorded)
Oct 11 18:25:00.265: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 11 18:25:00.265: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 11 18:25:00.265: INFO: canal-2xwdt from kube-system started at 2019-10-11 17:24:22 +0000 UTC (2 container statuses recorded)
Oct 11 18:25:00.265: INFO: 	Container calico-node ready: true, restart count 0
Oct 11 18:25:00.265: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-c8653dde-9b49-426c-bfcc-0deb4500a408 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-c8653dde-9b49-426c-bfcc-0deb4500a408 off the node ip-172-31-5-54.eu-west-3.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-c8653dde-9b49-426c-bfcc-0deb4500a408
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:25:16.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1527" for this suite.
Oct 11 18:25:36.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:25:36.558: INFO: namespace sched-pred-1527 deletion completed in 20.150340326s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:36.456 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:25:36.558: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Oct 11 18:25:36.668: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:25:40.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3900" for this suite.
Oct 11 18:26:08.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:26:08.989: INFO: namespace init-container-3900 deletion completed in 28.18804664s

• [SLOW TEST:32.431 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:26:08.989: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct 11 18:26:09.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-2916'
Oct 11 18:26:09.264: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 11 18:26:09.264: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Oct 11 18:26:11.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 delete deployment e2e-test-httpd-deployment --namespace=kubectl-2916'
Oct 11 18:26:11.355: INFO: stderr: ""
Oct 11 18:26:11.355: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:26:11.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2916" for this suite.
Oct 11 18:26:23.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:26:23.523: INFO: namespace kubectl-2916 deletion completed in 12.161934782s

• [SLOW TEST:14.534 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:26:23.524: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 11 18:26:23.882: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706415183, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706415183, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706415183, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706415183, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 11 18:26:25.886: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706415183, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706415183, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706415183, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706415183, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 11 18:26:28.903: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 18:26:28.908: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5174-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:26:29.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5055" for this suite.
Oct 11 18:26:35.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:26:35.700: INFO: namespace webhook-5055 deletion completed in 6.15367071s
STEP: Destroying namespace "webhook-5055-markers" for this suite.
Oct 11 18:26:41.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:26:41.845: INFO: namespace webhook-5055-markers deletion completed in 6.145030807s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.342 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:26:41.867: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Oct 11 18:26:42.526: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Oct 11 18:26:44.538: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706415202, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706415202, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706415202, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706415202, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 11 18:26:47.562: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 18:26:47.567: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:26:48.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-4502" for this suite.
Oct 11 18:26:55.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:26:55.155: INFO: namespace crd-webhook-4502 deletion completed in 6.162369948s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:13.310 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:26:55.177: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:26:57.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-60" for this suite.
Oct 11 18:27:07.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:27:07.542: INFO: namespace containers-60 deletion completed in 10.273794655s

• [SLOW TEST:12.364 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:27:07.543: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:27:07.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4167" for this suite.
Oct 11 18:27:13.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:27:13.740: INFO: namespace custom-resource-definition-4167 deletion completed in 6.147566861s

• [SLOW TEST:6.198 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:27:13.741: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Oct 11 18:27:18.332: INFO: Successfully updated pod "labelsupdatecfc037d3-76c1-4fcf-8688-47f7a0fe9c36"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:27:20.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-664" for this suite.
Oct 11 18:27:32.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:27:32.511: INFO: namespace projected-664 deletion completed in 12.152251513s

• [SLOW TEST:18.771 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:27:32.512: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Oct 11 18:27:32.627: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7930 /api/v1/namespaces/watch-7930/configmaps/e2e-watch-test-label-changed 16c417a9-27be-4d1a-afb5-c3b4a132cec2 19746 0 2019-10-11 18:27:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 11 18:27:32.627: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7930 /api/v1/namespaces/watch-7930/configmaps/e2e-watch-test-label-changed 16c417a9-27be-4d1a-afb5-c3b4a132cec2 19747 0 2019-10-11 18:27:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 11 18:27:32.627: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7930 /api/v1/namespaces/watch-7930/configmaps/e2e-watch-test-label-changed 16c417a9-27be-4d1a-afb5-c3b4a132cec2 19748 0 2019-10-11 18:27:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Oct 11 18:27:42.671: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7930 /api/v1/namespaces/watch-7930/configmaps/e2e-watch-test-label-changed 16c417a9-27be-4d1a-afb5-c3b4a132cec2 19775 0 2019-10-11 18:27:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 11 18:27:42.671: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7930 /api/v1/namespaces/watch-7930/configmaps/e2e-watch-test-label-changed 16c417a9-27be-4d1a-afb5-c3b4a132cec2 19776 0 2019-10-11 18:27:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Oct 11 18:27:42.671: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7930 /api/v1/namespaces/watch-7930/configmaps/e2e-watch-test-label-changed 16c417a9-27be-4d1a-afb5-c3b4a132cec2 19777 0 2019-10-11 18:27:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:27:42.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7930" for this suite.
Oct 11 18:27:48.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:27:48.829: INFO: namespace watch-7930 deletion completed in 6.152768883s

• [SLOW TEST:16.317 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:27:48.829: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:27:56.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3512" for this suite.
Oct 11 18:28:02.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:28:03.045: INFO: namespace job-3512 deletion completed in 6.156038885s

• [SLOW TEST:14.216 seconds]
[sig-apps] Job
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:28:03.046: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Oct 11 18:28:03.101: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6682 /api/v1/namespaces/watch-6682/configmaps/e2e-watch-test-watch-closed 6c7c1ef1-2708-421e-835e-4ccfbde57aa4 19952 0 2019-10-11 18:28:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 11 18:28:03.102: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6682 /api/v1/namespaces/watch-6682/configmaps/e2e-watch-test-watch-closed 6c7c1ef1-2708-421e-835e-4ccfbde57aa4 19953 0 2019-10-11 18:28:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Oct 11 18:28:03.123: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6682 /api/v1/namespaces/watch-6682/configmaps/e2e-watch-test-watch-closed 6c7c1ef1-2708-421e-835e-4ccfbde57aa4 19954 0 2019-10-11 18:28:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 11 18:28:03.124: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6682 /api/v1/namespaces/watch-6682/configmaps/e2e-watch-test-watch-closed 6c7c1ef1-2708-421e-835e-4ccfbde57aa4 19955 0 2019-10-11 18:28:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:28:03.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6682" for this suite.
Oct 11 18:28:09.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:28:09.275: INFO: namespace watch-6682 deletion completed in 6.146225884s

• [SLOW TEST:6.229 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:28:09.275: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-5d79c2c1-2bb1-4c7b-a707-69b7da315c74
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-5d79c2c1-2bb1-4c7b-a707-69b7da315c74
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:29:15.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3121" for this suite.
Oct 11 18:29:27.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:29:27.908: INFO: namespace projected-3121 deletion completed in 12.148971035s

• [SLOW TEST:78.633 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:29:27.908: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-8251d7bb-e1dd-4409-af3f-db5586e6fa45 in namespace container-probe-9424
Oct 11 18:29:29.966: INFO: Started pod busybox-8251d7bb-e1dd-4409-af3f-db5586e6fa45 in namespace container-probe-9424
STEP: checking the pod's current state and verifying that restartCount is present
Oct 11 18:29:29.970: INFO: Initial restart count of pod busybox-8251d7bb-e1dd-4409-af3f-db5586e6fa45 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:33:30.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9424" for this suite.
Oct 11 18:33:36.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:33:36.798: INFO: namespace container-probe-9424 deletion completed in 6.166003097s

• [SLOW TEST:248.890 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:33:36.799: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-3ff88d43-d2e4-406e-9053-dca1deecf5d4
STEP: Creating a pod to test consume secrets
Oct 11 18:33:36.852: INFO: Waiting up to 5m0s for pod "pod-secrets-76c7c7c2-8012-47e5-af86-6e3384d501fa" in namespace "secrets-1702" to be "success or failure"
Oct 11 18:33:36.856: INFO: Pod "pod-secrets-76c7c7c2-8012-47e5-af86-6e3384d501fa": Phase="Pending", Reason="", readiness=false. Elapsed: 4.45201ms
Oct 11 18:33:38.861: INFO: Pod "pod-secrets-76c7c7c2-8012-47e5-af86-6e3384d501fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008802451s
STEP: Saw pod success
Oct 11 18:33:38.861: INFO: Pod "pod-secrets-76c7c7c2-8012-47e5-af86-6e3384d501fa" satisfied condition "success or failure"
Oct 11 18:33:38.865: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-secrets-76c7c7c2-8012-47e5-af86-6e3384d501fa container secret-volume-test: <nil>
STEP: delete the pod
Oct 11 18:33:38.909: INFO: Waiting for pod pod-secrets-76c7c7c2-8012-47e5-af86-6e3384d501fa to disappear
Oct 11 18:33:38.913: INFO: Pod pod-secrets-76c7c7c2-8012-47e5-af86-6e3384d501fa no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:33:38.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1702" for this suite.
Oct 11 18:33:44.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:33:45.067: INFO: namespace secrets-1702 deletion completed in 6.147862686s

• [SLOW TEST:8.268 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:33:45.067: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Oct 11 18:33:45.107: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:34:03.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2462" for this suite.
Oct 11 18:34:09.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:34:09.350: INFO: namespace crd-publish-openapi-2462 deletion completed in 6.145325298s

• [SLOW TEST:24.283 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:34:09.351: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 18:34:09.386: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Oct 11 18:34:12.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 --namespace=crd-publish-openapi-822 create -f -'
Oct 11 18:34:13.269: INFO: stderr: ""
Oct 11 18:34:13.269: INFO: stdout: "e2e-test-crd-publish-openapi-4139-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Oct 11 18:34:13.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 --namespace=crd-publish-openapi-822 delete e2e-test-crd-publish-openapi-4139-crds test-cr'
Oct 11 18:34:13.369: INFO: stderr: ""
Oct 11 18:34:13.369: INFO: stdout: "e2e-test-crd-publish-openapi-4139-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Oct 11 18:34:13.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 --namespace=crd-publish-openapi-822 apply -f -'
Oct 11 18:34:13.521: INFO: stderr: ""
Oct 11 18:34:13.521: INFO: stdout: "e2e-test-crd-publish-openapi-4139-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Oct 11 18:34:13.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 --namespace=crd-publish-openapi-822 delete e2e-test-crd-publish-openapi-4139-crds test-cr'
Oct 11 18:34:13.591: INFO: stderr: ""
Oct 11 18:34:13.591: INFO: stdout: "e2e-test-crd-publish-openapi-4139-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Oct 11 18:34:13.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 explain e2e-test-crd-publish-openapi-4139-crds'
Oct 11 18:34:13.782: INFO: stderr: ""
Oct 11 18:34:13.782: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4139-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:34:17.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-822" for this suite.
Oct 11 18:34:23.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:34:23.483: INFO: namespace crd-publish-openapi-822 deletion completed in 6.153348663s

• [SLOW TEST:14.132 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:34:23.483: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-922.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-922.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-922.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-922.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 11 18:34:27.564: INFO: DNS probes using dns-test-aa79f446-e831-4004-951b-8d358e36c3c0 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-922.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-922.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-922.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-922.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 11 18:34:31.623: INFO: File wheezy_udp@dns-test-service-3.dns-922.svc.cluster.local from pod  dns-922/dns-test-3a80c5b5-76ec-47fb-8b2d-d6cba6781bc7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 11 18:34:31.629: INFO: File jessie_udp@dns-test-service-3.dns-922.svc.cluster.local from pod  dns-922/dns-test-3a80c5b5-76ec-47fb-8b2d-d6cba6781bc7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 11 18:34:31.629: INFO: Lookups using dns-922/dns-test-3a80c5b5-76ec-47fb-8b2d-d6cba6781bc7 failed for: [wheezy_udp@dns-test-service-3.dns-922.svc.cluster.local jessie_udp@dns-test-service-3.dns-922.svc.cluster.local]

Oct 11 18:34:36.636: INFO: File wheezy_udp@dns-test-service-3.dns-922.svc.cluster.local from pod  dns-922/dns-test-3a80c5b5-76ec-47fb-8b2d-d6cba6781bc7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 11 18:34:36.641: INFO: File jessie_udp@dns-test-service-3.dns-922.svc.cluster.local from pod  dns-922/dns-test-3a80c5b5-76ec-47fb-8b2d-d6cba6781bc7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 11 18:34:36.641: INFO: Lookups using dns-922/dns-test-3a80c5b5-76ec-47fb-8b2d-d6cba6781bc7 failed for: [wheezy_udp@dns-test-service-3.dns-922.svc.cluster.local jessie_udp@dns-test-service-3.dns-922.svc.cluster.local]

Oct 11 18:34:41.636: INFO: File wheezy_udp@dns-test-service-3.dns-922.svc.cluster.local from pod  dns-922/dns-test-3a80c5b5-76ec-47fb-8b2d-d6cba6781bc7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 11 18:34:41.642: INFO: File jessie_udp@dns-test-service-3.dns-922.svc.cluster.local from pod  dns-922/dns-test-3a80c5b5-76ec-47fb-8b2d-d6cba6781bc7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 11 18:34:41.642: INFO: Lookups using dns-922/dns-test-3a80c5b5-76ec-47fb-8b2d-d6cba6781bc7 failed for: [wheezy_udp@dns-test-service-3.dns-922.svc.cluster.local jessie_udp@dns-test-service-3.dns-922.svc.cluster.local]

Oct 11 18:34:46.635: INFO: File wheezy_udp@dns-test-service-3.dns-922.svc.cluster.local from pod  dns-922/dns-test-3a80c5b5-76ec-47fb-8b2d-d6cba6781bc7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 11 18:34:46.641: INFO: File jessie_udp@dns-test-service-3.dns-922.svc.cluster.local from pod  dns-922/dns-test-3a80c5b5-76ec-47fb-8b2d-d6cba6781bc7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 11 18:34:46.641: INFO: Lookups using dns-922/dns-test-3a80c5b5-76ec-47fb-8b2d-d6cba6781bc7 failed for: [wheezy_udp@dns-test-service-3.dns-922.svc.cluster.local jessie_udp@dns-test-service-3.dns-922.svc.cluster.local]

Oct 11 18:34:51.635: INFO: File wheezy_udp@dns-test-service-3.dns-922.svc.cluster.local from pod  dns-922/dns-test-3a80c5b5-76ec-47fb-8b2d-d6cba6781bc7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 11 18:34:51.641: INFO: File jessie_udp@dns-test-service-3.dns-922.svc.cluster.local from pod  dns-922/dns-test-3a80c5b5-76ec-47fb-8b2d-d6cba6781bc7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 11 18:34:51.641: INFO: Lookups using dns-922/dns-test-3a80c5b5-76ec-47fb-8b2d-d6cba6781bc7 failed for: [wheezy_udp@dns-test-service-3.dns-922.svc.cluster.local jessie_udp@dns-test-service-3.dns-922.svc.cluster.local]

Oct 11 18:34:56.641: INFO: DNS probes using dns-test-3a80c5b5-76ec-47fb-8b2d-d6cba6781bc7 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-922.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-922.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-922.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-922.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 11 18:35:00.772: INFO: DNS probes using dns-test-66bcf095-b8c8-478a-9166-895b76a7480b succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:35:00.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-922" for this suite.
Oct 11 18:35:06.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:35:07.085: INFO: namespace dns-922 deletion completed in 6.181467788s

• [SLOW TEST:43.601 seconds]
[sig-network] DNS
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:35:07.085: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:35:13.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1108" for this suite.
Oct 11 18:35:19.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:35:19.392: INFO: namespace namespaces-1108 deletion completed in 6.15407396s
STEP: Destroying namespace "nsdeletetest-4766" for this suite.
Oct 11 18:35:19.396: INFO: Namespace nsdeletetest-4766 was already deleted
STEP: Destroying namespace "nsdeletetest-3205" for this suite.
Oct 11 18:35:25.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:35:25.559: INFO: namespace nsdeletetest-3205 deletion completed in 6.162817814s

• [SLOW TEST:18.474 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:35:25.559: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:35:36.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3683" for this suite.
Oct 11 18:35:42.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:35:42.810: INFO: namespace resourcequota-3683 deletion completed in 6.154696849s

• [SLOW TEST:17.250 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:35:42.810: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Oct 11 18:35:42.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 create -f - --namespace=kubectl-6684'
Oct 11 18:35:43.037: INFO: stderr: ""
Oct 11 18:35:43.037: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 11 18:35:44.041: INFO: Selector matched 1 pods for map[app:redis]
Oct 11 18:35:44.041: INFO: Found 0 / 1
Oct 11 18:35:45.041: INFO: Selector matched 1 pods for map[app:redis]
Oct 11 18:35:45.041: INFO: Found 0 / 1
Oct 11 18:35:46.042: INFO: Selector matched 1 pods for map[app:redis]
Oct 11 18:35:46.042: INFO: Found 1 / 1
Oct 11 18:35:46.042: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Oct 11 18:35:46.049: INFO: Selector matched 1 pods for map[app:redis]
Oct 11 18:35:46.049: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 11 18:35:46.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 patch pod redis-master-8vlbp --namespace=kubectl-6684 -p {"metadata":{"annotations":{"x":"y"}}}'
Oct 11 18:35:46.121: INFO: stderr: ""
Oct 11 18:35:46.121: INFO: stdout: "pod/redis-master-8vlbp patched\n"
STEP: checking annotations
Oct 11 18:35:46.126: INFO: Selector matched 1 pods for map[app:redis]
Oct 11 18:35:46.126: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:35:46.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6684" for this suite.
Oct 11 18:36:14.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:36:14.280: INFO: namespace kubectl-6684 deletion completed in 28.147774389s

• [SLOW TEST:31.470 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:36:14.280: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-6168/configmap-test-3a58d21e-6d10-43b5-a585-f97bd9654b8f
STEP: Creating a pod to test consume configMaps
Oct 11 18:36:14.335: INFO: Waiting up to 5m0s for pod "pod-configmaps-34e7958d-d738-421e-ac22-c1fbb4b8d937" in namespace "configmap-6168" to be "success or failure"
Oct 11 18:36:14.340: INFO: Pod "pod-configmaps-34e7958d-d738-421e-ac22-c1fbb4b8d937": Phase="Pending", Reason="", readiness=false. Elapsed: 5.018861ms
Oct 11 18:36:16.344: INFO: Pod "pod-configmaps-34e7958d-d738-421e-ac22-c1fbb4b8d937": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009398194s
STEP: Saw pod success
Oct 11 18:36:16.344: INFO: Pod "pod-configmaps-34e7958d-d738-421e-ac22-c1fbb4b8d937" satisfied condition "success or failure"
Oct 11 18:36:16.348: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod pod-configmaps-34e7958d-d738-421e-ac22-c1fbb4b8d937 container env-test: <nil>
STEP: delete the pod
Oct 11 18:36:16.384: INFO: Waiting for pod pod-configmaps-34e7958d-d738-421e-ac22-c1fbb4b8d937 to disappear
Oct 11 18:36:16.388: INFO: Pod pod-configmaps-34e7958d-d738-421e-ac22-c1fbb4b8d937 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:36:16.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6168" for this suite.
Oct 11 18:36:22.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:36:22.538: INFO: namespace configmap-6168 deletion completed in 6.145591328s

• [SLOW TEST:8.259 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:36:22.539: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Oct 11 18:36:22.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 create -f - --namespace=kubectl-3613'
Oct 11 18:36:22.793: INFO: stderr: ""
Oct 11 18:36:22.793: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 11 18:36:22.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3613'
Oct 11 18:36:22.864: INFO: stderr: ""
Oct 11 18:36:22.864: INFO: stdout: "update-demo-nautilus-nlr4w update-demo-nautilus-ztc97 "
Oct 11 18:36:22.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-nlr4w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3613'
Oct 11 18:36:22.930: INFO: stderr: ""
Oct 11 18:36:22.930: INFO: stdout: ""
Oct 11 18:36:22.930: INFO: update-demo-nautilus-nlr4w is created but not running
Oct 11 18:36:27.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3613'
Oct 11 18:36:27.996: INFO: stderr: ""
Oct 11 18:36:27.996: INFO: stdout: "update-demo-nautilus-nlr4w update-demo-nautilus-ztc97 "
Oct 11 18:36:27.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-nlr4w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3613'
Oct 11 18:36:28.060: INFO: stderr: ""
Oct 11 18:36:28.060: INFO: stdout: "true"
Oct 11 18:36:28.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-nlr4w -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3613'
Oct 11 18:36:28.124: INFO: stderr: ""
Oct 11 18:36:28.124: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 11 18:36:28.124: INFO: validating pod update-demo-nautilus-nlr4w
Oct 11 18:36:28.133: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 11 18:36:28.133: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 11 18:36:28.133: INFO: update-demo-nautilus-nlr4w is verified up and running
Oct 11 18:36:28.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-ztc97 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3613'
Oct 11 18:36:28.200: INFO: stderr: ""
Oct 11 18:36:28.200: INFO: stdout: "true"
Oct 11 18:36:28.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods update-demo-nautilus-ztc97 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3613'
Oct 11 18:36:28.275: INFO: stderr: ""
Oct 11 18:36:28.275: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 11 18:36:28.275: INFO: validating pod update-demo-nautilus-ztc97
Oct 11 18:36:28.282: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 11 18:36:28.282: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 11 18:36:28.282: INFO: update-demo-nautilus-ztc97 is verified up and running
STEP: using delete to clean up resources
Oct 11 18:36:28.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 delete --grace-period=0 --force -f - --namespace=kubectl-3613'
Oct 11 18:36:28.362: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 11 18:36:28.362: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 11 18:36:28.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3613'
Oct 11 18:36:28.436: INFO: stderr: "No resources found in kubectl-3613 namespace.\n"
Oct 11 18:36:28.436: INFO: stdout: ""
Oct 11 18:36:28.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods -l name=update-demo --namespace=kubectl-3613 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 11 18:36:28.509: INFO: stderr: ""
Oct 11 18:36:28.509: INFO: stdout: "update-demo-nautilus-nlr4w\nupdate-demo-nautilus-ztc97\n"
Oct 11 18:36:29.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3613'
Oct 11 18:36:29.084: INFO: stderr: "No resources found in kubectl-3613 namespace.\n"
Oct 11 18:36:29.084: INFO: stdout: ""
Oct 11 18:36:29.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods -l name=update-demo --namespace=kubectl-3613 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 11 18:36:29.156: INFO: stderr: ""
Oct 11 18:36:29.156: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:36:29.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3613" for this suite.
Oct 11 18:36:35.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:36:35.318: INFO: namespace kubectl-3613 deletion completed in 6.155542263s

• [SLOW TEST:12.779 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:36:35.319: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 18:36:35.368: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-5be64d30-574b-475c-93de-ca634147e5ca" in namespace "security-context-test-4609" to be "success or failure"
Oct 11 18:36:35.372: INFO: Pod "busybox-readonly-false-5be64d30-574b-475c-93de-ca634147e5ca": Phase="Pending", Reason="", readiness=false. Elapsed: 4.407221ms
Oct 11 18:36:37.377: INFO: Pod "busybox-readonly-false-5be64d30-574b-475c-93de-ca634147e5ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008914469s
Oct 11 18:36:37.377: INFO: Pod "busybox-readonly-false-5be64d30-574b-475c-93de-ca634147e5ca" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:36:37.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4609" for this suite.
Oct 11 18:36:43.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:36:43.531: INFO: namespace security-context-test-4609 deletion completed in 6.147586115s

• [SLOW TEST:8.212 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:36:43.531: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct 11 18:36:43.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-4529'
Oct 11 18:36:43.656: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 11 18:36:43.656: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Oct 11 18:36:45.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 delete deployment e2e-test-httpd-deployment --namespace=kubectl-4529'
Oct 11 18:36:45.745: INFO: stderr: ""
Oct 11 18:36:45.745: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:36:45.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4529" for this suite.
Oct 11 18:36:57.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:36:57.899: INFO: namespace kubectl-4529 deletion completed in 12.148257386s

• [SLOW TEST:14.368 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:36:57.899: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 11 18:36:59.966: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:36:59.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8576" for this suite.
Oct 11 18:37:06.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:37:06.145: INFO: namespace container-runtime-8576 deletion completed in 6.149092372s

• [SLOW TEST:8.246 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:37:06.146: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-q8k2
STEP: Creating a pod to test atomic-volume-subpath
Oct 11 18:37:06.256: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-q8k2" in namespace "subpath-8640" to be "success or failure"
Oct 11 18:37:06.263: INFO: Pod "pod-subpath-test-configmap-q8k2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.900614ms
Oct 11 18:37:08.268: INFO: Pod "pod-subpath-test-configmap-q8k2": Phase="Running", Reason="", readiness=true. Elapsed: 2.012139082s
Oct 11 18:37:10.273: INFO: Pod "pod-subpath-test-configmap-q8k2": Phase="Running", Reason="", readiness=true. Elapsed: 4.017008358s
Oct 11 18:37:12.278: INFO: Pod "pod-subpath-test-configmap-q8k2": Phase="Running", Reason="", readiness=true. Elapsed: 6.021782813s
Oct 11 18:37:14.286: INFO: Pod "pod-subpath-test-configmap-q8k2": Phase="Running", Reason="", readiness=true. Elapsed: 8.029621235s
Oct 11 18:37:16.291: INFO: Pod "pod-subpath-test-configmap-q8k2": Phase="Running", Reason="", readiness=true. Elapsed: 10.034717169s
Oct 11 18:37:18.296: INFO: Pod "pod-subpath-test-configmap-q8k2": Phase="Running", Reason="", readiness=true. Elapsed: 12.039403847s
Oct 11 18:37:20.301: INFO: Pod "pod-subpath-test-configmap-q8k2": Phase="Running", Reason="", readiness=true. Elapsed: 14.044446785s
Oct 11 18:37:22.308: INFO: Pod "pod-subpath-test-configmap-q8k2": Phase="Running", Reason="", readiness=true. Elapsed: 16.05197268s
Oct 11 18:37:24.313: INFO: Pod "pod-subpath-test-configmap-q8k2": Phase="Running", Reason="", readiness=true. Elapsed: 18.05702061s
Oct 11 18:37:26.318: INFO: Pod "pod-subpath-test-configmap-q8k2": Phase="Running", Reason="", readiness=true. Elapsed: 20.062200668s
Oct 11 18:37:28.323: INFO: Pod "pod-subpath-test-configmap-q8k2": Phase="Running", Reason="", readiness=true. Elapsed: 22.067082583s
Oct 11 18:37:30.328: INFO: Pod "pod-subpath-test-configmap-q8k2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.071979564s
STEP: Saw pod success
Oct 11 18:37:30.328: INFO: Pod "pod-subpath-test-configmap-q8k2" satisfied condition "success or failure"
Oct 11 18:37:30.332: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-subpath-test-configmap-q8k2 container test-container-subpath-configmap-q8k2: <nil>
STEP: delete the pod
Oct 11 18:37:30.371: INFO: Waiting for pod pod-subpath-test-configmap-q8k2 to disappear
Oct 11 18:37:30.375: INFO: Pod pod-subpath-test-configmap-q8k2 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-q8k2
Oct 11 18:37:30.375: INFO: Deleting pod "pod-subpath-test-configmap-q8k2" in namespace "subpath-8640"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:37:30.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8640" for this suite.
Oct 11 18:37:36.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:37:36.554: INFO: namespace subpath-8640 deletion completed in 6.169727232s

• [SLOW TEST:30.409 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:37:36.555: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Oct 11 18:37:36.605: INFO: Waiting up to 5m0s for pod "client-containers-4b2c6ae0-d489-4604-b8cb-0865c29c2777" in namespace "containers-2197" to be "success or failure"
Oct 11 18:37:36.611: INFO: Pod "client-containers-4b2c6ae0-d489-4604-b8cb-0865c29c2777": Phase="Pending", Reason="", readiness=false. Elapsed: 6.263871ms
Oct 11 18:37:38.616: INFO: Pod "client-containers-4b2c6ae0-d489-4604-b8cb-0865c29c2777": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011012138s
STEP: Saw pod success
Oct 11 18:37:38.616: INFO: Pod "client-containers-4b2c6ae0-d489-4604-b8cb-0865c29c2777" satisfied condition "success or failure"
Oct 11 18:37:38.621: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod client-containers-4b2c6ae0-d489-4604-b8cb-0865c29c2777 container test-container: <nil>
STEP: delete the pod
Oct 11 18:37:38.651: INFO: Waiting for pod client-containers-4b2c6ae0-d489-4604-b8cb-0865c29c2777 to disappear
Oct 11 18:37:38.655: INFO: Pod client-containers-4b2c6ae0-d489-4604-b8cb-0865c29c2777 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:37:38.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2197" for this suite.
Oct 11 18:37:44.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:37:44.814: INFO: namespace containers-2197 deletion completed in 6.153644515s

• [SLOW TEST:8.260 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:37:44.815: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-caff2699-e6df-4e45-b147-b443a7cdfd82 in namespace container-probe-9710
Oct 11 18:37:46.870: INFO: Started pod liveness-caff2699-e6df-4e45-b147-b443a7cdfd82 in namespace container-probe-9710
STEP: checking the pod's current state and verifying that restartCount is present
Oct 11 18:37:46.874: INFO: Initial restart count of pod liveness-caff2699-e6df-4e45-b147-b443a7cdfd82 is 0
Oct 11 18:38:04.924: INFO: Restart count of pod container-probe-9710/liveness-caff2699-e6df-4e45-b147-b443a7cdfd82 is now 1 (18.049207183s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:38:04.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9710" for this suite.
Oct 11 18:38:10.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:38:11.109: INFO: namespace container-probe-9710 deletion completed in 6.162907983s

• [SLOW TEST:26.294 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:38:11.109: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:39:11.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3686" for this suite.
Oct 11 18:39:39.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:39:39.322: INFO: namespace container-probe-3686 deletion completed in 28.14768444s

• [SLOW TEST:88.213 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:39:39.322: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Oct 11 18:39:39.369: INFO: Waiting up to 5m0s for pod "var-expansion-fba40d85-af9b-475b-91ac-5f92754265bc" in namespace "var-expansion-9695" to be "success or failure"
Oct 11 18:39:39.374: INFO: Pod "var-expansion-fba40d85-af9b-475b-91ac-5f92754265bc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.803907ms
Oct 11 18:39:41.378: INFO: Pod "var-expansion-fba40d85-af9b-475b-91ac-5f92754265bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009667623s
Oct 11 18:39:43.383: INFO: Pod "var-expansion-fba40d85-af9b-475b-91ac-5f92754265bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014505475s
STEP: Saw pod success
Oct 11 18:39:43.383: INFO: Pod "var-expansion-fba40d85-af9b-475b-91ac-5f92754265bc" satisfied condition "success or failure"
Oct 11 18:39:43.388: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod var-expansion-fba40d85-af9b-475b-91ac-5f92754265bc container dapi-container: <nil>
STEP: delete the pod
Oct 11 18:39:43.429: INFO: Waiting for pod var-expansion-fba40d85-af9b-475b-91ac-5f92754265bc to disappear
Oct 11 18:39:43.433: INFO: Pod var-expansion-fba40d85-af9b-475b-91ac-5f92754265bc no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:39:43.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9695" for this suite.
Oct 11 18:39:49.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:39:49.592: INFO: namespace var-expansion-9695 deletion completed in 6.15393083s

• [SLOW TEST:10.270 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:39:49.593: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1608
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-1608
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1608
Oct 11 18:39:49.707: INFO: Found 0 stateful pods, waiting for 1
Oct 11 18:39:59.712: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Oct 11 18:39:59.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 11 18:39:59.998: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 11 18:39:59.998: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 11 18:39:59.998: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 11 18:40:00.003: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 11 18:40:10.008: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 11 18:40:10.008: INFO: Waiting for statefulset status.replicas updated to 0
Oct 11 18:40:10.028: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Oct 11 18:40:10.028: INFO: ss-0  ip-172-31-5-54.eu-west-3.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:39:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:39:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:39:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:39:49 +0000 UTC  }]
Oct 11 18:40:10.028: INFO: 
Oct 11 18:40:10.028: INFO: StatefulSet ss has not reached scale 3, at 1
Oct 11 18:40:11.032: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995792836s
Oct 11 18:40:12.041: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.99141182s
Oct 11 18:40:13.046: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.982790783s
Oct 11 18:40:14.051: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.977203713s
Oct 11 18:40:15.059: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.972267274s
Oct 11 18:40:16.064: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.964248251s
Oct 11 18:40:17.069: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.95919727s
Oct 11 18:40:18.075: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.95396109s
Oct 11 18:40:19.090: INFO: Verifying statefulset ss doesn't scale past 3 for another 948.500492ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1608
Oct 11 18:40:20.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:40:20.395: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 11 18:40:20.395: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 11 18:40:20.395: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 11 18:40:20.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:40:20.671: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 11 18:40:20.671: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 11 18:40:20.671: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 11 18:40:20.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:40:20.967: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 11 18:40:20.967: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 11 18:40:20.967: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 11 18:40:20.972: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Oct 11 18:40:30.977: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 11 18:40:30.977: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 11 18:40:30.977: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Oct 11 18:40:30.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 11 18:40:31.247: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 11 18:40:31.247: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 11 18:40:31.247: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 11 18:40:31.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 11 18:40:31.550: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 11 18:40:31.550: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 11 18:40:31.550: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 11 18:40:31.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 11 18:40:31.804: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 11 18:40:31.804: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 11 18:40:31.804: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 11 18:40:31.804: INFO: Waiting for statefulset status.replicas updated to 0
Oct 11 18:40:31.809: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Oct 11 18:40:41.818: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 11 18:40:41.818: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 11 18:40:41.818: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 11 18:40:41.831: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Oct 11 18:40:41.831: INFO: ss-0  ip-172-31-5-54.eu-west-3.compute.internal   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:39:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:39:49 +0000 UTC  }]
Oct 11 18:40:41.832: INFO: ss-1  ip-172-31-6-233.eu-west-3.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  }]
Oct 11 18:40:41.832: INFO: ss-2  ip-172-31-1-25.eu-west-3.compute.internal   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  }]
Oct 11 18:40:41.832: INFO: 
Oct 11 18:40:41.832: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 11 18:40:42.837: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Oct 11 18:40:42.837: INFO: ss-0  ip-172-31-5-54.eu-west-3.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:39:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:39:49 +0000 UTC  }]
Oct 11 18:40:42.837: INFO: ss-1  ip-172-31-6-233.eu-west-3.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  }]
Oct 11 18:40:42.837: INFO: ss-2  ip-172-31-1-25.eu-west-3.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  }]
Oct 11 18:40:42.837: INFO: 
Oct 11 18:40:42.837: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 11 18:40:43.842: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Oct 11 18:40:43.843: INFO: ss-0  ip-172-31-5-54.eu-west-3.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:39:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:39:49 +0000 UTC  }]
Oct 11 18:40:43.843: INFO: ss-1  ip-172-31-6-233.eu-west-3.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  }]
Oct 11 18:40:43.843: INFO: ss-2  ip-172-31-1-25.eu-west-3.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  }]
Oct 11 18:40:43.843: INFO: 
Oct 11 18:40:43.843: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 11 18:40:44.848: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Oct 11 18:40:44.848: INFO: ss-1  ip-172-31-6-233.eu-west-3.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  }]
Oct 11 18:40:44.848: INFO: ss-2  ip-172-31-1-25.eu-west-3.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  }]
Oct 11 18:40:44.848: INFO: 
Oct 11 18:40:44.848: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 11 18:40:45.858: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Oct 11 18:40:45.858: INFO: ss-1  ip-172-31-6-233.eu-west-3.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  }]
Oct 11 18:40:45.858: INFO: ss-2  ip-172-31-1-25.eu-west-3.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  }]
Oct 11 18:40:45.858: INFO: 
Oct 11 18:40:45.858: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 11 18:40:46.863: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Oct 11 18:40:46.863: INFO: ss-1  ip-172-31-6-233.eu-west-3.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  }]
Oct 11 18:40:46.863: INFO: ss-2  ip-172-31-1-25.eu-west-3.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  }]
Oct 11 18:40:46.863: INFO: 
Oct 11 18:40:46.863: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 11 18:40:47.868: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Oct 11 18:40:47.868: INFO: ss-1  ip-172-31-6-233.eu-west-3.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  }]
Oct 11 18:40:47.868: INFO: ss-2  ip-172-31-1-25.eu-west-3.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  }]
Oct 11 18:40:47.868: INFO: 
Oct 11 18:40:47.869: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 11 18:40:48.874: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Oct 11 18:40:48.874: INFO: ss-1  ip-172-31-6-233.eu-west-3.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  }]
Oct 11 18:40:48.874: INFO: ss-2  ip-172-31-1-25.eu-west-3.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  }]
Oct 11 18:40:48.874: INFO: 
Oct 11 18:40:48.874: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 11 18:40:49.879: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Oct 11 18:40:49.879: INFO: ss-1  ip-172-31-6-233.eu-west-3.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  }]
Oct 11 18:40:49.879: INFO: ss-2  ip-172-31-1-25.eu-west-3.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  }]
Oct 11 18:40:49.879: INFO: 
Oct 11 18:40:49.879: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 11 18:40:50.884: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Oct 11 18:40:50.884: INFO: ss-1  ip-172-31-6-233.eu-west-3.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-11 18:40:09 +0000 UTC  }]
Oct 11 18:40:50.884: INFO: 
Oct 11 18:40:50.884: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1608
Oct 11 18:40:51.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:40:51.984: INFO: rc: 1
Oct 11 18:40:51.984: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  error: unable to upgrade connection: container not found ("webserver")
 [] <nil> 0xc005978f90 exit status 1 <nil> <nil> true [0xc0026c68b0 0xc0026c68d8 0xc0026c6908] [0xc0026c68b0 0xc0026c68d8 0xc0026c6908] [0xc0026c68c8 0xc0026c68f0] [0x10ef3f0 0x10ef3f0] 0xc002b691a0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Oct 11 18:41:01.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:41:02.057: INFO: rc: 1
Oct 11 18:41:02.057: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0071791a0 exit status 1 <nil> <nil> true [0xc0031aa600 0xc0031aa648 0xc0031aa670] [0xc0031aa600 0xc0031aa648 0xc0031aa670] [0xc0031aa630 0xc0031aa668] [0x10ef3f0 0x10ef3f0] 0xc0029f6540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:41:12.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:41:12.129: INFO: rc: 1
Oct 11 18:41:12.129: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc007179530 exit status 1 <nil> <nil> true [0xc0031aa678 0xc0031aa690 0xc0031aa6a8] [0xc0031aa678 0xc0031aa690 0xc0031aa6a8] [0xc0031aa688 0xc0031aa6a0] [0x10ef3f0 0x10ef3f0] 0xc0029f6900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:41:22.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:41:22.194: INFO: rc: 1
Oct 11 18:41:22.194: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc007179890 exit status 1 <nil> <nil> true [0xc0031aa6b0 0xc0031aa6e0 0xc0031aa708] [0xc0031aa6b0 0xc0031aa6e0 0xc0031aa708] [0xc0031aa6d8 0xc0031aa6f0] [0x10ef3f0 0x10ef3f0] 0xc0029f6c60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:41:32.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:41:32.268: INFO: rc: 1
Oct 11 18:41:32.268: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc007179c20 exit status 1 <nil> <nil> true [0xc0031aa728 0xc0031aa750 0xc0031aa790] [0xc0031aa728 0xc0031aa750 0xc0031aa790] [0xc0031aa748 0xc0031aa770] [0x10ef3f0 0x10ef3f0] 0xc0029f7020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:41:42.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:41:42.347: INFO: rc: 1
Oct 11 18:41:42.348: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc005979350 exit status 1 <nil> <nil> true [0xc0026c6918 0xc0026c6960 0xc0026c69f0] [0xc0026c6918 0xc0026c6960 0xc0026c69f0] [0xc0026c6930 0xc0026c69d8] [0x10ef3f0 0x10ef3f0] 0xc002b69560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:41:52.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:41:52.421: INFO: rc: 1
Oct 11 18:41:52.421: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc007179fb0 exit status 1 <nil> <nil> true [0xc0031aa7a8 0xc0031aa7f8 0xc0031aa810] [0xc0031aa7a8 0xc0031aa7f8 0xc0031aa810] [0xc0031aa7e0 0xc0031aa808] [0x10ef3f0 0x10ef3f0] 0xc0029f74a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:42:02.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:42:02.497: INFO: rc: 1
Oct 11 18:42:02.497: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003502330 exit status 1 <nil> <nil> true [0xc0031aa830 0xc0031aa858 0xc0031aa870] [0xc0031aa830 0xc0031aa858 0xc0031aa870] [0xc0031aa850 0xc0031aa868] [0x10ef3f0 0x10ef3f0] 0xc0029f7920 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:42:12.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:42:12.572: INFO: rc: 1
Oct 11 18:42:12.572: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc005979710 exit status 1 <nil> <nil> true [0xc0026c6a28 0xc0026c6a68 0xc0026c6b40] [0xc0026c6a28 0xc0026c6a68 0xc0026c6b40] [0xc0026c6a40 0xc0026c6b00] [0x10ef3f0 0x10ef3f0] 0xc002b698c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:42:22.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:42:22.638: INFO: rc: 1
Oct 11 18:42:22.638: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc007178360 exit status 1 <nil> <nil> true [0xc0007c7028 0xc0007c7b18 0xc0007c7f88] [0xc0007c7028 0xc0007c7b18 0xc0007c7f88] [0xc0007c7968 0xc0007c7e60] [0x10ef3f0 0x10ef3f0] 0xc00210a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:42:32.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:42:32.708: INFO: rc: 1
Oct 11 18:42:32.708: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002d84360 exit status 1 <nil> <nil> true [0xc000dc2268 0xc000dc2b40 0xc000dc3960] [0xc000dc2268 0xc000dc2b40 0xc000dc3960] [0xc000dc2880 0xc000dc3280] [0x10ef3f0 0x10ef3f0] 0xc00346e8a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:42:42.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:42:42.875: INFO: rc: 1
Oct 11 18:42:42.875: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0071786c0 exit status 1 <nil> <nil> true [0xc0000cadc0 0xc0000cb428 0xc0000cb708] [0xc0000cadc0 0xc0000cb428 0xc0000cb708] [0xc0000cb270 0xc0000cb4e8] [0x10ef3f0 0x10ef3f0] 0xc00210a840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:42:52.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:42:52.945: INFO: rc: 1
Oct 11 18:42:52.945: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc007178a50 exit status 1 <nil> <nil> true [0xc0000cb790 0xc0000cba50 0xc0026c6138] [0xc0000cb790 0xc0000cba50 0xc0026c6138] [0xc0000cb910 0xc0026c60f0] [0x10ef3f0 0x10ef3f0] 0xc00210ade0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:43:02.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:43:03.019: INFO: rc: 1
Oct 11 18:43:03.019: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc007178de0 exit status 1 <nil> <nil> true [0xc0026c6140 0xc0026c62c0 0xc0026c6370] [0xc0026c6140 0xc0026c62c0 0xc0026c6370] [0xc0026c62a8 0xc0026c6350] [0x10ef3f0 0x10ef3f0] 0xc00210b1a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:43:13.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:43:13.090: INFO: rc: 1
Oct 11 18:43:13.090: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc007179170 exit status 1 <nil> <nil> true [0xc0026c6378 0xc0026c6400 0xc0026c6618] [0xc0026c6378 0xc0026c6400 0xc0026c6618] [0xc0026c63e0 0xc0026c65b0] [0x10ef3f0 0x10ef3f0] 0xc00210b560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:43:23.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:43:23.164: INFO: rc: 1
Oct 11 18:43:23.164: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc007179560 exit status 1 <nil> <nil> true [0xc0026c6640 0xc0026c6720 0xc0026c6768] [0xc0026c6640 0xc0026c6720 0xc0026c6768] [0xc0026c6710 0xc0026c6748] [0x10ef3f0 0x10ef3f0] 0xc00210b8c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:43:33.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:43:33.238: INFO: rc: 1
Oct 11 18:43:33.238: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc007179920 exit status 1 <nil> <nil> true [0xc0026c6778 0xc0026c67c0 0xc0026c67e0] [0xc0026c6778 0xc0026c67c0 0xc0026c67e0] [0xc0026c6790 0xc0026c67d8] [0x10ef3f0 0x10ef3f0] 0xc00210bc20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:43:43.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:43:43.311: INFO: rc: 1
Oct 11 18:43:43.311: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc007179ce0 exit status 1 <nil> <nil> true [0xc0026c6800 0xc0026c68a8 0xc0026c68c8] [0xc0026c6800 0xc0026c68a8 0xc0026c68c8] [0xc0026c6830 0xc0026c68b8] [0x10ef3f0 0x10ef3f0] 0xc0021e5620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:43:53.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:43:53.382: INFO: rc: 1
Oct 11 18:43:53.382: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002d84840 exit status 1 <nil> <nil> true [0xc000dc3a88 0xc000dc3dc8 0xc0031aa000] [0xc000dc3a88 0xc000dc3dc8 0xc0031aa000] [0xc000dc3d98 0xc000dc3dd8] [0x10ef3f0 0x10ef3f0] 0xc00346f0e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:44:03.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:44:03.462: INFO: rc: 1
Oct 11 18:44:03.462: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0028b80c0 exit status 1 <nil> <nil> true [0xc0026c68d8 0xc0026c6908 0xc0026c6930] [0xc0026c68d8 0xc0026c6908 0xc0026c6930] [0xc0026c68f0 0xc0026c6928] [0x10ef3f0 0x10ef3f0] 0xc002b68000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:44:13.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:44:13.679: INFO: rc: 1
Oct 11 18:44:13.679: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002d84bd0 exit status 1 <nil> <nil> true [0xc0031aa008 0xc0031aa040 0xc0031aa070] [0xc0031aa008 0xc0031aa040 0xc0031aa070] [0xc0031aa038 0xc0031aa068] [0x10ef3f0 0x10ef3f0] 0xc00346f7a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:44:23.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:44:23.753: INFO: rc: 1
Oct 11 18:44:23.753: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc007178390 exit status 1 <nil> <nil> true [0xc0000cafd0 0xc0000cb4a0 0xc0000cb790] [0xc0000cafd0 0xc0000cb4a0 0xc0000cb790] [0xc0000cb428 0xc0000cb708] [0x10ef3f0 0x10ef3f0] 0xc0021e4240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:44:33.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:44:33.829: INFO: rc: 1
Oct 11 18:44:33.829: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0028b8360 exit status 1 <nil> <nil> true [0xc000dc2268 0xc000dc2b40 0xc000dc3960] [0xc000dc2268 0xc000dc2b40 0xc000dc3960] [0xc000dc2880 0xc000dc3280] [0x10ef3f0 0x10ef3f0] 0xc00210a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:44:43.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:44:43.905: INFO: rc: 1
Oct 11 18:44:43.905: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc007178750 exit status 1 <nil> <nil> true [0xc0000cb888 0xc0007c6f38 0xc0007c7968] [0xc0000cb888 0xc0007c6f38 0xc0007c7968] [0xc0000cba50 0xc0007c7698] [0x10ef3f0 0x10ef3f0] 0xc002b683c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:44:53.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:44:53.978: INFO: rc: 1
Oct 11 18:44:53.978: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc007178ae0 exit status 1 <nil> <nil> true [0xc0007c7b18 0xc0007c7f88 0xc0026c6138] [0xc0007c7b18 0xc0007c7f88 0xc0026c6138] [0xc0007c7e60 0xc0026c60f0] [0x10ef3f0 0x10ef3f0] 0xc002b68720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:45:03.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:45:04.055: INFO: rc: 1
Oct 11 18:45:04.055: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0028b8720 exit status 1 <nil> <nil> true [0xc000dc3a88 0xc000dc3dc8 0xc0031aa000] [0xc000dc3a88 0xc000dc3dc8 0xc0031aa000] [0xc000dc3d98 0xc000dc3dd8] [0x10ef3f0 0x10ef3f0] 0xc00210a840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:45:14.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:45:14.142: INFO: rc: 1
Oct 11 18:45:14.142: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0028b8b40 exit status 1 <nil> <nil> true [0xc0031aa008 0xc0031aa040 0xc0031aa070] [0xc0031aa008 0xc0031aa040 0xc0031aa070] [0xc0031aa038 0xc0031aa068] [0x10ef3f0 0x10ef3f0] 0xc00210ade0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:45:24.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:45:24.264: INFO: rc: 1
Oct 11 18:45:24.264: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0028b8ed0 exit status 1 <nil> <nil> true [0xc0031aa078 0xc0031aa0b0 0xc0031aa0f0] [0xc0031aa078 0xc0031aa0b0 0xc0031aa0f0] [0xc0031aa0a8 0xc0031aa0e8] [0x10ef3f0 0x10ef3f0] 0xc00210b1a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:45:34.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:45:34.334: INFO: rc: 1
Oct 11 18:45:34.334: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0028b9230 exit status 1 <nil> <nil> true [0xc0031aa108 0xc0031aa138 0xc0031aa178] [0xc0031aa108 0xc0031aa138 0xc0031aa178] [0xc0031aa120 0xc0031aa150] [0x10ef3f0 0x10ef3f0] 0xc00210b560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:45:44.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:45:44.405: INFO: rc: 1
Oct 11 18:45:44.406: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0028b9590 exit status 1 <nil> <nil> true [0xc0031aa190 0xc0031aa1e0 0xc0031aa208] [0xc0031aa190 0xc0031aa1e0 0xc0031aa208] [0xc0031aa1c8 0xc0031aa200] [0x10ef3f0 0x10ef3f0] 0xc00210b8c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Oct 11 18:45:54.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-1608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 18:45:54.472: INFO: rc: 1
Oct 11 18:45:54.473: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: 
Oct 11 18:45:54.473: INFO: Scaling statefulset ss to 0
Oct 11 18:45:54.485: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct 11 18:45:54.489: INFO: Deleting all statefulset in ns statefulset-1608
Oct 11 18:45:54.493: INFO: Scaling statefulset ss to 0
Oct 11 18:45:54.506: INFO: Waiting for statefulset status.replicas updated to 0
Oct 11 18:45:54.510: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:45:54.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1608" for this suite.
Oct 11 18:46:00.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:46:00.701: INFO: namespace statefulset-1608 deletion completed in 6.168104896s

• [SLOW TEST:371.108 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:46:00.702: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-3320
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-3320
STEP: Deleting pre-stop pod
Oct 11 18:46:13.800: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:46:13.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-3320" for this suite.
Oct 11 18:46:57.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:46:57.966: INFO: namespace prestop-3320 deletion completed in 44.150839879s

• [SLOW TEST:57.264 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:46:57.966: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-f2c1dae6-3070-4350-bb04-4057c5e84516
STEP: Creating a pod to test consume configMaps
Oct 11 18:46:58.023: INFO: Waiting up to 5m0s for pod "pod-configmaps-ea958ec4-d655-4f53-8413-65895efd5974" in namespace "configmap-7993" to be "success or failure"
Oct 11 18:46:58.026: INFO: Pod "pod-configmaps-ea958ec4-d655-4f53-8413-65895efd5974": Phase="Pending", Reason="", readiness=false. Elapsed: 3.77425ms
Oct 11 18:47:00.032: INFO: Pod "pod-configmaps-ea958ec4-d655-4f53-8413-65895efd5974": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009076719s
STEP: Saw pod success
Oct 11 18:47:00.032: INFO: Pod "pod-configmaps-ea958ec4-d655-4f53-8413-65895efd5974" satisfied condition "success or failure"
Oct 11 18:47:00.036: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod pod-configmaps-ea958ec4-d655-4f53-8413-65895efd5974 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 11 18:47:00.085: INFO: Waiting for pod pod-configmaps-ea958ec4-d655-4f53-8413-65895efd5974 to disappear
Oct 11 18:47:00.089: INFO: Pod pod-configmaps-ea958ec4-d655-4f53-8413-65895efd5974 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:47:00.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7993" for this suite.
Oct 11 18:47:06.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:47:06.249: INFO: namespace configmap-7993 deletion completed in 6.154654475s

• [SLOW TEST:8.283 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:47:06.249: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-f64df15d-129b-49d3-9694-068a6383c272
STEP: Creating a pod to test consume secrets
Oct 11 18:47:06.303: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-76978213-c2ee-408f-a605-428ef841e471" in namespace "projected-5351" to be "success or failure"
Oct 11 18:47:06.308: INFO: Pod "pod-projected-secrets-76978213-c2ee-408f-a605-428ef841e471": Phase="Pending", Reason="", readiness=false. Elapsed: 5.41334ms
Oct 11 18:47:08.313: INFO: Pod "pod-projected-secrets-76978213-c2ee-408f-a605-428ef841e471": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01012171s
Oct 11 18:47:10.317: INFO: Pod "pod-projected-secrets-76978213-c2ee-408f-a605-428ef841e471": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01484258s
STEP: Saw pod success
Oct 11 18:47:10.317: INFO: Pod "pod-projected-secrets-76978213-c2ee-408f-a605-428ef841e471" satisfied condition "success or failure"
Oct 11 18:47:10.322: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-projected-secrets-76978213-c2ee-408f-a605-428ef841e471 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 11 18:47:10.362: INFO: Waiting for pod pod-projected-secrets-76978213-c2ee-408f-a605-428ef841e471 to disappear
Oct 11 18:47:10.365: INFO: Pod pod-projected-secrets-76978213-c2ee-408f-a605-428ef841e471 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:47:10.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5351" for this suite.
Oct 11 18:47:16.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:47:16.517: INFO: namespace projected-5351 deletion completed in 6.146416184s

• [SLOW TEST:10.268 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:47:16.517: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-81348896-c8f4-4c76-af68-e5bdb910d67b
Oct 11 18:47:16.565: INFO: Pod name my-hostname-basic-81348896-c8f4-4c76-af68-e5bdb910d67b: Found 0 pods out of 1
Oct 11 18:47:21.572: INFO: Pod name my-hostname-basic-81348896-c8f4-4c76-af68-e5bdb910d67b: Found 1 pods out of 1
Oct 11 18:47:21.572: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-81348896-c8f4-4c76-af68-e5bdb910d67b" are running
Oct 11 18:47:21.578: INFO: Pod "my-hostname-basic-81348896-c8f4-4c76-af68-e5bdb910d67b-q8jzj" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-11 18:47:16 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-11 18:47:18 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-11 18:47:18 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-11 18:47:16 +0000 UTC Reason: Message:}])
Oct 11 18:47:21.578: INFO: Trying to dial the pod
Oct 11 18:47:26.594: INFO: Controller my-hostname-basic-81348896-c8f4-4c76-af68-e5bdb910d67b: Got expected result from replica 1 [my-hostname-basic-81348896-c8f4-4c76-af68-e5bdb910d67b-q8jzj]: "my-hostname-basic-81348896-c8f4-4c76-af68-e5bdb910d67b-q8jzj", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:47:26.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8714" for this suite.
Oct 11 18:47:32.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:47:32.762: INFO: namespace replication-controller-8714 deletion completed in 6.160623176s

• [SLOW TEST:16.245 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:47:32.763: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-3cb80310-24bb-47f0-977c-3ef057f44e2f
STEP: Creating a pod to test consume configMaps
Oct 11 18:47:32.815: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f07d524c-d3bd-42bc-a124-a41851812ccc" in namespace "projected-2726" to be "success or failure"
Oct 11 18:47:32.820: INFO: Pod "pod-projected-configmaps-f07d524c-d3bd-42bc-a124-a41851812ccc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.176389ms
Oct 11 18:47:34.825: INFO: Pod "pod-projected-configmaps-f07d524c-d3bd-42bc-a124-a41851812ccc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009913217s
Oct 11 18:47:36.830: INFO: Pod "pod-projected-configmaps-f07d524c-d3bd-42bc-a124-a41851812ccc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014942019s
STEP: Saw pod success
Oct 11 18:47:36.830: INFO: Pod "pod-projected-configmaps-f07d524c-d3bd-42bc-a124-a41851812ccc" satisfied condition "success or failure"
Oct 11 18:47:36.834: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-projected-configmaps-f07d524c-d3bd-42bc-a124-a41851812ccc container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 11 18:47:36.859: INFO: Waiting for pod pod-projected-configmaps-f07d524c-d3bd-42bc-a124-a41851812ccc to disappear
Oct 11 18:47:36.864: INFO: Pod pod-projected-configmaps-f07d524c-d3bd-42bc-a124-a41851812ccc no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:47:36.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2726" for this suite.
Oct 11 18:47:42.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:47:43.020: INFO: namespace projected-2726 deletion completed in 6.149906642s

• [SLOW TEST:10.257 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:47:43.020: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 11 18:47:43.072: INFO: Waiting up to 5m0s for pod "pod-ddc7e103-b5c3-4894-9acc-8c9fb01e3c27" in namespace "emptydir-5114" to be "success or failure"
Oct 11 18:47:43.077: INFO: Pod "pod-ddc7e103-b5c3-4894-9acc-8c9fb01e3c27": Phase="Pending", Reason="", readiness=false. Elapsed: 4.323161ms
Oct 11 18:47:45.090: INFO: Pod "pod-ddc7e103-b5c3-4894-9acc-8c9fb01e3c27": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01762102s
Oct 11 18:47:47.095: INFO: Pod "pod-ddc7e103-b5c3-4894-9acc-8c9fb01e3c27": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022608176s
STEP: Saw pod success
Oct 11 18:47:47.095: INFO: Pod "pod-ddc7e103-b5c3-4894-9acc-8c9fb01e3c27" satisfied condition "success or failure"
Oct 11 18:47:47.099: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod pod-ddc7e103-b5c3-4894-9acc-8c9fb01e3c27 container test-container: <nil>
STEP: delete the pod
Oct 11 18:47:47.124: INFO: Waiting for pod pod-ddc7e103-b5c3-4894-9acc-8c9fb01e3c27 to disappear
Oct 11 18:47:47.128: INFO: Pod pod-ddc7e103-b5c3-4894-9acc-8c9fb01e3c27 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:47:47.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5114" for this suite.
Oct 11 18:47:53.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:47:53.281: INFO: namespace emptydir-5114 deletion completed in 6.148271755s

• [SLOW TEST:10.261 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:47:53.282: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 11 18:47:53.329: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6dae6665-0ed8-4c83-a824-0dec8ffd1de9" in namespace "downward-api-6213" to be "success or failure"
Oct 11 18:47:53.334: INFO: Pod "downwardapi-volume-6dae6665-0ed8-4c83-a824-0dec8ffd1de9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.955143ms
Oct 11 18:47:55.339: INFO: Pod "downwardapi-volume-6dae6665-0ed8-4c83-a824-0dec8ffd1de9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009760037s
Oct 11 18:47:57.344: INFO: Pod "downwardapi-volume-6dae6665-0ed8-4c83-a824-0dec8ffd1de9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014620029s
STEP: Saw pod success
Oct 11 18:47:57.344: INFO: Pod "downwardapi-volume-6dae6665-0ed8-4c83-a824-0dec8ffd1de9" satisfied condition "success or failure"
Oct 11 18:47:57.348: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod downwardapi-volume-6dae6665-0ed8-4c83-a824-0dec8ffd1de9 container client-container: <nil>
STEP: delete the pod
Oct 11 18:47:57.373: INFO: Waiting for pod downwardapi-volume-6dae6665-0ed8-4c83-a824-0dec8ffd1de9 to disappear
Oct 11 18:47:57.379: INFO: Pod downwardapi-volume-6dae6665-0ed8-4c83-a824-0dec8ffd1de9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:47:57.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6213" for this suite.
Oct 11 18:48:03.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:48:03.545: INFO: namespace downward-api-6213 deletion completed in 6.160275899s

• [SLOW TEST:10.263 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:48:03.545: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Oct 11 18:48:03.593: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-5709" to be "success or failure"
Oct 11 18:48:03.598: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.96076ms
Oct 11 18:48:05.603: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010048596s
Oct 11 18:48:07.608: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014981142s
STEP: Saw pod success
Oct 11 18:48:07.608: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Oct 11 18:48:07.612: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Oct 11 18:48:07.640: INFO: Waiting for pod pod-host-path-test to disappear
Oct 11 18:48:07.644: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:48:07.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-5709" for this suite.
Oct 11 18:48:13.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:48:13.796: INFO: namespace hostpath-5709 deletion completed in 6.14658399s

• [SLOW TEST:10.251 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:48:13.797: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Oct 11 18:48:13.835: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 18:48:16.856: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:48:28.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9177" for this suite.
Oct 11 18:48:34.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:48:34.516: INFO: namespace crd-publish-openapi-9177 deletion completed in 6.147320909s

• [SLOW TEST:20.719 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:48:34.516: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 18:48:34.602: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Oct 11 18:48:37.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 --namespace=crd-publish-openapi-127 create -f -'
Oct 11 18:48:38.007: INFO: stderr: ""
Oct 11 18:48:38.007: INFO: stdout: "e2e-test-crd-publish-openapi-1577-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Oct 11 18:48:38.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 --namespace=crd-publish-openapi-127 delete e2e-test-crd-publish-openapi-1577-crds test-cr'
Oct 11 18:48:38.124: INFO: stderr: ""
Oct 11 18:48:38.124: INFO: stdout: "e2e-test-crd-publish-openapi-1577-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Oct 11 18:48:38.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 --namespace=crd-publish-openapi-127 apply -f -'
Oct 11 18:48:38.285: INFO: stderr: ""
Oct 11 18:48:38.285: INFO: stdout: "e2e-test-crd-publish-openapi-1577-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Oct 11 18:48:38.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 --namespace=crd-publish-openapi-127 delete e2e-test-crd-publish-openapi-1577-crds test-cr'
Oct 11 18:48:38.366: INFO: stderr: ""
Oct 11 18:48:38.366: INFO: stdout: "e2e-test-crd-publish-openapi-1577-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Oct 11 18:48:38.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 explain e2e-test-crd-publish-openapi-1577-crds'
Oct 11 18:48:38.560: INFO: stderr: ""
Oct 11 18:48:38.560: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1577-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:48:42.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-127" for this suite.
Oct 11 18:48:48.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:48:48.217: INFO: namespace crd-publish-openapi-127 deletion completed in 6.144503977s

• [SLOW TEST:13.702 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:48:48.218: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1011 18:49:28.311082      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 11 18:49:28.311: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:49:28.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9503" for this suite.
Oct 11 18:49:34.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:49:34.504: INFO: namespace gc-9503 deletion completed in 6.185186297s

• [SLOW TEST:46.287 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:49:34.505: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 18:49:34.553: INFO: Waiting up to 5m0s for pod "busybox-user-65534-e7a3255b-9d67-4d5e-8c6f-4d238db357fe" in namespace "security-context-test-7070" to be "success or failure"
Oct 11 18:49:34.560: INFO: Pod "busybox-user-65534-e7a3255b-9d67-4d5e-8c6f-4d238db357fe": Phase="Pending", Reason="", readiness=false. Elapsed: 7.199731ms
Oct 11 18:49:36.565: INFO: Pod "busybox-user-65534-e7a3255b-9d67-4d5e-8c6f-4d238db357fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012513058s
Oct 11 18:49:36.565: INFO: Pod "busybox-user-65534-e7a3255b-9d67-4d5e-8c6f-4d238db357fe" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:49:36.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7070" for this suite.
Oct 11 18:49:42.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:49:42.726: INFO: namespace security-context-test-7070 deletion completed in 6.154997609s

• [SLOW TEST:8.221 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:49:42.726: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-5719
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 11 18:49:42.768: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 11 18:50:04.910: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.3.124:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5719 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 11 18:50:04.910: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 18:50:05.109: INFO: Found all expected endpoints: [netserver-0]
Oct 11 18:50:05.114: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.5.49:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5719 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 11 18:50:05.114: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 18:50:05.369: INFO: Found all expected endpoints: [netserver-1]
Oct 11 18:50:05.374: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.4.104:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5719 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 11 18:50:05.374: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 18:50:05.616: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:50:05.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5719" for this suite.
Oct 11 18:50:17.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:50:17.774: INFO: namespace pod-network-test-5719 deletion completed in 12.150793043s

• [SLOW TEST:35.047 seconds]
[sig-network] Networking
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:50:17.774: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 11 18:50:19.846: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:50:19.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9106" for this suite.
Oct 11 18:50:25.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:50:26.023: INFO: namespace container-runtime-9106 deletion completed in 6.146368225s

• [SLOW TEST:8.249 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:50:26.024: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-z8xp
STEP: Creating a pod to test atomic-volume-subpath
Oct 11 18:50:26.092: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-z8xp" in namespace "subpath-5396" to be "success or failure"
Oct 11 18:50:26.097: INFO: Pod "pod-subpath-test-projected-z8xp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.511392ms
Oct 11 18:50:28.103: INFO: Pod "pod-subpath-test-projected-z8xp": Phase="Running", Reason="", readiness=true. Elapsed: 2.010423702s
Oct 11 18:50:30.107: INFO: Pod "pod-subpath-test-projected-z8xp": Phase="Running", Reason="", readiness=true. Elapsed: 4.015296184s
Oct 11 18:50:32.112: INFO: Pod "pod-subpath-test-projected-z8xp": Phase="Running", Reason="", readiness=true. Elapsed: 6.020149992s
Oct 11 18:50:34.117: INFO: Pod "pod-subpath-test-projected-z8xp": Phase="Running", Reason="", readiness=true. Elapsed: 8.024868247s
Oct 11 18:50:36.122: INFO: Pod "pod-subpath-test-projected-z8xp": Phase="Running", Reason="", readiness=true. Elapsed: 10.029645574s
Oct 11 18:50:38.127: INFO: Pod "pod-subpath-test-projected-z8xp": Phase="Running", Reason="", readiness=true. Elapsed: 12.034587071s
Oct 11 18:50:40.131: INFO: Pod "pod-subpath-test-projected-z8xp": Phase="Running", Reason="", readiness=true. Elapsed: 14.039369924s
Oct 11 18:50:42.139: INFO: Pod "pod-subpath-test-projected-z8xp": Phase="Running", Reason="", readiness=true. Elapsed: 16.046607714s
Oct 11 18:50:44.144: INFO: Pod "pod-subpath-test-projected-z8xp": Phase="Running", Reason="", readiness=true. Elapsed: 18.051707558s
Oct 11 18:50:46.149: INFO: Pod "pod-subpath-test-projected-z8xp": Phase="Running", Reason="", readiness=true. Elapsed: 20.056943617s
Oct 11 18:50:48.154: INFO: Pod "pod-subpath-test-projected-z8xp": Phase="Running", Reason="", readiness=true. Elapsed: 22.06208767s
Oct 11 18:50:50.160: INFO: Pod "pod-subpath-test-projected-z8xp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.068221248s
STEP: Saw pod success
Oct 11 18:50:50.160: INFO: Pod "pod-subpath-test-projected-z8xp" satisfied condition "success or failure"
Oct 11 18:50:50.165: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-subpath-test-projected-z8xp container test-container-subpath-projected-z8xp: <nil>
STEP: delete the pod
Oct 11 18:50:50.207: INFO: Waiting for pod pod-subpath-test-projected-z8xp to disappear
Oct 11 18:50:50.211: INFO: Pod pod-subpath-test-projected-z8xp no longer exists
STEP: Deleting pod pod-subpath-test-projected-z8xp
Oct 11 18:50:50.211: INFO: Deleting pod "pod-subpath-test-projected-z8xp" in namespace "subpath-5396"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:50:50.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5396" for this suite.
Oct 11 18:50:56.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:50:56.373: INFO: namespace subpath-5396 deletion completed in 6.151867399s

• [SLOW TEST:30.349 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:50:56.373: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 11 18:50:57.231: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 11 18:50:59.244: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706416657, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706416657, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706416657, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706416657, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 11 18:51:02.294: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:51:02.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8151" for this suite.
Oct 11 18:51:14.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:51:14.513: INFO: namespace webhook-8151 deletion completed in 12.148973749s
STEP: Destroying namespace "webhook-8151-markers" for this suite.
Oct 11 18:51:20.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:51:20.673: INFO: namespace webhook-8151-markers deletion completed in 6.160355854s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.322 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:51:20.695: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-481dc674-6113-47e8-8955-bddb420652f1
STEP: Creating a pod to test consume secrets
Oct 11 18:51:20.748: INFO: Waiting up to 5m0s for pod "pod-secrets-1316ae8c-b044-4e96-9713-20f902af4c49" in namespace "secrets-6878" to be "success or failure"
Oct 11 18:51:20.753: INFO: Pod "pod-secrets-1316ae8c-b044-4e96-9713-20f902af4c49": Phase="Pending", Reason="", readiness=false. Elapsed: 4.611928ms
Oct 11 18:51:22.758: INFO: Pod "pod-secrets-1316ae8c-b044-4e96-9713-20f902af4c49": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009989822s
Oct 11 18:51:24.776: INFO: Pod "pod-secrets-1316ae8c-b044-4e96-9713-20f902af4c49": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027838504s
STEP: Saw pod success
Oct 11 18:51:24.776: INFO: Pod "pod-secrets-1316ae8c-b044-4e96-9713-20f902af4c49" satisfied condition "success or failure"
Oct 11 18:51:24.794: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod pod-secrets-1316ae8c-b044-4e96-9713-20f902af4c49 container secret-volume-test: <nil>
STEP: delete the pod
Oct 11 18:51:24.827: INFO: Waiting for pod pod-secrets-1316ae8c-b044-4e96-9713-20f902af4c49 to disappear
Oct 11 18:51:24.835: INFO: Pod pod-secrets-1316ae8c-b044-4e96-9713-20f902af4c49 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:51:24.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6878" for this suite.
Oct 11 18:51:30.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:51:30.991: INFO: namespace secrets-6878 deletion completed in 6.149019145s

• [SLOW TEST:10.296 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:51:30.991: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-791bc470-ea78-4127-b8c6-71c47ec1d9df in namespace container-probe-8887
Oct 11 18:51:33.049: INFO: Started pod test-webserver-791bc470-ea78-4127-b8c6-71c47ec1d9df in namespace container-probe-8887
STEP: checking the pod's current state and verifying that restartCount is present
Oct 11 18:51:33.053: INFO: Initial restart count of pod test-webserver-791bc470-ea78-4127-b8c6-71c47ec1d9df is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:55:33.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8887" for this suite.
Oct 11 18:55:39.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:55:39.887: INFO: namespace container-probe-8887 deletion completed in 6.162894379s

• [SLOW TEST:248.896 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:55:39.887: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-b004bb55-9747-49f6-a393-5917d0fd7b00
STEP: Creating a pod to test consume configMaps
Oct 11 18:55:39.941: INFO: Waiting up to 5m0s for pod "pod-configmaps-bf08de6b-256c-4844-9fec-f76e691f6a53" in namespace "configmap-1031" to be "success or failure"
Oct 11 18:55:39.946: INFO: Pod "pod-configmaps-bf08de6b-256c-4844-9fec-f76e691f6a53": Phase="Pending", Reason="", readiness=false. Elapsed: 5.530256ms
Oct 11 18:55:41.951: INFO: Pod "pod-configmaps-bf08de6b-256c-4844-9fec-f76e691f6a53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010291225s
Oct 11 18:55:43.956: INFO: Pod "pod-configmaps-bf08de6b-256c-4844-9fec-f76e691f6a53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015069955s
STEP: Saw pod success
Oct 11 18:55:43.956: INFO: Pod "pod-configmaps-bf08de6b-256c-4844-9fec-f76e691f6a53" satisfied condition "success or failure"
Oct 11 18:55:43.960: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod pod-configmaps-bf08de6b-256c-4844-9fec-f76e691f6a53 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 11 18:55:43.995: INFO: Waiting for pod pod-configmaps-bf08de6b-256c-4844-9fec-f76e691f6a53 to disappear
Oct 11 18:55:43.999: INFO: Pod pod-configmaps-bf08de6b-256c-4844-9fec-f76e691f6a53 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:55:43.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1031" for this suite.
Oct 11 18:55:50.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:55:50.154: INFO: namespace configmap-1031 deletion completed in 6.14968434s

• [SLOW TEST:10.267 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:55:50.154: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:55:50.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7258" for this suite.
Oct 11 18:56:02.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:56:02.383: INFO: namespace pods-7258 deletion completed in 12.167508595s

• [SLOW TEST:12.229 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:56:02.383: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Oct 11 18:56:02.419: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-158339303 proxy --unix-socket=/tmp/kubectl-proxy-unix354249822/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:56:02.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7242" for this suite.
Oct 11 18:56:08.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:56:08.634: INFO: namespace kubectl-7242 deletion completed in 6.154246289s

• [SLOW TEST:6.251 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:56:08.634: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Oct 11 18:56:08.674: INFO: Waiting up to 1m0s for all nodes to be ready
Oct 11 18:57:08.694: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 18:57:08.698: INFO: Starting informer...
STEP: Starting pods...
Oct 11 18:57:08.919: INFO: Pod1 is running on ip-172-31-5-54.eu-west-3.compute.internal. Tainting Node
Oct 11 18:57:11.141: INFO: Pod2 is running on ip-172-31-5-54.eu-west-3.compute.internal. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Oct 11 18:57:20.187: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Oct 11 18:57:40.182: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:57:40.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-2513" for this suite.
Oct 11 18:57:46.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:57:46.359: INFO: namespace taint-multiple-pods-2513 deletion completed in 6.156492886s

• [SLOW TEST:97.724 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:57:46.359: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 18:57:46.398: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:57:52.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9670" for this suite.
Oct 11 18:57:58.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:57:58.841: INFO: namespace custom-resource-definition-9670 deletion completed in 6.172322644s

• [SLOW TEST:12.482 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:57:58.841: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:58:02.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8629" for this suite.
Oct 11 18:58:46.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:58:47.080: INFO: namespace kubelet-test-8629 deletion completed in 44.153323494s

• [SLOW TEST:48.239 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:58:47.081: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-0109969d-1eba-4c4b-bd02-eba73db81f58
STEP: Creating a pod to test consume secrets
Oct 11 18:58:47.139: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2acb7344-e48f-4e0a-b4b8-074a6baf2179" in namespace "projected-2287" to be "success or failure"
Oct 11 18:58:47.144: INFO: Pod "pod-projected-secrets-2acb7344-e48f-4e0a-b4b8-074a6baf2179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.833951ms
Oct 11 18:58:49.148: INFO: Pod "pod-projected-secrets-2acb7344-e48f-4e0a-b4b8-074a6baf2179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009341494s
Oct 11 18:58:51.153: INFO: Pod "pod-projected-secrets-2acb7344-e48f-4e0a-b4b8-074a6baf2179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014190264s
STEP: Saw pod success
Oct 11 18:58:51.153: INFO: Pod "pod-projected-secrets-2acb7344-e48f-4e0a-b4b8-074a6baf2179" satisfied condition "success or failure"
Oct 11 18:58:51.157: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-projected-secrets-2acb7344-e48f-4e0a-b4b8-074a6baf2179 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 11 18:58:51.183: INFO: Waiting for pod pod-projected-secrets-2acb7344-e48f-4e0a-b4b8-074a6baf2179 to disappear
Oct 11 18:58:51.190: INFO: Pod pod-projected-secrets-2acb7344-e48f-4e0a-b4b8-074a6baf2179 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:58:51.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2287" for this suite.
Oct 11 18:58:57.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:58:57.344: INFO: namespace projected-2287 deletion completed in 6.148647076s

• [SLOW TEST:10.263 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:58:57.344: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2778.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2778.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2778.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2778.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2778.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2778.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2778.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2778.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2778.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2778.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2778.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 95.120.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.120.95_udp@PTR;check="$$(dig +tcp +noall +answer +search 95.120.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.120.95_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2778.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2778.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2778.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2778.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2778.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2778.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2778.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2778.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2778.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2778.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2778.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 95.120.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.120.95_udp@PTR;check="$$(dig +tcp +noall +answer +search 95.120.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.120.95_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 11 18:59:01.468: INFO: Unable to read wheezy_udp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:01.474: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:01.480: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:01.486: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:01.526: INFO: Unable to read jessie_udp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:01.531: INFO: Unable to read jessie_tcp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:01.537: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:01.542: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:01.581: INFO: Lookups using dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff failed for: [wheezy_udp@dns-test-service.dns-2778.svc.cluster.local wheezy_tcp@dns-test-service.dns-2778.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local jessie_udp@dns-test-service.dns-2778.svc.cluster.local jessie_tcp@dns-test-service.dns-2778.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local]

Oct 11 18:59:06.590: INFO: Unable to read wheezy_udp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:06.598: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:06.603: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:06.609: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:06.659: INFO: Unable to read jessie_udp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:06.664: INFO: Unable to read jessie_tcp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:06.670: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:06.675: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:06.705: INFO: Lookups using dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff failed for: [wheezy_udp@dns-test-service.dns-2778.svc.cluster.local wheezy_tcp@dns-test-service.dns-2778.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local jessie_udp@dns-test-service.dns-2778.svc.cluster.local jessie_tcp@dns-test-service.dns-2778.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local]

Oct 11 18:59:11.586: INFO: Unable to read wheezy_udp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:11.591: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:11.597: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:11.602: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:11.637: INFO: Unable to read jessie_udp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:11.642: INFO: Unable to read jessie_tcp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:11.647: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:11.652: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:11.683: INFO: Lookups using dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff failed for: [wheezy_udp@dns-test-service.dns-2778.svc.cluster.local wheezy_tcp@dns-test-service.dns-2778.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local jessie_udp@dns-test-service.dns-2778.svc.cluster.local jessie_tcp@dns-test-service.dns-2778.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local]

Oct 11 18:59:16.587: INFO: Unable to read wheezy_udp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:16.592: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:16.597: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:16.602: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:16.644: INFO: Unable to read jessie_udp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:16.649: INFO: Unable to read jessie_tcp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:16.654: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:16.659: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:16.689: INFO: Lookups using dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff failed for: [wheezy_udp@dns-test-service.dns-2778.svc.cluster.local wheezy_tcp@dns-test-service.dns-2778.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local jessie_udp@dns-test-service.dns-2778.svc.cluster.local jessie_tcp@dns-test-service.dns-2778.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local]

Oct 11 18:59:21.587: INFO: Unable to read wheezy_udp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:21.592: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:21.598: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:21.603: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:21.644: INFO: Unable to read jessie_udp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:21.649: INFO: Unable to read jessie_tcp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:21.654: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:21.659: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:21.688: INFO: Lookups using dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff failed for: [wheezy_udp@dns-test-service.dns-2778.svc.cluster.local wheezy_tcp@dns-test-service.dns-2778.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local jessie_udp@dns-test-service.dns-2778.svc.cluster.local jessie_tcp@dns-test-service.dns-2778.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local]

Oct 11 18:59:26.587: INFO: Unable to read wheezy_udp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:26.592: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:26.597: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:26.604: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:26.652: INFO: Unable to read jessie_udp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:26.657: INFO: Unable to read jessie_tcp@dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:26.662: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:26.667: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local from pod dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff: the server could not find the requested resource (get pods dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff)
Oct 11 18:59:26.697: INFO: Lookups using dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff failed for: [wheezy_udp@dns-test-service.dns-2778.svc.cluster.local wheezy_tcp@dns-test-service.dns-2778.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local jessie_udp@dns-test-service.dns-2778.svc.cluster.local jessie_tcp@dns-test-service.dns-2778.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2778.svc.cluster.local]

Oct 11 18:59:31.694: INFO: DNS probes using dns-2778/dns-test-629fcbca-57aa-4c4f-98f2-06d37234f7ff succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:59:31.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2778" for this suite.
Oct 11 18:59:37.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:59:37.949: INFO: namespace dns-2778 deletion completed in 6.153783023s

• [SLOW TEST:40.605 seconds]
[sig-network] DNS
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:59:37.950: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 11 18:59:38.331: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 11 18:59:40.345: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706417178, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706417178, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706417178, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706417178, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 11 18:59:43.366: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:59:43.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9346" for this suite.
Oct 11 18:59:49.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:59:49.722: INFO: namespace webhook-9346 deletion completed in 6.143605962s
STEP: Destroying namespace "webhook-9346-markers" for this suite.
Oct 11 18:59:55.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 18:59:55.871: INFO: namespace webhook-9346-markers deletion completed in 6.148152834s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.942 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 18:59:55.892: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-b4f1588e-697f-45bd-8e80-214d1558220f
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 18:59:55.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9900" for this suite.
Oct 11 19:00:01.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:00:02.091: INFO: namespace secrets-9900 deletion completed in 6.157847046s

• [SLOW TEST:6.200 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:00:02.092: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 11 19:00:02.144: INFO: Waiting up to 5m0s for pod "downwardapi-volume-67c1ada0-c717-4715-9b33-b2641122c79a" in namespace "projected-6226" to be "success or failure"
Oct 11 19:00:02.150: INFO: Pod "downwardapi-volume-67c1ada0-c717-4715-9b33-b2641122c79a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.905798ms
Oct 11 19:00:04.155: INFO: Pod "downwardapi-volume-67c1ada0-c717-4715-9b33-b2641122c79a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011917228s
Oct 11 19:00:06.160: INFO: Pod "downwardapi-volume-67c1ada0-c717-4715-9b33-b2641122c79a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016912468s
STEP: Saw pod success
Oct 11 19:00:06.161: INFO: Pod "downwardapi-volume-67c1ada0-c717-4715-9b33-b2641122c79a" satisfied condition "success or failure"
Oct 11 19:00:06.165: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod downwardapi-volume-67c1ada0-c717-4715-9b33-b2641122c79a container client-container: <nil>
STEP: delete the pod
Oct 11 19:00:06.197: INFO: Waiting for pod downwardapi-volume-67c1ada0-c717-4715-9b33-b2641122c79a to disappear
Oct 11 19:00:06.202: INFO: Pod downwardapi-volume-67c1ada0-c717-4715-9b33-b2641122c79a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:00:06.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6226" for this suite.
Oct 11 19:00:12.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:00:12.363: INFO: namespace projected-6226 deletion completed in 6.155079065s

• [SLOW TEST:10.270 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:00:12.365: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 19:00:12.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 create -f - --namespace=kubectl-2491'
Oct 11 19:00:12.761: INFO: stderr: ""
Oct 11 19:00:12.761: INFO: stdout: "replicationcontroller/redis-master created\n"
Oct 11 19:00:12.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 create -f - --namespace=kubectl-2491'
Oct 11 19:00:12.923: INFO: stderr: ""
Oct 11 19:00:12.923: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 11 19:00:13.928: INFO: Selector matched 1 pods for map[app:redis]
Oct 11 19:00:13.928: INFO: Found 0 / 1
Oct 11 19:00:14.928: INFO: Selector matched 1 pods for map[app:redis]
Oct 11 19:00:14.928: INFO: Found 1 / 1
Oct 11 19:00:14.928: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 11 19:00:14.933: INFO: Selector matched 1 pods for map[app:redis]
Oct 11 19:00:14.933: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 11 19:00:14.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 describe pod redis-master-4cx5z --namespace=kubectl-2491'
Oct 11 19:00:15.026: INFO: stderr: ""
Oct 11 19:00:15.026: INFO: stdout: "Name:         redis-master-4cx5z\nNamespace:    kubectl-2491\nPriority:     0\nNode:         ip-172-31-5-54.eu-west-3.compute.internal/172.31.5.54\nStart Time:   Fri, 11 Oct 2019 19:00:12 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  cni.projectcalico.org/podIP: 10.244.4.114/32\nStatus:       Running\nIP:           10.244.4.114\nIPs:\n  IP:           10.244.4.114\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://8145e25d79e69e1f1bb1fc10721faa01f92938418dd4b06e7812b4eeb84850b7\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 11 Oct 2019 19:00:14 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-hxvzt (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-hxvzt:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-hxvzt\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                                                Message\n  ----    ------     ----       ----                                                -------\n  Normal  Scheduled  <unknown>  default-scheduler                                   Successfully assigned kubectl-2491/redis-master-4cx5z to ip-172-31-5-54.eu-west-3.compute.internal\n  Normal  Pulled     2s         kubelet, ip-172-31-5-54.eu-west-3.compute.internal  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    2s         kubelet, ip-172-31-5-54.eu-west-3.compute.internal  Created container redis-master\n  Normal  Started    1s         kubelet, ip-172-31-5-54.eu-west-3.compute.internal  Started container redis-master\n"
Oct 11 19:00:15.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 describe rc redis-master --namespace=kubectl-2491'
Oct 11 19:00:15.112: INFO: stderr: ""
Oct 11 19:00:15.112: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-2491\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-4cx5z\n"
Oct 11 19:00:15.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 describe service redis-master --namespace=kubectl-2491'
Oct 11 19:00:15.191: INFO: stderr: ""
Oct 11 19:00:15.191: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-2491\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.106.152.75\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.4.114:6379\nSession Affinity:  None\nEvents:            <none>\n"
Oct 11 19:00:15.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 describe node ip-172-31-1-25.eu-west-3.compute.internal'
Oct 11 19:00:15.288: INFO: stderr: ""
Oct 11 19:00:15.288: INFO: stdout: "Name:               ip-172-31-1-25.eu-west-3.compute.internal\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=t3.medium\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-west-3\n                    failure-domain.beta.kubernetes.io/zone=eu-west-3a\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-1-25\n                    kubernetes.io/os=linux\n                    machine-controller/owned-by=5e7636e8-73bb-41f3-aa2c-fcdeec4bb63b\n                    workerset=k8s-conformance-pool1\nAnnotations:        cluster.k8s.io/machine: kube-system/k8s-conformance-pool1-6768cbc858-4nzch\n                    flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"66:f2:4e:ff:a4:d2\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 172.31.1.25\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 11 Oct 2019 17:26:31 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Fri, 11 Oct 2019 19:00:04 +0000   Fri, 11 Oct 2019 17:26:31 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Fri, 11 Oct 2019 19:00:04 +0000   Fri, 11 Oct 2019 17:26:31 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Fri, 11 Oct 2019 19:00:04 +0000   Fri, 11 Oct 2019 17:26:31 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Fri, 11 Oct 2019 19:00:04 +0000   Fri, 11 Oct 2019 17:26:41 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:   172.31.1.25\n  ExternalIP:   35.180.123.192\n  Hostname:     ip-172-31-1-25.eu-west-3.compute.internal\n  InternalDNS:  ip-172-31-1-25.eu-west-3.compute.internal\n  ExternalDNS:  ec2-35-180-123-192.eu-west-3.compute.amazonaws.com\nCapacity:\n attachable-volumes-aws-ebs:  25\n cpu:                         2\n ephemeral-storage:           50758604Ki\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      3978636Ki\n pods:                        110\nAllocatable:\n attachable-volumes-aws-ebs:  25\n cpu:                         1800m\n ephemeral-storage:           44631645721\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      3671436Ki\n pods:                        110\nSystem Info:\n Machine ID:                 ec2d4353e60f7aad596661b5c585ce85\n System UUID:                EC2D4353-E60F-7AAD-5966-61B5C585CE85\n Boot ID:                    bc719d12-1799-4837-b42e-76cc419a8ef8\n Kernel Version:             4.15.0-1051-aws\n OS Image:                   Ubuntu 18.04.3 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.2\n Kubelet Version:            v1.16.1\n Kube-Proxy Version:         v1.16.1\nPodCIDR:                     10.244.5.0/24\nPodCIDRs:                    10.244.5.0/24\nProviderID:                  aws:///eu-west-3a/i-0c925f2cdab428403\nNon-terminated Pods:         (4 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                canal-jn9ph                                                250m (13%)    0 (0%)      0 (0%)           0 (0%)         93m\n  kube-system                kube-proxy-m86rm                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         93m\n  sonobuoy                   sonobuoy-e2e-job-56f76d39d0764ff1                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         92m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-8223689078594c46-86r77    0 (0%)        0 (0%)      0 (0%)           0 (0%)         92m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                    Requests    Limits\n  --------                    --------    ------\n  cpu                         250m (13%)  0 (0%)\n  memory                      0 (0%)      0 (0%)\n  ephemeral-storage           0 (0%)      0 (0%)\n  attachable-volumes-aws-ebs  0           0\nEvents:                       <none>\n"
Oct 11 19:00:15.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 describe namespace kubectl-2491'
Oct 11 19:00:15.360: INFO: stderr: ""
Oct 11 19:00:15.360: INFO: stdout: "Name:         kubectl-2491\nLabels:       e2e-framework=kubectl\n              e2e-run=a199f19c-3e49-46f6-8dc9-dda61b9c246e\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:00:15.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2491" for this suite.
Oct 11 19:00:27.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:00:27.512: INFO: namespace kubectl-2491 deletion completed in 12.146430361s

• [SLOW TEST:15.147 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:00:27.512: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-db3a2cc5-abbd-4896-b2e4-d7e86791bbf0
STEP: Creating a pod to test consume configMaps
Oct 11 19:00:27.581: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-24afb324-d01e-4db8-aa6a-773a3fb6cec1" in namespace "projected-4531" to be "success or failure"
Oct 11 19:00:27.586: INFO: Pod "pod-projected-configmaps-24afb324-d01e-4db8-aa6a-773a3fb6cec1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.976678ms
Oct 11 19:00:29.591: INFO: Pod "pod-projected-configmaps-24afb324-d01e-4db8-aa6a-773a3fb6cec1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00970228s
Oct 11 19:00:31.595: INFO: Pod "pod-projected-configmaps-24afb324-d01e-4db8-aa6a-773a3fb6cec1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014131815s
STEP: Saw pod success
Oct 11 19:00:31.595: INFO: Pod "pod-projected-configmaps-24afb324-d01e-4db8-aa6a-773a3fb6cec1" satisfied condition "success or failure"
Oct 11 19:00:31.600: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-projected-configmaps-24afb324-d01e-4db8-aa6a-773a3fb6cec1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 11 19:00:31.634: INFO: Waiting for pod pod-projected-configmaps-24afb324-d01e-4db8-aa6a-773a3fb6cec1 to disappear
Oct 11 19:00:31.638: INFO: Pod pod-projected-configmaps-24afb324-d01e-4db8-aa6a-773a3fb6cec1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:00:31.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4531" for this suite.
Oct 11 19:00:37.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:00:37.796: INFO: namespace projected-4531 deletion completed in 6.152464372s

• [SLOW TEST:10.284 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:00:37.797: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-8236
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-8236
STEP: creating replication controller externalsvc in namespace services-8236
I1011 19:00:37.887994      19 runners.go:184] Created replication controller with name: externalsvc, namespace: services-8236, replica count: 2
I1011 19:00:40.938679      19 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Oct 11 19:00:40.969: INFO: Creating new exec pod
Oct 11 19:00:45.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=services-8236 execpodrh8rq -- /bin/sh -x -c nslookup clusterip-service'
Oct 11 19:00:45.310: INFO: stderr: "+ nslookup clusterip-service\n"
Oct 11 19:00:45.310: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-8236.svc.cluster.local\tcanonical name = externalsvc.services-8236.svc.cluster.local.\nName:\texternalsvc.services-8236.svc.cluster.local\nAddress: 10.107.79.119\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8236, will wait for the garbage collector to delete the pods
Oct 11 19:00:45.375: INFO: Deleting ReplicationController externalsvc took: 10.868291ms
Oct 11 19:00:45.775: INFO: Terminating ReplicationController externalsvc pods took: 400.179296ms
Oct 11 19:01:00.309: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:01:00.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8236" for this suite.
Oct 11 19:01:06.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:01:06.498: INFO: namespace services-8236 deletion completed in 6.155437691s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:28.701 seconds]
[sig-network] Services
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:01:06.499: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 19:01:06.535: INFO: Creating deployment "test-recreate-deployment"
Oct 11 19:01:06.543: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Oct 11 19:01:06.553: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Oct 11 19:01:08.562: INFO: Waiting deployment "test-recreate-deployment" to complete
Oct 11 19:01:08.566: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706417266, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706417266, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706417266, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706417266, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-68fc85c7bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 11 19:01:10.571: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Oct 11 19:01:10.581: INFO: Updating deployment test-recreate-deployment
Oct 11 19:01:10.581: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Oct 11 19:01:10.650: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-2175 /apis/apps/v1/namespaces/deployment-2175/deployments/test-recreate-deployment d9581f54-3f51-4eb2-926a-b766a5d17632 27260 2 2019-10-11 19:01:06 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0039b3d68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-10-11 19:01:10 +0000 UTC,LastTransitionTime:2019-10-11 19:01:10 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2019-10-11 19:01:10 +0000 UTC,LastTransitionTime:2019-10-11 19:01:06 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Oct 11 19:01:10.655: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-2175 /apis/apps/v1/namespaces/deployment-2175/replicasets/test-recreate-deployment-5f94c574ff 0cc78f57-fe63-46ae-ac78-2fde1613e4b0 27259 1 2019-10-11 19:01:10 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment d9581f54-3f51-4eb2-926a-b766a5d17632 0xc000322ed7 0xc000322ed8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000323388 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 11 19:01:10.655: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Oct 11 19:01:10.655: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-2175 /apis/apps/v1/namespaces/deployment-2175/replicasets/test-recreate-deployment-68fc85c7bb dd8b572c-5e1a-4b65-859d-a0a02aba37b2 27246 2 2019-10-11 19:01:06 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment d9581f54-3f51-4eb2-926a-b766a5d17632 0xc000323847 0xc000323848}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0003238f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 11 19:01:10.659: INFO: Pod "test-recreate-deployment-5f94c574ff-fxqvq" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-fxqvq test-recreate-deployment-5f94c574ff- deployment-2175 /api/v1/namespaces/deployment-2175/pods/test-recreate-deployment-5f94c574ff-fxqvq 15b9a765-6447-473c-be9c-4ad3a2b5b224 27257 0 2019-10-11 19:01:10 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff 0cc78f57-fe63-46ae-ac78-2fde1613e4b0 0xc002fd0757 0xc002fd0758}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-klw9j,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-klw9j,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-klw9j,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-5-54.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 19:01:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 19:01:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 19:01:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 19:01:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.5.54,PodIP:,StartTime:2019-10-11 19:01:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:01:10.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2175" for this suite.
Oct 11 19:01:16.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:01:16.821: INFO: namespace deployment-2175 deletion completed in 6.156446386s

• [SLOW TEST:10.323 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:01:16.822: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Oct 11 19:01:16.873: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7662 /api/v1/namespaces/watch-7662/configmaps/e2e-watch-test-configmap-a 420a8a7c-0337-4088-922e-6933447ae94a 27307 0 2019-10-11 19:01:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 11 19:01:16.873: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7662 /api/v1/namespaces/watch-7662/configmaps/e2e-watch-test-configmap-a 420a8a7c-0337-4088-922e-6933447ae94a 27307 0 2019-10-11 19:01:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Oct 11 19:01:26.884: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7662 /api/v1/namespaces/watch-7662/configmaps/e2e-watch-test-configmap-a 420a8a7c-0337-4088-922e-6933447ae94a 27333 0 2019-10-11 19:01:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 11 19:01:26.884: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7662 /api/v1/namespaces/watch-7662/configmaps/e2e-watch-test-configmap-a 420a8a7c-0337-4088-922e-6933447ae94a 27333 0 2019-10-11 19:01:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Oct 11 19:01:36.894: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7662 /api/v1/namespaces/watch-7662/configmaps/e2e-watch-test-configmap-a 420a8a7c-0337-4088-922e-6933447ae94a 27359 0 2019-10-11 19:01:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 11 19:01:36.894: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7662 /api/v1/namespaces/watch-7662/configmaps/e2e-watch-test-configmap-a 420a8a7c-0337-4088-922e-6933447ae94a 27359 0 2019-10-11 19:01:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Oct 11 19:01:46.907: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7662 /api/v1/namespaces/watch-7662/configmaps/e2e-watch-test-configmap-a 420a8a7c-0337-4088-922e-6933447ae94a 27385 0 2019-10-11 19:01:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 11 19:01:46.907: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7662 /api/v1/namespaces/watch-7662/configmaps/e2e-watch-test-configmap-a 420a8a7c-0337-4088-922e-6933447ae94a 27385 0 2019-10-11 19:01:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Oct 11 19:01:56.915: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7662 /api/v1/namespaces/watch-7662/configmaps/e2e-watch-test-configmap-b 78803936-9005-42d9-a9dd-64f721974f17 27411 0 2019-10-11 19:01:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 11 19:01:56.915: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7662 /api/v1/namespaces/watch-7662/configmaps/e2e-watch-test-configmap-b 78803936-9005-42d9-a9dd-64f721974f17 27411 0 2019-10-11 19:01:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Oct 11 19:02:06.926: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7662 /api/v1/namespaces/watch-7662/configmaps/e2e-watch-test-configmap-b 78803936-9005-42d9-a9dd-64f721974f17 27439 0 2019-10-11 19:01:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 11 19:02:06.926: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7662 /api/v1/namespaces/watch-7662/configmaps/e2e-watch-test-configmap-b 78803936-9005-42d9-a9dd-64f721974f17 27439 0 2019-10-11 19:01:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:02:16.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7662" for this suite.
Oct 11 19:02:22.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:02:23.084: INFO: namespace watch-7662 deletion completed in 6.149918493s

• [SLOW TEST:66.262 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:02:23.085: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 19:02:23.146: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Oct 11 19:02:23.160: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:23.160: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:23.160: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:23.163: INFO: Number of nodes with available pods: 0
Oct 11 19:02:23.163: INFO: Node ip-172-31-1-25.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:02:24.170: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:24.170: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:24.170: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:24.174: INFO: Number of nodes with available pods: 0
Oct 11 19:02:24.175: INFO: Node ip-172-31-1-25.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:02:25.170: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:25.170: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:25.170: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:25.174: INFO: Number of nodes with available pods: 0
Oct 11 19:02:25.174: INFO: Node ip-172-31-1-25.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:02:26.170: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:26.170: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:26.170: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:26.176: INFO: Number of nodes with available pods: 3
Oct 11 19:02:26.176: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Oct 11 19:02:26.211: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:26.211: INFO: Wrong image for pod: daemon-set-plmjj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:26.211: INFO: Wrong image for pod: daemon-set-pngmz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:26.218: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:26.218: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:26.218: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:27.223: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:27.223: INFO: Wrong image for pod: daemon-set-plmjj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:27.223: INFO: Wrong image for pod: daemon-set-pngmz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:27.229: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:27.229: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:27.229: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:28.229: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:28.229: INFO: Wrong image for pod: daemon-set-plmjj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:28.229: INFO: Wrong image for pod: daemon-set-pngmz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:28.260: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:28.260: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:28.260: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:29.223: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:29.223: INFO: Wrong image for pod: daemon-set-plmjj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:29.223: INFO: Pod daemon-set-plmjj is not available
Oct 11 19:02:29.223: INFO: Wrong image for pod: daemon-set-pngmz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:29.229: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:29.229: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:29.229: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:30.224: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:30.224: INFO: Pod daemon-set-6dcjd is not available
Oct 11 19:02:30.224: INFO: Wrong image for pod: daemon-set-pngmz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:30.229: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:30.229: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:30.229: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:31.224: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:31.224: INFO: Pod daemon-set-6dcjd is not available
Oct 11 19:02:31.224: INFO: Wrong image for pod: daemon-set-pngmz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:31.229: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:31.229: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:31.229: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:32.224: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:32.224: INFO: Wrong image for pod: daemon-set-pngmz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:32.229: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:32.229: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:32.230: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:33.224: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:33.224: INFO: Wrong image for pod: daemon-set-pngmz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:33.224: INFO: Pod daemon-set-pngmz is not available
Oct 11 19:02:33.230: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:33.230: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:33.230: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:34.225: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:34.225: INFO: Wrong image for pod: daemon-set-pngmz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:34.225: INFO: Pod daemon-set-pngmz is not available
Oct 11 19:02:34.231: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:34.231: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:34.231: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:35.224: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:35.224: INFO: Wrong image for pod: daemon-set-pngmz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:35.224: INFO: Pod daemon-set-pngmz is not available
Oct 11 19:02:35.229: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:35.229: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:35.229: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:36.224: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:36.224: INFO: Wrong image for pod: daemon-set-pngmz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:36.224: INFO: Pod daemon-set-pngmz is not available
Oct 11 19:02:36.229: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:36.229: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:36.229: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:37.224: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:37.224: INFO: Wrong image for pod: daemon-set-pngmz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:37.224: INFO: Pod daemon-set-pngmz is not available
Oct 11 19:02:37.229: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:37.229: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:37.229: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:38.228: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:38.228: INFO: Wrong image for pod: daemon-set-pngmz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:38.228: INFO: Pod daemon-set-pngmz is not available
Oct 11 19:02:38.234: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:38.234: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:38.234: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:39.224: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:39.224: INFO: Wrong image for pod: daemon-set-pngmz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:39.224: INFO: Pod daemon-set-pngmz is not available
Oct 11 19:02:39.229: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:39.229: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:39.229: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:40.223: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:40.223: INFO: Pod daemon-set-p7mgd is not available
Oct 11 19:02:40.229: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:40.229: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:40.229: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:41.224: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:41.224: INFO: Pod daemon-set-p7mgd is not available
Oct 11 19:02:41.230: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:41.230: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:41.230: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:42.224: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:42.224: INFO: Pod daemon-set-p7mgd is not available
Oct 11 19:02:42.229: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:42.229: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:42.229: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:43.223: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:43.229: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:43.229: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:43.229: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:44.224: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:44.224: INFO: Pod daemon-set-4ghd7 is not available
Oct 11 19:02:44.230: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:44.230: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:44.230: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:45.226: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:45.226: INFO: Pod daemon-set-4ghd7 is not available
Oct 11 19:02:45.236: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:45.236: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:45.236: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:46.229: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:46.229: INFO: Pod daemon-set-4ghd7 is not available
Oct 11 19:02:46.244: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:46.244: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:46.244: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:47.224: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:47.224: INFO: Pod daemon-set-4ghd7 is not available
Oct 11 19:02:47.229: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:47.229: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:47.229: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:48.224: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:48.224: INFO: Pod daemon-set-4ghd7 is not available
Oct 11 19:02:48.229: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:48.229: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:48.229: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:49.224: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:49.224: INFO: Pod daemon-set-4ghd7 is not available
Oct 11 19:02:49.229: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:49.229: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:49.229: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:50.224: INFO: Wrong image for pod: daemon-set-4ghd7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 11 19:02:50.224: INFO: Pod daemon-set-4ghd7 is not available
Oct 11 19:02:50.230: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:50.230: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:50.230: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:51.226: INFO: Pod daemon-set-qxr4g is not available
Oct 11 19:02:51.231: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:51.231: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:51.231: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Oct 11 19:02:51.236: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:51.236: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:51.236: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:51.240: INFO: Number of nodes with available pods: 2
Oct 11 19:02:51.240: INFO: Node ip-172-31-1-25.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:02:52.246: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:52.246: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:52.246: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:52.250: INFO: Number of nodes with available pods: 2
Oct 11 19:02:52.250: INFO: Node ip-172-31-1-25.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:02:53.246: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:53.247: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:53.247: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:02:53.251: INFO: Number of nodes with available pods: 3
Oct 11 19:02:53.251: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5019, will wait for the garbage collector to delete the pods
Oct 11 19:02:53.335: INFO: Deleting DaemonSet.extensions daemon-set took: 10.371142ms
Oct 11 19:02:53.735: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.206514ms
Oct 11 19:03:00.240: INFO: Number of nodes with available pods: 0
Oct 11 19:03:00.240: INFO: Number of running nodes: 0, number of available pods: 0
Oct 11 19:03:00.244: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5019/daemonsets","resourceVersion":"27694"},"items":null}

Oct 11 19:03:00.248: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5019/pods","resourceVersion":"27694"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:03:00.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5019" for this suite.
Oct 11 19:03:06.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:03:06.423: INFO: namespace daemonsets-5019 deletion completed in 6.153270931s

• [SLOW TEST:43.338 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:03:06.423: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6395
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Oct 11 19:03:06.481: INFO: Found 0 stateful pods, waiting for 3
Oct 11 19:03:16.486: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 11 19:03:16.486: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 11 19:03:16.486: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Oct 11 19:03:16.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-6395 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 11 19:03:16.759: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 11 19:03:16.759: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 11 19:03:16.759: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Oct 11 19:03:26.799: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Oct 11 19:03:36.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-6395 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 19:03:37.078: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 11 19:03:37.078: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 11 19:03:37.078: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 11 19:03:47.104: INFO: Waiting for StatefulSet statefulset-6395/ss2 to complete update
Oct 11 19:03:47.104: INFO: Waiting for Pod statefulset-6395/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Oct 11 19:03:47.104: INFO: Waiting for Pod statefulset-6395/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Oct 11 19:03:57.113: INFO: Waiting for StatefulSet statefulset-6395/ss2 to complete update
Oct 11 19:03:57.113: INFO: Waiting for Pod statefulset-6395/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Oct 11 19:03:57.113: INFO: Waiting for Pod statefulset-6395/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Oct 11 19:04:07.113: INFO: Waiting for StatefulSet statefulset-6395/ss2 to complete update
Oct 11 19:04:07.113: INFO: Waiting for Pod statefulset-6395/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Oct 11 19:04:17.113: INFO: Waiting for StatefulSet statefulset-6395/ss2 to complete update
STEP: Rolling back to a previous revision
Oct 11 19:04:27.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-6395 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 11 19:04:27.385: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 11 19:04:27.385: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 11 19:04:27.385: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 11 19:04:37.424: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Oct 11 19:04:47.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=statefulset-6395 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 11 19:04:47.726: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 11 19:04:47.726: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 11 19:04:47.726: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 11 19:04:57.752: INFO: Waiting for StatefulSet statefulset-6395/ss2 to complete update
Oct 11 19:04:57.752: INFO: Waiting for Pod statefulset-6395/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Oct 11 19:04:57.752: INFO: Waiting for Pod statefulset-6395/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Oct 11 19:04:57.752: INFO: Waiting for Pod statefulset-6395/ss2-2 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Oct 11 19:05:07.761: INFO: Waiting for StatefulSet statefulset-6395/ss2 to complete update
Oct 11 19:05:07.761: INFO: Waiting for Pod statefulset-6395/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Oct 11 19:05:07.761: INFO: Waiting for Pod statefulset-6395/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct 11 19:05:17.762: INFO: Deleting all statefulset in ns statefulset-6395
Oct 11 19:05:17.766: INFO: Scaling statefulset ss2 to 0
Oct 11 19:05:57.785: INFO: Waiting for statefulset status.replicas updated to 0
Oct 11 19:05:57.789: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:05:57.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6395" for this suite.
Oct 11 19:06:03.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:06:03.977: INFO: namespace statefulset-6395 deletion completed in 6.165884074s

• [SLOW TEST:177.554 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:06:03.978: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-728c5af9-b77c-4df5-883e-9a5acf889094
STEP: Creating a pod to test consume configMaps
Oct 11 19:06:04.031: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-962bcce3-910b-4d9f-b130-4c1a1bfbf0ee" in namespace "projected-9068" to be "success or failure"
Oct 11 19:06:04.041: INFO: Pod "pod-projected-configmaps-962bcce3-910b-4d9f-b130-4c1a1bfbf0ee": Phase="Pending", Reason="", readiness=false. Elapsed: 9.379641ms
Oct 11 19:06:06.047: INFO: Pod "pod-projected-configmaps-962bcce3-910b-4d9f-b130-4c1a1bfbf0ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01537223s
STEP: Saw pod success
Oct 11 19:06:06.047: INFO: Pod "pod-projected-configmaps-962bcce3-910b-4d9f-b130-4c1a1bfbf0ee" satisfied condition "success or failure"
Oct 11 19:06:06.051: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-projected-configmaps-962bcce3-910b-4d9f-b130-4c1a1bfbf0ee container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 11 19:06:06.089: INFO: Waiting for pod pod-projected-configmaps-962bcce3-910b-4d9f-b130-4c1a1bfbf0ee to disappear
Oct 11 19:06:06.099: INFO: Pod pod-projected-configmaps-962bcce3-910b-4d9f-b130-4c1a1bfbf0ee no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:06:06.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9068" for this suite.
Oct 11 19:06:12.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:06:12.254: INFO: namespace projected-9068 deletion completed in 6.149794619s

• [SLOW TEST:8.277 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:06:12.254: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Oct 11 19:06:14.327: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-158339303 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Oct 11 19:06:24.421: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:06:24.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2645" for this suite.
Oct 11 19:06:30.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:06:30.604: INFO: namespace pods-2645 deletion completed in 6.172043568s

• [SLOW TEST:18.350 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:06:30.604: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-4d75a42c-f92a-435a-8e8d-ba1705f8e5c1
STEP: Creating a pod to test consume configMaps
Oct 11 19:06:30.660: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-85e7ed17-a8cf-4dae-bbc6-60a079f6a632" in namespace "projected-6018" to be "success or failure"
Oct 11 19:06:30.665: INFO: Pod "pod-projected-configmaps-85e7ed17-a8cf-4dae-bbc6-60a079f6a632": Phase="Pending", Reason="", readiness=false. Elapsed: 4.866845ms
Oct 11 19:06:32.670: INFO: Pod "pod-projected-configmaps-85e7ed17-a8cf-4dae-bbc6-60a079f6a632": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009887375s
Oct 11 19:06:34.675: INFO: Pod "pod-projected-configmaps-85e7ed17-a8cf-4dae-bbc6-60a079f6a632": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014767623s
STEP: Saw pod success
Oct 11 19:06:34.675: INFO: Pod "pod-projected-configmaps-85e7ed17-a8cf-4dae-bbc6-60a079f6a632" satisfied condition "success or failure"
Oct 11 19:06:34.679: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod pod-projected-configmaps-85e7ed17-a8cf-4dae-bbc6-60a079f6a632 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 11 19:06:34.737: INFO: Waiting for pod pod-projected-configmaps-85e7ed17-a8cf-4dae-bbc6-60a079f6a632 to disappear
Oct 11 19:06:34.741: INFO: Pod pod-projected-configmaps-85e7ed17-a8cf-4dae-bbc6-60a079f6a632 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:06:34.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6018" for this suite.
Oct 11 19:06:40.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:06:40.934: INFO: namespace projected-6018 deletion completed in 6.18736234s

• [SLOW TEST:10.330 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:06:40.935: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 11 19:06:40.984: INFO: Waiting up to 5m0s for pod "pod-25ca1d0d-8659-4e75-a928-3a1c0bab96cc" in namespace "emptydir-7004" to be "success or failure"
Oct 11 19:06:40.990: INFO: Pod "pod-25ca1d0d-8659-4e75-a928-3a1c0bab96cc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.645003ms
Oct 11 19:06:42.995: INFO: Pod "pod-25ca1d0d-8659-4e75-a928-3a1c0bab96cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010427901s
STEP: Saw pod success
Oct 11 19:06:42.995: INFO: Pod "pod-25ca1d0d-8659-4e75-a928-3a1c0bab96cc" satisfied condition "success or failure"
Oct 11 19:06:43.000: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-25ca1d0d-8659-4e75-a928-3a1c0bab96cc container test-container: <nil>
STEP: delete the pod
Oct 11 19:06:43.027: INFO: Waiting for pod pod-25ca1d0d-8659-4e75-a928-3a1c0bab96cc to disappear
Oct 11 19:06:43.033: INFO: Pod pod-25ca1d0d-8659-4e75-a928-3a1c0bab96cc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:06:43.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7004" for this suite.
Oct 11 19:06:49.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:06:49.185: INFO: namespace emptydir-7004 deletion completed in 6.146247973s

• [SLOW TEST:8.251 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:06:49.186: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-a68241be-ff1b-49ff-b45f-4813782428f5
STEP: Creating a pod to test consume secrets
Oct 11 19:06:49.247: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-563c4e12-b97d-4233-9c99-a210f8496c8b" in namespace "projected-4208" to be "success or failure"
Oct 11 19:06:49.253: INFO: Pod "pod-projected-secrets-563c4e12-b97d-4233-9c99-a210f8496c8b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.425778ms
Oct 11 19:06:51.258: INFO: Pod "pod-projected-secrets-563c4e12-b97d-4233-9c99-a210f8496c8b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010267684s
Oct 11 19:06:53.265: INFO: Pod "pod-projected-secrets-563c4e12-b97d-4233-9c99-a210f8496c8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017491586s
STEP: Saw pod success
Oct 11 19:06:53.265: INFO: Pod "pod-projected-secrets-563c4e12-b97d-4233-9c99-a210f8496c8b" satisfied condition "success or failure"
Oct 11 19:06:53.269: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod pod-projected-secrets-563c4e12-b97d-4233-9c99-a210f8496c8b container secret-volume-test: <nil>
STEP: delete the pod
Oct 11 19:06:53.296: INFO: Waiting for pod pod-projected-secrets-563c4e12-b97d-4233-9c99-a210f8496c8b to disappear
Oct 11 19:06:53.299: INFO: Pod pod-projected-secrets-563c4e12-b97d-4233-9c99-a210f8496c8b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:06:53.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4208" for this suite.
Oct 11 19:06:59.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:06:59.452: INFO: namespace projected-4208 deletion completed in 6.147091297s

• [SLOW TEST:10.266 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:06:59.452: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-b9c8d097-896e-4359-aadf-c48d8c969dcf
STEP: Creating configMap with name cm-test-opt-upd-ceb82257-4d3e-4806-9f70-547c0074e401
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-b9c8d097-896e-4359-aadf-c48d8c969dcf
STEP: Updating configmap cm-test-opt-upd-ceb82257-4d3e-4806-9f70-547c0074e401
STEP: Creating configMap with name cm-test-opt-create-573b0c11-be9b-49d2-9c20-bcc2b4701ff2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:07:05.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2656" for this suite.
Oct 11 19:07:17.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:07:17.777: INFO: namespace projected-2656 deletion completed in 12.146805579s

• [SLOW TEST:18.324 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:07:17.777: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 11 19:07:17.825: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fda6fec5-250a-46bb-9ca2-0ed51f6da460" in namespace "downward-api-5346" to be "success or failure"
Oct 11 19:07:17.830: INFO: Pod "downwardapi-volume-fda6fec5-250a-46bb-9ca2-0ed51f6da460": Phase="Pending", Reason="", readiness=false. Elapsed: 5.547501ms
Oct 11 19:07:19.835: INFO: Pod "downwardapi-volume-fda6fec5-250a-46bb-9ca2-0ed51f6da460": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010652616s
Oct 11 19:07:21.840: INFO: Pod "downwardapi-volume-fda6fec5-250a-46bb-9ca2-0ed51f6da460": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015446418s
STEP: Saw pod success
Oct 11 19:07:21.840: INFO: Pod "downwardapi-volume-fda6fec5-250a-46bb-9ca2-0ed51f6da460" satisfied condition "success or failure"
Oct 11 19:07:21.844: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod downwardapi-volume-fda6fec5-250a-46bb-9ca2-0ed51f6da460 container client-container: <nil>
STEP: delete the pod
Oct 11 19:07:21.870: INFO: Waiting for pod downwardapi-volume-fda6fec5-250a-46bb-9ca2-0ed51f6da460 to disappear
Oct 11 19:07:21.874: INFO: Pod downwardapi-volume-fda6fec5-250a-46bb-9ca2-0ed51f6da460 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:07:21.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5346" for this suite.
Oct 11 19:07:27.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:07:28.041: INFO: namespace downward-api-5346 deletion completed in 6.161761232s

• [SLOW TEST:10.264 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:07:28.041: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 19:07:28.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 version'
Oct 11 19:07:28.174: INFO: stderr: ""
Oct 11 19:07:28.174: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.1\", GitCommit:\"d647ddbd755faf07169599a625faf302ffc34458\", GitTreeState:\"clean\", BuildDate:\"2019-10-02T17:01:15Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.1\", GitCommit:\"d647ddbd755faf07169599a625faf302ffc34458\", GitTreeState:\"clean\", BuildDate:\"2019-10-02T16:51:36Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:07:28.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2770" for this suite.
Oct 11 19:07:34.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:07:34.330: INFO: namespace kubectl-2770 deletion completed in 6.150499606s

• [SLOW TEST:6.289 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:07:34.331: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6363
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-6363
Oct 11 19:07:34.388: INFO: Found 0 stateful pods, waiting for 1
Oct 11 19:07:44.396: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct 11 19:07:44.421: INFO: Deleting all statefulset in ns statefulset-6363
Oct 11 19:07:44.426: INFO: Scaling statefulset ss to 0
Oct 11 19:08:04.450: INFO: Waiting for statefulset status.replicas updated to 0
Oct 11 19:08:04.455: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:08:04.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6363" for this suite.
Oct 11 19:08:10.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:08:10.638: INFO: namespace statefulset-6363 deletion completed in 6.15893105s

• [SLOW TEST:36.307 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:08:10.639: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-e10f6ee0-a8ca-450e-bb4e-d23984e1cf63
STEP: Creating secret with name s-test-opt-upd-2a8dba72-d477-431e-aa5b-0937cdc2d149
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-e10f6ee0-a8ca-450e-bb4e-d23984e1cf63
STEP: Updating secret s-test-opt-upd-2a8dba72-d477-431e-aa5b-0937cdc2d149
STEP: Creating secret with name s-test-opt-create-14b30c1e-c9ab-4a9b-ab26-21cb6b365c10
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:08:16.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1461" for this suite.
Oct 11 19:08:34.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:08:34.976: INFO: namespace secrets-1461 deletion completed in 18.153621712s

• [SLOW TEST:24.337 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:08:34.976: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 19:08:35.012: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Oct 11 19:08:36.049: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:08:37.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1287" for this suite.
Oct 11 19:08:43.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:08:43.216: INFO: namespace replication-controller-1287 deletion completed in 6.152879203s

• [SLOW TEST:8.239 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:08:43.216: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 19:08:43.281: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Oct 11 19:08:43.295: INFO: Number of nodes with available pods: 0
Oct 11 19:08:43.295: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Oct 11 19:08:43.315: INFO: Number of nodes with available pods: 0
Oct 11 19:08:43.315: INFO: Node ip-172-31-1-25.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:08:44.320: INFO: Number of nodes with available pods: 0
Oct 11 19:08:44.320: INFO: Node ip-172-31-1-25.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:08:45.320: INFO: Number of nodes with available pods: 0
Oct 11 19:08:45.320: INFO: Node ip-172-31-1-25.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:08:46.320: INFO: Number of nodes with available pods: 1
Oct 11 19:08:46.320: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Oct 11 19:08:46.340: INFO: Number of nodes with available pods: 1
Oct 11 19:08:46.340: INFO: Number of running nodes: 0, number of available pods: 1
Oct 11 19:08:47.345: INFO: Number of nodes with available pods: 0
Oct 11 19:08:47.345: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Oct 11 19:08:47.356: INFO: Number of nodes with available pods: 0
Oct 11 19:08:47.356: INFO: Node ip-172-31-1-25.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:08:48.361: INFO: Number of nodes with available pods: 0
Oct 11 19:08:48.361: INFO: Node ip-172-31-1-25.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:08:49.361: INFO: Number of nodes with available pods: 0
Oct 11 19:08:49.361: INFO: Node ip-172-31-1-25.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:08:50.361: INFO: Number of nodes with available pods: 0
Oct 11 19:08:50.361: INFO: Node ip-172-31-1-25.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:08:51.361: INFO: Number of nodes with available pods: 0
Oct 11 19:08:51.361: INFO: Node ip-172-31-1-25.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:08:52.361: INFO: Number of nodes with available pods: 1
Oct 11 19:08:52.361: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3898, will wait for the garbage collector to delete the pods
Oct 11 19:08:52.433: INFO: Deleting DaemonSet.extensions daemon-set took: 9.723885ms
Oct 11 19:08:52.533: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.228372ms
Oct 11 19:08:55.638: INFO: Number of nodes with available pods: 0
Oct 11 19:08:55.638: INFO: Number of running nodes: 0, number of available pods: 0
Oct 11 19:08:55.642: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3898/daemonsets","resourceVersion":"29463"},"items":null}

Oct 11 19:08:55.646: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3898/pods","resourceVersion":"29463"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:08:55.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3898" for this suite.
Oct 11 19:09:01.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:09:01.854: INFO: namespace daemonsets-3898 deletion completed in 6.177705491s

• [SLOW TEST:18.638 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:09:01.854: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:09:01.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4561" for this suite.
Oct 11 19:09:07.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:09:08.090: INFO: namespace resourcequota-4561 deletion completed in 6.147859758s

• [SLOW TEST:6.235 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:09:08.090: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 11 19:09:08.147: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7183f57d-a372-4063-bb1c-75233131a85e" in namespace "downward-api-1338" to be "success or failure"
Oct 11 19:09:08.153: INFO: Pod "downwardapi-volume-7183f57d-a372-4063-bb1c-75233131a85e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.203179ms
Oct 11 19:09:10.157: INFO: Pod "downwardapi-volume-7183f57d-a372-4063-bb1c-75233131a85e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01015864s
Oct 11 19:09:12.162: INFO: Pod "downwardapi-volume-7183f57d-a372-4063-bb1c-75233131a85e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015045623s
STEP: Saw pod success
Oct 11 19:09:12.162: INFO: Pod "downwardapi-volume-7183f57d-a372-4063-bb1c-75233131a85e" satisfied condition "success or failure"
Oct 11 19:09:12.166: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod downwardapi-volume-7183f57d-a372-4063-bb1c-75233131a85e container client-container: <nil>
STEP: delete the pod
Oct 11 19:09:12.201: INFO: Waiting for pod downwardapi-volume-7183f57d-a372-4063-bb1c-75233131a85e to disappear
Oct 11 19:09:12.205: INFO: Pod downwardapi-volume-7183f57d-a372-4063-bb1c-75233131a85e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:09:12.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1338" for this suite.
Oct 11 19:09:18.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:09:18.367: INFO: namespace downward-api-1338 deletion completed in 6.157038878s

• [SLOW TEST:10.277 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:09:18.367: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 11 19:09:22.944: INFO: Successfully updated pod "pod-update-activedeadlineseconds-ecce4d6a-32b0-416c-8514-a9d974c9e712"
Oct 11 19:09:22.944: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-ecce4d6a-32b0-416c-8514-a9d974c9e712" in namespace "pods-3260" to be "terminated due to deadline exceeded"
Oct 11 19:09:22.948: INFO: Pod "pod-update-activedeadlineseconds-ecce4d6a-32b0-416c-8514-a9d974c9e712": Phase="Running", Reason="", readiness=true. Elapsed: 4.313922ms
Oct 11 19:09:24.953: INFO: Pod "pod-update-activedeadlineseconds-ecce4d6a-32b0-416c-8514-a9d974c9e712": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.00903029s
Oct 11 19:09:24.953: INFO: Pod "pod-update-activedeadlineseconds-ecce4d6a-32b0-416c-8514-a9d974c9e712" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:09:24.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3260" for this suite.
Oct 11 19:09:30.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:09:31.118: INFO: namespace pods-3260 deletion completed in 6.159560098s

• [SLOW TEST:12.751 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:09:31.118: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 11 19:09:31.165: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d9572e3c-9eed-43ee-9808-4a7f3cd2cc7d" in namespace "projected-2530" to be "success or failure"
Oct 11 19:09:31.170: INFO: Pod "downwardapi-volume-d9572e3c-9eed-43ee-9808-4a7f3cd2cc7d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.812793ms
Oct 11 19:09:33.176: INFO: Pod "downwardapi-volume-d9572e3c-9eed-43ee-9808-4a7f3cd2cc7d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011170225s
Oct 11 19:09:35.181: INFO: Pod "downwardapi-volume-d9572e3c-9eed-43ee-9808-4a7f3cd2cc7d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015955763s
STEP: Saw pod success
Oct 11 19:09:35.181: INFO: Pod "downwardapi-volume-d9572e3c-9eed-43ee-9808-4a7f3cd2cc7d" satisfied condition "success or failure"
Oct 11 19:09:35.185: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod downwardapi-volume-d9572e3c-9eed-43ee-9808-4a7f3cd2cc7d container client-container: <nil>
STEP: delete the pod
Oct 11 19:09:35.221: INFO: Waiting for pod downwardapi-volume-d9572e3c-9eed-43ee-9808-4a7f3cd2cc7d to disappear
Oct 11 19:09:35.225: INFO: Pod downwardapi-volume-d9572e3c-9eed-43ee-9808-4a7f3cd2cc7d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:09:35.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2530" for this suite.
Oct 11 19:09:41.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:09:41.378: INFO: namespace projected-2530 deletion completed in 6.14682806s

• [SLOW TEST:10.259 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:09:41.378: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct 11 19:09:41.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-4070'
Oct 11 19:09:41.489: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 11 19:09:41.489: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Oct 11 19:09:41.495: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Oct 11 19:09:41.498: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Oct 11 19:09:41.505: INFO: scanned /root for discovery docs: <nil>
Oct 11 19:09:41.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-4070'
Oct 11 19:09:57.297: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 11 19:09:57.297: INFO: stdout: "Created e2e-test-httpd-rc-35583eb641f3c5015b5384cd79ca6334\nScaling up e2e-test-httpd-rc-35583eb641f3c5015b5384cd79ca6334 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-35583eb641f3c5015b5384cd79ca6334 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-35583eb641f3c5015b5384cd79ca6334 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Oct 11 19:09:57.297: INFO: stdout: "Created e2e-test-httpd-rc-35583eb641f3c5015b5384cd79ca6334\nScaling up e2e-test-httpd-rc-35583eb641f3c5015b5384cd79ca6334 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-35583eb641f3c5015b5384cd79ca6334 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-35583eb641f3c5015b5384cd79ca6334 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Oct 11 19:09:57.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-4070'
Oct 11 19:09:57.368: INFO: stderr: ""
Oct 11 19:09:57.368: INFO: stdout: "e2e-test-httpd-rc-35583eb641f3c5015b5384cd79ca6334-dp7kz "
Oct 11 19:09:57.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods e2e-test-httpd-rc-35583eb641f3c5015b5384cd79ca6334-dp7kz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4070'
Oct 11 19:09:57.436: INFO: stderr: ""
Oct 11 19:09:57.436: INFO: stdout: "true"
Oct 11 19:09:57.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 get pods e2e-test-httpd-rc-35583eb641f3c5015b5384cd79ca6334-dp7kz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4070'
Oct 11 19:09:57.504: INFO: stderr: ""
Oct 11 19:09:57.504: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Oct 11 19:09:57.504: INFO: e2e-test-httpd-rc-35583eb641f3c5015b5384cd79ca6334-dp7kz is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Oct 11 19:09:57.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 delete rc e2e-test-httpd-rc --namespace=kubectl-4070'
Oct 11 19:09:57.582: INFO: stderr: ""
Oct 11 19:09:57.582: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:09:57.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4070" for this suite.
Oct 11 19:10:03.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:10:03.742: INFO: namespace kubectl-4070 deletion completed in 6.152463377s

• [SLOW TEST:22.364 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:10:03.743: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 19:10:03.867: INFO: (0) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 21.991328ms)
Oct 11 19:10:03.875: INFO: (1) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 7.730675ms)
Oct 11 19:10:03.883: INFO: (2) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 7.809454ms)
Oct 11 19:10:03.893: INFO: (3) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 9.823766ms)
Oct 11 19:10:03.900: INFO: (4) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 7.388901ms)
Oct 11 19:10:03.913: INFO: (5) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 12.918721ms)
Oct 11 19:10:03.937: INFO: (6) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 23.59771ms)
Oct 11 19:10:03.946: INFO: (7) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 8.932515ms)
Oct 11 19:10:03.952: INFO: (8) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.811725ms)
Oct 11 19:10:03.963: INFO: (9) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 11.119998ms)
Oct 11 19:10:03.968: INFO: (10) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.662366ms)
Oct 11 19:10:03.974: INFO: (11) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.426822ms)
Oct 11 19:10:03.979: INFO: (12) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.385361ms)
Oct 11 19:10:03.985: INFO: (13) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.289826ms)
Oct 11 19:10:03.990: INFO: (14) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.4348ms)
Oct 11 19:10:03.996: INFO: (15) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.361848ms)
Oct 11 19:10:04.001: INFO: (16) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.396978ms)
Oct 11 19:10:04.006: INFO: (17) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.322963ms)
Oct 11 19:10:04.012: INFO: (18) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.363902ms)
Oct 11 19:10:04.018: INFO: (19) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.840746ms)
[AfterEach] version v1
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:10:04.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7919" for this suite.
Oct 11 19:10:10.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:10:10.193: INFO: namespace proxy-7919 deletion completed in 6.170424413s

• [SLOW TEST:6.450 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:10:10.193: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Oct 11 19:10:10.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-8884 -- logs-generator --log-lines-total 100 --run-duration 20s'
Oct 11 19:10:10.304: INFO: stderr: ""
Oct 11 19:10:10.304: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Oct 11 19:10:10.304: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Oct 11 19:10:10.304: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-8884" to be "running and ready, or succeeded"
Oct 11 19:10:10.308: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.275102ms
Oct 11 19:10:12.313: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009131637s
Oct 11 19:10:14.318: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.013731995s
Oct 11 19:10:14.318: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Oct 11 19:10:14.318: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Oct 11 19:10:14.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 logs logs-generator logs-generator --namespace=kubectl-8884'
Oct 11 19:10:14.551: INFO: stderr: ""
Oct 11 19:10:14.551: INFO: stdout: "I1011 19:10:11.684590       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/v4vl 257\nI1011 19:10:11.884738       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/zbvq 489\nI1011 19:10:12.084759       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/kzm 268\nI1011 19:10:12.284822       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/w95b 573\nI1011 19:10:12.484783       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/2d78 568\nI1011 19:10:12.684809       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/2prg 360\nI1011 19:10:12.884785       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/bn6 398\nI1011 19:10:13.084765       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/h2m 279\nI1011 19:10:13.284887       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/46j5 430\nI1011 19:10:13.484749       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/vhrc 422\nI1011 19:10:13.684844       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/5vrg 329\nI1011 19:10:13.884811       1 logs_generator.go:76] 11 POST /api/v1/namespaces/kube-system/pods/4dl 255\nI1011 19:10:14.084723       1 logs_generator.go:76] 12 GET /api/v1/namespaces/ns/pods/9zp 502\nI1011 19:10:14.284788       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/dc8f 240\nI1011 19:10:14.484707       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/default/pods/lfh 294\n"
STEP: limiting log lines
Oct 11 19:10:14.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 logs logs-generator logs-generator --namespace=kubectl-8884 --tail=1'
Oct 11 19:10:14.632: INFO: stderr: ""
Oct 11 19:10:14.632: INFO: stdout: "I1011 19:10:14.484707       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/default/pods/lfh 294\n"
STEP: limiting log bytes
Oct 11 19:10:14.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 logs logs-generator logs-generator --namespace=kubectl-8884 --limit-bytes=1'
Oct 11 19:10:14.717: INFO: stderr: ""
Oct 11 19:10:14.717: INFO: stdout: "I"
STEP: exposing timestamps
Oct 11 19:10:14.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 logs logs-generator logs-generator --namespace=kubectl-8884 --tail=1 --timestamps'
Oct 11 19:10:14.808: INFO: stderr: ""
Oct 11 19:10:14.808: INFO: stdout: "2019-10-11T19:10:14.684823472Z I1011 19:10:14.684712       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/ns/pods/5cdk 317\n"
STEP: restricting to a time range
Oct 11 19:10:17.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 logs logs-generator logs-generator --namespace=kubectl-8884 --since=1s'
Oct 11 19:10:17.391: INFO: stderr: ""
Oct 11 19:10:17.391: INFO: stdout: "I1011 19:10:16.484730       1 logs_generator.go:76] 24 PUT /api/v1/namespaces/kube-system/pods/t5n 360\nI1011 19:10:16.684715       1 logs_generator.go:76] 25 POST /api/v1/namespaces/default/pods/jk64 403\nI1011 19:10:16.884709       1 logs_generator.go:76] 26 POST /api/v1/namespaces/kube-system/pods/5xq 442\nI1011 19:10:17.084719       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/default/pods/dmn 460\nI1011 19:10:17.284716       1 logs_generator.go:76] 28 POST /api/v1/namespaces/default/pods/6s9 431\n"
Oct 11 19:10:17.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 logs logs-generator logs-generator --namespace=kubectl-8884 --since=24h'
Oct 11 19:10:17.473: INFO: stderr: ""
Oct 11 19:10:17.473: INFO: stdout: "I1011 19:10:11.684590       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/v4vl 257\nI1011 19:10:11.884738       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/zbvq 489\nI1011 19:10:12.084759       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/kzm 268\nI1011 19:10:12.284822       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/w95b 573\nI1011 19:10:12.484783       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/2d78 568\nI1011 19:10:12.684809       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/2prg 360\nI1011 19:10:12.884785       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/bn6 398\nI1011 19:10:13.084765       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/h2m 279\nI1011 19:10:13.284887       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/46j5 430\nI1011 19:10:13.484749       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/vhrc 422\nI1011 19:10:13.684844       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/5vrg 329\nI1011 19:10:13.884811       1 logs_generator.go:76] 11 POST /api/v1/namespaces/kube-system/pods/4dl 255\nI1011 19:10:14.084723       1 logs_generator.go:76] 12 GET /api/v1/namespaces/ns/pods/9zp 502\nI1011 19:10:14.284788       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/dc8f 240\nI1011 19:10:14.484707       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/default/pods/lfh 294\nI1011 19:10:14.684712       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/ns/pods/5cdk 317\nI1011 19:10:14.884797       1 logs_generator.go:76] 16 GET /api/v1/namespaces/kube-system/pods/rf4 491\nI1011 19:10:15.084724       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/62h 470\nI1011 19:10:15.284731       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/5tlk 432\nI1011 19:10:15.484725       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/kube-system/pods/tpzt 260\nI1011 19:10:15.684737       1 logs_generator.go:76] 20 POST /api/v1/namespaces/ns/pods/489 367\nI1011 19:10:15.884814       1 logs_generator.go:76] 21 GET /api/v1/namespaces/default/pods/hvp 577\nI1011 19:10:16.084728       1 logs_generator.go:76] 22 GET /api/v1/namespaces/kube-system/pods/vp5k 356\nI1011 19:10:16.284722       1 logs_generator.go:76] 23 GET /api/v1/namespaces/default/pods/b4z4 581\nI1011 19:10:16.484730       1 logs_generator.go:76] 24 PUT /api/v1/namespaces/kube-system/pods/t5n 360\nI1011 19:10:16.684715       1 logs_generator.go:76] 25 POST /api/v1/namespaces/default/pods/jk64 403\nI1011 19:10:16.884709       1 logs_generator.go:76] 26 POST /api/v1/namespaces/kube-system/pods/5xq 442\nI1011 19:10:17.084719       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/default/pods/dmn 460\nI1011 19:10:17.284716       1 logs_generator.go:76] 28 POST /api/v1/namespaces/default/pods/6s9 431\nI1011 19:10:17.484708       1 logs_generator.go:76] 29 PUT /api/v1/namespaces/default/pods/d47w 275\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Oct 11 19:10:17.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 delete pod logs-generator --namespace=kubectl-8884'
Oct 11 19:10:22.492: INFO: stderr: ""
Oct 11 19:10:22.492: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:10:22.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8884" for this suite.
Oct 11 19:10:28.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:10:28.647: INFO: namespace kubectl-8884 deletion completed in 6.148104276s

• [SLOW TEST:18.454 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:10:28.648: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:10:44.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7295" for this suite.
Oct 11 19:10:50.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:10:50.889: INFO: namespace resourcequota-7295 deletion completed in 6.147081151s

• [SLOW TEST:22.241 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:10:50.890: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Oct 11 19:10:55.971: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:10:56.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9985" for this suite.
Oct 11 19:11:23.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:11:23.153: INFO: namespace replicaset-9985 deletion completed in 26.152431615s

• [SLOW TEST:32.263 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:11:23.153: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-4851babc-e8d0-4534-8e62-27b3a54bb23d
STEP: Creating a pod to test consume secrets
Oct 11 19:11:23.248: INFO: Waiting up to 5m0s for pod "pod-secrets-a5b16e18-ebfd-43cf-b4d8-4ce7e4eaea88" in namespace "secrets-563" to be "success or failure"
Oct 11 19:11:23.254: INFO: Pod "pod-secrets-a5b16e18-ebfd-43cf-b4d8-4ce7e4eaea88": Phase="Pending", Reason="", readiness=false. Elapsed: 5.465176ms
Oct 11 19:11:25.259: INFO: Pod "pod-secrets-a5b16e18-ebfd-43cf-b4d8-4ce7e4eaea88": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010594491s
Oct 11 19:11:27.264: INFO: Pod "pod-secrets-a5b16e18-ebfd-43cf-b4d8-4ce7e4eaea88": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016238443s
STEP: Saw pod success
Oct 11 19:11:27.264: INFO: Pod "pod-secrets-a5b16e18-ebfd-43cf-b4d8-4ce7e4eaea88" satisfied condition "success or failure"
Oct 11 19:11:27.269: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-secrets-a5b16e18-ebfd-43cf-b4d8-4ce7e4eaea88 container secret-volume-test: <nil>
STEP: delete the pod
Oct 11 19:11:27.302: INFO: Waiting for pod pod-secrets-a5b16e18-ebfd-43cf-b4d8-4ce7e4eaea88 to disappear
Oct 11 19:11:27.306: INFO: Pod pod-secrets-a5b16e18-ebfd-43cf-b4d8-4ce7e4eaea88 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:11:27.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-563" for this suite.
Oct 11 19:11:33.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:11:33.516: INFO: namespace secrets-563 deletion completed in 6.204787236s
STEP: Destroying namespace "secret-namespace-9341" for this suite.
Oct 11 19:11:39.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:11:39.668: INFO: namespace secret-namespace-9341 deletion completed in 6.152091264s

• [SLOW TEST:16.515 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:11:39.670: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Oct 11 19:11:43.738: INFO: &Pod{ObjectMeta:{send-events-96d69b4c-01bc-416b-962e-2481b0492401  events-3831 /api/v1/namespaces/events-3831/pods/send-events-96d69b4c-01bc-416b-962e-2481b0492401 696092bf-f06b-43af-9fac-12bd4be675b1 30236 0 2019-10-11 19:11:39 +0000 UTC <nil> <nil> map[name:foo time:709080101] map[cni.projectcalico.org/podIP:10.244.4.129/32] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4jc7j,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4jc7j,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4jc7j,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-5-54.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 19:11:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 19:11:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 19:11:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 19:11:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.5.54,PodIP:10.244.4.129,StartTime:2019-10-11 19:11:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-11 19:11:41 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:docker://083af9d24eb01243b42348a25b4f5e65790f3d61993a683b8361490c87877b5e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.129,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Oct 11 19:11:45.743: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Oct 11 19:11:47.749: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:11:47.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-3831" for this suite.
Oct 11 19:12:31.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:12:31.923: INFO: namespace events-3831 deletion completed in 44.157549081s

• [SLOW TEST:52.254 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:12:31.923: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 11 19:12:32.013: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:32.013: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:32.013: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:32.017: INFO: Number of nodes with available pods: 0
Oct 11 19:12:32.017: INFO: Node ip-172-31-1-25.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:12:33.037: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:33.038: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:33.038: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:33.046: INFO: Number of nodes with available pods: 0
Oct 11 19:12:33.046: INFO: Node ip-172-31-1-25.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:12:34.023: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:34.023: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:34.023: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:34.028: INFO: Number of nodes with available pods: 0
Oct 11 19:12:34.028: INFO: Node ip-172-31-1-25.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:12:35.023: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:35.023: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:35.023: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:35.028: INFO: Number of nodes with available pods: 3
Oct 11 19:12:35.028: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Oct 11 19:12:35.049: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:35.049: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:35.049: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:35.053: INFO: Number of nodes with available pods: 2
Oct 11 19:12:35.053: INFO: Node ip-172-31-6-233.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:12:36.059: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:36.060: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:36.060: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:36.064: INFO: Number of nodes with available pods: 2
Oct 11 19:12:36.064: INFO: Node ip-172-31-6-233.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:12:37.060: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:37.060: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:37.060: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:37.064: INFO: Number of nodes with available pods: 2
Oct 11 19:12:37.064: INFO: Node ip-172-31-6-233.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:12:38.060: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:38.060: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:38.060: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:38.064: INFO: Number of nodes with available pods: 2
Oct 11 19:12:38.064: INFO: Node ip-172-31-6-233.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:12:39.063: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:39.063: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:39.063: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:39.067: INFO: Number of nodes with available pods: 2
Oct 11 19:12:39.067: INFO: Node ip-172-31-6-233.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:12:40.060: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:40.060: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:40.060: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:40.064: INFO: Number of nodes with available pods: 2
Oct 11 19:12:40.064: INFO: Node ip-172-31-6-233.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:12:41.060: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:41.060: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:41.060: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:41.064: INFO: Number of nodes with available pods: 2
Oct 11 19:12:41.064: INFO: Node ip-172-31-6-233.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:12:42.060: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:42.060: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:42.060: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:42.066: INFO: Number of nodes with available pods: 2
Oct 11 19:12:42.066: INFO: Node ip-172-31-6-233.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:12:43.060: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:43.060: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:43.060: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:43.064: INFO: Number of nodes with available pods: 2
Oct 11 19:12:43.064: INFO: Node ip-172-31-6-233.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:12:44.060: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:44.060: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:44.060: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:44.064: INFO: Number of nodes with available pods: 2
Oct 11 19:12:44.064: INFO: Node ip-172-31-6-233.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:12:45.060: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:45.060: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:45.060: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:12:45.064: INFO: Number of nodes with available pods: 3
Oct 11 19:12:45.064: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5622, will wait for the garbage collector to delete the pods
Oct 11 19:12:45.145: INFO: Deleting DaemonSet.extensions daemon-set took: 17.994202ms
Oct 11 19:12:45.545: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.177733ms
Oct 11 19:12:50.050: INFO: Number of nodes with available pods: 0
Oct 11 19:12:50.050: INFO: Number of running nodes: 0, number of available pods: 0
Oct 11 19:12:50.054: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5622/daemonsets","resourceVersion":"30497"},"items":null}

Oct 11 19:12:50.061: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5622/pods","resourceVersion":"30497"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:12:50.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5622" for this suite.
Oct 11 19:12:56.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:12:56.240: INFO: namespace daemonsets-5622 deletion completed in 6.15522345s

• [SLOW TEST:24.317 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:12:56.241: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1011 19:13:06.365771      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 11 19:13:06.365: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:13:06.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-896" for this suite.
Oct 11 19:13:12.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:13:12.534: INFO: namespace gc-896 deletion completed in 6.163789544s

• [SLOW TEST:16.294 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:13:12.534: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:13:12.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-4763" for this suite.
Oct 11 19:13:18.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:13:18.731: INFO: namespace tables-4763 deletion completed in 6.150357082s

• [SLOW TEST:6.197 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:13:18.731: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 11 19:13:18.779: INFO: Waiting up to 5m0s for pod "downwardapi-volume-50ef1e3e-80cf-4e85-b43f-e8696f59eb62" in namespace "projected-4445" to be "success or failure"
Oct 11 19:13:18.784: INFO: Pod "downwardapi-volume-50ef1e3e-80cf-4e85-b43f-e8696f59eb62": Phase="Pending", Reason="", readiness=false. Elapsed: 4.57087ms
Oct 11 19:13:20.790: INFO: Pod "downwardapi-volume-50ef1e3e-80cf-4e85-b43f-e8696f59eb62": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010792637s
Oct 11 19:13:22.795: INFO: Pod "downwardapi-volume-50ef1e3e-80cf-4e85-b43f-e8696f59eb62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015823523s
STEP: Saw pod success
Oct 11 19:13:22.795: INFO: Pod "downwardapi-volume-50ef1e3e-80cf-4e85-b43f-e8696f59eb62" satisfied condition "success or failure"
Oct 11 19:13:22.799: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod downwardapi-volume-50ef1e3e-80cf-4e85-b43f-e8696f59eb62 container client-container: <nil>
STEP: delete the pod
Oct 11 19:13:22.834: INFO: Waiting for pod downwardapi-volume-50ef1e3e-80cf-4e85-b43f-e8696f59eb62 to disappear
Oct 11 19:13:22.844: INFO: Pod downwardapi-volume-50ef1e3e-80cf-4e85-b43f-e8696f59eb62 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:13:22.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4445" for this suite.
Oct 11 19:13:28.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:13:28.997: INFO: namespace projected-4445 deletion completed in 6.147241502s

• [SLOW TEST:10.265 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:13:28.997: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 11 19:13:29.516: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 11 19:13:31.532: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418009, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418009, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418009, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418009, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 11 19:13:34.553: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:13:46.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2856" for this suite.
Oct 11 19:13:52.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:13:52.864: INFO: namespace webhook-2856 deletion completed in 6.144804039s
STEP: Destroying namespace "webhook-2856-markers" for this suite.
Oct 11 19:13:58.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:13:59.010: INFO: namespace webhook-2856-markers deletion completed in 6.146361534s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:30.034 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:13:59.032: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-2da1e4d0-0fbc-41e4-a228-d2d96e3e084c
STEP: Creating a pod to test consume configMaps
Oct 11 19:13:59.084: INFO: Waiting up to 5m0s for pod "pod-configmaps-43b83318-e900-4087-9e89-68dd10a0a8ad" in namespace "configmap-4319" to be "success or failure"
Oct 11 19:13:59.088: INFO: Pod "pod-configmaps-43b83318-e900-4087-9e89-68dd10a0a8ad": Phase="Pending", Reason="", readiness=false. Elapsed: 4.818731ms
Oct 11 19:14:01.096: INFO: Pod "pod-configmaps-43b83318-e900-4087-9e89-68dd10a0a8ad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012658515s
Oct 11 19:14:03.101: INFO: Pod "pod-configmaps-43b83318-e900-4087-9e89-68dd10a0a8ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017701528s
STEP: Saw pod success
Oct 11 19:14:03.101: INFO: Pod "pod-configmaps-43b83318-e900-4087-9e89-68dd10a0a8ad" satisfied condition "success or failure"
Oct 11 19:14:03.106: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-configmaps-43b83318-e900-4087-9e89-68dd10a0a8ad container configmap-volume-test: <nil>
STEP: delete the pod
Oct 11 19:14:03.132: INFO: Waiting for pod pod-configmaps-43b83318-e900-4087-9e89-68dd10a0a8ad to disappear
Oct 11 19:14:03.135: INFO: Pod pod-configmaps-43b83318-e900-4087-9e89-68dd10a0a8ad no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:14:03.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4319" for this suite.
Oct 11 19:14:09.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:14:09.288: INFO: namespace configmap-4319 deletion completed in 6.147100137s

• [SLOW TEST:10.257 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:14:09.288: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:14:09.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-47" for this suite.
Oct 11 19:14:15.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:14:15.502: INFO: namespace kubelet-test-47 deletion completed in 6.152893051s

• [SLOW TEST:6.214 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:14:15.503: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Oct 11 19:14:15.539: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-158339303 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:14:15.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1891" for this suite.
Oct 11 19:14:21.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:14:21.753: INFO: namespace kubectl-1891 deletion completed in 6.150188057s

• [SLOW TEST:6.250 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:14:21.753: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Oct 11 19:14:21.789: INFO: PodSpec: initContainers in spec.initContainers
Oct 11 19:15:03.121: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-6a359cf2-f9b6-44db-83e2-dc3b30b3e3f6", GenerateName:"", Namespace:"init-container-4768", SelfLink:"/api/v1/namespaces/init-container-4768/pods/pod-init-6a359cf2-f9b6-44db-83e2-dc3b30b3e3f6", UID:"eee39bb4-6b6d-4db8-a87b-158eb037ce7f", ResourceVersion:"31288", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63706418061, loc:(*time.Location)(0x84c12c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"789361668"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.244.3.161/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-px62g", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0076c4180), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-px62g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-px62g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-px62g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0023e22b8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-6-233.eu-west-3.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0034240c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0023e2330)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0023e2350)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0023e2358), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0023e235c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418061, loc:(*time.Location)(0x84c12c0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418061, loc:(*time.Location)(0x84c12c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418061, loc:(*time.Location)(0x84c12c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418061, loc:(*time.Location)(0x84c12c0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.6.233", PodIP:"10.244.3.161", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.244.3.161"}}, StartTime:(*v1.Time)(0xc00303c180), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc00303c1c0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0002f4310)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://6b0859b87fcad0f36102aaaea92dcfdfca74704d47427d9ca6c1aeab329c1d40", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00303c1e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00303c1a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0023e23df)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:15:03.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4768" for this suite.
Oct 11 19:15:15.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:15:15.313: INFO: namespace init-container-4768 deletion completed in 12.185042055s

• [SLOW TEST:53.560 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:15:15.313: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Oct 11 19:15:15.363: INFO: Waiting up to 5m0s for pod "client-containers-63eff372-8343-4810-bfc9-a559b26aaa2a" in namespace "containers-6718" to be "success or failure"
Oct 11 19:15:15.367: INFO: Pod "client-containers-63eff372-8343-4810-bfc9-a559b26aaa2a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.581727ms
Oct 11 19:15:17.372: INFO: Pod "client-containers-63eff372-8343-4810-bfc9-a559b26aaa2a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009268007s
STEP: Saw pod success
Oct 11 19:15:17.372: INFO: Pod "client-containers-63eff372-8343-4810-bfc9-a559b26aaa2a" satisfied condition "success or failure"
Oct 11 19:15:17.376: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod client-containers-63eff372-8343-4810-bfc9-a559b26aaa2a container test-container: <nil>
STEP: delete the pod
Oct 11 19:15:17.418: INFO: Waiting for pod client-containers-63eff372-8343-4810-bfc9-a559b26aaa2a to disappear
Oct 11 19:15:17.422: INFO: Pod client-containers-63eff372-8343-4810-bfc9-a559b26aaa2a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:15:17.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6718" for this suite.
Oct 11 19:15:23.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:15:23.573: INFO: namespace containers-6718 deletion completed in 6.145946448s

• [SLOW TEST:8.260 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:15:23.573: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 11 19:15:25.640: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:15:25.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6543" for this suite.
Oct 11 19:15:31.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:15:31.823: INFO: namespace container-runtime-6543 deletion completed in 6.157957701s

• [SLOW TEST:8.250 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:15:31.823: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 19:15:31.860: INFO: Creating ReplicaSet my-hostname-basic-951d7cb8-ce10-4a92-b00f-b28901551c62
Oct 11 19:15:31.874: INFO: Pod name my-hostname-basic-951d7cb8-ce10-4a92-b00f-b28901551c62: Found 0 pods out of 1
Oct 11 19:15:36.879: INFO: Pod name my-hostname-basic-951d7cb8-ce10-4a92-b00f-b28901551c62: Found 1 pods out of 1
Oct 11 19:15:36.879: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-951d7cb8-ce10-4a92-b00f-b28901551c62" is running
Oct 11 19:15:36.883: INFO: Pod "my-hostname-basic-951d7cb8-ce10-4a92-b00f-b28901551c62-zc92v" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-11 19:15:31 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-11 19:15:33 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-11 19:15:33 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-11 19:15:31 +0000 UTC Reason: Message:}])
Oct 11 19:15:36.883: INFO: Trying to dial the pod
Oct 11 19:15:41.902: INFO: Controller my-hostname-basic-951d7cb8-ce10-4a92-b00f-b28901551c62: Got expected result from replica 1 [my-hostname-basic-951d7cb8-ce10-4a92-b00f-b28901551c62-zc92v]: "my-hostname-basic-951d7cb8-ce10-4a92-b00f-b28901551c62-zc92v", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:15:41.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5174" for this suite.
Oct 11 19:15:47.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:15:48.084: INFO: namespace replicaset-5174 deletion completed in 6.17552609s

• [SLOW TEST:16.261 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:15:48.085: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1011 19:15:58.162527      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 11 19:15:58.162: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:15:58.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-56" for this suite.
Oct 11 19:16:04.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:16:04.312: INFO: namespace gc-56 deletion completed in 6.145359401s

• [SLOW TEST:16.227 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:16:04.313: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 11 19:16:04.996: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 11 19:16:07.010: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418165, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418165, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418165, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418165, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 11 19:16:10.031: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:16:10.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9018" for this suite.
Oct 11 19:16:16.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:16:16.436: INFO: namespace webhook-9018 deletion completed in 6.154015551s
STEP: Destroying namespace "webhook-9018-markers" for this suite.
Oct 11 19:16:22.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:16:22.682: INFO: namespace webhook-9018-markers deletion completed in 6.24542704s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.390 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:16:22.703: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-6afba3b5-07c1-432a-b4a8-c22ec42d0cbd
STEP: Creating a pod to test consume configMaps
Oct 11 19:16:22.757: INFO: Waiting up to 5m0s for pod "pod-configmaps-6035a21f-dee3-4d6c-bcdd-b5841430f375" in namespace "configmap-6595" to be "success or failure"
Oct 11 19:16:22.769: INFO: Pod "pod-configmaps-6035a21f-dee3-4d6c-bcdd-b5841430f375": Phase="Pending", Reason="", readiness=false. Elapsed: 10.945569ms
Oct 11 19:16:24.773: INFO: Pod "pod-configmaps-6035a21f-dee3-4d6c-bcdd-b5841430f375": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015393084s
STEP: Saw pod success
Oct 11 19:16:24.773: INFO: Pod "pod-configmaps-6035a21f-dee3-4d6c-bcdd-b5841430f375" satisfied condition "success or failure"
Oct 11 19:16:24.777: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-configmaps-6035a21f-dee3-4d6c-bcdd-b5841430f375 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 11 19:16:24.815: INFO: Waiting for pod pod-configmaps-6035a21f-dee3-4d6c-bcdd-b5841430f375 to disappear
Oct 11 19:16:24.820: INFO: Pod pod-configmaps-6035a21f-dee3-4d6c-bcdd-b5841430f375 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:16:24.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6595" for this suite.
Oct 11 19:16:30.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:16:30.985: INFO: namespace configmap-6595 deletion completed in 6.159486526s

• [SLOW TEST:8.282 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:16:30.985: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 11 19:16:31.034: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d214cd9d-fd43-4f4f-80d6-962fc062a5e6" in namespace "projected-8876" to be "success or failure"
Oct 11 19:16:31.039: INFO: Pod "downwardapi-volume-d214cd9d-fd43-4f4f-80d6-962fc062a5e6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.184094ms
Oct 11 19:16:33.044: INFO: Pod "downwardapi-volume-d214cd9d-fd43-4f4f-80d6-962fc062a5e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009638502s
STEP: Saw pod success
Oct 11 19:16:33.044: INFO: Pod "downwardapi-volume-d214cd9d-fd43-4f4f-80d6-962fc062a5e6" satisfied condition "success or failure"
Oct 11 19:16:33.048: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod downwardapi-volume-d214cd9d-fd43-4f4f-80d6-962fc062a5e6 container client-container: <nil>
STEP: delete the pod
Oct 11 19:16:33.076: INFO: Waiting for pod downwardapi-volume-d214cd9d-fd43-4f4f-80d6-962fc062a5e6 to disappear
Oct 11 19:16:33.084: INFO: Pod downwardapi-volume-d214cd9d-fd43-4f4f-80d6-962fc062a5e6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:16:33.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8876" for this suite.
Oct 11 19:16:39.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:16:39.240: INFO: namespace projected-8876 deletion completed in 6.149969524s

• [SLOW TEST:8.255 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:16:39.240: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct 11 19:16:39.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-9059'
Oct 11 19:16:39.352: INFO: stderr: ""
Oct 11 19:16:39.352: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Oct 11 19:16:39.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 delete pods e2e-test-httpd-pod --namespace=kubectl-9059'
Oct 11 19:17:27.667: INFO: stderr: ""
Oct 11 19:17:27.667: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:17:27.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9059" for this suite.
Oct 11 19:17:33.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:17:33.825: INFO: namespace kubectl-9059 deletion completed in 6.152689448s

• [SLOW TEST:54.585 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:17:33.826: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Oct 11 19:17:33.869: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:17:36.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5185" for this suite.
Oct 11 19:17:42.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:17:43.068: INFO: namespace init-container-5185 deletion completed in 6.142497765s

• [SLOW TEST:9.242 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:17:43.068: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:17:48.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8969" for this suite.
Oct 11 19:17:54.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:17:54.319: INFO: namespace watch-8969 deletion completed in 6.243593297s

• [SLOW TEST:11.251 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:17:54.320: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Oct 11 19:17:54.368: INFO: Waiting up to 5m0s for pod "pod-2c6b9f71-8244-48d0-bf15-e23c50f1cb0d" in namespace "emptydir-5559" to be "success or failure"
Oct 11 19:17:54.372: INFO: Pod "pod-2c6b9f71-8244-48d0-bf15-e23c50f1cb0d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.804165ms
Oct 11 19:17:56.377: INFO: Pod "pod-2c6b9f71-8244-48d0-bf15-e23c50f1cb0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009365173s
STEP: Saw pod success
Oct 11 19:17:56.377: INFO: Pod "pod-2c6b9f71-8244-48d0-bf15-e23c50f1cb0d" satisfied condition "success or failure"
Oct 11 19:17:56.381: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-2c6b9f71-8244-48d0-bf15-e23c50f1cb0d container test-container: <nil>
STEP: delete the pod
Oct 11 19:17:56.407: INFO: Waiting for pod pod-2c6b9f71-8244-48d0-bf15-e23c50f1cb0d to disappear
Oct 11 19:17:56.411: INFO: Pod pod-2c6b9f71-8244-48d0-bf15-e23c50f1cb0d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:17:56.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5559" for this suite.
Oct 11 19:18:02.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:18:02.597: INFO: namespace emptydir-5559 deletion completed in 6.181040637s

• [SLOW TEST:8.278 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:18:02.598: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 19:18:02.634: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Oct 11 19:18:02.647: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct 11 19:18:07.652: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 11 19:18:07.652: INFO: Creating deployment "test-rolling-update-deployment"
Oct 11 19:18:07.658: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Oct 11 19:18:07.667: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Oct 11 19:18:09.678: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Oct 11 19:18:09.681: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418287, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418287, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418287, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418287, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 11 19:18:11.686: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Oct 11 19:18:11.699: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-3351 /apis/apps/v1/namespaces/deployment-3351/deployments/test-rolling-update-deployment d2dbd533-e1d3-4f05-a273-132918976076 32272 1 2019-10-11 19:18:07 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc007bc13c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-10-11 19:18:07 +0000 UTC,LastTransitionTime:2019-10-11 19:18:07 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2019-10-11 19:18:09 +0000 UTC,LastTransitionTime:2019-10-11 19:18:07 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Oct 11 19:18:11.704: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-3351 /apis/apps/v1/namespaces/deployment-3351/replicasets/test-rolling-update-deployment-55d946486 a3d83233-9c23-4e9e-94c6-37d996679056 32261 1 2019-10-11 19:18:07 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment d2dbd533-e1d3-4f05-a273-132918976076 0xc007bc18c0 0xc007bc18c1}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc007bc1928 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct 11 19:18:11.704: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Oct 11 19:18:11.704: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-3351 /apis/apps/v1/namespaces/deployment-3351/replicasets/test-rolling-update-controller 4543f9c2-9c95-4936-b9a2-f7fc3f94783f 32271 2 2019-10-11 19:18:02 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment d2dbd533-e1d3-4f05-a273-132918976076 0xc007bc17f7 0xc007bc17f8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc007bc1858 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 11 19:18:11.708: INFO: Pod "test-rolling-update-deployment-55d946486-j4kvl" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-j4kvl test-rolling-update-deployment-55d946486- deployment-3351 /api/v1/namespaces/deployment-3351/pods/test-rolling-update-deployment-55d946486-j4kvl d67cc01d-4e31-478f-90b7-ced86270f92a 32260 0 2019-10-11 19:18:07 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[cni.projectcalico.org/podIP:10.244.3.170/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 a3d83233-9c23-4e9e-94c6-37d996679056 0xc007bc1db0 0xc007bc1db1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-p72p9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-p72p9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-p72p9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-6-233.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 19:18:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 19:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 19:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 19:18:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.6.233,PodIP:10.244.3.170,StartTime:2019-10-11 19:18:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-11 19:18:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://0add57bdc4f646ab7116b0e147b80fd18df47f80bbfc6adfee44515db1fb814e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.170,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:18:11.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3351" for this suite.
Oct 11 19:18:17.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:18:17.866: INFO: namespace deployment-3351 deletion completed in 6.153061365s

• [SLOW TEST:15.268 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:18:17.867: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 11 19:18:17.938: INFO: Waiting up to 5m0s for pod "downwardapi-volume-098066d0-4e2a-4f4e-8934-95dd3275f68d" in namespace "projected-3653" to be "success or failure"
Oct 11 19:18:17.947: INFO: Pod "downwardapi-volume-098066d0-4e2a-4f4e-8934-95dd3275f68d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.776379ms
Oct 11 19:18:19.952: INFO: Pod "downwardapi-volume-098066d0-4e2a-4f4e-8934-95dd3275f68d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013660066s
STEP: Saw pod success
Oct 11 19:18:19.952: INFO: Pod "downwardapi-volume-098066d0-4e2a-4f4e-8934-95dd3275f68d" satisfied condition "success or failure"
Oct 11 19:18:19.956: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod downwardapi-volume-098066d0-4e2a-4f4e-8934-95dd3275f68d container client-container: <nil>
STEP: delete the pod
Oct 11 19:18:19.992: INFO: Waiting for pod downwardapi-volume-098066d0-4e2a-4f4e-8934-95dd3275f68d to disappear
Oct 11 19:18:19.996: INFO: Pod downwardapi-volume-098066d0-4e2a-4f4e-8934-95dd3275f68d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:18:19.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3653" for this suite.
Oct 11 19:18:26.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:18:26.153: INFO: namespace projected-3653 deletion completed in 6.152251127s

• [SLOW TEST:8.286 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:18:26.155: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 11 19:18:28.227: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:18:28.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3177" for this suite.
Oct 11 19:18:34.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:18:34.402: INFO: namespace container-runtime-3177 deletion completed in 6.150558735s

• [SLOW TEST:8.248 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:18:34.403: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1011 19:18:40.482957      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 11 19:18:40.482: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:18:40.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3341" for this suite.
Oct 11 19:18:46.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:18:46.643: INFO: namespace gc-3341 deletion completed in 6.155561931s

• [SLOW TEST:12.240 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:18:46.643: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 11 19:18:47.048: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 11 19:18:49.063: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418327, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418327, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418327, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418327, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 11 19:18:52.088: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:18:52.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8014" for this suite.
Oct 11 19:18:58.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:18:58.338: INFO: namespace webhook-8014 deletion completed in 6.154103543s
STEP: Destroying namespace "webhook-8014-markers" for this suite.
Oct 11 19:19:04.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:19:04.494: INFO: namespace webhook-8014-markers deletion completed in 6.156206455s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.872 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:19:04.516: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 19:19:04.570: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-6aa6ab24-7bfd-43b9-a92e-88eaaa66bde0" in namespace "security-context-test-3992" to be "success or failure"
Oct 11 19:19:04.576: INFO: Pod "busybox-privileged-false-6aa6ab24-7bfd-43b9-a92e-88eaaa66bde0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.224463ms
Oct 11 19:19:06.581: INFO: Pod "busybox-privileged-false-6aa6ab24-7bfd-43b9-a92e-88eaaa66bde0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010528749s
Oct 11 19:19:08.586: INFO: Pod "busybox-privileged-false-6aa6ab24-7bfd-43b9-a92e-88eaaa66bde0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01556032s
Oct 11 19:19:08.586: INFO: Pod "busybox-privileged-false-6aa6ab24-7bfd-43b9-a92e-88eaaa66bde0" satisfied condition "success or failure"
Oct 11 19:19:08.596: INFO: Got logs for pod "busybox-privileged-false-6aa6ab24-7bfd-43b9-a92e-88eaaa66bde0": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:19:08.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3992" for this suite.
Oct 11 19:19:14.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:19:14.753: INFO: namespace security-context-test-3992 deletion completed in 6.151039338s

• [SLOW TEST:10.237 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:19:14.760: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct 11 19:19:14.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-9583'
Oct 11 19:19:14.881: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 11 19:19:14.881: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Oct 11 19:19:14.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 delete jobs e2e-test-httpd-job --namespace=kubectl-9583'
Oct 11 19:19:14.996: INFO: stderr: ""
Oct 11 19:19:14.996: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:19:14.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9583" for this suite.
Oct 11 19:19:21.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:19:21.151: INFO: namespace kubectl-9583 deletion completed in 6.150110746s

• [SLOW TEST:6.391 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:19:21.152: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 19:19:21.250: INFO: Pod name rollover-pod: Found 0 pods out of 1
Oct 11 19:19:26.255: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 11 19:19:26.255: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Oct 11 19:19:28.260: INFO: Creating deployment "test-rollover-deployment"
Oct 11 19:19:28.269: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Oct 11 19:19:30.280: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Oct 11 19:19:30.304: INFO: Ensure that both replica sets have 1 created replica
Oct 11 19:19:30.312: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Oct 11 19:19:30.326: INFO: Updating deployment test-rollover-deployment
Oct 11 19:19:30.326: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Oct 11 19:19:32.334: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Oct 11 19:19:32.343: INFO: Make sure deployment "test-rollover-deployment" is complete
Oct 11 19:19:32.351: INFO: all replica sets need to contain the pod-template-hash label
Oct 11 19:19:32.351: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418368, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418368, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418372, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418368, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 11 19:19:34.360: INFO: all replica sets need to contain the pod-template-hash label
Oct 11 19:19:34.360: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418368, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418368, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418372, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418368, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 11 19:19:36.360: INFO: all replica sets need to contain the pod-template-hash label
Oct 11 19:19:36.360: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418368, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418368, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418372, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418368, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 11 19:19:38.361: INFO: all replica sets need to contain the pod-template-hash label
Oct 11 19:19:38.361: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418368, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418368, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418372, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418368, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 11 19:19:40.360: INFO: all replica sets need to contain the pod-template-hash label
Oct 11 19:19:40.360: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418368, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418368, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418372, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418368, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 11 19:19:42.361: INFO: 
Oct 11 19:19:42.361: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418368, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418368, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418372, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418368, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 11 19:19:44.360: INFO: 
Oct 11 19:19:44.360: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Oct 11 19:19:44.374: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-7493 /apis/apps/v1/namespaces/deployment-7493/deployments/test-rollover-deployment ce5bc167-527a-4621-9783-f06b71e26741 33014 2 2019-10-11 19:19:28 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00417f2e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-10-11 19:19:28 +0000 UTC,LastTransitionTime:2019-10-11 19:19:28 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2019-10-11 19:19:42 +0000 UTC,LastTransitionTime:2019-10-11 19:19:28 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Oct 11 19:19:44.378: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-7493 /apis/apps/v1/namespaces/deployment-7493/replicasets/test-rollover-deployment-7d7dc6548c e59d26a3-e8b9-4b80-939b-2ed15cfed00d 33004 2 2019-10-11 19:19:30 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment ce5bc167-527a-4621-9783-f06b71e26741 0xc00417f7a7 0xc00417f7a8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00417f808 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct 11 19:19:44.378: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Oct 11 19:19:44.378: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-7493 /apis/apps/v1/namespaces/deployment-7493/replicasets/test-rollover-controller 8908f1f1-2d2e-4f0f-8a69-9b8ca3865c6a 33013 2 2019-10-11 19:19:21 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment ce5bc167-527a-4621-9783-f06b71e26741 0xc00417f6d7 0xc00417f6d8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00417f738 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 11 19:19:44.378: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-7493 /apis/apps/v1/namespaces/deployment-7493/replicasets/test-rollover-deployment-f6c94f66c 558153f3-4935-425a-abd8-d8b567cd4bd8 32959 2 2019-10-11 19:19:28 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment ce5bc167-527a-4621-9783-f06b71e26741 0xc00417f870 0xc00417f871}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00417f8e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 11 19:19:44.383: INFO: Pod "test-rollover-deployment-7d7dc6548c-g7djv" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-g7djv test-rollover-deployment-7d7dc6548c- deployment-7493 /api/v1/namespaces/deployment-7493/pods/test-rollover-deployment-7d7dc6548c-g7djv b4dac1fe-d03f-4430-9333-de21d7fd9af4 32975 0 2019-10-11 19:19:30 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[cni.projectcalico.org/podIP:10.244.3.177/32] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c e59d26a3-e8b9-4b80-939b-2ed15cfed00d 0xc00417fe47 0xc00417fe48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-k7qz5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-k7qz5,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-k7qz5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-6-233.eu-west-3.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 19:19:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 19:19:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 19:19:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-11 19:19:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.6.233,PodIP:10.244.3.177,StartTime:2019-10-11 19:19:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-11 19:19:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://803b3e08b375453f5164847d2de3751eeaa4d3bf36953872e34e118f62b0afb1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.177,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:19:44.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7493" for this suite.
Oct 11 19:19:50.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:19:50.539: INFO: namespace deployment-7493 deletion completed in 6.151438555s

• [SLOW TEST:29.388 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:19:50.540: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-0bf6fea3-1cfe-49d0-a0c3-f8e16d697d40
STEP: Creating a pod to test consume secrets
Oct 11 19:19:50.596: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ff7ca315-9db3-4f57-a037-1508d61964ec" in namespace "projected-7068" to be "success or failure"
Oct 11 19:19:50.603: INFO: Pod "pod-projected-secrets-ff7ca315-9db3-4f57-a037-1508d61964ec": Phase="Pending", Reason="", readiness=false. Elapsed: 7.115853ms
Oct 11 19:19:52.611: INFO: Pod "pod-projected-secrets-ff7ca315-9db3-4f57-a037-1508d61964ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015392163s
STEP: Saw pod success
Oct 11 19:19:52.611: INFO: Pod "pod-projected-secrets-ff7ca315-9db3-4f57-a037-1508d61964ec" satisfied condition "success or failure"
Oct 11 19:19:52.616: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-projected-secrets-ff7ca315-9db3-4f57-a037-1508d61964ec container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 11 19:19:52.646: INFO: Waiting for pod pod-projected-secrets-ff7ca315-9db3-4f57-a037-1508d61964ec to disappear
Oct 11 19:19:52.650: INFO: Pod pod-projected-secrets-ff7ca315-9db3-4f57-a037-1508d61964ec no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:19:52.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7068" for this suite.
Oct 11 19:19:58.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:19:58.817: INFO: namespace projected-7068 deletion completed in 6.15927955s

• [SLOW TEST:8.277 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:19:58.817: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 11 19:19:58.915: INFO: Waiting up to 5m0s for pod "downwardapi-volume-acfb174a-85e8-4790-89ae-6a4bf029c009" in namespace "downward-api-9780" to be "success or failure"
Oct 11 19:19:58.920: INFO: Pod "downwardapi-volume-acfb174a-85e8-4790-89ae-6a4bf029c009": Phase="Pending", Reason="", readiness=false. Elapsed: 4.399584ms
Oct 11 19:20:00.924: INFO: Pod "downwardapi-volume-acfb174a-85e8-4790-89ae-6a4bf029c009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0092879s
STEP: Saw pod success
Oct 11 19:20:00.924: INFO: Pod "downwardapi-volume-acfb174a-85e8-4790-89ae-6a4bf029c009" satisfied condition "success or failure"
Oct 11 19:20:00.929: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod downwardapi-volume-acfb174a-85e8-4790-89ae-6a4bf029c009 container client-container: <nil>
STEP: delete the pod
Oct 11 19:20:00.977: INFO: Waiting for pod downwardapi-volume-acfb174a-85e8-4790-89ae-6a4bf029c009 to disappear
Oct 11 19:20:00.982: INFO: Pod downwardapi-volume-acfb174a-85e8-4790-89ae-6a4bf029c009 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:20:00.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9780" for this suite.
Oct 11 19:20:07.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:20:07.156: INFO: namespace downward-api-9780 deletion completed in 6.156878923s

• [SLOW TEST:8.339 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:20:07.157: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 19:20:07.228: INFO: Create a RollingUpdate DaemonSet
Oct 11 19:20:07.236: INFO: Check that daemon pods launch on every node of the cluster
Oct 11 19:20:07.242: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:20:07.242: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:20:07.242: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:20:07.246: INFO: Number of nodes with available pods: 0
Oct 11 19:20:07.246: INFO: Node ip-172-31-1-25.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:20:08.252: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:20:08.253: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:20:08.253: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:20:08.257: INFO: Number of nodes with available pods: 0
Oct 11 19:20:08.257: INFO: Node ip-172-31-1-25.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:20:09.252: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:20:09.252: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:20:09.252: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:20:09.259: INFO: Number of nodes with available pods: 1
Oct 11 19:20:09.259: INFO: Node ip-172-31-1-25.eu-west-3.compute.internal is running more than one daemon pod
Oct 11 19:20:10.263: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:20:10.263: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:20:10.263: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:20:10.268: INFO: Number of nodes with available pods: 3
Oct 11 19:20:10.268: INFO: Number of running nodes: 3, number of available pods: 3
Oct 11 19:20:10.268: INFO: Update the DaemonSet to trigger a rollout
Oct 11 19:20:10.285: INFO: Updating DaemonSet daemon-set
Oct 11 19:20:14.309: INFO: Roll back the DaemonSet before rollout is complete
Oct 11 19:20:14.318: INFO: Updating DaemonSet daemon-set
Oct 11 19:20:14.318: INFO: Make sure DaemonSet rollback is complete
Oct 11 19:20:14.323: INFO: Wrong image for pod: daemon-set-f8kpx. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Oct 11 19:20:14.323: INFO: Pod daemon-set-f8kpx is not available
Oct 11 19:20:14.327: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:20:14.327: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:20:14.328: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:20:15.333: INFO: Wrong image for pod: daemon-set-f8kpx. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Oct 11 19:20:15.334: INFO: Pod daemon-set-f8kpx is not available
Oct 11 19:20:15.340: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:20:15.340: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:20:15.340: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:20:16.337: INFO: Pod daemon-set-2x94q is not available
Oct 11 19:20:16.343: INFO: DaemonSet pods can't tolerate node ip-172-31-13-140.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:20:16.343: INFO: DaemonSet pods can't tolerate node ip-172-31-30-180.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 11 19:20:16.343: INFO: DaemonSet pods can't tolerate node ip-172-31-35-60.eu-west-3.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7198, will wait for the garbage collector to delete the pods
Oct 11 19:20:16.415: INFO: Deleting DaemonSet.extensions daemon-set took: 10.232451ms
Oct 11 19:20:16.815: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.148612ms
Oct 11 19:21:35.020: INFO: Number of nodes with available pods: 0
Oct 11 19:21:35.020: INFO: Number of running nodes: 0, number of available pods: 0
Oct 11 19:21:35.024: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7198/daemonsets","resourceVersion":"33486"},"items":null}

Oct 11 19:21:35.028: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7198/pods","resourceVersion":"33486"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:21:35.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7198" for this suite.
Oct 11 19:21:41.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:21:41.202: INFO: namespace daemonsets-7198 deletion completed in 6.151870638s

• [SLOW TEST:94.045 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:21:41.203: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Oct 11 19:21:45.805: INFO: Successfully updated pod "annotationupdate9bff028c-370d-4009-ba55-2fedc1cfd204"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:21:47.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2156" for this suite.
Oct 11 19:21:59.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:21:59.978: INFO: namespace downward-api-2156 deletion completed in 12.145996369s

• [SLOW TEST:18.775 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:21:59.979: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:22:29.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3953" for this suite.
Oct 11 19:22:35.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:22:35.527: INFO: namespace container-runtime-3953 deletion completed in 6.149512472s

• [SLOW TEST:35.548 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:22:35.528: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-gmsg
STEP: Creating a pod to test atomic-volume-subpath
Oct 11 19:22:35.591: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-gmsg" in namespace "subpath-450" to be "success or failure"
Oct 11 19:22:35.596: INFO: Pod "pod-subpath-test-secret-gmsg": Phase="Pending", Reason="", readiness=false. Elapsed: 4.883444ms
Oct 11 19:22:37.601: INFO: Pod "pod-subpath-test-secret-gmsg": Phase="Running", Reason="", readiness=true. Elapsed: 2.009958588s
Oct 11 19:22:39.606: INFO: Pod "pod-subpath-test-secret-gmsg": Phase="Running", Reason="", readiness=true. Elapsed: 4.015094707s
Oct 11 19:22:41.611: INFO: Pod "pod-subpath-test-secret-gmsg": Phase="Running", Reason="", readiness=true. Elapsed: 6.02028043s
Oct 11 19:22:43.617: INFO: Pod "pod-subpath-test-secret-gmsg": Phase="Running", Reason="", readiness=true. Elapsed: 8.025849623s
Oct 11 19:22:45.621: INFO: Pod "pod-subpath-test-secret-gmsg": Phase="Running", Reason="", readiness=true. Elapsed: 10.030354843s
Oct 11 19:22:47.626: INFO: Pod "pod-subpath-test-secret-gmsg": Phase="Running", Reason="", readiness=true. Elapsed: 12.03519276s
Oct 11 19:22:49.631: INFO: Pod "pod-subpath-test-secret-gmsg": Phase="Running", Reason="", readiness=true. Elapsed: 14.040071545s
Oct 11 19:22:51.639: INFO: Pod "pod-subpath-test-secret-gmsg": Phase="Running", Reason="", readiness=true. Elapsed: 16.047918995s
Oct 11 19:22:53.644: INFO: Pod "pod-subpath-test-secret-gmsg": Phase="Running", Reason="", readiness=true. Elapsed: 18.05313013s
Oct 11 19:22:55.649: INFO: Pod "pod-subpath-test-secret-gmsg": Phase="Running", Reason="", readiness=true. Elapsed: 20.057950777s
Oct 11 19:22:57.657: INFO: Pod "pod-subpath-test-secret-gmsg": Phase="Running", Reason="", readiness=true. Elapsed: 22.066689001s
Oct 11 19:22:59.663: INFO: Pod "pod-subpath-test-secret-gmsg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.072338567s
STEP: Saw pod success
Oct 11 19:22:59.663: INFO: Pod "pod-subpath-test-secret-gmsg" satisfied condition "success or failure"
Oct 11 19:22:59.667: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod pod-subpath-test-secret-gmsg container test-container-subpath-secret-gmsg: <nil>
STEP: delete the pod
Oct 11 19:22:59.693: INFO: Waiting for pod pod-subpath-test-secret-gmsg to disappear
Oct 11 19:22:59.697: INFO: Pod pod-subpath-test-secret-gmsg no longer exists
STEP: Deleting pod pod-subpath-test-secret-gmsg
Oct 11 19:22:59.697: INFO: Deleting pod "pod-subpath-test-secret-gmsg" in namespace "subpath-450"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:22:59.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-450" for this suite.
Oct 11 19:23:05.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:23:05.854: INFO: namespace subpath-450 deletion completed in 6.147352298s

• [SLOW TEST:30.326 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:23:05.855: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 11 19:23:05.903: INFO: Waiting up to 5m0s for pod "pod-1d9f9236-2c74-4aff-a3f4-b672118ccff3" in namespace "emptydir-183" to be "success or failure"
Oct 11 19:23:05.909: INFO: Pod "pod-1d9f9236-2c74-4aff-a3f4-b672118ccff3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.287519ms
Oct 11 19:23:07.914: INFO: Pod "pod-1d9f9236-2c74-4aff-a3f4-b672118ccff3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011118915s
STEP: Saw pod success
Oct 11 19:23:07.914: INFO: Pod "pod-1d9f9236-2c74-4aff-a3f4-b672118ccff3" satisfied condition "success or failure"
Oct 11 19:23:07.918: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod pod-1d9f9236-2c74-4aff-a3f4-b672118ccff3 container test-container: <nil>
STEP: delete the pod
Oct 11 19:23:07.943: INFO: Waiting for pod pod-1d9f9236-2c74-4aff-a3f4-b672118ccff3 to disappear
Oct 11 19:23:07.946: INFO: Pod pod-1d9f9236-2c74-4aff-a3f4-b672118ccff3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:23:07.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-183" for this suite.
Oct 11 19:23:13.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:23:14.104: INFO: namespace emptydir-183 deletion completed in 6.152045084s

• [SLOW TEST:8.249 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:23:14.105: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Oct 11 19:23:14.158: INFO: Waiting up to 5m0s for pod "downward-api-6bd74a9e-8b9b-4590-b494-c81a42464e1a" in namespace "downward-api-2236" to be "success or failure"
Oct 11 19:23:14.163: INFO: Pod "downward-api-6bd74a9e-8b9b-4590-b494-c81a42464e1a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.041202ms
Oct 11 19:23:16.168: INFO: Pod "downward-api-6bd74a9e-8b9b-4590-b494-c81a42464e1a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009942885s
Oct 11 19:23:18.173: INFO: Pod "downward-api-6bd74a9e-8b9b-4590-b494-c81a42464e1a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014842042s
STEP: Saw pod success
Oct 11 19:23:18.173: INFO: Pod "downward-api-6bd74a9e-8b9b-4590-b494-c81a42464e1a" satisfied condition "success or failure"
Oct 11 19:23:18.177: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod downward-api-6bd74a9e-8b9b-4590-b494-c81a42464e1a container dapi-container: <nil>
STEP: delete the pod
Oct 11 19:23:18.214: INFO: Waiting for pod downward-api-6bd74a9e-8b9b-4590-b494-c81a42464e1a to disappear
Oct 11 19:23:18.218: INFO: Pod downward-api-6bd74a9e-8b9b-4590-b494-c81a42464e1a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:23:18.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2236" for this suite.
Oct 11 19:23:24.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:23:24.384: INFO: namespace downward-api-2236 deletion completed in 6.156274131s

• [SLOW TEST:10.279 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:23:24.384: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:23:41.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4020" for this suite.
Oct 11 19:23:47.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:23:47.631: INFO: namespace resourcequota-4020 deletion completed in 6.149785285s

• [SLOW TEST:23.247 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:23:47.632: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-38a4661c-325b-4336-b603-a0ff2a6fd2d2
STEP: Creating a pod to test consume secrets
Oct 11 19:23:47.684: INFO: Waiting up to 5m0s for pod "pod-secrets-5a275d7d-bd96-49be-a2bc-f390c6cab6c9" in namespace "secrets-7174" to be "success or failure"
Oct 11 19:23:47.688: INFO: Pod "pod-secrets-5a275d7d-bd96-49be-a2bc-f390c6cab6c9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.346182ms
Oct 11 19:23:49.693: INFO: Pod "pod-secrets-5a275d7d-bd96-49be-a2bc-f390c6cab6c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009300673s
Oct 11 19:23:51.698: INFO: Pod "pod-secrets-5a275d7d-bd96-49be-a2bc-f390c6cab6c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013970566s
STEP: Saw pod success
Oct 11 19:23:51.698: INFO: Pod "pod-secrets-5a275d7d-bd96-49be-a2bc-f390c6cab6c9" satisfied condition "success or failure"
Oct 11 19:23:51.702: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-secrets-5a275d7d-bd96-49be-a2bc-f390c6cab6c9 container secret-volume-test: <nil>
STEP: delete the pod
Oct 11 19:23:51.727: INFO: Waiting for pod pod-secrets-5a275d7d-bd96-49be-a2bc-f390c6cab6c9 to disappear
Oct 11 19:23:51.732: INFO: Pod pod-secrets-5a275d7d-bd96-49be-a2bc-f390c6cab6c9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:23:51.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7174" for this suite.
Oct 11 19:23:57.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:23:57.884: INFO: namespace secrets-7174 deletion completed in 6.146875547s

• [SLOW TEST:10.252 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:23:57.884: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-09cd4353-f3a6-43a3-af3b-572ee5457868
STEP: Creating secret with name s-test-opt-upd-9bb6451c-d826-4bee-9c7b-ec77e56cace1
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-09cd4353-f3a6-43a3-af3b-572ee5457868
STEP: Updating secret s-test-opt-upd-9bb6451c-d826-4bee-9c7b-ec77e56cace1
STEP: Creating secret with name s-test-opt-create-4c914805-7d20-40a9-b3a5-71c2640a2b83
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:25:12.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7205" for this suite.
Oct 11 19:25:40.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:25:40.678: INFO: namespace projected-7205 deletion completed in 28.177180433s

• [SLOW TEST:102.794 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:25:40.679: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 11 19:25:40.997: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 11 19:25:43.010: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418741, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418741, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418741, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418741, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 11 19:25:46.033: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:25:56.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1084" for this suite.
Oct 11 19:26:02.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:26:02.319: INFO: namespace webhook-1084 deletion completed in 6.152258194s
STEP: Destroying namespace "webhook-1084-markers" for this suite.
Oct 11 19:26:08.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:26:08.481: INFO: namespace webhook-1084-markers deletion completed in 6.161347253s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:27.830 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:26:08.509: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1011 19:26:39.099773      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 11 19:26:39.099: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:26:39.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2704" for this suite.
Oct 11 19:26:45.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:26:45.274: INFO: namespace gc-2704 deletion completed in 6.169180237s

• [SLOW TEST:36.765 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:26:45.274: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 19:27:09.340: INFO: Container started at 2019-10-11 19:26:46 +0000 UTC, pod became ready at 2019-10-11 19:27:09 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:27:09.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3149" for this suite.
Oct 11 19:27:37.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:27:37.500: INFO: namespace container-probe-3149 deletion completed in 28.154857675s

• [SLOW TEST:52.226 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:27:37.502: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Oct 11 19:27:42.095: INFO: Successfully updated pod "labelsupdate817a94ed-be59-4ae8-a9c1-5ac8e17dbb3c"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:27:44.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4810" for this suite.
Oct 11 19:27:56.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:27:56.288: INFO: namespace downward-api-4810 deletion completed in 12.153560913s

• [SLOW TEST:18.786 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:27:56.288: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-846d6f80-b410-494f-8dee-379bc3467d61
STEP: Creating a pod to test consume secrets
Oct 11 19:27:56.350: INFO: Waiting up to 5m0s for pod "pod-secrets-9d8d3b31-923e-463c-ac8d-d935cfc254f5" in namespace "secrets-5810" to be "success or failure"
Oct 11 19:27:56.375: INFO: Pod "pod-secrets-9d8d3b31-923e-463c-ac8d-d935cfc254f5": Phase="Pending", Reason="", readiness=false. Elapsed: 25.31564ms
Oct 11 19:27:58.380: INFO: Pod "pod-secrets-9d8d3b31-923e-463c-ac8d-d935cfc254f5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030150395s
Oct 11 19:28:00.385: INFO: Pod "pod-secrets-9d8d3b31-923e-463c-ac8d-d935cfc254f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035307466s
STEP: Saw pod success
Oct 11 19:28:00.385: INFO: Pod "pod-secrets-9d8d3b31-923e-463c-ac8d-d935cfc254f5" satisfied condition "success or failure"
Oct 11 19:28:00.390: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod pod-secrets-9d8d3b31-923e-463c-ac8d-d935cfc254f5 container secret-volume-test: <nil>
STEP: delete the pod
Oct 11 19:28:00.424: INFO: Waiting for pod pod-secrets-9d8d3b31-923e-463c-ac8d-d935cfc254f5 to disappear
Oct 11 19:28:00.428: INFO: Pod pod-secrets-9d8d3b31-923e-463c-ac8d-d935cfc254f5 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:28:00.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5810" for this suite.
Oct 11 19:28:06.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:28:06.586: INFO: namespace secrets-5810 deletion completed in 6.152399663s

• [SLOW TEST:10.298 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:28:06.587: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:28:37.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4115" for this suite.
Oct 11 19:28:43.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:28:43.960: INFO: namespace namespaces-4115 deletion completed in 6.145462158s
STEP: Destroying namespace "nsdeletetest-4049" for this suite.
Oct 11 19:28:43.964: INFO: Namespace nsdeletetest-4049 was already deleted
STEP: Destroying namespace "nsdeletetest-4920" for this suite.
Oct 11 19:28:49.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:28:50.109: INFO: namespace nsdeletetest-4920 deletion completed in 6.144202422s

• [SLOW TEST:43.522 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:28:50.109: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:28:50.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9298" for this suite.
Oct 11 19:28:56.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:28:56.325: INFO: namespace services-9298 deletion completed in 6.154195549s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.216 seconds]
[sig-network] Services
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:28:56.326: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 11 19:28:56.904: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 11 19:28:58.917: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418936, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418936, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418936, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706418936, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 11 19:29:01.939: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:29:01.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6384" for this suite.
Oct 11 19:29:08.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:29:08.156: INFO: namespace webhook-6384 deletion completed in 6.15706777s
STEP: Destroying namespace "webhook-6384-markers" for this suite.
Oct 11 19:29:14.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:29:14.313: INFO: namespace webhook-6384-markers deletion completed in 6.156444356s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.012 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:29:14.338: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 11 19:29:18.918: INFO: Successfully updated pod "pod-update-69c54f43-9c25-4f9d-b604-137eea151343"
STEP: verifying the updated pod is in kubernetes
Oct 11 19:29:18.930: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:29:18.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1313" for this suite.
Oct 11 19:29:46.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:29:47.094: INFO: namespace pods-1313 deletion completed in 28.158262918s

• [SLOW TEST:32.756 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:29:47.094: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Oct 11 19:29:47.130: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Oct 11 19:30:00.082: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 19:30:03.125: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:30:16.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9121" for this suite.
Oct 11 19:30:22.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:30:22.350: INFO: namespace crd-publish-openapi-9121 deletion completed in 6.16726732s

• [SLOW TEST:35.256 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:30:22.351: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-8228
STEP: creating replication controller nodeport-test in namespace services-8228
I1011 19:30:22.470085      19 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-8228, replica count: 2
I1011 19:30:25.520570      19 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 11 19:30:25.520: INFO: Creating new exec pod
Oct 11 19:30:30.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=services-8228 execpodx8czp -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Oct 11 19:30:30.967: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Oct 11 19:30:30.967: INFO: stdout: ""
Oct 11 19:30:30.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=services-8228 execpodx8czp -- /bin/sh -x -c nc -zv -t -w 2 10.102.100.3 80'
Oct 11 19:30:31.272: INFO: stderr: "+ nc -zv -t -w 2 10.102.100.3 80\nConnection to 10.102.100.3 80 port [tcp/http] succeeded!\n"
Oct 11 19:30:31.272: INFO: stdout: ""
Oct 11 19:30:31.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=services-8228 execpodx8czp -- /bin/sh -x -c nc -zv -t -w 2 172.31.1.25 32251'
Oct 11 19:30:31.615: INFO: stderr: "+ nc -zv -t -w 2 172.31.1.25 32251\nConnection to 172.31.1.25 32251 port [tcp/32251] succeeded!\n"
Oct 11 19:30:31.615: INFO: stdout: ""
Oct 11 19:30:31.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=services-8228 execpodx8czp -- /bin/sh -x -c nc -zv -t -w 2 172.31.5.54 32251'
Oct 11 19:30:31.931: INFO: stderr: "+ nc -zv -t -w 2 172.31.5.54 32251\nConnection to 172.31.5.54 32251 port [tcp/32251] succeeded!\n"
Oct 11 19:30:31.931: INFO: stdout: ""
Oct 11 19:30:31.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=services-8228 execpodx8czp -- /bin/sh -x -c nc -zv -t -w 2 35.180.123.192 32251'
Oct 11 19:30:32.246: INFO: stderr: "+ nc -zv -t -w 2 35.180.123.192 32251\nConnection to 35.180.123.192 32251 port [tcp/32251] succeeded!\n"
Oct 11 19:30:32.246: INFO: stdout: ""
Oct 11 19:30:32.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-158339303 exec --namespace=services-8228 execpodx8czp -- /bin/sh -x -c nc -zv -t -w 2 35.180.210.201 32251'
Oct 11 19:30:32.558: INFO: stderr: "+ nc -zv -t -w 2 35.180.210.201 32251\nConnection to 35.180.210.201 32251 port [tcp/32251] succeeded!\n"
Oct 11 19:30:32.558: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:30:32.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8228" for this suite.
Oct 11 19:30:38.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:30:38.721: INFO: namespace services-8228 deletion completed in 6.156866591s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:16.370 seconds]
[sig-network] Services
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:30:38.721: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-8592
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 11 19:30:38.756: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 11 19:31:04.895: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.4.162:8080/dial?request=hostName&protocol=udp&host=10.244.5.67&port=8081&tries=1'] Namespace:pod-network-test-8592 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 11 19:31:04.895: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 19:31:05.093: INFO: Waiting for endpoints: map[]
Oct 11 19:31:05.097: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.4.162:8080/dial?request=hostName&protocol=udp&host=10.244.3.190&port=8081&tries=1'] Namespace:pod-network-test-8592 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 11 19:31:05.097: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 19:31:05.311: INFO: Waiting for endpoints: map[]
Oct 11 19:31:05.316: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.4.162:8080/dial?request=hostName&protocol=udp&host=10.244.4.161&port=8081&tries=1'] Namespace:pod-network-test-8592 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 11 19:31:05.316: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
Oct 11 19:31:05.547: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:31:05.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8592" for this suite.
Oct 11 19:31:17.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:31:17.718: INFO: namespace pod-network-test-8592 deletion completed in 12.164514861s

• [SLOW TEST:38.997 seconds]
[sig-network] Networking
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:31:17.719: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 11 19:31:17.769: INFO: Waiting up to 5m0s for pod "pod-fab4f8d7-52ca-47a6-9be7-915427dd2150" in namespace "emptydir-3130" to be "success or failure"
Oct 11 19:31:17.774: INFO: Pod "pod-fab4f8d7-52ca-47a6-9be7-915427dd2150": Phase="Pending", Reason="", readiness=false. Elapsed: 4.901685ms
Oct 11 19:31:19.779: INFO: Pod "pod-fab4f8d7-52ca-47a6-9be7-915427dd2150": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009354132s
Oct 11 19:31:21.784: INFO: Pod "pod-fab4f8d7-52ca-47a6-9be7-915427dd2150": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01416823s
STEP: Saw pod success
Oct 11 19:31:21.784: INFO: Pod "pod-fab4f8d7-52ca-47a6-9be7-915427dd2150" satisfied condition "success or failure"
Oct 11 19:31:21.788: INFO: Trying to get logs from node ip-172-31-6-233.eu-west-3.compute.internal pod pod-fab4f8d7-52ca-47a6-9be7-915427dd2150 container test-container: <nil>
STEP: delete the pod
Oct 11 19:31:21.822: INFO: Waiting for pod pod-fab4f8d7-52ca-47a6-9be7-915427dd2150 to disappear
Oct 11 19:31:21.826: INFO: Pod pod-fab4f8d7-52ca-47a6-9be7-915427dd2150 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:31:21.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3130" for this suite.
Oct 11 19:31:27.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:31:28.127: INFO: namespace emptydir-3130 deletion completed in 6.294827383s

• [SLOW TEST:10.408 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:31:28.127: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 19:31:28.188: INFO: (0) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 14.073758ms)
Oct 11 19:31:28.194: INFO: (1) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.447295ms)
Oct 11 19:31:28.199: INFO: (2) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.383333ms)
Oct 11 19:31:28.204: INFO: (3) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.160534ms)
Oct 11 19:31:28.210: INFO: (4) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.25644ms)
Oct 11 19:31:28.219: INFO: (5) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 9.154213ms)
Oct 11 19:31:28.224: INFO: (6) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.241363ms)
Oct 11 19:31:28.229: INFO: (7) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.261211ms)
Oct 11 19:31:28.234: INFO: (8) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.059921ms)
Oct 11 19:31:28.240: INFO: (9) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.201404ms)
Oct 11 19:31:28.246: INFO: (10) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 6.822656ms)
Oct 11 19:31:28.252: INFO: (11) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.19652ms)
Oct 11 19:31:28.257: INFO: (12) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.347285ms)
Oct 11 19:31:28.262: INFO: (13) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.186972ms)
Oct 11 19:31:28.267: INFO: (14) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.092002ms)
Oct 11 19:31:28.273: INFO: (15) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.263731ms)
Oct 11 19:31:28.278: INFO: (16) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.097168ms)
Oct 11 19:31:28.283: INFO: (17) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.999056ms)
Oct 11 19:31:28.288: INFO: (18) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.921925ms)
Oct 11 19:31:28.293: INFO: (19) /api/v1/nodes/ip-172-31-1-25.eu-west-3.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.157476ms)
[AfterEach] version v1
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:31:28.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5950" for this suite.
Oct 11 19:31:34.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:31:34.448: INFO: namespace proxy-5950 deletion completed in 6.150400334s

• [SLOW TEST:6.321 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:31:34.449: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 11 19:31:34.764: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 11 19:31:36.778: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706419094, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706419094, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706419094, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706419094, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 11 19:31:39.798: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:31:39.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3031" for this suite.
Oct 11 19:31:45.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:31:45.964: INFO: namespace webhook-3031 deletion completed in 6.150235186s
STEP: Destroying namespace "webhook-3031-markers" for this suite.
Oct 11 19:31:51.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:31:52.109: INFO: namespace webhook-3031-markers deletion completed in 6.145581893s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.685 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:31:52.134: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Oct 11 19:31:56.741: INFO: Successfully updated pod "annotationupdate813d72ac-6226-4809-9209-344516a5bfc3"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:31:58.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2599" for this suite.
Oct 11 19:32:10.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:32:10.918: INFO: namespace projected-2599 deletion completed in 12.149455424s

• [SLOW TEST:18.785 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:32:10.919: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 11 19:32:15.015: INFO: Waiting up to 5m0s for pod "client-envvars-7fd04ab0-2692-477e-a790-93ca05294825" in namespace "pods-2163" to be "success or failure"
Oct 11 19:32:15.027: INFO: Pod "client-envvars-7fd04ab0-2692-477e-a790-93ca05294825": Phase="Pending", Reason="", readiness=false. Elapsed: 11.10517ms
Oct 11 19:32:17.031: INFO: Pod "client-envvars-7fd04ab0-2692-477e-a790-93ca05294825": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015990142s
STEP: Saw pod success
Oct 11 19:32:17.032: INFO: Pod "client-envvars-7fd04ab0-2692-477e-a790-93ca05294825" satisfied condition "success or failure"
Oct 11 19:32:17.036: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod client-envvars-7fd04ab0-2692-477e-a790-93ca05294825 container env3cont: <nil>
STEP: delete the pod
Oct 11 19:32:17.066: INFO: Waiting for pod client-envvars-7fd04ab0-2692-477e-a790-93ca05294825 to disappear
Oct 11 19:32:17.070: INFO: Pod client-envvars-7fd04ab0-2692-477e-a790-93ca05294825 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:32:17.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2163" for this suite.
Oct 11 19:32:45.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:32:45.239: INFO: namespace pods-2163 deletion completed in 28.163045455s

• [SLOW TEST:34.320 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:32:45.239: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:32:52.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9375" for this suite.
Oct 11 19:32:58.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:32:58.443: INFO: namespace resourcequota-9375 deletion completed in 6.145023074s

• [SLOW TEST:13.204 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:32:58.444: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-ef0bf6f0-76b0-4408-a3d2-1f34ba8090dd
STEP: Creating a pod to test consume configMaps
Oct 11 19:32:58.496: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a91d4a5b-18a3-4f3c-9cd7-5640a6a007d7" in namespace "projected-9736" to be "success or failure"
Oct 11 19:32:58.502: INFO: Pod "pod-projected-configmaps-a91d4a5b-18a3-4f3c-9cd7-5640a6a007d7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.944246ms
Oct 11 19:33:00.506: INFO: Pod "pod-projected-configmaps-a91d4a5b-18a3-4f3c-9cd7-5640a6a007d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010545931s
STEP: Saw pod success
Oct 11 19:33:00.506: INFO: Pod "pod-projected-configmaps-a91d4a5b-18a3-4f3c-9cd7-5640a6a007d7" satisfied condition "success or failure"
Oct 11 19:33:00.511: INFO: Trying to get logs from node ip-172-31-5-54.eu-west-3.compute.internal pod pod-projected-configmaps-a91d4a5b-18a3-4f3c-9cd7-5640a6a007d7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 11 19:33:00.546: INFO: Waiting for pod pod-projected-configmaps-a91d4a5b-18a3-4f3c-9cd7-5640a6a007d7 to disappear
Oct 11 19:33:00.551: INFO: Pod pod-projected-configmaps-a91d4a5b-18a3-4f3c-9cd7-5640a6a007d7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:33:00.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9736" for this suite.
Oct 11 19:33:06.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:33:06.704: INFO: namespace projected-9736 deletion completed in 6.147675308s

• [SLOW TEST:8.261 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 11 19:33:06.705: INFO: >>> kubeConfig: /tmp/kubeconfig-158339303
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1989
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Oct 11 19:33:06.762: INFO: Found 0 stateful pods, waiting for 3
Oct 11 19:33:16.768: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 11 19:33:16.768: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 11 19:33:16.768: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Oct 11 19:33:16.800: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Oct 11 19:33:26.839: INFO: Updating stateful set ss2
Oct 11 19:33:26.854: INFO: Waiting for Pod statefulset-1989/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Oct 11 19:33:36.913: INFO: Found 2 stateful pods, waiting for 3
Oct 11 19:33:46.922: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 11 19:33:46.922: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 11 19:33:46.922: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Oct 11 19:33:46.949: INFO: Updating stateful set ss2
Oct 11 19:33:46.959: INFO: Waiting for Pod statefulset-1989/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Oct 11 19:33:56.989: INFO: Updating stateful set ss2
Oct 11 19:33:57.002: INFO: Waiting for StatefulSet statefulset-1989/ss2 to complete update
Oct 11 19:33:57.002: INFO: Waiting for Pod statefulset-1989/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Oct 11 19:34:07.012: INFO: Waiting for StatefulSet statefulset-1989/ss2 to complete update
Oct 11 19:34:07.012: INFO: Waiting for Pod statefulset-1989/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct 11 19:34:17.012: INFO: Deleting all statefulset in ns statefulset-1989
Oct 11 19:34:17.016: INFO: Scaling statefulset ss2 to 0
Oct 11 19:34:37.035: INFO: Waiting for statefulset status.replicas updated to 0
Oct 11 19:34:37.039: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 11 19:34:37.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1989" for this suite.
Oct 11 19:34:43.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 11 19:34:43.206: INFO: namespace statefulset-1989 deletion completed in 6.143931383s

• [SLOW TEST:96.502 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSOct 11 19:34:43.207: INFO: Running AfterSuite actions on all nodes
Oct 11 19:34:43.207: INFO: Running AfterSuite actions on node 1
Oct 11 19:34:43.207: INFO: Skipping dumping logs from cluster

Ran 276 of 4897 Specs in 7572.988 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Pending | 4621 Skipped
PASS

Ginkgo ran 1 suite in 2h6m15.348792546s
Test Suite Passed
