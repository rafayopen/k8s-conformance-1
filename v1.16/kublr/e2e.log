I1224 01:20:09.157428      24 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-304826164
I1224 01:20:09.157539      24 e2e.go:92] Starting e2e run "2afe0d8d-0f39-465e-b92e-1b3f48c83b46" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1577150407 - Will randomize all specs
Will run 274 of 4731 specs

Dec 24 01:20:09.213: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 01:20:09.215: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec 24 01:20:09.242: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec 24 01:20:09.295: INFO: 55 / 55 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec 24 01:20:09.295: INFO: expected 10 pod replicas in namespace 'kube-system', 10 are Running and Ready.
Dec 24 01:20:09.295: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec 24 01:20:09.306: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
Dec 24 01:20:09.307: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Dec 24 01:20:09.307: INFO: e2e test version: v1.16.4
Dec 24 01:20:09.309: INFO: kube-apiserver version: v1.16.4
Dec 24 01:20:09.309: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 01:20:09.316: INFO: Cluster IP family: ipv4
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:20:09.317: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename init-container
Dec 24 01:20:09.411: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Dec 24 01:20:09.430: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-3993
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 24 01:20:09.545: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:20:12.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3993" for this suite.
Dec 24 01:20:18.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:20:18.955: INFO: namespace init-container-3993 deletion completed in 6.231514835s

• [SLOW TEST:9.639 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:20:18.956: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7360
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:20:32.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7360" for this suite.
Dec 24 01:20:38.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:20:38.430: INFO: namespace resourcequota-7360 deletion completed in 6.175513913s

• [SLOW TEST:19.474 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:20:38.430: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5989
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-a5c6e344-4bf7-4497-a3d9-ad91a81cacd4
STEP: Creating secret with name secret-projected-all-test-volume-494fed7a-ac92-46b4-8566-d796a716ddb5
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec 24 01:20:38.601: INFO: Waiting up to 5m0s for pod "projected-volume-5c2cda05-358b-4ac8-a670-503937b87c36" in namespace "projected-5989" to be "success or failure"
Dec 24 01:20:38.607: INFO: Pod "projected-volume-5c2cda05-358b-4ac8-a670-503937b87c36": Phase="Pending", Reason="", readiness=false. Elapsed: 5.998593ms
Dec 24 01:20:40.612: INFO: Pod "projected-volume-5c2cda05-358b-4ac8-a670-503937b87c36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011196987s
Dec 24 01:20:42.619: INFO: Pod "projected-volume-5c2cda05-358b-4ac8-a670-503937b87c36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018278003s
STEP: Saw pod success
Dec 24 01:20:42.619: INFO: Pod "projected-volume-5c2cda05-358b-4ac8-a670-503937b87c36" satisfied condition "success or failure"
Dec 24 01:20:42.623: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod projected-volume-5c2cda05-358b-4ac8-a670-503937b87c36 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec 24 01:20:42.651: INFO: Waiting for pod projected-volume-5c2cda05-358b-4ac8-a670-503937b87c36 to disappear
Dec 24 01:20:42.654: INFO: Pod projected-volume-5c2cda05-358b-4ac8-a670-503937b87c36 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:20:42.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5989" for this suite.
Dec 24 01:20:48.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:20:48.858: INFO: namespace projected-5989 deletion completed in 6.196418746s

• [SLOW TEST:10.428 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:20:48.859: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7657
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:21:05.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7657" for this suite.
Dec 24 01:21:11.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:21:11.340: INFO: namespace resourcequota-7657 deletion completed in 6.181667798s

• [SLOW TEST:22.482 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:21:11.341: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1885
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 24 01:21:11.505: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a0422381-c678-40fb-b1a9-d9c75674dad2" in namespace "downward-api-1885" to be "success or failure"
Dec 24 01:21:11.516: INFO: Pod "downwardapi-volume-a0422381-c678-40fb-b1a9-d9c75674dad2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.199795ms
Dec 24 01:21:13.522: INFO: Pod "downwardapi-volume-a0422381-c678-40fb-b1a9-d9c75674dad2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017524865s
Dec 24 01:21:15.529: INFO: Pod "downwardapi-volume-a0422381-c678-40fb-b1a9-d9c75674dad2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024104309s
STEP: Saw pod success
Dec 24 01:21:15.529: INFO: Pod "downwardapi-volume-a0422381-c678-40fb-b1a9-d9c75674dad2" satisfied condition "success or failure"
Dec 24 01:21:15.533: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod downwardapi-volume-a0422381-c678-40fb-b1a9-d9c75674dad2 container client-container: <nil>
STEP: delete the pod
Dec 24 01:21:15.563: INFO: Waiting for pod downwardapi-volume-a0422381-c678-40fb-b1a9-d9c75674dad2 to disappear
Dec 24 01:21:15.568: INFO: Pod downwardapi-volume-a0422381-c678-40fb-b1a9-d9c75674dad2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:21:15.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1885" for this suite.
Dec 24 01:21:21.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:21:21.738: INFO: namespace downward-api-1885 deletion completed in 6.161823633s

• [SLOW TEST:10.397 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:21:21.738: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9378
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 01:21:21.924: INFO: Create a RollingUpdate DaemonSet
Dec 24 01:21:21.930: INFO: Check that daemon pods launch on every node of the cluster
Dec 24 01:21:21.943: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:21.943: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:21.943: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:21.948: INFO: Number of nodes with available pods: 0
Dec 24 01:21:21.948: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:21:22.957: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:22.957: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:22.957: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:22.963: INFO: Number of nodes with available pods: 0
Dec 24 01:21:22.963: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:21:23.958: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:23.958: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:23.958: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:23.962: INFO: Number of nodes with available pods: 0
Dec 24 01:21:23.962: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:21:24.957: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:24.957: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:24.957: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:24.962: INFO: Number of nodes with available pods: 3
Dec 24 01:21:24.962: INFO: Number of running nodes: 3, number of available pods: 3
Dec 24 01:21:24.962: INFO: Update the DaemonSet to trigger a rollout
Dec 24 01:21:24.973: INFO: Updating DaemonSet daemon-set
Dec 24 01:21:29.002: INFO: Roll back the DaemonSet before rollout is complete
Dec 24 01:21:29.022: INFO: Updating DaemonSet daemon-set
Dec 24 01:21:29.022: INFO: Make sure DaemonSet rollback is complete
Dec 24 01:21:29.032: INFO: Wrong image for pod: daemon-set-9ck8c. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 24 01:21:29.032: INFO: Pod daemon-set-9ck8c is not available
Dec 24 01:21:29.040: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:29.040: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:29.040: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:30.046: INFO: Wrong image for pod: daemon-set-9ck8c. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 24 01:21:30.047: INFO: Pod daemon-set-9ck8c is not available
Dec 24 01:21:30.055: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:30.055: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:30.055: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:31.048: INFO: Wrong image for pod: daemon-set-9ck8c. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 24 01:21:31.048: INFO: Pod daemon-set-9ck8c is not available
Dec 24 01:21:31.054: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:31.054: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:31.054: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:32.047: INFO: Wrong image for pod: daemon-set-9ck8c. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 24 01:21:32.047: INFO: Pod daemon-set-9ck8c is not available
Dec 24 01:21:32.055: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:32.056: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:32.056: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:33.047: INFO: Wrong image for pod: daemon-set-9ck8c. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 24 01:21:33.047: INFO: Pod daemon-set-9ck8c is not available
Dec 24 01:21:33.054: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:33.054: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:33.054: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:34.048: INFO: Wrong image for pod: daemon-set-9ck8c. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 24 01:21:34.048: INFO: Pod daemon-set-9ck8c is not available
Dec 24 01:21:34.054: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:34.054: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:34.054: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:35.047: INFO: Wrong image for pod: daemon-set-9ck8c. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 24 01:21:35.047: INFO: Pod daemon-set-9ck8c is not available
Dec 24 01:21:35.053: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:35.053: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:35.053: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:36.045: INFO: Wrong image for pod: daemon-set-9ck8c. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 24 01:21:36.045: INFO: Pod daemon-set-9ck8c is not available
Dec 24 01:21:36.052: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:36.052: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:36.052: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:37.046: INFO: Wrong image for pod: daemon-set-9ck8c. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 24 01:21:37.046: INFO: Pod daemon-set-9ck8c is not available
Dec 24 01:21:37.060: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:37.061: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:37.061: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:38.047: INFO: Wrong image for pod: daemon-set-9ck8c. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 24 01:21:38.047: INFO: Pod daemon-set-9ck8c is not available
Dec 24 01:21:38.054: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:38.054: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:38.054: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:39.045: INFO: Wrong image for pod: daemon-set-9ck8c. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 24 01:21:39.045: INFO: Pod daemon-set-9ck8c is not available
Dec 24 01:21:39.051: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:39.051: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:39.051: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:40.047: INFO: Pod daemon-set-tkw6b is not available
Dec 24 01:21:40.054: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:40.054: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:21:40.055: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9378, will wait for the garbage collector to delete the pods
Dec 24 01:21:40.133: INFO: Deleting DaemonSet.extensions daemon-set took: 16.670808ms
Dec 24 01:21:40.535: INFO: Terminating DaemonSet.extensions daemon-set pods took: 401.573819ms
Dec 24 01:21:45.243: INFO: Number of nodes with available pods: 0
Dec 24 01:21:45.243: INFO: Number of running nodes: 0, number of available pods: 0
Dec 24 01:21:45.250: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9378/daemonsets","resourceVersion":"114361"},"items":null}

Dec 24 01:21:45.254: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9378/pods","resourceVersion":"114361"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:21:45.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9378" for this suite.
Dec 24 01:21:51.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:21:51.451: INFO: namespace daemonsets-9378 deletion completed in 6.168514836s

• [SLOW TEST:29.713 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:21:51.451: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5682
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 24 01:21:52.022: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 24 01:21:54.038: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747312, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747312, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747312, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747312, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 24 01:21:57.065: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:21:57.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5682" for this suite.
Dec 24 01:22:03.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:22:03.292: INFO: namespace webhook-5682 deletion completed in 6.173999742s
STEP: Destroying namespace "webhook-5682-markers" for this suite.
Dec 24 01:22:09.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:22:09.511: INFO: namespace webhook-5682-markers deletion completed in 6.219216965s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.088 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:22:09.539: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4692
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-52933a2b-c75a-46c1-95ac-0013a84cc66d
STEP: Creating a pod to test consume secrets
Dec 24 01:22:09.718: INFO: Waiting up to 5m0s for pod "pod-secrets-994c5c4a-1abf-4990-ad3e-60604e0c9df1" in namespace "secrets-4692" to be "success or failure"
Dec 24 01:22:09.728: INFO: Pod "pod-secrets-994c5c4a-1abf-4990-ad3e-60604e0c9df1": Phase="Pending", Reason="", readiness=false. Elapsed: 9.373449ms
Dec 24 01:22:11.734: INFO: Pod "pod-secrets-994c5c4a-1abf-4990-ad3e-60604e0c9df1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015352564s
Dec 24 01:22:13.738: INFO: Pod "pod-secrets-994c5c4a-1abf-4990-ad3e-60604e0c9df1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01984836s
STEP: Saw pod success
Dec 24 01:22:13.738: INFO: Pod "pod-secrets-994c5c4a-1abf-4990-ad3e-60604e0c9df1" satisfied condition "success or failure"
Dec 24 01:22:13.743: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-secrets-994c5c4a-1abf-4990-ad3e-60604e0c9df1 container secret-volume-test: <nil>
STEP: delete the pod
Dec 24 01:22:13.772: INFO: Waiting for pod pod-secrets-994c5c4a-1abf-4990-ad3e-60604e0c9df1 to disappear
Dec 24 01:22:13.779: INFO: Pod pod-secrets-994c5c4a-1abf-4990-ad3e-60604e0c9df1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:22:13.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4692" for this suite.
Dec 24 01:22:19.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:22:20.078: INFO: namespace secrets-4692 deletion completed in 6.292399078s

• [SLOW TEST:10.539 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:22:20.079: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4101
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-4101
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4101 to expose endpoints map[]
Dec 24 01:22:20.254: INFO: successfully validated that service multi-endpoint-test in namespace services-4101 exposes endpoints map[] (5.963654ms elapsed)
STEP: Creating pod pod1 in namespace services-4101
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4101 to expose endpoints map[pod1:[100]]
Dec 24 01:22:23.313: INFO: successfully validated that service multi-endpoint-test in namespace services-4101 exposes endpoints map[pod1:[100]] (3.046923411s elapsed)
STEP: Creating pod pod2 in namespace services-4101
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4101 to expose endpoints map[pod1:[100] pod2:[101]]
Dec 24 01:22:26.376: INFO: successfully validated that service multi-endpoint-test in namespace services-4101 exposes endpoints map[pod1:[100] pod2:[101]] (3.057874025s elapsed)
STEP: Deleting pod pod1 in namespace services-4101
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4101 to expose endpoints map[pod2:[101]]
Dec 24 01:22:26.402: INFO: successfully validated that service multi-endpoint-test in namespace services-4101 exposes endpoints map[pod2:[101]] (15.294978ms elapsed)
STEP: Deleting pod pod2 in namespace services-4101
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4101 to expose endpoints map[]
Dec 24 01:22:26.425: INFO: successfully validated that service multi-endpoint-test in namespace services-4101 exposes endpoints map[] (9.364238ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:22:26.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4101" for this suite.
Dec 24 01:22:38.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:22:38.645: INFO: namespace services-4101 deletion completed in 12.176806709s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:18.566 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:22:38.645: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1583
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 24 01:22:39.460: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 24 01:22:41.478: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747359, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747359, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747359, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747359, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 24 01:22:44.514: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
Dec 24 01:22:54.544: INFO: Waiting for webhook configuration to be ready...
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:22:54.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1583" for this suite.
Dec 24 01:23:00.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:23:00.923: INFO: namespace webhook-1583 deletion completed in 6.170700393s
STEP: Destroying namespace "webhook-1583-markers" for this suite.
Dec 24 01:23:06.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:23:07.090: INFO: namespace webhook-1583-markers deletion completed in 6.167608503s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.468 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:23:07.113: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1300
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 24 01:23:07.278: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cd0b6f2b-dcde-435c-bbd7-9e6db26c0f06" in namespace "downward-api-1300" to be "success or failure"
Dec 24 01:23:07.287: INFO: Pod "downwardapi-volume-cd0b6f2b-dcde-435c-bbd7-9e6db26c0f06": Phase="Pending", Reason="", readiness=false. Elapsed: 8.957693ms
Dec 24 01:23:09.292: INFO: Pod "downwardapi-volume-cd0b6f2b-dcde-435c-bbd7-9e6db26c0f06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013417952s
Dec 24 01:23:11.297: INFO: Pod "downwardapi-volume-cd0b6f2b-dcde-435c-bbd7-9e6db26c0f06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0188484s
STEP: Saw pod success
Dec 24 01:23:11.297: INFO: Pod "downwardapi-volume-cd0b6f2b-dcde-435c-bbd7-9e6db26c0f06" satisfied condition "success or failure"
Dec 24 01:23:11.303: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod downwardapi-volume-cd0b6f2b-dcde-435c-bbd7-9e6db26c0f06 container client-container: <nil>
STEP: delete the pod
Dec 24 01:23:11.329: INFO: Waiting for pod downwardapi-volume-cd0b6f2b-dcde-435c-bbd7-9e6db26c0f06 to disappear
Dec 24 01:23:11.333: INFO: Pod downwardapi-volume-cd0b6f2b-dcde-435c-bbd7-9e6db26c0f06 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:23:11.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1300" for this suite.
Dec 24 01:23:17.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:23:17.505: INFO: namespace downward-api-1300 deletion completed in 6.164579836s

• [SLOW TEST:10.392 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:23:17.506: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2247
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-3165f1e7-c7fc-4d04-906a-0d84cf34a7e2
STEP: Creating a pod to test consume secrets
Dec 24 01:23:17.686: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a2105a85-a376-4be6-9399-8a909c90fd35" in namespace "projected-2247" to be "success or failure"
Dec 24 01:23:17.690: INFO: Pod "pod-projected-secrets-a2105a85-a376-4be6-9399-8a909c90fd35": Phase="Pending", Reason="", readiness=false. Elapsed: 4.099482ms
Dec 24 01:23:19.695: INFO: Pod "pod-projected-secrets-a2105a85-a376-4be6-9399-8a909c90fd35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008255444s
Dec 24 01:23:21.702: INFO: Pod "pod-projected-secrets-a2105a85-a376-4be6-9399-8a909c90fd35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015656053s
STEP: Saw pod success
Dec 24 01:23:21.702: INFO: Pod "pod-projected-secrets-a2105a85-a376-4be6-9399-8a909c90fd35" satisfied condition "success or failure"
Dec 24 01:23:21.708: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-projected-secrets-a2105a85-a376-4be6-9399-8a909c90fd35 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 24 01:23:21.738: INFO: Waiting for pod pod-projected-secrets-a2105a85-a376-4be6-9399-8a909c90fd35 to disappear
Dec 24 01:23:21.742: INFO: Pod pod-projected-secrets-a2105a85-a376-4be6-9399-8a909c90fd35 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:23:21.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2247" for this suite.
Dec 24 01:23:27.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:23:27.924: INFO: namespace projected-2247 deletion completed in 6.173582354s

• [SLOW TEST:10.419 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:23:27.924: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8555
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 01:23:28.080: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 24 01:23:36.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 --namespace=crd-publish-openapi-8555 create -f -'
Dec 24 01:23:37.914: INFO: stderr: ""
Dec 24 01:23:37.914: INFO: stdout: "e2e-test-crd-publish-openapi-4423-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 24 01:23:37.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 --namespace=crd-publish-openapi-8555 delete e2e-test-crd-publish-openapi-4423-crds test-cr'
Dec 24 01:23:38.059: INFO: stderr: ""
Dec 24 01:23:38.059: INFO: stdout: "e2e-test-crd-publish-openapi-4423-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Dec 24 01:23:38.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 --namespace=crd-publish-openapi-8555 apply -f -'
Dec 24 01:23:38.242: INFO: stderr: ""
Dec 24 01:23:38.242: INFO: stdout: "e2e-test-crd-publish-openapi-4423-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 24 01:23:38.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 --namespace=crd-publish-openapi-8555 delete e2e-test-crd-publish-openapi-4423-crds test-cr'
Dec 24 01:23:38.346: INFO: stderr: ""
Dec 24 01:23:38.346: INFO: stdout: "e2e-test-crd-publish-openapi-4423-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec 24 01:23:38.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 explain e2e-test-crd-publish-openapi-4423-crds'
Dec 24 01:23:38.647: INFO: stderr: ""
Dec 24 01:23:38.647: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4423-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:23:42.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8555" for this suite.
Dec 24 01:23:48.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:23:48.407: INFO: namespace crd-publish-openapi-8555 deletion completed in 6.135846762s

• [SLOW TEST:20.483 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:23:48.407: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1541
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:23:48.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1541" for this suite.
Dec 24 01:23:54.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:23:54.737: INFO: namespace resourcequota-1541 deletion completed in 6.134109286s

• [SLOW TEST:6.330 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:23:54.737: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-2887
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:23:54.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-2887" for this suite.
Dec 24 01:24:00.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:24:01.040: INFO: namespace tables-2887 deletion completed in 6.139448036s

• [SLOW TEST:6.303 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:24:01.040: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7335
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-5z2l
STEP: Creating a pod to test atomic-volume-subpath
Dec 24 01:24:01.212: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-5z2l" in namespace "subpath-7335" to be "success or failure"
Dec 24 01:24:01.219: INFO: Pod "pod-subpath-test-configmap-5z2l": Phase="Pending", Reason="", readiness=false. Elapsed: 6.630378ms
Dec 24 01:24:03.223: INFO: Pod "pod-subpath-test-configmap-5z2l": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011060028s
Dec 24 01:24:05.228: INFO: Pod "pod-subpath-test-configmap-5z2l": Phase="Running", Reason="", readiness=true. Elapsed: 4.01592786s
Dec 24 01:24:07.240: INFO: Pod "pod-subpath-test-configmap-5z2l": Phase="Running", Reason="", readiness=true. Elapsed: 6.027972572s
Dec 24 01:24:09.246: INFO: Pod "pod-subpath-test-configmap-5z2l": Phase="Running", Reason="", readiness=true. Elapsed: 8.033895806s
Dec 24 01:24:11.251: INFO: Pod "pod-subpath-test-configmap-5z2l": Phase="Running", Reason="", readiness=true. Elapsed: 10.038564721s
Dec 24 01:24:13.255: INFO: Pod "pod-subpath-test-configmap-5z2l": Phase="Running", Reason="", readiness=true. Elapsed: 12.042870153s
Dec 24 01:24:15.260: INFO: Pod "pod-subpath-test-configmap-5z2l": Phase="Running", Reason="", readiness=true. Elapsed: 14.047866775s
Dec 24 01:24:17.265: INFO: Pod "pod-subpath-test-configmap-5z2l": Phase="Running", Reason="", readiness=true. Elapsed: 16.052719718s
Dec 24 01:24:19.269: INFO: Pod "pod-subpath-test-configmap-5z2l": Phase="Running", Reason="", readiness=true. Elapsed: 18.057191793s
Dec 24 01:24:21.274: INFO: Pod "pod-subpath-test-configmap-5z2l": Phase="Running", Reason="", readiness=true. Elapsed: 20.062060334s
Dec 24 01:24:23.279: INFO: Pod "pod-subpath-test-configmap-5z2l": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.066818874s
STEP: Saw pod success
Dec 24 01:24:23.279: INFO: Pod "pod-subpath-test-configmap-5z2l" satisfied condition "success or failure"
Dec 24 01:24:23.283: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-subpath-test-configmap-5z2l container test-container-subpath-configmap-5z2l: <nil>
STEP: delete the pod
Dec 24 01:24:23.321: INFO: Waiting for pod pod-subpath-test-configmap-5z2l to disappear
Dec 24 01:24:23.327: INFO: Pod pod-subpath-test-configmap-5z2l no longer exists
STEP: Deleting pod pod-subpath-test-configmap-5z2l
Dec 24 01:24:23.327: INFO: Deleting pod "pod-subpath-test-configmap-5z2l" in namespace "subpath-7335"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:24:23.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7335" for this suite.
Dec 24 01:24:29.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:24:29.489: INFO: namespace subpath-7335 deletion completed in 6.151921383s

• [SLOW TEST:28.449 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:24:29.489: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2083
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-2083
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-2083
STEP: creating replication controller externalsvc in namespace services-2083
I1224 01:24:29.708718      24 runners.go:184] Created replication controller with name: externalsvc, namespace: services-2083, replica count: 2
I1224 01:24:32.765276      24 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Dec 24 01:24:32.795: INFO: Creating new exec pod
Dec 24 01:24:36.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=services-2083 execpodzz6jg -- /bin/sh -x -c nslookup clusterip-service'
Dec 24 01:24:37.101: INFO: stderr: "+ nslookup clusterip-service\n"
Dec 24 01:24:37.101: INFO: stdout: "Server:\t\t169.254.20.10\nAddress:\t169.254.20.10#53\n\nclusterip-service.services-2083.svc.cluster.local\tcanonical name = externalsvc.services-2083.svc.cluster.local.\nName:\texternalsvc.services-2083.svc.cluster.local\nAddress: 100.68.187.187\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-2083, will wait for the garbage collector to delete the pods
Dec 24 01:24:37.192: INFO: Deleting ReplicationController externalsvc took: 25.06426ms
Dec 24 01:24:37.592: INFO: Terminating ReplicationController externalsvc pods took: 400.276018ms
Dec 24 01:24:45.325: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:24:45.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2083" for this suite.
Dec 24 01:24:51.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:24:51.490: INFO: namespace services-2083 deletion completed in 6.1374755s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:22.002 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:24:51.491: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3387
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 01:24:51.642: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:24:55.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3387" for this suite.
Dec 24 01:25:39.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:25:39.848: INFO: namespace pods-3387 deletion completed in 44.135180369s

• [SLOW TEST:48.357 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:25:39.848: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2652
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Dec 24 01:25:40.012: INFO: Waiting up to 5m0s for pod "var-expansion-bc9a2f97-adde-4f8b-a3a5-8f7d6a56f95e" in namespace "var-expansion-2652" to be "success or failure"
Dec 24 01:25:40.018: INFO: Pod "var-expansion-bc9a2f97-adde-4f8b-a3a5-8f7d6a56f95e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.995978ms
Dec 24 01:25:42.023: INFO: Pod "var-expansion-bc9a2f97-adde-4f8b-a3a5-8f7d6a56f95e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010558003s
Dec 24 01:25:44.028: INFO: Pod "var-expansion-bc9a2f97-adde-4f8b-a3a5-8f7d6a56f95e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015444198s
STEP: Saw pod success
Dec 24 01:25:44.028: INFO: Pod "var-expansion-bc9a2f97-adde-4f8b-a3a5-8f7d6a56f95e" satisfied condition "success or failure"
Dec 24 01:25:44.032: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod var-expansion-bc9a2f97-adde-4f8b-a3a5-8f7d6a56f95e container dapi-container: <nil>
STEP: delete the pod
Dec 24 01:25:44.070: INFO: Waiting for pod var-expansion-bc9a2f97-adde-4f8b-a3a5-8f7d6a56f95e to disappear
Dec 24 01:25:44.078: INFO: Pod var-expansion-bc9a2f97-adde-4f8b-a3a5-8f7d6a56f95e no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:25:44.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2652" for this suite.
Dec 24 01:25:50.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:25:50.222: INFO: namespace var-expansion-2652 deletion completed in 6.138831572s

• [SLOW TEST:10.374 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:25:50.222: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7295
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-3b49fc83-08cc-46f7-97ee-946e0500d908
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:25:50.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7295" for this suite.
Dec 24 01:25:56.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:25:56.519: INFO: namespace configmap-7295 deletion completed in 6.139559735s

• [SLOW TEST:6.296 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:25:56.519: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2027
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 24 01:25:57.109: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 24 01:25:59.121: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747557, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747557, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747557, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747557, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 24 01:26:02.151: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:26:02.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2027" for this suite.
Dec 24 01:26:08.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:26:08.387: INFO: namespace webhook-2027 deletion completed in 6.135581628s
STEP: Destroying namespace "webhook-2027-markers" for this suite.
Dec 24 01:26:14.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:26:14.532: INFO: namespace webhook-2027-markers deletion completed in 6.144549133s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.034 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:26:14.553: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-8164
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 01:26:14.709: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-dfd19310-5153-4ab7-835d-72addb7ce116" in namespace "security-context-test-8164" to be "success or failure"
Dec 24 01:26:14.717: INFO: Pod "alpine-nnp-false-dfd19310-5153-4ab7-835d-72addb7ce116": Phase="Pending", Reason="", readiness=false. Elapsed: 8.041582ms
Dec 24 01:26:16.722: INFO: Pod "alpine-nnp-false-dfd19310-5153-4ab7-835d-72addb7ce116": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013195652s
Dec 24 01:26:18.727: INFO: Pod "alpine-nnp-false-dfd19310-5153-4ab7-835d-72addb7ce116": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017726395s
Dec 24 01:26:18.727: INFO: Pod "alpine-nnp-false-dfd19310-5153-4ab7-835d-72addb7ce116" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:26:18.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8164" for this suite.
Dec 24 01:26:24.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:26:24.879: INFO: namespace security-context-test-8164 deletion completed in 6.133986725s

• [SLOW TEST:10.326 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:26:24.879: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9934
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 24 01:26:25.043: INFO: Waiting up to 5m0s for pod "pod-14ba44e9-4344-4b7e-9850-53c2e679bc2e" in namespace "emptydir-9934" to be "success or failure"
Dec 24 01:26:25.049: INFO: Pod "pod-14ba44e9-4344-4b7e-9850-53c2e679bc2e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.560467ms
Dec 24 01:26:27.054: INFO: Pod "pod-14ba44e9-4344-4b7e-9850-53c2e679bc2e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010467276s
Dec 24 01:26:29.060: INFO: Pod "pod-14ba44e9-4344-4b7e-9850-53c2e679bc2e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015989049s
STEP: Saw pod success
Dec 24 01:26:29.060: INFO: Pod "pod-14ba44e9-4344-4b7e-9850-53c2e679bc2e" satisfied condition "success or failure"
Dec 24 01:26:29.067: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod pod-14ba44e9-4344-4b7e-9850-53c2e679bc2e container test-container: <nil>
STEP: delete the pod
Dec 24 01:26:29.102: INFO: Waiting for pod pod-14ba44e9-4344-4b7e-9850-53c2e679bc2e to disappear
Dec 24 01:26:29.105: INFO: Pod pod-14ba44e9-4344-4b7e-9850-53c2e679bc2e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:26:29.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9934" for this suite.
Dec 24 01:26:35.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:26:35.249: INFO: namespace emptydir-9934 deletion completed in 6.138414763s

• [SLOW TEST:10.370 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:26:35.249: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2488
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Dec 24 01:26:39.439: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-304826164 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec 24 01:26:44.551: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:26:44.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2488" for this suite.
Dec 24 01:26:50.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:26:50.696: INFO: namespace pods-2488 deletion completed in 6.135852802s

• [SLOW TEST:15.447 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:26:50.697: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7827
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 24 01:26:50.861: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4c7956da-2344-423e-9c80-f0cb414f58b6" in namespace "downward-api-7827" to be "success or failure"
Dec 24 01:26:50.865: INFO: Pod "downwardapi-volume-4c7956da-2344-423e-9c80-f0cb414f58b6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.770832ms
Dec 24 01:26:52.870: INFO: Pod "downwardapi-volume-4c7956da-2344-423e-9c80-f0cb414f58b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008595703s
Dec 24 01:26:54.875: INFO: Pod "downwardapi-volume-4c7956da-2344-423e-9c80-f0cb414f58b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013372125s
STEP: Saw pod success
Dec 24 01:26:54.875: INFO: Pod "downwardapi-volume-4c7956da-2344-423e-9c80-f0cb414f58b6" satisfied condition "success or failure"
Dec 24 01:26:54.879: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod downwardapi-volume-4c7956da-2344-423e-9c80-f0cb414f58b6 container client-container: <nil>
STEP: delete the pod
Dec 24 01:26:54.917: INFO: Waiting for pod downwardapi-volume-4c7956da-2344-423e-9c80-f0cb414f58b6 to disappear
Dec 24 01:26:54.921: INFO: Pod downwardapi-volume-4c7956da-2344-423e-9c80-f0cb414f58b6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:26:54.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7827" for this suite.
Dec 24 01:27:00.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:27:01.067: INFO: namespace downward-api-7827 deletion completed in 6.141080556s

• [SLOW TEST:10.370 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:27:01.067: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-3154
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 01:27:01.248: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:27:07.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3154" for this suite.
Dec 24 01:27:13.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:27:13.331: INFO: namespace custom-resource-definition-3154 deletion completed in 6.171676658s

• [SLOW TEST:12.263 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:27:13.331: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2990
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-80450d1f-1680-46d1-8f37-b596cff36830
STEP: Creating a pod to test consume configMaps
Dec 24 01:27:13.494: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5be403f7-4e90-466f-af0e-7328f295b3e4" in namespace "projected-2990" to be "success or failure"
Dec 24 01:27:13.508: INFO: Pod "pod-projected-configmaps-5be403f7-4e90-466f-af0e-7328f295b3e4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.537764ms
Dec 24 01:27:15.513: INFO: Pod "pod-projected-configmaps-5be403f7-4e90-466f-af0e-7328f295b3e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019439848s
Dec 24 01:27:17.517: INFO: Pod "pod-projected-configmaps-5be403f7-4e90-466f-af0e-7328f295b3e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0238736s
STEP: Saw pod success
Dec 24 01:27:17.517: INFO: Pod "pod-projected-configmaps-5be403f7-4e90-466f-af0e-7328f295b3e4" satisfied condition "success or failure"
Dec 24 01:27:17.522: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-projected-configmaps-5be403f7-4e90-466f-af0e-7328f295b3e4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 24 01:27:17.550: INFO: Waiting for pod pod-projected-configmaps-5be403f7-4e90-466f-af0e-7328f295b3e4 to disappear
Dec 24 01:27:17.554: INFO: Pod pod-projected-configmaps-5be403f7-4e90-466f-af0e-7328f295b3e4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:27:17.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2990" for this suite.
Dec 24 01:27:23.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:27:23.704: INFO: namespace projected-2990 deletion completed in 6.142724539s

• [SLOW TEST:10.374 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:27:23.705: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3120
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 24 01:27:24.584: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 24 01:27:26.598: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747644, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747644, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747644, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747644, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 24 01:27:29.623: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:27:29.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3120" for this suite.
Dec 24 01:27:35.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:27:35.883: INFO: namespace webhook-3120 deletion completed in 6.160909831s
STEP: Destroying namespace "webhook-3120-markers" for this suite.
Dec 24 01:27:41.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:27:42.028: INFO: namespace webhook-3120-markers deletion completed in 6.144899976s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.353 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:27:42.057: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8781
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 24 01:27:42.216: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1188ede8-f497-4cdc-b8a3-3ac7805b7f08" in namespace "downward-api-8781" to be "success or failure"
Dec 24 01:27:42.223: INFO: Pod "downwardapi-volume-1188ede8-f497-4cdc-b8a3-3ac7805b7f08": Phase="Pending", Reason="", readiness=false. Elapsed: 7.717181ms
Dec 24 01:27:44.228: INFO: Pod "downwardapi-volume-1188ede8-f497-4cdc-b8a3-3ac7805b7f08": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012030584s
Dec 24 01:27:46.232: INFO: Pod "downwardapi-volume-1188ede8-f497-4cdc-b8a3-3ac7805b7f08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016119051s
STEP: Saw pod success
Dec 24 01:27:46.232: INFO: Pod "downwardapi-volume-1188ede8-f497-4cdc-b8a3-3ac7805b7f08" satisfied condition "success or failure"
Dec 24 01:27:46.236: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod downwardapi-volume-1188ede8-f497-4cdc-b8a3-3ac7805b7f08 container client-container: <nil>
STEP: delete the pod
Dec 24 01:27:46.262: INFO: Waiting for pod downwardapi-volume-1188ede8-f497-4cdc-b8a3-3ac7805b7f08 to disappear
Dec 24 01:27:46.266: INFO: Pod downwardapi-volume-1188ede8-f497-4cdc-b8a3-3ac7805b7f08 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:27:46.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8781" for this suite.
Dec 24 01:27:52.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:27:52.424: INFO: namespace downward-api-8781 deletion completed in 6.152466806s

• [SLOW TEST:10.378 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:27:52.436: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-680
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 24 01:27:52.595: INFO: Waiting up to 5m0s for pod "downwardapi-volume-55afb309-2846-4f5f-b9f4-63393f950777" in namespace "projected-680" to be "success or failure"
Dec 24 01:27:52.610: INFO: Pod "downwardapi-volume-55afb309-2846-4f5f-b9f4-63393f950777": Phase="Pending", Reason="", readiness=false. Elapsed: 14.848987ms
Dec 24 01:27:54.614: INFO: Pod "downwardapi-volume-55afb309-2846-4f5f-b9f4-63393f950777": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019369851s
Dec 24 01:27:56.620: INFO: Pod "downwardapi-volume-55afb309-2846-4f5f-b9f4-63393f950777": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024666872s
STEP: Saw pod success
Dec 24 01:27:56.620: INFO: Pod "downwardapi-volume-55afb309-2846-4f5f-b9f4-63393f950777" satisfied condition "success or failure"
Dec 24 01:27:56.623: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod downwardapi-volume-55afb309-2846-4f5f-b9f4-63393f950777 container client-container: <nil>
STEP: delete the pod
Dec 24 01:27:56.651: INFO: Waiting for pod downwardapi-volume-55afb309-2846-4f5f-b9f4-63393f950777 to disappear
Dec 24 01:27:56.654: INFO: Pod downwardapi-volume-55afb309-2846-4f5f-b9f4-63393f950777 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:27:56.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-680" for this suite.
Dec 24 01:28:02.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:28:02.803: INFO: namespace projected-680 deletion completed in 6.14342845s

• [SLOW TEST:10.367 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:28:02.803: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6613
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 24 01:28:02.965: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d3e73a56-5f63-4568-8910-6de61e4d5ca7" in namespace "projected-6613" to be "success or failure"
Dec 24 01:28:02.975: INFO: Pod "downwardapi-volume-d3e73a56-5f63-4568-8910-6de61e4d5ca7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.683888ms
Dec 24 01:28:04.980: INFO: Pod "downwardapi-volume-d3e73a56-5f63-4568-8910-6de61e4d5ca7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015485501s
Dec 24 01:28:06.992: INFO: Pod "downwardapi-volume-d3e73a56-5f63-4568-8910-6de61e4d5ca7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027461544s
STEP: Saw pod success
Dec 24 01:28:06.992: INFO: Pod "downwardapi-volume-d3e73a56-5f63-4568-8910-6de61e4d5ca7" satisfied condition "success or failure"
Dec 24 01:28:06.996: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod downwardapi-volume-d3e73a56-5f63-4568-8910-6de61e4d5ca7 container client-container: <nil>
STEP: delete the pod
Dec 24 01:28:07.038: INFO: Waiting for pod downwardapi-volume-d3e73a56-5f63-4568-8910-6de61e4d5ca7 to disappear
Dec 24 01:28:07.042: INFO: Pod downwardapi-volume-d3e73a56-5f63-4568-8910-6de61e4d5ca7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:28:07.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6613" for this suite.
Dec 24 01:28:13.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:28:13.238: INFO: namespace projected-6613 deletion completed in 6.191102102s

• [SLOW TEST:10.435 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:28:13.239: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3186
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 24 01:28:13.493: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:13.493: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:13.493: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:13.497: INFO: Number of nodes with available pods: 0
Dec 24 01:28:13.497: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:28:14.504: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:14.504: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:14.504: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:14.509: INFO: Number of nodes with available pods: 0
Dec 24 01:28:14.509: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:28:15.504: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:15.504: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:15.504: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:15.508: INFO: Number of nodes with available pods: 0
Dec 24 01:28:15.508: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:28:16.504: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:16.504: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:16.504: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:16.508: INFO: Number of nodes with available pods: 3
Dec 24 01:28:16.508: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec 24 01:28:16.533: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:16.533: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:16.533: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:16.537: INFO: Number of nodes with available pods: 2
Dec 24 01:28:16.537: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:28:17.543: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:17.543: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:17.543: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:17.547: INFO: Number of nodes with available pods: 2
Dec 24 01:28:17.547: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:28:18.557: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:18.557: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:18.557: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:18.561: INFO: Number of nodes with available pods: 2
Dec 24 01:28:18.561: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:28:19.547: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:19.547: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:19.547: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:19.555: INFO: Number of nodes with available pods: 2
Dec 24 01:28:19.555: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:28:20.543: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:20.543: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:20.543: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:20.547: INFO: Number of nodes with available pods: 2
Dec 24 01:28:20.547: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:28:21.545: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:21.546: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:21.546: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:21.550: INFO: Number of nodes with available pods: 2
Dec 24 01:28:21.550: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:28:22.543: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:22.543: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:22.543: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:22.547: INFO: Number of nodes with available pods: 2
Dec 24 01:28:22.547: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:28:23.545: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:23.546: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:23.546: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:23.550: INFO: Number of nodes with available pods: 2
Dec 24 01:28:23.550: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:28:24.543: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:24.543: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:24.543: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:24.547: INFO: Number of nodes with available pods: 2
Dec 24 01:28:24.548: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:28:25.543: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:25.543: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:25.543: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:25.547: INFO: Number of nodes with available pods: 2
Dec 24 01:28:25.547: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:28:26.543: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:26.543: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:26.543: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:26.547: INFO: Number of nodes with available pods: 2
Dec 24 01:28:26.547: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:28:27.546: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:27.546: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:27.546: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:27.551: INFO: Number of nodes with available pods: 2
Dec 24 01:28:27.551: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:28:28.544: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:28.544: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:28.544: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:28:28.548: INFO: Number of nodes with available pods: 3
Dec 24 01:28:28.548: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3186, will wait for the garbage collector to delete the pods
Dec 24 01:28:28.619: INFO: Deleting DaemonSet.extensions daemon-set took: 10.586808ms
Dec 24 01:28:29.019: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.466552ms
Dec 24 01:28:39.432: INFO: Number of nodes with available pods: 0
Dec 24 01:28:39.432: INFO: Number of running nodes: 0, number of available pods: 0
Dec 24 01:28:39.436: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3186/daemonsets","resourceVersion":"116526"},"items":null}

Dec 24 01:28:39.445: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3186/pods","resourceVersion":"116526"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:28:39.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3186" for this suite.
Dec 24 01:28:45.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:28:45.616: INFO: namespace daemonsets-3186 deletion completed in 6.147305061s

• [SLOW TEST:32.378 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:28:45.616: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4305
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:29:45.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4305" for this suite.
Dec 24 01:29:57.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:29:57.931: INFO: namespace container-probe-4305 deletion completed in 12.137362756s

• [SLOW TEST:72.315 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:29:57.931: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5454
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5454.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-5454.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5454.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-5454.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 24 01:30:10.132: INFO: DNS probes using dns-test-6ab4fb1d-c097-4a44-a385-823429d35770 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5454.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-5454.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5454.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-5454.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 24 01:30:14.198: INFO: File wheezy_udp@dns-test-service-3.dns-5454.svc.cluster.local from pod  dns-5454/dns-test-6d19d1fa-a9eb-4e9a-8867-05090922fc63 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 24 01:30:14.203: INFO: File jessie_udp@dns-test-service-3.dns-5454.svc.cluster.local from pod  dns-5454/dns-test-6d19d1fa-a9eb-4e9a-8867-05090922fc63 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 24 01:30:14.203: INFO: Lookups using dns-5454/dns-test-6d19d1fa-a9eb-4e9a-8867-05090922fc63 failed for: [wheezy_udp@dns-test-service-3.dns-5454.svc.cluster.local jessie_udp@dns-test-service-3.dns-5454.svc.cluster.local]

Dec 24 01:30:19.211: INFO: File wheezy_udp@dns-test-service-3.dns-5454.svc.cluster.local from pod  dns-5454/dns-test-6d19d1fa-a9eb-4e9a-8867-05090922fc63 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 24 01:30:19.215: INFO: File jessie_udp@dns-test-service-3.dns-5454.svc.cluster.local from pod  dns-5454/dns-test-6d19d1fa-a9eb-4e9a-8867-05090922fc63 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 24 01:30:19.215: INFO: Lookups using dns-5454/dns-test-6d19d1fa-a9eb-4e9a-8867-05090922fc63 failed for: [wheezy_udp@dns-test-service-3.dns-5454.svc.cluster.local jessie_udp@dns-test-service-3.dns-5454.svc.cluster.local]

Dec 24 01:30:24.209: INFO: File wheezy_udp@dns-test-service-3.dns-5454.svc.cluster.local from pod  dns-5454/dns-test-6d19d1fa-a9eb-4e9a-8867-05090922fc63 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 24 01:30:24.213: INFO: File jessie_udp@dns-test-service-3.dns-5454.svc.cluster.local from pod  dns-5454/dns-test-6d19d1fa-a9eb-4e9a-8867-05090922fc63 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 24 01:30:24.213: INFO: Lookups using dns-5454/dns-test-6d19d1fa-a9eb-4e9a-8867-05090922fc63 failed for: [wheezy_udp@dns-test-service-3.dns-5454.svc.cluster.local jessie_udp@dns-test-service-3.dns-5454.svc.cluster.local]

Dec 24 01:30:29.209: INFO: File wheezy_udp@dns-test-service-3.dns-5454.svc.cluster.local from pod  dns-5454/dns-test-6d19d1fa-a9eb-4e9a-8867-05090922fc63 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 24 01:30:29.214: INFO: File jessie_udp@dns-test-service-3.dns-5454.svc.cluster.local from pod  dns-5454/dns-test-6d19d1fa-a9eb-4e9a-8867-05090922fc63 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 24 01:30:29.214: INFO: Lookups using dns-5454/dns-test-6d19d1fa-a9eb-4e9a-8867-05090922fc63 failed for: [wheezy_udp@dns-test-service-3.dns-5454.svc.cluster.local jessie_udp@dns-test-service-3.dns-5454.svc.cluster.local]

Dec 24 01:30:34.215: INFO: DNS probes using dns-test-6d19d1fa-a9eb-4e9a-8867-05090922fc63 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5454.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-5454.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5454.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-5454.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 24 01:30:38.316: INFO: DNS probes using dns-test-911d05b5-cbe1-4e53-9024-90732493555d succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:30:38.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5454" for this suite.
Dec 24 01:30:44.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:30:44.556: INFO: namespace dns-5454 deletion completed in 6.183430499s

• [SLOW TEST:46.625 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:30:44.556: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1442
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 24 01:30:47.762: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:30:47.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1442" for this suite.
Dec 24 01:30:53.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:30:53.988: INFO: namespace container-runtime-1442 deletion completed in 6.194035226s

• [SLOW TEST:9.432 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:30:54.000: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8033
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 24 01:30:55.793: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 24 01:30:57.805: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747855, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747855, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747855, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747855, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 24 01:31:00.830: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
Dec 24 01:31:00.863: INFO: Waiting for webhook configuration to be ready...
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:31:11.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8033" for this suite.
Dec 24 01:31:17.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:31:17.244: INFO: namespace webhook-8033 deletion completed in 6.166004755s
STEP: Destroying namespace "webhook-8033-markers" for this suite.
Dec 24 01:31:23.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:31:23.389: INFO: namespace webhook-8033-markers deletion completed in 6.145807171s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:29.426 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:31:23.414: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4821
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 24 01:31:28.109: INFO: Successfully updated pod "pod-update-activedeadlineseconds-2b9702ac-2ac5-4876-9116-2416fb9d3afa"
Dec 24 01:31:28.110: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-2b9702ac-2ac5-4876-9116-2416fb9d3afa" in namespace "pods-4821" to be "terminated due to deadline exceeded"
Dec 24 01:31:28.114: INFO: Pod "pod-update-activedeadlineseconds-2b9702ac-2ac5-4876-9116-2416fb9d3afa": Phase="Running", Reason="", readiness=true. Elapsed: 3.95182ms
Dec 24 01:31:30.120: INFO: Pod "pod-update-activedeadlineseconds-2b9702ac-2ac5-4876-9116-2416fb9d3afa": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.009896679s
Dec 24 01:31:30.120: INFO: Pod "pod-update-activedeadlineseconds-2b9702ac-2ac5-4876-9116-2416fb9d3afa" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:31:30.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4821" for this suite.
Dec 24 01:31:36.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:31:36.337: INFO: namespace pods-4821 deletion completed in 6.211274976s

• [SLOW TEST:12.923 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:31:36.337: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6580
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 24 01:31:36.539: INFO: Waiting up to 5m0s for pod "pod-57303eed-765d-4e58-bed1-5fcd1ba1321e" in namespace "emptydir-6580" to be "success or failure"
Dec 24 01:31:36.546: INFO: Pod "pod-57303eed-765d-4e58-bed1-5fcd1ba1321e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.65259ms
Dec 24 01:31:38.552: INFO: Pod "pod-57303eed-765d-4e58-bed1-5fcd1ba1321e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013359784s
Dec 24 01:31:40.557: INFO: Pod "pod-57303eed-765d-4e58-bed1-5fcd1ba1321e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017993907s
STEP: Saw pod success
Dec 24 01:31:40.557: INFO: Pod "pod-57303eed-765d-4e58-bed1-5fcd1ba1321e" satisfied condition "success or failure"
Dec 24 01:31:40.561: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-57303eed-765d-4e58-bed1-5fcd1ba1321e container test-container: <nil>
STEP: delete the pod
Dec 24 01:31:40.596: INFO: Waiting for pod pod-57303eed-765d-4e58-bed1-5fcd1ba1321e to disappear
Dec 24 01:31:40.601: INFO: Pod pod-57303eed-765d-4e58-bed1-5fcd1ba1321e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:31:40.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6580" for this suite.
Dec 24 01:31:46.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:31:46.750: INFO: namespace emptydir-6580 deletion completed in 6.141938981s

• [SLOW TEST:10.413 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:31:46.751: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1590
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-9623
STEP: Creating secret with name secret-test-fa2838d4-3fef-4588-93c9-ed38da752b92
STEP: Creating a pod to test consume secrets
Dec 24 01:31:47.077: INFO: Waiting up to 5m0s for pod "pod-secrets-c45febc6-0340-4ec7-8eb9-6988b4df6ec8" in namespace "secrets-1590" to be "success or failure"
Dec 24 01:31:47.082: INFO: Pod "pod-secrets-c45febc6-0340-4ec7-8eb9-6988b4df6ec8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.240467ms
Dec 24 01:31:49.087: INFO: Pod "pod-secrets-c45febc6-0340-4ec7-8eb9-6988b4df6ec8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009631912s
Dec 24 01:31:51.092: INFO: Pod "pod-secrets-c45febc6-0340-4ec7-8eb9-6988b4df6ec8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014780843s
STEP: Saw pod success
Dec 24 01:31:51.092: INFO: Pod "pod-secrets-c45febc6-0340-4ec7-8eb9-6988b4df6ec8" satisfied condition "success or failure"
Dec 24 01:31:51.096: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-secrets-c45febc6-0340-4ec7-8eb9-6988b4df6ec8 container secret-volume-test: <nil>
STEP: delete the pod
Dec 24 01:31:51.128: INFO: Waiting for pod pod-secrets-c45febc6-0340-4ec7-8eb9-6988b4df6ec8 to disappear
Dec 24 01:31:51.132: INFO: Pod pod-secrets-c45febc6-0340-4ec7-8eb9-6988b4df6ec8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:31:51.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1590" for this suite.
Dec 24 01:31:57.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:31:57.284: INFO: namespace secrets-1590 deletion completed in 6.145685111s
STEP: Destroying namespace "secret-namespace-9623" for this suite.
Dec 24 01:32:03.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:32:03.424: INFO: namespace secret-namespace-9623 deletion completed in 6.140033893s

• [SLOW TEST:16.673 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:32:03.424: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4343
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 24 01:32:03.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-4343'
Dec 24 01:32:03.653: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 24 01:32:03.653: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Dec 24 01:32:03.664: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-vg2qp]
Dec 24 01:32:03.664: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-vg2qp" in namespace "kubectl-4343" to be "running and ready"
Dec 24 01:32:03.675: INFO: Pod "e2e-test-httpd-rc-vg2qp": Phase="Pending", Reason="", readiness=false. Elapsed: 11.040699ms
Dec 24 01:32:05.681: INFO: Pod "e2e-test-httpd-rc-vg2qp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016148803s
Dec 24 01:32:07.689: INFO: Pod "e2e-test-httpd-rc-vg2qp": Phase="Running", Reason="", readiness=true. Elapsed: 4.024092762s
Dec 24 01:32:07.689: INFO: Pod "e2e-test-httpd-rc-vg2qp" satisfied condition "running and ready"
Dec 24 01:32:07.689: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-vg2qp]
Dec 24 01:32:07.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 logs rc/e2e-test-httpd-rc --namespace=kubectl-4343'
Dec 24 01:32:07.808: INFO: stderr: ""
Dec 24 01:32:07.808: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 100.96.3.79. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 100.96.3.79. Set the 'ServerName' directive globally to suppress this message\n[Tue Dec 24 01:32:05.115512 2019] [mpm_event:notice] [pid 1:tid 140694461541224] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Tue Dec 24 01:32:05.115552 2019] [core:notice] [pid 1:tid 140694461541224] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Dec 24 01:32:07.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 delete rc e2e-test-httpd-rc --namespace=kubectl-4343'
Dec 24 01:32:07.901: INFO: stderr: ""
Dec 24 01:32:07.901: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:32:07.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4343" for this suite.
Dec 24 01:32:35.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:32:36.065: INFO: namespace kubectl-4343 deletion completed in 28.157948067s

• [SLOW TEST:32.641 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:32:36.065: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2896
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Dec 24 01:32:36.251: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec 24 01:32:45.311: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:32:45.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2896" for this suite.
Dec 24 01:32:51.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:32:51.471: INFO: namespace pods-2896 deletion completed in 6.150037551s

• [SLOW TEST:15.406 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:32:51.472: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-6666
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Dec 24 01:32:51.631: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Dec 24 01:32:52.905: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Dec 24 01:32:54.985: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747972, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747972, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747972, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712747972, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 24 01:33:06.249: INFO: Waited 9.251573209s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:33:06.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-6666" for this suite.
Dec 24 01:33:12.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:33:12.988: INFO: namespace aggregator-6666 deletion completed in 6.184291236s

• [SLOW TEST:21.517 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:33:12.989: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9552
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 24 01:33:13.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-9552'
Dec 24 01:33:13.223: INFO: stderr: ""
Dec 24 01:33:13.223: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Dec 24 01:33:18.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pod e2e-test-httpd-pod --namespace=kubectl-9552 -o json'
Dec 24 01:33:18.347: INFO: stderr: ""
Dec 24 01:33:18.347: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"100.96.3.81/32\",\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-12-24T01:33:13Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-9552\",\n        \"resourceVersion\": \"117850\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-9552/pods/e2e-test-httpd-pod\",\n        \"uid\": \"53ba1f6c-156a-45b9-bbbf-1e22d0c85641\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-gfmjc\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-16-44-108.ec2.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-gfmjc\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-gfmjc\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-24T01:33:13Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-24T01:33:15Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-24T01:33:15Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-24T01:33:13Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://19014949defce8a80f59b68af2b60d4377e57122746cbfa5fc30485da906ebc5\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-12-24T01:33:14Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.16.44.108\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.96.3.81\",\n        \"podIPs\": [\n            {\n                \"ip\": \"100.96.3.81\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-12-24T01:33:13Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec 24 01:33:18.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 replace -f - --namespace=kubectl-9552'
Dec 24 01:33:18.622: INFO: stderr: ""
Dec 24 01:33:18.623: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Dec 24 01:33:18.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 delete pods e2e-test-httpd-pod --namespace=kubectl-9552'
Dec 24 01:33:29.422: INFO: stderr: ""
Dec 24 01:33:29.422: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:33:29.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9552" for this suite.
Dec 24 01:33:35.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:33:35.571: INFO: namespace kubectl-9552 deletion completed in 6.135685178s

• [SLOW TEST:22.582 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:33:35.571: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5199
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 24 01:33:35.732: INFO: Waiting up to 5m0s for pod "pod-6db222ee-a6ef-47f0-b438-617c34687af1" in namespace "emptydir-5199" to be "success or failure"
Dec 24 01:33:35.736: INFO: Pod "pod-6db222ee-a6ef-47f0-b438-617c34687af1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.426579ms
Dec 24 01:33:37.741: INFO: Pod "pod-6db222ee-a6ef-47f0-b438-617c34687af1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008916072s
Dec 24 01:33:39.746: INFO: Pod "pod-6db222ee-a6ef-47f0-b438-617c34687af1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014519726s
STEP: Saw pod success
Dec 24 01:33:39.746: INFO: Pod "pod-6db222ee-a6ef-47f0-b438-617c34687af1" satisfied condition "success or failure"
Dec 24 01:33:39.750: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-6db222ee-a6ef-47f0-b438-617c34687af1 container test-container: <nil>
STEP: delete the pod
Dec 24 01:33:39.777: INFO: Waiting for pod pod-6db222ee-a6ef-47f0-b438-617c34687af1 to disappear
Dec 24 01:33:39.780: INFO: Pod pod-6db222ee-a6ef-47f0-b438-617c34687af1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:33:39.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5199" for this suite.
Dec 24 01:33:45.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:33:45.934: INFO: namespace emptydir-5199 deletion completed in 6.148712669s

• [SLOW TEST:10.363 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:33:45.934: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-3247
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec 24 01:33:46.744: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Dec 24 01:33:48.756: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748026, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748026, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748026, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748026, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 24 01:33:51.781: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 01:33:51.786: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:33:58.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-3247" for this suite.
Dec 24 01:34:04.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:34:04.534: INFO: namespace crd-webhook-3247 deletion completed in 6.265926905s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:18.639 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:34:04.574: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2115
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-79f5841b-0558-499d-bfe3-4dc407f4744b
STEP: Creating a pod to test consume configMaps
Dec 24 01:34:04.770: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f8920a10-9fed-4b8e-82da-9582d36b219b" in namespace "projected-2115" to be "success or failure"
Dec 24 01:34:04.776: INFO: Pod "pod-projected-configmaps-f8920a10-9fed-4b8e-82da-9582d36b219b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.525428ms
Dec 24 01:34:06.781: INFO: Pod "pod-projected-configmaps-f8920a10-9fed-4b8e-82da-9582d36b219b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011772926s
Dec 24 01:34:08.787: INFO: Pod "pod-projected-configmaps-f8920a10-9fed-4b8e-82da-9582d36b219b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017275557s
STEP: Saw pod success
Dec 24 01:34:08.787: INFO: Pod "pod-projected-configmaps-f8920a10-9fed-4b8e-82da-9582d36b219b" satisfied condition "success or failure"
Dec 24 01:34:08.790: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod pod-projected-configmaps-f8920a10-9fed-4b8e-82da-9582d36b219b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 24 01:34:08.826: INFO: Waiting for pod pod-projected-configmaps-f8920a10-9fed-4b8e-82da-9582d36b219b to disappear
Dec 24 01:34:08.830: INFO: Pod pod-projected-configmaps-f8920a10-9fed-4b8e-82da-9582d36b219b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:34:08.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2115" for this suite.
Dec 24 01:34:14.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:34:14.976: INFO: namespace projected-2115 deletion completed in 6.140526557s

• [SLOW TEST:10.402 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:34:14.976: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-490
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Dec 24 01:34:55.190: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1224 01:34:55.190134      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:34:55.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-490" for this suite.
Dec 24 01:35:01.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:35:01.357: INFO: namespace gc-490 deletion completed in 6.162010368s

• [SLOW TEST:46.381 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:35:01.357: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5262
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 24 01:35:04.552: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:35:04.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5262" for this suite.
Dec 24 01:35:10.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:35:10.725: INFO: namespace container-runtime-5262 deletion completed in 6.141414869s

• [SLOW TEST:9.368 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:35:10.725: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5497
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 24 01:35:10.889: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1cfc6f0b-cc35-487b-ac97-175bdfb501d2" in namespace "projected-5497" to be "success or failure"
Dec 24 01:35:10.894: INFO: Pod "downwardapi-volume-1cfc6f0b-cc35-487b-ac97-175bdfb501d2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.47717ms
Dec 24 01:35:12.899: INFO: Pod "downwardapi-volume-1cfc6f0b-cc35-487b-ac97-175bdfb501d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009483905s
Dec 24 01:35:14.903: INFO: Pod "downwardapi-volume-1cfc6f0b-cc35-487b-ac97-175bdfb501d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013792825s
STEP: Saw pod success
Dec 24 01:35:14.903: INFO: Pod "downwardapi-volume-1cfc6f0b-cc35-487b-ac97-175bdfb501d2" satisfied condition "success or failure"
Dec 24 01:35:14.907: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod downwardapi-volume-1cfc6f0b-cc35-487b-ac97-175bdfb501d2 container client-container: <nil>
STEP: delete the pod
Dec 24 01:35:14.951: INFO: Waiting for pod downwardapi-volume-1cfc6f0b-cc35-487b-ac97-175bdfb501d2 to disappear
Dec 24 01:35:14.954: INFO: Pod downwardapi-volume-1cfc6f0b-cc35-487b-ac97-175bdfb501d2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:35:14.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5497" for this suite.
Dec 24 01:35:20.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:35:21.103: INFO: namespace projected-5497 deletion completed in 6.142828194s

• [SLOW TEST:10.378 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:35:21.104: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-6425
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Dec 24 01:35:21.264: INFO: Waiting up to 5m0s for pod "var-expansion-2a667c66-43ed-4c43-889a-2cfecc6f98ea" in namespace "var-expansion-6425" to be "success or failure"
Dec 24 01:35:21.268: INFO: Pod "var-expansion-2a667c66-43ed-4c43-889a-2cfecc6f98ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.363912ms
Dec 24 01:35:23.274: INFO: Pod "var-expansion-2a667c66-43ed-4c43-889a-2cfecc6f98ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009925922s
Dec 24 01:35:25.278: INFO: Pod "var-expansion-2a667c66-43ed-4c43-889a-2cfecc6f98ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014131119s
STEP: Saw pod success
Dec 24 01:35:25.278: INFO: Pod "var-expansion-2a667c66-43ed-4c43-889a-2cfecc6f98ea" satisfied condition "success or failure"
Dec 24 01:35:25.282: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod var-expansion-2a667c66-43ed-4c43-889a-2cfecc6f98ea container dapi-container: <nil>
STEP: delete the pod
Dec 24 01:35:25.308: INFO: Waiting for pod var-expansion-2a667c66-43ed-4c43-889a-2cfecc6f98ea to disappear
Dec 24 01:35:25.312: INFO: Pod var-expansion-2a667c66-43ed-4c43-889a-2cfecc6f98ea no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:35:25.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6425" for this suite.
Dec 24 01:35:31.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:35:31.476: INFO: namespace var-expansion-6425 deletion completed in 6.157922744s

• [SLOW TEST:10.372 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:35:31.476: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7195
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-7195
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 24 01:35:31.643: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 24 01:35:57.767: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.3.90 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7195 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 24 01:35:57.767: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 01:35:58.908: INFO: Found all expected endpoints: [netserver-0]
Dec 24 01:35:58.912: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.4.107 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7195 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 24 01:35:58.912: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 01:36:00.064: INFO: Found all expected endpoints: [netserver-1]
Dec 24 01:36:00.069: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.5.87 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7195 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 24 01:36:00.069: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 01:36:01.221: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:36:01.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7195" for this suite.
Dec 24 01:36:13.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:36:13.366: INFO: namespace pod-network-test-7195 deletion completed in 12.138485086s

• [SLOW TEST:41.890 seconds]
[sig-network] Networking
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:36:13.366: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7017
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 24 01:36:13.531: INFO: Waiting up to 5m0s for pod "downwardapi-volume-39b0dac7-1141-4a28-813b-72272bd0355c" in namespace "projected-7017" to be "success or failure"
Dec 24 01:36:13.540: INFO: Pod "downwardapi-volume-39b0dac7-1141-4a28-813b-72272bd0355c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.959027ms
Dec 24 01:36:15.546: INFO: Pod "downwardapi-volume-39b0dac7-1141-4a28-813b-72272bd0355c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014183486s
Dec 24 01:36:17.550: INFO: Pod "downwardapi-volume-39b0dac7-1141-4a28-813b-72272bd0355c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018526684s
STEP: Saw pod success
Dec 24 01:36:17.550: INFO: Pod "downwardapi-volume-39b0dac7-1141-4a28-813b-72272bd0355c" satisfied condition "success or failure"
Dec 24 01:36:17.554: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod downwardapi-volume-39b0dac7-1141-4a28-813b-72272bd0355c container client-container: <nil>
STEP: delete the pod
Dec 24 01:36:17.589: INFO: Waiting for pod downwardapi-volume-39b0dac7-1141-4a28-813b-72272bd0355c to disappear
Dec 24 01:36:17.603: INFO: Pod downwardapi-volume-39b0dac7-1141-4a28-813b-72272bd0355c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:36:17.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7017" for this suite.
Dec 24 01:36:23.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:36:23.769: INFO: namespace projected-7017 deletion completed in 6.156153228s

• [SLOW TEST:10.403 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:36:23.769: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5779
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 24 01:36:23.931: INFO: Waiting up to 5m0s for pod "downwardapi-volume-72a4d7cf-8763-49f3-9574-af2832306a6f" in namespace "downward-api-5779" to be "success or failure"
Dec 24 01:36:23.935: INFO: Pod "downwardapi-volume-72a4d7cf-8763-49f3-9574-af2832306a6f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.365617ms
Dec 24 01:36:25.939: INFO: Pod "downwardapi-volume-72a4d7cf-8763-49f3-9574-af2832306a6f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007987493s
Dec 24 01:36:27.944: INFO: Pod "downwardapi-volume-72a4d7cf-8763-49f3-9574-af2832306a6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012690642s
STEP: Saw pod success
Dec 24 01:36:27.944: INFO: Pod "downwardapi-volume-72a4d7cf-8763-49f3-9574-af2832306a6f" satisfied condition "success or failure"
Dec 24 01:36:27.947: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod downwardapi-volume-72a4d7cf-8763-49f3-9574-af2832306a6f container client-container: <nil>
STEP: delete the pod
Dec 24 01:36:27.975: INFO: Waiting for pod downwardapi-volume-72a4d7cf-8763-49f3-9574-af2832306a6f to disappear
Dec 24 01:36:27.979: INFO: Pod downwardapi-volume-72a4d7cf-8763-49f3-9574-af2832306a6f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:36:27.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5779" for this suite.
Dec 24 01:36:34.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:36:34.152: INFO: namespace downward-api-5779 deletion completed in 6.167389066s

• [SLOW TEST:10.383 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:36:34.155: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7408
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 24 01:36:34.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-7408'
Dec 24 01:36:35.269: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 24 01:36:35.269: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Dec 24 01:36:37.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 delete deployment e2e-test-httpd-deployment --namespace=kubectl-7408'
Dec 24 01:36:37.428: INFO: stderr: ""
Dec 24 01:36:37.428: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:36:37.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7408" for this suite.
Dec 24 01:38:47.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:38:47.578: INFO: namespace kubectl-7408 deletion completed in 2m10.143482567s

• [SLOW TEST:133.423 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:38:47.578: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4124
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:39:04.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4124" for this suite.
Dec 24 01:39:10.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:39:10.926: INFO: namespace resourcequota-4124 deletion completed in 6.134186795s

• [SLOW TEST:23.348 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:39:10.926: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7515
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 24 01:39:11.101: INFO: Waiting up to 5m0s for pod "downward-api-2475b0e9-2ad6-47e2-b1ae-c632c2595690" in namespace "downward-api-7515" to be "success or failure"
Dec 24 01:39:11.105: INFO: Pod "downward-api-2475b0e9-2ad6-47e2-b1ae-c632c2595690": Phase="Pending", Reason="", readiness=false. Elapsed: 4.196572ms
Dec 24 01:39:13.110: INFO: Pod "downward-api-2475b0e9-2ad6-47e2-b1ae-c632c2595690": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009666074s
Dec 24 01:39:15.116: INFO: Pod "downward-api-2475b0e9-2ad6-47e2-b1ae-c632c2595690": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014966957s
STEP: Saw pod success
Dec 24 01:39:15.116: INFO: Pod "downward-api-2475b0e9-2ad6-47e2-b1ae-c632c2595690" satisfied condition "success or failure"
Dec 24 01:39:15.120: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod downward-api-2475b0e9-2ad6-47e2-b1ae-c632c2595690 container dapi-container: <nil>
STEP: delete the pod
Dec 24 01:39:15.160: INFO: Waiting for pod downward-api-2475b0e9-2ad6-47e2-b1ae-c632c2595690 to disappear
Dec 24 01:39:15.163: INFO: Pod downward-api-2475b0e9-2ad6-47e2-b1ae-c632c2595690 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:39:15.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7515" for this suite.
Dec 24 01:39:21.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:39:21.306: INFO: namespace downward-api-7515 deletion completed in 6.137039906s

• [SLOW TEST:10.380 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:39:21.307: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1807
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 24 01:39:21.457: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 24 01:39:21.473: INFO: Waiting for terminating namespaces to be deleted...
Dec 24 01:39:21.477: INFO: 
Logging pods the kubelet thinks is on node ip-172-16-103-244.ec2.internal before test
Dec 24 01:39:21.501: INFO: k8s-api-haproxy-de80cb1199e732ef3c9ca0051c41dd966f81ca8bee9c571b76dea5e659c7b97b-ip-172-16-103-244.ec2.internal from kube-system started at 2019-12-23 15:43:16 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.501: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Dec 24 01:39:21.501: INFO: canal-d28dx from kube-system started at 2019-12-23 15:44:11 +0000 UTC (4 container statuses recorded)
Dec 24 01:39:21.501: INFO: 	Container calico-node ready: true, restart count 0
Dec 24 01:39:21.501: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 24 01:39:21.501: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Dec 24 01:39:21.501: INFO: 	Container update-network-condition ready: true, restart count 0
Dec 24 01:39:21.501: INFO: kublr-logging-controller-7f5d56f594-rq5fl from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.501: INFO: 	Container kublr-feature-logging ready: true, restart count 0
Dec 24 01:39:21.501: INFO: kublr-monitoring-alertmanager-549cf5f44c-fbdlf from kublr started at 2019-12-23 15:46:09 +0000 UTC (2 container statuses recorded)
Dec 24 01:39:21.501: INFO: 	Container alertmanager ready: true, restart count 0
Dec 24 01:39:21.501: INFO: 	Container keycloak-proxy ready: true, restart count 4
Dec 24 01:39:21.501: INFO: kube-proxy-7e590abedfb7de51d1197b20e754686a6a8674ae8ac79bc64dcfdc0bb67fb64f-ip-172-16-103-244.ec2.internal from kube-system started at 2019-12-23 15:43:16 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.501: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 24 01:39:21.501: INFO: kublr-logging-rabbitmq-0 from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.501: INFO: 	Container rabbitmq ready: true, restart count 0
Dec 24 01:39:21.501: INFO: kublr-monitoring-prometheus-59564b557d-pkjhv from kublr started at 2019-12-23 15:46:15 +0000 UTC (2 container statuses recorded)
Dec 24 01:39:21.501: INFO: 	Container keycloak-proxy ready: true, restart count 4
Dec 24 01:39:21.501: INFO: 	Container prometheus ready: true, restart count 6
Dec 24 01:39:21.501: INFO: kublr-node-name-reporter-b5f50899e00ed5b8ad1b215b812381270bf0779993c3a6740826f2cfb378f08f-ip-172-16-103-244.ec2.internal from kube-system started at 2019-12-23 15:43:16 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.501: INFO: 	Container main ready: true, restart count 0
Dec 24 01:39:21.501: INFO: node-local-dns-hw2d5 from kube-system started at 2019-12-23 15:44:27 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.501: INFO: 	Container node-cache ready: true, restart count 0
Dec 24 01:39:21.501: INFO: kublr-logging-fluentd-es-7rd6f from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.501: INFO: 	Container fluentd-es ready: true, restart count 4
Dec 24 01:39:21.501: INFO: kublr-logging-elasticsearch-client-6f7d56fdbb-zgnhd from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.501: INFO: 	Container elasticsearch ready: true, restart count 0
Dec 24 01:39:21.501: INFO: kublr-monitoring-grafana-6fbbfc98f4-n9zw5 from kublr started at 2019-12-23 15:46:15 +0000 UTC (3 container statuses recorded)
Dec 24 01:39:21.501: INFO: 	Container grafana ready: true, restart count 0
Dec 24 01:39:21.501: INFO: 	Container keycloak-proxy ready: true, restart count 4
Dec 24 01:39:21.501: INFO: 	Container nginx-proxy ready: true, restart count 0
Dec 24 01:39:21.501: INFO: sonobuoy-systemd-logs-daemon-set-eb45748a27ab4169-h9v2w from sonobuoy started at 2019-12-24 01:19:59 +0000 UTC (2 container statuses recorded)
Dec 24 01:39:21.501: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 24 01:39:21.501: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 24 01:39:21.501: INFO: kublr-ingress-nginx-ingress-controller-849b4769fc-79bhq from kube-system started at 2019-12-23 15:45:19 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.501: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec 24 01:39:21.501: INFO: kublr-ingress-nginx-ingress-default-backend-7b84f6bc4b-xr9cg from kube-system started at 2019-12-23 15:45:19 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.501: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
Dec 24 01:39:21.501: INFO: 
Logging pods the kubelet thinks is on node ip-172-16-30-121.ec2.internal before test
Dec 24 01:39:21.512: INFO: heapster-v1.6.0-beta.1-5f6b4bf99b-bxcwv from kube-system started at 2019-12-23 15:44:31 +0000 UTC (2 container statuses recorded)
Dec 24 01:39:21.512: INFO: 	Container heapster ready: true, restart count 0
Dec 24 01:39:21.512: INFO: 	Container heapster-nanny ready: true, restart count 0
Dec 24 01:39:21.512: INFO: kcp-kublr-ui-5d5fbd8dc5-mxf6z from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.512: INFO: 	Container kublr-ui ready: true, restart count 0
Dec 24 01:39:21.512: INFO: kube-proxy-7e590abedfb7de51d1197b20e754686a6a8674ae8ac79bc64dcfdc0bb67fb64f-ip-172-16-30-121.ec2.internal from kube-system started at 2019-12-23 15:43:25 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.512: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 24 01:39:21.512: INFO: kublr-logging-sg-job-kqg5q from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.512: INFO: 	Container certgenerator ready: false, restart count 0
Dec 24 01:39:21.512: INFO: kcp-cluster-controller-846969f94d-998fm from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.512: INFO: 	Container cluster-controller ready: true, restart count 0
Dec 24 01:39:21.512: INFO: sonobuoy from sonobuoy started at 2019-12-24 01:19:56 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.512: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 24 01:39:21.512: INFO: kcp-app-mongodb-789bf97977-lckdz from kublr started at 2019-12-23 15:46:21 +0000 UTC (2 container statuses recorded)
Dec 24 01:39:21.512: INFO: 	Container mongo ready: true, restart count 0
Dec 24 01:39:21.512: INFO: 	Container mongo-exporter ready: true, restart count 0
Dec 24 01:39:21.512: INFO: k8s-api-haproxy-429d71c9c9d8df433e1397ffb7b8d70c5c9c56d08dcdf3f6b2e0fe52606e3c6f-ip-172-16-30-121.ec2.internal from kube-system started at 2019-12-23 15:43:25 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.512: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Dec 24 01:39:21.512: INFO: kublr-logging-fluentd-es-nc4f7 from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.512: INFO: 	Container fluentd-es ready: true, restart count 4
Dec 24 01:39:21.512: INFO: sonobuoy-systemd-logs-daemon-set-eb45748a27ab4169-v9f85 from sonobuoy started at 2019-12-24 01:19:59 +0000 UTC (2 container statuses recorded)
Dec 24 01:39:21.512: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 24 01:39:21.512: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 24 01:39:21.512: INFO: kublr-node-name-reporter-c6710394cb2609cca16a8c87ff84cdb8044d9d6e9239ff3abcfbaa4768a4122f-ip-172-16-30-121.ec2.internal from kube-system started at 2019-12-23 15:43:25 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.512: INFO: 	Container main ready: true, restart count 0
Dec 24 01:39:21.512: INFO: kcp-app-mysql-549dd84b74-pd89v from kublr started at 2019-12-23 15:46:21 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.512: INFO: 	Container kcp-app-mysql ready: true, restart count 0
Dec 24 01:39:21.512: INFO: kublr-logging-elasticsearch-master-0 from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.512: INFO: 	Container elasticsearch ready: true, restart count 0
Dec 24 01:39:21.512: INFO: kublr-logging-curator-1577149200-nkjhl from kublr started at 2019-12-24 01:00:01 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.512: INFO: 	Container curator ready: false, restart count 0
Dec 24 01:39:21.512: INFO: canal-7sp7t from kube-system started at 2019-12-23 15:44:11 +0000 UTC (4 container statuses recorded)
Dec 24 01:39:21.512: INFO: 	Container calico-node ready: true, restart count 0
Dec 24 01:39:21.512: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 24 01:39:21.512: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Dec 24 01:39:21.512: INFO: 	Container update-network-condition ready: true, restart count 0
Dec 24 01:39:21.512: INFO: tiller-deploy-db48c564c-gj6vz from kube-system started at 2019-12-23 15:44:34 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.512: INFO: 	Container tiller ready: true, restart count 0
Dec 24 01:39:21.512: INFO: kcp-generator-6bd556bcf6-dmqbq from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.512: INFO: 	Container generator ready: true, restart count 0
Dec 24 01:39:21.512: INFO: kublr-monitoring-kube-state-metrics-5ff6484cf7-bltmp from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.512: INFO: 	Container kubestatemetrics ready: true, restart count 0
Dec 24 01:39:21.512: INFO: kublr-monitoring-monitoring-controller-66578cf88c-fb2gk from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.512: INFO: 	Container app-monitoring ready: true, restart count 0
Dec 24 01:39:21.513: INFO: kcp-backup-controller-6894dbfd9f-mxv6r from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.513: INFO: 	Container backup-controller ready: true, restart count 0
Dec 24 01:39:21.513: INFO: node-local-dns-jq8bl from kube-system started at 2019-12-23 15:44:27 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.513: INFO: 	Container node-cache ready: true, restart count 0
Dec 24 01:39:21.513: INFO: kublr-logging-kibana-5d84bc784d-gfh6r from kublr started at 2019-12-23 15:46:03 +0000 UTC (4 container statuses recorded)
Dec 24 01:39:21.513: INFO: 	Container keycloak-proxy ready: true, restart count 0
Dec 24 01:39:21.513: INFO: 	Container kibana ready: true, restart count 0
Dec 24 01:39:21.513: INFO: 	Container nginx-proxy ready: true, restart count 0
Dec 24 01:39:21.513: INFO: 	Container sg-auth-proxy ready: true, restart count 0
Dec 24 01:39:21.513: INFO: 
Logging pods the kubelet thinks is on node ip-172-16-44-108.ec2.internal before test
Dec 24 01:39:21.534: INFO: kublr-logging-logstash-547687bcdc-vdg4k from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.547: INFO: 	Container logstash ready: true, restart count 0
Dec 24 01:39:21.549: INFO: kube-proxy-7e590abedfb7de51d1197b20e754686a6a8674ae8ac79bc64dcfdc0bb67fb64f-ip-172-16-44-108.ec2.internal from kube-system started at 2019-12-23 15:43:19 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.549: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 24 01:39:21.549: INFO: sonobuoy-e2e-job-457b3e5a99034c4d from sonobuoy started at 2019-12-24 01:19:59 +0000 UTC (2 container statuses recorded)
Dec 24 01:39:21.549: INFO: 	Container e2e ready: true, restart count 0
Dec 24 01:39:21.549: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 24 01:39:21.549: INFO: kublr-logging-fluentd-es-bpbg6 from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.549: INFO: 	Container fluentd-es ready: true, restart count 4
Dec 24 01:39:21.549: INFO: kublr-logging-rabbitmq-exporter-dc6b44ccd-6r8ks from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.549: INFO: 	Container kublr-logging-rabbitmq-exporter ready: true, restart count 0
Dec 24 01:39:21.549: INFO: kcp-keycloak-0 from kublr started at 2019-12-23 15:46:15 +0000 UTC (2 container statuses recorded)
Dec 24 01:39:21.549: INFO: 	Container init-keycloak ready: true, restart count 0
Dec 24 01:39:21.549: INFO: 	Container kcp-keycloak ready: true, restart count 0
Dec 24 01:39:21.549: INFO: kcp-terraform-controller-6f447b77d7-v69lk from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.549: INFO: 	Container terraform-controller ready: true, restart count 0
Dec 24 01:39:21.549: INFO: metrics-server-v0.3.6-86567757d-7d792 from kube-system started at 2019-12-23 17:20:18 +0000 UTC (2 container statuses recorded)
Dec 24 01:39:21.549: INFO: 	Container metrics-server ready: true, restart count 0
Dec 24 01:39:21.549: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Dec 24 01:39:21.549: INFO: kublr-node-name-reporter-be88daf430a9d4815e9777fe7bdbbdded5de4e21fb88257b9dc4b4a05304fcee-ip-172-16-44-108.ec2.internal from kube-system started at 2019-12-23 15:43:19 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.550: INFO: 	Container main ready: true, restart count 0
Dec 24 01:39:21.550: INFO: k8s-api-haproxy-de80cb1199e732ef3c9ca0051c41dd966f81ca8bee9c571b76dea5e659c7b97b-ip-172-16-44-108.ec2.internal from kube-system started at 2019-12-23 15:43:19 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.550: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Dec 24 01:39:21.550: INFO: canal-rxhg5 from kube-system started at 2019-12-23 15:44:11 +0000 UTC (4 container statuses recorded)
Dec 24 01:39:21.550: INFO: 	Container calico-node ready: true, restart count 0
Dec 24 01:39:21.550: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 24 01:39:21.550: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Dec 24 01:39:21.550: INFO: 	Container update-network-condition ready: true, restart count 0
Dec 24 01:39:21.550: INFO: node-local-dns-dzntt from kube-system started at 2019-12-23 15:44:27 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.550: INFO: 	Container node-cache ready: true, restart count 0
Dec 24 01:39:21.550: INFO: kubernetes-dashboard-84cb747b5c-td8jl from kubernetes-dashboard started at 2019-12-23 15:44:31 +0000 UTC (2 container statuses recorded)
Dec 24 01:39:21.550: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec 24 01:39:21.550: INFO: 	Container kubernetes-dashboard-auth-proxy ready: true, restart count 0
Dec 24 01:39:21.550: INFO: kublr-system-shell-6f4bcb9487-n9swc from kube-system started at 2019-12-23 15:45:12 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.550: INFO: 	Container shell ready: true, restart count 0
Dec 24 01:39:21.550: INFO: kublr-logging-elasticsearch-exporter-78df7c8987-w7b6q from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.550: INFO: 	Container main ready: true, restart count 0
Dec 24 01:39:21.550: INFO: kublr-logging-elasticsearch-data-0 from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.550: INFO: 	Container elasticsearch ready: true, restart count 0
Dec 24 01:39:21.550: INFO: kcp-kublr-api-6b7d4bc968-kd9pb from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 01:39:21.550: INFO: 	Container kublr-api ready: true, restart count 0
Dec 24 01:39:21.550: INFO: sonobuoy-systemd-logs-daemon-set-eb45748a27ab4169-wpzc6 from sonobuoy started at 2019-12-24 01:19:59 +0000 UTC (2 container statuses recorded)
Dec 24 01:39:21.550: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 24 01:39:21.550: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node ip-172-16-103-244.ec2.internal
STEP: verifying the node has the label node ip-172-16-30-121.ec2.internal
STEP: verifying the node has the label node ip-172-16-44-108.ec2.internal
Dec 24 01:39:21.644: INFO: Pod canal-7sp7t requesting resource cpu=50m on Node ip-172-16-30-121.ec2.internal
Dec 24 01:39:21.644: INFO: Pod canal-d28dx requesting resource cpu=50m on Node ip-172-16-103-244.ec2.internal
Dec 24 01:39:21.644: INFO: Pod canal-rxhg5 requesting resource cpu=50m on Node ip-172-16-44-108.ec2.internal
Dec 24 01:39:21.644: INFO: Pod heapster-v1.6.0-beta.1-5f6b4bf99b-bxcwv requesting resource cpu=50m on Node ip-172-16-30-121.ec2.internal
Dec 24 01:39:21.644: INFO: Pod k8s-api-haproxy-429d71c9c9d8df433e1397ffb7b8d70c5c9c56d08dcdf3f6b2e0fe52606e3c6f-ip-172-16-30-121.ec2.internal requesting resource cpu=1m on Node ip-172-16-30-121.ec2.internal
Dec 24 01:39:21.644: INFO: Pod k8s-api-haproxy-de80cb1199e732ef3c9ca0051c41dd966f81ca8bee9c571b76dea5e659c7b97b-ip-172-16-103-244.ec2.internal requesting resource cpu=1m on Node ip-172-16-103-244.ec2.internal
Dec 24 01:39:21.644: INFO: Pod k8s-api-haproxy-de80cb1199e732ef3c9ca0051c41dd966f81ca8bee9c571b76dea5e659c7b97b-ip-172-16-44-108.ec2.internal requesting resource cpu=1m on Node ip-172-16-44-108.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kube-proxy-7e590abedfb7de51d1197b20e754686a6a8674ae8ac79bc64dcfdc0bb67fb64f-ip-172-16-103-244.ec2.internal requesting resource cpu=5m on Node ip-172-16-103-244.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kube-proxy-7e590abedfb7de51d1197b20e754686a6a8674ae8ac79bc64dcfdc0bb67fb64f-ip-172-16-30-121.ec2.internal requesting resource cpu=5m on Node ip-172-16-30-121.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kube-proxy-7e590abedfb7de51d1197b20e754686a6a8674ae8ac79bc64dcfdc0bb67fb64f-ip-172-16-44-108.ec2.internal requesting resource cpu=5m on Node ip-172-16-44-108.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kublr-ingress-nginx-ingress-controller-849b4769fc-79bhq requesting resource cpu=100m on Node ip-172-16-103-244.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kublr-ingress-nginx-ingress-default-backend-7b84f6bc4b-xr9cg requesting resource cpu=0m on Node ip-172-16-103-244.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kublr-node-name-reporter-b5f50899e00ed5b8ad1b215b812381270bf0779993c3a6740826f2cfb378f08f-ip-172-16-103-244.ec2.internal requesting resource cpu=0m on Node ip-172-16-103-244.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kublr-node-name-reporter-be88daf430a9d4815e9777fe7bdbbdded5de4e21fb88257b9dc4b4a05304fcee-ip-172-16-44-108.ec2.internal requesting resource cpu=0m on Node ip-172-16-44-108.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kublr-node-name-reporter-c6710394cb2609cca16a8c87ff84cdb8044d9d6e9239ff3abcfbaa4768a4122f-ip-172-16-30-121.ec2.internal requesting resource cpu=0m on Node ip-172-16-30-121.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kublr-system-shell-6f4bcb9487-n9swc requesting resource cpu=10m on Node ip-172-16-44-108.ec2.internal
Dec 24 01:39:21.644: INFO: Pod metrics-server-v0.3.6-86567757d-7d792 requesting resource cpu=98m on Node ip-172-16-44-108.ec2.internal
Dec 24 01:39:21.644: INFO: Pod node-local-dns-dzntt requesting resource cpu=25m on Node ip-172-16-44-108.ec2.internal
Dec 24 01:39:21.644: INFO: Pod node-local-dns-hw2d5 requesting resource cpu=25m on Node ip-172-16-103-244.ec2.internal
Dec 24 01:39:21.644: INFO: Pod node-local-dns-jq8bl requesting resource cpu=25m on Node ip-172-16-30-121.ec2.internal
Dec 24 01:39:21.644: INFO: Pod tiller-deploy-db48c564c-gj6vz requesting resource cpu=5m on Node ip-172-16-30-121.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kubernetes-dashboard-84cb747b5c-td8jl requesting resource cpu=15m on Node ip-172-16-44-108.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kcp-app-mongodb-789bf97977-lckdz requesting resource cpu=100m on Node ip-172-16-30-121.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kcp-app-mysql-549dd84b74-pd89v requesting resource cpu=100m on Node ip-172-16-30-121.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kcp-backup-controller-6894dbfd9f-mxv6r requesting resource cpu=100m on Node ip-172-16-30-121.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kcp-cluster-controller-846969f94d-998fm requesting resource cpu=100m on Node ip-172-16-30-121.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kcp-generator-6bd556bcf6-dmqbq requesting resource cpu=100m on Node ip-172-16-30-121.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kcp-keycloak-0 requesting resource cpu=300m on Node ip-172-16-44-108.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kcp-kublr-api-6b7d4bc968-kd9pb requesting resource cpu=100m on Node ip-172-16-44-108.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kcp-kublr-ui-5d5fbd8dc5-mxf6z requesting resource cpu=10m on Node ip-172-16-30-121.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kcp-terraform-controller-6f447b77d7-v69lk requesting resource cpu=200m on Node ip-172-16-44-108.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kublr-logging-controller-7f5d56f594-rq5fl requesting resource cpu=100m on Node ip-172-16-103-244.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kublr-logging-elasticsearch-client-6f7d56fdbb-zgnhd requesting resource cpu=25m on Node ip-172-16-103-244.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kublr-logging-elasticsearch-data-0 requesting resource cpu=25m on Node ip-172-16-44-108.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kublr-logging-elasticsearch-exporter-78df7c8987-w7b6q requesting resource cpu=5m on Node ip-172-16-44-108.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kublr-logging-elasticsearch-master-0 requesting resource cpu=25m on Node ip-172-16-30-121.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kublr-logging-fluentd-es-7rd6f requesting resource cpu=150m on Node ip-172-16-103-244.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kublr-logging-fluentd-es-bpbg6 requesting resource cpu=150m on Node ip-172-16-44-108.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kublr-logging-fluentd-es-nc4f7 requesting resource cpu=150m on Node ip-172-16-30-121.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kublr-logging-kibana-5d84bc784d-gfh6r requesting resource cpu=220m on Node ip-172-16-30-121.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kublr-logging-logstash-547687bcdc-vdg4k requesting resource cpu=500m on Node ip-172-16-44-108.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kublr-logging-rabbitmq-0 requesting resource cpu=400m on Node ip-172-16-103-244.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kublr-logging-rabbitmq-exporter-dc6b44ccd-6r8ks requesting resource cpu=10m on Node ip-172-16-44-108.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kublr-monitoring-alertmanager-549cf5f44c-fbdlf requesting resource cpu=60m on Node ip-172-16-103-244.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kublr-monitoring-grafana-6fbbfc98f4-n9zw5 requesting resource cpu=320m on Node ip-172-16-103-244.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kublr-monitoring-kube-state-metrics-5ff6484cf7-bltmp requesting resource cpu=100m on Node ip-172-16-30-121.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kublr-monitoring-monitoring-controller-66578cf88c-fb2gk requesting resource cpu=100m on Node ip-172-16-30-121.ec2.internal
Dec 24 01:39:21.644: INFO: Pod kublr-monitoring-prometheus-59564b557d-pkjhv requesting resource cpu=710m on Node ip-172-16-103-244.ec2.internal
Dec 24 01:39:21.644: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-16-30-121.ec2.internal
Dec 24 01:39:21.644: INFO: Pod sonobuoy-e2e-job-457b3e5a99034c4d requesting resource cpu=0m on Node ip-172-16-44-108.ec2.internal
Dec 24 01:39:21.644: INFO: Pod sonobuoy-systemd-logs-daemon-set-eb45748a27ab4169-h9v2w requesting resource cpu=0m on Node ip-172-16-103-244.ec2.internal
Dec 24 01:39:21.644: INFO: Pod sonobuoy-systemd-logs-daemon-set-eb45748a27ab4169-v9f85 requesting resource cpu=0m on Node ip-172-16-30-121.ec2.internal
Dec 24 01:39:21.644: INFO: Pod sonobuoy-systemd-logs-daemon-set-eb45748a27ab4169-wpzc6 requesting resource cpu=0m on Node ip-172-16-44-108.ec2.internal
STEP: Starting Pods to consume most of the cluster CPU.
Dec 24 01:39:21.644: INFO: Creating a pod which consumes cpu=1367m on Node ip-172-16-103-244.ec2.internal
Dec 24 01:39:21.654: INFO: Creating a pod which consumes cpu=1861m on Node ip-172-16-30-121.ec2.internal
Dec 24 01:39:21.667: INFO: Creating a pod which consumes cpu=1684m on Node ip-172-16-44-108.ec2.internal
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0965b422-9ca9-4044-b946-a962247f5370.15e32afd3f6c1c92], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1807/filler-pod-0965b422-9ca9-4044-b946-a962247f5370 to ip-172-16-44-108.ec2.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0965b422-9ca9-4044-b946-a962247f5370.15e32afd87216904], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0965b422-9ca9-4044-b946-a962247f5370.15e32afd8ea65446], Reason = [Created], Message = [Created container filler-pod-0965b422-9ca9-4044-b946-a962247f5370]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0965b422-9ca9-4044-b946-a962247f5370.15e32afd9e16fc0b], Reason = [Started], Message = [Started container filler-pod-0965b422-9ca9-4044-b946-a962247f5370]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-83859757-53bb-43ac-bc10-739c64edc78e.15e32afd3da32036], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1807/filler-pod-83859757-53bb-43ac-bc10-739c64edc78e to ip-172-16-103-244.ec2.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-83859757-53bb-43ac-bc10-739c64edc78e.15e32afd85907ad8], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-83859757-53bb-43ac-bc10-739c64edc78e.15e32afd8c44bcdc], Reason = [Created], Message = [Created container filler-pod-83859757-53bb-43ac-bc10-739c64edc78e]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-83859757-53bb-43ac-bc10-739c64edc78e.15e32afd994c0cea], Reason = [Started], Message = [Started container filler-pod-83859757-53bb-43ac-bc10-739c64edc78e]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ac3438f4-0fb6-4948-9d64-947a1b888ab9.15e32afd3eda7bd7], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1807/filler-pod-ac3438f4-0fb6-4948-9d64-947a1b888ab9 to ip-172-16-30-121.ec2.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ac3438f4-0fb6-4948-9d64-947a1b888ab9.15e32afd83015607], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ac3438f4-0fb6-4948-9d64-947a1b888ab9.15e32afd8aaaa6b0], Reason = [Created], Message = [Created container filler-pod-ac3438f4-0fb6-4948-9d64-947a1b888ab9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ac3438f4-0fb6-4948-9d64-947a1b888ab9.15e32afd97acacc7], Reason = [Started], Message = [Started container filler-pod-ac3438f4-0fb6-4948-9d64-947a1b888ab9]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15e32afe2f54d379], Reason = [FailedScheduling], Message = [0/6 nodes are available: 6 Insufficient cpu.]
STEP: removing the label node off the node ip-172-16-103-244.ec2.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-16-30-121.ec2.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-16-44-108.ec2.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:39:26.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1807" for this suite.
Dec 24 01:39:32.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:39:32.934: INFO: namespace sched-pred-1807 deletion completed in 6.153607792s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:11.628 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:39:32.935: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8986
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-7fc1d173-4b40-431e-b8ee-62f20d1962a9
STEP: Creating a pod to test consume configMaps
Dec 24 01:39:33.103: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-17905a99-b035-41f9-b5e4-8a4adf7b40c1" in namespace "projected-8986" to be "success or failure"
Dec 24 01:39:33.112: INFO: Pod "pod-projected-configmaps-17905a99-b035-41f9-b5e4-8a4adf7b40c1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.877532ms
Dec 24 01:39:35.117: INFO: Pod "pod-projected-configmaps-17905a99-b035-41f9-b5e4-8a4adf7b40c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014167637s
Dec 24 01:39:37.127: INFO: Pod "pod-projected-configmaps-17905a99-b035-41f9-b5e4-8a4adf7b40c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023512145s
STEP: Saw pod success
Dec 24 01:39:37.127: INFO: Pod "pod-projected-configmaps-17905a99-b035-41f9-b5e4-8a4adf7b40c1" satisfied condition "success or failure"
Dec 24 01:39:37.133: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod pod-projected-configmaps-17905a99-b035-41f9-b5e4-8a4adf7b40c1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 24 01:39:37.163: INFO: Waiting for pod pod-projected-configmaps-17905a99-b035-41f9-b5e4-8a4adf7b40c1 to disappear
Dec 24 01:39:37.167: INFO: Pod pod-projected-configmaps-17905a99-b035-41f9-b5e4-8a4adf7b40c1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:39:37.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8986" for this suite.
Dec 24 01:39:43.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:39:43.321: INFO: namespace projected-8986 deletion completed in 6.148238437s

• [SLOW TEST:10.386 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:39:43.322: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5843
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 24 01:39:43.492: INFO: Waiting up to 5m0s for pod "downward-api-bf7826e0-2245-46ec-b6d4-ebd119e5c857" in namespace "downward-api-5843" to be "success or failure"
Dec 24 01:39:43.498: INFO: Pod "downward-api-bf7826e0-2245-46ec-b6d4-ebd119e5c857": Phase="Pending", Reason="", readiness=false. Elapsed: 6.184515ms
Dec 24 01:39:45.503: INFO: Pod "downward-api-bf7826e0-2245-46ec-b6d4-ebd119e5c857": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011460317s
Dec 24 01:39:47.509: INFO: Pod "downward-api-bf7826e0-2245-46ec-b6d4-ebd119e5c857": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017071764s
STEP: Saw pod success
Dec 24 01:39:47.509: INFO: Pod "downward-api-bf7826e0-2245-46ec-b6d4-ebd119e5c857" satisfied condition "success or failure"
Dec 24 01:39:47.512: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod downward-api-bf7826e0-2245-46ec-b6d4-ebd119e5c857 container dapi-container: <nil>
STEP: delete the pod
Dec 24 01:39:47.542: INFO: Waiting for pod downward-api-bf7826e0-2245-46ec-b6d4-ebd119e5c857 to disappear
Dec 24 01:39:47.558: INFO: Pod downward-api-bf7826e0-2245-46ec-b6d4-ebd119e5c857 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:39:47.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5843" for this suite.
Dec 24 01:39:53.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:39:53.718: INFO: namespace downward-api-5843 deletion completed in 6.15314771s

• [SLOW TEST:10.397 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:39:53.721: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4176
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec 24 01:39:53.881: INFO: Waiting up to 5m0s for pod "pod-c25ed689-e09f-4811-b9fe-64730ceebb0e" in namespace "emptydir-4176" to be "success or failure"
Dec 24 01:39:53.887: INFO: Pod "pod-c25ed689-e09f-4811-b9fe-64730ceebb0e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.461539ms
Dec 24 01:39:55.892: INFO: Pod "pod-c25ed689-e09f-4811-b9fe-64730ceebb0e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010131757s
Dec 24 01:39:57.897: INFO: Pod "pod-c25ed689-e09f-4811-b9fe-64730ceebb0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015260622s
STEP: Saw pod success
Dec 24 01:39:57.897: INFO: Pod "pod-c25ed689-e09f-4811-b9fe-64730ceebb0e" satisfied condition "success or failure"
Dec 24 01:39:57.901: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-c25ed689-e09f-4811-b9fe-64730ceebb0e container test-container: <nil>
STEP: delete the pod
Dec 24 01:39:57.925: INFO: Waiting for pod pod-c25ed689-e09f-4811-b9fe-64730ceebb0e to disappear
Dec 24 01:39:57.931: INFO: Pod pod-c25ed689-e09f-4811-b9fe-64730ceebb0e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:39:57.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4176" for this suite.
Dec 24 01:40:03.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:40:04.082: INFO: namespace emptydir-4176 deletion completed in 6.145638599s

• [SLOW TEST:10.361 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:40:04.083: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3866
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 24 01:40:12.305: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 24 01:40:12.315: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 24 01:40:14.315: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 24 01:40:14.320: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 24 01:40:16.315: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 24 01:40:16.320: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 24 01:40:18.315: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 24 01:40:18.319: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 24 01:40:20.317: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 24 01:40:20.322: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:40:20.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3866" for this suite.
Dec 24 01:40:48.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:40:48.482: INFO: namespace container-lifecycle-hook-3866 deletion completed in 28.153016228s

• [SLOW TEST:44.399 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:40:48.482: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4800
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 24 01:40:48.648: INFO: Waiting up to 5m0s for pod "pod-54311213-749d-463a-bd63-ada64338c600" in namespace "emptydir-4800" to be "success or failure"
Dec 24 01:40:48.653: INFO: Pod "pod-54311213-749d-463a-bd63-ada64338c600": Phase="Pending", Reason="", readiness=false. Elapsed: 5.099524ms
Dec 24 01:40:50.658: INFO: Pod "pod-54311213-749d-463a-bd63-ada64338c600": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009871394s
Dec 24 01:40:52.662: INFO: Pod "pod-54311213-749d-463a-bd63-ada64338c600": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013600722s
STEP: Saw pod success
Dec 24 01:40:52.662: INFO: Pod "pod-54311213-749d-463a-bd63-ada64338c600" satisfied condition "success or failure"
Dec 24 01:40:52.665: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod pod-54311213-749d-463a-bd63-ada64338c600 container test-container: <nil>
STEP: delete the pod
Dec 24 01:40:52.697: INFO: Waiting for pod pod-54311213-749d-463a-bd63-ada64338c600 to disappear
Dec 24 01:40:52.701: INFO: Pod pod-54311213-749d-463a-bd63-ada64338c600 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:40:52.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4800" for this suite.
Dec 24 01:40:58.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:40:58.839: INFO: namespace emptydir-4800 deletion completed in 6.133498595s

• [SLOW TEST:10.358 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:40:58.840: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-2000
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Dec 24 01:41:03.518: INFO: Successfully updated pod "adopt-release-bzqtk"
STEP: Checking that the Job readopts the Pod
Dec 24 01:41:03.518: INFO: Waiting up to 15m0s for pod "adopt-release-bzqtk" in namespace "job-2000" to be "adopted"
Dec 24 01:41:03.523: INFO: Pod "adopt-release-bzqtk": Phase="Running", Reason="", readiness=true. Elapsed: 4.901666ms
Dec 24 01:41:05.528: INFO: Pod "adopt-release-bzqtk": Phase="Running", Reason="", readiness=true. Elapsed: 2.00983356s
Dec 24 01:41:05.528: INFO: Pod "adopt-release-bzqtk" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Dec 24 01:41:06.040: INFO: Successfully updated pod "adopt-release-bzqtk"
STEP: Checking that the Job releases the Pod
Dec 24 01:41:06.040: INFO: Waiting up to 15m0s for pod "adopt-release-bzqtk" in namespace "job-2000" to be "released"
Dec 24 01:41:06.044: INFO: Pod "adopt-release-bzqtk": Phase="Running", Reason="", readiness=true. Elapsed: 3.997064ms
Dec 24 01:41:08.049: INFO: Pod "adopt-release-bzqtk": Phase="Running", Reason="", readiness=true. Elapsed: 2.00885208s
Dec 24 01:41:08.049: INFO: Pod "adopt-release-bzqtk" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:41:08.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2000" for this suite.
Dec 24 01:41:48.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:41:48.199: INFO: namespace job-2000 deletion completed in 40.141386233s

• [SLOW TEST:49.359 seconds]
[sig-apps] Job
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:41:48.199: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9471
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 01:41:48.362: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec 24 01:41:53.367: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 24 01:41:53.367: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 24 01:41:57.399: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-9471 /apis/apps/v1/namespaces/deployment-9471/deployments/test-cleanup-deployment c12b2228-2bcc-4518-92ef-a089274c8688 120305 1 2019-12-24 01:41:53 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0024c29c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-24 01:41:53 +0000 UTC,LastTransitionTime:2019-12-24 01:41:53 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-65db99849b" has successfully progressed.,LastUpdateTime:2019-12-24 01:41:55 +0000 UTC,LastTransitionTime:2019-12-24 01:41:53 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 24 01:41:57.403: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-9471 /apis/apps/v1/namespaces/deployment-9471/replicasets/test-cleanup-deployment-65db99849b 1e89ceff-0a0c-47e6-9705-fc2de86e471e 120294 1 2019-12-24 01:41:53 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment c12b2228-2bcc-4518-92ef-a089274c8688 0xc0024c2df7 0xc0024c2df8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0024c2e58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 24 01:41:57.407: INFO: Pod "test-cleanup-deployment-65db99849b-582z6" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-65db99849b-582z6 test-cleanup-deployment-65db99849b- deployment-9471 /api/v1/namespaces/deployment-9471/pods/test-cleanup-deployment-65db99849b-582z6 1dcca151-e03a-4478-8623-9703b3061144 120293 0 2019-12-24 01:41:53 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[cni.projectcalico.org/podIP:100.96.3.99/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-cleanup-deployment-65db99849b 1e89ceff-0a0c-47e6-9705-fc2de86e471e 0xc0024c3217 0xc0024c3218}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-kslqz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-kslqz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-kslqz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-44-108.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 01:41:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 01:41:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 01:41:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 01:41:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.16.44.108,PodIP:100.96.3.99,StartTime:2019-12-24 01:41:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-24 01:41:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://2663219da9775edcd6292432aa07b1fcf8530f8a57a99ca00a1063630fbb9fd6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.3.99,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:41:57.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9471" for this suite.
Dec 24 01:42:03.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:42:03.554: INFO: namespace deployment-9471 deletion completed in 6.14133332s

• [SLOW TEST:15.356 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:42:03.555: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7521
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 01:42:03.716: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec 24 01:42:08.721: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 24 01:42:08.721: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec 24 01:42:10.726: INFO: Creating deployment "test-rollover-deployment"
Dec 24 01:42:10.736: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec 24 01:42:12.746: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec 24 01:42:12.757: INFO: Ensure that both replica sets have 1 created replica
Dec 24 01:42:12.766: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec 24 01:42:12.774: INFO: Updating deployment test-rollover-deployment
Dec 24 01:42:12.774: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec 24 01:42:14.782: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec 24 01:42:14.790: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec 24 01:42:14.798: INFO: all replica sets need to contain the pod-template-hash label
Dec 24 01:42:14.799: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748530, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748530, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748532, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748530, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 24 01:42:16.808: INFO: all replica sets need to contain the pod-template-hash label
Dec 24 01:42:16.808: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748530, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748530, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748534, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748530, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 24 01:42:18.807: INFO: all replica sets need to contain the pod-template-hash label
Dec 24 01:42:18.807: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748530, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748530, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748534, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748530, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 24 01:42:20.808: INFO: all replica sets need to contain the pod-template-hash label
Dec 24 01:42:20.808: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748530, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748530, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748534, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748530, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 24 01:42:22.807: INFO: all replica sets need to contain the pod-template-hash label
Dec 24 01:42:22.807: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748530, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748530, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748534, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748530, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 24 01:42:24.807: INFO: all replica sets need to contain the pod-template-hash label
Dec 24 01:42:24.807: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748530, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748530, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748534, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748530, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 24 01:42:26.807: INFO: 
Dec 24 01:42:26.807: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 24 01:42:26.821: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-7521 /apis/apps/v1/namespaces/deployment-7521/deployments/test-rollover-deployment 396f98d9-3596-4394-9099-fc56c86dec64 120495 2 2019-12-24 01:42:10 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00360a5f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-24 01:42:10 +0000 UTC,LastTransitionTime:2019-12-24 01:42:10 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2019-12-24 01:42:24 +0000 UTC,LastTransitionTime:2019-12-24 01:42:10 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 24 01:42:26.825: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-7521 /apis/apps/v1/namespaces/deployment-7521/replicasets/test-rollover-deployment-7d7dc6548c bf78346c-0a91-4ed3-a57f-ff5f562b0b52 120482 2 2019-12-24 01:42:12 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 396f98d9-3596-4394-9099-fc56c86dec64 0xc00360abb7 0xc00360abb8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00360ac18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 24 01:42:26.825: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec 24 01:42:26.825: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-7521 /apis/apps/v1/namespaces/deployment-7521/replicasets/test-rollover-controller 5fc20bd7-3248-4a55-89ee-f52bd4d182ef 120494 2 2019-12-24 01:42:03 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 396f98d9-3596-4394-9099-fc56c86dec64 0xc00360aae7 0xc00360aae8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00360ab48 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 24 01:42:26.826: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-7521 /apis/apps/v1/namespaces/deployment-7521/replicasets/test-rollover-deployment-f6c94f66c 54e25aee-b86b-4393-ad96-827127b7a48f 120442 2 2019-12-24 01:42:10 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 396f98d9-3596-4394-9099-fc56c86dec64 0xc00360ac80 0xc00360ac81}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00360acf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 24 01:42:26.830: INFO: Pod "test-rollover-deployment-7d7dc6548c-6wlds" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-6wlds test-rollover-deployment-7d7dc6548c- deployment-7521 /api/v1/namespaces/deployment-7521/pods/test-rollover-deployment-7d7dc6548c-6wlds 60fff0f6-00e6-4b5c-8a6c-c554a86627a6 120454 0 2019-12-24 01:42:12 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[cni.projectcalico.org/podIP:100.96.4.117/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c bf78346c-0a91-4ed3-a57f-ff5f562b0b52 0xc00360b267 0xc00360b268}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mpcbx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mpcbx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mpcbx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-30-121.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 01:42:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 01:42:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 01:42:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 01:42:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.16.30.121,PodIP:100.96.4.117,StartTime:2019-12-24 01:42:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-24 01:42:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://293725821a8b989e795d5bf24877d1708b9822a030a25176a186397f91491933,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.4.117,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:42:26.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7521" for this suite.
Dec 24 01:42:32.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:42:33.002: INFO: namespace deployment-7521 deletion completed in 6.16634082s

• [SLOW TEST:29.447 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:42:33.002: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-4710
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec 24 01:42:33.712: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Dec 24 01:42:35.725: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748553, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748553, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748553, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748553, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 24 01:42:38.752: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 01:42:38.757: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:42:44.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-4710" for this suite.
Dec 24 01:42:50.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:42:50.604: INFO: namespace crd-webhook-4710 deletion completed in 6.142627843s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:17.623 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:42:50.625: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6626
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-f2e3a511-499d-4955-8c61-12ea95b698c5
STEP: Creating a pod to test consume secrets
Dec 24 01:42:50.795: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cd110748-5364-4060-bf02-e8738f009ab6" in namespace "projected-6626" to be "success or failure"
Dec 24 01:42:50.805: INFO: Pod "pod-projected-secrets-cd110748-5364-4060-bf02-e8738f009ab6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.479384ms
Dec 24 01:42:52.812: INFO: Pod "pod-projected-secrets-cd110748-5364-4060-bf02-e8738f009ab6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01629924s
STEP: Saw pod success
Dec 24 01:42:52.812: INFO: Pod "pod-projected-secrets-cd110748-5364-4060-bf02-e8738f009ab6" satisfied condition "success or failure"
Dec 24 01:42:52.816: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod pod-projected-secrets-cd110748-5364-4060-bf02-e8738f009ab6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 24 01:42:52.848: INFO: Waiting for pod pod-projected-secrets-cd110748-5364-4060-bf02-e8738f009ab6 to disappear
Dec 24 01:42:52.855: INFO: Pod pod-projected-secrets-cd110748-5364-4060-bf02-e8738f009ab6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:42:52.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6626" for this suite.
Dec 24 01:42:58.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:42:59.004: INFO: namespace projected-6626 deletion completed in 6.143112929s

• [SLOW TEST:8.379 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:42:59.004: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7503
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 01:42:59.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 create -f - --namespace=kubectl-7503'
Dec 24 01:42:59.379: INFO: stderr: ""
Dec 24 01:42:59.379: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec 24 01:42:59.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 create -f - --namespace=kubectl-7503'
Dec 24 01:42:59.547: INFO: stderr: ""
Dec 24 01:42:59.547: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 24 01:43:00.552: INFO: Selector matched 1 pods for map[app:redis]
Dec 24 01:43:00.553: INFO: Found 0 / 1
Dec 24 01:43:01.552: INFO: Selector matched 1 pods for map[app:redis]
Dec 24 01:43:01.552: INFO: Found 0 / 1
Dec 24 01:43:02.552: INFO: Selector matched 1 pods for map[app:redis]
Dec 24 01:43:02.552: INFO: Found 1 / 1
Dec 24 01:43:02.552: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 24 01:43:02.558: INFO: Selector matched 1 pods for map[app:redis]
Dec 24 01:43:02.558: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 24 01:43:02.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 describe pod redis-master-c5w88 --namespace=kubectl-7503'
Dec 24 01:43:02.646: INFO: stderr: ""
Dec 24 01:43:02.646: INFO: stdout: "Name:         redis-master-c5w88\nNamespace:    kubectl-7503\nPriority:     0\nNode:         ip-172-16-30-121.ec2.internal/172.16.30.121\nStart Time:   Tue, 24 Dec 2019 01:42:59 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  cni.projectcalico.org/podIP: 100.96.4.118/32\n              kubernetes.io/psp: e2e-test-privileged-psp\nStatus:       Running\nIP:           100.96.4.118\nIPs:\n  IP:           100.96.4.118\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://853623f0d787b3f9769223a7bdeb42c495059870f393ac8cbe3d3489daaa0f96\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 24 Dec 2019 01:43:00 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-g27nm (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-g27nm:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-g27nm\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                    Message\n  ----    ------     ----  ----                                    -------\n  Normal  Scheduled  3s    default-scheduler                       Successfully assigned kubectl-7503/redis-master-c5w88 to ip-172-16-30-121.ec2.internal\n  Normal  Pulled     2s    kubelet, ip-172-16-30-121.ec2.internal  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    2s    kubelet, ip-172-16-30-121.ec2.internal  Created container redis-master\n  Normal  Started    2s    kubelet, ip-172-16-30-121.ec2.internal  Started container redis-master\n"
Dec 24 01:43:02.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 describe rc redis-master --namespace=kubectl-7503'
Dec 24 01:43:02.740: INFO: stderr: ""
Dec 24 01:43:02.740: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-7503\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-c5w88\n"
Dec 24 01:43:02.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 describe service redis-master --namespace=kubectl-7503'
Dec 24 01:43:02.819: INFO: stderr: ""
Dec 24 01:43:02.819: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-7503\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                100.70.0.235\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         100.96.4.118:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec 24 01:43:02.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 describe node ip-172-16-103-244.ec2.internal'
Dec 24 01:43:02.928: INFO: stderr: ""
Dec 24 01:43:02.928: INFO: stdout: "Name:               ip-172-16-103-244.ec2.internal\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=t2.xlarge\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-east-1\n                    failure-domain.beta.kubernetes.io/zone=us-east-1f\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-16-103-244\n                    kubernetes.io/os=linux\n                    kublr.io/location=aws1\n                    kublr.io/node-group=group1\n                    kublr.io/node-identifier=516fe9da-e770-433b-8f20-f711717a95d0\n                    kublr.io/node-ordinal=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"5a:85:12:25:a6:b7\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 172.16.103.244\n                    kublr.io/agent-status:\n                      {\"clusterName\":\"dvi-5231-pfct-1577115245\",\"location\":\"aws1\",\"nodeGroup\":\"group1\",\"nodeOrdinal\":-1,\"nodeIdentifier\":\"516fe9da-e770-433b-8f2...\n                    kublr.io/location: aws1\n                    kublr.io/node-group: group1\n                    kublr.io/node-identifier: 516fe9da-e770-433b-8f20-f711717a95d0\n                    kublr.io/node-ordinal: \n                    kublr.io/seeder-status:\n                      {\"clusterName\":\"dvi-5231-pfct-1577115245\",\"location\":\"aws1\",\"nodeGroup\":\"group1\",\"nodeOrdinal\":-1,\"nodeIdentifier\":\"516fe9da-e770-433b-8f2...\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4IPIPTunnelAddr: 100.96.5.1\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 23 Dec 2019 15:44:07 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                             ------  -----------------                 ------------------                ------                       -------\n  KublrSeederAgentReady            True    Tue, 24 Dec 2019 01:42:48 +0000   Mon, 23 Dec 2019 15:41:30 +0000   KublrAgentRunning            Kublr agent is running\n  KublrSeederInstanceReady         True    Tue, 24 Dec 2019 01:42:48 +0000   Mon, 23 Dec 2019 15:39:19 +0000   SeederRunning                Seeder is running\n  KublrSeederSecretStoreReady      True    Tue, 24 Dec 2019 01:42:48 +0000   Mon, 23 Dec 2019 15:39:19 +0000   SecretStoreOk                Secret store is running and accessible\n  KublrAgentContainerEngineReady   True    Tue, 24 Dec 2019 01:42:33 +0000   Mon, 23 Dec 2019 15:41:36 +0000   DockerRunning                Docker is running\n  KublrAgentInstanceReady          True    Tue, 24 Dec 2019 01:42:32 +0000   Mon, 23 Dec 2019 15:41:16 +0000   AgentRunning                 Agent is running\n  KublrAgentKubeletReady           True    Tue, 24 Dec 2019 01:42:32 +0000   Mon, 23 Dec 2019 15:41:36 +0000   KubeletRunning               Kubelet is running\n  MemoryPressure                   False   Tue, 24 Dec 2019 01:42:32 +0000   Mon, 23 Dec 2019 15:44:07 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure                     False   Tue, 24 Dec 2019 01:42:32 +0000   Mon, 23 Dec 2019 15:44:07 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure                      False   Tue, 24 Dec 2019 01:42:32 +0000   Mon, 23 Dec 2019 15:44:07 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                            True    Tue, 24 Dec 2019 01:42:32 +0000   Mon, 23 Dec 2019 15:44:27 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:   172.16.103.244\n  ExternalIP:   34.231.180.117\n  Hostname:     ip-172-16-103-244.ec2.internal\n  InternalDNS:  ip-172-16-103-244.ec2.internal\n  ExternalDNS:  ec2-34-231-180-117.compute-1.amazonaws.com\nCapacity:\n attachable-volumes-aws-ebs:  39\n cpu:                         4\n ephemeral-storage:           40593612Ki\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      16424572Ki\n pods:                        110\nAllocatable:\n attachable-volumes-aws-ebs:  39\n cpu:                         3900m\n ephemeral-storage:           35263589110\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      15273596Ki\n pods:                        110\nSystem Info:\n Machine ID:                 3d8695bc2d6d440abfaa44ac95ff1232\n System UUID:                EC2E2656-9EC7-28A3-8001-1C1D3F565A36\n Boot ID:                    5327f390-f3d7-40ee-85e9-572038eedea3\n Kernel Version:             4.15.0-1054-aws\n OS Image:                   Ubuntu 18.04.3 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.7\n Kubelet Version:            v1.16.4\n Kube-Proxy Version:         v1.16.4\nPodCIDR:                     100.96.5.0/24\nPodCIDRs:                    100.96.5.0/24\nProviderID:                  aws:///us-east-1f/i-077484b9dffe2d027\nNon-terminated Pods:         (15 in total)\n  Namespace                  Name                                                                                                                        CPU Requests  CPU Limits  Memory Requests  Memory Limits    AGE\n  ---------                  ----                                                                                                                        ------------  ----------  ---------------  -------------    ---\n  kube-system                canal-d28dx                                                                                                                 50m (1%)      0 (0%)      114Mi (0%)       128Mi (0%)       9h\n  kube-system                k8s-api-haproxy-de80cb1199e732ef3c9ca0051c41dd966f81ca8bee9c571b76dea5e659c7b97b-ip-172-16-103-244.ec2.internal             1m (0%)       0 (0%)      20Mi (0%)        20Mi (0%)        9h\n  kube-system                kube-proxy-7e590abedfb7de51d1197b20e754686a6a8674ae8ac79bc64dcfdc0bb67fb64f-ip-172-16-103-244.ec2.internal                  5m (0%)       250m (6%)   48Mi (0%)        48Mi (0%)        9h\n  kube-system                kublr-ingress-nginx-ingress-controller-849b4769fc-79bhq                                                                     100m (2%)     100m (2%)   64Mi (0%)        256Mi (1%)       9h\n  kube-system                kublr-ingress-nginx-ingress-default-backend-7b84f6bc4b-xr9cg                                                                0 (0%)        0 (0%)      0 (0%)           0 (0%)           9h\n  kube-system                kublr-node-name-reporter-b5f50899e00ed5b8ad1b215b812381270bf0779993c3a6740826f2cfb378f08f-ip-172-16-103-244.ec2.internal    0 (0%)        0 (0%)      32Mi (0%)        32Mi (0%)        9h\n  kube-system                node-local-dns-hw2d5                                                                                                        25m (0%)      0 (0%)      5Mi (0%)         30Mi (0%)        9h\n  kublr                      kublr-logging-controller-7f5d56f594-rq5fl                                                                                   100m (2%)     0 (0%)      32Mi (0%)        160Mi (1%)       9h\n  kublr                      kublr-logging-elasticsearch-client-6f7d56fdbb-zgnhd                                                                         25m (0%)      0 (0%)      2Gi (13%)        2Gi (13%)        9h\n  kublr                      kublr-logging-fluentd-es-7rd6f                                                                                              150m (3%)     0 (0%)      128Mi (0%)       512Mi (3%)       9h\n  kublr                      kublr-logging-rabbitmq-0                                                                                                    400m (10%)    0 (0%)      512Mi (3%)       1Gi (6%)         9h\n  kublr                      kublr-monitoring-alertmanager-549cf5f44c-fbdlf                                                                              60m (1%)      0 (0%)      352Mi (2%)       352Mi (2%)       9h\n  kublr                      kublr-monitoring-grafana-6fbbfc98f4-n9zw5                                                                                   320m (8%)     0 (0%)      448Mi (3%)       448Mi (3%)       9h\n  kublr                      kublr-monitoring-prometheus-59564b557d-pkjhv                                                                                710m (18%)    0 (0%)      4004554Ki (26%)  4004554Ki (26%)  9h\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-eb45748a27ab4169-h9v2w                                                                     0 (0%)        0 (0%)      0 (0%)           0 (0%)           23m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                    Requests         Limits\n  --------                    --------         ------\n  cpu                         1946m (49%)      350m (8%)\n  memory                      7898826Ki (51%)  9183946Ki (60%)\n  ephemeral-storage           0 (0%)           0 (0%)\n  attachable-volumes-aws-ebs  0                0\nEvents:                       <none>\n"
Dec 24 01:43:02.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 describe namespace kubectl-7503'
Dec 24 01:43:03.008: INFO: stderr: ""
Dec 24 01:43:03.008: INFO: stdout: "Name:         kubectl-7503\nLabels:       e2e-framework=kubectl\n              e2e-run=2afe0d8d-0f39-465e-b92e-1b3f48c83b46\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:43:03.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7503" for this suite.
Dec 24 01:43:15.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:43:15.156: INFO: namespace kubectl-7503 deletion completed in 12.143042946s

• [SLOW TEST:16.152 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:43:15.156: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5221
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 24 01:43:15.319: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2021a272-2690-4d54-b9ed-ec38b68f6484" in namespace "downward-api-5221" to be "success or failure"
Dec 24 01:43:15.325: INFO: Pod "downwardapi-volume-2021a272-2690-4d54-b9ed-ec38b68f6484": Phase="Pending", Reason="", readiness=false. Elapsed: 5.552405ms
Dec 24 01:43:17.330: INFO: Pod "downwardapi-volume-2021a272-2690-4d54-b9ed-ec38b68f6484": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010806237s
Dec 24 01:43:19.334: INFO: Pod "downwardapi-volume-2021a272-2690-4d54-b9ed-ec38b68f6484": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015175982s
STEP: Saw pod success
Dec 24 01:43:19.334: INFO: Pod "downwardapi-volume-2021a272-2690-4d54-b9ed-ec38b68f6484" satisfied condition "success or failure"
Dec 24 01:43:19.338: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod downwardapi-volume-2021a272-2690-4d54-b9ed-ec38b68f6484 container client-container: <nil>
STEP: delete the pod
Dec 24 01:43:19.369: INFO: Waiting for pod downwardapi-volume-2021a272-2690-4d54-b9ed-ec38b68f6484 to disappear
Dec 24 01:43:19.373: INFO: Pod downwardapi-volume-2021a272-2690-4d54-b9ed-ec38b68f6484 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:43:19.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5221" for this suite.
Dec 24 01:43:25.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:43:25.509: INFO: namespace downward-api-5221 deletion completed in 6.130927727s

• [SLOW TEST:10.353 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:43:25.509: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2543
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:43:25.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2543" for this suite.
Dec 24 01:43:31.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:43:31.854: INFO: namespace kubelet-test-2543 deletion completed in 6.154985617s

• [SLOW TEST:6.345 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:43:31.854: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-3607
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:43:32.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3607" for this suite.
Dec 24 01:43:38.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:43:38.185: INFO: namespace custom-resource-definition-3607 deletion completed in 6.169203329s

• [SLOW TEST:6.331 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:43:38.185: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5379
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-9182aa94-a910-43f4-868c-eeca3928bf41
STEP: Creating configMap with name cm-test-opt-upd-e37f32e6-0335-43cb-b1f5-e583e8d9f2a6
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-9182aa94-a910-43f4-868c-eeca3928bf41
STEP: Updating configmap cm-test-opt-upd-e37f32e6-0335-43cb-b1f5-e583e8d9f2a6
STEP: Creating configMap with name cm-test-opt-create-ee3853a8-6f01-4055-b466-427bf479c72d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:43:46.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5379" for this suite.
Dec 24 01:43:58.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:43:58.645: INFO: namespace projected-5379 deletion completed in 12.144539443s

• [SLOW TEST:20.460 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:43:58.645: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-1049
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9682
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-829
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:44:30.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1049" for this suite.
Dec 24 01:44:36.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:44:36.303: INFO: namespace namespaces-1049 deletion completed in 6.139248796s
STEP: Destroying namespace "nsdeletetest-9682" for this suite.
Dec 24 01:44:36.307: INFO: Namespace nsdeletetest-9682 was already deleted
STEP: Destroying namespace "nsdeletetest-829" for this suite.
Dec 24 01:44:42.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:44:42.442: INFO: namespace nsdeletetest-829 deletion completed in 6.134985654s

• [SLOW TEST:43.797 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:44:42.443: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7832
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Dec 24 01:44:42.601: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec 24 01:44:42.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 create -f - --namespace=kubectl-7832'
Dec 24 01:44:42.829: INFO: stderr: ""
Dec 24 01:44:42.829: INFO: stdout: "service/redis-slave created\n"
Dec 24 01:44:42.829: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec 24 01:44:42.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 create -f - --namespace=kubectl-7832'
Dec 24 01:44:43.066: INFO: stderr: ""
Dec 24 01:44:43.066: INFO: stdout: "service/redis-master created\n"
Dec 24 01:44:43.066: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec 24 01:44:43.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 create -f - --namespace=kubectl-7832'
Dec 24 01:44:43.289: INFO: stderr: ""
Dec 24 01:44:43.289: INFO: stdout: "service/frontend created\n"
Dec 24 01:44:43.289: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec 24 01:44:43.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 create -f - --namespace=kubectl-7832'
Dec 24 01:44:43.546: INFO: stderr: ""
Dec 24 01:44:43.546: INFO: stdout: "deployment.apps/frontend created\n"
Dec 24 01:44:43.547: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 24 01:44:43.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 create -f - --namespace=kubectl-7832'
Dec 24 01:44:43.821: INFO: stderr: ""
Dec 24 01:44:43.821: INFO: stdout: "deployment.apps/redis-master created\n"
Dec 24 01:44:43.821: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec 24 01:44:43.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 create -f - --namespace=kubectl-7832'
Dec 24 01:44:44.013: INFO: stderr: ""
Dec 24 01:44:44.013: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Dec 24 01:44:44.013: INFO: Waiting for all frontend pods to be Running.
Dec 24 01:44:49.063: INFO: Waiting for frontend to serve content.
Dec 24 01:44:54.088: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Dec 24 01:44:59.107: INFO: Trying to add a new entry to the guestbook.
Dec 24 01:44:59.124: INFO: Verifying that added entry can be retrieved.
Dec 24 01:44:59.135: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec 24 01:45:04.151: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec 24 01:45:09.168: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec 24 01:45:14.184: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec 24 01:45:19.201: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec 24 01:45:24.222: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec 24 01:45:29.238: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec 24 01:45:34.264: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec 24 01:45:39.282: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec 24 01:45:44.302: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Dec 24 01:45:49.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 delete --grace-period=0 --force -f - --namespace=kubectl-7832'
Dec 24 01:45:49.433: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 24 01:45:49.433: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec 24 01:45:49.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 delete --grace-period=0 --force -f - --namespace=kubectl-7832'
Dec 24 01:45:49.529: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 24 01:45:49.529: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 24 01:45:49.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 delete --grace-period=0 --force -f - --namespace=kubectl-7832'
Dec 24 01:45:49.635: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 24 01:45:49.635: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 24 01:45:49.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 delete --grace-period=0 --force -f - --namespace=kubectl-7832'
Dec 24 01:45:49.717: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 24 01:45:49.717: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 24 01:45:49.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 delete --grace-period=0 --force -f - --namespace=kubectl-7832'
Dec 24 01:45:49.805: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 24 01:45:49.806: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 24 01:45:49.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 delete --grace-period=0 --force -f - --namespace=kubectl-7832'
Dec 24 01:45:49.901: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 24 01:45:49.901: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:45:49.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7832" for this suite.
Dec 24 01:46:17.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:46:18.049: INFO: namespace kubectl-7832 deletion completed in 28.142936763s

• [SLOW TEST:95.607 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:46:18.050: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5043
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Dec 24 01:46:18.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 api-versions'
Dec 24 01:46:18.296: INFO: stderr: ""
Dec 24 01:46:18.296: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncore.kublr.io/v1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:46:18.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5043" for this suite.
Dec 24 01:46:24.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:46:24.441: INFO: namespace kubectl-5043 deletion completed in 6.138419094s

• [SLOW TEST:6.391 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:46:24.441: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-34
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 24 01:46:25.181: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 24 01:46:27.195: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748785, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748785, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748785, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712748785, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 24 01:46:30.230: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 01:46:30.236: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7521-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:46:36.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-34" for this suite.
Dec 24 01:46:42.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:46:42.601: INFO: namespace webhook-34 deletion completed in 6.223143737s
STEP: Destroying namespace "webhook-34-markers" for this suite.
Dec 24 01:46:48.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:46:48.735: INFO: namespace webhook-34-markers deletion completed in 6.134285511s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.315 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:46:48.756: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5044
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 24 01:46:53.445: INFO: Successfully updated pod "pod-update-25a692dc-3ff0-4549-b3a1-ed6d0924c582"
STEP: verifying the updated pod is in kubernetes
Dec 24 01:46:53.454: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:46:53.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5044" for this suite.
Dec 24 01:47:21.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:47:21.645: INFO: namespace pods-5044 deletion completed in 28.178696332s

• [SLOW TEST:32.889 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:47:21.649: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-75
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 01:47:25.856: INFO: Waiting up to 5m0s for pod "client-envvars-6705045e-55fd-48c7-a29b-199aafa9fddf" in namespace "pods-75" to be "success or failure"
Dec 24 01:47:25.860: INFO: Pod "client-envvars-6705045e-55fd-48c7-a29b-199aafa9fddf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.316058ms
Dec 24 01:47:27.865: INFO: Pod "client-envvars-6705045e-55fd-48c7-a29b-199aafa9fddf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008917469s
Dec 24 01:47:29.869: INFO: Pod "client-envvars-6705045e-55fd-48c7-a29b-199aafa9fddf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013452653s
STEP: Saw pod success
Dec 24 01:47:29.869: INFO: Pod "client-envvars-6705045e-55fd-48c7-a29b-199aafa9fddf" satisfied condition "success or failure"
Dec 24 01:47:29.876: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod client-envvars-6705045e-55fd-48c7-a29b-199aafa9fddf container env3cont: <nil>
STEP: delete the pod
Dec 24 01:47:29.912: INFO: Waiting for pod client-envvars-6705045e-55fd-48c7-a29b-199aafa9fddf to disappear
Dec 24 01:47:29.921: INFO: Pod client-envvars-6705045e-55fd-48c7-a29b-199aafa9fddf no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:47:29.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-75" for this suite.
Dec 24 01:47:41.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:47:42.075: INFO: namespace pods-75 deletion completed in 12.137837216s

• [SLOW TEST:20.426 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:47:42.075: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7439
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7439.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7439.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7439.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7439.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7439.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7439.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7439.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7439.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7439.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7439.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7439.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 57.42.71.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.71.42.57_udp@PTR;check="$$(dig +tcp +noall +answer +search 57.42.71.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.71.42.57_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7439.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7439.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7439.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7439.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7439.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7439.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7439.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7439.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7439.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7439.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7439.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 57.42.71.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.71.42.57_udp@PTR;check="$$(dig +tcp +noall +answer +search 57.42.71.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.71.42.57_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 24 01:47:46.288: INFO: Unable to read wheezy_udp@dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:46.293: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:46.298: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:46.312: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:46.346: INFO: Unable to read jessie_udp@dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:46.352: INFO: Unable to read jessie_tcp@dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:46.356: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:46.362: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:46.392: INFO: Lookups using dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae failed for: [wheezy_udp@dns-test-service.dns-7439.svc.cluster.local wheezy_tcp@dns-test-service.dns-7439.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local jessie_udp@dns-test-service.dns-7439.svc.cluster.local jessie_tcp@dns-test-service.dns-7439.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local]

Dec 24 01:47:51.397: INFO: Unable to read wheezy_udp@dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:51.403: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:51.408: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:51.412: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:51.451: INFO: Unable to read jessie_udp@dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:51.457: INFO: Unable to read jessie_tcp@dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:51.462: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:51.466: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:51.494: INFO: Lookups using dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae failed for: [wheezy_udp@dns-test-service.dns-7439.svc.cluster.local wheezy_tcp@dns-test-service.dns-7439.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local jessie_udp@dns-test-service.dns-7439.svc.cluster.local jessie_tcp@dns-test-service.dns-7439.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local]

Dec 24 01:47:56.397: INFO: Unable to read wheezy_udp@dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:56.403: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:56.408: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:56.412: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:56.449: INFO: Unable to read jessie_udp@dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:56.454: INFO: Unable to read jessie_tcp@dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:56.459: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:56.463: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:47:56.491: INFO: Lookups using dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae failed for: [wheezy_udp@dns-test-service.dns-7439.svc.cluster.local wheezy_tcp@dns-test-service.dns-7439.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local jessie_udp@dns-test-service.dns-7439.svc.cluster.local jessie_tcp@dns-test-service.dns-7439.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local]

Dec 24 01:48:01.398: INFO: Unable to read wheezy_udp@dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:48:01.403: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:48:01.408: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:48:01.412: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:48:01.446: INFO: Unable to read jessie_udp@dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:48:01.450: INFO: Unable to read jessie_tcp@dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:48:01.455: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:48:01.461: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local from pod dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae: the server could not find the requested resource (get pods dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae)
Dec 24 01:48:01.490: INFO: Lookups using dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae failed for: [wheezy_udp@dns-test-service.dns-7439.svc.cluster.local wheezy_tcp@dns-test-service.dns-7439.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local jessie_udp@dns-test-service.dns-7439.svc.cluster.local jessie_tcp@dns-test-service.dns-7439.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7439.svc.cluster.local]

Dec 24 01:48:06.484: INFO: DNS probes using dns-7439/dns-test-bc81a4cb-11c8-4784-8a91-f7acf1ad3cae succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:48:06.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7439" for this suite.
Dec 24 01:48:12.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:48:12.743: INFO: namespace dns-7439 deletion completed in 6.143525184s

• [SLOW TEST:30.668 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:48:12.743: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8386
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 24 01:48:17.454: INFO: Successfully updated pod "labelsupdatefee6197d-3618-4418-9c52-9a2ba7d9c176"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:48:19.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8386" for this suite.
Dec 24 01:48:31.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:48:31.625: INFO: namespace projected-8386 deletion completed in 12.144306295s

• [SLOW TEST:18.882 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:48:31.626: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8898
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 01:48:31.783: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:48:37.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8898" for this suite.
Dec 24 01:48:43.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:48:43.463: INFO: namespace custom-resource-definition-8898 deletion completed in 6.135411689s

• [SLOW TEST:11.837 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:48:43.463: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-2899
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-2899
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-2899
STEP: Deleting pre-stop pod
Dec 24 01:48:56.712: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:48:56.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-2899" for this suite.
Dec 24 01:49:40.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:49:40.876: INFO: namespace prestop-2899 deletion completed in 44.142569232s

• [SLOW TEST:57.413 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:49:40.876: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5588
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 24 01:49:41.039: INFO: Waiting up to 5m0s for pod "downward-api-9d8d0eee-21fa-404e-a3c6-0f32e199bd9c" in namespace "downward-api-5588" to be "success or failure"
Dec 24 01:49:41.042: INFO: Pod "downward-api-9d8d0eee-21fa-404e-a3c6-0f32e199bd9c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.172881ms
Dec 24 01:49:43.047: INFO: Pod "downward-api-9d8d0eee-21fa-404e-a3c6-0f32e199bd9c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007901072s
Dec 24 01:49:45.052: INFO: Pod "downward-api-9d8d0eee-21fa-404e-a3c6-0f32e199bd9c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012819955s
STEP: Saw pod success
Dec 24 01:49:45.052: INFO: Pod "downward-api-9d8d0eee-21fa-404e-a3c6-0f32e199bd9c" satisfied condition "success or failure"
Dec 24 01:49:45.056: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod downward-api-9d8d0eee-21fa-404e-a3c6-0f32e199bd9c container dapi-container: <nil>
STEP: delete the pod
Dec 24 01:49:45.083: INFO: Waiting for pod downward-api-9d8d0eee-21fa-404e-a3c6-0f32e199bd9c to disappear
Dec 24 01:49:45.087: INFO: Pod downward-api-9d8d0eee-21fa-404e-a3c6-0f32e199bd9c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:49:45.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5588" for this suite.
Dec 24 01:49:51.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:49:51.248: INFO: namespace downward-api-5588 deletion completed in 6.154563799s

• [SLOW TEST:10.372 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:49:51.248: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-919
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Dec 24 01:49:51.397: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 01:50:00.018: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:50:19.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-919" for this suite.
Dec 24 01:50:25.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:50:25.434: INFO: namespace crd-publish-openapi-919 deletion completed in 6.146371798s

• [SLOW TEST:34.186 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:50:25.435: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-5890
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec 24 01:50:33.642: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5890 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 24 01:50:33.642: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 01:50:33.776: INFO: Exec stderr: ""
Dec 24 01:50:33.776: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5890 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 24 01:50:33.776: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 01:50:33.929: INFO: Exec stderr: ""
Dec 24 01:50:33.929: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5890 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 24 01:50:33.929: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 01:50:34.085: INFO: Exec stderr: ""
Dec 24 01:50:34.085: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5890 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 24 01:50:34.085: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 01:50:34.231: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec 24 01:50:34.231: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5890 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 24 01:50:34.231: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 01:50:34.364: INFO: Exec stderr: ""
Dec 24 01:50:34.364: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5890 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 24 01:50:34.364: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 01:50:34.509: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec 24 01:50:34.509: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5890 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 24 01:50:34.509: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 01:50:34.696: INFO: Exec stderr: ""
Dec 24 01:50:34.696: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5890 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 24 01:50:34.696: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 01:50:34.872: INFO: Exec stderr: ""
Dec 24 01:50:34.872: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5890 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 24 01:50:34.872: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 01:50:35.041: INFO: Exec stderr: ""
Dec 24 01:50:35.041: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5890 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 24 01:50:35.041: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 01:50:35.236: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:50:35.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5890" for this suite.
Dec 24 01:51:21.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:51:21.398: INFO: namespace e2e-kubelet-etc-hosts-5890 deletion completed in 46.153534701s

• [SLOW TEST:55.963 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:51:21.398: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8712
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec 24 01:51:21.563: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8712 /api/v1/namespaces/watch-8712/configmaps/e2e-watch-test-configmap-a 39accf4e-8ef7-4e63-8641-6587315e93e7 122953 0 2019-12-24 01:51:21 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 24 01:51:21.564: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8712 /api/v1/namespaces/watch-8712/configmaps/e2e-watch-test-configmap-a 39accf4e-8ef7-4e63-8641-6587315e93e7 122953 0 2019-12-24 01:51:21 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec 24 01:51:31.575: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8712 /api/v1/namespaces/watch-8712/configmaps/e2e-watch-test-configmap-a 39accf4e-8ef7-4e63-8641-6587315e93e7 122982 0 2019-12-24 01:51:21 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 24 01:51:31.575: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8712 /api/v1/namespaces/watch-8712/configmaps/e2e-watch-test-configmap-a 39accf4e-8ef7-4e63-8641-6587315e93e7 122982 0 2019-12-24 01:51:21 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec 24 01:51:41.585: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8712 /api/v1/namespaces/watch-8712/configmaps/e2e-watch-test-configmap-a 39accf4e-8ef7-4e63-8641-6587315e93e7 123012 0 2019-12-24 01:51:21 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 24 01:51:41.585: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8712 /api/v1/namespaces/watch-8712/configmaps/e2e-watch-test-configmap-a 39accf4e-8ef7-4e63-8641-6587315e93e7 123012 0 2019-12-24 01:51:21 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec 24 01:51:51.597: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8712 /api/v1/namespaces/watch-8712/configmaps/e2e-watch-test-configmap-a 39accf4e-8ef7-4e63-8641-6587315e93e7 123039 0 2019-12-24 01:51:21 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 24 01:51:51.597: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8712 /api/v1/namespaces/watch-8712/configmaps/e2e-watch-test-configmap-a 39accf4e-8ef7-4e63-8641-6587315e93e7 123039 0 2019-12-24 01:51:21 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec 24 01:52:01.606: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8712 /api/v1/namespaces/watch-8712/configmaps/e2e-watch-test-configmap-b b0370807-eda0-4d10-8c46-2c576cddf1fe 123067 0 2019-12-24 01:52:01 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 24 01:52:01.607: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8712 /api/v1/namespaces/watch-8712/configmaps/e2e-watch-test-configmap-b b0370807-eda0-4d10-8c46-2c576cddf1fe 123067 0 2019-12-24 01:52:01 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec 24 01:52:11.617: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8712 /api/v1/namespaces/watch-8712/configmaps/e2e-watch-test-configmap-b b0370807-eda0-4d10-8c46-2c576cddf1fe 123097 0 2019-12-24 01:52:01 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 24 01:52:11.617: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8712 /api/v1/namespaces/watch-8712/configmaps/e2e-watch-test-configmap-b b0370807-eda0-4d10-8c46-2c576cddf1fe 123097 0 2019-12-24 01:52:01 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:52:21.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8712" for this suite.
Dec 24 01:52:27.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:52:27.811: INFO: namespace watch-8712 deletion completed in 6.178913016s

• [SLOW TEST:66.413 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:52:27.811: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-6961
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec 24 01:52:28.300: INFO: Pod name wrapped-volume-race-46bff233-18ad-426c-aca9-b161a3fe81f1: Found 0 pods out of 5
Dec 24 01:52:33.306: INFO: Pod name wrapped-volume-race-46bff233-18ad-426c-aca9-b161a3fe81f1: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-46bff233-18ad-426c-aca9-b161a3fe81f1 in namespace emptydir-wrapper-6961, will wait for the garbage collector to delete the pods
Dec 24 01:52:43.398: INFO: Deleting ReplicationController wrapped-volume-race-46bff233-18ad-426c-aca9-b161a3fe81f1 took: 11.063027ms
Dec 24 01:52:43.898: INFO: Terminating ReplicationController wrapped-volume-race-46bff233-18ad-426c-aca9-b161a3fe81f1 pods took: 500.268165ms
STEP: Creating RC which spawns configmap-volume pods
Dec 24 01:53:26.120: INFO: Pod name wrapped-volume-race-be9a64c4-75d1-4702-8f8c-688a40665e19: Found 0 pods out of 5
Dec 24 01:53:31.127: INFO: Pod name wrapped-volume-race-be9a64c4-75d1-4702-8f8c-688a40665e19: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-be9a64c4-75d1-4702-8f8c-688a40665e19 in namespace emptydir-wrapper-6961, will wait for the garbage collector to delete the pods
Dec 24 01:53:41.220: INFO: Deleting ReplicationController wrapped-volume-race-be9a64c4-75d1-4702-8f8c-688a40665e19 took: 10.09804ms
Dec 24 01:53:41.720: INFO: Terminating ReplicationController wrapped-volume-race-be9a64c4-75d1-4702-8f8c-688a40665e19 pods took: 500.295663ms
STEP: Creating RC which spawns configmap-volume pods
Dec 24 01:54:26.444: INFO: Pod name wrapped-volume-race-224db125-cc94-4275-ba65-23b8b044c5e6: Found 0 pods out of 5
Dec 24 01:54:31.451: INFO: Pod name wrapped-volume-race-224db125-cc94-4275-ba65-23b8b044c5e6: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-224db125-cc94-4275-ba65-23b8b044c5e6 in namespace emptydir-wrapper-6961, will wait for the garbage collector to delete the pods
Dec 24 01:54:43.550: INFO: Deleting ReplicationController wrapped-volume-race-224db125-cc94-4275-ba65-23b8b044c5e6 took: 11.743286ms
Dec 24 01:54:44.050: INFO: Terminating ReplicationController wrapped-volume-race-224db125-cc94-4275-ba65-23b8b044c5e6 pods took: 500.315146ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:55:27.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-6961" for this suite.
Dec 24 01:55:35.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:55:35.731: INFO: namespace emptydir-wrapper-6961 deletion completed in 8.141452241s

• [SLOW TEST:187.919 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:55:35.731: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9833
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 24 01:55:35.894: INFO: Waiting up to 5m0s for pod "downwardapi-volume-87ba6b5f-fbdc-499a-8dd3-1ca2cd832647" in namespace "downward-api-9833" to be "success or failure"
Dec 24 01:55:35.907: INFO: Pod "downwardapi-volume-87ba6b5f-fbdc-499a-8dd3-1ca2cd832647": Phase="Pending", Reason="", readiness=false. Elapsed: 12.740196ms
Dec 24 01:55:37.912: INFO: Pod "downwardapi-volume-87ba6b5f-fbdc-499a-8dd3-1ca2cd832647": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01771019s
Dec 24 01:55:39.917: INFO: Pod "downwardapi-volume-87ba6b5f-fbdc-499a-8dd3-1ca2cd832647": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022287584s
STEP: Saw pod success
Dec 24 01:55:39.917: INFO: Pod "downwardapi-volume-87ba6b5f-fbdc-499a-8dd3-1ca2cd832647" satisfied condition "success or failure"
Dec 24 01:55:39.921: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod downwardapi-volume-87ba6b5f-fbdc-499a-8dd3-1ca2cd832647 container client-container: <nil>
STEP: delete the pod
Dec 24 01:55:39.960: INFO: Waiting for pod downwardapi-volume-87ba6b5f-fbdc-499a-8dd3-1ca2cd832647 to disappear
Dec 24 01:55:39.970: INFO: Pod downwardapi-volume-87ba6b5f-fbdc-499a-8dd3-1ca2cd832647 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:55:39.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9833" for this suite.
Dec 24 01:55:46.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:55:46.122: INFO: namespace downward-api-9833 deletion completed in 6.138340317s

• [SLOW TEST:10.392 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:55:46.122: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1566
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 24 01:55:46.291: INFO: Waiting up to 5m0s for pod "downward-api-3c3725ac-fffe-4f50-ac71-e56ab3196d31" in namespace "downward-api-1566" to be "success or failure"
Dec 24 01:55:46.294: INFO: Pod "downward-api-3c3725ac-fffe-4f50-ac71-e56ab3196d31": Phase="Pending", Reason="", readiness=false. Elapsed: 3.635178ms
Dec 24 01:55:48.299: INFO: Pod "downward-api-3c3725ac-fffe-4f50-ac71-e56ab3196d31": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00807733s
Dec 24 01:55:50.303: INFO: Pod "downward-api-3c3725ac-fffe-4f50-ac71-e56ab3196d31": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011942865s
STEP: Saw pod success
Dec 24 01:55:50.303: INFO: Pod "downward-api-3c3725ac-fffe-4f50-ac71-e56ab3196d31" satisfied condition "success or failure"
Dec 24 01:55:50.306: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod downward-api-3c3725ac-fffe-4f50-ac71-e56ab3196d31 container dapi-container: <nil>
STEP: delete the pod
Dec 24 01:55:50.344: INFO: Waiting for pod downward-api-3c3725ac-fffe-4f50-ac71-e56ab3196d31 to disappear
Dec 24 01:55:50.349: INFO: Pod downward-api-3c3725ac-fffe-4f50-ac71-e56ab3196d31 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:55:50.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1566" for this suite.
Dec 24 01:55:56.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:55:56.497: INFO: namespace downward-api-1566 deletion completed in 6.140835814s

• [SLOW TEST:10.374 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:55:56.497: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2536
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 24 01:56:01.209: INFO: Successfully updated pod "annotationupdateeabf2f40-e210-4c37-acc5-63c1efd05406"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:56:03.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2536" for this suite.
Dec 24 01:56:31.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:56:31.388: INFO: namespace projected-2536 deletion completed in 28.144141813s

• [SLOW TEST:34.891 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:56:31.388: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9063
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 24 01:56:32.404: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 24 01:56:34.417: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712749392, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712749392, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712749392, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712749392, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 24 01:56:37.456: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:56:37.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9063" for this suite.
Dec 24 01:56:43.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:56:43.908: INFO: namespace webhook-9063 deletion completed in 6.158837383s
STEP: Destroying namespace "webhook-9063-markers" for this suite.
Dec 24 01:56:49.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:56:50.057: INFO: namespace webhook-9063-markers deletion completed in 6.148864221s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.689 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:56:50.077: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7985
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-7985
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-7985
I1224 01:56:50.279179      24 runners.go:184] Created replication controller with name: externalname-service, namespace: services-7985, replica count: 2
Dec 24 01:56:53.329: INFO: Creating new exec pod
I1224 01:56:53.329685      24 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 24 01:56:58.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=services-7985 execpodnc2g2 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec 24 01:56:59.360: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 24 01:56:59.360: INFO: stdout: ""
Dec 24 01:56:59.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=services-7985 execpodnc2g2 -- /bin/sh -x -c nc -zv -t -w 2 100.67.248.4 80'
Dec 24 01:56:59.618: INFO: stderr: "+ nc -zv -t -w 2 100.67.248.4 80\nConnection to 100.67.248.4 80 port [tcp/http] succeeded!\n"
Dec 24 01:56:59.618: INFO: stdout: ""
Dec 24 01:56:59.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=services-7985 execpodnc2g2 -- /bin/sh -x -c nc -zv -t -w 2 172.16.103.244 31669'
Dec 24 01:56:59.872: INFO: stderr: "+ nc -zv -t -w 2 172.16.103.244 31669\nConnection to 172.16.103.244 31669 port [tcp/31669] succeeded!\n"
Dec 24 01:56:59.872: INFO: stdout: ""
Dec 24 01:56:59.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=services-7985 execpodnc2g2 -- /bin/sh -x -c nc -zv -t -w 2 172.16.30.121 31669'
Dec 24 01:57:00.180: INFO: stderr: "+ nc -zv -t -w 2 172.16.30.121 31669\nConnection to 172.16.30.121 31669 port [tcp/31669] succeeded!\n"
Dec 24 01:57:00.180: INFO: stdout: ""
Dec 24 01:57:00.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=services-7985 execpodnc2g2 -- /bin/sh -x -c nc -zv -t -w 2 34.231.180.117 31669'
Dec 24 01:57:00.465: INFO: stderr: "+ nc -zv -t -w 2 34.231.180.117 31669\nConnection to 34.231.180.117 31669 port [tcp/31669] succeeded!\n"
Dec 24 01:57:00.465: INFO: stdout: ""
Dec 24 01:57:00.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=services-7985 execpodnc2g2 -- /bin/sh -x -c nc -zv -t -w 2 54.211.144.53 31669'
Dec 24 01:57:00.732: INFO: stderr: "+ nc -zv -t -w 2 54.211.144.53 31669\nConnection to 54.211.144.53 31669 port [tcp/31669] succeeded!\n"
Dec 24 01:57:00.732: INFO: stdout: ""
Dec 24 01:57:00.732: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:57:00.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7985" for this suite.
Dec 24 01:57:06.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:57:06.935: INFO: namespace services-7985 deletion completed in 6.152531722s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:16.858 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:57:06.935: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7710
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Dec 24 01:57:07.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 create -f - --namespace=kubectl-7710'
Dec 24 01:57:07.337: INFO: stderr: ""
Dec 24 01:57:07.337: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 24 01:57:07.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7710'
Dec 24 01:57:07.446: INFO: stderr: ""
Dec 24 01:57:07.446: INFO: stdout: "update-demo-nautilus-76d5t update-demo-nautilus-cspqc "
Dec 24 01:57:07.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-nautilus-76d5t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7710'
Dec 24 01:57:07.535: INFO: stderr: ""
Dec 24 01:57:07.535: INFO: stdout: ""
Dec 24 01:57:07.535: INFO: update-demo-nautilus-76d5t is created but not running
Dec 24 01:57:12.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7710'
Dec 24 01:57:12.606: INFO: stderr: ""
Dec 24 01:57:12.606: INFO: stdout: "update-demo-nautilus-76d5t update-demo-nautilus-cspqc "
Dec 24 01:57:12.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-nautilus-76d5t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7710'
Dec 24 01:57:12.681: INFO: stderr: ""
Dec 24 01:57:12.681: INFO: stdout: "true"
Dec 24 01:57:12.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-nautilus-76d5t -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7710'
Dec 24 01:57:12.753: INFO: stderr: ""
Dec 24 01:57:12.753: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 24 01:57:12.753: INFO: validating pod update-demo-nautilus-76d5t
Dec 24 01:57:12.760: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 24 01:57:12.760: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 24 01:57:12.760: INFO: update-demo-nautilus-76d5t is verified up and running
Dec 24 01:57:12.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-nautilus-cspqc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7710'
Dec 24 01:57:12.847: INFO: stderr: ""
Dec 24 01:57:12.847: INFO: stdout: "true"
Dec 24 01:57:12.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-nautilus-cspqc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7710'
Dec 24 01:57:12.922: INFO: stderr: ""
Dec 24 01:57:12.922: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 24 01:57:12.922: INFO: validating pod update-demo-nautilus-cspqc
Dec 24 01:57:12.928: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 24 01:57:12.928: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 24 01:57:12.928: INFO: update-demo-nautilus-cspqc is verified up and running
STEP: rolling-update to new replication controller
Dec 24 01:57:12.929: INFO: scanned /root for discovery docs: <nil>
Dec 24 01:57:12.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-7710'
Dec 24 01:57:35.356: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 24 01:57:35.356: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 24 01:57:35.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7710'
Dec 24 01:57:35.476: INFO: stderr: ""
Dec 24 01:57:35.476: INFO: stdout: "update-demo-kitten-kql82 update-demo-kitten-tlvwx "
Dec 24 01:57:35.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-kitten-kql82 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7710'
Dec 24 01:57:35.579: INFO: stderr: ""
Dec 24 01:57:35.579: INFO: stdout: "true"
Dec 24 01:57:35.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-kitten-kql82 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7710'
Dec 24 01:57:35.669: INFO: stderr: ""
Dec 24 01:57:35.669: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 24 01:57:35.669: INFO: validating pod update-demo-kitten-kql82
Dec 24 01:57:35.676: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 24 01:57:35.676: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 24 01:57:35.676: INFO: update-demo-kitten-kql82 is verified up and running
Dec 24 01:57:35.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-kitten-tlvwx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7710'
Dec 24 01:57:35.761: INFO: stderr: ""
Dec 24 01:57:35.761: INFO: stdout: "true"
Dec 24 01:57:35.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-kitten-tlvwx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7710'
Dec 24 01:57:35.839: INFO: stderr: ""
Dec 24 01:57:35.839: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 24 01:57:35.839: INFO: validating pod update-demo-kitten-tlvwx
Dec 24 01:57:35.848: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 24 01:57:35.848: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 24 01:57:35.848: INFO: update-demo-kitten-tlvwx is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:57:35.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7710" for this suite.
Dec 24 01:57:47.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:57:47.999: INFO: namespace kubectl-7710 deletion completed in 12.143790608s

• [SLOW TEST:41.063 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:57:47.999: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6237
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 24 01:57:48.194: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:48.194: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:48.194: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:48.199: INFO: Number of nodes with available pods: 0
Dec 24 01:57:48.199: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:57:49.206: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:49.206: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:49.206: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:49.210: INFO: Number of nodes with available pods: 0
Dec 24 01:57:49.210: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:57:50.210: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:50.210: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:50.210: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:50.214: INFO: Number of nodes with available pods: 0
Dec 24 01:57:50.215: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:57:51.206: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:51.206: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:51.206: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:51.210: INFO: Number of nodes with available pods: 3
Dec 24 01:57:51.210: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec 24 01:57:51.235: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:51.235: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:51.235: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:51.245: INFO: Number of nodes with available pods: 2
Dec 24 01:57:51.245: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:57:52.268: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:52.268: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:52.268: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:52.272: INFO: Number of nodes with available pods: 2
Dec 24 01:57:52.272: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:57:53.254: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:53.254: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:53.254: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:53.261: INFO: Number of nodes with available pods: 2
Dec 24 01:57:53.261: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 01:57:54.251: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:54.252: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:54.252: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 01:57:54.255: INFO: Number of nodes with available pods: 3
Dec 24 01:57:54.256: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6237, will wait for the garbage collector to delete the pods
Dec 24 01:57:54.329: INFO: Deleting DaemonSet.extensions daemon-set took: 10.76398ms
Dec 24 01:57:54.729: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.182768ms
Dec 24 01:58:06.035: INFO: Number of nodes with available pods: 0
Dec 24 01:58:06.035: INFO: Number of running nodes: 0, number of available pods: 0
Dec 24 01:58:06.039: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6237/daemonsets","resourceVersion":"125412"},"items":null}

Dec 24 01:58:06.045: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6237/pods","resourceVersion":"125412"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:58:06.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6237" for this suite.
Dec 24 01:58:12.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:58:12.280: INFO: namespace daemonsets-6237 deletion completed in 6.20919247s

• [SLOW TEST:24.281 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:58:12.280: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-9932
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 01:58:12.459: INFO: (0) /api/v1/nodes/ip-172-16-103-244.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 17.856892ms)
Dec 24 01:58:12.464: INFO: (1) /api/v1/nodes/ip-172-16-103-244.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.850416ms)
Dec 24 01:58:12.469: INFO: (2) /api/v1/nodes/ip-172-16-103-244.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.956591ms)
Dec 24 01:58:12.475: INFO: (3) /api/v1/nodes/ip-172-16-103-244.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 6.261445ms)
Dec 24 01:58:12.480: INFO: (4) /api/v1/nodes/ip-172-16-103-244.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.669327ms)
Dec 24 01:58:12.486: INFO: (5) /api/v1/nodes/ip-172-16-103-244.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.464433ms)
Dec 24 01:58:12.492: INFO: (6) /api/v1/nodes/ip-172-16-103-244.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.860854ms)
Dec 24 01:58:12.498: INFO: (7) /api/v1/nodes/ip-172-16-103-244.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 6.691301ms)
Dec 24 01:58:12.504: INFO: (8) /api/v1/nodes/ip-172-16-103-244.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.60691ms)
Dec 24 01:58:12.514: INFO: (9) /api/v1/nodes/ip-172-16-103-244.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.819649ms)
Dec 24 01:58:12.519: INFO: (10) /api/v1/nodes/ip-172-16-103-244.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.582144ms)
Dec 24 01:58:12.524: INFO: (11) /api/v1/nodes/ip-172-16-103-244.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.083598ms)
Dec 24 01:58:12.534: INFO: (12) /api/v1/nodes/ip-172-16-103-244.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 10.606918ms)
Dec 24 01:58:12.540: INFO: (13) /api/v1/nodes/ip-172-16-103-244.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.372707ms)
Dec 24 01:58:12.545: INFO: (14) /api/v1/nodes/ip-172-16-103-244.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.939812ms)
Dec 24 01:58:12.551: INFO: (15) /api/v1/nodes/ip-172-16-103-244.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.688584ms)
Dec 24 01:58:12.556: INFO: (16) /api/v1/nodes/ip-172-16-103-244.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.634118ms)
Dec 24 01:58:12.566: INFO: (17) /api/v1/nodes/ip-172-16-103-244.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.359247ms)
Dec 24 01:58:12.573: INFO: (18) /api/v1/nodes/ip-172-16-103-244.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 6.125303ms)
Dec 24 01:58:12.578: INFO: (19) /api/v1/nodes/ip-172-16-103-244.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.956582ms)
[AfterEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:58:12.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9932" for this suite.
Dec 24 01:58:18.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:58:18.743: INFO: namespace proxy-9932 deletion completed in 6.147109745s

• [SLOW TEST:6.462 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:58:18.743: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3451
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Dec 24 01:58:18.905: INFO: Waiting up to 5m0s for pod "client-containers-79ef5cfc-8cf2-48ff-a230-51995c491532" in namespace "containers-3451" to be "success or failure"
Dec 24 01:58:18.913: INFO: Pod "client-containers-79ef5cfc-8cf2-48ff-a230-51995c491532": Phase="Pending", Reason="", readiness=false. Elapsed: 7.838171ms
Dec 24 01:58:20.917: INFO: Pod "client-containers-79ef5cfc-8cf2-48ff-a230-51995c491532": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012180545s
Dec 24 01:58:22.922: INFO: Pod "client-containers-79ef5cfc-8cf2-48ff-a230-51995c491532": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01691146s
STEP: Saw pod success
Dec 24 01:58:22.922: INFO: Pod "client-containers-79ef5cfc-8cf2-48ff-a230-51995c491532" satisfied condition "success or failure"
Dec 24 01:58:22.927: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod client-containers-79ef5cfc-8cf2-48ff-a230-51995c491532 container test-container: <nil>
STEP: delete the pod
Dec 24 01:58:22.960: INFO: Waiting for pod client-containers-79ef5cfc-8cf2-48ff-a230-51995c491532 to disappear
Dec 24 01:58:22.969: INFO: Pod client-containers-79ef5cfc-8cf2-48ff-a230-51995c491532 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:58:22.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3451" for this suite.
Dec 24 01:58:28.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:58:29.125: INFO: namespace containers-3451 deletion completed in 6.146763331s

• [SLOW TEST:10.382 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:58:29.125: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2937
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 24 01:58:29.292: INFO: Waiting up to 5m0s for pod "pod-bacf204c-e51d-44bd-810d-4d1143bd51f3" in namespace "emptydir-2937" to be "success or failure"
Dec 24 01:58:29.296: INFO: Pod "pod-bacf204c-e51d-44bd-810d-4d1143bd51f3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.130673ms
Dec 24 01:58:31.302: INFO: Pod "pod-bacf204c-e51d-44bd-810d-4d1143bd51f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009434859s
Dec 24 01:58:33.306: INFO: Pod "pod-bacf204c-e51d-44bd-810d-4d1143bd51f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013984186s
STEP: Saw pod success
Dec 24 01:58:33.306: INFO: Pod "pod-bacf204c-e51d-44bd-810d-4d1143bd51f3" satisfied condition "success or failure"
Dec 24 01:58:33.310: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-bacf204c-e51d-44bd-810d-4d1143bd51f3 container test-container: <nil>
STEP: delete the pod
Dec 24 01:58:33.348: INFO: Waiting for pod pod-bacf204c-e51d-44bd-810d-4d1143bd51f3 to disappear
Dec 24 01:58:33.352: INFO: Pod pod-bacf204c-e51d-44bd-810d-4d1143bd51f3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:58:33.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2937" for this suite.
Dec 24 01:58:39.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:58:39.585: INFO: namespace emptydir-2937 deletion completed in 6.225227518s

• [SLOW TEST:10.460 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:58:39.585: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-7677
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 01:58:39.751: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Creating first CR 
Dec 24 01:58:44.884: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-24T01:58:44Z generation:1 name:name1 resourceVersion:125635 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:442bf2bc-4061-4811-aacf-7323ef53de29] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Dec 24 01:58:54.891: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-24T01:58:54Z generation:1 name:name2 resourceVersion:125660 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:5fd55403-6822-4e54-bd1a-2aef726d1683] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Dec 24 01:59:04.898: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-24T01:58:44Z generation:2 name:name1 resourceVersion:125689 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:442bf2bc-4061-4811-aacf-7323ef53de29] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Dec 24 01:59:14.905: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-24T01:58:54Z generation:2 name:name2 resourceVersion:125719 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:5fd55403-6822-4e54-bd1a-2aef726d1683] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Dec 24 01:59:24.916: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-24T01:58:44Z generation:2 name:name1 resourceVersion:125745 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:442bf2bc-4061-4811-aacf-7323ef53de29] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Dec 24 01:59:34.928: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-24T01:58:54Z generation:2 name:name2 resourceVersion:125774 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:5fd55403-6822-4e54-bd1a-2aef726d1683] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:59:45.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-7677" for this suite.
Dec 24 01:59:51.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 01:59:51.604: INFO: namespace crd-watch-7677 deletion completed in 6.153798403s

• [SLOW TEST:72.019 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 01:59:51.604: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-457
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Dec 24 01:59:51.766: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-457" to be "success or failure"
Dec 24 01:59:51.776: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 10.128128ms
Dec 24 01:59:53.781: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014583006s
Dec 24 01:59:55.786: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019462687s
STEP: Saw pod success
Dec 24 01:59:55.786: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec 24 01:59:55.790: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec 24 01:59:55.824: INFO: Waiting for pod pod-host-path-test to disappear
Dec 24 01:59:55.829: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 01:59:55.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-457" for this suite.
Dec 24 02:00:01.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:00:01.998: INFO: namespace hostpath-457 deletion completed in 6.16254405s

• [SLOW TEST:10.394 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:00:01.998: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3655
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-01391f3f-ec0a-4367-9270-337bcdada6e6
STEP: Creating secret with name s-test-opt-upd-ac4d3e63-4b2d-495e-9549-eccaf27e9c93
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-01391f3f-ec0a-4367-9270-337bcdada6e6
STEP: Updating secret s-test-opt-upd-ac4d3e63-4b2d-495e-9549-eccaf27e9c93
STEP: Creating secret with name s-test-opt-create-1fcd32f1-0baa-4325-b674-4099a3d33d5b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:00:10.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3655" for this suite.
Dec 24 02:00:22.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:00:22.483: INFO: namespace projected-3655 deletion completed in 12.165712309s

• [SLOW TEST:20.485 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:00:22.483: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4437
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 02:00:22.660: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec 24 02:00:22.669: INFO: Number of nodes with available pods: 0
Dec 24 02:00:22.669: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec 24 02:00:22.694: INFO: Number of nodes with available pods: 0
Dec 24 02:00:22.694: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 02:00:23.699: INFO: Number of nodes with available pods: 0
Dec 24 02:00:23.699: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 02:00:24.699: INFO: Number of nodes with available pods: 0
Dec 24 02:00:24.699: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 02:00:25.699: INFO: Number of nodes with available pods: 1
Dec 24 02:00:25.699: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec 24 02:00:25.722: INFO: Number of nodes with available pods: 1
Dec 24 02:00:25.722: INFO: Number of running nodes: 0, number of available pods: 1
Dec 24 02:00:26.727: INFO: Number of nodes with available pods: 0
Dec 24 02:00:26.727: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec 24 02:00:26.742: INFO: Number of nodes with available pods: 0
Dec 24 02:00:26.742: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 02:00:27.747: INFO: Number of nodes with available pods: 0
Dec 24 02:00:27.747: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 02:00:28.747: INFO: Number of nodes with available pods: 0
Dec 24 02:00:28.747: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 02:00:29.748: INFO: Number of nodes with available pods: 0
Dec 24 02:00:29.748: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 02:00:30.746: INFO: Number of nodes with available pods: 0
Dec 24 02:00:30.746: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 02:00:31.747: INFO: Number of nodes with available pods: 1
Dec 24 02:00:31.747: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4437, will wait for the garbage collector to delete the pods
Dec 24 02:00:31.819: INFO: Deleting DaemonSet.extensions daemon-set took: 9.915541ms
Dec 24 02:00:32.219: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.308341ms
Dec 24 02:00:46.024: INFO: Number of nodes with available pods: 0
Dec 24 02:00:46.024: INFO: Number of running nodes: 0, number of available pods: 0
Dec 24 02:00:46.027: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4437/daemonsets","resourceVersion":"126113"},"items":null}

Dec 24 02:00:46.032: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4437/pods","resourceVersion":"126113"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:00:46.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4437" for this suite.
Dec 24 02:00:52.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:00:52.214: INFO: namespace daemonsets-4437 deletion completed in 6.148438141s

• [SLOW TEST:29.730 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:00:52.214: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8415
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8415.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8415.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8415.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8415.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8415.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8415.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 24 02:00:56.486: INFO: DNS probes using dns-8415/dns-test-3879666b-98be-4015-9058-357c906e2521 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:00:56.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8415" for this suite.
Dec 24 02:01:02.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:01:02.660: INFO: namespace dns-8415 deletion completed in 6.147834571s

• [SLOW TEST:10.446 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:01:02.660: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2529
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 02:01:02.846: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"bb678834-dd25-4521-abeb-78d3c7a3f48d", Controller:(*bool)(0xc008745a6a), BlockOwnerDeletion:(*bool)(0xc008745a6b)}}
Dec 24 02:01:02.863: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"3de7b8eb-8d83-4c70-bb5a-43d086e9ca92", Controller:(*bool)(0xc0087a9f72), BlockOwnerDeletion:(*bool)(0xc0087a9f73)}}
Dec 24 02:01:02.880: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"a16291da-1d3b-4472-80da-a7f65962b2b9", Controller:(*bool)(0xc00685fda2), BlockOwnerDeletion:(*bool)(0xc00685fda3)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:01:07.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2529" for this suite.
Dec 24 02:01:13.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:01:14.044: INFO: namespace gc-2529 deletion completed in 6.141812389s

• [SLOW TEST:11.384 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:01:14.045: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-136
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-453070f7-04e7-4f56-8dc4-53bb03490406
STEP: Creating a pod to test consume configMaps
Dec 24 02:01:14.210: INFO: Waiting up to 5m0s for pod "pod-configmaps-7855e9d2-a501-469d-9a1c-d895a1e746e9" in namespace "configmap-136" to be "success or failure"
Dec 24 02:01:14.215: INFO: Pod "pod-configmaps-7855e9d2-a501-469d-9a1c-d895a1e746e9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.07012ms
Dec 24 02:01:16.220: INFO: Pod "pod-configmaps-7855e9d2-a501-469d-9a1c-d895a1e746e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009676346s
Dec 24 02:01:18.226: INFO: Pod "pod-configmaps-7855e9d2-a501-469d-9a1c-d895a1e746e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015410782s
STEP: Saw pod success
Dec 24 02:01:18.226: INFO: Pod "pod-configmaps-7855e9d2-a501-469d-9a1c-d895a1e746e9" satisfied condition "success or failure"
Dec 24 02:01:18.229: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-configmaps-7855e9d2-a501-469d-9a1c-d895a1e746e9 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 24 02:01:18.259: INFO: Waiting for pod pod-configmaps-7855e9d2-a501-469d-9a1c-d895a1e746e9 to disappear
Dec 24 02:01:18.264: INFO: Pod pod-configmaps-7855e9d2-a501-469d-9a1c-d895a1e746e9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:01:18.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-136" for this suite.
Dec 24 02:01:24.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:01:24.413: INFO: namespace configmap-136 deletion completed in 6.143913692s

• [SLOW TEST:10.369 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:01:24.413: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8375
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 24 02:01:24.577: INFO: Waiting up to 5m0s for pod "downward-api-e9115b92-4f80-4875-968a-025caa201f3b" in namespace "downward-api-8375" to be "success or failure"
Dec 24 02:01:24.583: INFO: Pod "downward-api-e9115b92-4f80-4875-968a-025caa201f3b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.054779ms
Dec 24 02:01:26.587: INFO: Pod "downward-api-e9115b92-4f80-4875-968a-025caa201f3b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010744002s
Dec 24 02:01:28.592: INFO: Pod "downward-api-e9115b92-4f80-4875-968a-025caa201f3b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015799195s
STEP: Saw pod success
Dec 24 02:01:28.592: INFO: Pod "downward-api-e9115b92-4f80-4875-968a-025caa201f3b" satisfied condition "success or failure"
Dec 24 02:01:28.598: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod downward-api-e9115b92-4f80-4875-968a-025caa201f3b container dapi-container: <nil>
STEP: delete the pod
Dec 24 02:01:28.625: INFO: Waiting for pod downward-api-e9115b92-4f80-4875-968a-025caa201f3b to disappear
Dec 24 02:01:28.629: INFO: Pod downward-api-e9115b92-4f80-4875-968a-025caa201f3b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:01:28.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8375" for this suite.
Dec 24 02:01:34.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:01:34.781: INFO: namespace downward-api-8375 deletion completed in 6.143381094s

• [SLOW TEST:10.367 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:01:34.782: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5121
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Dec 24 02:01:34.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 cluster-info'
Dec 24 02:01:35.109: INFO: stderr: ""
Dec 24 02:01:35.109: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443\x1b[0m\n\x1b[0;32mheapster\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mmetrics-server\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:01:35.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5121" for this suite.
Dec 24 02:01:41.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:01:41.325: INFO: namespace kubectl-5121 deletion completed in 6.196474287s

• [SLOW TEST:6.544 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:01:41.326: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3069
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Dec 24 02:01:41.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 create -f - --namespace=kubectl-3069'
Dec 24 02:01:41.759: INFO: stderr: ""
Dec 24 02:01:41.759: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 24 02:01:42.764: INFO: Selector matched 1 pods for map[app:redis]
Dec 24 02:01:42.764: INFO: Found 0 / 1
Dec 24 02:01:43.764: INFO: Selector matched 1 pods for map[app:redis]
Dec 24 02:01:43.764: INFO: Found 0 / 1
Dec 24 02:01:44.764: INFO: Selector matched 1 pods for map[app:redis]
Dec 24 02:01:44.764: INFO: Found 1 / 1
Dec 24 02:01:44.764: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec 24 02:01:44.769: INFO: Selector matched 1 pods for map[app:redis]
Dec 24 02:01:44.769: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 24 02:01:44.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 patch pod redis-master-dtd4s --namespace=kubectl-3069 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec 24 02:01:44.857: INFO: stderr: ""
Dec 24 02:01:44.857: INFO: stdout: "pod/redis-master-dtd4s patched\n"
STEP: checking annotations
Dec 24 02:01:44.862: INFO: Selector matched 1 pods for map[app:redis]
Dec 24 02:01:44.862: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:01:44.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3069" for this suite.
Dec 24 02:01:56.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:01:57.006: INFO: namespace kubectl-3069 deletion completed in 12.138267955s

• [SLOW TEST:15.680 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:01:57.007: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-2448
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-2448, will wait for the garbage collector to delete the pods
Dec 24 02:02:01.231: INFO: Deleting Job.batch foo took: 10.48585ms
Dec 24 02:02:01.332: INFO: Terminating Job.batch foo pods took: 100.260152ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:02:45.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2448" for this suite.
Dec 24 02:02:51.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:02:51.387: INFO: namespace job-2448 deletion completed in 6.143777102s

• [SLOW TEST:54.380 seconds]
[sig-apps] Job
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:02:51.387: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5165
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Dec 24 02:02:51.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 create -f - --namespace=kubectl-5165'
Dec 24 02:02:51.701: INFO: stderr: ""
Dec 24 02:02:51.701: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 24 02:02:51.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5165'
Dec 24 02:02:51.782: INFO: stderr: ""
Dec 24 02:02:51.782: INFO: stdout: "update-demo-nautilus-hvxdz update-demo-nautilus-jhpz6 "
Dec 24 02:02:51.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-nautilus-hvxdz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5165'
Dec 24 02:02:51.851: INFO: stderr: ""
Dec 24 02:02:51.851: INFO: stdout: ""
Dec 24 02:02:51.851: INFO: update-demo-nautilus-hvxdz is created but not running
Dec 24 02:02:56.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5165'
Dec 24 02:02:56.935: INFO: stderr: ""
Dec 24 02:02:56.935: INFO: stdout: "update-demo-nautilus-hvxdz update-demo-nautilus-jhpz6 "
Dec 24 02:02:56.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-nautilus-hvxdz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5165'
Dec 24 02:02:57.013: INFO: stderr: ""
Dec 24 02:02:57.014: INFO: stdout: "true"
Dec 24 02:02:57.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-nautilus-hvxdz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5165'
Dec 24 02:02:57.089: INFO: stderr: ""
Dec 24 02:02:57.089: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 24 02:02:57.089: INFO: validating pod update-demo-nautilus-hvxdz
Dec 24 02:02:57.095: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 24 02:02:57.095: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 24 02:02:57.095: INFO: update-demo-nautilus-hvxdz is verified up and running
Dec 24 02:02:57.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-nautilus-jhpz6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5165'
Dec 24 02:02:57.165: INFO: stderr: ""
Dec 24 02:02:57.165: INFO: stdout: "true"
Dec 24 02:02:57.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-nautilus-jhpz6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5165'
Dec 24 02:02:57.268: INFO: stderr: ""
Dec 24 02:02:57.268: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 24 02:02:57.268: INFO: validating pod update-demo-nautilus-jhpz6
Dec 24 02:02:57.276: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 24 02:02:57.276: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 24 02:02:57.276: INFO: update-demo-nautilus-jhpz6 is verified up and running
STEP: using delete to clean up resources
Dec 24 02:02:57.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 delete --grace-period=0 --force -f - --namespace=kubectl-5165'
Dec 24 02:02:57.352: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 24 02:02:57.352: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 24 02:02:57.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5165'
Dec 24 02:02:57.434: INFO: stderr: "No resources found in kubectl-5165 namespace.\n"
Dec 24 02:02:57.434: INFO: stdout: ""
Dec 24 02:02:57.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods -l name=update-demo --namespace=kubectl-5165 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 24 02:02:57.518: INFO: stderr: ""
Dec 24 02:02:57.518: INFO: stdout: "update-demo-nautilus-hvxdz\nupdate-demo-nautilus-jhpz6\n"
Dec 24 02:02:58.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5165'
Dec 24 02:02:58.139: INFO: stderr: "No resources found in kubectl-5165 namespace.\n"
Dec 24 02:02:58.139: INFO: stdout: ""
Dec 24 02:02:58.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods -l name=update-demo --namespace=kubectl-5165 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 24 02:02:58.259: INFO: stderr: ""
Dec 24 02:02:58.259: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:02:58.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5165" for this suite.
Dec 24 02:03:04.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:03:04.408: INFO: namespace kubectl-5165 deletion completed in 6.141525385s

• [SLOW TEST:13.021 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:03:04.408: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2855
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 02:03:28.589: INFO: Container started at 2019-12-24 02:03:06 +0000 UTC, pod became ready at 2019-12-24 02:03:28 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:03:28.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2855" for this suite.
Dec 24 02:03:56.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:03:56.745: INFO: namespace container-probe-2855 deletion completed in 28.150723737s

• [SLOW TEST:52.337 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:03:56.746: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1442
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 02:03:56.909: INFO: Creating deployment "webserver-deployment"
Dec 24 02:03:56.916: INFO: Waiting for observed generation 1
Dec 24 02:03:58.926: INFO: Waiting for all required pods to come up
Dec 24 02:03:58.938: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec 24 02:04:00.959: INFO: Waiting for deployment "webserver-deployment" to complete
Dec 24 02:04:01.020: INFO: Updating deployment "webserver-deployment" with a non-existent image
Dec 24 02:04:01.033: INFO: Updating deployment webserver-deployment
Dec 24 02:04:01.033: INFO: Waiting for observed generation 2
Dec 24 02:04:03.047: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec 24 02:04:03.052: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec 24 02:04:03.056: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 24 02:04:03.068: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec 24 02:04:03.068: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec 24 02:04:03.072: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 24 02:04:03.084: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Dec 24 02:04:03.084: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Dec 24 02:04:03.093: INFO: Updating deployment webserver-deployment
Dec 24 02:04:03.093: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Dec 24 02:04:03.103: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec 24 02:04:03.118: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 24 02:04:03.159: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-1442 /apis/apps/v1/namespaces/deployment-1442/deployments/webserver-deployment b00ca945-4d77-4416-bd2a-5bf432d1d792 127234 3 2019-12-24 02:03:56 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00423ac18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2019-12-24 02:04:01 +0000 UTC,LastTransitionTime:2019-12-24 02:03:56 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-12-24 02:04:03 +0000 UTC,LastTransitionTime:2019-12-24 02:04:03 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Dec 24 02:04:03.198: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-1442 /apis/apps/v1/namespaces/deployment-1442/replicasets/webserver-deployment-c7997dcc8 5c29a0ea-e624-4eb4-9bff-52d082df84e9 127226 3 2019-12-24 02:04:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment b00ca945-4d77-4416-bd2a-5bf432d1d792 0xc0058c4bc7 0xc0058c4bc8}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0058c4c38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 24 02:04:03.198: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Dec 24 02:04:03.198: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-1442 /apis/apps/v1/namespaces/deployment-1442/replicasets/webserver-deployment-595b5b9587 5a233585-3059-4758-8c02-cfc9d2fd840d 127225 3 2019-12-24 02:03:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment b00ca945-4d77-4416-bd2a-5bf432d1d792 0xc0058c4b07 0xc0058c4b08}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0058c4b68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Dec 24 02:04:03.222: INFO: Pod "webserver-deployment-595b5b9587-287px" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-287px webserver-deployment-595b5b9587- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-595b5b9587-287px 9047cb7c-6fac-4008-9987-e58fcd58951f 127255 0 2019-12-24 02:04:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 5a233585-3059-4758-8c02-cfc9d2fd840d 0xc00423b037 0xc00423b038}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-103-244.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.222: INFO: Pod "webserver-deployment-595b5b9587-64tx8" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-64tx8 webserver-deployment-595b5b9587- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-595b5b9587-64tx8 61485d0a-7826-4ab4-a000-92f6df2aae0d 127260 0 2019-12-24 02:04:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 5a233585-3059-4758-8c02-cfc9d2fd840d 0xc00423b140 0xc00423b141}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-44-108.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.16.44.108,PodIP:,StartTime:2019-12-24 02:04:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.222: INFO: Pod "webserver-deployment-595b5b9587-7jv2z" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-7jv2z webserver-deployment-595b5b9587- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-595b5b9587-7jv2z a043780e-46a5-4ec2-a7da-67ad054c6906 127123 0 2019-12-24 02:03:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.96.4.142/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 5a233585-3059-4758-8c02-cfc9d2fd840d 0xc00423b297 0xc00423b298}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-30-121.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.16.30.121,PodIP:100.96.4.142,StartTime:2019-12-24 02:03:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-24 02:03:59 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://2129fff89ce5e66ac20f4bb45184976d414f063af2223d7862689aaac32e3e9f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.4.142,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.223: INFO: Pod "webserver-deployment-595b5b9587-9v5wx" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-9v5wx webserver-deployment-595b5b9587- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-595b5b9587-9v5wx 3b50e85b-0ff2-4f41-859b-b0aee78c0610 127108 0 2019-12-24 02:03:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.96.5.111/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 5a233585-3059-4758-8c02-cfc9d2fd840d 0xc00423b417 0xc00423b418}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-103-244.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.16.103.244,PodIP:100.96.5.111,StartTime:2019-12-24 02:03:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-24 02:03:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://8c4e42442baa56fcc2550bd3f290f687b8e9d65cdef616ec3aefb0139862d807,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.5.111,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.223: INFO: Pod "webserver-deployment-595b5b9587-b9sfc" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-b9sfc webserver-deployment-595b5b9587- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-595b5b9587-b9sfc e2962a65-5a5a-474a-8013-798f8f654a32 127258 0 2019-12-24 02:04:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 5a233585-3059-4758-8c02-cfc9d2fd840d 0xc00423b587 0xc00423b588}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-30-121.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.223: INFO: Pod "webserver-deployment-595b5b9587-bzqwq" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-bzqwq webserver-deployment-595b5b9587- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-595b5b9587-bzqwq e5a80385-b97c-4c8b-889d-8190d6d73518 127238 0 2019-12-24 02:04:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 5a233585-3059-4758-8c02-cfc9d2fd840d 0xc00423b690 0xc00423b691}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-44-108.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.223: INFO: Pod "webserver-deployment-595b5b9587-cqhn9" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-cqhn9 webserver-deployment-595b5b9587- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-595b5b9587-cqhn9 06cfa746-2c86-453a-a07b-64d098e7c900 127243 0 2019-12-24 02:04:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 5a233585-3059-4758-8c02-cfc9d2fd840d 0xc00423b790 0xc00423b791}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-44-108.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.223: INFO: Pod "webserver-deployment-595b5b9587-jnln2" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-jnln2 webserver-deployment-595b5b9587- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-595b5b9587-jnln2 2a8244bc-6c7c-42e0-b6d9-a978d231c9e3 127114 0 2019-12-24 02:03:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.96.5.113/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 5a233585-3059-4758-8c02-cfc9d2fd840d 0xc00423b8a0 0xc00423b8a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-103-244.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.16.103.244,PodIP:100.96.5.113,StartTime:2019-12-24 02:03:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-24 02:03:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://4bcbaeca8e0d8c272e9b884a2ee7c5ec3a96f4408cf2d19bdcc0de83a0519a7f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.5.113,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.223: INFO: Pod "webserver-deployment-595b5b9587-l2mtm" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-l2mtm webserver-deployment-595b5b9587- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-595b5b9587-l2mtm cccdd794-6559-4d8b-921d-e8ceb9f998f6 127111 0 2019-12-24 02:03:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.96.5.112/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 5a233585-3059-4758-8c02-cfc9d2fd840d 0xc00423ba17 0xc00423ba18}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-103-244.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.16.103.244,PodIP:100.96.5.112,StartTime:2019-12-24 02:03:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-24 02:03:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://b28b618f4281004dd28d8f2e3ad48c0482e93c5a76de19d1eeffd50926de6be5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.5.112,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.224: INFO: Pod "webserver-deployment-595b5b9587-ldrdz" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-ldrdz webserver-deployment-595b5b9587- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-595b5b9587-ldrdz 2eaa4a3c-257b-4e26-b9dd-d00a594ac5b5 127126 0 2019-12-24 02:03:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.96.4.140/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 5a233585-3059-4758-8c02-cfc9d2fd840d 0xc00423bb97 0xc00423bb98}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-30-121.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.16.30.121,PodIP:100.96.4.140,StartTime:2019-12-24 02:03:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-24 02:03:59 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://23683036f815f38a0d4e226654a2e2df2df41266dd899863dd0b8582ef09cff1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.4.140,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.224: INFO: Pod "webserver-deployment-595b5b9587-mhlnz" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mhlnz webserver-deployment-595b5b9587- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-595b5b9587-mhlnz 77b0c2bb-9f85-49b0-b7fb-15ef878a84ee 127253 0 2019-12-24 02:04:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 5a233585-3059-4758-8c02-cfc9d2fd840d 0xc00423bd07 0xc00423bd08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-103-244.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.224: INFO: Pod "webserver-deployment-595b5b9587-mr9s6" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mr9s6 webserver-deployment-595b5b9587- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-595b5b9587-mr9s6 ddb4f70a-9d1a-46b3-a5d6-d7578a445978 127263 0 2019-12-24 02:04:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 5a233585-3059-4758-8c02-cfc9d2fd840d 0xc00423be20 0xc00423be21}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-44-108.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.224: INFO: Pod "webserver-deployment-595b5b9587-mvp8r" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mvp8r webserver-deployment-595b5b9587- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-595b5b9587-mvp8r 7bbc0c9b-fa26-4b1b-89d0-4a12741529f4 127130 0 2019-12-24 02:03:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.96.3.128/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 5a233585-3059-4758-8c02-cfc9d2fd840d 0xc00423bf30 0xc00423bf31}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-44-108.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.16.44.108,PodIP:100.96.3.128,StartTime:2019-12-24 02:03:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-24 02:03:59 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://b2adae2f522b115ed0ae57eafa679a37bc7d689d17d6693ac87b4ea93076e91c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.3.128,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.224: INFO: Pod "webserver-deployment-595b5b9587-qxwhh" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-qxwhh webserver-deployment-595b5b9587- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-595b5b9587-qxwhh 799dc3d1-5f83-4314-ba7a-934b3285ba9a 127117 0 2019-12-24 02:03:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.96.4.139/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 5a233585-3059-4758-8c02-cfc9d2fd840d 0xc002e360a7 0xc002e360a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-30-121.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.16.30.121,PodIP:100.96.4.139,StartTime:2019-12-24 02:03:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-24 02:03:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://d6b6ea1dfaf2c1b43a46187cf0aa676c4e69338cfae287ff41062de6e16f3fdd,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.4.139,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.224: INFO: Pod "webserver-deployment-595b5b9587-zxsqg" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-zxsqg webserver-deployment-595b5b9587- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-595b5b9587-zxsqg 3cd45ff3-1922-4b24-b8a5-bbf88d9ba812 127120 0 2019-12-24 02:03:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.96.4.141/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 5a233585-3059-4758-8c02-cfc9d2fd840d 0xc002e36237 0xc002e36238}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-30-121.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:03:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.16.30.121,PodIP:100.96.4.141,StartTime:2019-12-24 02:03:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-24 02:03:59 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://18e08dccd94ceb6247ffe70c41d90b801704bfbc56efed7a724697932ddbd3e5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.4.141,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.224: INFO: Pod "webserver-deployment-c7997dcc8-49xm8" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-49xm8 webserver-deployment-c7997dcc8- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-c7997dcc8-49xm8 54206435-6c36-49b6-a9ab-50719134aa9c 127209 0 2019-12-24 02:04:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:100.96.4.143/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5c29a0ea-e624-4eb4-9bff-52d082df84e9 0xc002e363b7 0xc002e363b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-30-121.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.16.30.121,PodIP:100.96.4.143,StartTime:2019-12-24 02:04:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login',},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.4.143,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.224: INFO: Pod "webserver-deployment-c7997dcc8-4t5lm" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-4t5lm webserver-deployment-c7997dcc8- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-c7997dcc8-4t5lm be92709f-6ccf-4715-a12c-e34b48cfc571 127216 0 2019-12-24 02:04:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:100.96.4.144/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5c29a0ea-e624-4eb4-9bff-52d082df84e9 0xc002e36567 0xc002e36568}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-30-121.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.16.30.121,PodIP:,StartTime:2019-12-24 02:04:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.225: INFO: Pod "webserver-deployment-c7997dcc8-769v4" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-769v4 webserver-deployment-c7997dcc8- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-c7997dcc8-769v4 f6b24657-561b-4147-aaef-6d5208fc93ad 127214 0 2019-12-24 02:04:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:100.96.3.129/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5c29a0ea-e624-4eb4-9bff-52d082df84e9 0xc002e366e7 0xc002e366e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-44-108.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.16.44.108,PodIP:100.96.3.129,StartTime:2019-12-24 02:04:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login',},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.3.129,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.225: INFO: Pod "webserver-deployment-c7997dcc8-hkjqs" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-hkjqs webserver-deployment-c7997dcc8- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-c7997dcc8-hkjqs ee1bb65d-2203-4989-b2fa-bcb778930306 127261 0 2019-12-24 02:04:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5c29a0ea-e624-4eb4-9bff-52d082df84e9 0xc002e36897 0xc002e36898}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-103-244.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.225: INFO: Pod "webserver-deployment-c7997dcc8-nqzns" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-nqzns webserver-deployment-c7997dcc8- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-c7997dcc8-nqzns e54f3176-86b1-48f4-bae4-7adf0b3783f2 127240 0 2019-12-24 02:04:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5c29a0ea-e624-4eb4-9bff-52d082df84e9 0xc002e369b0 0xc002e369b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-30-121.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.225: INFO: Pod "webserver-deployment-c7997dcc8-qqd8k" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-qqd8k webserver-deployment-c7997dcc8- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-c7997dcc8-qqd8k 49646a26-042c-433e-8093-d30cb60d1a38 127199 0 2019-12-24 02:04:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:100.96.5.114/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5c29a0ea-e624-4eb4-9bff-52d082df84e9 0xc002e36ad0 0xc002e36ad1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-103-244.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.16.103.244,PodIP:,StartTime:2019-12-24 02:04:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.225: INFO: Pod "webserver-deployment-c7997dcc8-tcs7q" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-tcs7q webserver-deployment-c7997dcc8- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-c7997dcc8-tcs7q 7d1e970e-bace-42c8-92f1-d6c18019eba8 127218 0 2019-12-24 02:04:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:100.96.3.130/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5c29a0ea-e624-4eb4-9bff-52d082df84e9 0xc002e36c47 0xc002e36c48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-44-108.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.16.44.108,PodIP:,StartTime:2019-12-24 02:04:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.225: INFO: Pod "webserver-deployment-c7997dcc8-trcdj" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-trcdj webserver-deployment-c7997dcc8- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-c7997dcc8-trcdj 1f20fe09-04b9-4b0e-b052-1fcd795aa46d 127239 0 2019-12-24 02:04:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5c29a0ea-e624-4eb4-9bff-52d082df84e9 0xc002e36db7 0xc002e36db8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-44-108.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.225: INFO: Pod "webserver-deployment-c7997dcc8-w5vsn" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-w5vsn webserver-deployment-c7997dcc8- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-c7997dcc8-w5vsn e32998b6-d64a-4100-87b2-74207eecd718 127250 0 2019-12-24 02:04:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5c29a0ea-e624-4eb4-9bff-52d082df84e9 0xc002e36ed0 0xc002e36ed1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.226: INFO: Pod "webserver-deployment-c7997dcc8-wm8r2" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-wm8r2 webserver-deployment-c7997dcc8- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-c7997dcc8-wm8r2 2dc86d46-a508-4e66-a325-1ff098aae196 127252 0 2019-12-24 02:04:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5c29a0ea-e624-4eb4-9bff-52d082df84e9 0xc002e36fd0 0xc002e36fd1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-103-244.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.16.103.244,PodIP:,StartTime:2019-12-24 02:04:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.226: INFO: Pod "webserver-deployment-c7997dcc8-xf6rv" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-xf6rv webserver-deployment-c7997dcc8- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-c7997dcc8-xf6rv 80bdb545-495c-4535-9683-5978c47ee1af 127259 0 2019-12-24 02:04:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5c29a0ea-e624-4eb4-9bff-52d082df84e9 0xc002e37137 0xc002e37138}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-103-244.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 24 02:04:03.226: INFO: Pod "webserver-deployment-c7997dcc8-zqzqg" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-zqzqg webserver-deployment-c7997dcc8- deployment-1442 /api/v1/namespaces/deployment-1442/pods/webserver-deployment-c7997dcc8-zqzqg 2bbae155-1139-4e39-b13f-0a98432d4992 127262 0 2019-12-24 02:04:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5c29a0ea-e624-4eb4-9bff-52d082df84e9 0xc002e37250 0xc002e37251}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h2b59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h2b59,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h2b59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-44-108.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:04:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:04:03.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1442" for this suite.
Dec 24 02:04:11.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:04:11.464: INFO: namespace deployment-1442 deletion completed in 8.218594451s

• [SLOW TEST:14.719 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:04:11.465: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-5797
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9427
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2520
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:04:17.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5797" for this suite.
Dec 24 02:04:23.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:04:24.118: INFO: namespace namespaces-5797 deletion completed in 6.147984718s
STEP: Destroying namespace "nsdeletetest-9427" for this suite.
Dec 24 02:04:24.122: INFO: Namespace nsdeletetest-9427 was already deleted
STEP: Destroying namespace "nsdeletetest-2520" for this suite.
Dec 24 02:04:30.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:04:30.340: INFO: namespace nsdeletetest-2520 deletion completed in 6.218353229s

• [SLOW TEST:18.875 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:04:30.341: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5121
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-b042c51b-f927-43f6-813f-3e828829c4ce in namespace container-probe-5121
Dec 24 02:04:34.517: INFO: Started pod liveness-b042c51b-f927-43f6-813f-3e828829c4ce in namespace container-probe-5121
STEP: checking the pod's current state and verifying that restartCount is present
Dec 24 02:04:34.522: INFO: Initial restart count of pod liveness-b042c51b-f927-43f6-813f-3e828829c4ce is 0
Dec 24 02:04:50.571: INFO: Restart count of pod container-probe-5121/liveness-b042c51b-f927-43f6-813f-3e828829c4ce is now 1 (16.048970156s elapsed)
Dec 24 02:05:12.632: INFO: Restart count of pod container-probe-5121/liveness-b042c51b-f927-43f6-813f-3e828829c4ce is now 2 (38.110578744s elapsed)
Dec 24 02:05:30.680: INFO: Restart count of pod container-probe-5121/liveness-b042c51b-f927-43f6-813f-3e828829c4ce is now 3 (56.158562071s elapsed)
Dec 24 02:05:50.733: INFO: Restart count of pod container-probe-5121/liveness-b042c51b-f927-43f6-813f-3e828829c4ce is now 4 (1m16.211802864s elapsed)
Dec 24 02:06:58.932: INFO: Restart count of pod container-probe-5121/liveness-b042c51b-f927-43f6-813f-3e828829c4ce is now 5 (2m24.40998762s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:06:58.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5121" for this suite.
Dec 24 02:07:04.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:07:05.152: INFO: namespace container-probe-5121 deletion completed in 6.179777313s

• [SLOW TEST:154.812 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:07:05.153: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3274
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:07:05.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3274" for this suite.
Dec 24 02:07:17.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:07:17.510: INFO: namespace pods-3274 deletion completed in 12.161629165s

• [SLOW TEST:12.357 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:07:17.510: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2146
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-2146
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-2146
I1224 02:07:17.718583      24 runners.go:184] Created replication controller with name: externalname-service, namespace: services-2146, replica count: 2
Dec 24 02:07:20.769: INFO: Creating new exec pod
I1224 02:07:20.769024      24 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 24 02:07:25.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=services-2146 execpod8dsxv -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec 24 02:07:28.751: INFO: rc: 1
Dec 24 02:07:28.751: INFO: Service reachability failing with error: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=services-2146 execpod8dsxv -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80] []  <nil>  + nc -zv -t -w 2 externalname-service 80
nc: connect to externalname-service port 80 (tcp) timed out: Operation in progress
command terminated with exit code 1
 [] <nil> 0xc004993140 exit status 1 <nil> <nil> true [0xc002bcc9d0 0xc002bcc9e8 0xc002bcca00] [0xc002bcc9d0 0xc002bcc9e8 0xc002bcca00] [0xc002bcc9e0 0xc002bcc9f8] [0x10efe30 0x10efe30] 0xc00394d440 <nil>}:
Command stdout:

stderr:
+ nc -zv -t -w 2 externalname-service 80
nc: connect to externalname-service port 80 (tcp) timed out: Operation in progress
command terminated with exit code 1

error:
exit status 1
Retrying...
Dec 24 02:07:29.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=services-2146 execpod8dsxv -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec 24 02:07:30.101: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 24 02:07:30.101: INFO: stdout: ""
Dec 24 02:07:30.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=services-2146 execpod8dsxv -- /bin/sh -x -c nc -zv -t -w 2 100.67.99.31 80'
Dec 24 02:07:30.464: INFO: stderr: "+ nc -zv -t -w 2 100.67.99.31 80\nConnection to 100.67.99.31 80 port [tcp/http] succeeded!\n"
Dec 24 02:07:30.464: INFO: stdout: ""
Dec 24 02:07:30.464: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:07:30.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2146" for this suite.
Dec 24 02:07:36.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:07:36.693: INFO: namespace services-2146 deletion completed in 6.183337979s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:19.183 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:07:36.693: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-930
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 24 02:07:36.847: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 24 02:07:36.864: INFO: Waiting for terminating namespaces to be deleted...
Dec 24 02:07:36.868: INFO: 
Logging pods the kubelet thinks is on node ip-172-16-103-244.ec2.internal before test
Dec 24 02:07:36.892: INFO: kube-proxy-7e590abedfb7de51d1197b20e754686a6a8674ae8ac79bc64dcfdc0bb67fb64f-ip-172-16-103-244.ec2.internal from kube-system started at 2019-12-23 15:43:16 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.892: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 24 02:07:36.892: INFO: kublr-logging-rabbitmq-0 from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.892: INFO: 	Container rabbitmq ready: true, restart count 0
Dec 24 02:07:36.892: INFO: kublr-monitoring-prometheus-59564b557d-pkjhv from kublr started at 2019-12-23 15:46:15 +0000 UTC (2 container statuses recorded)
Dec 24 02:07:36.892: INFO: 	Container keycloak-proxy ready: true, restart count 4
Dec 24 02:07:36.892: INFO: 	Container prometheus ready: true, restart count 6
Dec 24 02:07:36.892: INFO: kublr-logging-elasticsearch-client-6f7d56fdbb-zgnhd from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.892: INFO: 	Container elasticsearch ready: true, restart count 0
Dec 24 02:07:36.892: INFO: kublr-monitoring-grafana-6fbbfc98f4-n9zw5 from kublr started at 2019-12-23 15:46:15 +0000 UTC (3 container statuses recorded)
Dec 24 02:07:36.892: INFO: 	Container grafana ready: true, restart count 0
Dec 24 02:07:36.892: INFO: 	Container keycloak-proxy ready: true, restart count 4
Dec 24 02:07:36.892: INFO: 	Container nginx-proxy ready: true, restart count 0
Dec 24 02:07:36.892: INFO: sonobuoy-systemd-logs-daemon-set-eb45748a27ab4169-h9v2w from sonobuoy started at 2019-12-24 01:19:59 +0000 UTC (2 container statuses recorded)
Dec 24 02:07:36.892: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 24 02:07:36.892: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 24 02:07:36.892: INFO: kublr-node-name-reporter-b5f50899e00ed5b8ad1b215b812381270bf0779993c3a6740826f2cfb378f08f-ip-172-16-103-244.ec2.internal from kube-system started at 2019-12-23 15:43:16 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.892: INFO: 	Container main ready: true, restart count 0
Dec 24 02:07:36.892: INFO: node-local-dns-hw2d5 from kube-system started at 2019-12-23 15:44:27 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.892: INFO: 	Container node-cache ready: true, restart count 0
Dec 24 02:07:36.892: INFO: kublr-logging-fluentd-es-7rd6f from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.892: INFO: 	Container fluentd-es ready: true, restart count 4
Dec 24 02:07:36.892: INFO: kublr-ingress-nginx-ingress-controller-849b4769fc-79bhq from kube-system started at 2019-12-23 15:45:19 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.892: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec 24 02:07:36.892: INFO: kublr-ingress-nginx-ingress-default-backend-7b84f6bc4b-xr9cg from kube-system started at 2019-12-23 15:45:19 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.892: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
Dec 24 02:07:36.892: INFO: kublr-monitoring-alertmanager-549cf5f44c-fbdlf from kublr started at 2019-12-23 15:46:09 +0000 UTC (2 container statuses recorded)
Dec 24 02:07:36.892: INFO: 	Container alertmanager ready: true, restart count 0
Dec 24 02:07:36.892: INFO: 	Container keycloak-proxy ready: true, restart count 4
Dec 24 02:07:36.892: INFO: k8s-api-haproxy-de80cb1199e732ef3c9ca0051c41dd966f81ca8bee9c571b76dea5e659c7b97b-ip-172-16-103-244.ec2.internal from kube-system started at 2019-12-23 15:43:16 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.892: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Dec 24 02:07:36.892: INFO: canal-d28dx from kube-system started at 2019-12-23 15:44:11 +0000 UTC (4 container statuses recorded)
Dec 24 02:07:36.892: INFO: 	Container calico-node ready: true, restart count 0
Dec 24 02:07:36.892: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 24 02:07:36.892: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Dec 24 02:07:36.892: INFO: 	Container update-network-condition ready: true, restart count 0
Dec 24 02:07:36.892: INFO: kublr-logging-controller-7f5d56f594-rq5fl from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.892: INFO: 	Container kublr-feature-logging ready: true, restart count 0
Dec 24 02:07:36.892: INFO: 
Logging pods the kubelet thinks is on node ip-172-16-30-121.ec2.internal before test
Dec 24 02:07:36.912: INFO: node-local-dns-jq8bl from kube-system started at 2019-12-23 15:44:27 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.912: INFO: 	Container node-cache ready: true, restart count 0
Dec 24 02:07:36.912: INFO: kublr-logging-kibana-5d84bc784d-gfh6r from kublr started at 2019-12-23 15:46:03 +0000 UTC (4 container statuses recorded)
Dec 24 02:07:36.912: INFO: 	Container keycloak-proxy ready: true, restart count 0
Dec 24 02:07:36.912: INFO: 	Container kibana ready: true, restart count 0
Dec 24 02:07:36.912: INFO: 	Container nginx-proxy ready: true, restart count 0
Dec 24 02:07:36.912: INFO: 	Container sg-auth-proxy ready: true, restart count 0
Dec 24 02:07:36.912: INFO: kcp-backup-controller-6894dbfd9f-mxv6r from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.912: INFO: 	Container backup-controller ready: true, restart count 0
Dec 24 02:07:36.912: INFO: heapster-v1.6.0-beta.1-5f6b4bf99b-bxcwv from kube-system started at 2019-12-23 15:44:31 +0000 UTC (2 container statuses recorded)
Dec 24 02:07:36.912: INFO: 	Container heapster ready: true, restart count 0
Dec 24 02:07:36.912: INFO: 	Container heapster-nanny ready: true, restart count 0
Dec 24 02:07:36.912: INFO: kcp-kublr-ui-5d5fbd8dc5-mxf6z from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.912: INFO: 	Container kublr-ui ready: true, restart count 0
Dec 24 02:07:36.912: INFO: kube-proxy-7e590abedfb7de51d1197b20e754686a6a8674ae8ac79bc64dcfdc0bb67fb64f-ip-172-16-30-121.ec2.internal from kube-system started at 2019-12-23 15:43:25 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.912: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 24 02:07:36.912: INFO: kublr-logging-sg-job-kqg5q from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.912: INFO: 	Container certgenerator ready: false, restart count 0
Dec 24 02:07:36.912: INFO: kcp-cluster-controller-846969f94d-998fm from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.912: INFO: 	Container cluster-controller ready: true, restart count 0
Dec 24 02:07:36.912: INFO: sonobuoy from sonobuoy started at 2019-12-24 01:19:56 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.912: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 24 02:07:36.912: INFO: k8s-api-haproxy-429d71c9c9d8df433e1397ffb7b8d70c5c9c56d08dcdf3f6b2e0fe52606e3c6f-ip-172-16-30-121.ec2.internal from kube-system started at 2019-12-23 15:43:25 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.912: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Dec 24 02:07:36.912: INFO: kublr-logging-fluentd-es-nc4f7 from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.912: INFO: 	Container fluentd-es ready: true, restart count 4
Dec 24 02:07:36.912: INFO: kcp-app-mongodb-789bf97977-lckdz from kublr started at 2019-12-23 15:46:21 +0000 UTC (2 container statuses recorded)
Dec 24 02:07:36.912: INFO: 	Container mongo ready: true, restart count 0
Dec 24 02:07:36.912: INFO: 	Container mongo-exporter ready: true, restart count 0
Dec 24 02:07:36.912: INFO: kublr-node-name-reporter-c6710394cb2609cca16a8c87ff84cdb8044d9d6e9239ff3abcfbaa4768a4122f-ip-172-16-30-121.ec2.internal from kube-system started at 2019-12-23 15:43:25 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.912: INFO: 	Container main ready: true, restart count 0
Dec 24 02:07:36.912: INFO: kcp-app-mysql-549dd84b74-pd89v from kublr started at 2019-12-23 15:46:21 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.913: INFO: 	Container kcp-app-mysql ready: true, restart count 0
Dec 24 02:07:36.913: INFO: sonobuoy-systemd-logs-daemon-set-eb45748a27ab4169-v9f85 from sonobuoy started at 2019-12-24 01:19:59 +0000 UTC (2 container statuses recorded)
Dec 24 02:07:36.913: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 24 02:07:36.913: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 24 02:07:36.913: INFO: canal-7sp7t from kube-system started at 2019-12-23 15:44:11 +0000 UTC (4 container statuses recorded)
Dec 24 02:07:36.913: INFO: 	Container calico-node ready: true, restart count 0
Dec 24 02:07:36.913: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 24 02:07:36.913: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Dec 24 02:07:36.913: INFO: 	Container update-network-condition ready: true, restart count 0
Dec 24 02:07:36.913: INFO: tiller-deploy-db48c564c-gj6vz from kube-system started at 2019-12-23 15:44:34 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.913: INFO: 	Container tiller ready: true, restart count 0
Dec 24 02:07:36.913: INFO: kublr-logging-elasticsearch-master-0 from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.913: INFO: 	Container elasticsearch ready: true, restart count 0
Dec 24 02:07:36.913: INFO: kublr-logging-curator-1577149200-nkjhl from kublr started at 2019-12-24 01:00:01 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.913: INFO: 	Container curator ready: false, restart count 0
Dec 24 02:07:36.913: INFO: kublr-monitoring-kube-state-metrics-5ff6484cf7-bltmp from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.913: INFO: 	Container kubestatemetrics ready: true, restart count 0
Dec 24 02:07:36.913: INFO: kublr-monitoring-monitoring-controller-66578cf88c-fb2gk from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.913: INFO: 	Container app-monitoring ready: true, restart count 0
Dec 24 02:07:36.913: INFO: kcp-generator-6bd556bcf6-dmqbq from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.913: INFO: 	Container generator ready: true, restart count 0
Dec 24 02:07:36.913: INFO: 
Logging pods the kubelet thinks is on node ip-172-16-44-108.ec2.internal before test
Dec 24 02:07:36.935: INFO: kube-proxy-7e590abedfb7de51d1197b20e754686a6a8674ae8ac79bc64dcfdc0bb67fb64f-ip-172-16-44-108.ec2.internal from kube-system started at 2019-12-23 15:43:19 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.935: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 24 02:07:36.935: INFO: sonobuoy-e2e-job-457b3e5a99034c4d from sonobuoy started at 2019-12-24 01:19:59 +0000 UTC (2 container statuses recorded)
Dec 24 02:07:36.935: INFO: 	Container e2e ready: true, restart count 0
Dec 24 02:07:36.935: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 24 02:07:36.935: INFO: kublr-logging-fluentd-es-bpbg6 from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.935: INFO: 	Container fluentd-es ready: true, restart count 4
Dec 24 02:07:36.935: INFO: kublr-logging-rabbitmq-exporter-dc6b44ccd-6r8ks from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.935: INFO: 	Container kublr-logging-rabbitmq-exporter ready: true, restart count 0
Dec 24 02:07:36.935: INFO: kcp-keycloak-0 from kublr started at 2019-12-23 15:46:15 +0000 UTC (2 container statuses recorded)
Dec 24 02:07:36.935: INFO: 	Container init-keycloak ready: true, restart count 0
Dec 24 02:07:36.935: INFO: 	Container kcp-keycloak ready: true, restart count 0
Dec 24 02:07:36.935: INFO: kcp-terraform-controller-6f447b77d7-v69lk from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.935: INFO: 	Container terraform-controller ready: true, restart count 0
Dec 24 02:07:36.935: INFO: metrics-server-v0.3.6-86567757d-7d792 from kube-system started at 2019-12-23 17:20:18 +0000 UTC (2 container statuses recorded)
Dec 24 02:07:36.935: INFO: 	Container metrics-server ready: true, restart count 0
Dec 24 02:07:36.935: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Dec 24 02:07:36.935: INFO: kubernetes-dashboard-84cb747b5c-td8jl from kubernetes-dashboard started at 2019-12-23 15:44:31 +0000 UTC (2 container statuses recorded)
Dec 24 02:07:36.935: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec 24 02:07:36.935: INFO: 	Container kubernetes-dashboard-auth-proxy ready: true, restart count 0
Dec 24 02:07:36.935: INFO: kublr-system-shell-6f4bcb9487-n9swc from kube-system started at 2019-12-23 15:45:12 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.935: INFO: 	Container shell ready: true, restart count 0
Dec 24 02:07:36.935: INFO: kublr-node-name-reporter-be88daf430a9d4815e9777fe7bdbbdded5de4e21fb88257b9dc4b4a05304fcee-ip-172-16-44-108.ec2.internal from kube-system started at 2019-12-23 15:43:19 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.935: INFO: 	Container main ready: true, restart count 0
Dec 24 02:07:36.935: INFO: k8s-api-haproxy-de80cb1199e732ef3c9ca0051c41dd966f81ca8bee9c571b76dea5e659c7b97b-ip-172-16-44-108.ec2.internal from kube-system started at 2019-12-23 15:43:19 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.935: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Dec 24 02:07:36.936: INFO: canal-rxhg5 from kube-system started at 2019-12-23 15:44:11 +0000 UTC (4 container statuses recorded)
Dec 24 02:07:36.936: INFO: 	Container calico-node ready: true, restart count 0
Dec 24 02:07:36.936: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 24 02:07:36.936: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Dec 24 02:07:36.936: INFO: 	Container update-network-condition ready: true, restart count 0
Dec 24 02:07:36.936: INFO: node-local-dns-dzntt from kube-system started at 2019-12-23 15:44:27 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.936: INFO: 	Container node-cache ready: true, restart count 0
Dec 24 02:07:36.936: INFO: kublr-logging-elasticsearch-exporter-78df7c8987-w7b6q from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.936: INFO: 	Container main ready: true, restart count 0
Dec 24 02:07:36.936: INFO: kublr-logging-elasticsearch-data-0 from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.936: INFO: 	Container elasticsearch ready: true, restart count 0
Dec 24 02:07:36.936: INFO: kcp-kublr-api-6b7d4bc968-kd9pb from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.936: INFO: 	Container kublr-api ready: true, restart count 0
Dec 24 02:07:36.937: INFO: sonobuoy-systemd-logs-daemon-set-eb45748a27ab4169-wpzc6 from sonobuoy started at 2019-12-24 01:19:59 +0000 UTC (2 container statuses recorded)
Dec 24 02:07:36.937: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 24 02:07:36.937: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 24 02:07:36.937: INFO: kublr-logging-logstash-547687bcdc-vdg4k from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:07:36.937: INFO: 	Container logstash ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-076e2d2a-1f53-4e6d-ab43-50fbcb0a3726 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-076e2d2a-1f53-4e6d-ab43-50fbcb0a3726 off the node ip-172-16-44-108.ec2.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-076e2d2a-1f53-4e6d-ab43-50fbcb0a3726
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:07:53.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-930" for this suite.
Dec 24 02:08:05.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:08:05.265: INFO: namespace sched-pred-930 deletion completed in 12.151912518s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:28.572 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:08:05.265: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2632
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 24 02:08:05.950: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 24 02:08:07.970: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750085, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750085, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750086, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750085, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 24 02:08:10.996: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Dec 24 02:08:15.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 attach --namespace=webhook-2632 to-be-attached-pod -i -c=container1'
Dec 24 02:08:15.133: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:08:15.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2632" for this suite.
Dec 24 02:08:27.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:08:27.295: INFO: namespace webhook-2632 deletion completed in 12.141734609s
STEP: Destroying namespace "webhook-2632-markers" for this suite.
Dec 24 02:08:37.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:08:37.532: INFO: namespace webhook-2632-markers deletion completed in 10.236720593s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:32.294 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:08:37.559: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7125
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 24 02:08:38.132: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 24 02:08:40.153: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750118, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750118, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750118, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750118, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 24 02:08:43.179: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:08:43.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7125" for this suite.
Dec 24 02:08:49.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:08:49.348: INFO: namespace webhook-7125 deletion completed in 6.153684637s
STEP: Destroying namespace "webhook-7125-markers" for this suite.
Dec 24 02:08:55.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:08:55.498: INFO: namespace webhook-7125-markers deletion completed in 6.150304112s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.958 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:08:55.518: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9320
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-f39e06bf-c4b5-438a-aecd-d800f61246f1
STEP: Creating a pod to test consume secrets
Dec 24 02:08:55.682: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-09f09f40-1485-4fe3-b22d-09247b3ba4fa" in namespace "projected-9320" to be "success or failure"
Dec 24 02:08:55.685: INFO: Pod "pod-projected-secrets-09f09f40-1485-4fe3-b22d-09247b3ba4fa": Phase="Pending", Reason="", readiness=false. Elapsed: 3.360709ms
Dec 24 02:08:57.690: INFO: Pod "pod-projected-secrets-09f09f40-1485-4fe3-b22d-09247b3ba4fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007473133s
Dec 24 02:08:59.696: INFO: Pod "pod-projected-secrets-09f09f40-1485-4fe3-b22d-09247b3ba4fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013513497s
STEP: Saw pod success
Dec 24 02:08:59.696: INFO: Pod "pod-projected-secrets-09f09f40-1485-4fe3-b22d-09247b3ba4fa" satisfied condition "success or failure"
Dec 24 02:08:59.699: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod pod-projected-secrets-09f09f40-1485-4fe3-b22d-09247b3ba4fa container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 24 02:08:59.724: INFO: Waiting for pod pod-projected-secrets-09f09f40-1485-4fe3-b22d-09247b3ba4fa to disappear
Dec 24 02:08:59.729: INFO: Pod pod-projected-secrets-09f09f40-1485-4fe3-b22d-09247b3ba4fa no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:08:59.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9320" for this suite.
Dec 24 02:09:05.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:09:05.897: INFO: namespace projected-9320 deletion completed in 6.160358621s

• [SLOW TEST:10.379 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:09:05.898: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7349
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Dec 24 02:09:16.088: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W1224 02:09:16.088831      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 24 02:09:16.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7349" for this suite.
Dec 24 02:09:22.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:09:22.296: INFO: namespace gc-7349 deletion completed in 6.201770226s

• [SLOW TEST:16.397 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:09:22.296: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3025
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-4de0daa5-2558-4fdd-999a-685bf776883b
STEP: Creating a pod to test consume secrets
Dec 24 02:09:22.471: INFO: Waiting up to 5m0s for pod "pod-secrets-c0360d54-d4f5-4a85-b3ad-208c08a9f7c5" in namespace "secrets-3025" to be "success or failure"
Dec 24 02:09:22.479: INFO: Pod "pod-secrets-c0360d54-d4f5-4a85-b3ad-208c08a9f7c5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.770002ms
Dec 24 02:09:24.485: INFO: Pod "pod-secrets-c0360d54-d4f5-4a85-b3ad-208c08a9f7c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013564869s
Dec 24 02:09:26.489: INFO: Pod "pod-secrets-c0360d54-d4f5-4a85-b3ad-208c08a9f7c5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017923562s
STEP: Saw pod success
Dec 24 02:09:26.489: INFO: Pod "pod-secrets-c0360d54-d4f5-4a85-b3ad-208c08a9f7c5" satisfied condition "success or failure"
Dec 24 02:09:26.494: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-secrets-c0360d54-d4f5-4a85-b3ad-208c08a9f7c5 container secret-env-test: <nil>
STEP: delete the pod
Dec 24 02:09:26.529: INFO: Waiting for pod pod-secrets-c0360d54-d4f5-4a85-b3ad-208c08a9f7c5 to disappear
Dec 24 02:09:26.533: INFO: Pod pod-secrets-c0360d54-d4f5-4a85-b3ad-208c08a9f7c5 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:09:26.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3025" for this suite.
Dec 24 02:09:32.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:09:32.698: INFO: namespace secrets-3025 deletion completed in 6.157830275s

• [SLOW TEST:10.402 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:09:32.698: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-6474
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Dec 24 02:09:33.397: INFO: created pod pod-service-account-defaultsa
Dec 24 02:09:33.397: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec 24 02:09:33.414: INFO: created pod pod-service-account-mountsa
Dec 24 02:09:33.414: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec 24 02:09:33.436: INFO: created pod pod-service-account-nomountsa
Dec 24 02:09:33.436: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec 24 02:09:33.442: INFO: created pod pod-service-account-defaultsa-mountspec
Dec 24 02:09:33.442: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec 24 02:09:33.483: INFO: created pod pod-service-account-mountsa-mountspec
Dec 24 02:09:33.483: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec 24 02:09:33.498: INFO: created pod pod-service-account-nomountsa-mountspec
Dec 24 02:09:33.498: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec 24 02:09:33.509: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec 24 02:09:33.509: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec 24 02:09:33.523: INFO: created pod pod-service-account-mountsa-nomountspec
Dec 24 02:09:33.523: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec 24 02:09:33.542: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec 24 02:09:33.542: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:09:33.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6474" for this suite.
Dec 24 02:09:39.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:09:39.815: INFO: namespace svcaccounts-6474 deletion completed in 6.259314413s

• [SLOW TEST:7.117 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:09:39.818: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2453
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-585ea8f6-ed50-4dd1-b252-33468c82a3a8
STEP: Creating a pod to test consume configMaps
Dec 24 02:09:40.000: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5d0d6bda-a0c1-49bc-8649-e62554c9ea94" in namespace "projected-2453" to be "success or failure"
Dec 24 02:09:40.014: INFO: Pod "pod-projected-configmaps-5d0d6bda-a0c1-49bc-8649-e62554c9ea94": Phase="Pending", Reason="", readiness=false. Elapsed: 14.578122ms
Dec 24 02:09:42.022: INFO: Pod "pod-projected-configmaps-5d0d6bda-a0c1-49bc-8649-e62554c9ea94": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022003413s
Dec 24 02:09:44.026: INFO: Pod "pod-projected-configmaps-5d0d6bda-a0c1-49bc-8649-e62554c9ea94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026235614s
STEP: Saw pod success
Dec 24 02:09:44.026: INFO: Pod "pod-projected-configmaps-5d0d6bda-a0c1-49bc-8649-e62554c9ea94" satisfied condition "success or failure"
Dec 24 02:09:44.030: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-projected-configmaps-5d0d6bda-a0c1-49bc-8649-e62554c9ea94 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 24 02:09:44.057: INFO: Waiting for pod pod-projected-configmaps-5d0d6bda-a0c1-49bc-8649-e62554c9ea94 to disappear
Dec 24 02:09:44.061: INFO: Pod pod-projected-configmaps-5d0d6bda-a0c1-49bc-8649-e62554c9ea94 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:09:44.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2453" for this suite.
Dec 24 02:09:50.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:09:50.211: INFO: namespace projected-2453 deletion completed in 6.14428034s

• [SLOW TEST:10.394 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:09:50.213: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9332
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-9332/configmap-test-e3a621a8-d9e9-43ed-b7b3-125deca39ef7
STEP: Creating a pod to test consume configMaps
Dec 24 02:09:50.392: INFO: Waiting up to 5m0s for pod "pod-configmaps-614d8584-de61-453c-aaba-ac1d7f4634d2" in namespace "configmap-9332" to be "success or failure"
Dec 24 02:09:50.401: INFO: Pod "pod-configmaps-614d8584-de61-453c-aaba-ac1d7f4634d2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.747414ms
Dec 24 02:09:52.420: INFO: Pod "pod-configmaps-614d8584-de61-453c-aaba-ac1d7f4634d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02573996s
Dec 24 02:09:54.425: INFO: Pod "pod-configmaps-614d8584-de61-453c-aaba-ac1d7f4634d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031001099s
STEP: Saw pod success
Dec 24 02:09:54.425: INFO: Pod "pod-configmaps-614d8584-de61-453c-aaba-ac1d7f4634d2" satisfied condition "success or failure"
Dec 24 02:09:54.429: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod pod-configmaps-614d8584-de61-453c-aaba-ac1d7f4634d2 container env-test: <nil>
STEP: delete the pod
Dec 24 02:09:54.455: INFO: Waiting for pod pod-configmaps-614d8584-de61-453c-aaba-ac1d7f4634d2 to disappear
Dec 24 02:09:54.459: INFO: Pod pod-configmaps-614d8584-de61-453c-aaba-ac1d7f4634d2 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:09:54.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9332" for this suite.
Dec 24 02:10:00.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:10:00.620: INFO: namespace configmap-9332 deletion completed in 6.151550891s

• [SLOW TEST:10.407 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:10:00.620: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-7280
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 02:10:00.782: INFO: Waiting up to 5m0s for pod "busybox-user-65534-3f1414a4-ed87-402d-842d-012435d7ae2e" in namespace "security-context-test-7280" to be "success or failure"
Dec 24 02:10:00.791: INFO: Pod "busybox-user-65534-3f1414a4-ed87-402d-842d-012435d7ae2e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.300371ms
Dec 24 02:10:02.803: INFO: Pod "busybox-user-65534-3f1414a4-ed87-402d-842d-012435d7ae2e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020721645s
Dec 24 02:10:04.808: INFO: Pod "busybox-user-65534-3f1414a4-ed87-402d-842d-012435d7ae2e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02607275s
Dec 24 02:10:04.808: INFO: Pod "busybox-user-65534-3f1414a4-ed87-402d-842d-012435d7ae2e" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:10:04.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7280" for this suite.
Dec 24 02:10:10.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:10:10.963: INFO: namespace security-context-test-7280 deletion completed in 6.145168905s

• [SLOW TEST:10.343 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:10:10.963: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7966
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 02:10:11.132: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Dec 24 02:10:12.172: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:10:12.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7966" for this suite.
Dec 24 02:10:18.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:10:18.338: INFO: namespace replication-controller-7966 deletion completed in 6.150352072s

• [SLOW TEST:7.375 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:10:18.338: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1521
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 24 02:10:18.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-1521'
Dec 24 02:10:18.621: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 24 02:10:18.621: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Dec 24 02:10:18.631: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Dec 24 02:10:18.637: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec 24 02:10:18.645: INFO: scanned /root for discovery docs: <nil>
Dec 24 02:10:18.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-1521'
Dec 24 02:10:34.488: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 24 02:10:34.488: INFO: stdout: "Created e2e-test-httpd-rc-c7afb44500568c5cbcb49adf720f42be\nScaling up e2e-test-httpd-rc-c7afb44500568c5cbcb49adf720f42be from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-c7afb44500568c5cbcb49adf720f42be up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-c7afb44500568c5cbcb49adf720f42be to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Dec 24 02:10:34.488: INFO: stdout: "Created e2e-test-httpd-rc-c7afb44500568c5cbcb49adf720f42be\nScaling up e2e-test-httpd-rc-c7afb44500568c5cbcb49adf720f42be from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-c7afb44500568c5cbcb49adf720f42be up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-c7afb44500568c5cbcb49adf720f42be to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Dec 24 02:10:34.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-1521'
Dec 24 02:10:34.568: INFO: stderr: ""
Dec 24 02:10:34.568: INFO: stdout: "e2e-test-httpd-rc-c7afb44500568c5cbcb49adf720f42be-xkb9w "
Dec 24 02:10:34.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods e2e-test-httpd-rc-c7afb44500568c5cbcb49adf720f42be-xkb9w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1521'
Dec 24 02:10:34.638: INFO: stderr: ""
Dec 24 02:10:34.638: INFO: stdout: "true"
Dec 24 02:10:34.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods e2e-test-httpd-rc-c7afb44500568c5cbcb49adf720f42be-xkb9w -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1521'
Dec 24 02:10:34.716: INFO: stderr: ""
Dec 24 02:10:34.716: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Dec 24 02:10:34.716: INFO: e2e-test-httpd-rc-c7afb44500568c5cbcb49adf720f42be-xkb9w is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Dec 24 02:10:34.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 delete rc e2e-test-httpd-rc --namespace=kubectl-1521'
Dec 24 02:10:34.826: INFO: stderr: ""
Dec 24 02:10:34.826: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:10:34.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1521" for this suite.
Dec 24 02:10:46.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:10:46.987: INFO: namespace kubectl-1521 deletion completed in 12.152902568s

• [SLOW TEST:28.649 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:10:46.987: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4022
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-2e9ee36f-ac29-41f1-ab88-c76a5a22a058
STEP: Creating a pod to test consume secrets
Dec 24 02:10:47.172: INFO: Waiting up to 5m0s for pod "pod-secrets-8bc776a6-8413-4982-be8c-86805cf6159b" in namespace "secrets-4022" to be "success or failure"
Dec 24 02:10:47.177: INFO: Pod "pod-secrets-8bc776a6-8413-4982-be8c-86805cf6159b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.98105ms
Dec 24 02:10:49.182: INFO: Pod "pod-secrets-8bc776a6-8413-4982-be8c-86805cf6159b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010545782s
Dec 24 02:10:51.187: INFO: Pod "pod-secrets-8bc776a6-8413-4982-be8c-86805cf6159b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014938573s
STEP: Saw pod success
Dec 24 02:10:51.187: INFO: Pod "pod-secrets-8bc776a6-8413-4982-be8c-86805cf6159b" satisfied condition "success or failure"
Dec 24 02:10:51.190: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-secrets-8bc776a6-8413-4982-be8c-86805cf6159b container secret-volume-test: <nil>
STEP: delete the pod
Dec 24 02:10:51.218: INFO: Waiting for pod pod-secrets-8bc776a6-8413-4982-be8c-86805cf6159b to disappear
Dec 24 02:10:51.221: INFO: Pod pod-secrets-8bc776a6-8413-4982-be8c-86805cf6159b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:10:51.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4022" for this suite.
Dec 24 02:10:57.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:10:57.431: INFO: namespace secrets-4022 deletion completed in 6.204105858s

• [SLOW TEST:10.444 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:10:57.431: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6393
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec 24 02:10:57.623: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6393 /api/v1/namespaces/watch-6393/configmaps/e2e-watch-test-label-changed 3a0eb4b0-d9c0-4174-b292-c4c97256058c 129666 0 2019-12-24 02:10:57 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 24 02:10:57.623: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6393 /api/v1/namespaces/watch-6393/configmaps/e2e-watch-test-label-changed 3a0eb4b0-d9c0-4174-b292-c4c97256058c 129667 0 2019-12-24 02:10:57 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 24 02:10:57.624: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6393 /api/v1/namespaces/watch-6393/configmaps/e2e-watch-test-label-changed 3a0eb4b0-d9c0-4174-b292-c4c97256058c 129668 0 2019-12-24 02:10:57 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec 24 02:11:07.679: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6393 /api/v1/namespaces/watch-6393/configmaps/e2e-watch-test-label-changed 3a0eb4b0-d9c0-4174-b292-c4c97256058c 129697 0 2019-12-24 02:10:57 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 24 02:11:07.680: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6393 /api/v1/namespaces/watch-6393/configmaps/e2e-watch-test-label-changed 3a0eb4b0-d9c0-4174-b292-c4c97256058c 129698 0 2019-12-24 02:10:57 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec 24 02:11:07.680: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6393 /api/v1/namespaces/watch-6393/configmaps/e2e-watch-test-label-changed 3a0eb4b0-d9c0-4174-b292-c4c97256058c 129699 0 2019-12-24 02:10:57 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:11:07.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6393" for this suite.
Dec 24 02:11:13.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:11:13.833: INFO: namespace watch-6393 deletion completed in 6.145994256s

• [SLOW TEST:16.402 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:11:13.833: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4094
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 24 02:11:14.321: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 24 02:11:16.334: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750274, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750274, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750274, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750274, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 24 02:11:19.360: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:11:19.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4094" for this suite.
Dec 24 02:11:25.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:11:25.592: INFO: namespace webhook-4094 deletion completed in 6.154927704s
STEP: Destroying namespace "webhook-4094-markers" for this suite.
Dec 24 02:11:31.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:11:31.747: INFO: namespace webhook-4094-markers deletion completed in 6.154477321s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.937 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:11:31.771: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7152
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-c7d35351-e28f-4ab1-adf2-151413348ecc
Dec 24 02:11:31.935: INFO: Pod name my-hostname-basic-c7d35351-e28f-4ab1-adf2-151413348ecc: Found 0 pods out of 1
Dec 24 02:11:36.940: INFO: Pod name my-hostname-basic-c7d35351-e28f-4ab1-adf2-151413348ecc: Found 1 pods out of 1
Dec 24 02:11:36.940: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-c7d35351-e28f-4ab1-adf2-151413348ecc" are running
Dec 24 02:11:36.944: INFO: Pod "my-hostname-basic-c7d35351-e28f-4ab1-adf2-151413348ecc-sxbj2" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-24 02:11:31 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-24 02:11:34 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-24 02:11:34 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-24 02:11:31 +0000 UTC Reason: Message:}])
Dec 24 02:11:36.944: INFO: Trying to dial the pod
Dec 24 02:11:41.963: INFO: Controller my-hostname-basic-c7d35351-e28f-4ab1-adf2-151413348ecc: Got expected result from replica 1 [my-hostname-basic-c7d35351-e28f-4ab1-adf2-151413348ecc-sxbj2]: "my-hostname-basic-c7d35351-e28f-4ab1-adf2-151413348ecc-sxbj2", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:11:41.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7152" for this suite.
Dec 24 02:11:47.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:11:48.109: INFO: namespace replication-controller-7152 deletion completed in 6.140216098s

• [SLOW TEST:16.338 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:11:48.109: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6633
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:11:52.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6633" for this suite.
Dec 24 02:12:40.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:12:40.482: INFO: namespace kubelet-test-6633 deletion completed in 48.165574895s

• [SLOW TEST:52.373 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:12:40.482: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7546
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-7546
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 24 02:12:40.636: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 24 02:13:02.763: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.3.163:8080/dial?request=hostName&protocol=udp&host=100.96.3.162&port=8081&tries=1'] Namespace:pod-network-test-7546 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 24 02:13:02.763: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 02:13:02.907: INFO: Waiting for endpoints: map[]
Dec 24 02:13:02.912: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.3.163:8080/dial?request=hostName&protocol=udp&host=100.96.4.162&port=8081&tries=1'] Namespace:pod-network-test-7546 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 24 02:13:02.912: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 02:13:03.057: INFO: Waiting for endpoints: map[]
Dec 24 02:13:03.062: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.3.163:8080/dial?request=hostName&protocol=udp&host=100.96.5.123&port=8081&tries=1'] Namespace:pod-network-test-7546 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 24 02:13:03.062: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 02:13:03.216: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:13:03.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7546" for this suite.
Dec 24 02:13:15.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:13:15.376: INFO: namespace pod-network-test-7546 deletion completed in 12.150954319s

• [SLOW TEST:34.894 seconds]
[sig-network] Networking
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:13:15.376: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-666
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-666/secret-test-4174bc4f-5968-4a84-afda-287d5b351dbf
STEP: Creating a pod to test consume secrets
Dec 24 02:13:15.548: INFO: Waiting up to 5m0s for pod "pod-configmaps-1c636bd7-6457-4566-8c79-68c7aff852e8" in namespace "secrets-666" to be "success or failure"
Dec 24 02:13:15.556: INFO: Pod "pod-configmaps-1c636bd7-6457-4566-8c79-68c7aff852e8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.059158ms
Dec 24 02:13:17.562: INFO: Pod "pod-configmaps-1c636bd7-6457-4566-8c79-68c7aff852e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013802159s
Dec 24 02:13:19.568: INFO: Pod "pod-configmaps-1c636bd7-6457-4566-8c79-68c7aff852e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01950302s
STEP: Saw pod success
Dec 24 02:13:19.568: INFO: Pod "pod-configmaps-1c636bd7-6457-4566-8c79-68c7aff852e8" satisfied condition "success or failure"
Dec 24 02:13:19.575: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-configmaps-1c636bd7-6457-4566-8c79-68c7aff852e8 container env-test: <nil>
STEP: delete the pod
Dec 24 02:13:19.617: INFO: Waiting for pod pod-configmaps-1c636bd7-6457-4566-8c79-68c7aff852e8 to disappear
Dec 24 02:13:19.621: INFO: Pod pod-configmaps-1c636bd7-6457-4566-8c79-68c7aff852e8 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:13:19.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-666" for this suite.
Dec 24 02:13:25.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:13:25.768: INFO: namespace secrets-666 deletion completed in 6.138550844s

• [SLOW TEST:10.392 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:13:25.769: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-299
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-09a987e0-3ba2-4d01-9a7c-a77576c48c2f
STEP: Creating a pod to test consume secrets
Dec 24 02:13:25.940: INFO: Waiting up to 5m0s for pod "pod-secrets-f1213184-52f9-424e-985d-9c92b74d8a79" in namespace "secrets-299" to be "success or failure"
Dec 24 02:13:25.945: INFO: Pod "pod-secrets-f1213184-52f9-424e-985d-9c92b74d8a79": Phase="Pending", Reason="", readiness=false. Elapsed: 5.824924ms
Dec 24 02:13:27.950: INFO: Pod "pod-secrets-f1213184-52f9-424e-985d-9c92b74d8a79": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010611579s
Dec 24 02:13:29.960: INFO: Pod "pod-secrets-f1213184-52f9-424e-985d-9c92b74d8a79": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02051599s
STEP: Saw pod success
Dec 24 02:13:29.961: INFO: Pod "pod-secrets-f1213184-52f9-424e-985d-9c92b74d8a79" satisfied condition "success or failure"
Dec 24 02:13:29.965: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-secrets-f1213184-52f9-424e-985d-9c92b74d8a79 container secret-volume-test: <nil>
STEP: delete the pod
Dec 24 02:13:30.002: INFO: Waiting for pod pod-secrets-f1213184-52f9-424e-985d-9c92b74d8a79 to disappear
Dec 24 02:13:30.007: INFO: Pod pod-secrets-f1213184-52f9-424e-985d-9c92b74d8a79 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:13:30.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-299" for this suite.
Dec 24 02:13:36.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:13:36.184: INFO: namespace secrets-299 deletion completed in 6.167174775s

• [SLOW TEST:10.415 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:13:36.184: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4085
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 24 02:13:36.712: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 24 02:13:38.729: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750416, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750416, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750416, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750416, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 24 02:13:41.756: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 02:13:41.760: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:13:48.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4085" for this suite.
Dec 24 02:13:54.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:13:54.367: INFO: namespace webhook-4085 deletion completed in 6.152754586s
STEP: Destroying namespace "webhook-4085-markers" for this suite.
Dec 24 02:14:00.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:14:00.524: INFO: namespace webhook-4085-markers deletion completed in 6.157162593s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.363 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:14:00.547: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7110
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 02:14:00.711: INFO: Creating deployment "test-recreate-deployment"
Dec 24 02:14:00.717: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec 24 02:14:00.727: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Dec 24 02:14:02.737: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec 24 02:14:02.741: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750440, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750440, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750440, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750440, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-68fc85c7bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 24 02:14:04.746: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec 24 02:14:04.756: INFO: Updating deployment test-recreate-deployment
Dec 24 02:14:04.756: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 24 02:14:04.893: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-7110 /apis/apps/v1/namespaces/deployment-7110/deployments/test-recreate-deployment 6c964033-8a0e-42b3-b148-6d4ef760caed 130597 2 2019-12-24 02:14:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0078d71b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-12-24 02:14:04 +0000 UTC,LastTransitionTime:2019-12-24 02:14:04 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2019-12-24 02:14:04 +0000 UTC,LastTransitionTime:2019-12-24 02:14:00 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Dec 24 02:14:04.898: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-7110 /apis/apps/v1/namespaces/deployment-7110/replicasets/test-recreate-deployment-5f94c574ff 1a8d56d4-7dab-4e9d-be1e-50b8c9a50980 130595 1 2019-12-24 02:14:04 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 6c964033-8a0e-42b3-b148-6d4ef760caed 0xc0078d75a7 0xc0078d75a8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0078d7608 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 24 02:14:04.898: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec 24 02:14:04.898: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-7110 /apis/apps/v1/namespaces/deployment-7110/replicasets/test-recreate-deployment-68fc85c7bb 40043664-7d24-4522-be9a-5faedd9561a1 130586 2 2019-12-24 02:14:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 6c964033-8a0e-42b3-b148-6d4ef760caed 0xc0078d7677 0xc0078d7678}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0078d76d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 24 02:14:04.902: INFO: Pod "test-recreate-deployment-5f94c574ff-mdvwg" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-mdvwg test-recreate-deployment-5f94c574ff- deployment-7110 /api/v1/namespaces/deployment-7110/pods/test-recreate-deployment-5f94c574ff-mdvwg 026a4ff5-0648-419c-9e57-2cf17ba2c010 130598 0 2019-12-24 02:14:04 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff 1a8d56d4-7dab-4e9d-be1e-50b8c9a50980 0xc0078d7b57 0xc0078d7b58}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-g9wbm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-g9wbm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-g9wbm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-30-121.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:14:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:14:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:14:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:14:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.16.30.121,PodIP:,StartTime:2019-12-24 02:14:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:14:04.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7110" for this suite.
Dec 24 02:14:10.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:14:11.062: INFO: namespace deployment-7110 deletion completed in 6.153110006s

• [SLOW TEST:10.515 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:14:11.062: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-441
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-e1d6df40-b76b-43b4-b558-144df705e4b9
STEP: Creating configMap with name cm-test-opt-upd-340831d7-b646-4759-b7d7-f54ad623ccf5
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-e1d6df40-b76b-43b4-b558-144df705e4b9
STEP: Updating configmap cm-test-opt-upd-340831d7-b646-4759-b7d7-f54ad623ccf5
STEP: Creating configMap with name cm-test-opt-create-3dbf8546-6bd2-4ca6-aa99-57b0e6f871bb
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:14:19.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-441" for this suite.
Dec 24 02:14:31.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:14:31.568: INFO: namespace configmap-441 deletion completed in 12.177464116s

• [SLOW TEST:20.506 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:14:31.568: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3440
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Dec 24 02:14:35.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec pod-sharedvolume-c8772296-afdb-4165-80e6-d4d15463f118 -c busybox-main-container --namespace=emptydir-3440 -- cat /usr/share/volumeshare/shareddata.txt'
Dec 24 02:14:36.058: INFO: stderr: ""
Dec 24 02:14:36.058: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:14:36.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3440" for this suite.
Dec 24 02:14:42.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:14:42.209: INFO: namespace emptydir-3440 deletion completed in 6.145023361s

• [SLOW TEST:10.641 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:14:42.210: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2459
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 24 02:14:42.374: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4830ac39-f7f1-4737-957b-e3a0259405a7" in namespace "projected-2459" to be "success or failure"
Dec 24 02:14:42.390: INFO: Pod "downwardapi-volume-4830ac39-f7f1-4737-957b-e3a0259405a7": Phase="Pending", Reason="", readiness=false. Elapsed: 15.53281ms
Dec 24 02:14:44.396: INFO: Pod "downwardapi-volume-4830ac39-f7f1-4737-957b-e3a0259405a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021542392s
Dec 24 02:14:46.400: INFO: Pod "downwardapi-volume-4830ac39-f7f1-4737-957b-e3a0259405a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026216821s
STEP: Saw pod success
Dec 24 02:14:46.400: INFO: Pod "downwardapi-volume-4830ac39-f7f1-4737-957b-e3a0259405a7" satisfied condition "success or failure"
Dec 24 02:14:46.404: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod downwardapi-volume-4830ac39-f7f1-4737-957b-e3a0259405a7 container client-container: <nil>
STEP: delete the pod
Dec 24 02:14:46.435: INFO: Waiting for pod downwardapi-volume-4830ac39-f7f1-4737-957b-e3a0259405a7 to disappear
Dec 24 02:14:46.439: INFO: Pod downwardapi-volume-4830ac39-f7f1-4737-957b-e3a0259405a7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:14:46.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2459" for this suite.
Dec 24 02:14:52.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:14:52.581: INFO: namespace projected-2459 deletion completed in 6.135454678s

• [SLOW TEST:10.372 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:14:52.582: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1456
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-8b547af7-b5ba-40b7-9d10-895a50105720
STEP: Creating a pod to test consume secrets
Dec 24 02:14:52.769: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5f8c1fe9-7ae3-4177-b162-491dbefc714f" in namespace "projected-1456" to be "success or failure"
Dec 24 02:14:52.775: INFO: Pod "pod-projected-secrets-5f8c1fe9-7ae3-4177-b162-491dbefc714f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.574895ms
Dec 24 02:14:54.779: INFO: Pod "pod-projected-secrets-5f8c1fe9-7ae3-4177-b162-491dbefc714f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010177425s
Dec 24 02:14:56.784: INFO: Pod "pod-projected-secrets-5f8c1fe9-7ae3-4177-b162-491dbefc714f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014459066s
STEP: Saw pod success
Dec 24 02:14:56.784: INFO: Pod "pod-projected-secrets-5f8c1fe9-7ae3-4177-b162-491dbefc714f" satisfied condition "success or failure"
Dec 24 02:14:56.787: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod pod-projected-secrets-5f8c1fe9-7ae3-4177-b162-491dbefc714f container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 24 02:14:56.812: INFO: Waiting for pod pod-projected-secrets-5f8c1fe9-7ae3-4177-b162-491dbefc714f to disappear
Dec 24 02:14:56.815: INFO: Pod pod-projected-secrets-5f8c1fe9-7ae3-4177-b162-491dbefc714f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:14:56.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1456" for this suite.
Dec 24 02:15:02.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:15:02.998: INFO: namespace projected-1456 deletion completed in 6.176756954s

• [SLOW TEST:10.416 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:15:02.998: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-5022
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 24 02:15:03.160: INFO: PodSpec: initContainers in spec.initContainers
Dec 24 02:15:50.222: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-6a1a9d2e-e06b-427e-be96-452f14136b46", GenerateName:"", Namespace:"init-container-5022", SelfLink:"/api/v1/namespaces/init-container-5022/pods/pod-init-6a1a9d2e-e06b-427e-be96-452f14136b46", UID:"34995eec-43d8-4f2e-9fb7-b0d46ef7a024", ResourceVersion:"131086", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63712750503, loc:(*time.Location)(0x84bfb00)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"160800424"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.96.4.167/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-nd59d", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc005bdacc0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-nd59d", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-nd59d", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-nd59d", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00388a058), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-16-30-121.ec2.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00303f260), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00388a0d0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00388a0f0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00388a0f8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00388a0fc), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750503, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750503, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750503, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712750503, loc:(*time.Location)(0x84bfb00)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.16.30.121", PodIP:"100.96.4.167", PodIPs:[]v1.PodIP{v1.PodIP{IP:"100.96.4.167"}}, StartTime:(*v1.Time)(0xc000589aa0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000798770)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0007987e0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://98d4a42efcc33b205020a2bc1896acf942913e6c038e0dc2477dcc2c3176defe", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000589c40), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000589c00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc00388a17f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:15:50.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5022" for this suite.
Dec 24 02:16:18.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:16:18.421: INFO: namespace init-container-5022 deletion completed in 28.192170367s

• [SLOW TEST:75.423 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:16:18.421: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3278
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3278
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-3278
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3278
Dec 24 02:16:18.607: INFO: Found 0 stateful pods, waiting for 1
Dec 24 02:16:28.612: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec 24 02:16:28.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=statefulset-3278 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 24 02:16:28.879: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 24 02:16:28.879: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 24 02:16:28.879: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 24 02:16:28.884: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 24 02:16:38.890: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 24 02:16:38.890: INFO: Waiting for statefulset status.replicas updated to 0
Dec 24 02:16:38.907: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Dec 24 02:16:38.907: INFO: ss-0  ip-172-16-44-108.ec2.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:18 +0000 UTC  }]
Dec 24 02:16:38.907: INFO: 
Dec 24 02:16:38.907: INFO: StatefulSet ss has not reached scale 3, at 1
Dec 24 02:16:39.912: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995974143s
Dec 24 02:16:40.917: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990817762s
Dec 24 02:16:41.922: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985948345s
Dec 24 02:16:42.928: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980977234s
Dec 24 02:16:43.933: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.975033054s
Dec 24 02:16:44.938: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.969977784s
Dec 24 02:16:45.943: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.964928491s
Dec 24 02:16:46.949: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.96012208s
Dec 24 02:16:47.959: INFO: Verifying statefulset ss doesn't scale past 3 for another 953.797534ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3278
Dec 24 02:16:48.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=statefulset-3278 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 24 02:16:49.218: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 24 02:16:49.218: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 24 02:16:49.218: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 24 02:16:49.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=statefulset-3278 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 24 02:16:49.458: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 24 02:16:49.459: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 24 02:16:49.459: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 24 02:16:49.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=statefulset-3278 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 24 02:16:49.679: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 24 02:16:49.679: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 24 02:16:49.679: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 24 02:16:49.685: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 24 02:16:49.685: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 24 02:16:49.685: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec 24 02:16:49.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=statefulset-3278 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 24 02:16:49.957: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 24 02:16:49.957: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 24 02:16:49.957: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 24 02:16:49.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=statefulset-3278 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 24 02:16:50.224: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 24 02:16:50.224: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 24 02:16:50.224: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 24 02:16:50.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=statefulset-3278 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 24 02:16:50.447: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 24 02:16:50.447: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 24 02:16:50.447: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 24 02:16:50.447: INFO: Waiting for statefulset status.replicas updated to 0
Dec 24 02:16:50.453: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec 24 02:17:00.463: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 24 02:17:00.463: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 24 02:17:00.463: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 24 02:17:00.481: INFO: POD   NODE                            PHASE    GRACE  CONDITIONS
Dec 24 02:17:00.481: INFO: ss-0  ip-172-16-44-108.ec2.internal   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:18 +0000 UTC  }]
Dec 24 02:17:00.481: INFO: ss-1  ip-172-16-30-121.ec2.internal   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:38 +0000 UTC  }]
Dec 24 02:17:00.481: INFO: ss-2  ip-172-16-103-244.ec2.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:38 +0000 UTC  }]
Dec 24 02:17:00.481: INFO: 
Dec 24 02:17:00.481: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 24 02:17:01.486: INFO: POD   NODE                            PHASE    GRACE  CONDITIONS
Dec 24 02:17:01.486: INFO: ss-0  ip-172-16-44-108.ec2.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:18 +0000 UTC  }]
Dec 24 02:17:01.486: INFO: ss-1  ip-172-16-30-121.ec2.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:38 +0000 UTC  }]
Dec 24 02:17:01.487: INFO: ss-2  ip-172-16-103-244.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:38 +0000 UTC  }]
Dec 24 02:17:01.487: INFO: 
Dec 24 02:17:01.487: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 24 02:17:02.492: INFO: POD   NODE                            PHASE    GRACE  CONDITIONS
Dec 24 02:17:02.492: INFO: ss-0  ip-172-16-44-108.ec2.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:18 +0000 UTC  }]
Dec 24 02:17:02.492: INFO: ss-1  ip-172-16-30-121.ec2.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:38 +0000 UTC  }]
Dec 24 02:17:02.492: INFO: ss-2  ip-172-16-103-244.ec2.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:38 +0000 UTC  }]
Dec 24 02:17:02.492: INFO: 
Dec 24 02:17:02.492: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 24 02:17:03.496: INFO: POD   NODE                            PHASE    GRACE  CONDITIONS
Dec 24 02:17:03.496: INFO: ss-0  ip-172-16-44-108.ec2.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:18 +0000 UTC  }]
Dec 24 02:17:03.496: INFO: ss-1  ip-172-16-30-121.ec2.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:38 +0000 UTC  }]
Dec 24 02:17:03.496: INFO: ss-2  ip-172-16-103-244.ec2.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:38 +0000 UTC  }]
Dec 24 02:17:03.496: INFO: 
Dec 24 02:17:03.496: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 24 02:17:04.501: INFO: POD   NODE                            PHASE    GRACE  CONDITIONS
Dec 24 02:17:04.501: INFO: ss-0  ip-172-16-44-108.ec2.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:18 +0000 UTC  }]
Dec 24 02:17:04.501: INFO: ss-1  ip-172-16-30-121.ec2.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:38 +0000 UTC  }]
Dec 24 02:17:04.501: INFO: ss-2  ip-172-16-103-244.ec2.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:38 +0000 UTC  }]
Dec 24 02:17:04.501: INFO: 
Dec 24 02:17:04.501: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 24 02:17:05.507: INFO: POD   NODE                            PHASE    GRACE  CONDITIONS
Dec 24 02:17:05.507: INFO: ss-0  ip-172-16-44-108.ec2.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:18 +0000 UTC  }]
Dec 24 02:17:05.507: INFO: ss-2  ip-172-16-103-244.ec2.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:38 +0000 UTC  }]
Dec 24 02:17:05.507: INFO: 
Dec 24 02:17:05.507: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 24 02:17:06.512: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Dec 24 02:17:06.512: INFO: ss-0  ip-172-16-44-108.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:18 +0000 UTC  }]
Dec 24 02:17:06.512: INFO: 
Dec 24 02:17:06.512: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 24 02:17:07.518: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Dec 24 02:17:07.518: INFO: ss-0  ip-172-16-44-108.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:18 +0000 UTC  }]
Dec 24 02:17:07.518: INFO: 
Dec 24 02:17:07.518: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 24 02:17:08.532: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Dec 24 02:17:08.532: INFO: ss-0  ip-172-16-44-108.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-24 02:16:18 +0000 UTC  }]
Dec 24 02:17:08.532: INFO: 
Dec 24 02:17:08.532: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 24 02:17:09.537: INFO: Verifying statefulset ss doesn't scale past 0 for another 944.205164ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3278
Dec 24 02:17:10.542: INFO: Scaling statefulset ss to 0
Dec 24 02:17:10.555: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 24 02:17:10.558: INFO: Deleting all statefulset in ns statefulset-3278
Dec 24 02:17:10.562: INFO: Scaling statefulset ss to 0
Dec 24 02:17:10.573: INFO: Waiting for statefulset status.replicas updated to 0
Dec 24 02:17:10.577: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:17:10.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3278" for this suite.
Dec 24 02:17:16.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:17:16.738: INFO: namespace statefulset-3278 deletion completed in 6.138451266s

• [SLOW TEST:58.316 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:17:16.738: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1517
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 24 02:17:16.897: INFO: Waiting up to 5m0s for pod "pod-b2e6ad99-fb65-41b0-bd03-157d5a51f54d" in namespace "emptydir-1517" to be "success or failure"
Dec 24 02:17:16.902: INFO: Pod "pod-b2e6ad99-fb65-41b0-bd03-157d5a51f54d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.175138ms
Dec 24 02:17:18.907: INFO: Pod "pod-b2e6ad99-fb65-41b0-bd03-157d5a51f54d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009898793s
Dec 24 02:17:20.912: INFO: Pod "pod-b2e6ad99-fb65-41b0-bd03-157d5a51f54d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014370298s
STEP: Saw pod success
Dec 24 02:17:20.912: INFO: Pod "pod-b2e6ad99-fb65-41b0-bd03-157d5a51f54d" satisfied condition "success or failure"
Dec 24 02:17:20.915: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-b2e6ad99-fb65-41b0-bd03-157d5a51f54d container test-container: <nil>
STEP: delete the pod
Dec 24 02:17:20.950: INFO: Waiting for pod pod-b2e6ad99-fb65-41b0-bd03-157d5a51f54d to disappear
Dec 24 02:17:20.953: INFO: Pod pod-b2e6ad99-fb65-41b0-bd03-157d5a51f54d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:17:20.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1517" for this suite.
Dec 24 02:17:26.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:17:27.098: INFO: namespace emptydir-1517 deletion completed in 6.138233019s

• [SLOW TEST:10.360 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:17:27.098: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2582
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 02:17:27.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 version'
Dec 24 02:17:27.317: INFO: stderr: ""
Dec 24 02:17:27.317: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.4\", GitCommit:\"224be7bdce5a9dd0c2fd0d46b83865648e2fe0ba\", GitTreeState:\"clean\", BuildDate:\"2019-12-11T12:47:40Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.4\", GitCommit:\"224be7bdce5a9dd0c2fd0d46b83865648e2fe0ba\", GitTreeState:\"clean\", BuildDate:\"2019-12-11T12:37:43Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:17:27.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2582" for this suite.
Dec 24 02:17:33.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:17:33.500: INFO: namespace kubectl-2582 deletion completed in 6.177460223s

• [SLOW TEST:6.403 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:17:33.501: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-459
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 24 02:17:38.227: INFO: Successfully updated pod "annotationupdateb896181f-480a-435f-bf50-6212e2253908"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:17:40.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-459" for this suite.
Dec 24 02:17:56.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:17:56.395: INFO: namespace downward-api-459 deletion completed in 16.140761088s

• [SLOW TEST:22.895 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:17:56.395: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8800
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Dec 24 02:17:56.549: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Dec 24 02:18:15.275: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 02:18:23.979: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:18:43.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8800" for this suite.
Dec 24 02:18:49.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:18:49.179: INFO: namespace crd-publish-openapi-8800 deletion completed in 6.149322209s

• [SLOW TEST:52.784 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:18:49.180: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3519
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3519.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3519.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 24 02:19:03.414: INFO: DNS probes using dns-3519/dns-test-41feca80-6257-40fe-88f8-6a56f5638dac succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:19:03.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3519" for this suite.
Dec 24 02:19:09.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:19:09.586: INFO: namespace dns-3519 deletion completed in 6.146027441s

• [SLOW TEST:20.406 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:19:09.586: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-3516
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 02:19:09.769: INFO: (0) /api/v1/nodes/ip-172-16-103-244.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 17.789244ms)
Dec 24 02:19:09.774: INFO: (1) /api/v1/nodes/ip-172-16-103-244.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.383415ms)
Dec 24 02:19:09.780: INFO: (2) /api/v1/nodes/ip-172-16-103-244.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.579544ms)
Dec 24 02:19:09.786: INFO: (3) /api/v1/nodes/ip-172-16-103-244.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.648189ms)
Dec 24 02:19:09.791: INFO: (4) /api/v1/nodes/ip-172-16-103-244.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.888932ms)
Dec 24 02:19:09.801: INFO: (5) /api/v1/nodes/ip-172-16-103-244.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 10.801303ms)
Dec 24 02:19:09.809: INFO: (6) /api/v1/nodes/ip-172-16-103-244.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 7.658805ms)
Dec 24 02:19:09.816: INFO: (7) /api/v1/nodes/ip-172-16-103-244.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 6.907282ms)
Dec 24 02:19:09.822: INFO: (8) /api/v1/nodes/ip-172-16-103-244.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.287071ms)
Dec 24 02:19:09.827: INFO: (9) /api/v1/nodes/ip-172-16-103-244.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.980566ms)
Dec 24 02:19:09.832: INFO: (10) /api/v1/nodes/ip-172-16-103-244.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.65273ms)
Dec 24 02:19:09.838: INFO: (11) /api/v1/nodes/ip-172-16-103-244.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 6.090198ms)
Dec 24 02:19:09.844: INFO: (12) /api/v1/nodes/ip-172-16-103-244.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.346793ms)
Dec 24 02:19:09.849: INFO: (13) /api/v1/nodes/ip-172-16-103-244.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.634587ms)
Dec 24 02:19:09.855: INFO: (14) /api/v1/nodes/ip-172-16-103-244.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.569903ms)
Dec 24 02:19:09.860: INFO: (15) /api/v1/nodes/ip-172-16-103-244.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.951748ms)
Dec 24 02:19:09.865: INFO: (16) /api/v1/nodes/ip-172-16-103-244.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.381919ms)
Dec 24 02:19:09.871: INFO: (17) /api/v1/nodes/ip-172-16-103-244.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.472631ms)
Dec 24 02:19:09.876: INFO: (18) /api/v1/nodes/ip-172-16-103-244.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.082013ms)
Dec 24 02:19:09.882: INFO: (19) /api/v1/nodes/ip-172-16-103-244.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.980444ms)
[AfterEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:19:09.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3516" for this suite.
Dec 24 02:19:15.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:19:16.027: INFO: namespace proxy-3516 deletion completed in 6.137500528s

• [SLOW TEST:6.441 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:19:16.027: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-5604
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 24 02:19:16.180: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 24 02:19:16.196: INFO: Waiting for terminating namespaces to be deleted...
Dec 24 02:19:16.200: INFO: 
Logging pods the kubelet thinks is on node ip-172-16-103-244.ec2.internal before test
Dec 24 02:19:16.212: INFO: kube-proxy-7e590abedfb7de51d1197b20e754686a6a8674ae8ac79bc64dcfdc0bb67fb64f-ip-172-16-103-244.ec2.internal from kube-system started at 2019-12-23 15:43:16 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.212: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 24 02:19:16.212: INFO: kublr-logging-rabbitmq-0 from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.212: INFO: 	Container rabbitmq ready: true, restart count 0
Dec 24 02:19:16.212: INFO: kublr-monitoring-prometheus-59564b557d-pkjhv from kublr started at 2019-12-23 15:46:15 +0000 UTC (2 container statuses recorded)
Dec 24 02:19:16.212: INFO: 	Container keycloak-proxy ready: true, restart count 4
Dec 24 02:19:16.212: INFO: 	Container prometheus ready: true, restart count 6
Dec 24 02:19:16.212: INFO: kublr-node-name-reporter-b5f50899e00ed5b8ad1b215b812381270bf0779993c3a6740826f2cfb378f08f-ip-172-16-103-244.ec2.internal from kube-system started at 2019-12-23 15:43:16 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.212: INFO: 	Container main ready: true, restart count 0
Dec 24 02:19:16.212: INFO: node-local-dns-hw2d5 from kube-system started at 2019-12-23 15:44:27 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.212: INFO: 	Container node-cache ready: true, restart count 0
Dec 24 02:19:16.212: INFO: kublr-logging-fluentd-es-7rd6f from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.212: INFO: 	Container fluentd-es ready: true, restart count 4
Dec 24 02:19:16.212: INFO: kublr-logging-elasticsearch-client-6f7d56fdbb-zgnhd from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.212: INFO: 	Container elasticsearch ready: true, restart count 0
Dec 24 02:19:16.212: INFO: kublr-monitoring-grafana-6fbbfc98f4-n9zw5 from kublr started at 2019-12-23 15:46:15 +0000 UTC (3 container statuses recorded)
Dec 24 02:19:16.212: INFO: 	Container grafana ready: true, restart count 0
Dec 24 02:19:16.212: INFO: 	Container keycloak-proxy ready: true, restart count 4
Dec 24 02:19:16.212: INFO: 	Container nginx-proxy ready: true, restart count 0
Dec 24 02:19:16.212: INFO: sonobuoy-systemd-logs-daemon-set-eb45748a27ab4169-h9v2w from sonobuoy started at 2019-12-24 01:19:59 +0000 UTC (2 container statuses recorded)
Dec 24 02:19:16.212: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 24 02:19:16.212: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 24 02:19:16.212: INFO: kublr-ingress-nginx-ingress-controller-849b4769fc-79bhq from kube-system started at 2019-12-23 15:45:19 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.212: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec 24 02:19:16.212: INFO: kublr-ingress-nginx-ingress-default-backend-7b84f6bc4b-xr9cg from kube-system started at 2019-12-23 15:45:19 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.212: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
Dec 24 02:19:16.212: INFO: k8s-api-haproxy-de80cb1199e732ef3c9ca0051c41dd966f81ca8bee9c571b76dea5e659c7b97b-ip-172-16-103-244.ec2.internal from kube-system started at 2019-12-23 15:43:16 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.212: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Dec 24 02:19:16.212: INFO: canal-d28dx from kube-system started at 2019-12-23 15:44:11 +0000 UTC (4 container statuses recorded)
Dec 24 02:19:16.212: INFO: 	Container calico-node ready: true, restart count 0
Dec 24 02:19:16.212: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 24 02:19:16.212: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Dec 24 02:19:16.212: INFO: 	Container update-network-condition ready: true, restart count 0
Dec 24 02:19:16.212: INFO: kublr-logging-controller-7f5d56f594-rq5fl from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.212: INFO: 	Container kublr-feature-logging ready: true, restart count 0
Dec 24 02:19:16.212: INFO: kublr-monitoring-alertmanager-549cf5f44c-fbdlf from kublr started at 2019-12-23 15:46:09 +0000 UTC (2 container statuses recorded)
Dec 24 02:19:16.212: INFO: 	Container alertmanager ready: true, restart count 0
Dec 24 02:19:16.212: INFO: 	Container keycloak-proxy ready: true, restart count 4
Dec 24 02:19:16.212: INFO: 
Logging pods the kubelet thinks is on node ip-172-16-30-121.ec2.internal before test
Dec 24 02:19:16.234: INFO: heapster-v1.6.0-beta.1-5f6b4bf99b-bxcwv from kube-system started at 2019-12-23 15:44:31 +0000 UTC (2 container statuses recorded)
Dec 24 02:19:16.234: INFO: 	Container heapster ready: true, restart count 0
Dec 24 02:19:16.234: INFO: 	Container heapster-nanny ready: true, restart count 0
Dec 24 02:19:16.234: INFO: kcp-kublr-ui-5d5fbd8dc5-mxf6z from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.234: INFO: 	Container kublr-ui ready: true, restart count 0
Dec 24 02:19:16.234: INFO: kube-proxy-7e590abedfb7de51d1197b20e754686a6a8674ae8ac79bc64dcfdc0bb67fb64f-ip-172-16-30-121.ec2.internal from kube-system started at 2019-12-23 15:43:25 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.234: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 24 02:19:16.234: INFO: kublr-logging-sg-job-kqg5q from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.234: INFO: 	Container certgenerator ready: false, restart count 0
Dec 24 02:19:16.234: INFO: kcp-cluster-controller-846969f94d-998fm from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.234: INFO: 	Container cluster-controller ready: true, restart count 0
Dec 24 02:19:16.234: INFO: sonobuoy from sonobuoy started at 2019-12-24 01:19:56 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.234: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 24 02:19:16.234: INFO: k8s-api-haproxy-429d71c9c9d8df433e1397ffb7b8d70c5c9c56d08dcdf3f6b2e0fe52606e3c6f-ip-172-16-30-121.ec2.internal from kube-system started at 2019-12-23 15:43:25 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.234: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Dec 24 02:19:16.234: INFO: kublr-logging-fluentd-es-nc4f7 from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.234: INFO: 	Container fluentd-es ready: true, restart count 4
Dec 24 02:19:16.234: INFO: kcp-app-mongodb-789bf97977-lckdz from kublr started at 2019-12-23 15:46:21 +0000 UTC (2 container statuses recorded)
Dec 24 02:19:16.234: INFO: 	Container mongo ready: true, restart count 0
Dec 24 02:19:16.234: INFO: 	Container mongo-exporter ready: true, restart count 0
Dec 24 02:19:16.234: INFO: kublr-node-name-reporter-c6710394cb2609cca16a8c87ff84cdb8044d9d6e9239ff3abcfbaa4768a4122f-ip-172-16-30-121.ec2.internal from kube-system started at 2019-12-23 15:43:25 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.234: INFO: 	Container main ready: true, restart count 0
Dec 24 02:19:16.234: INFO: kcp-app-mysql-549dd84b74-pd89v from kublr started at 2019-12-23 15:46:21 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.234: INFO: 	Container kcp-app-mysql ready: true, restart count 0
Dec 24 02:19:16.234: INFO: sonobuoy-systemd-logs-daemon-set-eb45748a27ab4169-v9f85 from sonobuoy started at 2019-12-24 01:19:59 +0000 UTC (2 container statuses recorded)
Dec 24 02:19:16.234: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 24 02:19:16.234: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 24 02:19:16.234: INFO: kublr-logging-curator-1577149200-nkjhl from kublr started at 2019-12-24 01:00:01 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.234: INFO: 	Container curator ready: false, restart count 0
Dec 24 02:19:16.234: INFO: canal-7sp7t from kube-system started at 2019-12-23 15:44:11 +0000 UTC (4 container statuses recorded)
Dec 24 02:19:16.234: INFO: 	Container calico-node ready: true, restart count 0
Dec 24 02:19:16.234: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 24 02:19:16.234: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Dec 24 02:19:16.234: INFO: 	Container update-network-condition ready: true, restart count 0
Dec 24 02:19:16.234: INFO: tiller-deploy-db48c564c-gj6vz from kube-system started at 2019-12-23 15:44:34 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.234: INFO: 	Container tiller ready: true, restart count 0
Dec 24 02:19:16.234: INFO: kublr-logging-elasticsearch-master-0 from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.234: INFO: 	Container elasticsearch ready: true, restart count 0
Dec 24 02:19:16.234: INFO: kublr-monitoring-kube-state-metrics-5ff6484cf7-bltmp from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.234: INFO: 	Container kubestatemetrics ready: true, restart count 0
Dec 24 02:19:16.234: INFO: kublr-monitoring-monitoring-controller-66578cf88c-fb2gk from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.234: INFO: 	Container app-monitoring ready: true, restart count 0
Dec 24 02:19:16.234: INFO: kcp-generator-6bd556bcf6-dmqbq from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.234: INFO: 	Container generator ready: true, restart count 0
Dec 24 02:19:16.234: INFO: node-local-dns-jq8bl from kube-system started at 2019-12-23 15:44:27 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.234: INFO: 	Container node-cache ready: true, restart count 0
Dec 24 02:19:16.234: INFO: kublr-logging-kibana-5d84bc784d-gfh6r from kublr started at 2019-12-23 15:46:03 +0000 UTC (4 container statuses recorded)
Dec 24 02:19:16.234: INFO: 	Container keycloak-proxy ready: true, restart count 0
Dec 24 02:19:16.234: INFO: 	Container kibana ready: true, restart count 0
Dec 24 02:19:16.234: INFO: 	Container nginx-proxy ready: true, restart count 0
Dec 24 02:19:16.234: INFO: 	Container sg-auth-proxy ready: true, restart count 0
Dec 24 02:19:16.234: INFO: kcp-backup-controller-6894dbfd9f-mxv6r from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.234: INFO: 	Container backup-controller ready: true, restart count 0
Dec 24 02:19:16.234: INFO: 
Logging pods the kubelet thinks is on node ip-172-16-44-108.ec2.internal before test
Dec 24 02:19:16.262: INFO: kublr-node-name-reporter-be88daf430a9d4815e9777fe7bdbbdded5de4e21fb88257b9dc4b4a05304fcee-ip-172-16-44-108.ec2.internal from kube-system started at 2019-12-23 15:43:19 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.262: INFO: 	Container main ready: true, restart count 0
Dec 24 02:19:16.262: INFO: k8s-api-haproxy-de80cb1199e732ef3c9ca0051c41dd966f81ca8bee9c571b76dea5e659c7b97b-ip-172-16-44-108.ec2.internal from kube-system started at 2019-12-23 15:43:19 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.262: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Dec 24 02:19:16.262: INFO: canal-rxhg5 from kube-system started at 2019-12-23 15:44:11 +0000 UTC (4 container statuses recorded)
Dec 24 02:19:16.262: INFO: 	Container calico-node ready: true, restart count 0
Dec 24 02:19:16.262: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 24 02:19:16.262: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Dec 24 02:19:16.262: INFO: 	Container update-network-condition ready: true, restart count 0
Dec 24 02:19:16.262: INFO: node-local-dns-dzntt from kube-system started at 2019-12-23 15:44:27 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.262: INFO: 	Container node-cache ready: true, restart count 0
Dec 24 02:19:16.262: INFO: kubernetes-dashboard-84cb747b5c-td8jl from kubernetes-dashboard started at 2019-12-23 15:44:31 +0000 UTC (2 container statuses recorded)
Dec 24 02:19:16.262: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec 24 02:19:16.262: INFO: 	Container kubernetes-dashboard-auth-proxy ready: true, restart count 0
Dec 24 02:19:16.262: INFO: kublr-system-shell-6f4bcb9487-n9swc from kube-system started at 2019-12-23 15:45:12 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.262: INFO: 	Container shell ready: true, restart count 0
Dec 24 02:19:16.262: INFO: kublr-logging-elasticsearch-exporter-78df7c8987-w7b6q from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.262: INFO: 	Container main ready: true, restart count 0
Dec 24 02:19:16.262: INFO: kublr-logging-elasticsearch-data-0 from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.262: INFO: 	Container elasticsearch ready: true, restart count 0
Dec 24 02:19:16.262: INFO: kcp-kublr-api-6b7d4bc968-kd9pb from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.262: INFO: 	Container kublr-api ready: true, restart count 0
Dec 24 02:19:16.262: INFO: sonobuoy-systemd-logs-daemon-set-eb45748a27ab4169-wpzc6 from sonobuoy started at 2019-12-24 01:19:59 +0000 UTC (2 container statuses recorded)
Dec 24 02:19:16.262: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 24 02:19:16.262: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 24 02:19:16.262: INFO: kublr-logging-logstash-547687bcdc-vdg4k from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.262: INFO: 	Container logstash ready: true, restart count 0
Dec 24 02:19:16.262: INFO: kube-proxy-7e590abedfb7de51d1197b20e754686a6a8674ae8ac79bc64dcfdc0bb67fb64f-ip-172-16-44-108.ec2.internal from kube-system started at 2019-12-23 15:43:19 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.262: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 24 02:19:16.262: INFO: sonobuoy-e2e-job-457b3e5a99034c4d from sonobuoy started at 2019-12-24 01:19:59 +0000 UTC (2 container statuses recorded)
Dec 24 02:19:16.262: INFO: 	Container e2e ready: true, restart count 0
Dec 24 02:19:16.262: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 24 02:19:16.262: INFO: kublr-logging-fluentd-es-bpbg6 from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.262: INFO: 	Container fluentd-es ready: true, restart count 4
Dec 24 02:19:16.262: INFO: kublr-logging-rabbitmq-exporter-dc6b44ccd-6r8ks from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.262: INFO: 	Container kublr-logging-rabbitmq-exporter ready: true, restart count 0
Dec 24 02:19:16.262: INFO: kcp-keycloak-0 from kublr started at 2019-12-23 15:46:15 +0000 UTC (2 container statuses recorded)
Dec 24 02:19:16.262: INFO: 	Container init-keycloak ready: true, restart count 0
Dec 24 02:19:16.262: INFO: 	Container kcp-keycloak ready: true, restart count 0
Dec 24 02:19:16.262: INFO: kcp-terraform-controller-6f447b77d7-v69lk from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:19:16.262: INFO: 	Container terraform-controller ready: true, restart count 0
Dec 24 02:19:16.262: INFO: metrics-server-v0.3.6-86567757d-7d792 from kube-system started at 2019-12-23 17:20:18 +0000 UTC (2 container statuses recorded)
Dec 24 02:19:16.262: INFO: 	Container metrics-server ready: true, restart count 0
Dec 24 02:19:16.262: INFO: 	Container metrics-server-nanny ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-c5a3877b-0838-45ac-8170-2ab9f77f5ade 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-c5a3877b-0838-45ac-8170-2ab9f77f5ade off the node ip-172-16-44-108.ec2.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-c5a3877b-0838-45ac-8170-2ab9f77f5ade
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:24:24.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5604" for this suite.
Dec 24 02:24:34.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:24:34.589: INFO: namespace sched-pred-5604 deletion completed in 10.175663314s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:318.562 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:24:34.590: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-6756
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Dec 24 02:24:34.744: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:24:57.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6756" for this suite.
Dec 24 02:25:03.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:25:04.137: INFO: namespace crd-publish-openapi-6756 deletion completed in 6.174306509s

• [SLOW TEST:29.548 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:25:04.138: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2358
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-c7e5dbaf-c9b7-4250-90d9-4774919b8bc9
STEP: Creating secret with name s-test-opt-upd-62524d96-3806-4daa-9d8e-1305192c4548
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-c7e5dbaf-c9b7-4250-90d9-4774919b8bc9
STEP: Updating secret s-test-opt-upd-62524d96-3806-4daa-9d8e-1305192c4548
STEP: Creating secret with name s-test-opt-create-98895bd3-3fe1-496b-8e2c-ad7b2d02e956
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:25:12.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2358" for this suite.
Dec 24 02:25:24.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:25:24.668: INFO: namespace secrets-2358 deletion completed in 12.166000585s

• [SLOW TEST:20.530 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:25:24.668: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7962
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 24 02:25:24.827: INFO: Waiting up to 5m0s for pod "pod-4d53ca31-2fef-43e6-947a-77889f2079d9" in namespace "emptydir-7962" to be "success or failure"
Dec 24 02:25:24.836: INFO: Pod "pod-4d53ca31-2fef-43e6-947a-77889f2079d9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.834594ms
Dec 24 02:25:26.842: INFO: Pod "pod-4d53ca31-2fef-43e6-947a-77889f2079d9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014493737s
Dec 24 02:25:28.848: INFO: Pod "pod-4d53ca31-2fef-43e6-947a-77889f2079d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020947289s
STEP: Saw pod success
Dec 24 02:25:28.848: INFO: Pod "pod-4d53ca31-2fef-43e6-947a-77889f2079d9" satisfied condition "success or failure"
Dec 24 02:25:28.851: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod pod-4d53ca31-2fef-43e6-947a-77889f2079d9 container test-container: <nil>
STEP: delete the pod
Dec 24 02:25:28.883: INFO: Waiting for pod pod-4d53ca31-2fef-43e6-947a-77889f2079d9 to disappear
Dec 24 02:25:28.887: INFO: Pod pod-4d53ca31-2fef-43e6-947a-77889f2079d9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:25:28.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7962" for this suite.
Dec 24 02:25:34.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:25:35.096: INFO: namespace emptydir-7962 deletion completed in 6.200278867s

• [SLOW TEST:10.430 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:25:35.100: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2794
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 24 02:25:43.332: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 24 02:25:43.336: INFO: Pod pod-with-poststart-http-hook still exists
Dec 24 02:25:45.336: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 24 02:25:45.342: INFO: Pod pod-with-poststart-http-hook still exists
Dec 24 02:25:47.336: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 24 02:25:47.340: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:25:47.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2794" for this suite.
Dec 24 02:25:59.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:25:59.516: INFO: namespace container-lifecycle-hook-2794 deletion completed in 12.170001159s

• [SLOW TEST:24.416 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:25:59.518: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3203
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3203
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-3203
STEP: Creating statefulset with conflicting port in namespace statefulset-3203
STEP: Waiting until pod test-pod will start running in namespace statefulset-3203
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3203
Dec 24 02:26:03.731: INFO: Observed stateful pod in namespace: statefulset-3203, name: ss-0, uid: d18fc638-4087-4379-8a92-afc92f6aa408, status phase: Pending. Waiting for statefulset controller to delete.
Dec 24 02:26:05.968: INFO: Observed stateful pod in namespace: statefulset-3203, name: ss-0, uid: d18fc638-4087-4379-8a92-afc92f6aa408, status phase: Failed. Waiting for statefulset controller to delete.
Dec 24 02:26:05.978: INFO: Observed stateful pod in namespace: statefulset-3203, name: ss-0, uid: d18fc638-4087-4379-8a92-afc92f6aa408, status phase: Failed. Waiting for statefulset controller to delete.
Dec 24 02:26:05.997: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3203
STEP: Removing pod with conflicting port in namespace statefulset-3203
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3203 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 24 02:26:10.043: INFO: Deleting all statefulset in ns statefulset-3203
Dec 24 02:26:10.047: INFO: Scaling statefulset ss to 0
Dec 24 02:26:20.069: INFO: Waiting for statefulset status.replicas updated to 0
Dec 24 02:26:20.074: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:26:20.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3203" for this suite.
Dec 24 02:26:26.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:26:26.292: INFO: namespace statefulset-3203 deletion completed in 6.181687441s

• [SLOW TEST:26.773 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:26:26.292: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5450
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Dec 24 02:26:26.440: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 02:26:35.105: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:26:53.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5450" for this suite.
Dec 24 02:26:59.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:26:59.904: INFO: namespace crd-publish-openapi-5450 deletion completed in 6.191586853s

• [SLOW TEST:33.612 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:26:59.904: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6040
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 02:27:00.097: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec 24 02:27:00.110: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:00.110: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:00.110: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:00.115: INFO: Number of nodes with available pods: 0
Dec 24 02:27:00.115: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 02:27:01.127: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:01.127: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:01.127: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:01.131: INFO: Number of nodes with available pods: 0
Dec 24 02:27:01.131: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 02:27:02.122: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:02.122: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:02.122: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:02.127: INFO: Number of nodes with available pods: 0
Dec 24 02:27:02.127: INFO: Node ip-172-16-103-244.ec2.internal is running more than one daemon pod
Dec 24 02:27:03.121: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:03.121: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:03.121: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:03.126: INFO: Number of nodes with available pods: 3
Dec 24 02:27:03.126: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec 24 02:27:03.157: INFO: Wrong image for pod: daemon-set-66cvl. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:03.157: INFO: Wrong image for pod: daemon-set-qwk8n. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:03.157: INFO: Wrong image for pod: daemon-set-rgh67. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:03.163: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:03.163: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:03.163: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:04.168: INFO: Wrong image for pod: daemon-set-66cvl. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:04.168: INFO: Wrong image for pod: daemon-set-qwk8n. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:04.168: INFO: Wrong image for pod: daemon-set-rgh67. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:04.174: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:04.174: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:04.174: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:05.168: INFO: Wrong image for pod: daemon-set-66cvl. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:05.168: INFO: Wrong image for pod: daemon-set-qwk8n. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:05.168: INFO: Wrong image for pod: daemon-set-rgh67. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:05.176: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:05.176: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:05.176: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:06.168: INFO: Wrong image for pod: daemon-set-66cvl. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:06.168: INFO: Wrong image for pod: daemon-set-qwk8n. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:06.168: INFO: Wrong image for pod: daemon-set-rgh67. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:06.168: INFO: Pod daemon-set-rgh67 is not available
Dec 24 02:27:06.174: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:06.174: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:06.174: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:07.168: INFO: Wrong image for pod: daemon-set-66cvl. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:07.168: INFO: Wrong image for pod: daemon-set-qwk8n. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:07.168: INFO: Wrong image for pod: daemon-set-rgh67. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:07.168: INFO: Pod daemon-set-rgh67 is not available
Dec 24 02:27:07.174: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:07.174: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:07.174: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:08.167: INFO: Wrong image for pod: daemon-set-66cvl. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:08.167: INFO: Wrong image for pod: daemon-set-qwk8n. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:08.167: INFO: Wrong image for pod: daemon-set-rgh67. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:08.167: INFO: Pod daemon-set-rgh67 is not available
Dec 24 02:27:08.173: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:08.173: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:08.173: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:09.168: INFO: Wrong image for pod: daemon-set-66cvl. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:09.168: INFO: Wrong image for pod: daemon-set-qwk8n. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:09.168: INFO: Wrong image for pod: daemon-set-rgh67. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:09.168: INFO: Pod daemon-set-rgh67 is not available
Dec 24 02:27:09.173: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:09.173: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:09.173: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:10.185: INFO: Pod daemon-set-2rkdn is not available
Dec 24 02:27:10.185: INFO: Wrong image for pod: daemon-set-66cvl. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:10.185: INFO: Wrong image for pod: daemon-set-qwk8n. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:10.209: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:10.209: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:10.209: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:11.167: INFO: Pod daemon-set-2rkdn is not available
Dec 24 02:27:11.167: INFO: Wrong image for pod: daemon-set-66cvl. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:11.167: INFO: Wrong image for pod: daemon-set-qwk8n. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:11.173: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:11.173: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:11.173: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:12.167: INFO: Wrong image for pod: daemon-set-66cvl. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:12.167: INFO: Wrong image for pod: daemon-set-qwk8n. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:12.172: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:12.172: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:12.173: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:13.168: INFO: Wrong image for pod: daemon-set-66cvl. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:13.168: INFO: Pod daemon-set-66cvl is not available
Dec 24 02:27:13.168: INFO: Wrong image for pod: daemon-set-qwk8n. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:13.173: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:13.173: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:13.173: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:14.168: INFO: Wrong image for pod: daemon-set-66cvl. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:14.168: INFO: Pod daemon-set-66cvl is not available
Dec 24 02:27:14.168: INFO: Wrong image for pod: daemon-set-qwk8n. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:14.174: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:14.174: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:14.174: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:15.168: INFO: Wrong image for pod: daemon-set-66cvl. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:15.168: INFO: Pod daemon-set-66cvl is not available
Dec 24 02:27:15.168: INFO: Wrong image for pod: daemon-set-qwk8n. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:15.173: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:15.174: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:15.174: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:16.168: INFO: Pod daemon-set-9mldh is not available
Dec 24 02:27:16.168: INFO: Wrong image for pod: daemon-set-qwk8n. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:16.174: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:16.174: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:16.174: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:17.168: INFO: Pod daemon-set-9mldh is not available
Dec 24 02:27:17.168: INFO: Wrong image for pod: daemon-set-qwk8n. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:17.172: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:17.173: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:17.173: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:18.168: INFO: Wrong image for pod: daemon-set-qwk8n. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:18.173: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:18.173: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:18.173: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:19.167: INFO: Wrong image for pod: daemon-set-qwk8n. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:19.173: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:19.173: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:19.173: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:20.168: INFO: Wrong image for pod: daemon-set-qwk8n. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:20.168: INFO: Pod daemon-set-qwk8n is not available
Dec 24 02:27:20.174: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:20.174: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:20.174: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:21.168: INFO: Wrong image for pod: daemon-set-qwk8n. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:21.168: INFO: Pod daemon-set-qwk8n is not available
Dec 24 02:27:21.173: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:21.173: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:21.173: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:22.167: INFO: Wrong image for pod: daemon-set-qwk8n. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:22.167: INFO: Pod daemon-set-qwk8n is not available
Dec 24 02:27:22.173: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:22.173: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:22.173: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:23.168: INFO: Wrong image for pod: daemon-set-qwk8n. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:23.168: INFO: Pod daemon-set-qwk8n is not available
Dec 24 02:27:23.174: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:23.174: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:23.174: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:24.168: INFO: Wrong image for pod: daemon-set-qwk8n. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:24.168: INFO: Pod daemon-set-qwk8n is not available
Dec 24 02:27:24.174: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:24.174: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:24.174: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:25.167: INFO: Wrong image for pod: daemon-set-qwk8n. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 24 02:27:25.167: INFO: Pod daemon-set-qwk8n is not available
Dec 24 02:27:25.173: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:25.173: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:25.173: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:26.168: INFO: Pod daemon-set-czsdd is not available
Dec 24 02:27:26.173: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:26.173: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:26.173: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Dec 24 02:27:26.178: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:26.178: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:26.178: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:26.182: INFO: Number of nodes with available pods: 2
Dec 24 02:27:26.182: INFO: Node ip-172-16-30-121.ec2.internal is running more than one daemon pod
Dec 24 02:27:27.188: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:27.188: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:27.188: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:27.196: INFO: Number of nodes with available pods: 2
Dec 24 02:27:27.196: INFO: Node ip-172-16-30-121.ec2.internal is running more than one daemon pod
Dec 24 02:27:28.189: INFO: DaemonSet pods can't tolerate node ip-172-16-12-106.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:28.189: INFO: DaemonSet pods can't tolerate node ip-172-16-3-70.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:28.189: INFO: DaemonSet pods can't tolerate node ip-172-16-5-37.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 24 02:27:28.193: INFO: Number of nodes with available pods: 3
Dec 24 02:27:28.193: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6040, will wait for the garbage collector to delete the pods
Dec 24 02:27:28.278: INFO: Deleting DaemonSet.extensions daemon-set took: 10.731224ms
Dec 24 02:27:28.678: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.246231ms
Dec 24 02:27:39.483: INFO: Number of nodes with available pods: 0
Dec 24 02:27:39.483: INFO: Number of running nodes: 0, number of available pods: 0
Dec 24 02:27:39.487: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6040/daemonsets","resourceVersion":"133890"},"items":null}

Dec 24 02:27:39.490: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6040/pods","resourceVersion":"133890"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:27:39.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6040" for this suite.
Dec 24 02:27:45.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:27:45.652: INFO: namespace daemonsets-6040 deletion completed in 6.137769008s

• [SLOW TEST:45.748 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:27:45.652: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-1303
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 02:27:45.814: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-b52f4dac-55e3-4f17-99a2-06c3b54bbc92" in namespace "security-context-test-1303" to be "success or failure"
Dec 24 02:27:45.826: INFO: Pod "busybox-readonly-false-b52f4dac-55e3-4f17-99a2-06c3b54bbc92": Phase="Pending", Reason="", readiness=false. Elapsed: 11.244151ms
Dec 24 02:27:47.832: INFO: Pod "busybox-readonly-false-b52f4dac-55e3-4f17-99a2-06c3b54bbc92": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017723104s
Dec 24 02:27:49.837: INFO: Pod "busybox-readonly-false-b52f4dac-55e3-4f17-99a2-06c3b54bbc92": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023075398s
Dec 24 02:27:49.837: INFO: Pod "busybox-readonly-false-b52f4dac-55e3-4f17-99a2-06c3b54bbc92" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:27:49.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1303" for this suite.
Dec 24 02:27:55.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:27:55.997: INFO: namespace security-context-test-1303 deletion completed in 6.152868944s

• [SLOW TEST:10.345 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:27:55.997: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-742
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 24 02:27:56.152: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:28:00.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-742" for this suite.
Dec 24 02:28:12.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:28:12.958: INFO: namespace init-container-742 deletion completed in 12.139392223s

• [SLOW TEST:16.961 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:28:12.959: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2368
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2368
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Dec 24 02:28:13.130: INFO: Found 0 stateful pods, waiting for 3
Dec 24 02:28:23.135: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 24 02:28:23.136: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 24 02:28:23.136: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec 24 02:28:23.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=statefulset-2368 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 24 02:28:24.243: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 24 02:28:24.243: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 24 02:28:24.243: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec 24 02:28:34.294: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec 24 02:28:34.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=statefulset-2368 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 24 02:28:34.583: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 24 02:28:34.583: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 24 02:28:34.583: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 24 02:28:44.620: INFO: Waiting for StatefulSet statefulset-2368/ss2 to complete update
Dec 24 02:28:44.620: INFO: Waiting for Pod statefulset-2368/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 24 02:28:44.620: INFO: Waiting for Pod statefulset-2368/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 24 02:28:44.620: INFO: Waiting for Pod statefulset-2368/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 24 02:28:54.629: INFO: Waiting for StatefulSet statefulset-2368/ss2 to complete update
Dec 24 02:28:54.629: INFO: Waiting for Pod statefulset-2368/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 24 02:28:54.629: INFO: Waiting for Pod statefulset-2368/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 24 02:29:04.632: INFO: Waiting for StatefulSet statefulset-2368/ss2 to complete update
Dec 24 02:29:04.632: INFO: Waiting for Pod statefulset-2368/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 24 02:29:14.629: INFO: Waiting for StatefulSet statefulset-2368/ss2 to complete update
Dec 24 02:29:14.629: INFO: Waiting for Pod statefulset-2368/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Dec 24 02:29:24.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=statefulset-2368 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 24 02:29:24.878: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 24 02:29:24.878: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 24 02:29:24.878: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 24 02:29:34.917: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec 24 02:29:44.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=statefulset-2368 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 24 02:29:45.149: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 24 02:29:45.149: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 24 02:29:45.149: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 24 02:29:55.174: INFO: Waiting for StatefulSet statefulset-2368/ss2 to complete update
Dec 24 02:29:55.174: INFO: Waiting for Pod statefulset-2368/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Dec 24 02:29:55.174: INFO: Waiting for Pod statefulset-2368/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Dec 24 02:29:55.174: INFO: Waiting for Pod statefulset-2368/ss2-2 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Dec 24 02:30:05.184: INFO: Waiting for StatefulSet statefulset-2368/ss2 to complete update
Dec 24 02:30:05.184: INFO: Waiting for Pod statefulset-2368/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Dec 24 02:30:15.184: INFO: Waiting for StatefulSet statefulset-2368/ss2 to complete update
Dec 24 02:30:15.184: INFO: Waiting for Pod statefulset-2368/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 24 02:30:25.183: INFO: Deleting all statefulset in ns statefulset-2368
Dec 24 02:30:25.187: INFO: Scaling statefulset ss2 to 0
Dec 24 02:30:55.206: INFO: Waiting for statefulset status.replicas updated to 0
Dec 24 02:30:55.210: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:30:55.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2368" for this suite.
Dec 24 02:31:01.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:31:01.387: INFO: namespace statefulset-2368 deletion completed in 6.144783714s

• [SLOW TEST:168.428 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:31:01.387: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7277
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 02:31:01.540: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Dec 24 02:31:10.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 --namespace=crd-publish-openapi-7277 create -f -'
Dec 24 02:31:11.267: INFO: stderr: ""
Dec 24 02:31:11.267: INFO: stdout: "e2e-test-crd-publish-openapi-8659-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 24 02:31:11.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 --namespace=crd-publish-openapi-7277 delete e2e-test-crd-publish-openapi-8659-crds test-foo'
Dec 24 02:31:11.385: INFO: stderr: ""
Dec 24 02:31:11.385: INFO: stdout: "e2e-test-crd-publish-openapi-8659-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Dec 24 02:31:11.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 --namespace=crd-publish-openapi-7277 apply -f -'
Dec 24 02:31:11.676: INFO: stderr: ""
Dec 24 02:31:11.676: INFO: stdout: "e2e-test-crd-publish-openapi-8659-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 24 02:31:11.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 --namespace=crd-publish-openapi-7277 delete e2e-test-crd-publish-openapi-8659-crds test-foo'
Dec 24 02:31:11.763: INFO: stderr: ""
Dec 24 02:31:11.763: INFO: stdout: "e2e-test-crd-publish-openapi-8659-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Dec 24 02:31:11.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 --namespace=crd-publish-openapi-7277 create -f -'
Dec 24 02:31:11.967: INFO: rc: 1
Dec 24 02:31:11.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 --namespace=crd-publish-openapi-7277 apply -f -'
Dec 24 02:31:12.183: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Dec 24 02:31:12.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 --namespace=crd-publish-openapi-7277 create -f -'
Dec 24 02:31:12.401: INFO: rc: 1
Dec 24 02:31:12.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 --namespace=crd-publish-openapi-7277 apply -f -'
Dec 24 02:31:12.607: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Dec 24 02:31:12.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 explain e2e-test-crd-publish-openapi-8659-crds'
Dec 24 02:31:12.823: INFO: stderr: ""
Dec 24 02:31:12.823: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8659-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Dec 24 02:31:12.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 explain e2e-test-crd-publish-openapi-8659-crds.metadata'
Dec 24 02:31:12.972: INFO: stderr: ""
Dec 24 02:31:12.972: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8659-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Dec 24 02:31:12.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 explain e2e-test-crd-publish-openapi-8659-crds.spec'
Dec 24 02:31:13.180: INFO: stderr: ""
Dec 24 02:31:13.180: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8659-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Dec 24 02:31:13.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 explain e2e-test-crd-publish-openapi-8659-crds.spec.bars'
Dec 24 02:31:13.330: INFO: stderr: ""
Dec 24 02:31:13.330: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8659-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Dec 24 02:31:13.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 explain e2e-test-crd-publish-openapi-8659-crds.spec.bars2'
Dec 24 02:31:13.559: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:31:17.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7277" for this suite.
Dec 24 02:31:23.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:31:23.310: INFO: namespace crd-publish-openapi-7277 deletion completed in 6.161119234s

• [SLOW TEST:21.923 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:31:23.310: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3540
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 24 02:31:23.477: INFO: Waiting up to 5m0s for pod "downwardapi-volume-26f14a9d-b867-43d3-982f-777adc2bc1e9" in namespace "projected-3540" to be "success or failure"
Dec 24 02:31:23.484: INFO: Pod "downwardapi-volume-26f14a9d-b867-43d3-982f-777adc2bc1e9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.799089ms
Dec 24 02:31:25.489: INFO: Pod "downwardapi-volume-26f14a9d-b867-43d3-982f-777adc2bc1e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011796587s
Dec 24 02:31:27.494: INFO: Pod "downwardapi-volume-26f14a9d-b867-43d3-982f-777adc2bc1e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017236389s
STEP: Saw pod success
Dec 24 02:31:27.494: INFO: Pod "downwardapi-volume-26f14a9d-b867-43d3-982f-777adc2bc1e9" satisfied condition "success or failure"
Dec 24 02:31:27.499: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod downwardapi-volume-26f14a9d-b867-43d3-982f-777adc2bc1e9 container client-container: <nil>
STEP: delete the pod
Dec 24 02:31:27.538: INFO: Waiting for pod downwardapi-volume-26f14a9d-b867-43d3-982f-777adc2bc1e9 to disappear
Dec 24 02:31:27.544: INFO: Pod downwardapi-volume-26f14a9d-b867-43d3-982f-777adc2bc1e9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:31:27.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3540" for this suite.
Dec 24 02:31:33.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:31:33.736: INFO: namespace projected-3540 deletion completed in 6.184828777s

• [SLOW TEST:10.426 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:31:33.736: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9155
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 24 02:31:38.495: INFO: Successfully updated pod "labelsupdatef91dd97f-afa3-4a64-994e-4c30407ebdf3"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:31:40.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9155" for this suite.
Dec 24 02:32:08.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:32:08.688: INFO: namespace downward-api-9155 deletion completed in 28.154046112s

• [SLOW TEST:34.952 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:32:08.689: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4465
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-1314bb27-030f-423e-bcc7-29faee45fb56 in namespace container-probe-4465
Dec 24 02:32:12.864: INFO: Started pod liveness-1314bb27-030f-423e-bcc7-29faee45fb56 in namespace container-probe-4465
STEP: checking the pod's current state and verifying that restartCount is present
Dec 24 02:32:12.869: INFO: Initial restart count of pod liveness-1314bb27-030f-423e-bcc7-29faee45fb56 is 0
Dec 24 02:32:32.928: INFO: Restart count of pod container-probe-4465/liveness-1314bb27-030f-423e-bcc7-29faee45fb56 is now 1 (20.058946511s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:32:32.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4465" for this suite.
Dec 24 02:32:38.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:32:39.102: INFO: namespace container-probe-4465 deletion completed in 6.151365074s

• [SLOW TEST:30.414 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:32:39.102: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-14
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:32:43.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-14" for this suite.
Dec 24 02:33:27.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:33:27.527: INFO: namespace kubelet-test-14 deletion completed in 44.173061028s

• [SLOW TEST:48.425 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:33:27.527: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2140
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 24 02:33:28.406: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Dec 24 02:33:30.421: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712751608, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712751608, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712751608, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712751608, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 24 02:33:33.454: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Dec 24 02:33:33.480: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:33:33.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2140" for this suite.
Dec 24 02:33:39.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:33:39.663: INFO: namespace webhook-2140 deletion completed in 6.145973576s
STEP: Destroying namespace "webhook-2140-markers" for this suite.
Dec 24 02:33:45.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:33:45.819: INFO: namespace webhook-2140-markers deletion completed in 6.155744754s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.313 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:33:45.840: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-9416
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:33:54.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9416" for this suite.
Dec 24 02:34:00.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:34:00.164: INFO: namespace job-9416 deletion completed in 6.157179642s

• [SLOW TEST:14.324 seconds]
[sig-apps] Job
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:34:00.166: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2864
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 24 02:34:00.335: INFO: Waiting up to 5m0s for pod "pod-2e4903ce-9bca-42d5-be94-a66c313c6ab4" in namespace "emptydir-2864" to be "success or failure"
Dec 24 02:34:00.340: INFO: Pod "pod-2e4903ce-9bca-42d5-be94-a66c313c6ab4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.349031ms
Dec 24 02:34:02.344: INFO: Pod "pod-2e4903ce-9bca-42d5-be94-a66c313c6ab4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009644683s
Dec 24 02:34:04.349: INFO: Pod "pod-2e4903ce-9bca-42d5-be94-a66c313c6ab4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014201062s
STEP: Saw pod success
Dec 24 02:34:04.349: INFO: Pod "pod-2e4903ce-9bca-42d5-be94-a66c313c6ab4" satisfied condition "success or failure"
Dec 24 02:34:04.353: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-2e4903ce-9bca-42d5-be94-a66c313c6ab4 container test-container: <nil>
STEP: delete the pod
Dec 24 02:34:04.391: INFO: Waiting for pod pod-2e4903ce-9bca-42d5-be94-a66c313c6ab4 to disappear
Dec 24 02:34:04.397: INFO: Pod pod-2e4903ce-9bca-42d5-be94-a66c313c6ab4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:34:04.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2864" for this suite.
Dec 24 02:34:10.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:34:10.562: INFO: namespace emptydir-2864 deletion completed in 6.153728387s

• [SLOW TEST:10.396 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:34:10.562: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-923
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Dec 24 02:34:15.253: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-923 pod-service-account-16f49521-1d59-4f18-8555-2477c03eae72 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Dec 24 02:34:15.487: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-923 pod-service-account-16f49521-1d59-4f18-8555-2477c03eae72 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Dec 24 02:34:15.710: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-923 pod-service-account-16f49521-1d59-4f18-8555-2477c03eae72 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:34:15.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-923" for this suite.
Dec 24 02:34:21.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:34:22.098: INFO: namespace svcaccounts-923 deletion completed in 6.151942473s

• [SLOW TEST:11.535 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:34:22.098: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8616
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-65a85253-1e2e-4c97-ac4e-09c504c84181
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-65a85253-1e2e-4c97-ac4e-09c504c84181
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:35:36.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8616" for this suite.
Dec 24 02:35:48.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:35:48.925: INFO: namespace projected-8616 deletion completed in 12.149548221s

• [SLOW TEST:86.827 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:35:48.925: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4626
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-026db9a7-75d3-4693-ad95-d835d9976abd
STEP: Creating a pod to test consume secrets
Dec 24 02:35:49.095: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-215d3d65-b248-49aa-94b8-348395697518" in namespace "projected-4626" to be "success or failure"
Dec 24 02:35:49.103: INFO: Pod "pod-projected-secrets-215d3d65-b248-49aa-94b8-348395697518": Phase="Pending", Reason="", readiness=false. Elapsed: 7.95137ms
Dec 24 02:35:51.108: INFO: Pod "pod-projected-secrets-215d3d65-b248-49aa-94b8-348395697518": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013084491s
Dec 24 02:35:53.116: INFO: Pod "pod-projected-secrets-215d3d65-b248-49aa-94b8-348395697518": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02107184s
STEP: Saw pod success
Dec 24 02:35:53.116: INFO: Pod "pod-projected-secrets-215d3d65-b248-49aa-94b8-348395697518" satisfied condition "success or failure"
Dec 24 02:35:53.120: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod pod-projected-secrets-215d3d65-b248-49aa-94b8-348395697518 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 24 02:35:53.163: INFO: Waiting for pod pod-projected-secrets-215d3d65-b248-49aa-94b8-348395697518 to disappear
Dec 24 02:35:53.166: INFO: Pod pod-projected-secrets-215d3d65-b248-49aa-94b8-348395697518 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:35:53.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4626" for this suite.
Dec 24 02:35:59.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:35:59.320: INFO: namespace projected-4626 deletion completed in 6.144503475s

• [SLOW TEST:10.395 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:35:59.321: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6305
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec 24 02:35:59.512: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6305 /api/v1/namespaces/watch-6305/configmaps/e2e-watch-test-watch-closed 87d862df-be55-4212-940b-0e63c8640d2f 136194 0 2019-12-24 02:35:59 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 24 02:35:59.512: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6305 /api/v1/namespaces/watch-6305/configmaps/e2e-watch-test-watch-closed 87d862df-be55-4212-940b-0e63c8640d2f 136195 0 2019-12-24 02:35:59 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec 24 02:35:59.533: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6305 /api/v1/namespaces/watch-6305/configmaps/e2e-watch-test-watch-closed 87d862df-be55-4212-940b-0e63c8640d2f 136196 0 2019-12-24 02:35:59 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 24 02:35:59.534: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6305 /api/v1/namespaces/watch-6305/configmaps/e2e-watch-test-watch-closed 87d862df-be55-4212-940b-0e63c8640d2f 136197 0 2019-12-24 02:35:59 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:35:59.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6305" for this suite.
Dec 24 02:36:05.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:36:05.683: INFO: namespace watch-6305 deletion completed in 6.142865162s

• [SLOW TEST:6.362 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:36:05.683: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6756
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 24 02:36:06.674: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 24 02:36:08.688: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712751766, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712751766, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712751766, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712751766, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 24 02:36:11.715: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:36:11.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6756" for this suite.
Dec 24 02:36:18.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:36:18.189: INFO: namespace webhook-6756 deletion completed in 6.203242823s
STEP: Destroying namespace "webhook-6756-markers" for this suite.
Dec 24 02:36:24.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:36:24.356: INFO: namespace webhook-6756-markers deletion completed in 6.166751388s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.695 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:36:24.378: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5805
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-1ce9791d-0a69-4ee7-9fb0-85884cca5d6e
STEP: Creating a pod to test consume configMaps
Dec 24 02:36:24.553: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c995a602-7e27-4179-bf8c-507310adba53" in namespace "projected-5805" to be "success or failure"
Dec 24 02:36:24.559: INFO: Pod "pod-projected-configmaps-c995a602-7e27-4179-bf8c-507310adba53": Phase="Pending", Reason="", readiness=false. Elapsed: 5.821428ms
Dec 24 02:36:26.563: INFO: Pod "pod-projected-configmaps-c995a602-7e27-4179-bf8c-507310adba53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01042632s
Dec 24 02:36:28.572: INFO: Pod "pod-projected-configmaps-c995a602-7e27-4179-bf8c-507310adba53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019174796s
STEP: Saw pod success
Dec 24 02:36:28.572: INFO: Pod "pod-projected-configmaps-c995a602-7e27-4179-bf8c-507310adba53" satisfied condition "success or failure"
Dec 24 02:36:28.577: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod pod-projected-configmaps-c995a602-7e27-4179-bf8c-507310adba53 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 24 02:36:28.617: INFO: Waiting for pod pod-projected-configmaps-c995a602-7e27-4179-bf8c-507310adba53 to disappear
Dec 24 02:36:28.622: INFO: Pod pod-projected-configmaps-c995a602-7e27-4179-bf8c-507310adba53 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:36:28.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5805" for this suite.
Dec 24 02:36:34.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:36:34.772: INFO: namespace projected-5805 deletion completed in 6.144262587s

• [SLOW TEST:10.394 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:36:34.772: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6443
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec 24 02:36:34.971: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6443 /api/v1/namespaces/watch-6443/configmaps/e2e-watch-test-resource-version 9e7e42b4-bade-4612-9e73-eb1a547853ea 136418 0 2019-12-24 02:36:34 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 24 02:36:34.971: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6443 /api/v1/namespaces/watch-6443/configmaps/e2e-watch-test-resource-version 9e7e42b4-bade-4612-9e73-eb1a547853ea 136419 0 2019-12-24 02:36:34 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:36:34.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6443" for this suite.
Dec 24 02:36:40.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:36:41.134: INFO: namespace watch-6443 deletion completed in 6.153343552s

• [SLOW TEST:6.362 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:36:41.134: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-577
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 02:36:41.290: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:36:45.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-577" for this suite.
Dec 24 02:37:29.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:37:29.648: INFO: namespace pods-577 deletion completed in 44.168118409s

• [SLOW TEST:48.514 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:37:29.648: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9292
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-fc108f43-a39d-4cfd-881e-cc3d89d94cd6
STEP: Creating a pod to test consume secrets
Dec 24 02:37:29.814: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9ea4e2aa-4b20-4c3f-af00-22c758143617" in namespace "projected-9292" to be "success or failure"
Dec 24 02:37:29.822: INFO: Pod "pod-projected-secrets-9ea4e2aa-4b20-4c3f-af00-22c758143617": Phase="Pending", Reason="", readiness=false. Elapsed: 8.307503ms
Dec 24 02:37:31.827: INFO: Pod "pod-projected-secrets-9ea4e2aa-4b20-4c3f-af00-22c758143617": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012883436s
Dec 24 02:37:33.832: INFO: Pod "pod-projected-secrets-9ea4e2aa-4b20-4c3f-af00-22c758143617": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018347727s
STEP: Saw pod success
Dec 24 02:37:33.832: INFO: Pod "pod-projected-secrets-9ea4e2aa-4b20-4c3f-af00-22c758143617" satisfied condition "success or failure"
Dec 24 02:37:33.835: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod pod-projected-secrets-9ea4e2aa-4b20-4c3f-af00-22c758143617 container secret-volume-test: <nil>
STEP: delete the pod
Dec 24 02:37:33.873: INFO: Waiting for pod pod-projected-secrets-9ea4e2aa-4b20-4c3f-af00-22c758143617 to disappear
Dec 24 02:37:33.877: INFO: Pod pod-projected-secrets-9ea4e2aa-4b20-4c3f-af00-22c758143617 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:37:33.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9292" for this suite.
Dec 24 02:37:39.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:37:40.062: INFO: namespace projected-9292 deletion completed in 6.177935732s

• [SLOW TEST:10.414 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:37:40.062: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6545
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-ddd432de-48df-4009-b532-6ad0aaeb99d8
STEP: Creating a pod to test consume configMaps
Dec 24 02:37:40.236: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d7fda943-5b53-4f99-9859-2c73cf330827" in namespace "projected-6545" to be "success or failure"
Dec 24 02:37:40.245: INFO: Pod "pod-projected-configmaps-d7fda943-5b53-4f99-9859-2c73cf330827": Phase="Pending", Reason="", readiness=false. Elapsed: 8.731676ms
Dec 24 02:37:42.250: INFO: Pod "pod-projected-configmaps-d7fda943-5b53-4f99-9859-2c73cf330827": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013254846s
Dec 24 02:37:44.255: INFO: Pod "pod-projected-configmaps-d7fda943-5b53-4f99-9859-2c73cf330827": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018717165s
STEP: Saw pod success
Dec 24 02:37:44.255: INFO: Pod "pod-projected-configmaps-d7fda943-5b53-4f99-9859-2c73cf330827" satisfied condition "success or failure"
Dec 24 02:37:44.259: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-projected-configmaps-d7fda943-5b53-4f99-9859-2c73cf330827 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 24 02:37:44.295: INFO: Waiting for pod pod-projected-configmaps-d7fda943-5b53-4f99-9859-2c73cf330827 to disappear
Dec 24 02:37:44.299: INFO: Pod pod-projected-configmaps-d7fda943-5b53-4f99-9859-2c73cf330827 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:37:44.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6545" for this suite.
Dec 24 02:37:50.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:37:50.522: INFO: namespace projected-6545 deletion completed in 6.216054087s

• [SLOW TEST:10.459 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:37:50.522: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4444
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Dec 24 02:37:54.700: INFO: Pod pod-hostip-7b3a2bb4-3059-4cbb-b421-5e907fe6bd58 has hostIP: 172.16.44.108
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:37:54.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4444" for this suite.
Dec 24 02:38:06.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:38:06.856: INFO: namespace pods-4444 deletion completed in 12.14961742s

• [SLOW TEST:16.334 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:38:06.856: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-644
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 02:38:07.012: INFO: Creating ReplicaSet my-hostname-basic-309ee65e-2729-4695-8d6a-4e193c988083
Dec 24 02:38:07.036: INFO: Pod name my-hostname-basic-309ee65e-2729-4695-8d6a-4e193c988083: Found 0 pods out of 1
Dec 24 02:38:12.041: INFO: Pod name my-hostname-basic-309ee65e-2729-4695-8d6a-4e193c988083: Found 1 pods out of 1
Dec 24 02:38:12.042: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-309ee65e-2729-4695-8d6a-4e193c988083" is running
Dec 24 02:38:12.045: INFO: Pod "my-hostname-basic-309ee65e-2729-4695-8d6a-4e193c988083-xjhwt" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-24 02:38:07 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-24 02:38:09 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-24 02:38:09 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-24 02:38:07 +0000 UTC Reason: Message:}])
Dec 24 02:38:12.045: INFO: Trying to dial the pod
Dec 24 02:38:17.060: INFO: Controller my-hostname-basic-309ee65e-2729-4695-8d6a-4e193c988083: Got expected result from replica 1 [my-hostname-basic-309ee65e-2729-4695-8d6a-4e193c988083-xjhwt]: "my-hostname-basic-309ee65e-2729-4695-8d6a-4e193c988083-xjhwt", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:38:17.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-644" for this suite.
Dec 24 02:38:23.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:38:23.220: INFO: namespace replicaset-644 deletion completed in 6.153365891s

• [SLOW TEST:16.364 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:38:23.223: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5157
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-b0bf26a3-f296-45cb-8ca5-1eda51dd1a94
STEP: Creating a pod to test consume configMaps
Dec 24 02:38:23.397: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ce28a315-8584-4f40-9d67-a12256411e60" in namespace "projected-5157" to be "success or failure"
Dec 24 02:38:23.406: INFO: Pod "pod-projected-configmaps-ce28a315-8584-4f40-9d67-a12256411e60": Phase="Pending", Reason="", readiness=false. Elapsed: 8.703847ms
Dec 24 02:38:25.411: INFO: Pod "pod-projected-configmaps-ce28a315-8584-4f40-9d67-a12256411e60": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013645949s
Dec 24 02:38:27.416: INFO: Pod "pod-projected-configmaps-ce28a315-8584-4f40-9d67-a12256411e60": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018610176s
STEP: Saw pod success
Dec 24 02:38:27.416: INFO: Pod "pod-projected-configmaps-ce28a315-8584-4f40-9d67-a12256411e60" satisfied condition "success or failure"
Dec 24 02:38:27.420: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-projected-configmaps-ce28a315-8584-4f40-9d67-a12256411e60 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 24 02:38:27.448: INFO: Waiting for pod pod-projected-configmaps-ce28a315-8584-4f40-9d67-a12256411e60 to disappear
Dec 24 02:38:27.453: INFO: Pod pod-projected-configmaps-ce28a315-8584-4f40-9d67-a12256411e60 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:38:27.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5157" for this suite.
Dec 24 02:38:33.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:38:33.623: INFO: namespace projected-5157 deletion completed in 6.164051607s

• [SLOW TEST:10.400 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:38:33.623: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-772
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:38:44.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-772" for this suite.
Dec 24 02:38:50.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:38:50.996: INFO: namespace resourcequota-772 deletion completed in 6.164248237s

• [SLOW TEST:17.373 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:38:50.996: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2359
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2359.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-2359.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2359.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2359.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-2359.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2359.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 24 02:38:55.239: INFO: DNS probes using dns-2359/dns-test-4072042c-a8a4-4f99-9c56-9752cda7c3cd succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:38:55.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2359" for this suite.
Dec 24 02:39:01.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:39:01.457: INFO: namespace dns-2359 deletion completed in 6.166201977s

• [SLOW TEST:10.461 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:39:01.457: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6385
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-b21a114f-394b-444d-bbf7-88e7c0a20665
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-b21a114f-394b-444d-bbf7-88e7c0a20665
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:40:32.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6385" for this suite.
Dec 24 02:40:44.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:40:44.394: INFO: namespace configmap-6385 deletion completed in 12.155001803s

• [SLOW TEST:102.937 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:40:44.394: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7872
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 24 02:40:45.051: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 24 02:40:47.063: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712752045, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712752045, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712752045, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712752045, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 24 02:40:50.089: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
Dec 24 02:40:57.297: INFO: Waiting for webhook configuration to be ready...
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:41:02.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7872" for this suite.
Dec 24 02:41:08.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:41:08.614: INFO: namespace webhook-7872 deletion completed in 6.16542829s
STEP: Destroying namespace "webhook-7872-markers" for this suite.
Dec 24 02:41:14.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:41:14.753: INFO: namespace webhook-7872-markers deletion completed in 6.139455814s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:30.381 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:41:14.776: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9725
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-5gjz
STEP: Creating a pod to test atomic-volume-subpath
Dec 24 02:41:14.957: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-5gjz" in namespace "subpath-9725" to be "success or failure"
Dec 24 02:41:14.961: INFO: Pod "pod-subpath-test-secret-5gjz": Phase="Pending", Reason="", readiness=false. Elapsed: 4.042569ms
Dec 24 02:41:16.966: INFO: Pod "pod-subpath-test-secret-5gjz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009269983s
Dec 24 02:41:18.972: INFO: Pod "pod-subpath-test-secret-5gjz": Phase="Running", Reason="", readiness=true. Elapsed: 4.015075879s
Dec 24 02:41:20.977: INFO: Pod "pod-subpath-test-secret-5gjz": Phase="Running", Reason="", readiness=true. Elapsed: 6.020245986s
Dec 24 02:41:23.000: INFO: Pod "pod-subpath-test-secret-5gjz": Phase="Running", Reason="", readiness=true. Elapsed: 8.043019372s
Dec 24 02:41:25.006: INFO: Pod "pod-subpath-test-secret-5gjz": Phase="Running", Reason="", readiness=true. Elapsed: 10.048698656s
Dec 24 02:41:27.012: INFO: Pod "pod-subpath-test-secret-5gjz": Phase="Running", Reason="", readiness=true. Elapsed: 12.054534293s
Dec 24 02:41:29.016: INFO: Pod "pod-subpath-test-secret-5gjz": Phase="Running", Reason="", readiness=true. Elapsed: 14.05911793s
Dec 24 02:41:31.021: INFO: Pod "pod-subpath-test-secret-5gjz": Phase="Running", Reason="", readiness=true. Elapsed: 16.06423226s
Dec 24 02:41:33.027: INFO: Pod "pod-subpath-test-secret-5gjz": Phase="Running", Reason="", readiness=true. Elapsed: 18.069495105s
Dec 24 02:41:35.031: INFO: Pod "pod-subpath-test-secret-5gjz": Phase="Running", Reason="", readiness=true. Elapsed: 20.074194215s
Dec 24 02:41:37.037: INFO: Pod "pod-subpath-test-secret-5gjz": Phase="Running", Reason="", readiness=true. Elapsed: 22.080147592s
Dec 24 02:41:39.042: INFO: Pod "pod-subpath-test-secret-5gjz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.084605519s
STEP: Saw pod success
Dec 24 02:41:39.042: INFO: Pod "pod-subpath-test-secret-5gjz" satisfied condition "success or failure"
Dec 24 02:41:39.046: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod pod-subpath-test-secret-5gjz container test-container-subpath-secret-5gjz: <nil>
STEP: delete the pod
Dec 24 02:41:39.071: INFO: Waiting for pod pod-subpath-test-secret-5gjz to disappear
Dec 24 02:41:39.076: INFO: Pod pod-subpath-test-secret-5gjz no longer exists
STEP: Deleting pod pod-subpath-test-secret-5gjz
Dec 24 02:41:39.076: INFO: Deleting pod "pod-subpath-test-secret-5gjz" in namespace "subpath-9725"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:41:39.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9725" for this suite.
Dec 24 02:41:45.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:41:45.225: INFO: namespace subpath-9725 deletion completed in 6.138174505s

• [SLOW TEST:30.450 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:41:45.226: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7350
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Dec 24 02:41:45.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 create -f - --namespace=kubectl-7350'
Dec 24 02:41:46.348: INFO: stderr: ""
Dec 24 02:41:46.348: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 24 02:41:46.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7350'
Dec 24 02:41:46.430: INFO: stderr: ""
Dec 24 02:41:46.430: INFO: stdout: "update-demo-nautilus-84jbj update-demo-nautilus-kdxwk "
Dec 24 02:41:46.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-nautilus-84jbj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7350'
Dec 24 02:41:46.499: INFO: stderr: ""
Dec 24 02:41:46.499: INFO: stdout: ""
Dec 24 02:41:46.499: INFO: update-demo-nautilus-84jbj is created but not running
Dec 24 02:41:51.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7350'
Dec 24 02:41:51.636: INFO: stderr: ""
Dec 24 02:41:51.636: INFO: stdout: "update-demo-nautilus-84jbj update-demo-nautilus-kdxwk "
Dec 24 02:41:51.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-nautilus-84jbj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7350'
Dec 24 02:41:51.742: INFO: stderr: ""
Dec 24 02:41:51.742: INFO: stdout: "true"
Dec 24 02:41:51.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-nautilus-84jbj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7350'
Dec 24 02:41:51.838: INFO: stderr: ""
Dec 24 02:41:51.838: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 24 02:41:51.838: INFO: validating pod update-demo-nautilus-84jbj
Dec 24 02:41:51.847: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 24 02:41:51.847: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 24 02:41:51.847: INFO: update-demo-nautilus-84jbj is verified up and running
Dec 24 02:41:51.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-nautilus-kdxwk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7350'
Dec 24 02:41:51.945: INFO: stderr: ""
Dec 24 02:41:51.945: INFO: stdout: "true"
Dec 24 02:41:51.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-nautilus-kdxwk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7350'
Dec 24 02:41:52.044: INFO: stderr: ""
Dec 24 02:41:52.044: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 24 02:41:52.044: INFO: validating pod update-demo-nautilus-kdxwk
Dec 24 02:41:52.050: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 24 02:41:52.050: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 24 02:41:52.050: INFO: update-demo-nautilus-kdxwk is verified up and running
STEP: scaling down the replication controller
Dec 24 02:41:52.052: INFO: scanned /root for discovery docs: <nil>
Dec 24 02:41:52.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-7350'
Dec 24 02:41:52.237: INFO: stderr: ""
Dec 24 02:41:52.237: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 24 02:41:52.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7350'
Dec 24 02:41:52.345: INFO: stderr: ""
Dec 24 02:41:52.345: INFO: stdout: "update-demo-nautilus-84jbj update-demo-nautilus-kdxwk "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 24 02:41:57.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7350'
Dec 24 02:41:57.434: INFO: stderr: ""
Dec 24 02:41:57.434: INFO: stdout: "update-demo-nautilus-kdxwk "
Dec 24 02:41:57.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-nautilus-kdxwk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7350'
Dec 24 02:41:57.513: INFO: stderr: ""
Dec 24 02:41:57.513: INFO: stdout: "true"
Dec 24 02:41:57.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-nautilus-kdxwk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7350'
Dec 24 02:41:57.593: INFO: stderr: ""
Dec 24 02:41:57.594: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 24 02:41:57.594: INFO: validating pod update-demo-nautilus-kdxwk
Dec 24 02:41:57.600: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 24 02:41:57.600: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 24 02:41:57.601: INFO: update-demo-nautilus-kdxwk is verified up and running
STEP: scaling up the replication controller
Dec 24 02:41:57.602: INFO: scanned /root for discovery docs: <nil>
Dec 24 02:41:57.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-7350'
Dec 24 02:41:57.739: INFO: stderr: ""
Dec 24 02:41:57.739: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 24 02:41:57.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7350'
Dec 24 02:41:57.845: INFO: stderr: ""
Dec 24 02:41:57.845: INFO: stdout: "update-demo-nautilus-dmw8h update-demo-nautilus-kdxwk "
Dec 24 02:41:57.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-nautilus-dmw8h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7350'
Dec 24 02:41:57.961: INFO: stderr: ""
Dec 24 02:41:57.961: INFO: stdout: ""
Dec 24 02:41:57.961: INFO: update-demo-nautilus-dmw8h is created but not running
Dec 24 02:42:02.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7350'
Dec 24 02:42:03.059: INFO: stderr: ""
Dec 24 02:42:03.059: INFO: stdout: "update-demo-nautilus-dmw8h update-demo-nautilus-kdxwk "
Dec 24 02:42:03.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-nautilus-dmw8h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7350'
Dec 24 02:42:03.140: INFO: stderr: ""
Dec 24 02:42:03.140: INFO: stdout: "true"
Dec 24 02:42:03.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-nautilus-dmw8h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7350'
Dec 24 02:42:03.222: INFO: stderr: ""
Dec 24 02:42:03.222: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 24 02:42:03.222: INFO: validating pod update-demo-nautilus-dmw8h
Dec 24 02:42:03.230: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 24 02:42:03.230: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 24 02:42:03.230: INFO: update-demo-nautilus-dmw8h is verified up and running
Dec 24 02:42:03.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-nautilus-kdxwk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7350'
Dec 24 02:42:03.306: INFO: stderr: ""
Dec 24 02:42:03.306: INFO: stdout: "true"
Dec 24 02:42:03.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods update-demo-nautilus-kdxwk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7350'
Dec 24 02:42:03.383: INFO: stderr: ""
Dec 24 02:42:03.383: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 24 02:42:03.383: INFO: validating pod update-demo-nautilus-kdxwk
Dec 24 02:42:03.389: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 24 02:42:03.389: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 24 02:42:03.389: INFO: update-demo-nautilus-kdxwk is verified up and running
STEP: using delete to clean up resources
Dec 24 02:42:03.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 delete --grace-period=0 --force -f - --namespace=kubectl-7350'
Dec 24 02:42:03.530: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 24 02:42:03.530: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 24 02:42:03.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7350'
Dec 24 02:42:03.642: INFO: stderr: "No resources found in kubectl-7350 namespace.\n"
Dec 24 02:42:03.642: INFO: stdout: ""
Dec 24 02:42:03.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods -l name=update-demo --namespace=kubectl-7350 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 24 02:42:03.724: INFO: stderr: ""
Dec 24 02:42:03.724: INFO: stdout: "update-demo-nautilus-dmw8h\nupdate-demo-nautilus-kdxwk\n"
Dec 24 02:42:04.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7350'
Dec 24 02:42:04.336: INFO: stderr: "No resources found in kubectl-7350 namespace.\n"
Dec 24 02:42:04.336: INFO: stdout: ""
Dec 24 02:42:04.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods -l name=update-demo --namespace=kubectl-7350 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 24 02:42:04.411: INFO: stderr: ""
Dec 24 02:42:04.411: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:42:04.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7350" for this suite.
Dec 24 02:42:10.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:42:10.571: INFO: namespace kubectl-7350 deletion completed in 6.153133358s

• [SLOW TEST:25.345 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:42:10.571: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3514
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-bc8p
STEP: Creating a pod to test atomic-volume-subpath
Dec 24 02:42:10.752: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-bc8p" in namespace "subpath-3514" to be "success or failure"
Dec 24 02:42:10.764: INFO: Pod "pod-subpath-test-projected-bc8p": Phase="Pending", Reason="", readiness=false. Elapsed: 11.080823ms
Dec 24 02:42:12.768: INFO: Pod "pod-subpath-test-projected-bc8p": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01551005s
Dec 24 02:42:14.773: INFO: Pod "pod-subpath-test-projected-bc8p": Phase="Running", Reason="", readiness=true. Elapsed: 4.020912248s
Dec 24 02:42:16.778: INFO: Pod "pod-subpath-test-projected-bc8p": Phase="Running", Reason="", readiness=true. Elapsed: 6.025116985s
Dec 24 02:42:18.783: INFO: Pod "pod-subpath-test-projected-bc8p": Phase="Running", Reason="", readiness=true. Elapsed: 8.030954094s
Dec 24 02:42:20.789: INFO: Pod "pod-subpath-test-projected-bc8p": Phase="Running", Reason="", readiness=true. Elapsed: 10.036151325s
Dec 24 02:42:22.793: INFO: Pod "pod-subpath-test-projected-bc8p": Phase="Running", Reason="", readiness=true. Elapsed: 12.040660986s
Dec 24 02:42:24.799: INFO: Pod "pod-subpath-test-projected-bc8p": Phase="Running", Reason="", readiness=true. Elapsed: 14.046113756s
Dec 24 02:42:26.803: INFO: Pod "pod-subpath-test-projected-bc8p": Phase="Running", Reason="", readiness=true. Elapsed: 16.050379096s
Dec 24 02:42:28.813: INFO: Pod "pod-subpath-test-projected-bc8p": Phase="Running", Reason="", readiness=true. Elapsed: 18.060028354s
Dec 24 02:42:30.827: INFO: Pod "pod-subpath-test-projected-bc8p": Phase="Running", Reason="", readiness=true. Elapsed: 20.07413264s
Dec 24 02:42:32.832: INFO: Pod "pod-subpath-test-projected-bc8p": Phase="Running", Reason="", readiness=true. Elapsed: 22.079521392s
Dec 24 02:42:34.838: INFO: Pod "pod-subpath-test-projected-bc8p": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.085362958s
STEP: Saw pod success
Dec 24 02:42:34.838: INFO: Pod "pod-subpath-test-projected-bc8p" satisfied condition "success or failure"
Dec 24 02:42:34.842: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod pod-subpath-test-projected-bc8p container test-container-subpath-projected-bc8p: <nil>
STEP: delete the pod
Dec 24 02:42:34.889: INFO: Waiting for pod pod-subpath-test-projected-bc8p to disappear
Dec 24 02:42:34.894: INFO: Pod pod-subpath-test-projected-bc8p no longer exists
STEP: Deleting pod pod-subpath-test-projected-bc8p
Dec 24 02:42:34.894: INFO: Deleting pod "pod-subpath-test-projected-bc8p" in namespace "subpath-3514"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:42:34.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3514" for this suite.
Dec 24 02:42:40.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:42:41.051: INFO: namespace subpath-3514 deletion completed in 6.146821671s

• [SLOW TEST:30.480 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:42:41.051: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8499
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 24 02:42:41.214: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2a6e3d87-cf3b-4f7b-85b5-0d141bf89338" in namespace "downward-api-8499" to be "success or failure"
Dec 24 02:42:41.222: INFO: Pod "downwardapi-volume-2a6e3d87-cf3b-4f7b-85b5-0d141bf89338": Phase="Pending", Reason="", readiness=false. Elapsed: 7.398522ms
Dec 24 02:42:43.226: INFO: Pod "downwardapi-volume-2a6e3d87-cf3b-4f7b-85b5-0d141bf89338": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012011233s
Dec 24 02:42:45.232: INFO: Pod "downwardapi-volume-2a6e3d87-cf3b-4f7b-85b5-0d141bf89338": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017893575s
STEP: Saw pod success
Dec 24 02:42:45.233: INFO: Pod "downwardapi-volume-2a6e3d87-cf3b-4f7b-85b5-0d141bf89338" satisfied condition "success or failure"
Dec 24 02:42:45.236: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod downwardapi-volume-2a6e3d87-cf3b-4f7b-85b5-0d141bf89338 container client-container: <nil>
STEP: delete the pod
Dec 24 02:42:45.268: INFO: Waiting for pod downwardapi-volume-2a6e3d87-cf3b-4f7b-85b5-0d141bf89338 to disappear
Dec 24 02:42:45.272: INFO: Pod downwardapi-volume-2a6e3d87-cf3b-4f7b-85b5-0d141bf89338 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:42:45.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8499" for this suite.
Dec 24 02:42:51.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:42:51.481: INFO: namespace downward-api-8499 deletion completed in 6.189122379s

• [SLOW TEST:10.430 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:42:51.481: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8459
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-abce5a2d-b1dc-45a2-8cb3-053cf119f896
STEP: Creating a pod to test consume secrets
Dec 24 02:42:51.658: INFO: Waiting up to 5m0s for pod "pod-secrets-c85728ed-1c1c-408d-8767-210709f40a98" in namespace "secrets-8459" to be "success or failure"
Dec 24 02:42:51.664: INFO: Pod "pod-secrets-c85728ed-1c1c-408d-8767-210709f40a98": Phase="Pending", Reason="", readiness=false. Elapsed: 5.957806ms
Dec 24 02:42:53.669: INFO: Pod "pod-secrets-c85728ed-1c1c-408d-8767-210709f40a98": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01130293s
Dec 24 02:42:55.673: INFO: Pod "pod-secrets-c85728ed-1c1c-408d-8767-210709f40a98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015914732s
STEP: Saw pod success
Dec 24 02:42:55.674: INFO: Pod "pod-secrets-c85728ed-1c1c-408d-8767-210709f40a98" satisfied condition "success or failure"
Dec 24 02:42:55.677: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-secrets-c85728ed-1c1c-408d-8767-210709f40a98 container secret-volume-test: <nil>
STEP: delete the pod
Dec 24 02:42:55.718: INFO: Waiting for pod pod-secrets-c85728ed-1c1c-408d-8767-210709f40a98 to disappear
Dec 24 02:42:55.721: INFO: Pod pod-secrets-c85728ed-1c1c-408d-8767-210709f40a98 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:42:55.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8459" for this suite.
Dec 24 02:43:01.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:43:01.895: INFO: namespace secrets-8459 deletion completed in 6.167771436s

• [SLOW TEST:10.414 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:43:01.895: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4416
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Dec 24 02:43:02.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-4416 -- logs-generator --log-lines-total 100 --run-duration 20s'
Dec 24 02:43:02.225: INFO: stderr: ""
Dec 24 02:43:02.226: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Dec 24 02:43:02.226: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Dec 24 02:43:02.226: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-4416" to be "running and ready, or succeeded"
Dec 24 02:43:02.233: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 6.847397ms
Dec 24 02:43:04.237: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011080582s
Dec 24 02:43:06.242: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.015391188s
Dec 24 02:43:06.242: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Dec 24 02:43:06.242: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Dec 24 02:43:06.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 logs logs-generator logs-generator --namespace=kubectl-4416'
Dec 24 02:43:06.339: INFO: stderr: ""
Dec 24 02:43:06.339: INFO: stdout: "I1224 02:43:03.886556       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/lxtb 562\nI1224 02:43:04.086819       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/szk 315\nI1224 02:43:04.286969       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/q4b 211\nI1224 02:43:04.486733       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/2mk 203\nI1224 02:43:04.686737       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/qjdv 566\nI1224 02:43:04.886732       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/dsb5 434\nI1224 02:43:05.086742       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/xsgb 238\nI1224 02:43:05.286754       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/5hh 372\nI1224 02:43:05.486743       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/gnb8 483\nI1224 02:43:05.686745       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/kvb 247\nI1224 02:43:05.886763       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/hpxt 400\nI1224 02:43:06.086740       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/sr8 405\nI1224 02:43:06.288504       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/ns/pods/qg79 549\n"
STEP: limiting log lines
Dec 24 02:43:06.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 logs logs-generator logs-generator --namespace=kubectl-4416 --tail=1'
Dec 24 02:43:06.455: INFO: stderr: ""
Dec 24 02:43:06.455: INFO: stdout: "I1224 02:43:06.288504       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/ns/pods/qg79 549\n"
STEP: limiting log bytes
Dec 24 02:43:06.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 logs logs-generator logs-generator --namespace=kubectl-4416 --limit-bytes=1'
Dec 24 02:43:06.557: INFO: stderr: ""
Dec 24 02:43:06.557: INFO: stdout: "I"
STEP: exposing timestamps
Dec 24 02:43:06.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 logs logs-generator logs-generator --namespace=kubectl-4416 --tail=1 --timestamps'
Dec 24 02:43:06.695: INFO: stderr: ""
Dec 24 02:43:06.695: INFO: stdout: "2019-12-24T02:43:06.686891041Z I1224 02:43:06.686745       1 logs_generator.go:76] 14 GET /api/v1/namespaces/default/pods/q8n8 504\n"
STEP: restricting to a time range
Dec 24 02:43:09.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 logs logs-generator logs-generator --namespace=kubectl-4416 --since=1s'
Dec 24 02:43:09.283: INFO: stderr: ""
Dec 24 02:43:09.283: INFO: stdout: "I1224 02:43:08.286721       1 logs_generator.go:76] 22 GET /api/v1/namespaces/default/pods/dxn 214\nI1224 02:43:08.486755       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/ns/pods/r6r 537\nI1224 02:43:08.686727       1 logs_generator.go:76] 24 GET /api/v1/namespaces/ns/pods/mhqt 452\nI1224 02:43:08.886732       1 logs_generator.go:76] 25 PUT /api/v1/namespaces/kube-system/pods/94p 434\nI1224 02:43:09.086724       1 logs_generator.go:76] 26 PUT /api/v1/namespaces/kube-system/pods/bqq 312\n"
Dec 24 02:43:09.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 logs logs-generator logs-generator --namespace=kubectl-4416 --since=24h'
Dec 24 02:43:09.374: INFO: stderr: ""
Dec 24 02:43:09.374: INFO: stdout: "I1224 02:43:03.886556       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/lxtb 562\nI1224 02:43:04.086819       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/szk 315\nI1224 02:43:04.286969       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/q4b 211\nI1224 02:43:04.486733       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/2mk 203\nI1224 02:43:04.686737       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/qjdv 566\nI1224 02:43:04.886732       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/dsb5 434\nI1224 02:43:05.086742       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/xsgb 238\nI1224 02:43:05.286754       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/5hh 372\nI1224 02:43:05.486743       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/gnb8 483\nI1224 02:43:05.686745       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/kvb 247\nI1224 02:43:05.886763       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/hpxt 400\nI1224 02:43:06.086740       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/sr8 405\nI1224 02:43:06.288504       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/ns/pods/qg79 549\nI1224 02:43:06.486729       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/4f8l 216\nI1224 02:43:06.686745       1 logs_generator.go:76] 14 GET /api/v1/namespaces/default/pods/q8n8 504\nI1224 02:43:06.889496       1 logs_generator.go:76] 15 POST /api/v1/namespaces/kube-system/pods/79c7 355\nI1224 02:43:07.086733       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/lpqt 533\nI1224 02:43:07.286735       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/bnx2 284\nI1224 02:43:07.486734       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/l42l 526\nI1224 02:43:07.686735       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/k5s9 260\nI1224 02:43:07.886751       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/tfrx 300\nI1224 02:43:08.086732       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/ns/pods/66s 244\nI1224 02:43:08.286721       1 logs_generator.go:76] 22 GET /api/v1/namespaces/default/pods/dxn 214\nI1224 02:43:08.486755       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/ns/pods/r6r 537\nI1224 02:43:08.686727       1 logs_generator.go:76] 24 GET /api/v1/namespaces/ns/pods/mhqt 452\nI1224 02:43:08.886732       1 logs_generator.go:76] 25 PUT /api/v1/namespaces/kube-system/pods/94p 434\nI1224 02:43:09.086724       1 logs_generator.go:76] 26 PUT /api/v1/namespaces/kube-system/pods/bqq 312\nI1224 02:43:09.286734       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/ns/pods/kd6 321\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Dec 24 02:43:09.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 delete pod logs-generator --namespace=kubectl-4416'
Dec 24 02:43:11.530: INFO: stderr: ""
Dec 24 02:43:11.530: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:43:11.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4416" for this suite.
Dec 24 02:43:17.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:43:17.686: INFO: namespace kubectl-4416 deletion completed in 6.148359259s

• [SLOW TEST:15.791 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:43:17.687: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7516
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-8339e476-1755-4d5f-a607-1893dead03ed
STEP: Creating a pod to test consume configMaps
Dec 24 02:43:17.868: INFO: Waiting up to 5m0s for pod "pod-configmaps-10d4391f-7fe6-47ad-a6ee-49e1240ccc76" in namespace "configmap-7516" to be "success or failure"
Dec 24 02:43:17.875: INFO: Pod "pod-configmaps-10d4391f-7fe6-47ad-a6ee-49e1240ccc76": Phase="Pending", Reason="", readiness=false. Elapsed: 6.992765ms
Dec 24 02:43:19.891: INFO: Pod "pod-configmaps-10d4391f-7fe6-47ad-a6ee-49e1240ccc76": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022444637s
Dec 24 02:43:21.904: INFO: Pod "pod-configmaps-10d4391f-7fe6-47ad-a6ee-49e1240ccc76": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036102711s
STEP: Saw pod success
Dec 24 02:43:21.923: INFO: Pod "pod-configmaps-10d4391f-7fe6-47ad-a6ee-49e1240ccc76" satisfied condition "success or failure"
Dec 24 02:43:21.928: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-configmaps-10d4391f-7fe6-47ad-a6ee-49e1240ccc76 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 24 02:43:21.961: INFO: Waiting for pod pod-configmaps-10d4391f-7fe6-47ad-a6ee-49e1240ccc76 to disappear
Dec 24 02:43:21.967: INFO: Pod pod-configmaps-10d4391f-7fe6-47ad-a6ee-49e1240ccc76 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:43:21.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7516" for this suite.
Dec 24 02:43:27.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:43:28.140: INFO: namespace configmap-7516 deletion completed in 6.167307567s

• [SLOW TEST:10.453 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:43:28.140: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1446
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 02:43:28.304: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 24 02:43:36.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 --namespace=crd-publish-openapi-1446 create -f -'
Dec 24 02:43:37.898: INFO: stderr: ""
Dec 24 02:43:37.899: INFO: stdout: "e2e-test-crd-publish-openapi-7411-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 24 02:43:37.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 --namespace=crd-publish-openapi-1446 delete e2e-test-crd-publish-openapi-7411-crds test-cr'
Dec 24 02:43:38.018: INFO: stderr: ""
Dec 24 02:43:38.018: INFO: stdout: "e2e-test-crd-publish-openapi-7411-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Dec 24 02:43:38.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 --namespace=crd-publish-openapi-1446 apply -f -'
Dec 24 02:43:38.262: INFO: stderr: ""
Dec 24 02:43:38.262: INFO: stdout: "e2e-test-crd-publish-openapi-7411-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 24 02:43:38.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 --namespace=crd-publish-openapi-1446 delete e2e-test-crd-publish-openapi-7411-crds test-cr'
Dec 24 02:43:38.345: INFO: stderr: ""
Dec 24 02:43:38.345: INFO: stdout: "e2e-test-crd-publish-openapi-7411-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Dec 24 02:43:38.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 explain e2e-test-crd-publish-openapi-7411-crds'
Dec 24 02:43:38.585: INFO: stderr: ""
Dec 24 02:43:38.585: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7411-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:43:42.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1446" for this suite.
Dec 24 02:43:48.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:43:48.368: INFO: namespace crd-publish-openapi-1446 deletion completed in 6.176943973s

• [SLOW TEST:20.228 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:43:48.369: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4319
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Dec 24 02:43:48.537: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:44:13.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4319" for this suite.
Dec 24 02:44:19.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:44:19.886: INFO: namespace crd-publish-openapi-4319 deletion completed in 6.141869613s

• [SLOW TEST:31.518 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:44:19.887: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4674
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 24 02:44:20.045: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 24 02:44:20.063: INFO: Waiting for terminating namespaces to be deleted...
Dec 24 02:44:20.066: INFO: 
Logging pods the kubelet thinks is on node ip-172-16-103-244.ec2.internal before test
Dec 24 02:44:20.088: INFO: kublr-monitoring-alertmanager-549cf5f44c-fbdlf from kublr started at 2019-12-23 15:46:09 +0000 UTC (2 container statuses recorded)
Dec 24 02:44:20.088: INFO: 	Container alertmanager ready: true, restart count 0
Dec 24 02:44:20.088: INFO: 	Container keycloak-proxy ready: true, restart count 4
Dec 24 02:44:20.088: INFO: k8s-api-haproxy-de80cb1199e732ef3c9ca0051c41dd966f81ca8bee9c571b76dea5e659c7b97b-ip-172-16-103-244.ec2.internal from kube-system started at 2019-12-23 15:43:16 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.088: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Dec 24 02:44:20.088: INFO: canal-d28dx from kube-system started at 2019-12-23 15:44:11 +0000 UTC (4 container statuses recorded)
Dec 24 02:44:20.088: INFO: 	Container calico-node ready: true, restart count 0
Dec 24 02:44:20.088: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 24 02:44:20.088: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Dec 24 02:44:20.088: INFO: 	Container update-network-condition ready: true, restart count 0
Dec 24 02:44:20.088: INFO: kublr-logging-controller-7f5d56f594-rq5fl from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.088: INFO: 	Container kublr-feature-logging ready: true, restart count 0
Dec 24 02:44:20.089: INFO: kube-proxy-7e590abedfb7de51d1197b20e754686a6a8674ae8ac79bc64dcfdc0bb67fb64f-ip-172-16-103-244.ec2.internal from kube-system started at 2019-12-23 15:43:16 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.089: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 24 02:44:20.089: INFO: kublr-logging-rabbitmq-0 from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.089: INFO: 	Container rabbitmq ready: true, restart count 0
Dec 24 02:44:20.089: INFO: kublr-monitoring-prometheus-59564b557d-pkjhv from kublr started at 2019-12-23 15:46:15 +0000 UTC (2 container statuses recorded)
Dec 24 02:44:20.089: INFO: 	Container keycloak-proxy ready: true, restart count 4
Dec 24 02:44:20.089: INFO: 	Container prometheus ready: true, restart count 6
Dec 24 02:44:20.089: INFO: kublr-logging-elasticsearch-client-6f7d56fdbb-zgnhd from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.089: INFO: 	Container elasticsearch ready: true, restart count 0
Dec 24 02:44:20.089: INFO: kublr-monitoring-grafana-6fbbfc98f4-n9zw5 from kublr started at 2019-12-23 15:46:15 +0000 UTC (3 container statuses recorded)
Dec 24 02:44:20.089: INFO: 	Container grafana ready: true, restart count 0
Dec 24 02:44:20.089: INFO: 	Container keycloak-proxy ready: true, restart count 4
Dec 24 02:44:20.089: INFO: 	Container nginx-proxy ready: true, restart count 0
Dec 24 02:44:20.089: INFO: sonobuoy-systemd-logs-daemon-set-eb45748a27ab4169-h9v2w from sonobuoy started at 2019-12-24 01:19:59 +0000 UTC (2 container statuses recorded)
Dec 24 02:44:20.089: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 24 02:44:20.089: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 24 02:44:20.089: INFO: kublr-node-name-reporter-b5f50899e00ed5b8ad1b215b812381270bf0779993c3a6740826f2cfb378f08f-ip-172-16-103-244.ec2.internal from kube-system started at 2019-12-23 15:43:16 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.089: INFO: 	Container main ready: true, restart count 0
Dec 24 02:44:20.089: INFO: node-local-dns-hw2d5 from kube-system started at 2019-12-23 15:44:27 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.089: INFO: 	Container node-cache ready: true, restart count 0
Dec 24 02:44:20.089: INFO: kublr-logging-fluentd-es-7rd6f from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.089: INFO: 	Container fluentd-es ready: true, restart count 4
Dec 24 02:44:20.089: INFO: kublr-ingress-nginx-ingress-controller-849b4769fc-79bhq from kube-system started at 2019-12-23 15:45:19 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.089: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec 24 02:44:20.089: INFO: kublr-ingress-nginx-ingress-default-backend-7b84f6bc4b-xr9cg from kube-system started at 2019-12-23 15:45:19 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.089: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
Dec 24 02:44:20.089: INFO: 
Logging pods the kubelet thinks is on node ip-172-16-30-121.ec2.internal before test
Dec 24 02:44:20.101: INFO: kublr-monitoring-monitoring-controller-66578cf88c-fb2gk from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.101: INFO: 	Container app-monitoring ready: true, restart count 0
Dec 24 02:44:20.101: INFO: kcp-generator-6bd556bcf6-dmqbq from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.101: INFO: 	Container generator ready: true, restart count 0
Dec 24 02:44:20.101: INFO: kublr-monitoring-kube-state-metrics-5ff6484cf7-bltmp from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.101: INFO: 	Container kubestatemetrics ready: true, restart count 0
Dec 24 02:44:20.101: INFO: kublr-logging-kibana-5d84bc784d-gfh6r from kublr started at 2019-12-23 15:46:03 +0000 UTC (4 container statuses recorded)
Dec 24 02:44:20.101: INFO: 	Container keycloak-proxy ready: true, restart count 0
Dec 24 02:44:20.101: INFO: 	Container kibana ready: true, restart count 0
Dec 24 02:44:20.101: INFO: 	Container nginx-proxy ready: true, restart count 0
Dec 24 02:44:20.101: INFO: 	Container sg-auth-proxy ready: true, restart count 0
Dec 24 02:44:20.101: INFO: kcp-backup-controller-6894dbfd9f-mxv6r from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.101: INFO: 	Container backup-controller ready: true, restart count 0
Dec 24 02:44:20.101: INFO: node-local-dns-jq8bl from kube-system started at 2019-12-23 15:44:27 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.101: INFO: 	Container node-cache ready: true, restart count 0
Dec 24 02:44:20.101: INFO: kcp-kublr-ui-5d5fbd8dc5-mxf6z from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.101: INFO: 	Container kublr-ui ready: true, restart count 0
Dec 24 02:44:20.101: INFO: heapster-v1.6.0-beta.1-5f6b4bf99b-bxcwv from kube-system started at 2019-12-23 15:44:31 +0000 UTC (2 container statuses recorded)
Dec 24 02:44:20.101: INFO: 	Container heapster ready: true, restart count 0
Dec 24 02:44:20.101: INFO: 	Container heapster-nanny ready: true, restart count 0
Dec 24 02:44:20.101: INFO: kublr-logging-sg-job-kqg5q from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.101: INFO: 	Container certgenerator ready: false, restart count 0
Dec 24 02:44:20.101: INFO: kube-proxy-7e590abedfb7de51d1197b20e754686a6a8674ae8ac79bc64dcfdc0bb67fb64f-ip-172-16-30-121.ec2.internal from kube-system started at 2019-12-23 15:43:25 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.101: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 24 02:44:20.101: INFO: sonobuoy from sonobuoy started at 2019-12-24 01:19:56 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.101: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 24 02:44:20.101: INFO: kcp-cluster-controller-846969f94d-998fm from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.101: INFO: 	Container cluster-controller ready: true, restart count 0
Dec 24 02:44:20.101: INFO: kublr-logging-fluentd-es-nc4f7 from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.101: INFO: 	Container fluentd-es ready: true, restart count 4
Dec 24 02:44:20.101: INFO: kcp-app-mongodb-789bf97977-lckdz from kublr started at 2019-12-23 15:46:21 +0000 UTC (2 container statuses recorded)
Dec 24 02:44:20.101: INFO: 	Container mongo ready: true, restart count 0
Dec 24 02:44:20.101: INFO: 	Container mongo-exporter ready: true, restart count 0
Dec 24 02:44:20.101: INFO: k8s-api-haproxy-429d71c9c9d8df433e1397ffb7b8d70c5c9c56d08dcdf3f6b2e0fe52606e3c6f-ip-172-16-30-121.ec2.internal from kube-system started at 2019-12-23 15:43:25 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.101: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Dec 24 02:44:20.101: INFO: kcp-app-mysql-549dd84b74-pd89v from kublr started at 2019-12-23 15:46:21 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.101: INFO: 	Container kcp-app-mysql ready: true, restart count 0
Dec 24 02:44:20.101: INFO: sonobuoy-systemd-logs-daemon-set-eb45748a27ab4169-v9f85 from sonobuoy started at 2019-12-24 01:19:59 +0000 UTC (2 container statuses recorded)
Dec 24 02:44:20.101: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 24 02:44:20.101: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 24 02:44:20.101: INFO: kublr-node-name-reporter-c6710394cb2609cca16a8c87ff84cdb8044d9d6e9239ff3abcfbaa4768a4122f-ip-172-16-30-121.ec2.internal from kube-system started at 2019-12-23 15:43:25 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.101: INFO: 	Container main ready: true, restart count 0
Dec 24 02:44:20.101: INFO: tiller-deploy-db48c564c-gj6vz from kube-system started at 2019-12-23 15:44:34 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.101: INFO: 	Container tiller ready: true, restart count 0
Dec 24 02:44:20.101: INFO: kublr-logging-elasticsearch-master-0 from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.101: INFO: 	Container elasticsearch ready: true, restart count 0
Dec 24 02:44:20.101: INFO: kublr-logging-curator-1577149200-nkjhl from kublr started at 2019-12-24 01:00:01 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.101: INFO: 	Container curator ready: false, restart count 0
Dec 24 02:44:20.101: INFO: canal-7sp7t from kube-system started at 2019-12-23 15:44:11 +0000 UTC (4 container statuses recorded)
Dec 24 02:44:20.101: INFO: 	Container calico-node ready: true, restart count 0
Dec 24 02:44:20.101: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 24 02:44:20.101: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Dec 24 02:44:20.101: INFO: 	Container update-network-condition ready: true, restart count 0
Dec 24 02:44:20.101: INFO: 
Logging pods the kubelet thinks is on node ip-172-16-44-108.ec2.internal before test
Dec 24 02:44:20.114: INFO: kublr-logging-elasticsearch-exporter-78df7c8987-w7b6q from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.114: INFO: 	Container main ready: true, restart count 0
Dec 24 02:44:20.114: INFO: kublr-logging-elasticsearch-data-0 from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.114: INFO: 	Container elasticsearch ready: true, restart count 0
Dec 24 02:44:20.114: INFO: kcp-kublr-api-6b7d4bc968-kd9pb from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.114: INFO: 	Container kublr-api ready: true, restart count 0
Dec 24 02:44:20.114: INFO: sonobuoy-systemd-logs-daemon-set-eb45748a27ab4169-wpzc6 from sonobuoy started at 2019-12-24 01:19:59 +0000 UTC (2 container statuses recorded)
Dec 24 02:44:20.114: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 24 02:44:20.114: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 24 02:44:20.114: INFO: kublr-logging-logstash-547687bcdc-vdg4k from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.114: INFO: 	Container logstash ready: true, restart count 0
Dec 24 02:44:20.114: INFO: kube-proxy-7e590abedfb7de51d1197b20e754686a6a8674ae8ac79bc64dcfdc0bb67fb64f-ip-172-16-44-108.ec2.internal from kube-system started at 2019-12-23 15:43:19 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.114: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 24 02:44:20.114: INFO: sonobuoy-e2e-job-457b3e5a99034c4d from sonobuoy started at 2019-12-24 01:19:59 +0000 UTC (2 container statuses recorded)
Dec 24 02:44:20.114: INFO: 	Container e2e ready: true, restart count 0
Dec 24 02:44:20.114: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 24 02:44:20.114: INFO: kublr-logging-fluentd-es-bpbg6 from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.114: INFO: 	Container fluentd-es ready: true, restart count 4
Dec 24 02:44:20.114: INFO: kublr-logging-rabbitmq-exporter-dc6b44ccd-6r8ks from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.114: INFO: 	Container kublr-logging-rabbitmq-exporter ready: true, restart count 0
Dec 24 02:44:20.114: INFO: kcp-keycloak-0 from kublr started at 2019-12-23 15:46:15 +0000 UTC (2 container statuses recorded)
Dec 24 02:44:20.114: INFO: 	Container init-keycloak ready: true, restart count 0
Dec 24 02:44:20.114: INFO: 	Container kcp-keycloak ready: true, restart count 0
Dec 24 02:44:20.115: INFO: kcp-terraform-controller-6f447b77d7-v69lk from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.115: INFO: 	Container terraform-controller ready: true, restart count 0
Dec 24 02:44:20.115: INFO: metrics-server-v0.3.6-86567757d-7d792 from kube-system started at 2019-12-23 17:20:18 +0000 UTC (2 container statuses recorded)
Dec 24 02:44:20.115: INFO: 	Container metrics-server ready: true, restart count 0
Dec 24 02:44:20.115: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Dec 24 02:44:20.115: INFO: kubernetes-dashboard-84cb747b5c-td8jl from kubernetes-dashboard started at 2019-12-23 15:44:31 +0000 UTC (2 container statuses recorded)
Dec 24 02:44:20.115: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec 24 02:44:20.115: INFO: 	Container kubernetes-dashboard-auth-proxy ready: true, restart count 0
Dec 24 02:44:20.115: INFO: kublr-system-shell-6f4bcb9487-n9swc from kube-system started at 2019-12-23 15:45:12 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.115: INFO: 	Container shell ready: true, restart count 0
Dec 24 02:44:20.115: INFO: kublr-node-name-reporter-be88daf430a9d4815e9777fe7bdbbdded5de4e21fb88257b9dc4b4a05304fcee-ip-172-16-44-108.ec2.internal from kube-system started at 2019-12-23 15:43:19 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.115: INFO: 	Container main ready: true, restart count 0
Dec 24 02:44:20.115: INFO: k8s-api-haproxy-de80cb1199e732ef3c9ca0051c41dd966f81ca8bee9c571b76dea5e659c7b97b-ip-172-16-44-108.ec2.internal from kube-system started at 2019-12-23 15:43:19 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.115: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Dec 24 02:44:20.115: INFO: canal-rxhg5 from kube-system started at 2019-12-23 15:44:11 +0000 UTC (4 container statuses recorded)
Dec 24 02:44:20.115: INFO: 	Container calico-node ready: true, restart count 0
Dec 24 02:44:20.115: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 24 02:44:20.115: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Dec 24 02:44:20.115: INFO: 	Container update-network-condition ready: true, restart count 0
Dec 24 02:44:20.115: INFO: node-local-dns-dzntt from kube-system started at 2019-12-23 15:44:27 +0000 UTC (1 container statuses recorded)
Dec 24 02:44:20.115: INFO: 	Container node-cache ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15e32e88ede68f93], Reason = [FailedScheduling], Message = [0/6 nodes are available: 6 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:44:21.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4674" for this suite.
Dec 24 02:44:27.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:44:27.322: INFO: namespace sched-pred-4674 deletion completed in 6.158360389s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:7.435 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:44:27.322: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9066
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-vs8l
STEP: Creating a pod to test atomic-volume-subpath
Dec 24 02:44:27.499: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-vs8l" in namespace "subpath-9066" to be "success or failure"
Dec 24 02:44:27.503: INFO: Pod "pod-subpath-test-configmap-vs8l": Phase="Pending", Reason="", readiness=false. Elapsed: 4.113113ms
Dec 24 02:44:29.508: INFO: Pod "pod-subpath-test-configmap-vs8l": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008584934s
Dec 24 02:44:31.514: INFO: Pod "pod-subpath-test-configmap-vs8l": Phase="Running", Reason="", readiness=true. Elapsed: 4.015495839s
Dec 24 02:44:33.521: INFO: Pod "pod-subpath-test-configmap-vs8l": Phase="Running", Reason="", readiness=true. Elapsed: 6.02229803s
Dec 24 02:44:35.527: INFO: Pod "pod-subpath-test-configmap-vs8l": Phase="Running", Reason="", readiness=true. Elapsed: 8.028064965s
Dec 24 02:44:37.550: INFO: Pod "pod-subpath-test-configmap-vs8l": Phase="Running", Reason="", readiness=true. Elapsed: 10.050619362s
Dec 24 02:44:39.555: INFO: Pod "pod-subpath-test-configmap-vs8l": Phase="Running", Reason="", readiness=true. Elapsed: 12.056165882s
Dec 24 02:44:41.561: INFO: Pod "pod-subpath-test-configmap-vs8l": Phase="Running", Reason="", readiness=true. Elapsed: 14.062134253s
Dec 24 02:44:43.567: INFO: Pod "pod-subpath-test-configmap-vs8l": Phase="Running", Reason="", readiness=true. Elapsed: 16.068108978s
Dec 24 02:44:45.573: INFO: Pod "pod-subpath-test-configmap-vs8l": Phase="Running", Reason="", readiness=true. Elapsed: 18.074469067s
Dec 24 02:44:47.578: INFO: Pod "pod-subpath-test-configmap-vs8l": Phase="Running", Reason="", readiness=true. Elapsed: 20.078786597s
Dec 24 02:44:49.582: INFO: Pod "pod-subpath-test-configmap-vs8l": Phase="Running", Reason="", readiness=true. Elapsed: 22.082886072s
Dec 24 02:44:51.587: INFO: Pod "pod-subpath-test-configmap-vs8l": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.088511644s
STEP: Saw pod success
Dec 24 02:44:51.588: INFO: Pod "pod-subpath-test-configmap-vs8l" satisfied condition "success or failure"
Dec 24 02:44:51.593: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-subpath-test-configmap-vs8l container test-container-subpath-configmap-vs8l: <nil>
STEP: delete the pod
Dec 24 02:44:51.620: INFO: Waiting for pod pod-subpath-test-configmap-vs8l to disappear
Dec 24 02:44:51.623: INFO: Pod pod-subpath-test-configmap-vs8l no longer exists
STEP: Deleting pod pod-subpath-test-configmap-vs8l
Dec 24 02:44:51.623: INFO: Deleting pod "pod-subpath-test-configmap-vs8l" in namespace "subpath-9066"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:44:51.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9066" for this suite.
Dec 24 02:44:57.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:44:57.802: INFO: namespace subpath-9066 deletion completed in 6.163414322s

• [SLOW TEST:30.480 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:44:57.802: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4636
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:44:57.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4636" for this suite.
Dec 24 02:45:03.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:45:04.143: INFO: namespace services-4636 deletion completed in 6.175751611s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.340 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:45:04.143: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5783
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Dec 24 02:45:04.309: INFO: Waiting up to 5m0s for pod "client-containers-d3fa703e-d217-4baa-a48c-931e34ed9652" in namespace "containers-5783" to be "success or failure"
Dec 24 02:45:04.313: INFO: Pod "client-containers-d3fa703e-d217-4baa-a48c-931e34ed9652": Phase="Pending", Reason="", readiness=false. Elapsed: 3.357423ms
Dec 24 02:45:06.317: INFO: Pod "client-containers-d3fa703e-d217-4baa-a48c-931e34ed9652": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007264042s
Dec 24 02:45:08.326: INFO: Pod "client-containers-d3fa703e-d217-4baa-a48c-931e34ed9652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016953228s
STEP: Saw pod success
Dec 24 02:45:08.327: INFO: Pod "client-containers-d3fa703e-d217-4baa-a48c-931e34ed9652" satisfied condition "success or failure"
Dec 24 02:45:08.330: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod client-containers-d3fa703e-d217-4baa-a48c-931e34ed9652 container test-container: <nil>
STEP: delete the pod
Dec 24 02:45:08.359: INFO: Waiting for pod client-containers-d3fa703e-d217-4baa-a48c-931e34ed9652 to disappear
Dec 24 02:45:08.363: INFO: Pod client-containers-d3fa703e-d217-4baa-a48c-931e34ed9652 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:45:08.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5783" for this suite.
Dec 24 02:45:14.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:45:14.536: INFO: namespace containers-5783 deletion completed in 6.166253895s

• [SLOW TEST:10.393 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:45:14.536: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4607
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-4607
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-4607
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4607
Dec 24 02:45:14.716: INFO: Found 0 stateful pods, waiting for 1
Dec 24 02:45:24.723: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec 24 02:45:24.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=statefulset-4607 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 24 02:45:24.948: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 24 02:45:24.948: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 24 02:45:24.948: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 24 02:45:24.955: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 24 02:45:34.960: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 24 02:45:34.960: INFO: Waiting for statefulset status.replicas updated to 0
Dec 24 02:45:34.993: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998415s
Dec 24 02:45:36.008: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.983886268s
Dec 24 02:45:37.013: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.976729689s
Dec 24 02:45:38.018: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.971960949s
Dec 24 02:45:39.023: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.967095423s
Dec 24 02:45:40.030: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.9617029s
Dec 24 02:45:41.034: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.954867986s
Dec 24 02:45:42.040: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.950609818s
Dec 24 02:45:43.046: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.945162364s
Dec 24 02:45:44.050: INFO: Verifying statefulset ss doesn't scale past 1 for another 938.926534ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4607
Dec 24 02:45:45.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=statefulset-4607 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 24 02:45:45.325: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 24 02:45:45.325: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 24 02:45:45.325: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 24 02:45:45.331: INFO: Found 1 stateful pods, waiting for 3
Dec 24 02:45:55.338: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 24 02:45:55.338: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 24 02:45:55.338: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec 24 02:45:55.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=statefulset-4607 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 24 02:45:55.583: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 24 02:45:55.583: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 24 02:45:55.583: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 24 02:45:55.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=statefulset-4607 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 24 02:45:55.790: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 24 02:45:55.790: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 24 02:45:55.790: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 24 02:45:55.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=statefulset-4607 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 24 02:45:56.028: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 24 02:45:56.028: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 24 02:45:56.028: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 24 02:45:56.028: INFO: Waiting for statefulset status.replicas updated to 0
Dec 24 02:45:56.032: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec 24 02:46:06.042: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 24 02:46:06.042: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 24 02:46:06.042: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 24 02:46:06.058: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998595s
Dec 24 02:46:07.063: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993106235s
Dec 24 02:46:08.071: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.986564073s
Dec 24 02:46:09.077: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.980713092s
Dec 24 02:46:10.082: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.974497002s
Dec 24 02:46:11.089: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.969379565s
Dec 24 02:46:12.096: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.96270943s
Dec 24 02:46:13.100: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.955819s
Dec 24 02:46:14.109: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.95108703s
Dec 24 02:46:15.116: INFO: Verifying statefulset ss doesn't scale past 3 for another 942.308639ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4607
Dec 24 02:46:16.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=statefulset-4607 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 24 02:46:16.340: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 24 02:46:16.340: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 24 02:46:16.340: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 24 02:46:16.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=statefulset-4607 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 24 02:46:16.557: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 24 02:46:16.557: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 24 02:46:16.557: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 24 02:46:16.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=statefulset-4607 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 24 02:46:16.796: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 24 02:46:16.796: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 24 02:46:16.796: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 24 02:46:16.796: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 24 02:46:36.836: INFO: Deleting all statefulset in ns statefulset-4607
Dec 24 02:46:36.851: INFO: Scaling statefulset ss to 0
Dec 24 02:46:36.884: INFO: Waiting for statefulset status.replicas updated to 0
Dec 24 02:46:36.895: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:46:36.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4607" for this suite.
Dec 24 02:46:43.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:46:43.214: INFO: namespace statefulset-4607 deletion completed in 6.20862022s

• [SLOW TEST:88.678 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:46:43.215: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8040
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-bf11ed36-7631-4b8f-94fc-9dddb898dfb4 in namespace container-probe-8040
Dec 24 02:46:47.391: INFO: Started pod busybox-bf11ed36-7631-4b8f-94fc-9dddb898dfb4 in namespace container-probe-8040
STEP: checking the pod's current state and verifying that restartCount is present
Dec 24 02:46:47.397: INFO: Initial restart count of pod busybox-bf11ed36-7631-4b8f-94fc-9dddb898dfb4 is 0
Dec 24 02:47:33.549: INFO: Restart count of pod container-probe-8040/busybox-bf11ed36-7631-4b8f-94fc-9dddb898dfb4 is now 1 (46.152431062s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:47:33.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8040" for this suite.
Dec 24 02:47:39.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:47:39.774: INFO: namespace container-probe-8040 deletion completed in 6.174904429s

• [SLOW TEST:56.560 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:47:39.774: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3837
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-abcd59cc-8fdb-41d8-8fed-5a2a501014f3
STEP: Creating a pod to test consume secrets
Dec 24 02:47:39.943: INFO: Waiting up to 5m0s for pod "pod-secrets-94620b1c-7032-474a-9c07-60e4bb3101c7" in namespace "secrets-3837" to be "success or failure"
Dec 24 02:47:39.947: INFO: Pod "pod-secrets-94620b1c-7032-474a-9c07-60e4bb3101c7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.274948ms
Dec 24 02:47:41.953: INFO: Pod "pod-secrets-94620b1c-7032-474a-9c07-60e4bb3101c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009444271s
Dec 24 02:47:43.961: INFO: Pod "pod-secrets-94620b1c-7032-474a-9c07-60e4bb3101c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017521345s
STEP: Saw pod success
Dec 24 02:47:43.961: INFO: Pod "pod-secrets-94620b1c-7032-474a-9c07-60e4bb3101c7" satisfied condition "success or failure"
Dec 24 02:47:43.965: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod pod-secrets-94620b1c-7032-474a-9c07-60e4bb3101c7 container secret-volume-test: <nil>
STEP: delete the pod
Dec 24 02:47:44.047: INFO: Waiting for pod pod-secrets-94620b1c-7032-474a-9c07-60e4bb3101c7 to disappear
Dec 24 02:47:44.054: INFO: Pod pod-secrets-94620b1c-7032-474a-9c07-60e4bb3101c7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:47:44.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3837" for this suite.
Dec 24 02:47:50.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:47:50.291: INFO: namespace secrets-3837 deletion completed in 6.214744091s

• [SLOW TEST:10.517 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:47:50.294: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-6883
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec 24 02:47:55.520: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:47:56.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6883" for this suite.
Dec 24 02:48:24.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:48:24.709: INFO: namespace replicaset-6883 deletion completed in 28.161041973s

• [SLOW TEST:34.415 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:48:24.709: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-4289
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:48:28.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4289" for this suite.
Dec 24 02:48:34.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:48:35.134: INFO: namespace emptydir-wrapper-4289 deletion completed in 6.162036447s

• [SLOW TEST:10.425 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:48:35.134: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8961
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 24 02:48:38.324: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:48:38.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8961" for this suite.
Dec 24 02:48:44.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:48:44.546: INFO: namespace container-runtime-8961 deletion completed in 6.190677272s

• [SLOW TEST:9.412 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:48:44.547: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3896
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 24 02:48:44.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-3896'
Dec 24 02:48:44.825: INFO: stderr: ""
Dec 24 02:48:44.825: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Dec 24 02:48:44.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 delete pods e2e-test-httpd-pod --namespace=kubectl-3896'
Dec 24 02:48:55.239: INFO: stderr: ""
Dec 24 02:48:55.239: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:48:55.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3896" for this suite.
Dec 24 02:49:01.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:49:01.415: INFO: namespace kubectl-3896 deletion completed in 6.166945181s

• [SLOW TEST:16.869 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:49:01.415: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-575
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-575.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-575.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-575.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-575.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-575.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-575.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-575.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-575.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-575.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-575.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-575.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-575.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-575.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-575.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-575.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-575.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-575.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-575.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 24 02:49:05.645: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-575.svc.cluster.local from pod dns-575/dns-test-06008d20-95fb-49a0-bc4a-3346a35110e8: the server could not find the requested resource (get pods dns-test-06008d20-95fb-49a0-bc4a-3346a35110e8)
Dec 24 02:49:05.652: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-575.svc.cluster.local from pod dns-575/dns-test-06008d20-95fb-49a0-bc4a-3346a35110e8: the server could not find the requested resource (get pods dns-test-06008d20-95fb-49a0-bc4a-3346a35110e8)
Dec 24 02:49:05.658: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-575.svc.cluster.local from pod dns-575/dns-test-06008d20-95fb-49a0-bc4a-3346a35110e8: the server could not find the requested resource (get pods dns-test-06008d20-95fb-49a0-bc4a-3346a35110e8)
Dec 24 02:49:05.665: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-575.svc.cluster.local from pod dns-575/dns-test-06008d20-95fb-49a0-bc4a-3346a35110e8: the server could not find the requested resource (get pods dns-test-06008d20-95fb-49a0-bc4a-3346a35110e8)
Dec 24 02:49:05.686: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-575.svc.cluster.local from pod dns-575/dns-test-06008d20-95fb-49a0-bc4a-3346a35110e8: the server could not find the requested resource (get pods dns-test-06008d20-95fb-49a0-bc4a-3346a35110e8)
Dec 24 02:49:05.692: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-575.svc.cluster.local from pod dns-575/dns-test-06008d20-95fb-49a0-bc4a-3346a35110e8: the server could not find the requested resource (get pods dns-test-06008d20-95fb-49a0-bc4a-3346a35110e8)
Dec 24 02:49:05.701: INFO: Unable to read jessie_udp@dns-test-service-2.dns-575.svc.cluster.local from pod dns-575/dns-test-06008d20-95fb-49a0-bc4a-3346a35110e8: the server could not find the requested resource (get pods dns-test-06008d20-95fb-49a0-bc4a-3346a35110e8)
Dec 24 02:49:05.705: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-575.svc.cluster.local from pod dns-575/dns-test-06008d20-95fb-49a0-bc4a-3346a35110e8: the server could not find the requested resource (get pods dns-test-06008d20-95fb-49a0-bc4a-3346a35110e8)
Dec 24 02:49:05.718: INFO: Lookups using dns-575/dns-test-06008d20-95fb-49a0-bc4a-3346a35110e8 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-575.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-575.svc.cluster.local wheezy_udp@dns-test-service-2.dns-575.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-575.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-575.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-575.svc.cluster.local jessie_udp@dns-test-service-2.dns-575.svc.cluster.local jessie_tcp@dns-test-service-2.dns-575.svc.cluster.local]

Dec 24 02:49:10.803: INFO: DNS probes using dns-575/dns-test-06008d20-95fb-49a0-bc4a-3346a35110e8 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:49:10.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-575" for this suite.
Dec 24 02:49:16.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:49:17.015: INFO: namespace dns-575 deletion completed in 6.16247005s

• [SLOW TEST:15.600 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:49:17.015: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-4170
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec 24 02:49:21.198: INFO: &Pod{ObjectMeta:{send-events-0a8a91a8-4357-416d-aae0-00334356086e  events-4170 /api/v1/namespaces/events-4170/pods/send-events-0a8a91a8-4357-416d-aae0-00334356086e 95245081-d8d8-41ca-a51f-2f380bb86133 139785 0 2019-12-24 02:49:17 +0000 UTC <nil> <nil> map[name:foo time:166336469] map[cni.projectcalico.org/podIP:100.96.4.196/32 kubernetes.io/psp:e2e-test-privileged-psp] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bq266,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bq266,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bq266,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-30-121.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:49:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:49:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:49:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:49:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.16.30.121,PodIP:100.96.4.196,StartTime:2019-12-24 02:49:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-24 02:49:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:docker://ac8391fde1479fe3a9da0b322792f7e416568d16cc4682c99447221ddbd3d4f1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.4.196,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Dec 24 02:49:23.204: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec 24 02:49:25.209: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:49:25.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4170" for this suite.
Dec 24 02:50:09.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:50:09.519: INFO: namespace events-4170 deletion completed in 44.293630712s

• [SLOW TEST:52.503 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:50:09.519: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-226
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-m8zkz in namespace proxy-226
I1224 02:50:09.706902      24 runners.go:184] Created replication controller with name: proxy-service-m8zkz, namespace: proxy-226, replica count: 1
I1224 02:50:10.758989      24 runners.go:184] proxy-service-m8zkz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1224 02:50:11.759200      24 runners.go:184] proxy-service-m8zkz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1224 02:50:12.759420      24 runners.go:184] proxy-service-m8zkz Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 24 02:50:12.766: INFO: setup took 3.086830968s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec 24 02:50:12.779: INFO: (0) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 13.018161ms)
Dec 24 02:50:12.779: INFO: (0) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 12.917133ms)
Dec 24 02:50:12.781: INFO: (0) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/rewriteme">test</a> (200; 14.87948ms)
Dec 24 02:50:12.781: INFO: (0) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">test</... (200; 14.919355ms)
Dec 24 02:50:12.781: INFO: (0) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 14.882569ms)
Dec 24 02:50:12.783: INFO: (0) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:462/proxy/: tls qux (200; 17.210448ms)
Dec 24 02:50:12.783: INFO: (0) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 17.056155ms)
Dec 24 02:50:12.784: INFO: (0) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname1/proxy/: foo (200; 18.412892ms)
Dec 24 02:50:12.785: INFO: (0) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname2/proxy/: bar (200; 19.267388ms)
Dec 24 02:50:12.785: INFO: (0) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">t... (200; 19.213961ms)
Dec 24 02:50:12.786: INFO: (0) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname2/proxy/: bar (200; 19.855365ms)
Dec 24 02:50:12.786: INFO: (0) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname2/proxy/: tls qux (200; 19.990378ms)
Dec 24 02:50:12.787: INFO: (0) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:460/proxy/: tls baz (200; 21.292195ms)
Dec 24 02:50:12.788: INFO: (0) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname1/proxy/: tls baz (200; 21.921857ms)
Dec 24 02:50:12.789: INFO: (0) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/tlsrewriteme... (200; 22.956323ms)
Dec 24 02:50:12.790: INFO: (0) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname1/proxy/: foo (200; 23.857812ms)
Dec 24 02:50:12.797: INFO: (1) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 6.77366ms)
Dec 24 02:50:12.798: INFO: (1) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 7.843525ms)
Dec 24 02:50:12.799: INFO: (1) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 8.6565ms)
Dec 24 02:50:12.799: INFO: (1) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:460/proxy/: tls baz (200; 9.141661ms)
Dec 24 02:50:12.800: INFO: (1) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:462/proxy/: tls qux (200; 9.428713ms)
Dec 24 02:50:12.801: INFO: (1) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">test</... (200; 10.956519ms)
Dec 24 02:50:12.801: INFO: (1) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/rewriteme">test</a> (200; 11.17658ms)
Dec 24 02:50:12.803: INFO: (1) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/tlsrewriteme... (200; 12.909199ms)
Dec 24 02:50:12.803: INFO: (1) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">t... (200; 12.851185ms)
Dec 24 02:50:12.803: INFO: (1) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 13.283626ms)
Dec 24 02:50:12.805: INFO: (1) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname1/proxy/: tls baz (200; 14.644625ms)
Dec 24 02:50:12.805: INFO: (1) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname1/proxy/: foo (200; 14.972427ms)
Dec 24 02:50:12.805: INFO: (1) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname2/proxy/: tls qux (200; 15.20013ms)
Dec 24 02:50:12.806: INFO: (1) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname1/proxy/: foo (200; 16.295301ms)
Dec 24 02:50:12.807: INFO: (1) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname2/proxy/: bar (200; 16.551903ms)
Dec 24 02:50:12.807: INFO: (1) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname2/proxy/: bar (200; 16.618494ms)
Dec 24 02:50:12.815: INFO: (2) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">test</... (200; 8.070735ms)
Dec 24 02:50:12.816: INFO: (2) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">t... (200; 8.269153ms)
Dec 24 02:50:12.816: INFO: (2) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 8.194022ms)
Dec 24 02:50:12.817: INFO: (2) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/tlsrewriteme... (200; 9.447793ms)
Dec 24 02:50:12.819: INFO: (2) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 11.768573ms)
Dec 24 02:50:12.819: INFO: (2) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname1/proxy/: foo (200; 12.400368ms)
Dec 24 02:50:12.819: INFO: (2) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 12.091179ms)
Dec 24 02:50:12.820: INFO: (2) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/rewriteme">test</a> (200; 11.958775ms)
Dec 24 02:50:12.820: INFO: (2) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:460/proxy/: tls baz (200; 12.679599ms)
Dec 24 02:50:12.820: INFO: (2) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:462/proxy/: tls qux (200; 12.626003ms)
Dec 24 02:50:12.821: INFO: (2) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 13.812971ms)
Dec 24 02:50:12.822: INFO: (2) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname1/proxy/: foo (200; 13.495311ms)
Dec 24 02:50:12.822: INFO: (2) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname2/proxy/: bar (200; 13.660344ms)
Dec 24 02:50:12.822: INFO: (2) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname1/proxy/: tls baz (200; 15.154488ms)
Dec 24 02:50:12.824: INFO: (2) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname2/proxy/: tls qux (200; 16.033403ms)
Dec 24 02:50:12.826: INFO: (2) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname2/proxy/: bar (200; 18.778306ms)
Dec 24 02:50:12.834: INFO: (3) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:460/proxy/: tls baz (200; 7.102927ms)
Dec 24 02:50:12.836: INFO: (3) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">t... (200; 9.014038ms)
Dec 24 02:50:12.836: INFO: (3) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 9.371858ms)
Dec 24 02:50:12.836: INFO: (3) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:462/proxy/: tls qux (200; 9.80099ms)
Dec 24 02:50:12.838: INFO: (3) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname2/proxy/: bar (200; 11.817223ms)
Dec 24 02:50:12.841: INFO: (3) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 14.397639ms)
Dec 24 02:50:12.841: INFO: (3) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 14.492619ms)
Dec 24 02:50:12.841: INFO: (3) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/tlsrewriteme... (200; 14.555255ms)
Dec 24 02:50:12.842: INFO: (3) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">test</... (200; 14.801875ms)
Dec 24 02:50:12.842: INFO: (3) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname1/proxy/: foo (200; 15.163039ms)
Dec 24 02:50:12.842: INFO: (3) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname1/proxy/: tls baz (200; 15.736737ms)
Dec 24 02:50:12.843: INFO: (3) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 16.084795ms)
Dec 24 02:50:12.844: INFO: (3) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/rewriteme">test</a> (200; 17.159961ms)
Dec 24 02:50:12.844: INFO: (3) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname1/proxy/: foo (200; 17.308793ms)
Dec 24 02:50:12.845: INFO: (3) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname2/proxy/: tls qux (200; 18.633396ms)
Dec 24 02:50:12.847: INFO: (3) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname2/proxy/: bar (200; 19.948038ms)
Dec 24 02:50:12.856: INFO: (4) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">t... (200; 9.085647ms)
Dec 24 02:50:12.856: INFO: (4) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/tlsrewriteme... (200; 8.909997ms)
Dec 24 02:50:12.856: INFO: (4) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:460/proxy/: tls baz (200; 9.493131ms)
Dec 24 02:50:12.856: INFO: (4) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 9.568141ms)
Dec 24 02:50:12.859: INFO: (4) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname1/proxy/: foo (200; 12.257798ms)
Dec 24 02:50:12.860: INFO: (4) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 12.740856ms)
Dec 24 02:50:12.860: INFO: (4) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:462/proxy/: tls qux (200; 13.147102ms)
Dec 24 02:50:12.860: INFO: (4) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/rewriteme">test</a> (200; 13.279257ms)
Dec 24 02:50:12.860: INFO: (4) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname2/proxy/: tls qux (200; 13.757515ms)
Dec 24 02:50:12.861: INFO: (4) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 13.606105ms)
Dec 24 02:50:12.862: INFO: (4) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 14.496956ms)
Dec 24 02:50:12.862: INFO: (4) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">test</... (200; 14.577605ms)
Dec 24 02:50:12.864: INFO: (4) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname1/proxy/: tls baz (200; 16.792828ms)
Dec 24 02:50:12.864: INFO: (4) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname1/proxy/: foo (200; 17.127285ms)
Dec 24 02:50:12.864: INFO: (4) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname2/proxy/: bar (200; 17.586922ms)
Dec 24 02:50:12.866: INFO: (4) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname2/proxy/: bar (200; 18.915902ms)
Dec 24 02:50:12.873: INFO: (5) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 7.128236ms)
Dec 24 02:50:12.874: INFO: (5) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 8.437575ms)
Dec 24 02:50:12.875: INFO: (5) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/rewriteme">test</a> (200; 8.465049ms)
Dec 24 02:50:12.876: INFO: (5) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/tlsrewriteme... (200; 9.788717ms)
Dec 24 02:50:12.877: INFO: (5) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname1/proxy/: foo (200; 10.568964ms)
Dec 24 02:50:12.877: INFO: (5) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 10.604182ms)
Dec 24 02:50:12.877: INFO: (5) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 10.732927ms)
Dec 24 02:50:12.878: INFO: (5) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">test</... (200; 11.741117ms)
Dec 24 02:50:12.880: INFO: (5) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:460/proxy/: tls baz (200; 13.252229ms)
Dec 24 02:50:12.880: INFO: (5) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:462/proxy/: tls qux (200; 13.236428ms)
Dec 24 02:50:12.880: INFO: (5) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">t... (200; 14.395398ms)
Dec 24 02:50:12.881: INFO: (5) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname1/proxy/: foo (200; 14.626294ms)
Dec 24 02:50:12.881: INFO: (5) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname2/proxy/: bar (200; 15.347115ms)
Dec 24 02:50:12.882: INFO: (5) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname1/proxy/: tls baz (200; 15.636259ms)
Dec 24 02:50:12.883: INFO: (5) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname2/proxy/: bar (200; 16.486122ms)
Dec 24 02:50:12.884: INFO: (5) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname2/proxy/: tls qux (200; 17.551086ms)
Dec 24 02:50:12.890: INFO: (6) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">t... (200; 6.261354ms)
Dec 24 02:50:12.892: INFO: (6) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/tlsrewriteme... (200; 7.026992ms)
Dec 24 02:50:12.892: INFO: (6) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/rewriteme">test</a> (200; 7.751675ms)
Dec 24 02:50:12.892: INFO: (6) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:462/proxy/: tls qux (200; 8.286163ms)
Dec 24 02:50:12.897: INFO: (6) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 13.156368ms)
Dec 24 02:50:12.897: INFO: (6) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">test</... (200; 13.359542ms)
Dec 24 02:50:12.897: INFO: (6) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 13.236652ms)
Dec 24 02:50:12.897: INFO: (6) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:460/proxy/: tls baz (200; 13.176902ms)
Dec 24 02:50:12.898: INFO: (6) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname2/proxy/: tls qux (200; 13.316166ms)
Dec 24 02:50:12.898: INFO: (6) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 13.732794ms)
Dec 24 02:50:12.898: INFO: (6) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 13.694936ms)
Dec 24 02:50:12.899: INFO: (6) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname1/proxy/: foo (200; 15.030286ms)
Dec 24 02:50:12.899: INFO: (6) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname1/proxy/: foo (200; 15.106754ms)
Dec 24 02:50:12.900: INFO: (6) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname2/proxy/: bar (200; 15.392533ms)
Dec 24 02:50:12.903: INFO: (6) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname1/proxy/: tls baz (200; 18.331907ms)
Dec 24 02:50:12.903: INFO: (6) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname2/proxy/: bar (200; 18.557039ms)
Dec 24 02:50:12.910: INFO: (7) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/tlsrewriteme... (200; 6.589578ms)
Dec 24 02:50:12.910: INFO: (7) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">t... (200; 7.015409ms)
Dec 24 02:50:12.911: INFO: (7) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 7.619297ms)
Dec 24 02:50:12.911: INFO: (7) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:460/proxy/: tls baz (200; 7.651734ms)
Dec 24 02:50:12.912: INFO: (7) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 8.091299ms)
Dec 24 02:50:12.915: INFO: (7) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/rewriteme">test</a> (200; 11.176373ms)
Dec 24 02:50:12.915: INFO: (7) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 11.527943ms)
Dec 24 02:50:12.915: INFO: (7) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 12.050695ms)
Dec 24 02:50:12.915: INFO: (7) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">test</... (200; 11.893475ms)
Dec 24 02:50:12.915: INFO: (7) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:462/proxy/: tls qux (200; 11.553188ms)
Dec 24 02:50:12.917: INFO: (7) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname2/proxy/: tls qux (200; 13.905874ms)
Dec 24 02:50:12.917: INFO: (7) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname1/proxy/: tls baz (200; 14.130788ms)
Dec 24 02:50:12.918: INFO: (7) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname2/proxy/: bar (200; 14.541487ms)
Dec 24 02:50:12.919: INFO: (7) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname1/proxy/: foo (200; 16.012284ms)
Dec 24 02:50:12.920: INFO: (7) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname1/proxy/: foo (200; 17.152574ms)
Dec 24 02:50:12.921: INFO: (7) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname2/proxy/: bar (200; 16.981939ms)
Dec 24 02:50:12.927: INFO: (8) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/rewriteme">test</a> (200; 6.158956ms)
Dec 24 02:50:12.928: INFO: (8) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 7.271611ms)
Dec 24 02:50:12.930: INFO: (8) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/tlsrewriteme... (200; 8.908856ms)
Dec 24 02:50:12.930: INFO: (8) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 9.080316ms)
Dec 24 02:50:12.931: INFO: (8) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname1/proxy/: foo (200; 9.906366ms)
Dec 24 02:50:12.931: INFO: (8) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">t... (200; 9.797755ms)
Dec 24 02:50:12.931: INFO: (8) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">test</... (200; 10.061164ms)
Dec 24 02:50:12.932: INFO: (8) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 10.591106ms)
Dec 24 02:50:12.935: INFO: (8) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 13.614159ms)
Dec 24 02:50:12.935: INFO: (8) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:460/proxy/: tls baz (200; 13.932574ms)
Dec 24 02:50:12.936: INFO: (8) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:462/proxy/: tls qux (200; 14.901363ms)
Dec 24 02:50:12.936: INFO: (8) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname1/proxy/: tls baz (200; 14.970028ms)
Dec 24 02:50:12.937: INFO: (8) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname2/proxy/: bar (200; 16.437254ms)
Dec 24 02:50:12.939: INFO: (8) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname2/proxy/: tls qux (200; 17.575239ms)
Dec 24 02:50:12.939: INFO: (8) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname1/proxy/: foo (200; 17.430922ms)
Dec 24 02:50:12.939: INFO: (8) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname2/proxy/: bar (200; 17.417627ms)
Dec 24 02:50:12.949: INFO: (9) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 10.425458ms)
Dec 24 02:50:12.949: INFO: (9) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">test</... (200; 10.319344ms)
Dec 24 02:50:12.949: INFO: (9) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/tlsrewriteme... (200; 10.40329ms)
Dec 24 02:50:12.949: INFO: (9) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname1/proxy/: foo (200; 10.8195ms)
Dec 24 02:50:12.949: INFO: (9) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:460/proxy/: tls baz (200; 10.520092ms)
Dec 24 02:50:12.953: INFO: (9) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">t... (200; 14.100943ms)
Dec 24 02:50:12.955: INFO: (9) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname1/proxy/: foo (200; 15.86241ms)
Dec 24 02:50:12.955: INFO: (9) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 15.843641ms)
Dec 24 02:50:12.955: INFO: (9) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:462/proxy/: tls qux (200; 15.736131ms)
Dec 24 02:50:12.955: INFO: (9) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/rewriteme">test</a> (200; 15.954908ms)
Dec 24 02:50:12.955: INFO: (9) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname1/proxy/: tls baz (200; 16.26069ms)
Dec 24 02:50:12.955: INFO: (9) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 16.546054ms)
Dec 24 02:50:12.955: INFO: (9) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 16.465571ms)
Dec 24 02:50:12.959: INFO: (9) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname2/proxy/: bar (200; 19.79956ms)
Dec 24 02:50:12.959: INFO: (9) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname2/proxy/: bar (200; 19.898646ms)
Dec 24 02:50:12.961: INFO: (9) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname2/proxy/: tls qux (200; 22.310016ms)
Dec 24 02:50:12.968: INFO: (10) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/rewriteme">test</a> (200; 6.758072ms)
Dec 24 02:50:12.969: INFO: (10) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:460/proxy/: tls baz (200; 7.154784ms)
Dec 24 02:50:12.969: INFO: (10) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 7.563025ms)
Dec 24 02:50:12.969: INFO: (10) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/tlsrewriteme... (200; 7.69208ms)
Dec 24 02:50:12.971: INFO: (10) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">test</... (200; 9.383401ms)
Dec 24 02:50:12.972: INFO: (10) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname1/proxy/: foo (200; 10.487241ms)
Dec 24 02:50:12.973: INFO: (10) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 11.765709ms)
Dec 24 02:50:12.975: INFO: (10) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">t... (200; 12.992518ms)
Dec 24 02:50:12.975: INFO: (10) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 13.093604ms)
Dec 24 02:50:12.975: INFO: (10) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname2/proxy/: bar (200; 13.157035ms)
Dec 24 02:50:12.975: INFO: (10) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 13.554019ms)
Dec 24 02:50:12.976: INFO: (10) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:462/proxy/: tls qux (200; 13.931295ms)
Dec 24 02:50:12.977: INFO: (10) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname1/proxy/: foo (200; 15.529432ms)
Dec 24 02:50:12.978: INFO: (10) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname1/proxy/: tls baz (200; 16.077318ms)
Dec 24 02:50:12.979: INFO: (10) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname2/proxy/: tls qux (200; 17.939604ms)
Dec 24 02:50:12.980: INFO: (10) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname2/proxy/: bar (200; 18.082616ms)
Dec 24 02:50:12.986: INFO: (11) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 5.838885ms)
Dec 24 02:50:12.987: INFO: (11) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">t... (200; 7.043345ms)
Dec 24 02:50:12.989: INFO: (11) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:460/proxy/: tls baz (200; 9.038796ms)
Dec 24 02:50:12.989: INFO: (11) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 9.349641ms)
Dec 24 02:50:12.990: INFO: (11) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:462/proxy/: tls qux (200; 10.006879ms)
Dec 24 02:50:12.990: INFO: (11) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">test</... (200; 10.199886ms)
Dec 24 02:50:12.990: INFO: (11) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 10.076739ms)
Dec 24 02:50:12.992: INFO: (11) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 11.630954ms)
Dec 24 02:50:12.994: INFO: (11) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/tlsrewriteme... (200; 14.327419ms)
Dec 24 02:50:12.995: INFO: (11) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/rewriteme">test</a> (200; 14.627537ms)
Dec 24 02:50:12.995: INFO: (11) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname1/proxy/: foo (200; 15.196362ms)
Dec 24 02:50:12.996: INFO: (11) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname1/proxy/: foo (200; 15.487002ms)
Dec 24 02:50:12.996: INFO: (11) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname2/proxy/: bar (200; 16.29804ms)
Dec 24 02:50:12.997: INFO: (11) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname1/proxy/: tls baz (200; 17.284802ms)
Dec 24 02:50:12.999: INFO: (11) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname2/proxy/: bar (200; 18.669361ms)
Dec 24 02:50:13.000: INFO: (11) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname2/proxy/: tls qux (200; 19.98295ms)
Dec 24 02:50:13.008: INFO: (12) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/tlsrewriteme... (200; 8.070484ms)
Dec 24 02:50:13.008: INFO: (12) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 8.059478ms)
Dec 24 02:50:13.009: INFO: (12) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:462/proxy/: tls qux (200; 8.734338ms)
Dec 24 02:50:13.009: INFO: (12) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/rewriteme">test</a> (200; 8.874902ms)
Dec 24 02:50:13.009: INFO: (12) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:460/proxy/: tls baz (200; 9.351486ms)
Dec 24 02:50:13.010: INFO: (12) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname2/proxy/: tls qux (200; 10.022799ms)
Dec 24 02:50:13.010: INFO: (12) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 9.822026ms)
Dec 24 02:50:13.011: INFO: (12) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 10.30966ms)
Dec 24 02:50:13.012: INFO: (12) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">t... (200; 11.892877ms)
Dec 24 02:50:13.013: INFO: (12) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">test</... (200; 12.76323ms)
Dec 24 02:50:13.013: INFO: (12) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 12.884432ms)
Dec 24 02:50:13.015: INFO: (12) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname2/proxy/: bar (200; 14.63182ms)
Dec 24 02:50:13.015: INFO: (12) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname1/proxy/: foo (200; 14.785064ms)
Dec 24 02:50:13.016: INFO: (12) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname1/proxy/: tls baz (200; 15.530008ms)
Dec 24 02:50:13.016: INFO: (12) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname2/proxy/: bar (200; 16.36392ms)
Dec 24 02:50:13.018: INFO: (12) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname1/proxy/: foo (200; 17.617088ms)
Dec 24 02:50:13.027: INFO: (13) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 8.665522ms)
Dec 24 02:50:13.027: INFO: (13) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">t... (200; 8.684317ms)
Dec 24 02:50:13.027: INFO: (13) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:460/proxy/: tls baz (200; 9.191221ms)
Dec 24 02:50:13.029: INFO: (13) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:462/proxy/: tls qux (200; 11.064419ms)
Dec 24 02:50:13.030: INFO: (13) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 11.834985ms)
Dec 24 02:50:13.031: INFO: (13) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname2/proxy/: bar (200; 13.184244ms)
Dec 24 02:50:13.031: INFO: (13) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 13.263415ms)
Dec 24 02:50:13.033: INFO: (13) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname2/proxy/: bar (200; 15.420895ms)
Dec 24 02:50:13.034: INFO: (13) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/tlsrewriteme... (200; 16.533289ms)
Dec 24 02:50:13.034: INFO: (13) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname1/proxy/: tls baz (200; 16.219996ms)
Dec 24 02:50:13.035: INFO: (13) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 17.204147ms)
Dec 24 02:50:13.036: INFO: (13) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname1/proxy/: foo (200; 17.352543ms)
Dec 24 02:50:13.036: INFO: (13) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/rewriteme">test</a> (200; 17.815798ms)
Dec 24 02:50:13.036: INFO: (13) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname1/proxy/: foo (200; 18.216994ms)
Dec 24 02:50:13.037: INFO: (13) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname2/proxy/: tls qux (200; 18.624237ms)
Dec 24 02:50:13.037: INFO: (13) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">test</... (200; 19.080368ms)
Dec 24 02:50:13.043: INFO: (14) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">test</... (200; 6.195814ms)
Dec 24 02:50:13.045: INFO: (14) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:462/proxy/: tls qux (200; 7.779465ms)
Dec 24 02:50:13.046: INFO: (14) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 8.425212ms)
Dec 24 02:50:13.046: INFO: (14) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/rewriteme">test</a> (200; 8.800997ms)
Dec 24 02:50:13.048: INFO: (14) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 10.849048ms)
Dec 24 02:50:13.049: INFO: (14) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/tlsrewriteme... (200; 11.56709ms)
Dec 24 02:50:13.049: INFO: (14) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname1/proxy/: tls baz (200; 11.842355ms)
Dec 24 02:50:13.050: INFO: (14) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 12.137803ms)
Dec 24 02:50:13.052: INFO: (14) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 14.791496ms)
Dec 24 02:50:13.052: INFO: (14) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:460/proxy/: tls baz (200; 14.913092ms)
Dec 24 02:50:13.053: INFO: (14) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">t... (200; 15.384016ms)
Dec 24 02:50:13.053: INFO: (14) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname1/proxy/: foo (200; 15.113556ms)
Dec 24 02:50:13.053: INFO: (14) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname2/proxy/: bar (200; 15.477566ms)
Dec 24 02:50:13.055: INFO: (14) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname1/proxy/: foo (200; 17.528027ms)
Dec 24 02:50:13.055: INFO: (14) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname2/proxy/: tls qux (200; 17.996201ms)
Dec 24 02:50:13.057: INFO: (14) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname2/proxy/: bar (200; 19.413556ms)
Dec 24 02:50:13.063: INFO: (15) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 6.226211ms)
Dec 24 02:50:13.065: INFO: (15) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/tlsrewriteme... (200; 8.235936ms)
Dec 24 02:50:13.066: INFO: (15) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 8.752857ms)
Dec 24 02:50:13.068: INFO: (15) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 11.197043ms)
Dec 24 02:50:13.068: INFO: (15) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">test</... (200; 11.436646ms)
Dec 24 02:50:13.070: INFO: (15) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:462/proxy/: tls qux (200; 13.0316ms)
Dec 24 02:50:13.070: INFO: (15) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">t... (200; 12.959028ms)
Dec 24 02:50:13.070: INFO: (15) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/rewriteme">test</a> (200; 13.160235ms)
Dec 24 02:50:13.071: INFO: (15) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:460/proxy/: tls baz (200; 13.995686ms)
Dec 24 02:50:13.072: INFO: (15) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname1/proxy/: foo (200; 14.457649ms)
Dec 24 02:50:13.072: INFO: (15) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname2/proxy/: bar (200; 15.284859ms)
Dec 24 02:50:13.073: INFO: (15) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 16.10504ms)
Dec 24 02:50:13.074: INFO: (15) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname1/proxy/: tls baz (200; 17.31185ms)
Dec 24 02:50:13.075: INFO: (15) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname1/proxy/: foo (200; 18.428282ms)
Dec 24 02:50:13.077: INFO: (15) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname2/proxy/: tls qux (200; 19.778852ms)
Dec 24 02:50:13.077: INFO: (15) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname2/proxy/: bar (200; 19.888454ms)
Dec 24 02:50:13.085: INFO: (16) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 8.147642ms)
Dec 24 02:50:13.086: INFO: (16) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 8.703508ms)
Dec 24 02:50:13.089: INFO: (16) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/rewriteme">test</a> (200; 11.416688ms)
Dec 24 02:50:13.089: INFO: (16) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/tlsrewriteme... (200; 11.657152ms)
Dec 24 02:50:13.089: INFO: (16) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">t... (200; 11.648004ms)
Dec 24 02:50:13.089: INFO: (16) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">test</... (200; 11.643089ms)
Dec 24 02:50:13.090: INFO: (16) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:460/proxy/: tls baz (200; 12.764599ms)
Dec 24 02:50:13.091: INFO: (16) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:462/proxy/: tls qux (200; 12.921914ms)
Dec 24 02:50:13.091: INFO: (16) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 13.303993ms)
Dec 24 02:50:13.091: INFO: (16) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 13.778703ms)
Dec 24 02:50:13.091: INFO: (16) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname2/proxy/: bar (200; 13.960988ms)
Dec 24 02:50:13.092: INFO: (16) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname2/proxy/: tls qux (200; 14.689335ms)
Dec 24 02:50:13.093: INFO: (16) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname2/proxy/: bar (200; 15.446181ms)
Dec 24 02:50:13.096: INFO: (16) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname1/proxy/: foo (200; 18.236662ms)
Dec 24 02:50:13.097: INFO: (16) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname1/proxy/: tls baz (200; 18.988281ms)
Dec 24 02:50:13.098: INFO: (16) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname1/proxy/: foo (200; 20.395792ms)
Dec 24 02:50:13.106: INFO: (17) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:460/proxy/: tls baz (200; 7.662817ms)
Dec 24 02:50:13.107: INFO: (17) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/rewriteme">test</a> (200; 8.418317ms)
Dec 24 02:50:13.107: INFO: (17) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 8.502851ms)
Dec 24 02:50:13.108: INFO: (17) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname1/proxy/: foo (200; 9.635055ms)
Dec 24 02:50:13.109: INFO: (17) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 10.563781ms)
Dec 24 02:50:13.109: INFO: (17) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">test</... (200; 10.77244ms)
Dec 24 02:50:13.110: INFO: (17) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/tlsrewriteme... (200; 11.530788ms)
Dec 24 02:50:13.110: INFO: (17) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 11.751751ms)
Dec 24 02:50:13.112: INFO: (17) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">t... (200; 13.710235ms)
Dec 24 02:50:13.112: INFO: (17) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:462/proxy/: tls qux (200; 14.067222ms)
Dec 24 02:50:13.112: INFO: (17) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname1/proxy/: foo (200; 14.079285ms)
Dec 24 02:50:13.113: INFO: (17) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 15.236551ms)
Dec 24 02:50:13.114: INFO: (17) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname1/proxy/: tls baz (200; 15.743471ms)
Dec 24 02:50:13.115: INFO: (17) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname2/proxy/: tls qux (200; 16.598658ms)
Dec 24 02:50:13.116: INFO: (17) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname2/proxy/: bar (200; 17.988219ms)
Dec 24 02:50:13.117: INFO: (17) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname2/proxy/: bar (200; 18.522919ms)
Dec 24 02:50:13.124: INFO: (18) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:462/proxy/: tls qux (200; 7.421432ms)
Dec 24 02:50:13.125: INFO: (18) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:460/proxy/: tls baz (200; 8.00639ms)
Dec 24 02:50:13.125: INFO: (18) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 8.068316ms)
Dec 24 02:50:13.126: INFO: (18) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/rewriteme">test</a> (200; 8.686545ms)
Dec 24 02:50:13.126: INFO: (18) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 9.37228ms)
Dec 24 02:50:13.128: INFO: (18) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 10.681939ms)
Dec 24 02:50:13.128: INFO: (18) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">t... (200; 10.928628ms)
Dec 24 02:50:13.128: INFO: (18) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname2/proxy/: bar (200; 11.315525ms)
Dec 24 02:50:13.129: INFO: (18) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 12.406599ms)
Dec 24 02:50:13.130: INFO: (18) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/tlsrewriteme... (200; 13.431063ms)
Dec 24 02:50:13.131: INFO: (18) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">test</... (200; 13.697142ms)
Dec 24 02:50:13.132: INFO: (18) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname1/proxy/: tls baz (200; 15.027463ms)
Dec 24 02:50:13.133: INFO: (18) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname1/proxy/: foo (200; 16.463737ms)
Dec 24 02:50:13.134: INFO: (18) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname1/proxy/: foo (200; 16.771939ms)
Dec 24 02:50:13.137: INFO: (18) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname2/proxy/: tls qux (200; 19.718398ms)
Dec 24 02:50:13.137: INFO: (18) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname2/proxy/: bar (200; 20.262226ms)
Dec 24 02:50:13.145: INFO: (19) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6/proxy/rewriteme">test</a> (200; 7.658651ms)
Dec 24 02:50:13.146: INFO: (19) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:443/proxy/tlsrewriteme... (200; 8.314513ms)
Dec 24 02:50:13.146: INFO: (19) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">t... (200; 8.464947ms)
Dec 24 02:50:13.146: INFO: (19) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 8.724648ms)
Dec 24 02:50:13.148: INFO: (19) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:462/proxy/: tls qux (200; 10.563781ms)
Dec 24 02:50:13.148: INFO: (19) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 10.812146ms)
Dec 24 02:50:13.148: INFO: (19) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:160/proxy/: foo (200; 11.127921ms)
Dec 24 02:50:13.150: INFO: (19) /api/v1/namespaces/proxy-226/pods/http:proxy-service-m8zkz-9zfh6:162/proxy/: bar (200; 12.304633ms)
Dec 24 02:50:13.151: INFO: (19) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname1/proxy/: foo (200; 13.289324ms)
Dec 24 02:50:13.152: INFO: (19) /api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/: <a href="/api/v1/namespaces/proxy-226/pods/proxy-service-m8zkz-9zfh6:1080/proxy/rewriteme">test</... (200; 14.136907ms)
Dec 24 02:50:13.152: INFO: (19) /api/v1/namespaces/proxy-226/pods/https:proxy-service-m8zkz-9zfh6:460/proxy/: tls baz (200; 14.666532ms)
Dec 24 02:50:13.152: INFO: (19) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname2/proxy/: tls qux (200; 14.653301ms)
Dec 24 02:50:13.153: INFO: (19) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname1/proxy/: foo (200; 15.262019ms)
Dec 24 02:50:13.154: INFO: (19) /api/v1/namespaces/proxy-226/services/https:proxy-service-m8zkz:tlsportname1/proxy/: tls baz (200; 16.129097ms)
Dec 24 02:50:13.154: INFO: (19) /api/v1/namespaces/proxy-226/services/proxy-service-m8zkz:portname2/proxy/: bar (200; 17.032132ms)
Dec 24 02:50:13.158: INFO: (19) /api/v1/namespaces/proxy-226/services/http:proxy-service-m8zkz:portname2/proxy/: bar (200; 20.828031ms)
STEP: deleting ReplicationController proxy-service-m8zkz in namespace proxy-226, will wait for the garbage collector to delete the pods
Dec 24 02:50:13.224: INFO: Deleting ReplicationController proxy-service-m8zkz took: 10.644116ms
Dec 24 02:50:13.625: INFO: Terminating ReplicationController proxy-service-m8zkz pods took: 400.256246ms
[AfterEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:50:16.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-226" for this suite.
Dec 24 02:50:22.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:50:22.189: INFO: namespace proxy-226 deletion completed in 6.154889484s

• [SLOW TEST:12.670 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:50:22.190: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5839
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:50:46.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5839" for this suite.
Dec 24 02:50:52.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:50:52.934: INFO: namespace container-runtime-5839 deletion completed in 6.212532315s

• [SLOW TEST:30.745 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:50:52.934: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3829
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-3829
STEP: creating replication controller nodeport-test in namespace services-3829
I1224 02:50:53.136827      24 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-3829, replica count: 2
Dec 24 02:50:56.187: INFO: Creating new exec pod
I1224 02:50:56.187348      24 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 24 02:51:01.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=services-3829 execpod85qxn -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Dec 24 02:51:03.466: INFO: rc: 1
Dec 24 02:51:03.466: INFO: Service reachability failing with error: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=services-3829 execpod85qxn -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80] []  <nil>  + nc -zv -t -w 2 nodeport-test 80
nc: connect to nodeport-test port 80 (tcp) timed out: Operation in progress
command terminated with exit code 1
 [] <nil> 0xc002788fc0 exit status 1 <nil> <nil> true [0xc001a5fa48 0xc001a5fac0 0xc001a5fb60] [0xc001a5fa48 0xc001a5fac0 0xc001a5fb60] [0xc001a5fab0 0xc001a5fb38] [0x10efe30 0x10efe30] 0xc002f50de0 <nil>}:
Command stdout:

stderr:
+ nc -zv -t -w 2 nodeport-test 80
nc: connect to nodeport-test port 80 (tcp) timed out: Operation in progress
command terminated with exit code 1

error:
exit status 1
Retrying...
Dec 24 02:51:04.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=services-3829 execpod85qxn -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Dec 24 02:51:04.703: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Dec 24 02:51:04.703: INFO: stdout: ""
Dec 24 02:51:04.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=services-3829 execpod85qxn -- /bin/sh -x -c nc -zv -t -w 2 100.69.105.216 80'
Dec 24 02:51:04.929: INFO: stderr: "+ nc -zv -t -w 2 100.69.105.216 80\nConnection to 100.69.105.216 80 port [tcp/http] succeeded!\n"
Dec 24 02:51:04.929: INFO: stdout: ""
Dec 24 02:51:04.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=services-3829 execpod85qxn -- /bin/sh -x -c nc -zv -t -w 2 172.16.103.244 32235'
Dec 24 02:51:05.193: INFO: stderr: "+ nc -zv -t -w 2 172.16.103.244 32235\nConnection to 172.16.103.244 32235 port [tcp/32235] succeeded!\n"
Dec 24 02:51:05.193: INFO: stdout: ""
Dec 24 02:51:05.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=services-3829 execpod85qxn -- /bin/sh -x -c nc -zv -t -w 2 172.16.30.121 32235'
Dec 24 02:51:05.444: INFO: stderr: "+ nc -zv -t -w 2 172.16.30.121 32235\nConnection to 172.16.30.121 32235 port [tcp/32235] succeeded!\n"
Dec 24 02:51:05.444: INFO: stdout: ""
Dec 24 02:51:05.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=services-3829 execpod85qxn -- /bin/sh -x -c nc -zv -t -w 2 34.231.180.117 32235'
Dec 24 02:51:05.667: INFO: stderr: "+ nc -zv -t -w 2 34.231.180.117 32235\nConnection to 34.231.180.117 32235 port [tcp/32235] succeeded!\n"
Dec 24 02:51:05.667: INFO: stdout: ""
Dec 24 02:51:05.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=services-3829 execpod85qxn -- /bin/sh -x -c nc -zv -t -w 2 54.211.144.53 32235'
Dec 24 02:51:05.910: INFO: stderr: "+ nc -zv -t -w 2 54.211.144.53 32235\nConnection to 54.211.144.53 32235 port [tcp/32235] succeeded!\n"
Dec 24 02:51:05.910: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:51:05.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3829" for this suite.
Dec 24 02:51:11.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:51:12.082: INFO: namespace services-3829 deletion completed in 6.162354658s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:19.147 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:51:12.082: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9678
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:51:16.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9678" for this suite.
Dec 24 02:51:22.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:51:22.887: INFO: namespace watch-9678 deletion completed in 6.24517298s

• [SLOW TEST:10.805 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:51:22.887: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7861
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec 24 02:51:33.166: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1224 02:51:33.166159      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:51:33.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7861" for this suite.
Dec 24 02:51:39.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:51:39.405: INFO: namespace gc-7861 deletion completed in 6.233945247s

• [SLOW TEST:16.518 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:51:39.405: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-4475
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Dec 24 02:51:39.566: INFO: Waiting up to 5m0s for pod "var-expansion-00c96117-bbfa-4539-ac63-0a44ebc1b995" in namespace "var-expansion-4475" to be "success or failure"
Dec 24 02:51:39.573: INFO: Pod "var-expansion-00c96117-bbfa-4539-ac63-0a44ebc1b995": Phase="Pending", Reason="", readiness=false. Elapsed: 6.451792ms
Dec 24 02:51:41.577: INFO: Pod "var-expansion-00c96117-bbfa-4539-ac63-0a44ebc1b995": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010744438s
Dec 24 02:51:43.582: INFO: Pod "var-expansion-00c96117-bbfa-4539-ac63-0a44ebc1b995": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01531675s
STEP: Saw pod success
Dec 24 02:51:43.582: INFO: Pod "var-expansion-00c96117-bbfa-4539-ac63-0a44ebc1b995" satisfied condition "success or failure"
Dec 24 02:51:43.586: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod var-expansion-00c96117-bbfa-4539-ac63-0a44ebc1b995 container dapi-container: <nil>
STEP: delete the pod
Dec 24 02:51:43.614: INFO: Waiting for pod var-expansion-00c96117-bbfa-4539-ac63-0a44ebc1b995 to disappear
Dec 24 02:51:43.620: INFO: Pod var-expansion-00c96117-bbfa-4539-ac63-0a44ebc1b995 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:51:43.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4475" for this suite.
Dec 24 02:51:49.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:51:49.828: INFO: namespace var-expansion-4475 deletion completed in 6.196333479s

• [SLOW TEST:10.423 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:51:49.829: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9312
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 02:51:49.998: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec 24 02:51:50.015: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 24 02:51:55.022: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 24 02:51:55.022: INFO: Creating deployment "test-rolling-update-deployment"
Dec 24 02:51:55.030: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec 24 02:51:55.038: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec 24 02:51:57.047: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec 24 02:51:57.052: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712752715, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712752715, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712752715, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712752715, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 24 02:51:59.056: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 24 02:51:59.073: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-9312 /apis/apps/v1/namespaces/deployment-9312/deployments/test-rolling-update-deployment d3ec6150-dca0-47d4-9a01-39b3223fddf4 140863 1 2019-12-24 02:51:55 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005510ea8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-24 02:51:55 +0000 UTC,LastTransitionTime:2019-12-24 02:51:55 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2019-12-24 02:51:57 +0000 UTC,LastTransitionTime:2019-12-24 02:51:55 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 24 02:51:59.079: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-9312 /apis/apps/v1/namespaces/deployment-9312/replicasets/test-rolling-update-deployment-55d946486 eb5771c7-965f-4cd6-b767-1d2327318c84 140853 1 2019-12-24 02:51:55 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment d3ec6150-dca0-47d4-9a01-39b3223fddf4 0xc005511390 0xc005511391}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0055113f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 24 02:51:59.079: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec 24 02:51:59.079: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-9312 /apis/apps/v1/namespaces/deployment-9312/replicasets/test-rolling-update-controller e4515d0c-fc0c-4f82-94ce-f68244724525 140862 2 2019-12-24 02:51:49 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment d3ec6150-dca0-47d4-9a01-39b3223fddf4 0xc0055112c7 0xc0055112c8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005511328 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 24 02:51:59.083: INFO: Pod "test-rolling-update-deployment-55d946486-dbs5c" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-dbs5c test-rolling-update-deployment-55d946486- deployment-9312 /api/v1/namespaces/deployment-9312/pods/test-rolling-update-deployment-55d946486-dbs5c c5037bb7-74e8-4fee-b2cb-5cb22a845775 140852 0 2019-12-24 02:51:55 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[cni.projectcalico.org/podIP:100.96.3.215/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 eb5771c7-965f-4cd6-b767-1d2327318c84 0xc005511880 0xc005511881}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-xk9g7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-xk9g7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-xk9g7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-16-44-108.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:51:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:51:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:51:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-24 02:51:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.16.44.108,PodIP:100.96.3.215,StartTime:2019-12-24 02:51:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-24 02:51:56 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://c9fc7e37d03a547b53cf0033cff4d3c0ce0895f565aab1f3e991622dd95ba5e3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.3.215,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:51:59.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9312" for this suite.
Dec 24 02:52:05.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:52:05.342: INFO: namespace deployment-9312 deletion completed in 6.252992984s

• [SLOW TEST:15.513 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:52:05.342: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4335
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Dec 24 02:52:05.505: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-304826164 proxy --unix-socket=/tmp/kubectl-proxy-unix387695911/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:52:05.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4335" for this suite.
Dec 24 02:52:11.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:52:11.765: INFO: namespace kubectl-4335 deletion completed in 6.163236876s

• [SLOW TEST:6.423 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:52:11.765: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-711
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 24 02:52:11.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-711'
Dec 24 02:52:11.995: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 24 02:52:11.995: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Dec 24 02:52:12.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 delete jobs e2e-test-httpd-job --namespace=kubectl-711'
Dec 24 02:52:12.100: INFO: stderr: ""
Dec 24 02:52:12.101: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:52:12.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-711" for this suite.
Dec 24 02:52:40.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:52:40.290: INFO: namespace kubectl-711 deletion completed in 28.182849098s

• [SLOW TEST:28.525 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:52:40.290: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5892
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:52:51.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5892" for this suite.
Dec 24 02:52:57.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:52:57.741: INFO: namespace resourcequota-5892 deletion completed in 6.190523152s

• [SLOW TEST:17.451 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:52:57.741: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1683
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-f9e4f7ce-1cf0-4328-aabf-3617c48db4f8
STEP: Creating a pod to test consume configMaps
Dec 24 02:52:57.910: INFO: Waiting up to 5m0s for pod "pod-configmaps-6918ffa2-52fe-422b-8e30-b236a2701cd7" in namespace "configmap-1683" to be "success or failure"
Dec 24 02:52:57.918: INFO: Pod "pod-configmaps-6918ffa2-52fe-422b-8e30-b236a2701cd7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.056904ms
Dec 24 02:52:59.922: INFO: Pod "pod-configmaps-6918ffa2-52fe-422b-8e30-b236a2701cd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012447631s
Dec 24 02:53:01.937: INFO: Pod "pod-configmaps-6918ffa2-52fe-422b-8e30-b236a2701cd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026919002s
STEP: Saw pod success
Dec 24 02:53:01.937: INFO: Pod "pod-configmaps-6918ffa2-52fe-422b-8e30-b236a2701cd7" satisfied condition "success or failure"
Dec 24 02:53:01.948: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-configmaps-6918ffa2-52fe-422b-8e30-b236a2701cd7 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 24 02:53:01.991: INFO: Waiting for pod pod-configmaps-6918ffa2-52fe-422b-8e30-b236a2701cd7 to disappear
Dec 24 02:53:02.000: INFO: Pod pod-configmaps-6918ffa2-52fe-422b-8e30-b236a2701cd7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:53:02.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1683" for this suite.
Dec 24 02:53:08.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:53:08.238: INFO: namespace configmap-1683 deletion completed in 6.232530133s

• [SLOW TEST:10.497 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:53:08.239: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6429
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-6429
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 24 02:53:08.404: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 24 02:53:34.575: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.3.217:8080/dial?request=hostName&protocol=http&host=100.96.4.208&port=8080&tries=1'] Namespace:pod-network-test-6429 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 24 02:53:34.576: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 02:53:34.735: INFO: Waiting for endpoints: map[]
Dec 24 02:53:34.741: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.3.217:8080/dial?request=hostName&protocol=http&host=100.96.3.216&port=8080&tries=1'] Namespace:pod-network-test-6429 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 24 02:53:34.741: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 02:53:34.889: INFO: Waiting for endpoints: map[]
Dec 24 02:53:34.892: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.3.217:8080/dial?request=hostName&protocol=http&host=100.96.5.138&port=8080&tries=1'] Namespace:pod-network-test-6429 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 24 02:53:34.892: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 02:53:35.040: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:53:35.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6429" for this suite.
Dec 24 02:53:47.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:53:47.221: INFO: namespace pod-network-test-6429 deletion completed in 12.174545533s

• [SLOW TEST:38.982 seconds]
[sig-network] Networking
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:53:47.221: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3871
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-15713dc7-36b9-4456-925e-9f52c3493aa4
STEP: Creating a pod to test consume configMaps
Dec 24 02:53:47.403: INFO: Waiting up to 5m0s for pod "pod-configmaps-adf40e85-3c49-4b01-b8cf-31cd1b7a155e" in namespace "configmap-3871" to be "success or failure"
Dec 24 02:53:47.408: INFO: Pod "pod-configmaps-adf40e85-3c49-4b01-b8cf-31cd1b7a155e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.382539ms
Dec 24 02:53:49.412: INFO: Pod "pod-configmaps-adf40e85-3c49-4b01-b8cf-31cd1b7a155e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009562382s
Dec 24 02:53:51.425: INFO: Pod "pod-configmaps-adf40e85-3c49-4b01-b8cf-31cd1b7a155e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022080875s
STEP: Saw pod success
Dec 24 02:53:51.425: INFO: Pod "pod-configmaps-adf40e85-3c49-4b01-b8cf-31cd1b7a155e" satisfied condition "success or failure"
Dec 24 02:53:51.428: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod pod-configmaps-adf40e85-3c49-4b01-b8cf-31cd1b7a155e container configmap-volume-test: <nil>
STEP: delete the pod
Dec 24 02:53:51.460: INFO: Waiting for pod pod-configmaps-adf40e85-3c49-4b01-b8cf-31cd1b7a155e to disappear
Dec 24 02:53:51.469: INFO: Pod pod-configmaps-adf40e85-3c49-4b01-b8cf-31cd1b7a155e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:53:51.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3871" for this suite.
Dec 24 02:53:57.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:53:57.645: INFO: namespace configmap-3871 deletion completed in 6.16686971s

• [SLOW TEST:10.424 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:53:57.645: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1002
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-1002/configmap-test-39cacd55-94f0-4faf-b001-c2da4b2cd518
STEP: Creating a pod to test consume configMaps
Dec 24 02:53:57.812: INFO: Waiting up to 5m0s for pod "pod-configmaps-31f42459-92fb-4df4-9d9c-2a04b1f72b79" in namespace "configmap-1002" to be "success or failure"
Dec 24 02:53:57.817: INFO: Pod "pod-configmaps-31f42459-92fb-4df4-9d9c-2a04b1f72b79": Phase="Pending", Reason="", readiness=false. Elapsed: 5.02291ms
Dec 24 02:53:59.821: INFO: Pod "pod-configmaps-31f42459-92fb-4df4-9d9c-2a04b1f72b79": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00896749s
Dec 24 02:54:01.828: INFO: Pod "pod-configmaps-31f42459-92fb-4df4-9d9c-2a04b1f72b79": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015911953s
STEP: Saw pod success
Dec 24 02:54:01.828: INFO: Pod "pod-configmaps-31f42459-92fb-4df4-9d9c-2a04b1f72b79" satisfied condition "success or failure"
Dec 24 02:54:01.832: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod pod-configmaps-31f42459-92fb-4df4-9d9c-2a04b1f72b79 container env-test: <nil>
STEP: delete the pod
Dec 24 02:54:01.862: INFO: Waiting for pod pod-configmaps-31f42459-92fb-4df4-9d9c-2a04b1f72b79 to disappear
Dec 24 02:54:01.866: INFO: Pod pod-configmaps-31f42459-92fb-4df4-9d9c-2a04b1f72b79 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:54:01.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1002" for this suite.
Dec 24 02:54:07.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:54:08.023: INFO: namespace configmap-1002 deletion completed in 6.149204056s

• [SLOW TEST:10.378 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:54:08.023: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2096
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec 24 02:54:14.227: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1224 02:54:14.227421      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:54:14.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2096" for this suite.
Dec 24 02:54:22.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:54:22.432: INFO: namespace gc-2096 deletion completed in 8.19724307s

• [SLOW TEST:14.409 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:54:22.432: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-1586
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 02:54:22.607: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-1ebfb928-5dbd-4b01-80cb-f1ad85b8011d" in namespace "security-context-test-1586" to be "success or failure"
Dec 24 02:54:22.634: INFO: Pod "busybox-privileged-false-1ebfb928-5dbd-4b01-80cb-f1ad85b8011d": Phase="Pending", Reason="", readiness=false. Elapsed: 26.384812ms
Dec 24 02:54:24.638: INFO: Pod "busybox-privileged-false-1ebfb928-5dbd-4b01-80cb-f1ad85b8011d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030700643s
Dec 24 02:54:26.643: INFO: Pod "busybox-privileged-false-1ebfb928-5dbd-4b01-80cb-f1ad85b8011d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036004379s
Dec 24 02:54:26.643: INFO: Pod "busybox-privileged-false-1ebfb928-5dbd-4b01-80cb-f1ad85b8011d" satisfied condition "success or failure"
Dec 24 02:54:26.664: INFO: Got logs for pod "busybox-privileged-false-1ebfb928-5dbd-4b01-80cb-f1ad85b8011d": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:54:26.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1586" for this suite.
Dec 24 02:54:32.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:54:32.883: INFO: namespace security-context-test-1586 deletion completed in 6.209772767s

• [SLOW TEST:10.451 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:54:32.883: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8612
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:54:37.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8612" for this suite.
Dec 24 02:55:29.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:55:29.255: INFO: namespace kubelet-test-8612 deletion completed in 52.168876623s

• [SLOW TEST:56.372 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:55:29.255: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6445
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 24 02:55:29.426: INFO: Waiting up to 5m0s for pod "pod-eeff84d1-df91-4aad-93ff-d07b5ba48c40" in namespace "emptydir-6445" to be "success or failure"
Dec 24 02:55:29.447: INFO: Pod "pod-eeff84d1-df91-4aad-93ff-d07b5ba48c40": Phase="Pending", Reason="", readiness=false. Elapsed: 21.16982ms
Dec 24 02:55:31.453: INFO: Pod "pod-eeff84d1-df91-4aad-93ff-d07b5ba48c40": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027066981s
Dec 24 02:55:33.464: INFO: Pod "pod-eeff84d1-df91-4aad-93ff-d07b5ba48c40": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037489507s
STEP: Saw pod success
Dec 24 02:55:33.464: INFO: Pod "pod-eeff84d1-df91-4aad-93ff-d07b5ba48c40" satisfied condition "success or failure"
Dec 24 02:55:33.469: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-eeff84d1-df91-4aad-93ff-d07b5ba48c40 container test-container: <nil>
STEP: delete the pod
Dec 24 02:55:33.501: INFO: Waiting for pod pod-eeff84d1-df91-4aad-93ff-d07b5ba48c40 to disappear
Dec 24 02:55:33.504: INFO: Pod pod-eeff84d1-df91-4aad-93ff-d07b5ba48c40 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:55:33.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6445" for this suite.
Dec 24 02:55:39.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:55:39.712: INFO: namespace emptydir-6445 deletion completed in 6.172792324s

• [SLOW TEST:10.457 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:55:39.712: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5867
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 24 02:55:47.952: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 24 02:55:47.958: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 24 02:55:49.962: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 24 02:55:49.970: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 24 02:55:51.959: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 24 02:55:51.963: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:55:51.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5867" for this suite.
Dec 24 02:56:03.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:56:04.155: INFO: namespace container-lifecycle-hook-5867 deletion completed in 12.17277273s

• [SLOW TEST:24.443 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:56:04.156: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-343
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 24 02:56:04.937: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 24 02:56:06.953: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712752964, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712752964, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712752964, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712752964, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 24 02:56:09.986: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:56:10.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-343" for this suite.
Dec 24 02:56:22.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:56:22.263: INFO: namespace webhook-343 deletion completed in 12.171108804s
STEP: Destroying namespace "webhook-343-markers" for this suite.
Dec 24 02:56:28.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:56:28.463: INFO: namespace webhook-343-markers deletion completed in 6.199575077s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.332 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:56:28.488: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3326
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-31752de8-8fe8-4d77-b12b-a6d24a88e196
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:56:28.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3326" for this suite.
Dec 24 02:56:34.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:56:34.829: INFO: namespace secrets-3326 deletion completed in 6.167508694s

• [SLOW TEST:6.341 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:56:34.829: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1462
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 02:56:34.987: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 24 02:56:43.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 --namespace=crd-publish-openapi-1462 create -f -'
Dec 24 02:56:44.303: INFO: stderr: ""
Dec 24 02:56:44.303: INFO: stdout: "e2e-test-crd-publish-openapi-208-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 24 02:56:44.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 --namespace=crd-publish-openapi-1462 delete e2e-test-crd-publish-openapi-208-crds test-cr'
Dec 24 02:56:44.458: INFO: stderr: ""
Dec 24 02:56:44.458: INFO: stdout: "e2e-test-crd-publish-openapi-208-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Dec 24 02:56:44.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 --namespace=crd-publish-openapi-1462 apply -f -'
Dec 24 02:56:44.760: INFO: stderr: ""
Dec 24 02:56:44.760: INFO: stdout: "e2e-test-crd-publish-openapi-208-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 24 02:56:44.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 --namespace=crd-publish-openapi-1462 delete e2e-test-crd-publish-openapi-208-crds test-cr'
Dec 24 02:56:44.871: INFO: stderr: ""
Dec 24 02:56:44.872: INFO: stdout: "e2e-test-crd-publish-openapi-208-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec 24 02:56:44.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 explain e2e-test-crd-publish-openapi-208-crds'
Dec 24 02:56:45.129: INFO: stderr: ""
Dec 24 02:56:45.129: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-208-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:56:48.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1462" for this suite.
Dec 24 02:56:54.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:56:54.878: INFO: namespace crd-publish-openapi-1462 deletion completed in 6.147283422s

• [SLOW TEST:20.049 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:56:54.878: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3329
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Dec 24 02:56:56.118: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1224 02:56:56.118102      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:56:56.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3329" for this suite.
Dec 24 02:57:02.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:57:02.285: INFO: namespace gc-3329 deletion completed in 6.161501835s

• [SLOW TEST:7.406 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:57:02.286: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6420
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:57:09.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6420" for this suite.
Dec 24 02:57:15.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:57:15.652: INFO: namespace resourcequota-6420 deletion completed in 6.173849022s

• [SLOW TEST:13.367 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:57:15.652: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-218
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 24 02:57:15.818: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 24 02:57:15.836: INFO: Waiting for terminating namespaces to be deleted...
Dec 24 02:57:15.839: INFO: 
Logging pods the kubelet thinks is on node ip-172-16-103-244.ec2.internal before test
Dec 24 02:57:15.870: INFO: k8s-api-haproxy-de80cb1199e732ef3c9ca0051c41dd966f81ca8bee9c571b76dea5e659c7b97b-ip-172-16-103-244.ec2.internal from kube-system started at 2019-12-23 15:43:16 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.870: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Dec 24 02:57:15.870: INFO: canal-d28dx from kube-system started at 2019-12-23 15:44:11 +0000 UTC (4 container statuses recorded)
Dec 24 02:57:15.870: INFO: 	Container calico-node ready: true, restart count 0
Dec 24 02:57:15.870: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 24 02:57:15.870: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Dec 24 02:57:15.870: INFO: 	Container update-network-condition ready: true, restart count 0
Dec 24 02:57:15.870: INFO: kublr-logging-controller-7f5d56f594-rq5fl from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.870: INFO: 	Container kublr-feature-logging ready: true, restart count 0
Dec 24 02:57:15.870: INFO: kublr-monitoring-alertmanager-549cf5f44c-fbdlf from kublr started at 2019-12-23 15:46:09 +0000 UTC (2 container statuses recorded)
Dec 24 02:57:15.870: INFO: 	Container alertmanager ready: true, restart count 0
Dec 24 02:57:15.870: INFO: 	Container keycloak-proxy ready: true, restart count 4
Dec 24 02:57:15.870: INFO: kube-proxy-7e590abedfb7de51d1197b20e754686a6a8674ae8ac79bc64dcfdc0bb67fb64f-ip-172-16-103-244.ec2.internal from kube-system started at 2019-12-23 15:43:16 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.870: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 24 02:57:15.870: INFO: kublr-logging-rabbitmq-0 from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.870: INFO: 	Container rabbitmq ready: true, restart count 0
Dec 24 02:57:15.870: INFO: kublr-monitoring-prometheus-59564b557d-pkjhv from kublr started at 2019-12-23 15:46:15 +0000 UTC (2 container statuses recorded)
Dec 24 02:57:15.870: INFO: 	Container keycloak-proxy ready: true, restart count 4
Dec 24 02:57:15.870: INFO: 	Container prometheus ready: true, restart count 6
Dec 24 02:57:15.870: INFO: kublr-node-name-reporter-b5f50899e00ed5b8ad1b215b812381270bf0779993c3a6740826f2cfb378f08f-ip-172-16-103-244.ec2.internal from kube-system started at 2019-12-23 15:43:16 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.870: INFO: 	Container main ready: true, restart count 0
Dec 24 02:57:15.870: INFO: node-local-dns-hw2d5 from kube-system started at 2019-12-23 15:44:27 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.870: INFO: 	Container node-cache ready: true, restart count 0
Dec 24 02:57:15.870: INFO: kublr-logging-fluentd-es-7rd6f from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.870: INFO: 	Container fluentd-es ready: true, restart count 4
Dec 24 02:57:15.870: INFO: kublr-logging-elasticsearch-client-6f7d56fdbb-zgnhd from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.870: INFO: 	Container elasticsearch ready: true, restart count 0
Dec 24 02:57:15.870: INFO: kublr-monitoring-grafana-6fbbfc98f4-n9zw5 from kublr started at 2019-12-23 15:46:15 +0000 UTC (3 container statuses recorded)
Dec 24 02:57:15.870: INFO: 	Container grafana ready: true, restart count 0
Dec 24 02:57:15.870: INFO: 	Container keycloak-proxy ready: true, restart count 4
Dec 24 02:57:15.870: INFO: 	Container nginx-proxy ready: true, restart count 0
Dec 24 02:57:15.870: INFO: sonobuoy-systemd-logs-daemon-set-eb45748a27ab4169-h9v2w from sonobuoy started at 2019-12-24 01:19:59 +0000 UTC (2 container statuses recorded)
Dec 24 02:57:15.870: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 24 02:57:15.870: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 24 02:57:15.870: INFO: kublr-ingress-nginx-ingress-controller-849b4769fc-79bhq from kube-system started at 2019-12-23 15:45:19 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.870: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec 24 02:57:15.870: INFO: kublr-ingress-nginx-ingress-default-backend-7b84f6bc4b-xr9cg from kube-system started at 2019-12-23 15:45:19 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.870: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
Dec 24 02:57:15.870: INFO: 
Logging pods the kubelet thinks is on node ip-172-16-30-121.ec2.internal before test
Dec 24 02:57:15.891: INFO: kublr-logging-sg-job-kqg5q from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.891: INFO: 	Container certgenerator ready: false, restart count 0
Dec 24 02:57:15.891: INFO: kube-proxy-7e590abedfb7de51d1197b20e754686a6a8674ae8ac79bc64dcfdc0bb67fb64f-ip-172-16-30-121.ec2.internal from kube-system started at 2019-12-23 15:43:25 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.891: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 24 02:57:15.891: INFO: sonobuoy from sonobuoy started at 2019-12-24 01:19:56 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.891: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 24 02:57:15.891: INFO: kcp-cluster-controller-846969f94d-998fm from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.891: INFO: 	Container cluster-controller ready: true, restart count 0
Dec 24 02:57:15.891: INFO: kublr-logging-fluentd-es-nc4f7 from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.891: INFO: 	Container fluentd-es ready: true, restart count 4
Dec 24 02:57:15.891: INFO: kcp-app-mongodb-789bf97977-lckdz from kublr started at 2019-12-23 15:46:21 +0000 UTC (2 container statuses recorded)
Dec 24 02:57:15.891: INFO: 	Container mongo ready: true, restart count 0
Dec 24 02:57:15.891: INFO: 	Container mongo-exporter ready: true, restart count 0
Dec 24 02:57:15.891: INFO: k8s-api-haproxy-429d71c9c9d8df433e1397ffb7b8d70c5c9c56d08dcdf3f6b2e0fe52606e3c6f-ip-172-16-30-121.ec2.internal from kube-system started at 2019-12-23 15:43:25 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.891: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Dec 24 02:57:15.891: INFO: kcp-app-mysql-549dd84b74-pd89v from kublr started at 2019-12-23 15:46:21 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.891: INFO: 	Container kcp-app-mysql ready: true, restart count 0
Dec 24 02:57:15.891: INFO: sonobuoy-systemd-logs-daemon-set-eb45748a27ab4169-v9f85 from sonobuoy started at 2019-12-24 01:19:59 +0000 UTC (2 container statuses recorded)
Dec 24 02:57:15.891: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 24 02:57:15.891: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 24 02:57:15.891: INFO: kublr-node-name-reporter-c6710394cb2609cca16a8c87ff84cdb8044d9d6e9239ff3abcfbaa4768a4122f-ip-172-16-30-121.ec2.internal from kube-system started at 2019-12-23 15:43:25 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.891: INFO: 	Container main ready: true, restart count 0
Dec 24 02:57:15.891: INFO: tiller-deploy-db48c564c-gj6vz from kube-system started at 2019-12-23 15:44:34 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.891: INFO: 	Container tiller ready: true, restart count 0
Dec 24 02:57:15.891: INFO: kublr-logging-elasticsearch-master-0 from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.891: INFO: 	Container elasticsearch ready: true, restart count 0
Dec 24 02:57:15.891: INFO: kublr-logging-curator-1577149200-nkjhl from kublr started at 2019-12-24 01:00:01 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.891: INFO: 	Container curator ready: false, restart count 0
Dec 24 02:57:15.891: INFO: canal-7sp7t from kube-system started at 2019-12-23 15:44:11 +0000 UTC (4 container statuses recorded)
Dec 24 02:57:15.891: INFO: 	Container calico-node ready: true, restart count 0
Dec 24 02:57:15.891: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 24 02:57:15.891: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Dec 24 02:57:15.891: INFO: 	Container update-network-condition ready: true, restart count 0
Dec 24 02:57:15.891: INFO: kublr-monitoring-monitoring-controller-66578cf88c-fb2gk from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.891: INFO: 	Container app-monitoring ready: true, restart count 0
Dec 24 02:57:15.891: INFO: kcp-generator-6bd556bcf6-dmqbq from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.891: INFO: 	Container generator ready: true, restart count 0
Dec 24 02:57:15.891: INFO: kublr-monitoring-kube-state-metrics-5ff6484cf7-bltmp from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.891: INFO: 	Container kubestatemetrics ready: true, restart count 0
Dec 24 02:57:15.891: INFO: kublr-logging-kibana-5d84bc784d-gfh6r from kublr started at 2019-12-23 15:46:03 +0000 UTC (4 container statuses recorded)
Dec 24 02:57:15.891: INFO: 	Container keycloak-proxy ready: true, restart count 0
Dec 24 02:57:15.891: INFO: 	Container kibana ready: true, restart count 0
Dec 24 02:57:15.891: INFO: 	Container nginx-proxy ready: true, restart count 0
Dec 24 02:57:15.891: INFO: 	Container sg-auth-proxy ready: true, restart count 0
Dec 24 02:57:15.891: INFO: kcp-backup-controller-6894dbfd9f-mxv6r from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.891: INFO: 	Container backup-controller ready: true, restart count 0
Dec 24 02:57:15.891: INFO: node-local-dns-jq8bl from kube-system started at 2019-12-23 15:44:27 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.891: INFO: 	Container node-cache ready: true, restart count 0
Dec 24 02:57:15.891: INFO: kcp-kublr-ui-5d5fbd8dc5-mxf6z from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.891: INFO: 	Container kublr-ui ready: true, restart count 0
Dec 24 02:57:15.891: INFO: heapster-v1.6.0-beta.1-5f6b4bf99b-bxcwv from kube-system started at 2019-12-23 15:44:31 +0000 UTC (2 container statuses recorded)
Dec 24 02:57:15.891: INFO: 	Container heapster ready: true, restart count 0
Dec 24 02:57:15.891: INFO: 	Container heapster-nanny ready: true, restart count 0
Dec 24 02:57:15.891: INFO: 
Logging pods the kubelet thinks is on node ip-172-16-44-108.ec2.internal before test
Dec 24 02:57:15.923: INFO: kublr-logging-fluentd-es-bpbg6 from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.923: INFO: 	Container fluentd-es ready: true, restart count 4
Dec 24 02:57:15.923: INFO: kublr-logging-rabbitmq-exporter-dc6b44ccd-6r8ks from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.923: INFO: 	Container kublr-logging-rabbitmq-exporter ready: true, restart count 0
Dec 24 02:57:15.923: INFO: kcp-keycloak-0 from kublr started at 2019-12-23 15:46:15 +0000 UTC (2 container statuses recorded)
Dec 24 02:57:15.923: INFO: 	Container init-keycloak ready: true, restart count 0
Dec 24 02:57:15.923: INFO: 	Container kcp-keycloak ready: true, restart count 0
Dec 24 02:57:15.923: INFO: kcp-terraform-controller-6f447b77d7-v69lk from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.923: INFO: 	Container terraform-controller ready: true, restart count 0
Dec 24 02:57:15.923: INFO: metrics-server-v0.3.6-86567757d-7d792 from kube-system started at 2019-12-23 17:20:18 +0000 UTC (2 container statuses recorded)
Dec 24 02:57:15.923: INFO: 	Container metrics-server ready: true, restart count 0
Dec 24 02:57:15.923: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Dec 24 02:57:15.923: INFO: kubernetes-dashboard-84cb747b5c-td8jl from kubernetes-dashboard started at 2019-12-23 15:44:31 +0000 UTC (2 container statuses recorded)
Dec 24 02:57:15.923: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec 24 02:57:15.923: INFO: 	Container kubernetes-dashboard-auth-proxy ready: true, restart count 0
Dec 24 02:57:15.923: INFO: kublr-system-shell-6f4bcb9487-n9swc from kube-system started at 2019-12-23 15:45:12 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.923: INFO: 	Container shell ready: true, restart count 0
Dec 24 02:57:15.923: INFO: kublr-node-name-reporter-be88daf430a9d4815e9777fe7bdbbdded5de4e21fb88257b9dc4b4a05304fcee-ip-172-16-44-108.ec2.internal from kube-system started at 2019-12-23 15:43:19 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.923: INFO: 	Container main ready: true, restart count 0
Dec 24 02:57:15.923: INFO: k8s-api-haproxy-de80cb1199e732ef3c9ca0051c41dd966f81ca8bee9c571b76dea5e659c7b97b-ip-172-16-44-108.ec2.internal from kube-system started at 2019-12-23 15:43:19 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.923: INFO: 	Container k8s-api-haproxy ready: true, restart count 0
Dec 24 02:57:15.923: INFO: canal-rxhg5 from kube-system started at 2019-12-23 15:44:11 +0000 UTC (4 container statuses recorded)
Dec 24 02:57:15.923: INFO: 	Container calico-node ready: true, restart count 0
Dec 24 02:57:15.923: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 24 02:57:15.923: INFO: 	Container monitor-blackhole-route ready: true, restart count 0
Dec 24 02:57:15.923: INFO: 	Container update-network-condition ready: true, restart count 0
Dec 24 02:57:15.923: INFO: node-local-dns-dzntt from kube-system started at 2019-12-23 15:44:27 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.923: INFO: 	Container node-cache ready: true, restart count 0
Dec 24 02:57:15.923: INFO: kublr-logging-elasticsearch-exporter-78df7c8987-w7b6q from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.923: INFO: 	Container main ready: true, restart count 0
Dec 24 02:57:15.923: INFO: kublr-logging-elasticsearch-data-0 from kublr started at 2019-12-23 15:46:09 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.923: INFO: 	Container elasticsearch ready: true, restart count 0
Dec 24 02:57:15.923: INFO: kcp-kublr-api-6b7d4bc968-kd9pb from kublr started at 2019-12-23 15:46:15 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.923: INFO: 	Container kublr-api ready: true, restart count 0
Dec 24 02:57:15.923: INFO: sonobuoy-systemd-logs-daemon-set-eb45748a27ab4169-wpzc6 from sonobuoy started at 2019-12-24 01:19:59 +0000 UTC (2 container statuses recorded)
Dec 24 02:57:15.923: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 24 02:57:15.923: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 24 02:57:15.923: INFO: kublr-logging-logstash-547687bcdc-vdg4k from kublr started at 2019-12-23 15:46:03 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.923: INFO: 	Container logstash ready: true, restart count 0
Dec 24 02:57:15.923: INFO: kube-proxy-7e590abedfb7de51d1197b20e754686a6a8674ae8ac79bc64dcfdc0bb67fb64f-ip-172-16-44-108.ec2.internal from kube-system started at 2019-12-23 15:43:19 +0000 UTC (1 container statuses recorded)
Dec 24 02:57:15.923: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 24 02:57:15.923: INFO: sonobuoy-e2e-job-457b3e5a99034c4d from sonobuoy started at 2019-12-24 01:19:59 +0000 UTC (2 container statuses recorded)
Dec 24 02:57:15.923: INFO: 	Container e2e ready: true, restart count 0
Dec 24 02:57:15.923: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-61d49fa5-85c2-4704-8df8-311d71fcaa08 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-61d49fa5-85c2-4704-8df8-311d71fcaa08 off the node ip-172-16-44-108.ec2.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-61d49fa5-85c2-4704-8df8-311d71fcaa08
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:57:24.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-218" for this suite.
Dec 24 02:57:44.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:57:44.227: INFO: namespace sched-pred-218 deletion completed in 20.14715018s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:28.575 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:57:44.227: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5864
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-mtxn
STEP: Creating a pod to test atomic-volume-subpath
Dec 24 02:57:44.398: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-mtxn" in namespace "subpath-5864" to be "success or failure"
Dec 24 02:57:44.410: INFO: Pod "pod-subpath-test-downwardapi-mtxn": Phase="Pending", Reason="", readiness=false. Elapsed: 11.785451ms
Dec 24 02:57:46.415: INFO: Pod "pod-subpath-test-downwardapi-mtxn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017128577s
Dec 24 02:57:48.424: INFO: Pod "pod-subpath-test-downwardapi-mtxn": Phase="Running", Reason="", readiness=true. Elapsed: 4.026077467s
Dec 24 02:57:50.429: INFO: Pod "pod-subpath-test-downwardapi-mtxn": Phase="Running", Reason="", readiness=true. Elapsed: 6.030924293s
Dec 24 02:57:52.434: INFO: Pod "pod-subpath-test-downwardapi-mtxn": Phase="Running", Reason="", readiness=true. Elapsed: 8.036335179s
Dec 24 02:57:54.447: INFO: Pod "pod-subpath-test-downwardapi-mtxn": Phase="Running", Reason="", readiness=true. Elapsed: 10.048997153s
Dec 24 02:57:56.453: INFO: Pod "pod-subpath-test-downwardapi-mtxn": Phase="Running", Reason="", readiness=true. Elapsed: 12.054636819s
Dec 24 02:57:58.458: INFO: Pod "pod-subpath-test-downwardapi-mtxn": Phase="Running", Reason="", readiness=true. Elapsed: 14.05991385s
Dec 24 02:58:00.463: INFO: Pod "pod-subpath-test-downwardapi-mtxn": Phase="Running", Reason="", readiness=true. Elapsed: 16.065244732s
Dec 24 02:58:02.470: INFO: Pod "pod-subpath-test-downwardapi-mtxn": Phase="Running", Reason="", readiness=true. Elapsed: 18.07151009s
Dec 24 02:58:04.479: INFO: Pod "pod-subpath-test-downwardapi-mtxn": Phase="Running", Reason="", readiness=true. Elapsed: 20.081215088s
Dec 24 02:58:06.485: INFO: Pod "pod-subpath-test-downwardapi-mtxn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.086753693s
STEP: Saw pod success
Dec 24 02:58:06.485: INFO: Pod "pod-subpath-test-downwardapi-mtxn" satisfied condition "success or failure"
Dec 24 02:58:06.488: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod pod-subpath-test-downwardapi-mtxn container test-container-subpath-downwardapi-mtxn: <nil>
STEP: delete the pod
Dec 24 02:58:06.522: INFO: Waiting for pod pod-subpath-test-downwardapi-mtxn to disappear
Dec 24 02:58:06.526: INFO: Pod pod-subpath-test-downwardapi-mtxn no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-mtxn
Dec 24 02:58:06.526: INFO: Deleting pod "pod-subpath-test-downwardapi-mtxn" in namespace "subpath-5864"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:58:06.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5864" for this suite.
Dec 24 02:58:12.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:58:12.682: INFO: namespace subpath-5864 deletion completed in 6.142993626s

• [SLOW TEST:28.455 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:58:12.683: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8448
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 24 02:58:12.840: INFO: Waiting up to 5m0s for pod "pod-0e228b9c-1e86-4d7a-be64-90f36fcc6490" in namespace "emptydir-8448" to be "success or failure"
Dec 24 02:58:12.844: INFO: Pod "pod-0e228b9c-1e86-4d7a-be64-90f36fcc6490": Phase="Pending", Reason="", readiness=false. Elapsed: 4.385993ms
Dec 24 02:58:14.849: INFO: Pod "pod-0e228b9c-1e86-4d7a-be64-90f36fcc6490": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00956722s
Dec 24 02:58:16.854: INFO: Pod "pod-0e228b9c-1e86-4d7a-be64-90f36fcc6490": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013929946s
STEP: Saw pod success
Dec 24 02:58:16.854: INFO: Pod "pod-0e228b9c-1e86-4d7a-be64-90f36fcc6490" satisfied condition "success or failure"
Dec 24 02:58:16.857: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod pod-0e228b9c-1e86-4d7a-be64-90f36fcc6490 container test-container: <nil>
STEP: delete the pod
Dec 24 02:58:16.886: INFO: Waiting for pod pod-0e228b9c-1e86-4d7a-be64-90f36fcc6490 to disappear
Dec 24 02:58:16.890: INFO: Pod pod-0e228b9c-1e86-4d7a-be64-90f36fcc6490 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:58:16.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8448" for this suite.
Dec 24 02:58:22.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:58:23.040: INFO: namespace emptydir-8448 deletion completed in 6.143486691s

• [SLOW TEST:10.358 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:58:23.041: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1482
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 24 02:58:26.225: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:58:26.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1482" for this suite.
Dec 24 02:58:32.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:58:32.458: INFO: namespace container-runtime-1482 deletion completed in 6.207008712s

• [SLOW TEST:9.418 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:58:32.460: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7038
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-c080b95a-0a35-4a19-82b1-6a9afe7c4faa
STEP: Creating a pod to test consume configMaps
Dec 24 02:58:32.630: INFO: Waiting up to 5m0s for pod "pod-configmaps-90a9e7b4-e8e5-4438-b93d-317451000eda" in namespace "configmap-7038" to be "success or failure"
Dec 24 02:58:32.638: INFO: Pod "pod-configmaps-90a9e7b4-e8e5-4438-b93d-317451000eda": Phase="Pending", Reason="", readiness=false. Elapsed: 7.857275ms
Dec 24 02:58:34.643: INFO: Pod "pod-configmaps-90a9e7b4-e8e5-4438-b93d-317451000eda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012649888s
Dec 24 02:58:36.647: INFO: Pod "pod-configmaps-90a9e7b4-e8e5-4438-b93d-317451000eda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016997391s
STEP: Saw pod success
Dec 24 02:58:36.647: INFO: Pod "pod-configmaps-90a9e7b4-e8e5-4438-b93d-317451000eda" satisfied condition "success or failure"
Dec 24 02:58:36.651: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-configmaps-90a9e7b4-e8e5-4438-b93d-317451000eda container configmap-volume-test: <nil>
STEP: delete the pod
Dec 24 02:58:36.678: INFO: Waiting for pod pod-configmaps-90a9e7b4-e8e5-4438-b93d-317451000eda to disappear
Dec 24 02:58:36.682: INFO: Pod pod-configmaps-90a9e7b4-e8e5-4438-b93d-317451000eda no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:58:36.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7038" for this suite.
Dec 24 02:58:42.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:58:42.831: INFO: namespace configmap-7038 deletion completed in 6.139641856s

• [SLOW TEST:10.371 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:58:42.832: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9852
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Dec 24 02:58:42.992: INFO: Waiting up to 5m0s for pod "client-containers-0c16f1d7-addc-4c35-9bfe-dbe742b021c5" in namespace "containers-9852" to be "success or failure"
Dec 24 02:58:43.001: INFO: Pod "client-containers-0c16f1d7-addc-4c35-9bfe-dbe742b021c5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.012794ms
Dec 24 02:58:45.006: INFO: Pod "client-containers-0c16f1d7-addc-4c35-9bfe-dbe742b021c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014511195s
Dec 24 02:58:47.011: INFO: Pod "client-containers-0c16f1d7-addc-4c35-9bfe-dbe742b021c5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019467177s
STEP: Saw pod success
Dec 24 02:58:47.011: INFO: Pod "client-containers-0c16f1d7-addc-4c35-9bfe-dbe742b021c5" satisfied condition "success or failure"
Dec 24 02:58:47.015: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod client-containers-0c16f1d7-addc-4c35-9bfe-dbe742b021c5 container test-container: <nil>
STEP: delete the pod
Dec 24 02:58:47.054: INFO: Waiting for pod client-containers-0c16f1d7-addc-4c35-9bfe-dbe742b021c5 to disappear
Dec 24 02:58:47.062: INFO: Pod client-containers-0c16f1d7-addc-4c35-9bfe-dbe742b021c5 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:58:47.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9852" for this suite.
Dec 24 02:58:53.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:58:53.307: INFO: namespace containers-9852 deletion completed in 6.202824555s

• [SLOW TEST:10.479 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:58:53.311: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8058
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 24 02:59:01.536: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 24 02:59:01.540: INFO: Pod pod-with-prestop-http-hook still exists
Dec 24 02:59:03.541: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 24 02:59:03.546: INFO: Pod pod-with-prestop-http-hook still exists
Dec 24 02:59:05.541: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 24 02:59:05.545: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:59:05.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8058" for this suite.
Dec 24 02:59:33.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:59:33.720: INFO: namespace container-lifecycle-hook-8058 deletion completed in 28.149172615s

• [SLOW TEST:40.409 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:59:33.726: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-939
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:59:37.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-939" for this suite.
Dec 24 02:59:43.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:59:44.063: INFO: namespace kubelet-test-939 deletion completed in 6.152745834s

• [SLOW TEST:10.337 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:59:44.063: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3439
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Dec 24 02:59:44.237: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-304826164 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:59:44.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3439" for this suite.
Dec 24 02:59:50.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 02:59:50.538: INFO: namespace kubectl-3439 deletion completed in 6.203272892s

• [SLOW TEST:6.475 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 02:59:50.538: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6478
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-0a9088cc-2a09-45de-bd7d-14c7d308637f
STEP: Creating a pod to test consume configMaps
Dec 24 02:59:50.707: INFO: Waiting up to 5m0s for pod "pod-configmaps-0124eed5-57de-48a0-8af7-5bbbadc8b78d" in namespace "configmap-6478" to be "success or failure"
Dec 24 02:59:50.711: INFO: Pod "pod-configmaps-0124eed5-57de-48a0-8af7-5bbbadc8b78d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.526979ms
Dec 24 02:59:52.715: INFO: Pod "pod-configmaps-0124eed5-57de-48a0-8af7-5bbbadc8b78d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008315766s
Dec 24 02:59:54.720: INFO: Pod "pod-configmaps-0124eed5-57de-48a0-8af7-5bbbadc8b78d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013193729s
STEP: Saw pod success
Dec 24 02:59:54.720: INFO: Pod "pod-configmaps-0124eed5-57de-48a0-8af7-5bbbadc8b78d" satisfied condition "success or failure"
Dec 24 02:59:54.725: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-configmaps-0124eed5-57de-48a0-8af7-5bbbadc8b78d container configmap-volume-test: <nil>
STEP: delete the pod
Dec 24 02:59:54.752: INFO: Waiting for pod pod-configmaps-0124eed5-57de-48a0-8af7-5bbbadc8b78d to disappear
Dec 24 02:59:54.756: INFO: Pod pod-configmaps-0124eed5-57de-48a0-8af7-5bbbadc8b78d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 02:59:54.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6478" for this suite.
Dec 24 03:00:00.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:00:00.924: INFO: namespace configmap-6478 deletion completed in 6.161985429s

• [SLOW TEST:10.386 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:00:00.925: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2896
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 24 03:00:01.088: INFO: Waiting up to 5m0s for pod "pod-ef0e375d-d413-48d9-bdeb-dbf10bd00a4a" in namespace "emptydir-2896" to be "success or failure"
Dec 24 03:00:01.097: INFO: Pod "pod-ef0e375d-d413-48d9-bdeb-dbf10bd00a4a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.322135ms
Dec 24 03:00:03.103: INFO: Pod "pod-ef0e375d-d413-48d9-bdeb-dbf10bd00a4a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014467199s
Dec 24 03:00:05.111: INFO: Pod "pod-ef0e375d-d413-48d9-bdeb-dbf10bd00a4a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022848038s
STEP: Saw pod success
Dec 24 03:00:05.111: INFO: Pod "pod-ef0e375d-d413-48d9-bdeb-dbf10bd00a4a" satisfied condition "success or failure"
Dec 24 03:00:05.115: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod pod-ef0e375d-d413-48d9-bdeb-dbf10bd00a4a container test-container: <nil>
STEP: delete the pod
Dec 24 03:00:05.151: INFO: Waiting for pod pod-ef0e375d-d413-48d9-bdeb-dbf10bd00a4a to disappear
Dec 24 03:00:05.156: INFO: Pod pod-ef0e375d-d413-48d9-bdeb-dbf10bd00a4a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:00:05.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2896" for this suite.
Dec 24 03:00:11.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:00:11.339: INFO: namespace emptydir-2896 deletion completed in 6.168683581s

• [SLOW TEST:10.414 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:00:11.339: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8752
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:00:22.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8752" for this suite.
Dec 24 03:00:28.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:00:28.686: INFO: namespace resourcequota-8752 deletion completed in 6.132675878s

• [SLOW TEST:17.347 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:00:28.687: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1767
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1767
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-1767
Dec 24 03:00:28.864: INFO: Found 0 stateful pods, waiting for 1
Dec 24 03:00:38.869: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 24 03:00:38.916: INFO: Deleting all statefulset in ns statefulset-1767
Dec 24 03:00:38.932: INFO: Scaling statefulset ss to 0
Dec 24 03:00:58.965: INFO: Waiting for statefulset status.replicas updated to 0
Dec 24 03:00:58.971: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:00:58.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1767" for this suite.
Dec 24 03:01:05.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:01:05.174: INFO: namespace statefulset-1767 deletion completed in 6.177301276s

• [SLOW TEST:36.487 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:01:05.174: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4752
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-cf369a79-3f52-4ada-98e2-7cc1bf1561b0 in namespace container-probe-4752
Dec 24 03:01:09.364: INFO: Started pod busybox-cf369a79-3f52-4ada-98e2-7cc1bf1561b0 in namespace container-probe-4752
STEP: checking the pod's current state and verifying that restartCount is present
Dec 24 03:01:09.375: INFO: Initial restart count of pod busybox-cf369a79-3f52-4ada-98e2-7cc1bf1561b0 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:05:10.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4752" for this suite.
Dec 24 03:05:16.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:05:16.304: INFO: namespace container-probe-4752 deletion completed in 6.212578795s

• [SLOW TEST:251.130 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:05:16.304: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9882
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-8c9758e0-0c4e-4733-91b0-93c88ec28067
STEP: Creating a pod to test consume configMaps
Dec 24 03:05:16.528: INFO: Waiting up to 5m0s for pod "pod-configmaps-db3676db-7016-4a39-8dff-ff623c8f6877" in namespace "configmap-9882" to be "success or failure"
Dec 24 03:05:16.536: INFO: Pod "pod-configmaps-db3676db-7016-4a39-8dff-ff623c8f6877": Phase="Pending", Reason="", readiness=false. Elapsed: 7.770477ms
Dec 24 03:05:18.542: INFO: Pod "pod-configmaps-db3676db-7016-4a39-8dff-ff623c8f6877": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01378713s
Dec 24 03:05:20.547: INFO: Pod "pod-configmaps-db3676db-7016-4a39-8dff-ff623c8f6877": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018536531s
STEP: Saw pod success
Dec 24 03:05:20.547: INFO: Pod "pod-configmaps-db3676db-7016-4a39-8dff-ff623c8f6877" satisfied condition "success or failure"
Dec 24 03:05:20.552: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-configmaps-db3676db-7016-4a39-8dff-ff623c8f6877 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 24 03:05:20.592: INFO: Waiting for pod pod-configmaps-db3676db-7016-4a39-8dff-ff623c8f6877 to disappear
Dec 24 03:05:20.599: INFO: Pod pod-configmaps-db3676db-7016-4a39-8dff-ff623c8f6877 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:05:20.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9882" for this suite.
Dec 24 03:05:26.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:05:26.755: INFO: namespace configmap-9882 deletion completed in 6.149321962s

• [SLOW TEST:10.451 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:05:26.755: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-2194
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-2194
I1224 03:05:26.913864      24 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-2194, replica count: 1
I1224 03:05:27.966391      24 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1224 03:05:28.967012      24 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1224 03:05:29.967229      24 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 24 03:05:30.092: INFO: Created: latency-svc-8qt5j
Dec 24 03:05:30.095: INFO: Got endpoints: latency-svc-8qt5j [28.527656ms]
Dec 24 03:05:30.121: INFO: Created: latency-svc-nz5jg
Dec 24 03:05:30.137: INFO: Got endpoints: latency-svc-nz5jg [41.138915ms]
Dec 24 03:05:30.144: INFO: Created: latency-svc-wkr9k
Dec 24 03:05:30.151: INFO: Got endpoints: latency-svc-wkr9k [55.071491ms]
Dec 24 03:05:30.162: INFO: Created: latency-svc-xlj26
Dec 24 03:05:30.179: INFO: Got endpoints: latency-svc-xlj26 [82.977667ms]
Dec 24 03:05:30.185: INFO: Created: latency-svc-qgpbj
Dec 24 03:05:30.202: INFO: Got endpoints: latency-svc-qgpbj [106.377174ms]
Dec 24 03:05:30.206: INFO: Created: latency-svc-r56pd
Dec 24 03:05:30.220: INFO: Got endpoints: latency-svc-r56pd [123.342258ms]
Dec 24 03:05:30.244: INFO: Created: latency-svc-wck67
Dec 24 03:05:30.249: INFO: Got endpoints: latency-svc-wck67 [153.364194ms]
Dec 24 03:05:30.260: INFO: Created: latency-svc-d5s5c
Dec 24 03:05:30.267: INFO: Got endpoints: latency-svc-d5s5c [170.894466ms]
Dec 24 03:05:30.281: INFO: Created: latency-svc-7vnjq
Dec 24 03:05:30.295: INFO: Got endpoints: latency-svc-7vnjq [198.684557ms]
Dec 24 03:05:30.305: INFO: Created: latency-svc-9z6bn
Dec 24 03:05:30.312: INFO: Got endpoints: latency-svc-9z6bn [215.73245ms]
Dec 24 03:05:30.331: INFO: Created: latency-svc-p77dp
Dec 24 03:05:30.357: INFO: Got endpoints: latency-svc-p77dp [260.868294ms]
Dec 24 03:05:30.368: INFO: Created: latency-svc-s2pgv
Dec 24 03:05:30.374: INFO: Got endpoints: latency-svc-s2pgv [277.542711ms]
Dec 24 03:05:30.386: INFO: Created: latency-svc-w55w9
Dec 24 03:05:30.394: INFO: Got endpoints: latency-svc-w55w9 [297.572333ms]
Dec 24 03:05:30.412: INFO: Created: latency-svc-cdzst
Dec 24 03:05:30.428: INFO: Created: latency-svc-2tmx7
Dec 24 03:05:30.428: INFO: Got endpoints: latency-svc-cdzst [331.999536ms]
Dec 24 03:05:30.504: INFO: Got endpoints: latency-svc-2tmx7 [407.060377ms]
Dec 24 03:05:30.522: INFO: Created: latency-svc-nvxkx
Dec 24 03:05:30.526: INFO: Got endpoints: latency-svc-nvxkx [429.78424ms]
Dec 24 03:05:30.539: INFO: Created: latency-svc-mm8st
Dec 24 03:05:30.552: INFO: Got endpoints: latency-svc-mm8st [415.436134ms]
Dec 24 03:05:30.559: INFO: Created: latency-svc-zs7js
Dec 24 03:05:30.574: INFO: Got endpoints: latency-svc-zs7js [423.249078ms]
Dec 24 03:05:30.578: INFO: Created: latency-svc-2nd6s
Dec 24 03:05:30.582: INFO: Got endpoints: latency-svc-2nd6s [402.533773ms]
Dec 24 03:05:30.594: INFO: Created: latency-svc-kz2z7
Dec 24 03:05:30.607: INFO: Got endpoints: latency-svc-kz2z7 [404.091276ms]
Dec 24 03:05:30.615: INFO: Created: latency-svc-mbwzn
Dec 24 03:05:30.621: INFO: Got endpoints: latency-svc-mbwzn [39.239344ms]
Dec 24 03:05:30.632: INFO: Created: latency-svc-cl5l6
Dec 24 03:05:30.639: INFO: Got endpoints: latency-svc-cl5l6 [419.239386ms]
Dec 24 03:05:30.661: INFO: Created: latency-svc-ks2g7
Dec 24 03:05:30.668: INFO: Got endpoints: latency-svc-ks2g7 [418.300332ms]
Dec 24 03:05:30.683: INFO: Created: latency-svc-zpf7m
Dec 24 03:05:30.688: INFO: Got endpoints: latency-svc-zpf7m [420.721465ms]
Dec 24 03:05:30.706: INFO: Created: latency-svc-49vjd
Dec 24 03:05:30.712: INFO: Got endpoints: latency-svc-49vjd [416.389169ms]
Dec 24 03:05:30.729: INFO: Created: latency-svc-9s5tj
Dec 24 03:05:30.734: INFO: Got endpoints: latency-svc-9s5tj [402.919235ms]
Dec 24 03:05:30.745: INFO: Created: latency-svc-76m6j
Dec 24 03:05:30.761: INFO: Got endpoints: latency-svc-76m6j [403.708639ms]
Dec 24 03:05:30.764: INFO: Created: latency-svc-kv5gt
Dec 24 03:05:30.767: INFO: Got endpoints: latency-svc-kv5gt [393.494502ms]
Dec 24 03:05:30.792: INFO: Created: latency-svc-r88nd
Dec 24 03:05:30.809: INFO: Got endpoints: latency-svc-r88nd [415.00576ms]
Dec 24 03:05:30.811: INFO: Created: latency-svc-vk6l7
Dec 24 03:05:30.819: INFO: Got endpoints: latency-svc-vk6l7 [390.580507ms]
Dec 24 03:05:30.837: INFO: Created: latency-svc-nm7h5
Dec 24 03:05:30.838: INFO: Got endpoints: latency-svc-nm7h5 [334.106141ms]
Dec 24 03:05:30.853: INFO: Created: latency-svc-64k5k
Dec 24 03:05:30.868: INFO: Got endpoints: latency-svc-64k5k [341.399297ms]
Dec 24 03:05:30.876: INFO: Created: latency-svc-zckwx
Dec 24 03:05:30.881: INFO: Got endpoints: latency-svc-zckwx [328.289748ms]
Dec 24 03:05:30.899: INFO: Created: latency-svc-d4shw
Dec 24 03:05:30.903: INFO: Got endpoints: latency-svc-d4shw [328.658293ms]
Dec 24 03:05:30.934: INFO: Created: latency-svc-dgft6
Dec 24 03:05:30.935: INFO: Got endpoints: latency-svc-dgft6 [328.567369ms]
Dec 24 03:05:30.938: INFO: Created: latency-svc-shd7w
Dec 24 03:05:30.943: INFO: Got endpoints: latency-svc-shd7w [321.364992ms]
Dec 24 03:05:30.963: INFO: Created: latency-svc-mqk77
Dec 24 03:05:30.976: INFO: Got endpoints: latency-svc-mqk77 [337.154205ms]
Dec 24 03:05:30.985: INFO: Created: latency-svc-kcjxt
Dec 24 03:05:31.010: INFO: Got endpoints: latency-svc-kcjxt [342.348346ms]
Dec 24 03:05:31.013: INFO: Created: latency-svc-dxjhm
Dec 24 03:05:31.029: INFO: Got endpoints: latency-svc-dxjhm [341.206938ms]
Dec 24 03:05:31.036: INFO: Created: latency-svc-6jt9g
Dec 24 03:05:31.041: INFO: Got endpoints: latency-svc-6jt9g [329.343655ms]
Dec 24 03:05:31.053: INFO: Created: latency-svc-fvrpx
Dec 24 03:05:31.069: INFO: Got endpoints: latency-svc-fvrpx [334.358254ms]
Dec 24 03:05:31.071: INFO: Created: latency-svc-wkpv2
Dec 24 03:05:31.081: INFO: Got endpoints: latency-svc-wkpv2 [320.249851ms]
Dec 24 03:05:31.097: INFO: Created: latency-svc-rhrlr
Dec 24 03:05:31.102: INFO: Got endpoints: latency-svc-rhrlr [334.830251ms]
Dec 24 03:05:31.119: INFO: Created: latency-svc-c6qpm
Dec 24 03:05:31.122: INFO: Got endpoints: latency-svc-c6qpm [313.081545ms]
Dec 24 03:05:31.131: INFO: Created: latency-svc-mqsfk
Dec 24 03:05:31.137: INFO: Got endpoints: latency-svc-mqsfk [317.38992ms]
Dec 24 03:05:31.148: INFO: Created: latency-svc-95t2w
Dec 24 03:05:31.155: INFO: Got endpoints: latency-svc-95t2w [316.880404ms]
Dec 24 03:05:31.199: INFO: Created: latency-svc-924fm
Dec 24 03:05:31.204: INFO: Got endpoints: latency-svc-924fm [336.141441ms]
Dec 24 03:05:31.207: INFO: Created: latency-svc-w6vh7
Dec 24 03:05:31.215: INFO: Got endpoints: latency-svc-w6vh7 [334.560894ms]
Dec 24 03:05:31.234: INFO: Created: latency-svc-jz8kz
Dec 24 03:05:31.238: INFO: Got endpoints: latency-svc-jz8kz [334.579198ms]
Dec 24 03:05:31.250: INFO: Created: latency-svc-rffqg
Dec 24 03:05:31.264: INFO: Created: latency-svc-qm8ms
Dec 24 03:05:31.271: INFO: Got endpoints: latency-svc-qm8ms [327.946774ms]
Dec 24 03:05:31.271: INFO: Got endpoints: latency-svc-rffqg [335.64146ms]
Dec 24 03:05:31.289: INFO: Created: latency-svc-qzr2w
Dec 24 03:05:31.291: INFO: Got endpoints: latency-svc-qzr2w [314.263194ms]
Dec 24 03:05:31.304: INFO: Created: latency-svc-l5s2l
Dec 24 03:05:31.324: INFO: Got endpoints: latency-svc-l5s2l [313.81908ms]
Dec 24 03:05:31.327: INFO: Created: latency-svc-rpszv
Dec 24 03:05:31.333: INFO: Got endpoints: latency-svc-rpszv [303.566093ms]
Dec 24 03:05:31.352: INFO: Created: latency-svc-mz9nw
Dec 24 03:05:31.352: INFO: Got endpoints: latency-svc-mz9nw [310.800305ms]
Dec 24 03:05:31.384: INFO: Created: latency-svc-w7d52
Dec 24 03:05:31.399: INFO: Created: latency-svc-v25d6
Dec 24 03:05:31.405: INFO: Got endpoints: latency-svc-w7d52 [335.785234ms]
Dec 24 03:05:31.422: INFO: Created: latency-svc-jnn2d
Dec 24 03:05:31.439: INFO: Created: latency-svc-4vw5l
Dec 24 03:05:31.453: INFO: Got endpoints: latency-svc-v25d6 [371.89984ms]
Dec 24 03:05:31.458: INFO: Created: latency-svc-hj2f9
Dec 24 03:05:31.482: INFO: Created: latency-svc-mktxj
Dec 24 03:05:31.497: INFO: Created: latency-svc-65gd9
Dec 24 03:05:31.505: INFO: Got endpoints: latency-svc-jnn2d [402.87526ms]
Dec 24 03:05:31.522: INFO: Created: latency-svc-rnsvg
Dec 24 03:05:31.541: INFO: Created: latency-svc-r9cw4
Dec 24 03:05:31.556: INFO: Got endpoints: latency-svc-4vw5l [433.734711ms]
Dec 24 03:05:31.566: INFO: Created: latency-svc-wxdp5
Dec 24 03:05:31.580: INFO: Created: latency-svc-7bpcb
Dec 24 03:05:31.597: INFO: Created: latency-svc-jtxqg
Dec 24 03:05:31.599: INFO: Got endpoints: latency-svc-hj2f9 [462.050966ms]
Dec 24 03:05:31.614: INFO: Created: latency-svc-tsnvl
Dec 24 03:05:31.644: INFO: Created: latency-svc-2j5jv
Dec 24 03:05:31.655: INFO: Got endpoints: latency-svc-mktxj [499.888144ms]
Dec 24 03:05:31.662: INFO: Created: latency-svc-tmhkx
Dec 24 03:05:31.678: INFO: Created: latency-svc-mhgdr
Dec 24 03:05:31.697: INFO: Created: latency-svc-4zrhc
Dec 24 03:05:31.699: INFO: Got endpoints: latency-svc-65gd9 [494.59201ms]
Dec 24 03:05:31.720: INFO: Created: latency-svc-mk6vg
Dec 24 03:05:31.740: INFO: Created: latency-svc-lg79p
Dec 24 03:05:31.751: INFO: Got endpoints: latency-svc-rnsvg [536.170519ms]
Dec 24 03:05:31.755: INFO: Created: latency-svc-hcvvq
Dec 24 03:05:31.772: INFO: Created: latency-svc-z47vg
Dec 24 03:05:31.788: INFO: Created: latency-svc-vvrvr
Dec 24 03:05:31.802: INFO: Got endpoints: latency-svc-r9cw4 [564.946552ms]
Dec 24 03:05:31.806: INFO: Created: latency-svc-s99w2
Dec 24 03:05:31.823: INFO: Created: latency-svc-2zvhn
Dec 24 03:05:31.844: INFO: Got endpoints: latency-svc-wxdp5 [573.490197ms]
Dec 24 03:05:31.868: INFO: Created: latency-svc-72vjk
Dec 24 03:05:31.896: INFO: Got endpoints: latency-svc-7bpcb [624.439588ms]
Dec 24 03:05:31.915: INFO: Created: latency-svc-7txkt
Dec 24 03:05:31.948: INFO: Got endpoints: latency-svc-jtxqg [657.091475ms]
Dec 24 03:05:31.970: INFO: Created: latency-svc-jr62f
Dec 24 03:05:31.994: INFO: Got endpoints: latency-svc-tsnvl [670.31458ms]
Dec 24 03:05:32.015: INFO: Created: latency-svc-v6ndh
Dec 24 03:05:32.045: INFO: Got endpoints: latency-svc-2j5jv [711.880948ms]
Dec 24 03:05:32.064: INFO: Created: latency-svc-jzsk5
Dec 24 03:05:32.095: INFO: Got endpoints: latency-svc-tmhkx [742.733624ms]
Dec 24 03:05:32.116: INFO: Created: latency-svc-q798q
Dec 24 03:05:32.144: INFO: Got endpoints: latency-svc-mhgdr [739.58271ms]
Dec 24 03:05:32.166: INFO: Created: latency-svc-wch88
Dec 24 03:05:32.196: INFO: Got endpoints: latency-svc-4zrhc [743.213169ms]
Dec 24 03:05:32.215: INFO: Created: latency-svc-4pjv6
Dec 24 03:05:32.244: INFO: Got endpoints: latency-svc-mk6vg [738.722878ms]
Dec 24 03:05:32.273: INFO: Created: latency-svc-slcvk
Dec 24 03:05:32.295: INFO: Got endpoints: latency-svc-lg79p [738.609365ms]
Dec 24 03:05:32.316: INFO: Created: latency-svc-27c92
Dec 24 03:05:32.351: INFO: Got endpoints: latency-svc-hcvvq [752.469763ms]
Dec 24 03:05:32.370: INFO: Created: latency-svc-tbtr9
Dec 24 03:05:32.394: INFO: Got endpoints: latency-svc-z47vg [739.667931ms]
Dec 24 03:05:32.422: INFO: Created: latency-svc-2k8jv
Dec 24 03:05:32.447: INFO: Got endpoints: latency-svc-vvrvr [747.762975ms]
Dec 24 03:05:32.467: INFO: Created: latency-svc-hdbbp
Dec 24 03:05:32.494: INFO: Got endpoints: latency-svc-s99w2 [742.626332ms]
Dec 24 03:05:32.513: INFO: Created: latency-svc-pqvt2
Dec 24 03:05:32.546: INFO: Got endpoints: latency-svc-2zvhn [743.505289ms]
Dec 24 03:05:32.566: INFO: Created: latency-svc-hp4dp
Dec 24 03:05:32.595: INFO: Got endpoints: latency-svc-72vjk [750.659932ms]
Dec 24 03:05:32.617: INFO: Created: latency-svc-2r74z
Dec 24 03:05:32.644: INFO: Got endpoints: latency-svc-7txkt [748.334669ms]
Dec 24 03:05:32.663: INFO: Created: latency-svc-99s6v
Dec 24 03:05:32.700: INFO: Got endpoints: latency-svc-jr62f [751.931214ms]
Dec 24 03:05:32.721: INFO: Created: latency-svc-5pgz2
Dec 24 03:05:32.745: INFO: Got endpoints: latency-svc-v6ndh [750.112197ms]
Dec 24 03:05:32.766: INFO: Created: latency-svc-bh5hh
Dec 24 03:05:32.805: INFO: Got endpoints: latency-svc-jzsk5 [760.275225ms]
Dec 24 03:05:32.824: INFO: Created: latency-svc-472bp
Dec 24 03:05:32.845: INFO: Got endpoints: latency-svc-q798q [749.528619ms]
Dec 24 03:05:32.866: INFO: Created: latency-svc-plm9z
Dec 24 03:05:32.895: INFO: Got endpoints: latency-svc-wch88 [750.216751ms]
Dec 24 03:05:32.915: INFO: Created: latency-svc-j782j
Dec 24 03:05:32.944: INFO: Got endpoints: latency-svc-4pjv6 [747.586201ms]
Dec 24 03:05:32.965: INFO: Created: latency-svc-9kkbc
Dec 24 03:05:32.995: INFO: Got endpoints: latency-svc-slcvk [751.03174ms]
Dec 24 03:05:33.017: INFO: Created: latency-svc-2bq9r
Dec 24 03:05:33.045: INFO: Got endpoints: latency-svc-27c92 [750.503608ms]
Dec 24 03:05:33.069: INFO: Created: latency-svc-564kq
Dec 24 03:05:33.095: INFO: Got endpoints: latency-svc-tbtr9 [743.041873ms]
Dec 24 03:05:33.114: INFO: Created: latency-svc-lbx44
Dec 24 03:05:33.145: INFO: Got endpoints: latency-svc-2k8jv [750.083692ms]
Dec 24 03:05:33.166: INFO: Created: latency-svc-4fjrb
Dec 24 03:05:33.202: INFO: Got endpoints: latency-svc-hdbbp [754.952838ms]
Dec 24 03:05:33.224: INFO: Created: latency-svc-d4kql
Dec 24 03:05:33.244: INFO: Got endpoints: latency-svc-pqvt2 [749.984949ms]
Dec 24 03:05:33.264: INFO: Created: latency-svc-fff7v
Dec 24 03:05:33.295: INFO: Got endpoints: latency-svc-hp4dp [749.063924ms]
Dec 24 03:05:33.316: INFO: Created: latency-svc-dfwdd
Dec 24 03:05:33.345: INFO: Got endpoints: latency-svc-2r74z [750.057809ms]
Dec 24 03:05:33.367: INFO: Created: latency-svc-ttmds
Dec 24 03:05:33.394: INFO: Got endpoints: latency-svc-99s6v [749.979848ms]
Dec 24 03:05:33.416: INFO: Created: latency-svc-9gls6
Dec 24 03:05:33.445: INFO: Got endpoints: latency-svc-5pgz2 [744.904569ms]
Dec 24 03:05:33.467: INFO: Created: latency-svc-xpqbs
Dec 24 03:05:33.497: INFO: Got endpoints: latency-svc-bh5hh [751.519421ms]
Dec 24 03:05:33.518: INFO: Created: latency-svc-9qrxn
Dec 24 03:05:33.545: INFO: Got endpoints: latency-svc-472bp [739.300291ms]
Dec 24 03:05:33.564: INFO: Created: latency-svc-lfg9r
Dec 24 03:05:33.598: INFO: Got endpoints: latency-svc-plm9z [753.856907ms]
Dec 24 03:05:33.619: INFO: Created: latency-svc-sm9m9
Dec 24 03:05:33.647: INFO: Got endpoints: latency-svc-j782j [751.916764ms]
Dec 24 03:05:33.667: INFO: Created: latency-svc-lz49s
Dec 24 03:05:33.695: INFO: Got endpoints: latency-svc-9kkbc [750.703999ms]
Dec 24 03:05:33.716: INFO: Created: latency-svc-7v5ls
Dec 24 03:05:33.745: INFO: Got endpoints: latency-svc-2bq9r [750.008853ms]
Dec 24 03:05:33.767: INFO: Created: latency-svc-b5wkb
Dec 24 03:05:33.796: INFO: Got endpoints: latency-svc-564kq [750.111592ms]
Dec 24 03:05:33.818: INFO: Created: latency-svc-fmpsq
Dec 24 03:05:33.844: INFO: Got endpoints: latency-svc-lbx44 [749.425422ms]
Dec 24 03:05:33.865: INFO: Created: latency-svc-m64m5
Dec 24 03:05:33.895: INFO: Got endpoints: latency-svc-4fjrb [750.784548ms]
Dec 24 03:05:33.916: INFO: Created: latency-svc-cjj4f
Dec 24 03:05:33.945: INFO: Got endpoints: latency-svc-d4kql [742.880695ms]
Dec 24 03:05:33.966: INFO: Created: latency-svc-khblj
Dec 24 03:05:33.994: INFO: Got endpoints: latency-svc-fff7v [749.883695ms]
Dec 24 03:05:34.013: INFO: Created: latency-svc-kmfx9
Dec 24 03:05:34.046: INFO: Got endpoints: latency-svc-dfwdd [751.229366ms]
Dec 24 03:05:34.071: INFO: Created: latency-svc-qpnfc
Dec 24 03:05:34.096: INFO: Got endpoints: latency-svc-ttmds [750.644556ms]
Dec 24 03:05:34.117: INFO: Created: latency-svc-vpldk
Dec 24 03:05:34.145: INFO: Got endpoints: latency-svc-9gls6 [749.996902ms]
Dec 24 03:05:34.164: INFO: Created: latency-svc-62vkd
Dec 24 03:05:34.195: INFO: Got endpoints: latency-svc-xpqbs [749.539756ms]
Dec 24 03:05:34.219: INFO: Created: latency-svc-kk4w2
Dec 24 03:05:34.244: INFO: Got endpoints: latency-svc-9qrxn [747.442915ms]
Dec 24 03:05:34.267: INFO: Created: latency-svc-624r7
Dec 24 03:05:34.295: INFO: Got endpoints: latency-svc-lfg9r [749.777663ms]
Dec 24 03:05:34.314: INFO: Created: latency-svc-sgtgz
Dec 24 03:05:34.345: INFO: Got endpoints: latency-svc-sm9m9 [746.539458ms]
Dec 24 03:05:34.365: INFO: Created: latency-svc-zwlbq
Dec 24 03:05:34.394: INFO: Got endpoints: latency-svc-lz49s [747.829369ms]
Dec 24 03:05:34.418: INFO: Created: latency-svc-rzfcw
Dec 24 03:05:34.445: INFO: Got endpoints: latency-svc-7v5ls [750.341171ms]
Dec 24 03:05:34.465: INFO: Created: latency-svc-5p5ps
Dec 24 03:05:34.496: INFO: Got endpoints: latency-svc-b5wkb [750.01486ms]
Dec 24 03:05:34.517: INFO: Created: latency-svc-jwwhh
Dec 24 03:05:34.545: INFO: Got endpoints: latency-svc-fmpsq [749.145213ms]
Dec 24 03:05:34.567: INFO: Created: latency-svc-kqp7v
Dec 24 03:05:34.595: INFO: Got endpoints: latency-svc-m64m5 [751.05972ms]
Dec 24 03:05:34.614: INFO: Created: latency-svc-hp6rk
Dec 24 03:05:34.645: INFO: Got endpoints: latency-svc-cjj4f [749.868969ms]
Dec 24 03:05:34.665: INFO: Created: latency-svc-nsp85
Dec 24 03:05:34.694: INFO: Got endpoints: latency-svc-khblj [749.305162ms]
Dec 24 03:05:34.714: INFO: Created: latency-svc-755bx
Dec 24 03:05:34.745: INFO: Got endpoints: latency-svc-kmfx9 [750.638744ms]
Dec 24 03:05:34.764: INFO: Created: latency-svc-f6cpj
Dec 24 03:05:34.795: INFO: Got endpoints: latency-svc-qpnfc [748.672521ms]
Dec 24 03:05:34.815: INFO: Created: latency-svc-tcbgc
Dec 24 03:05:34.844: INFO: Got endpoints: latency-svc-vpldk [748.144464ms]
Dec 24 03:05:34.865: INFO: Created: latency-svc-k8x4n
Dec 24 03:05:34.895: INFO: Got endpoints: latency-svc-62vkd [749.784938ms]
Dec 24 03:05:34.914: INFO: Created: latency-svc-n7pcz
Dec 24 03:05:34.945: INFO: Got endpoints: latency-svc-kk4w2 [750.207871ms]
Dec 24 03:05:34.966: INFO: Created: latency-svc-g98k5
Dec 24 03:05:34.994: INFO: Got endpoints: latency-svc-624r7 [750.117257ms]
Dec 24 03:05:35.016: INFO: Created: latency-svc-zmzkp
Dec 24 03:05:35.045: INFO: Got endpoints: latency-svc-sgtgz [750.075697ms]
Dec 24 03:05:35.065: INFO: Created: latency-svc-g4gx2
Dec 24 03:05:35.095: INFO: Got endpoints: latency-svc-zwlbq [750.266562ms]
Dec 24 03:05:35.115: INFO: Created: latency-svc-qgk6q
Dec 24 03:05:35.144: INFO: Got endpoints: latency-svc-rzfcw [749.642451ms]
Dec 24 03:05:35.165: INFO: Created: latency-svc-2gp64
Dec 24 03:05:35.195: INFO: Got endpoints: latency-svc-5p5ps [750.342205ms]
Dec 24 03:05:35.215: INFO: Created: latency-svc-ksb5d
Dec 24 03:05:35.245: INFO: Got endpoints: latency-svc-jwwhh [749.51253ms]
Dec 24 03:05:35.267: INFO: Created: latency-svc-2ld4s
Dec 24 03:05:35.294: INFO: Got endpoints: latency-svc-kqp7v [749.363288ms]
Dec 24 03:05:35.315: INFO: Created: latency-svc-68hv2
Dec 24 03:05:35.345: INFO: Got endpoints: latency-svc-hp6rk [749.45936ms]
Dec 24 03:05:35.368: INFO: Created: latency-svc-r42gn
Dec 24 03:05:35.395: INFO: Got endpoints: latency-svc-nsp85 [750.086304ms]
Dec 24 03:05:35.420: INFO: Created: latency-svc-pt4nj
Dec 24 03:05:35.445: INFO: Got endpoints: latency-svc-755bx [751.375719ms]
Dec 24 03:05:35.467: INFO: Created: latency-svc-lt96v
Dec 24 03:05:35.495: INFO: Got endpoints: latency-svc-f6cpj [749.91237ms]
Dec 24 03:05:35.515: INFO: Created: latency-svc-wt7d5
Dec 24 03:05:35.548: INFO: Got endpoints: latency-svc-tcbgc [752.45668ms]
Dec 24 03:05:35.567: INFO: Created: latency-svc-b4zd2
Dec 24 03:05:35.594: INFO: Got endpoints: latency-svc-k8x4n [750.373575ms]
Dec 24 03:05:35.615: INFO: Created: latency-svc-827c8
Dec 24 03:05:35.645: INFO: Got endpoints: latency-svc-n7pcz [749.925103ms]
Dec 24 03:05:35.665: INFO: Created: latency-svc-8hxxj
Dec 24 03:05:35.695: INFO: Got endpoints: latency-svc-g98k5 [749.4258ms]
Dec 24 03:05:35.741: INFO: Created: latency-svc-f9nkn
Dec 24 03:05:35.745: INFO: Got endpoints: latency-svc-zmzkp [750.078668ms]
Dec 24 03:05:35.768: INFO: Created: latency-svc-9vr26
Dec 24 03:05:35.805: INFO: Got endpoints: latency-svc-g4gx2 [760.161714ms]
Dec 24 03:05:35.890: INFO: Got endpoints: latency-svc-qgk6q [794.998602ms]
Dec 24 03:05:35.895: INFO: Created: latency-svc-kpdqs
Dec 24 03:05:35.897: INFO: Got endpoints: latency-svc-2gp64 [752.75206ms]
Dec 24 03:05:35.922: INFO: Created: latency-svc-5q5rs
Dec 24 03:05:35.969: INFO: Got endpoints: latency-svc-ksb5d [772.872474ms]
Dec 24 03:05:35.974: INFO: Created: latency-svc-ct6vj
Dec 24 03:05:35.989: INFO: Created: latency-svc-nfkql
Dec 24 03:05:35.997: INFO: Got endpoints: latency-svc-2ld4s [751.676305ms]
Dec 24 03:05:36.016: INFO: Created: latency-svc-68bwf
Dec 24 03:05:36.047: INFO: Got endpoints: latency-svc-68hv2 [752.574911ms]
Dec 24 03:05:36.069: INFO: Created: latency-svc-4wbt8
Dec 24 03:05:36.094: INFO: Got endpoints: latency-svc-r42gn [749.653593ms]
Dec 24 03:05:36.113: INFO: Created: latency-svc-sndtv
Dec 24 03:05:36.146: INFO: Got endpoints: latency-svc-pt4nj [749.827868ms]
Dec 24 03:05:36.165: INFO: Created: latency-svc-gms7c
Dec 24 03:05:36.194: INFO: Got endpoints: latency-svc-lt96v [748.512433ms]
Dec 24 03:05:36.214: INFO: Created: latency-svc-m4z75
Dec 24 03:05:36.254: INFO: Got endpoints: latency-svc-wt7d5 [759.12433ms]
Dec 24 03:05:36.273: INFO: Created: latency-svc-nz2k7
Dec 24 03:05:36.293: INFO: Got endpoints: latency-svc-b4zd2 [745.832992ms]
Dec 24 03:05:36.313: INFO: Created: latency-svc-qqft8
Dec 24 03:05:36.345: INFO: Got endpoints: latency-svc-827c8 [750.539628ms]
Dec 24 03:05:36.365: INFO: Created: latency-svc-2d5l5
Dec 24 03:05:36.395: INFO: Got endpoints: latency-svc-8hxxj [750.296529ms]
Dec 24 03:05:36.414: INFO: Created: latency-svc-dsql9
Dec 24 03:05:36.444: INFO: Got endpoints: latency-svc-f9nkn [749.385519ms]
Dec 24 03:05:36.472: INFO: Created: latency-svc-46fv8
Dec 24 03:05:36.495: INFO: Got endpoints: latency-svc-9vr26 [750.451516ms]
Dec 24 03:05:36.516: INFO: Created: latency-svc-x2xgb
Dec 24 03:05:36.544: INFO: Got endpoints: latency-svc-kpdqs [739.333504ms]
Dec 24 03:05:36.563: INFO: Created: latency-svc-546wg
Dec 24 03:05:36.594: INFO: Got endpoints: latency-svc-5q5rs [703.37842ms]
Dec 24 03:05:36.615: INFO: Created: latency-svc-7k8jl
Dec 24 03:05:36.645: INFO: Got endpoints: latency-svc-ct6vj [747.663517ms]
Dec 24 03:05:36.669: INFO: Created: latency-svc-9rzgl
Dec 24 03:05:36.695: INFO: Got endpoints: latency-svc-nfkql [726.258867ms]
Dec 24 03:05:36.714: INFO: Created: latency-svc-6vtpm
Dec 24 03:05:36.745: INFO: Got endpoints: latency-svc-68bwf [747.794674ms]
Dec 24 03:05:36.766: INFO: Created: latency-svc-vcsgk
Dec 24 03:05:36.794: INFO: Got endpoints: latency-svc-4wbt8 [747.333608ms]
Dec 24 03:05:36.820: INFO: Created: latency-svc-wfr79
Dec 24 03:05:36.845: INFO: Got endpoints: latency-svc-sndtv [750.056753ms]
Dec 24 03:05:36.863: INFO: Created: latency-svc-j6xrb
Dec 24 03:05:36.894: INFO: Got endpoints: latency-svc-gms7c [748.575248ms]
Dec 24 03:05:36.914: INFO: Created: latency-svc-vp9hb
Dec 24 03:05:36.945: INFO: Got endpoints: latency-svc-m4z75 [750.473005ms]
Dec 24 03:05:36.967: INFO: Created: latency-svc-j9q2c
Dec 24 03:05:36.995: INFO: Got endpoints: latency-svc-nz2k7 [741.197871ms]
Dec 24 03:05:37.014: INFO: Created: latency-svc-x6pp6
Dec 24 03:05:37.044: INFO: Got endpoints: latency-svc-qqft8 [750.217308ms]
Dec 24 03:05:37.066: INFO: Created: latency-svc-r9xbg
Dec 24 03:05:37.095: INFO: Got endpoints: latency-svc-2d5l5 [750.103822ms]
Dec 24 03:05:37.116: INFO: Created: latency-svc-ddzs2
Dec 24 03:05:37.145: INFO: Got endpoints: latency-svc-dsql9 [749.633125ms]
Dec 24 03:05:37.167: INFO: Created: latency-svc-lzrn7
Dec 24 03:05:37.196: INFO: Got endpoints: latency-svc-46fv8 [751.565943ms]
Dec 24 03:05:37.217: INFO: Created: latency-svc-zsp8j
Dec 24 03:05:37.245: INFO: Got endpoints: latency-svc-x2xgb [749.952513ms]
Dec 24 03:05:37.274: INFO: Created: latency-svc-zcdrr
Dec 24 03:05:37.295: INFO: Got endpoints: latency-svc-546wg [750.846838ms]
Dec 24 03:05:37.320: INFO: Created: latency-svc-c4xb8
Dec 24 03:05:37.344: INFO: Got endpoints: latency-svc-7k8jl [749.956801ms]
Dec 24 03:05:37.368: INFO: Created: latency-svc-d62ks
Dec 24 03:05:37.396: INFO: Got endpoints: latency-svc-9rzgl [750.90656ms]
Dec 24 03:05:37.417: INFO: Created: latency-svc-wst68
Dec 24 03:05:37.445: INFO: Got endpoints: latency-svc-6vtpm [749.853449ms]
Dec 24 03:05:37.466: INFO: Created: latency-svc-g55bh
Dec 24 03:05:37.495: INFO: Got endpoints: latency-svc-vcsgk [750.022337ms]
Dec 24 03:05:37.514: INFO: Created: latency-svc-srdjx
Dec 24 03:05:37.545: INFO: Got endpoints: latency-svc-wfr79 [750.23507ms]
Dec 24 03:05:37.573: INFO: Created: latency-svc-7kcls
Dec 24 03:05:37.595: INFO: Got endpoints: latency-svc-j6xrb [750.252713ms]
Dec 24 03:05:37.616: INFO: Created: latency-svc-ztdfx
Dec 24 03:05:37.644: INFO: Got endpoints: latency-svc-vp9hb [749.781789ms]
Dec 24 03:05:37.664: INFO: Created: latency-svc-f4jjb
Dec 24 03:05:37.698: INFO: Got endpoints: latency-svc-j9q2c [753.399302ms]
Dec 24 03:05:37.721: INFO: Created: latency-svc-wf2tt
Dec 24 03:05:37.746: INFO: Got endpoints: latency-svc-x6pp6 [750.727818ms]
Dec 24 03:05:37.766: INFO: Created: latency-svc-pmcbw
Dec 24 03:05:37.794: INFO: Got endpoints: latency-svc-r9xbg [750.459364ms]
Dec 24 03:05:37.815: INFO: Created: latency-svc-87v5l
Dec 24 03:05:37.845: INFO: Got endpoints: latency-svc-ddzs2 [749.771394ms]
Dec 24 03:05:37.866: INFO: Created: latency-svc-bdbqf
Dec 24 03:05:37.902: INFO: Got endpoints: latency-svc-lzrn7 [756.842672ms]
Dec 24 03:05:37.939: INFO: Created: latency-svc-fg756
Dec 24 03:05:37.944: INFO: Got endpoints: latency-svc-zsp8j [748.019271ms]
Dec 24 03:05:37.995: INFO: Got endpoints: latency-svc-zcdrr [750.093396ms]
Dec 24 03:05:38.045: INFO: Got endpoints: latency-svc-c4xb8 [749.441156ms]
Dec 24 03:05:38.095: INFO: Got endpoints: latency-svc-d62ks [750.567914ms]
Dec 24 03:05:38.145: INFO: Got endpoints: latency-svc-wst68 [749.304039ms]
Dec 24 03:05:38.195: INFO: Got endpoints: latency-svc-g55bh [750.550663ms]
Dec 24 03:05:38.245: INFO: Got endpoints: latency-svc-srdjx [749.835049ms]
Dec 24 03:05:38.295: INFO: Got endpoints: latency-svc-7kcls [750.22663ms]
Dec 24 03:05:38.346: INFO: Got endpoints: latency-svc-ztdfx [750.434308ms]
Dec 24 03:05:38.395: INFO: Got endpoints: latency-svc-f4jjb [750.929947ms]
Dec 24 03:05:38.445: INFO: Got endpoints: latency-svc-wf2tt [746.553696ms]
Dec 24 03:05:38.495: INFO: Got endpoints: latency-svc-pmcbw [748.611254ms]
Dec 24 03:05:38.545: INFO: Got endpoints: latency-svc-87v5l [750.524302ms]
Dec 24 03:05:38.595: INFO: Got endpoints: latency-svc-bdbqf [750.072952ms]
Dec 24 03:05:38.644: INFO: Got endpoints: latency-svc-fg756 [741.895171ms]
Dec 24 03:05:38.644: INFO: Latencies: [39.239344ms 41.138915ms 55.071491ms 82.977667ms 106.377174ms 123.342258ms 153.364194ms 170.894466ms 198.684557ms 215.73245ms 260.868294ms 277.542711ms 297.572333ms 303.566093ms 310.800305ms 313.081545ms 313.81908ms 314.263194ms 316.880404ms 317.38992ms 320.249851ms 321.364992ms 327.946774ms 328.289748ms 328.567369ms 328.658293ms 329.343655ms 331.999536ms 334.106141ms 334.358254ms 334.560894ms 334.579198ms 334.830251ms 335.64146ms 335.785234ms 336.141441ms 337.154205ms 341.206938ms 341.399297ms 342.348346ms 371.89984ms 390.580507ms 393.494502ms 402.533773ms 402.87526ms 402.919235ms 403.708639ms 404.091276ms 407.060377ms 415.00576ms 415.436134ms 416.389169ms 418.300332ms 419.239386ms 420.721465ms 423.249078ms 429.78424ms 433.734711ms 462.050966ms 494.59201ms 499.888144ms 536.170519ms 564.946552ms 573.490197ms 624.439588ms 657.091475ms 670.31458ms 703.37842ms 711.880948ms 726.258867ms 738.609365ms 738.722878ms 739.300291ms 739.333504ms 739.58271ms 739.667931ms 741.197871ms 741.895171ms 742.626332ms 742.733624ms 742.880695ms 743.041873ms 743.213169ms 743.505289ms 744.904569ms 745.832992ms 746.539458ms 746.553696ms 747.333608ms 747.442915ms 747.586201ms 747.663517ms 747.762975ms 747.794674ms 747.829369ms 748.019271ms 748.144464ms 748.334669ms 748.512433ms 748.575248ms 748.611254ms 748.672521ms 749.063924ms 749.145213ms 749.304039ms 749.305162ms 749.363288ms 749.385519ms 749.425422ms 749.4258ms 749.441156ms 749.45936ms 749.51253ms 749.528619ms 749.539756ms 749.633125ms 749.642451ms 749.653593ms 749.771394ms 749.777663ms 749.781789ms 749.784938ms 749.827868ms 749.835049ms 749.853449ms 749.868969ms 749.883695ms 749.91237ms 749.925103ms 749.952513ms 749.956801ms 749.979848ms 749.984949ms 749.996902ms 750.008853ms 750.01486ms 750.022337ms 750.056753ms 750.057809ms 750.072952ms 750.075697ms 750.078668ms 750.083692ms 750.086304ms 750.093396ms 750.103822ms 750.111592ms 750.112197ms 750.117257ms 750.207871ms 750.216751ms 750.217308ms 750.22663ms 750.23507ms 750.252713ms 750.266562ms 750.296529ms 750.341171ms 750.342205ms 750.373575ms 750.434308ms 750.451516ms 750.459364ms 750.473005ms 750.503608ms 750.524302ms 750.539628ms 750.550663ms 750.567914ms 750.638744ms 750.644556ms 750.659932ms 750.703999ms 750.727818ms 750.784548ms 750.846838ms 750.90656ms 750.929947ms 751.03174ms 751.05972ms 751.229366ms 751.375719ms 751.519421ms 751.565943ms 751.676305ms 751.916764ms 751.931214ms 752.45668ms 752.469763ms 752.574911ms 752.75206ms 753.399302ms 753.856907ms 754.952838ms 756.842672ms 759.12433ms 760.161714ms 760.275225ms 772.872474ms 794.998602ms]
Dec 24 03:05:38.644: INFO: 50 %ile: 748.611254ms
Dec 24 03:05:38.644: INFO: 90 %ile: 751.229366ms
Dec 24 03:05:38.644: INFO: 99 %ile: 772.872474ms
Dec 24 03:05:38.644: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:05:38.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-2194" for this suite.
Dec 24 03:06:06.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:06:06.796: INFO: namespace svc-latency-2194 deletion completed in 28.1444385s

• [SLOW TEST:40.040 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:06:06.796: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7977
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 24 03:06:06.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-7977'
Dec 24 03:06:07.048: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 24 03:06:07.048: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Dec 24 03:06:09.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 delete deployment e2e-test-httpd-deployment --namespace=kubectl-7977'
Dec 24 03:06:09.168: INFO: stderr: ""
Dec 24 03:06:09.168: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:06:09.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7977" for this suite.
Dec 24 03:06:21.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:06:21.328: INFO: namespace kubectl-7977 deletion completed in 12.152630265s

• [SLOW TEST:14.532 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:06:21.328: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-121
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec 24 03:06:21.494: INFO: Pod name pod-release: Found 0 pods out of 1
Dec 24 03:06:26.500: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:06:26.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-121" for this suite.
Dec 24 03:06:32.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:06:32.772: INFO: namespace replication-controller-121 deletion completed in 6.236976376s

• [SLOW TEST:11.444 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:06:32.772: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8180
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 24 03:06:32.988: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d88173bb-30ee-4492-bfe8-bf508410de65" in namespace "projected-8180" to be "success or failure"
Dec 24 03:06:32.998: INFO: Pod "downwardapi-volume-d88173bb-30ee-4492-bfe8-bf508410de65": Phase="Pending", Reason="", readiness=false. Elapsed: 5.501996ms
Dec 24 03:06:35.003: INFO: Pod "downwardapi-volume-d88173bb-30ee-4492-bfe8-bf508410de65": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010302851s
Dec 24 03:06:37.007: INFO: Pod "downwardapi-volume-d88173bb-30ee-4492-bfe8-bf508410de65": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014683253s
STEP: Saw pod success
Dec 24 03:06:37.007: INFO: Pod "downwardapi-volume-d88173bb-30ee-4492-bfe8-bf508410de65" satisfied condition "success or failure"
Dec 24 03:06:37.011: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod downwardapi-volume-d88173bb-30ee-4492-bfe8-bf508410de65 container client-container: <nil>
STEP: delete the pod
Dec 24 03:06:37.071: INFO: Waiting for pod downwardapi-volume-d88173bb-30ee-4492-bfe8-bf508410de65 to disappear
Dec 24 03:06:37.077: INFO: Pod downwardapi-volume-d88173bb-30ee-4492-bfe8-bf508410de65 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:06:37.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8180" for this suite.
Dec 24 03:06:43.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:06:43.237: INFO: namespace projected-8180 deletion completed in 6.150736144s

• [SLOW TEST:10.465 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:06:43.237: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-963
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-963
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-963
STEP: creating replication controller externalsvc in namespace services-963
I1224 03:06:43.459379      24 runners.go:184] Created replication controller with name: externalsvc, namespace: services-963, replica count: 2
I1224 03:06:46.509788      24 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Dec 24 03:06:46.547: INFO: Creating new exec pod
Dec 24 03:06:50.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 exec --namespace=services-963 execpod2k7fk -- /bin/sh -x -c nslookup nodeport-service'
Dec 24 03:06:51.628: INFO: stderr: "+ nslookup nodeport-service\n"
Dec 24 03:06:51.628: INFO: stdout: "Server:\t\t169.254.20.10\nAddress:\t169.254.20.10#53\n\nnodeport-service.services-963.svc.cluster.local\tcanonical name = externalsvc.services-963.svc.cluster.local.\nName:\texternalsvc.services-963.svc.cluster.local\nAddress: 100.71.0.232\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-963, will wait for the garbage collector to delete the pods
Dec 24 03:06:51.694: INFO: Deleting ReplicationController externalsvc took: 11.593398ms
Dec 24 03:06:52.094: INFO: Terminating ReplicationController externalsvc pods took: 400.267483ms
Dec 24 03:06:56.023: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:06:56.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-963" for this suite.
Dec 24 03:07:02.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:07:02.236: INFO: namespace services-963 deletion completed in 6.186290765s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:18.999 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:07:02.236: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-3315
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:07:18.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3315" for this suite.
Dec 24 03:07:24.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:07:24.620: INFO: namespace resourcequota-3315 deletion completed in 6.166281226s

• [SLOW TEST:22.384 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:07:24.620: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4575
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Dec 24 03:07:24.799: INFO: namespace kubectl-4575
Dec 24 03:07:24.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 create -f - --namespace=kubectl-4575'
Dec 24 03:07:25.109: INFO: stderr: ""
Dec 24 03:07:25.109: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 24 03:07:26.114: INFO: Selector matched 1 pods for map[app:redis]
Dec 24 03:07:26.114: INFO: Found 0 / 1
Dec 24 03:07:27.116: INFO: Selector matched 1 pods for map[app:redis]
Dec 24 03:07:27.116: INFO: Found 0 / 1
Dec 24 03:07:28.114: INFO: Selector matched 1 pods for map[app:redis]
Dec 24 03:07:28.114: INFO: Found 1 / 1
Dec 24 03:07:28.114: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 24 03:07:28.118: INFO: Selector matched 1 pods for map[app:redis]
Dec 24 03:07:28.118: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 24 03:07:28.118: INFO: wait on redis-master startup in kubectl-4575 
Dec 24 03:07:28.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 logs redis-master-jz2kt redis-master --namespace=kubectl-4575'
Dec 24 03:07:28.234: INFO: stderr: ""
Dec 24 03:07:28.234: INFO: stdout: "1:C 24 Dec 2019 03:07:26.674 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 24 Dec 2019 03:07:26.674 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 24 Dec 2019 03:07:26.674 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 24 Dec 2019 03:07:26.676 * Running mode=standalone, port=6379.\n1:M 24 Dec 2019 03:07:26.676 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 24 Dec 2019 03:07:26.676 # Server initialized\n1:M 24 Dec 2019 03:07:26.676 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 24 Dec 2019 03:07:26.676 * Ready to accept connections\n"
STEP: exposing RC
Dec 24 03:07:28.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-4575'
Dec 24 03:07:28.359: INFO: stderr: ""
Dec 24 03:07:28.359: INFO: stdout: "service/rm2 exposed\n"
Dec 24 03:07:28.368: INFO: Service rm2 in namespace kubectl-4575 found.
STEP: exposing service
Dec 24 03:07:30.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-4575'
Dec 24 03:07:30.513: INFO: stderr: ""
Dec 24 03:07:30.513: INFO: stdout: "service/rm3 exposed\n"
Dec 24 03:07:30.518: INFO: Service rm3 in namespace kubectl-4575 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:07:32.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4575" for this suite.
Dec 24 03:08:00.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:08:00.674: INFO: namespace kubectl-4575 deletion completed in 28.142920309s

• [SLOW TEST:36.054 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:08:00.675: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1247
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1247
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Dec 24 03:08:00.857: INFO: Found 0 stateful pods, waiting for 3
Dec 24 03:08:10.865: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 24 03:08:10.866: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 24 03:08:10.866: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec 24 03:08:10.914: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec 24 03:08:20.956: INFO: Updating stateful set ss2
Dec 24 03:08:20.965: INFO: Waiting for Pod statefulset-1247/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Dec 24 03:08:31.040: INFO: Found 2 stateful pods, waiting for 3
Dec 24 03:08:41.049: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 24 03:08:41.049: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 24 03:08:41.049: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec 24 03:08:41.080: INFO: Updating stateful set ss2
Dec 24 03:08:41.113: INFO: Waiting for Pod statefulset-1247/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 24 03:08:51.143: INFO: Updating stateful set ss2
Dec 24 03:08:51.153: INFO: Waiting for StatefulSet statefulset-1247/ss2 to complete update
Dec 24 03:08:51.153: INFO: Waiting for Pod statefulset-1247/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 24 03:09:01.163: INFO: Deleting all statefulset in ns statefulset-1247
Dec 24 03:09:01.168: INFO: Scaling statefulset ss2 to 0
Dec 24 03:09:31.188: INFO: Waiting for statefulset status.replicas updated to 0
Dec 24 03:09:31.191: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:09:31.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1247" for this suite.
Dec 24 03:09:37.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:09:37.398: INFO: namespace statefulset-1247 deletion completed in 6.182868334s

• [SLOW TEST:96.724 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:09:37.399: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-334
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 24 03:09:37.563: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7615c587-cc77-4d26-a089-3fa83fadbe2a" in namespace "projected-334" to be "success or failure"
Dec 24 03:09:37.571: INFO: Pod "downwardapi-volume-7615c587-cc77-4d26-a089-3fa83fadbe2a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.954473ms
Dec 24 03:09:39.577: INFO: Pod "downwardapi-volume-7615c587-cc77-4d26-a089-3fa83fadbe2a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01393609s
Dec 24 03:09:41.583: INFO: Pod "downwardapi-volume-7615c587-cc77-4d26-a089-3fa83fadbe2a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019562429s
STEP: Saw pod success
Dec 24 03:09:41.583: INFO: Pod "downwardapi-volume-7615c587-cc77-4d26-a089-3fa83fadbe2a" satisfied condition "success or failure"
Dec 24 03:09:41.597: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod downwardapi-volume-7615c587-cc77-4d26-a089-3fa83fadbe2a container client-container: <nil>
STEP: delete the pod
Dec 24 03:09:41.636: INFO: Waiting for pod downwardapi-volume-7615c587-cc77-4d26-a089-3fa83fadbe2a to disappear
Dec 24 03:09:41.639: INFO: Pod downwardapi-volume-7615c587-cc77-4d26-a089-3fa83fadbe2a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:09:41.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-334" for this suite.
Dec 24 03:09:47.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:09:47.812: INFO: namespace projected-334 deletion completed in 6.164347195s

• [SLOW TEST:10.413 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:09:47.812: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2289
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-7a1599c9-36ec-4ed2-b290-b5df1a102bbd in namespace container-probe-2289
Dec 24 03:09:51.993: INFO: Started pod test-webserver-7a1599c9-36ec-4ed2-b290-b5df1a102bbd in namespace container-probe-2289
STEP: checking the pod's current state and verifying that restartCount is present
Dec 24 03:09:51.998: INFO: Initial restart count of pod test-webserver-7a1599c9-36ec-4ed2-b290-b5df1a102bbd is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:13:52.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2289" for this suite.
Dec 24 03:13:58.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:13:58.864: INFO: namespace container-probe-2289 deletion completed in 6.147586866s

• [SLOW TEST:251.053 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:13:58.865: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7803
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-37bec5fa-fbc4-4a2c-bc01-cda6dccd7114
STEP: Creating a pod to test consume secrets
Dec 24 03:13:59.031: INFO: Waiting up to 5m0s for pod "pod-secrets-5b1eda40-27d7-43ec-9aa8-f265be6e5d0c" in namespace "secrets-7803" to be "success or failure"
Dec 24 03:13:59.037: INFO: Pod "pod-secrets-5b1eda40-27d7-43ec-9aa8-f265be6e5d0c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.261817ms
Dec 24 03:14:01.042: INFO: Pod "pod-secrets-5b1eda40-27d7-43ec-9aa8-f265be6e5d0c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011701927s
Dec 24 03:14:03.047: INFO: Pod "pod-secrets-5b1eda40-27d7-43ec-9aa8-f265be6e5d0c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016275588s
STEP: Saw pod success
Dec 24 03:14:03.047: INFO: Pod "pod-secrets-5b1eda40-27d7-43ec-9aa8-f265be6e5d0c" satisfied condition "success or failure"
Dec 24 03:14:03.052: INFO: Trying to get logs from node ip-172-16-44-108.ec2.internal pod pod-secrets-5b1eda40-27d7-43ec-9aa8-f265be6e5d0c container secret-volume-test: <nil>
STEP: delete the pod
Dec 24 03:14:03.091: INFO: Waiting for pod pod-secrets-5b1eda40-27d7-43ec-9aa8-f265be6e5d0c to disappear
Dec 24 03:14:03.095: INFO: Pod pod-secrets-5b1eda40-27d7-43ec-9aa8-f265be6e5d0c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:14:03.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7803" for this suite.
Dec 24 03:14:09.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:14:09.272: INFO: namespace secrets-7803 deletion completed in 6.170389929s

• [SLOW TEST:10.407 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:14:09.272: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4541
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Dec 24 03:14:09.492: INFO: Waiting up to 5m0s for pod "pod-61d21595-4ebc-4065-825d-ba75917c1707" in namespace "emptydir-4541" to be "success or failure"
Dec 24 03:14:09.501: INFO: Pod "pod-61d21595-4ebc-4065-825d-ba75917c1707": Phase="Pending", Reason="", readiness=false. Elapsed: 8.610942ms
Dec 24 03:14:11.505: INFO: Pod "pod-61d21595-4ebc-4065-825d-ba75917c1707": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012919419s
Dec 24 03:14:13.518: INFO: Pod "pod-61d21595-4ebc-4065-825d-ba75917c1707": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025476839s
STEP: Saw pod success
Dec 24 03:14:13.518: INFO: Pod "pod-61d21595-4ebc-4065-825d-ba75917c1707" satisfied condition "success or failure"
Dec 24 03:14:13.525: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-61d21595-4ebc-4065-825d-ba75917c1707 container test-container: <nil>
STEP: delete the pod
Dec 24 03:14:13.562: INFO: Waiting for pod pod-61d21595-4ebc-4065-825d-ba75917c1707 to disappear
Dec 24 03:14:13.566: INFO: Pod pod-61d21595-4ebc-4065-825d-ba75917c1707 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:14:13.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4541" for this suite.
Dec 24 03:14:19.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:14:19.716: INFO: namespace emptydir-4541 deletion completed in 6.143792716s

• [SLOW TEST:10.444 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:14:19.717: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6569
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:14:24.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6569" for this suite.
Dec 24 03:14:36.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:14:37.068: INFO: namespace replication-controller-6569 deletion completed in 12.149168961s

• [SLOW TEST:17.351 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:14:37.068: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6602
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 24 03:14:37.232: INFO: Waiting up to 5m0s for pod "pod-b2d2e01f-fe6d-4a6e-a619-70be3776b791" in namespace "emptydir-6602" to be "success or failure"
Dec 24 03:14:37.240: INFO: Pod "pod-b2d2e01f-fe6d-4a6e-a619-70be3776b791": Phase="Pending", Reason="", readiness=false. Elapsed: 7.901107ms
Dec 24 03:14:39.244: INFO: Pod "pod-b2d2e01f-fe6d-4a6e-a619-70be3776b791": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011882231s
Dec 24 03:14:41.248: INFO: Pod "pod-b2d2e01f-fe6d-4a6e-a619-70be3776b791": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016582778s
STEP: Saw pod success
Dec 24 03:14:41.248: INFO: Pod "pod-b2d2e01f-fe6d-4a6e-a619-70be3776b791" satisfied condition "success or failure"
Dec 24 03:14:41.253: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod pod-b2d2e01f-fe6d-4a6e-a619-70be3776b791 container test-container: <nil>
STEP: delete the pod
Dec 24 03:14:41.281: INFO: Waiting for pod pod-b2d2e01f-fe6d-4a6e-a619-70be3776b791 to disappear
Dec 24 03:14:41.286: INFO: Pod pod-b2d2e01f-fe6d-4a6e-a619-70be3776b791 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:14:41.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6602" for this suite.
Dec 24 03:14:47.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:14:47.442: INFO: namespace emptydir-6602 deletion completed in 6.149798575s

• [SLOW TEST:10.374 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:14:47.442: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7523
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:15:03.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7523" for this suite.
Dec 24 03:15:09.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:15:09.923: INFO: namespace resourcequota-7523 deletion completed in 6.203693876s

• [SLOW TEST:22.481 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:15:09.923: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2298
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-2298
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2298 to expose endpoints map[]
Dec 24 03:15:10.105: INFO: successfully validated that service endpoint-test2 in namespace services-2298 exposes endpoints map[] (5.438642ms elapsed)
STEP: Creating pod pod1 in namespace services-2298
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2298 to expose endpoints map[pod1:[80]]
Dec 24 03:15:13.172: INFO: successfully validated that service endpoint-test2 in namespace services-2298 exposes endpoints map[pod1:[80]] (3.055819045s elapsed)
STEP: Creating pod pod2 in namespace services-2298
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2298 to expose endpoints map[pod1:[80] pod2:[80]]
Dec 24 03:15:16.234: INFO: successfully validated that service endpoint-test2 in namespace services-2298 exposes endpoints map[pod1:[80] pod2:[80]] (3.054869634s elapsed)
STEP: Deleting pod pod1 in namespace services-2298
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2298 to expose endpoints map[pod2:[80]]
Dec 24 03:15:16.253: INFO: successfully validated that service endpoint-test2 in namespace services-2298 exposes endpoints map[pod2:[80]] (7.412798ms elapsed)
STEP: Deleting pod pod2 in namespace services-2298
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2298 to expose endpoints map[]
Dec 24 03:15:16.273: INFO: successfully validated that service endpoint-test2 in namespace services-2298 exposes endpoints map[] (9.153268ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:15:16.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2298" for this suite.
Dec 24 03:15:44.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:15:44.498: INFO: namespace services-2298 deletion completed in 28.172069652s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:34.575 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:15:44.498: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9419
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Dec 24 03:15:44.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 create -f - --namespace=kubectl-9419'
Dec 24 03:15:44.825: INFO: stderr: ""
Dec 24 03:15:44.825: INFO: stdout: "pod/pause created\n"
Dec 24 03:15:44.825: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec 24 03:15:44.825: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-9419" to be "running and ready"
Dec 24 03:15:44.830: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.568646ms
Dec 24 03:15:46.836: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01187712s
Dec 24 03:15:48.841: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.016766724s
Dec 24 03:15:48.841: INFO: Pod "pause" satisfied condition "running and ready"
Dec 24 03:15:48.841: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Dec 24 03:15:48.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 label pods pause testing-label=testing-label-value --namespace=kubectl-9419'
Dec 24 03:15:48.965: INFO: stderr: ""
Dec 24 03:15:48.965: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec 24 03:15:48.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pod pause -L testing-label --namespace=kubectl-9419'
Dec 24 03:15:49.067: INFO: stderr: ""
Dec 24 03:15:49.067: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec 24 03:15:49.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 label pods pause testing-label- --namespace=kubectl-9419'
Dec 24 03:15:49.168: INFO: stderr: ""
Dec 24 03:15:49.168: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec 24 03:15:49.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pod pause -L testing-label --namespace=kubectl-9419'
Dec 24 03:15:49.262: INFO: stderr: ""
Dec 24 03:15:49.262: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Dec 24 03:15:49.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 delete --grace-period=0 --force -f - --namespace=kubectl-9419'
Dec 24 03:15:49.376: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 24 03:15:49.376: INFO: stdout: "pod \"pause\" force deleted\n"
Dec 24 03:15:49.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get rc,svc -l name=pause --no-headers --namespace=kubectl-9419'
Dec 24 03:15:49.508: INFO: stderr: "No resources found in kubectl-9419 namespace.\n"
Dec 24 03:15:49.508: INFO: stdout: ""
Dec 24 03:15:49.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 get pods -l name=pause --namespace=kubectl-9419 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 24 03:15:49.614: INFO: stderr: ""
Dec 24 03:15:49.614: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:15:49.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9419" for this suite.
Dec 24 03:15:55.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:15:55.792: INFO: namespace kubectl-9419 deletion completed in 6.171742968s

• [SLOW TEST:11.294 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:15:55.792: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2489
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 24 03:15:55.950: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5b2135c5-6ce4-4a23-8323-0ae36c7de841" in namespace "downward-api-2489" to be "success or failure"
Dec 24 03:15:55.954: INFO: Pod "downwardapi-volume-5b2135c5-6ce4-4a23-8323-0ae36c7de841": Phase="Pending", Reason="", readiness=false. Elapsed: 3.799521ms
Dec 24 03:15:57.960: INFO: Pod "downwardapi-volume-5b2135c5-6ce4-4a23-8323-0ae36c7de841": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00946005s
Dec 24 03:15:59.965: INFO: Pod "downwardapi-volume-5b2135c5-6ce4-4a23-8323-0ae36c7de841": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014722347s
STEP: Saw pod success
Dec 24 03:15:59.965: INFO: Pod "downwardapi-volume-5b2135c5-6ce4-4a23-8323-0ae36c7de841" satisfied condition "success or failure"
Dec 24 03:15:59.970: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod downwardapi-volume-5b2135c5-6ce4-4a23-8323-0ae36c7de841 container client-container: <nil>
STEP: delete the pod
Dec 24 03:15:59.994: INFO: Waiting for pod downwardapi-volume-5b2135c5-6ce4-4a23-8323-0ae36c7de841 to disappear
Dec 24 03:15:59.999: INFO: Pod downwardapi-volume-5b2135c5-6ce4-4a23-8323-0ae36c7de841 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:16:00.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2489" for this suite.
Dec 24 03:16:06.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:16:06.176: INFO: namespace downward-api-2489 deletion completed in 6.168814619s

• [SLOW TEST:10.384 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:16:06.176: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7399
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 24 03:16:06.911: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Dec 24 03:16:08.927: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712754166, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712754166, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712754166, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712754166, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 24 03:16:11.953: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 03:16:11.957: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8836-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:16:18.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7399" for this suite.
Dec 24 03:16:24.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:16:24.316: INFO: namespace webhook-7399 deletion completed in 6.167379595s
STEP: Destroying namespace "webhook-7399-markers" for this suite.
Dec 24 03:16:30.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:16:30.467: INFO: namespace webhook-7399-markers deletion completed in 6.151262699s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.315 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:16:30.491: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-631
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-631
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 24 03:16:30.648: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 24 03:16:50.777: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.3.250:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-631 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 24 03:16:50.777: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 03:16:50.915: INFO: Found all expected endpoints: [netserver-0]
Dec 24 03:16:50.919: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.5.146:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-631 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 24 03:16:50.919: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 03:16:51.085: INFO: Found all expected endpoints: [netserver-1]
Dec 24 03:16:51.099: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.4.235:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-631 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 24 03:16:51.099: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
Dec 24 03:16:51.265: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:16:51.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-631" for this suite.
Dec 24 03:17:03.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:17:03.481: INFO: namespace pod-network-test-631 deletion completed in 12.196015674s

• [SLOW TEST:32.990 seconds]
[sig-network] Networking
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:17:03.482: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8562
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Dec 24 03:17:34.202: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W1224 03:17:34.201966      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 24 03:17:34.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8562" for this suite.
Dec 24 03:17:40.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:17:40.354: INFO: namespace gc-8562 deletion completed in 6.146822033s

• [SLOW TEST:36.872 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:17:40.354: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8362
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-2b28bf0b-fe27-4c31-8b8f-231df189e734
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:17:44.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8362" for this suite.
Dec 24 03:17:56.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:17:56.715: INFO: namespace configmap-8362 deletion completed in 12.137789296s

• [SLOW TEST:16.361 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:17:56.715: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9260
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Dec 24 03:17:56.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-304826164 --namespace=kubectl-9260 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec 24 03:18:00.207: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec 24 03:18:00.207: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:18:02.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9260" for this suite.
Dec 24 03:18:08.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:18:08.402: INFO: namespace kubectl-9260 deletion completed in 6.178101973s

• [SLOW TEST:11.687 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:18:08.405: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1206
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 24 03:18:08.609: INFO: Waiting up to 5m0s for pod "downwardapi-volume-db55a52b-9cee-4f64-9536-a011da96607a" in namespace "projected-1206" to be "success or failure"
Dec 24 03:18:08.617: INFO: Pod "downwardapi-volume-db55a52b-9cee-4f64-9536-a011da96607a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.712668ms
Dec 24 03:18:10.636: INFO: Pod "downwardapi-volume-db55a52b-9cee-4f64-9536-a011da96607a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027544307s
Dec 24 03:18:12.642: INFO: Pod "downwardapi-volume-db55a52b-9cee-4f64-9536-a011da96607a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032887705s
STEP: Saw pod success
Dec 24 03:18:12.642: INFO: Pod "downwardapi-volume-db55a52b-9cee-4f64-9536-a011da96607a" satisfied condition "success or failure"
Dec 24 03:18:12.645: INFO: Trying to get logs from node ip-172-16-30-121.ec2.internal pod downwardapi-volume-db55a52b-9cee-4f64-9536-a011da96607a container client-container: <nil>
STEP: delete the pod
Dec 24 03:18:12.681: INFO: Waiting for pod downwardapi-volume-db55a52b-9cee-4f64-9536-a011da96607a to disappear
Dec 24 03:18:12.684: INFO: Pod downwardapi-volume-db55a52b-9cee-4f64-9536-a011da96607a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:18:12.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1206" for this suite.
Dec 24 03:18:18.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:18:18.841: INFO: namespace projected-1206 deletion completed in 6.15080721s

• [SLOW TEST:10.436 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:18:18.841: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-9721
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 24 03:18:19.011: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:18:23.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9721" for this suite.
Dec 24 03:18:29.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:18:29.667: INFO: namespace init-container-9721 deletion completed in 6.139117842s

• [SLOW TEST:10.826 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:18:29.667: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9855
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 24 03:18:30.223: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 24 03:18:32.236: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712754310, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712754310, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712754310, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712754310, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 24 03:18:35.262: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 03:18:35.267: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-41-crds.webhook.example.com via the AdmissionRegistration API
Dec 24 03:18:41.354: INFO: Waiting for webhook configuration to be ready...
Dec 24 03:18:42.502: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:18:44.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9855" for this suite.
Dec 24 03:18:50.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:18:50.415: INFO: namespace webhook-9855 deletion completed in 6.142360026s
STEP: Destroying namespace "webhook-9855-markers" for this suite.
Dec 24 03:18:56.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:18:56.611: INFO: namespace webhook-9855-markers deletion completed in 6.195435736s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:26.965 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:18:56.632: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1822
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:19:00.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1822" for this suite.
Dec 24 03:19:20.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:19:21.012: INFO: namespace containers-1822 deletion completed in 20.140154056s

• [SLOW TEST:24.379 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 24 03:19:21.012: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-4304
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 24 03:19:21.166: INFO: >>> kubeConfig: /tmp/kubeconfig-304826164
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 24 03:20:18.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4304" for this suite.
Dec 24 03:20:24.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 24 03:20:25.110: INFO: namespace custom-resource-definition-4304 deletion completed in 6.22687566s

• [SLOW TEST:64.098 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSDec 24 03:20:25.110: INFO: Running AfterSuite actions on all nodes
Dec 24 03:20:25.110: INFO: Running AfterSuite actions on node 1
Dec 24 03:20:25.110: INFO: Skipping dumping logs from cluster

Ran 274 of 4731 Specs in 7215.902 seconds
SUCCESS! -- 274 Passed | 0 Failed | 0 Pending | 4457 Skipped
PASS

Ginkgo ran 1 suite in 2h0m17.478093738s
Test Suite Passed
