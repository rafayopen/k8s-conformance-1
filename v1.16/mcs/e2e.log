I0220 12:25:51.716034      18 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-673477187
I0220 12:25:51.722734      18 e2e.go:92] Starting e2e run "12997d22-1f8a-4b40-b29e-175ec55fa231" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1582201549 - Will randomize all specs
Will run 274 of 4731 specs

Feb 20 12:25:51.840: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
Feb 20 12:25:51.845: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 20 12:25:51.879: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 20 12:25:51.915: INFO: 12 / 12 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 20 12:25:51.915: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
Feb 20 12:25:51.915: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 20 12:25:51.927: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Feb 20 12:25:51.927: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'openstack-cloud-controller-manager' (0 seconds elapsed)
Feb 20 12:25:51.928: INFO: e2e test version: v1.16.4
Feb 20 12:25:51.930: INFO: kube-apiserver version: v1.16.4
Feb 20 12:25:51.930: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
Feb 20 12:25:51.940: INFO: Cluster IP family: ipv4
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:25:51.943: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename secrets
Feb 20 12:25:51.995: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Feb 20 12:25:52.006: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7427
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-7005
STEP: Creating secret with name secret-test-192616fc-da8b-4ddf-b950-5cae4ca0e24a
STEP: Creating a pod to test consume secrets
Feb 20 12:25:52.289: INFO: Waiting up to 5m0s for pod "pod-secrets-04bcef43-0166-46f3-9de9-d8014f8d3549" in namespace "secrets-7427" to be "success or failure"
Feb 20 12:25:52.292: INFO: Pod "pod-secrets-04bcef43-0166-46f3-9de9-d8014f8d3549": Phase="Pending", Reason="", readiness=false. Elapsed: 3.342779ms
Feb 20 12:25:54.296: INFO: Pod "pod-secrets-04bcef43-0166-46f3-9de9-d8014f8d3549": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007286242s
Feb 20 12:25:56.305: INFO: Pod "pod-secrets-04bcef43-0166-46f3-9de9-d8014f8d3549": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016445415s
STEP: Saw pod success
Feb 20 12:25:56.306: INFO: Pod "pod-secrets-04bcef43-0166-46f3-9de9-d8014f8d3549" satisfied condition "success or failure"
Feb 20 12:25:56.308: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-secrets-04bcef43-0166-46f3-9de9-d8014f8d3549 container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 12:25:56.421: INFO: Waiting for pod pod-secrets-04bcef43-0166-46f3-9de9-d8014f8d3549 to disappear
Feb 20 12:25:56.425: INFO: Pod pod-secrets-04bcef43-0166-46f3-9de9-d8014f8d3549 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:25:56.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7427" for this suite.
Feb 20 12:26:02.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:26:02.572: INFO: namespace secrets-7427 deletion completed in 6.141348494s
STEP: Destroying namespace "secret-namespace-7005" for this suite.
Feb 20 12:26:08.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:26:08.704: INFO: namespace secret-namespace-7005 deletion completed in 6.131665049s

• [SLOW TEST:16.762 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:26:08.719: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3441
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-3441
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-3441
I0220 12:26:08.921750      18 runners.go:184] Created replication controller with name: externalname-service, namespace: services-3441, replica count: 2
I0220 12:26:11.973481      18 runners.go:184] externalname-service Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0220 12:26:14.976028      18 runners.go:184] externalname-service Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0220 12:26:17.980250      18 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 20 12:26:17.981: INFO: Creating new exec pod
Feb 20 12:26:21.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=services-3441 execpodfl6gh -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Feb 20 12:26:21.733: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Feb 20 12:26:21.733: INFO: stdout: ""
Feb 20 12:26:21.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=services-3441 execpodfl6gh -- /bin/sh -x -c nc -zv -t -w 2 10.254.131.116 80'
Feb 20 12:26:21.972: INFO: stderr: "+ nc -zv -t -w 2 10.254.131.116 80\nConnection to 10.254.131.116 80 port [tcp/http] succeeded!\n"
Feb 20 12:26:21.972: INFO: stdout: ""
Feb 20 12:26:21.973: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:26:21.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3441" for this suite.
Feb 20 12:26:28.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:26:28.117: INFO: namespace services-3441 deletion completed in 6.114534426s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:19.404 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:26:28.131: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-2714
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Feb 20 12:26:28.296: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Feb 20 12:26:28.635: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Feb 20 12:26:30.702: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 12:26:32.708: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 12:26:34.708: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 12:26:36.707: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 12:26:38.760: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 12:26:40.707: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798388, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 12:26:44.091: INFO: Waited 1.374279511s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:26:45.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-2714" for this suite.
Feb 20 12:26:51.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:26:51.308: INFO: namespace aggregator-2714 deletion completed in 6.214496837s

• [SLOW TEST:23.179 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:26:51.315: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3624
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 20 12:26:51.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-3624'
Feb 20 12:26:51.634: INFO: stderr: ""
Feb 20 12:26:51.634: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Feb 20 12:26:56.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pod e2e-test-httpd-pod --namespace=kubectl-3624 -o json'
Feb 20 12:26:56.842: INFO: stderr: ""
Feb 20 12:26:56.842: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2020-02-20T12:26:51Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-3624\",\n        \"resourceVersion\": \"217420\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-3624/pods/e2e-test-httpd-pod\",\n        \"uid\": \"2bb590c7-ba68-4e4f-a3a5-69c91bc42ca5\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-mvzt2\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"kube16prod-img-kube16prod-img-minion-1\",\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"volumes\": [\n            {\n                \"name\": \"default-token-mvzt2\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-mvzt2\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-20T12:26:51Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-20T12:26:53Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-20T12:26:53Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-20T12:26:51Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://9cf56b0ab5af3ec9c02464e9ee3c2ba542ed752811bb5e306119f5e81c124410\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-02-20T12:26:52Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.0.29\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.100.99.140\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.100.99.140\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-02-20T12:26:51Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 20 12:26:56.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 replace -f - --namespace=kubectl-3624'
Feb 20 12:26:57.473: INFO: stderr: ""
Feb 20 12:26:57.473: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Feb 20 12:26:57.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 delete pods e2e-test-httpd-pod --namespace=kubectl-3624'
Feb 20 12:27:02.219: INFO: stderr: ""
Feb 20 12:27:02.220: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:27:02.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3624" for this suite.
Feb 20 12:27:08.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:27:08.338: INFO: namespace kubectl-3624 deletion completed in 6.111687024s

• [SLOW TEST:17.024 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:27:08.348: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-3728
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb 20 12:27:08.493: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:27:13.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3728" for this suite.
Feb 20 12:27:25.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:27:25.429: INFO: namespace init-container-3728 deletion completed in 12.10193653s

• [SLOW TEST:17.082 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:27:25.437: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-545
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-545.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-545.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-545.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-545.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-545.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-545.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 20 12:27:43.631: INFO: DNS probes using dns-545/dns-test-a5f6ca4b-1d98-409f-bc38-707bbfee796f succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:27:43.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-545" for this suite.
Feb 20 12:27:49.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:27:49.782: INFO: namespace dns-545 deletion completed in 6.130508127s

• [SLOW TEST:24.347 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:27:49.789: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7016
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 20 12:27:49.967: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c1ec6caa-8720-460d-a5ba-35f9047aca74" in namespace "downward-api-7016" to be "success or failure"
Feb 20 12:27:49.978: INFO: Pod "downwardapi-volume-c1ec6caa-8720-460d-a5ba-35f9047aca74": Phase="Pending", Reason="", readiness=false. Elapsed: 10.730398ms
Feb 20 12:27:51.982: INFO: Pod "downwardapi-volume-c1ec6caa-8720-460d-a5ba-35f9047aca74": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014489327s
Feb 20 12:27:53.987: INFO: Pod "downwardapi-volume-c1ec6caa-8720-460d-a5ba-35f9047aca74": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019643624s
Feb 20 12:27:55.993: INFO: Pod "downwardapi-volume-c1ec6caa-8720-460d-a5ba-35f9047aca74": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025410636s
STEP: Saw pod success
Feb 20 12:27:55.994: INFO: Pod "downwardapi-volume-c1ec6caa-8720-460d-a5ba-35f9047aca74" satisfied condition "success or failure"
Feb 20 12:27:55.997: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod downwardapi-volume-c1ec6caa-8720-460d-a5ba-35f9047aca74 container client-container: <nil>
STEP: delete the pod
Feb 20 12:27:56.053: INFO: Waiting for pod downwardapi-volume-c1ec6caa-8720-460d-a5ba-35f9047aca74 to disappear
Feb 20 12:27:56.055: INFO: Pod downwardapi-volume-c1ec6caa-8720-460d-a5ba-35f9047aca74 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:27:56.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7016" for this suite.
Feb 20 12:28:02.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:28:02.201: INFO: namespace downward-api-7016 deletion completed in 6.140692678s

• [SLOW TEST:12.413 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:28:02.211: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9411
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Feb 20 12:28:02.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 cluster-info'
Feb 20 12:28:02.548: INFO: stderr: ""
Feb 20 12:28:02.548: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:28:02.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9411" for this suite.
Feb 20 12:28:08.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:28:08.666: INFO: namespace kubectl-9411 deletion completed in 6.113372343s

• [SLOW TEST:6.455 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:28:08.666: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6841
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-6841
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-6841
STEP: creating replication controller externalsvc in namespace services-6841
I0220 12:28:08.890710      18 runners.go:184] Created replication controller with name: externalsvc, namespace: services-6841, replica count: 2
I0220 12:28:11.943078      18 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Feb 20 12:28:11.969: INFO: Creating new exec pod
Feb 20 12:28:15.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=services-6841 execpodj2pw4 -- /bin/sh -x -c nslookup clusterip-service'
Feb 20 12:28:16.337: INFO: stderr: "+ nslookup clusterip-service\n"
Feb 20 12:28:16.337: INFO: stdout: "Server:\t\t10.254.0.10\nAddress:\t10.254.0.10#53\n\nclusterip-service.services-6841.svc.cluster.local\tcanonical name = externalsvc.services-6841.svc.cluster.local.\nName:\texternalsvc.services-6841.svc.cluster.local\nAddress: 10.254.251.221\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-6841, will wait for the garbage collector to delete the pods
Feb 20 12:28:16.402: INFO: Deleting ReplicationController externalsvc took: 9.461644ms
Feb 20 12:28:17.302: INFO: Terminating ReplicationController externalsvc pods took: 900.382796ms
Feb 20 12:28:23.741: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:28:23.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6841" for this suite.
Feb 20 12:28:29.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:28:29.890: INFO: namespace services-6841 deletion completed in 6.131132119s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:21.225 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:28:29.898: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6975
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-2b771cdf-5b5d-4183-80cf-a30f5efe5c14
STEP: Creating a pod to test consume secrets
Feb 20 12:28:30.180: INFO: Waiting up to 5m0s for pod "pod-secrets-0a07d4dd-5eab-4b94-9f75-749ded2ced89" in namespace "secrets-6975" to be "success or failure"
Feb 20 12:28:30.183: INFO: Pod "pod-secrets-0a07d4dd-5eab-4b94-9f75-749ded2ced89": Phase="Pending", Reason="", readiness=false. Elapsed: 3.147126ms
Feb 20 12:28:32.192: INFO: Pod "pod-secrets-0a07d4dd-5eab-4b94-9f75-749ded2ced89": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012456682s
STEP: Saw pod success
Feb 20 12:28:32.193: INFO: Pod "pod-secrets-0a07d4dd-5eab-4b94-9f75-749ded2ced89" satisfied condition "success or failure"
Feb 20 12:28:32.201: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod pod-secrets-0a07d4dd-5eab-4b94-9f75-749ded2ced89 container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 12:28:32.224: INFO: Waiting for pod pod-secrets-0a07d4dd-5eab-4b94-9f75-749ded2ced89 to disappear
Feb 20 12:28:32.226: INFO: Pod pod-secrets-0a07d4dd-5eab-4b94-9f75-749ded2ced89 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:28:32.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6975" for this suite.
Feb 20 12:28:38.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:28:38.363: INFO: namespace secrets-6975 deletion completed in 6.132465073s

• [SLOW TEST:8.467 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:28:38.368: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3728
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb 20 12:28:41.094: INFO: Successfully updated pod "annotationupdatedee6e8f8-024e-4f71-8383-8739e303f550"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:28:43.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3728" for this suite.
Feb 20 12:28:55.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:28:55.249: INFO: namespace projected-3728 deletion completed in 12.125610053s

• [SLOW TEST:16.881 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:28:55.254: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9652
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb 20 12:28:55.438: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 20 12:28:55.449: INFO: Waiting for terminating namespaces to be deleted...
Feb 20 12:28:55.452: INFO: 
Logging pods the kubelet thinks is on node kube16prod-img-kube16prod-img-minion-1 before test
Feb 20 12:28:55.471: INFO: sonobuoy-systemd-logs-daemon-set-27e71f1a82d14495-ggbs7 from sonobuoy started at 2020-02-20 12:25:04 +0000 UTC (2 container statuses recorded)
Feb 20 12:28:55.472: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 20 12:28:55.472: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 20 12:28:55.472: INFO: metrics-server-f96ddff8f-h2kx6 from kube-system started at 2020-02-20 10:40:28 +0000 UTC (1 container statuses recorded)
Feb 20 12:28:55.472: INFO: 	Container metrics-server ready: true, restart count 0
Feb 20 12:28:55.472: INFO: calico-node-vkbjk from kube-system started at 2020-02-20 10:28:15 +0000 UTC (2 container statuses recorded)
Feb 20 12:28:55.473: INFO: 	Container calico-node ready: true, restart count 0
Feb 20 12:28:55.473: INFO: 	Container install-cni ready: true, restart count 0
Feb 20 12:28:55.473: INFO: prometheus-operator-prometheus-node-exporter-c2v94 from prometheus-monitoring started at 2020-02-20 10:28:15 +0000 UTC (1 container statuses recorded)
Feb 20 12:28:55.473: INFO: 	Container node-exporter ready: true, restart count 0
Feb 20 12:28:55.473: INFO: calico-kube-controllers-555d6f4bd9-xfg9t from kube-system started at 2020-02-20 10:56:19 +0000 UTC (1 container statuses recorded)
Feb 20 12:28:55.473: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 20 12:28:55.473: INFO: 
Logging pods the kubelet thinks is on node kube16prod-img-kube16prod-img-minion-2 before test
Feb 20 12:28:55.486: INFO: calico-node-6fj4h from kube-system started at 2020-02-20 12:20:59 +0000 UTC (2 container statuses recorded)
Feb 20 12:28:55.487: INFO: 	Container calico-node ready: true, restart count 0
Feb 20 12:28:55.487: INFO: 	Container install-cni ready: true, restart count 0
Feb 20 12:28:55.487: INFO: prometheus-operator-prometheus-node-exporter-wr9zk from prometheus-monitoring started at 2020-02-20 12:20:59 +0000 UTC (1 container statuses recorded)
Feb 20 12:28:55.487: INFO: 	Container node-exporter ready: true, restart count 0
Feb 20 12:28:55.487: INFO: sonobuoy from sonobuoy started at 2020-02-20 12:24:54 +0000 UTC (1 container statuses recorded)
Feb 20 12:28:55.487: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 20 12:28:55.487: INFO: sonobuoy-e2e-job-3610336cc2ba449a from sonobuoy started at 2020-02-20 12:25:05 +0000 UTC (2 container statuses recorded)
Feb 20 12:28:55.487: INFO: 	Container e2e ready: true, restart count 0
Feb 20 12:28:55.487: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 20 12:28:55.487: INFO: sonobuoy-systemd-logs-daemon-set-27e71f1a82d14495-fj7b9 from sonobuoy started at 2020-02-20 12:25:05 +0000 UTC (2 container statuses recorded)
Feb 20 12:28:55.487: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 20 12:28:55.487: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-4ac3a335-9f9c-4606-8370-817cf8732da1 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-4ac3a335-9f9c-4606-8370-817cf8732da1 off the node kube16prod-img-kube16prod-img-minion-2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-4ac3a335-9f9c-4606-8370-817cf8732da1
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:29:03.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9652" for this suite.
Feb 20 12:29:31.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:29:31.724: INFO: namespace sched-pred-9652 deletion completed in 28.136197175s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:36.472 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:29:31.735: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7103
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 20 12:29:31.963: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4b18fba9-5997-4ba2-bb57-48ef6bdfdf46" in namespace "projected-7103" to be "success or failure"
Feb 20 12:29:31.967: INFO: Pod "downwardapi-volume-4b18fba9-5997-4ba2-bb57-48ef6bdfdf46": Phase="Pending", Reason="", readiness=false. Elapsed: 3.452462ms
Feb 20 12:29:33.972: INFO: Pod "downwardapi-volume-4b18fba9-5997-4ba2-bb57-48ef6bdfdf46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008616944s
STEP: Saw pod success
Feb 20 12:29:33.973: INFO: Pod "downwardapi-volume-4b18fba9-5997-4ba2-bb57-48ef6bdfdf46" satisfied condition "success or failure"
Feb 20 12:29:33.976: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod downwardapi-volume-4b18fba9-5997-4ba2-bb57-48ef6bdfdf46 container client-container: <nil>
STEP: delete the pod
Feb 20 12:29:34.000: INFO: Waiting for pod downwardapi-volume-4b18fba9-5997-4ba2-bb57-48ef6bdfdf46 to disappear
Feb 20 12:29:34.003: INFO: Pod downwardapi-volume-4b18fba9-5997-4ba2-bb57-48ef6bdfdf46 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:29:34.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7103" for this suite.
Feb 20 12:29:40.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:29:40.124: INFO: namespace projected-7103 deletion completed in 6.11539531s

• [SLOW TEST:8.390 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:29:40.131: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-1681
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 12:29:40.288: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-600fdc86-bc59-4d74-aa56-2dff2c544913" in namespace "security-context-test-1681" to be "success or failure"
Feb 20 12:29:40.297: INFO: Pod "busybox-privileged-false-600fdc86-bc59-4d74-aa56-2dff2c544913": Phase="Pending", Reason="", readiness=false. Elapsed: 8.954736ms
Feb 20 12:29:42.304: INFO: Pod "busybox-privileged-false-600fdc86-bc59-4d74-aa56-2dff2c544913": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015924016s
Feb 20 12:29:44.310: INFO: Pod "busybox-privileged-false-600fdc86-bc59-4d74-aa56-2dff2c544913": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022404217s
Feb 20 12:29:46.316: INFO: Pod "busybox-privileged-false-600fdc86-bc59-4d74-aa56-2dff2c544913": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02750173s
Feb 20 12:29:46.316: INFO: Pod "busybox-privileged-false-600fdc86-bc59-4d74-aa56-2dff2c544913" satisfied condition "success or failure"
Feb 20 12:29:46.324: INFO: Got logs for pod "busybox-privileged-false-600fdc86-bc59-4d74-aa56-2dff2c544913": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:29:46.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1681" for this suite.
Feb 20 12:29:52.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:29:52.478: INFO: namespace security-context-test-1681 deletion completed in 6.141744591s

• [SLOW TEST:12.349 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:29:52.485: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8378
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 20 12:29:52.680: INFO: Waiting up to 5m0s for pod "downwardapi-volume-47efd110-b4b2-4d1a-b156-7ee64740fb8a" in namespace "projected-8378" to be "success or failure"
Feb 20 12:29:52.684: INFO: Pod "downwardapi-volume-47efd110-b4b2-4d1a-b156-7ee64740fb8a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.68747ms
Feb 20 12:29:54.689: INFO: Pod "downwardapi-volume-47efd110-b4b2-4d1a-b156-7ee64740fb8a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008809195s
Feb 20 12:29:56.697: INFO: Pod "downwardapi-volume-47efd110-b4b2-4d1a-b156-7ee64740fb8a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016538435s
STEP: Saw pod success
Feb 20 12:29:56.698: INFO: Pod "downwardapi-volume-47efd110-b4b2-4d1a-b156-7ee64740fb8a" satisfied condition "success or failure"
Feb 20 12:29:56.710: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod downwardapi-volume-47efd110-b4b2-4d1a-b156-7ee64740fb8a container client-container: <nil>
STEP: delete the pod
Feb 20 12:29:56.740: INFO: Waiting for pod downwardapi-volume-47efd110-b4b2-4d1a-b156-7ee64740fb8a to disappear
Feb 20 12:29:56.744: INFO: Pod downwardapi-volume-47efd110-b4b2-4d1a-b156-7ee64740fb8a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:29:56.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8378" for this suite.
Feb 20 12:30:02.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:30:02.907: INFO: namespace projected-8378 deletion completed in 6.157140795s

• [SLOW TEST:10.424 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:30:02.914: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1217
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 20 12:30:03.568: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 20 12:30:05.578: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798603, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798603, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798603, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798603, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 20 12:30:08.592: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 12:30:08.597: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:30:09.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1217" for this suite.
Feb 20 12:30:15.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:30:15.519: INFO: namespace webhook-1217 deletion completed in 6.147371356s
STEP: Destroying namespace "webhook-1217-markers" for this suite.
Feb 20 12:30:21.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:30:21.716: INFO: namespace webhook-1217-markers deletion completed in 6.196046423s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.815 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:30:21.734: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4606
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:30:25.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4606" for this suite.
Feb 20 12:31:09.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:31:10.082: INFO: namespace kubelet-test-4606 deletion completed in 44.16849555s

• [SLOW TEST:48.350 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:31:10.090: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-47
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-47
I0220 12:31:10.247103      18 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-47, replica count: 1
I0220 12:31:11.299383      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0220 12:31:12.300932      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 20 12:31:12.416: INFO: Created: latency-svc-nrrj6
Feb 20 12:31:12.421: INFO: Got endpoints: latency-svc-nrrj6 [18.729617ms]
Feb 20 12:31:12.439: INFO: Created: latency-svc-vgjfg
Feb 20 12:31:12.440: INFO: Created: latency-svc-mtknh
Feb 20 12:31:12.442: INFO: Got endpoints: latency-svc-vgjfg [20.545867ms]
Feb 20 12:31:12.446: INFO: Got endpoints: latency-svc-mtknh [23.356603ms]
Feb 20 12:31:12.460: INFO: Created: latency-svc-krxq4
Feb 20 12:31:12.460: INFO: Created: latency-svc-wn68b
Feb 20 12:31:12.460: INFO: Got endpoints: latency-svc-wn68b [37.241977ms]
Feb 20 12:31:12.463: INFO: Created: latency-svc-7lclm
Feb 20 12:31:12.464: INFO: Got endpoints: latency-svc-krxq4 [41.082449ms]
Feb 20 12:31:12.471: INFO: Created: latency-svc-dpzkt
Feb 20 12:31:12.471: INFO: Got endpoints: latency-svc-7lclm [47.626648ms]
Feb 20 12:31:12.477: INFO: Created: latency-svc-cgmh2
Feb 20 12:31:12.478: INFO: Got endpoints: latency-svc-dpzkt [54.68807ms]
Feb 20 12:31:12.485: INFO: Got endpoints: latency-svc-cgmh2 [61.826617ms]
Feb 20 12:31:12.486: INFO: Created: latency-svc-wlcmg
Feb 20 12:31:12.496: INFO: Created: latency-svc-bcnvl
Feb 20 12:31:12.497: INFO: Got endpoints: latency-svc-wlcmg [73.875653ms]
Feb 20 12:31:12.504: INFO: Got endpoints: latency-svc-bcnvl [80.191975ms]
Feb 20 12:31:12.505: INFO: Created: latency-svc-55wcm
Feb 20 12:31:12.510: INFO: Got endpoints: latency-svc-55wcm [86.588754ms]
Feb 20 12:31:12.514: INFO: Created: latency-svc-xqb42
Feb 20 12:31:12.516: INFO: Created: latency-svc-fgc2b
Feb 20 12:31:12.535: INFO: Created: latency-svc-r7cpv
Feb 20 12:31:12.536: INFO: Got endpoints: latency-svc-xqb42 [38.793055ms]
Feb 20 12:31:12.537: INFO: Got endpoints: latency-svc-fgc2b [112.751117ms]
Feb 20 12:31:12.542: INFO: Created: latency-svc-2lb26
Feb 20 12:31:12.549: INFO: Got endpoints: latency-svc-2lb26 [121.949767ms]
Feb 20 12:31:12.550: INFO: Got endpoints: latency-svc-r7cpv [125.727979ms]
Feb 20 12:31:12.560: INFO: Created: latency-svc-vwqgk
Feb 20 12:31:12.562: INFO: Got endpoints: latency-svc-vwqgk [134.253496ms]
Feb 20 12:31:12.567: INFO: Created: latency-svc-995s5
Feb 20 12:31:12.570: INFO: Created: latency-svc-7g2jk
Feb 20 12:31:12.573: INFO: Got endpoints: latency-svc-995s5 [149.064108ms]
Feb 20 12:31:12.579: INFO: Created: latency-svc-j6lgb
Feb 20 12:31:12.583: INFO: Created: latency-svc-rrk2b
Feb 20 12:31:12.583: INFO: Got endpoints: latency-svc-j6lgb [136.590407ms]
Feb 20 12:31:12.583: INFO: Got endpoints: latency-svc-7g2jk [140.501201ms]
Feb 20 12:31:12.590: INFO: Created: latency-svc-vwzk9
Feb 20 12:31:12.591: INFO: Got endpoints: latency-svc-rrk2b [126.20016ms]
Feb 20 12:31:12.601: INFO: Created: latency-svc-hdsr6
Feb 20 12:31:12.601: INFO: Got endpoints: latency-svc-vwzk9 [138.54785ms]
Feb 20 12:31:12.610: INFO: Got endpoints: latency-svc-hdsr6 [139.128867ms]
Feb 20 12:31:12.611: INFO: Created: latency-svc-zpb98
Feb 20 12:31:12.615: INFO: Got endpoints: latency-svc-zpb98 [137.268819ms]
Feb 20 12:31:12.619: INFO: Created: latency-svc-5dl8n
Feb 20 12:31:12.623: INFO: Created: latency-svc-vlmd2
Feb 20 12:31:12.624: INFO: Got endpoints: latency-svc-5dl8n [138.137331ms]
Feb 20 12:31:12.631: INFO: Created: latency-svc-4m75b
Feb 20 12:31:12.633: INFO: Got endpoints: latency-svc-vlmd2 [128.841137ms]
Feb 20 12:31:12.646: INFO: Got endpoints: latency-svc-4m75b [135.579652ms]
Feb 20 12:31:12.648: INFO: Created: latency-svc-dbswl
Feb 20 12:31:12.653: INFO: Got endpoints: latency-svc-dbswl [116.259233ms]
Feb 20 12:31:12.661: INFO: Created: latency-svc-d7h6p
Feb 20 12:31:12.672: INFO: Got endpoints: latency-svc-d7h6p [134.847526ms]
Feb 20 12:31:12.672: INFO: Created: latency-svc-jr89m
Feb 20 12:31:12.674: INFO: Got endpoints: latency-svc-jr89m [124.926446ms]
Feb 20 12:31:12.676: INFO: Created: latency-svc-cglw5
Feb 20 12:31:12.684: INFO: Created: latency-svc-6xxd8
Feb 20 12:31:12.684: INFO: Got endpoints: latency-svc-cglw5 [133.898796ms]
Feb 20 12:31:12.691: INFO: Created: latency-svc-566jm
Feb 20 12:31:12.699: INFO: Got endpoints: latency-svc-6xxd8 [136.581516ms]
Feb 20 12:31:12.699: INFO: Got endpoints: latency-svc-566jm [125.568265ms]
Feb 20 12:31:12.700: INFO: Created: latency-svc-qgtx6
Feb 20 12:31:12.703: INFO: Created: latency-svc-pdzkz
Feb 20 12:31:12.712: INFO: Created: latency-svc-d24z2
Feb 20 12:31:12.712: INFO: Got endpoints: latency-svc-pdzkz [128.870298ms]
Feb 20 12:31:12.712: INFO: Got endpoints: latency-svc-qgtx6 [129.647555ms]
Feb 20 12:31:12.717: INFO: Created: latency-svc-nb8pp
Feb 20 12:31:12.720: INFO: Got endpoints: latency-svc-d24z2 [129.16496ms]
Feb 20 12:31:12.723: INFO: Created: latency-svc-nrbp6
Feb 20 12:31:12.723: INFO: Got endpoints: latency-svc-nb8pp [121.834178ms]
Feb 20 12:31:12.736: INFO: Created: latency-svc-6bmtf
Feb 20 12:31:12.780: INFO: Got endpoints: latency-svc-nrbp6 [170.222674ms]
Feb 20 12:31:12.784: INFO: Created: latency-svc-5fzvm
Feb 20 12:31:12.789: INFO: Created: latency-svc-kjt8d
Feb 20 12:31:12.798: INFO: Created: latency-svc-g2vbz
Feb 20 12:31:12.802: INFO: Created: latency-svc-qrmjn
Feb 20 12:31:12.809: INFO: Created: latency-svc-n5r5k
Feb 20 12:31:12.822: INFO: Created: latency-svc-kkdmj
Feb 20 12:31:12.823: INFO: Got endpoints: latency-svc-6bmtf [207.622658ms]
Feb 20 12:31:12.828: INFO: Created: latency-svc-nksrz
Feb 20 12:31:12.837: INFO: Created: latency-svc-jtqpg
Feb 20 12:31:12.844: INFO: Created: latency-svc-fbw9q
Feb 20 12:31:12.851: INFO: Created: latency-svc-nk75d
Feb 20 12:31:12.857: INFO: Created: latency-svc-l4trh
Feb 20 12:31:12.862: INFO: Created: latency-svc-ncb6p
Feb 20 12:31:12.871: INFO: Got endpoints: latency-svc-5fzvm [246.858943ms]
Feb 20 12:31:12.871: INFO: Created: latency-svc-rmqsl
Feb 20 12:31:12.877: INFO: Created: latency-svc-5kk29
Feb 20 12:31:12.899: INFO: Created: latency-svc-h6d5x
Feb 20 12:31:12.905: INFO: Created: latency-svc-hmp87
Feb 20 12:31:12.916: INFO: Got endpoints: latency-svc-kjt8d [283.091587ms]
Feb 20 12:31:12.929: INFO: Created: latency-svc-lwq9c
Feb 20 12:31:12.972: INFO: Got endpoints: latency-svc-g2vbz [325.631188ms]
Feb 20 12:31:12.984: INFO: Created: latency-svc-v49rw
Feb 20 12:31:13.016: INFO: Got endpoints: latency-svc-qrmjn [363.197476ms]
Feb 20 12:31:13.027: INFO: Created: latency-svc-jphpz
Feb 20 12:31:13.066: INFO: Got endpoints: latency-svc-n5r5k [394.443605ms]
Feb 20 12:31:13.076: INFO: Created: latency-svc-jk264
Feb 20 12:31:13.116: INFO: Got endpoints: latency-svc-kkdmj [441.988501ms]
Feb 20 12:31:13.125: INFO: Created: latency-svc-mt598
Feb 20 12:31:13.167: INFO: Got endpoints: latency-svc-nksrz [482.84151ms]
Feb 20 12:31:13.176: INFO: Created: latency-svc-2pm5f
Feb 20 12:31:13.219: INFO: Got endpoints: latency-svc-jtqpg [520.854068ms]
Feb 20 12:31:13.228: INFO: Created: latency-svc-5462n
Feb 20 12:31:13.277: INFO: Got endpoints: latency-svc-fbw9q [577.85314ms]
Feb 20 12:31:13.285: INFO: Created: latency-svc-tx8kp
Feb 20 12:31:13.316: INFO: Got endpoints: latency-svc-nk75d [604.339103ms]
Feb 20 12:31:13.331: INFO: Created: latency-svc-5hfk8
Feb 20 12:31:13.367: INFO: Got endpoints: latency-svc-l4trh [654.076011ms]
Feb 20 12:31:13.377: INFO: Created: latency-svc-rmwss
Feb 20 12:31:13.417: INFO: Got endpoints: latency-svc-ncb6p [693.249086ms]
Feb 20 12:31:13.434: INFO: Created: latency-svc-d2rfw
Feb 20 12:31:13.477: INFO: Got endpoints: latency-svc-rmqsl [757.63186ms]
Feb 20 12:31:13.499: INFO: Created: latency-svc-hz8b8
Feb 20 12:31:13.520: INFO: Got endpoints: latency-svc-5kk29 [739.871053ms]
Feb 20 12:31:13.534: INFO: Created: latency-svc-rwchr
Feb 20 12:31:13.569: INFO: Got endpoints: latency-svc-h6d5x [746.039882ms]
Feb 20 12:31:13.581: INFO: Created: latency-svc-8568g
Feb 20 12:31:13.616: INFO: Got endpoints: latency-svc-hmp87 [745.328878ms]
Feb 20 12:31:13.652: INFO: Created: latency-svc-c6zms
Feb 20 12:31:13.666: INFO: Got endpoints: latency-svc-lwq9c [750.200294ms]
Feb 20 12:31:13.677: INFO: Created: latency-svc-lstqq
Feb 20 12:31:13.723: INFO: Got endpoints: latency-svc-v49rw [750.467757ms]
Feb 20 12:31:13.742: INFO: Created: latency-svc-crkf2
Feb 20 12:31:13.766: INFO: Got endpoints: latency-svc-jphpz [750.066904ms]
Feb 20 12:31:13.776: INFO: Created: latency-svc-c2grm
Feb 20 12:31:13.820: INFO: Got endpoints: latency-svc-jk264 [754.154858ms]
Feb 20 12:31:13.830: INFO: Created: latency-svc-dlrhb
Feb 20 12:31:13.866: INFO: Got endpoints: latency-svc-mt598 [749.787579ms]
Feb 20 12:31:13.877: INFO: Created: latency-svc-sttgl
Feb 20 12:31:13.917: INFO: Got endpoints: latency-svc-2pm5f [750.213067ms]
Feb 20 12:31:13.927: INFO: Created: latency-svc-2whzp
Feb 20 12:31:13.971: INFO: Got endpoints: latency-svc-5462n [751.6587ms]
Feb 20 12:31:13.993: INFO: Created: latency-svc-dd958
Feb 20 12:31:14.016: INFO: Got endpoints: latency-svc-tx8kp [739.64535ms]
Feb 20 12:31:14.027: INFO: Created: latency-svc-r2hn7
Feb 20 12:31:14.066: INFO: Got endpoints: latency-svc-5hfk8 [749.462687ms]
Feb 20 12:31:14.083: INFO: Created: latency-svc-4mtvk
Feb 20 12:31:14.149: INFO: Got endpoints: latency-svc-rmwss [782.162892ms]
Feb 20 12:31:14.158: INFO: Created: latency-svc-g6lkz
Feb 20 12:31:14.166: INFO: Got endpoints: latency-svc-d2rfw [749.1523ms]
Feb 20 12:31:14.175: INFO: Created: latency-svc-zw8pm
Feb 20 12:31:14.216: INFO: Got endpoints: latency-svc-hz8b8 [738.66174ms]
Feb 20 12:31:14.225: INFO: Created: latency-svc-lb5z9
Feb 20 12:31:14.271: INFO: Got endpoints: latency-svc-rwchr [750.020233ms]
Feb 20 12:31:14.281: INFO: Created: latency-svc-9dwrw
Feb 20 12:31:14.316: INFO: Got endpoints: latency-svc-8568g [747.073604ms]
Feb 20 12:31:14.326: INFO: Created: latency-svc-vjb9z
Feb 20 12:31:14.367: INFO: Got endpoints: latency-svc-c6zms [750.963987ms]
Feb 20 12:31:14.376: INFO: Created: latency-svc-tmtff
Feb 20 12:31:14.416: INFO: Got endpoints: latency-svc-lstqq [749.682681ms]
Feb 20 12:31:14.427: INFO: Created: latency-svc-tszk4
Feb 20 12:31:14.466: INFO: Got endpoints: latency-svc-crkf2 [743.532865ms]
Feb 20 12:31:14.475: INFO: Created: latency-svc-js24f
Feb 20 12:31:14.516: INFO: Got endpoints: latency-svc-c2grm [750.074558ms]
Feb 20 12:31:14.528: INFO: Created: latency-svc-n5wbr
Feb 20 12:31:14.566: INFO: Got endpoints: latency-svc-dlrhb [745.280253ms]
Feb 20 12:31:14.576: INFO: Created: latency-svc-bgjg7
Feb 20 12:31:14.616: INFO: Got endpoints: latency-svc-sttgl [749.793031ms]
Feb 20 12:31:14.625: INFO: Created: latency-svc-2dvh8
Feb 20 12:31:14.668: INFO: Got endpoints: latency-svc-2whzp [750.971129ms]
Feb 20 12:31:14.678: INFO: Created: latency-svc-wmsdt
Feb 20 12:31:14.719: INFO: Got endpoints: latency-svc-dd958 [747.166347ms]
Feb 20 12:31:14.730: INFO: Created: latency-svc-nxwtm
Feb 20 12:31:14.766: INFO: Got endpoints: latency-svc-r2hn7 [749.589732ms]
Feb 20 12:31:14.785: INFO: Created: latency-svc-ph627
Feb 20 12:31:14.817: INFO: Got endpoints: latency-svc-4mtvk [751.216771ms]
Feb 20 12:31:14.836: INFO: Created: latency-svc-rdcx5
Feb 20 12:31:14.867: INFO: Got endpoints: latency-svc-g6lkz [718.0825ms]
Feb 20 12:31:14.877: INFO: Created: latency-svc-7vgjs
Feb 20 12:31:14.918: INFO: Got endpoints: latency-svc-zw8pm [751.799767ms]
Feb 20 12:31:14.934: INFO: Created: latency-svc-9kn8h
Feb 20 12:31:14.966: INFO: Got endpoints: latency-svc-lb5z9 [749.903958ms]
Feb 20 12:31:14.977: INFO: Created: latency-svc-w5vkj
Feb 20 12:31:15.021: INFO: Got endpoints: latency-svc-9dwrw [750.696321ms]
Feb 20 12:31:15.033: INFO: Created: latency-svc-knz5m
Feb 20 12:31:15.075: INFO: Got endpoints: latency-svc-vjb9z [758.209932ms]
Feb 20 12:31:15.084: INFO: Created: latency-svc-zpspn
Feb 20 12:31:15.117: INFO: Got endpoints: latency-svc-tmtff [749.851046ms]
Feb 20 12:31:15.129: INFO: Created: latency-svc-sjs4s
Feb 20 12:31:15.175: INFO: Got endpoints: latency-svc-tszk4 [758.497091ms]
Feb 20 12:31:15.188: INFO: Created: latency-svc-mlt6k
Feb 20 12:31:15.216: INFO: Got endpoints: latency-svc-js24f [750.034134ms]
Feb 20 12:31:15.226: INFO: Created: latency-svc-fkdtr
Feb 20 12:31:15.266: INFO: Got endpoints: latency-svc-n5wbr [749.53366ms]
Feb 20 12:31:15.282: INFO: Created: latency-svc-pzmsx
Feb 20 12:31:15.317: INFO: Got endpoints: latency-svc-bgjg7 [750.432414ms]
Feb 20 12:31:15.326: INFO: Created: latency-svc-75mvh
Feb 20 12:31:15.366: INFO: Got endpoints: latency-svc-2dvh8 [749.559834ms]
Feb 20 12:31:15.376: INFO: Created: latency-svc-bs4nj
Feb 20 12:31:15.419: INFO: Got endpoints: latency-svc-wmsdt [750.336356ms]
Feb 20 12:31:15.447: INFO: Created: latency-svc-wfrdw
Feb 20 12:31:15.467: INFO: Got endpoints: latency-svc-nxwtm [747.848087ms]
Feb 20 12:31:15.478: INFO: Created: latency-svc-nkzms
Feb 20 12:31:15.518: INFO: Got endpoints: latency-svc-ph627 [751.761851ms]
Feb 20 12:31:15.531: INFO: Created: latency-svc-9zd64
Feb 20 12:31:15.567: INFO: Got endpoints: latency-svc-rdcx5 [749.842784ms]
Feb 20 12:31:15.577: INFO: Created: latency-svc-4lzw6
Feb 20 12:31:15.617: INFO: Got endpoints: latency-svc-7vgjs [749.372907ms]
Feb 20 12:31:15.627: INFO: Created: latency-svc-ndljl
Feb 20 12:31:15.666: INFO: Got endpoints: latency-svc-9kn8h [748.058971ms]
Feb 20 12:31:15.678: INFO: Created: latency-svc-r7ptv
Feb 20 12:31:15.717: INFO: Got endpoints: latency-svc-w5vkj [750.907882ms]
Feb 20 12:31:15.731: INFO: Created: latency-svc-n4vxc
Feb 20 12:31:15.768: INFO: Got endpoints: latency-svc-knz5m [746.486421ms]
Feb 20 12:31:15.788: INFO: Created: latency-svc-wbmg9
Feb 20 12:31:15.818: INFO: Got endpoints: latency-svc-zpspn [743.464572ms]
Feb 20 12:31:15.836: INFO: Created: latency-svc-jpz64
Feb 20 12:31:15.868: INFO: Got endpoints: latency-svc-sjs4s [750.152562ms]
Feb 20 12:31:15.880: INFO: Created: latency-svc-8lznw
Feb 20 12:31:15.918: INFO: Got endpoints: latency-svc-mlt6k [743.004291ms]
Feb 20 12:31:15.930: INFO: Created: latency-svc-p5z9z
Feb 20 12:31:15.969: INFO: Got endpoints: latency-svc-fkdtr [751.95774ms]
Feb 20 12:31:15.980: INFO: Created: latency-svc-njxf2
Feb 20 12:31:16.019: INFO: Got endpoints: latency-svc-pzmsx [753.212957ms]
Feb 20 12:31:16.042: INFO: Created: latency-svc-h2q9d
Feb 20 12:31:16.067: INFO: Got endpoints: latency-svc-75mvh [750.764222ms]
Feb 20 12:31:16.078: INFO: Created: latency-svc-vntlt
Feb 20 12:31:16.117: INFO: Got endpoints: latency-svc-bs4nj [750.823031ms]
Feb 20 12:31:16.142: INFO: Created: latency-svc-2zsng
Feb 20 12:31:16.166: INFO: Got endpoints: latency-svc-wfrdw [747.205187ms]
Feb 20 12:31:16.178: INFO: Created: latency-svc-zj84q
Feb 20 12:31:16.217: INFO: Got endpoints: latency-svc-nkzms [749.490685ms]
Feb 20 12:31:16.226: INFO: Created: latency-svc-d4pgk
Feb 20 12:31:16.266: INFO: Got endpoints: latency-svc-9zd64 [748.11834ms]
Feb 20 12:31:16.287: INFO: Created: latency-svc-k7vmn
Feb 20 12:31:16.316: INFO: Got endpoints: latency-svc-4lzw6 [748.685155ms]
Feb 20 12:31:16.326: INFO: Created: latency-svc-kxcxp
Feb 20 12:31:16.367: INFO: Got endpoints: latency-svc-ndljl [750.096734ms]
Feb 20 12:31:16.377: INFO: Created: latency-svc-x9mr6
Feb 20 12:31:16.418: INFO: Got endpoints: latency-svc-r7ptv [752.160018ms]
Feb 20 12:31:16.433: INFO: Created: latency-svc-mcfxj
Feb 20 12:31:16.473: INFO: Got endpoints: latency-svc-n4vxc [755.02463ms]
Feb 20 12:31:16.483: INFO: Created: latency-svc-rd7n2
Feb 20 12:31:16.517: INFO: Got endpoints: latency-svc-wbmg9 [749.214253ms]
Feb 20 12:31:16.549: INFO: Created: latency-svc-mcpdn
Feb 20 12:31:16.617: INFO: Got endpoints: latency-svc-jpz64 [798.529354ms]
Feb 20 12:31:16.619: INFO: Got endpoints: latency-svc-8lznw [751.724103ms]
Feb 20 12:31:16.630: INFO: Created: latency-svc-c8dpq
Feb 20 12:31:16.637: INFO: Created: latency-svc-zcnmv
Feb 20 12:31:16.666: INFO: Got endpoints: latency-svc-p5z9z [748.209849ms]
Feb 20 12:31:16.678: INFO: Created: latency-svc-nknx4
Feb 20 12:31:16.718: INFO: Got endpoints: latency-svc-njxf2 [749.302936ms]
Feb 20 12:31:16.734: INFO: Created: latency-svc-f7klb
Feb 20 12:31:16.767: INFO: Got endpoints: latency-svc-h2q9d [746.910426ms]
Feb 20 12:31:16.777: INFO: Created: latency-svc-2mhjw
Feb 20 12:31:16.816: INFO: Got endpoints: latency-svc-vntlt [748.541011ms]
Feb 20 12:31:16.826: INFO: Created: latency-svc-z8vfb
Feb 20 12:31:16.867: INFO: Got endpoints: latency-svc-2zsng [750.371492ms]
Feb 20 12:31:16.881: INFO: Created: latency-svc-xpcd9
Feb 20 12:31:16.917: INFO: Got endpoints: latency-svc-zj84q [750.890638ms]
Feb 20 12:31:16.940: INFO: Created: latency-svc-xhshc
Feb 20 12:31:16.967: INFO: Got endpoints: latency-svc-d4pgk [749.808561ms]
Feb 20 12:31:16.975: INFO: Created: latency-svc-768j9
Feb 20 12:31:17.018: INFO: Got endpoints: latency-svc-k7vmn [751.070621ms]
Feb 20 12:31:17.028: INFO: Created: latency-svc-ps4qf
Feb 20 12:31:17.066: INFO: Got endpoints: latency-svc-kxcxp [749.832979ms]
Feb 20 12:31:17.080: INFO: Created: latency-svc-n6qxk
Feb 20 12:31:17.116: INFO: Got endpoints: latency-svc-x9mr6 [748.820411ms]
Feb 20 12:31:17.125: INFO: Created: latency-svc-5w92v
Feb 20 12:31:17.167: INFO: Got endpoints: latency-svc-mcfxj [747.85949ms]
Feb 20 12:31:17.175: INFO: Created: latency-svc-djkfw
Feb 20 12:31:17.216: INFO: Got endpoints: latency-svc-rd7n2 [742.493979ms]
Feb 20 12:31:17.224: INFO: Created: latency-svc-5j57k
Feb 20 12:31:17.267: INFO: Got endpoints: latency-svc-mcpdn [749.251597ms]
Feb 20 12:31:17.275: INFO: Created: latency-svc-xdk49
Feb 20 12:31:17.316: INFO: Got endpoints: latency-svc-c8dpq [699.211201ms]
Feb 20 12:31:17.326: INFO: Created: latency-svc-vmr2v
Feb 20 12:31:17.372: INFO: Got endpoints: latency-svc-zcnmv [752.864171ms]
Feb 20 12:31:17.382: INFO: Created: latency-svc-fmwfk
Feb 20 12:31:17.418: INFO: Got endpoints: latency-svc-nknx4 [751.195317ms]
Feb 20 12:31:17.427: INFO: Created: latency-svc-9vw4s
Feb 20 12:31:17.467: INFO: Got endpoints: latency-svc-f7klb [748.283089ms]
Feb 20 12:31:17.500: INFO: Created: latency-svc-r6zws
Feb 20 12:31:17.517: INFO: Got endpoints: latency-svc-2mhjw [750.34938ms]
Feb 20 12:31:17.528: INFO: Created: latency-svc-2b5vs
Feb 20 12:31:17.567: INFO: Got endpoints: latency-svc-z8vfb [750.80684ms]
Feb 20 12:31:17.579: INFO: Created: latency-svc-84rrl
Feb 20 12:31:17.617: INFO: Got endpoints: latency-svc-xpcd9 [749.838987ms]
Feb 20 12:31:17.628: INFO: Created: latency-svc-xvx8d
Feb 20 12:31:17.666: INFO: Got endpoints: latency-svc-xhshc [748.54953ms]
Feb 20 12:31:17.678: INFO: Created: latency-svc-bk8qb
Feb 20 12:31:17.716: INFO: Got endpoints: latency-svc-768j9 [749.123151ms]
Feb 20 12:31:17.724: INFO: Created: latency-svc-lstx8
Feb 20 12:31:17.767: INFO: Got endpoints: latency-svc-ps4qf [749.658395ms]
Feb 20 12:31:17.780: INFO: Created: latency-svc-f556f
Feb 20 12:31:17.816: INFO: Got endpoints: latency-svc-n6qxk [750.302958ms]
Feb 20 12:31:17.824: INFO: Created: latency-svc-htlwl
Feb 20 12:31:17.866: INFO: Got endpoints: latency-svc-5w92v [749.868412ms]
Feb 20 12:31:17.886: INFO: Created: latency-svc-78jw5
Feb 20 12:31:17.916: INFO: Got endpoints: latency-svc-djkfw [749.019422ms]
Feb 20 12:31:17.927: INFO: Created: latency-svc-7pnlj
Feb 20 12:31:17.967: INFO: Got endpoints: latency-svc-5j57k [751.2646ms]
Feb 20 12:31:17.976: INFO: Created: latency-svc-4qptl
Feb 20 12:31:18.021: INFO: Got endpoints: latency-svc-xdk49 [754.338398ms]
Feb 20 12:31:18.032: INFO: Created: latency-svc-njmbw
Feb 20 12:31:18.067: INFO: Got endpoints: latency-svc-vmr2v [750.003735ms]
Feb 20 12:31:18.083: INFO: Created: latency-svc-m2dgp
Feb 20 12:31:18.116: INFO: Got endpoints: latency-svc-fmwfk [743.434678ms]
Feb 20 12:31:18.130: INFO: Created: latency-svc-ppk2j
Feb 20 12:31:18.167: INFO: Got endpoints: latency-svc-9vw4s [749.770458ms]
Feb 20 12:31:18.178: INFO: Created: latency-svc-gxr6v
Feb 20 12:31:18.218: INFO: Got endpoints: latency-svc-r6zws [750.944193ms]
Feb 20 12:31:18.229: INFO: Created: latency-svc-bjzxn
Feb 20 12:31:18.268: INFO: Got endpoints: latency-svc-2b5vs [751.003234ms]
Feb 20 12:31:18.279: INFO: Created: latency-svc-pjbck
Feb 20 12:31:18.316: INFO: Got endpoints: latency-svc-84rrl [749.14464ms]
Feb 20 12:31:18.325: INFO: Created: latency-svc-dk8lj
Feb 20 12:31:18.366: INFO: Got endpoints: latency-svc-xvx8d [748.330214ms]
Feb 20 12:31:18.384: INFO: Created: latency-svc-87bkk
Feb 20 12:31:18.417: INFO: Got endpoints: latency-svc-bk8qb [751.28707ms]
Feb 20 12:31:18.429: INFO: Created: latency-svc-h777g
Feb 20 12:31:18.466: INFO: Got endpoints: latency-svc-lstx8 [749.764874ms]
Feb 20 12:31:18.479: INFO: Created: latency-svc-rsl62
Feb 20 12:31:18.518: INFO: Got endpoints: latency-svc-f556f [750.812532ms]
Feb 20 12:31:18.530: INFO: Created: latency-svc-b5ww9
Feb 20 12:31:18.569: INFO: Got endpoints: latency-svc-htlwl [752.534251ms]
Feb 20 12:31:18.579: INFO: Created: latency-svc-8lrmt
Feb 20 12:31:18.617: INFO: Got endpoints: latency-svc-78jw5 [750.110593ms]
Feb 20 12:31:18.626: INFO: Created: latency-svc-hn2p5
Feb 20 12:31:18.666: INFO: Got endpoints: latency-svc-7pnlj [749.866143ms]
Feb 20 12:31:18.688: INFO: Created: latency-svc-g4qxw
Feb 20 12:31:18.716: INFO: Got endpoints: latency-svc-4qptl [748.174435ms]
Feb 20 12:31:18.725: INFO: Created: latency-svc-gzrp6
Feb 20 12:31:18.846: INFO: Got endpoints: latency-svc-m2dgp [779.559306ms]
Feb 20 12:31:18.847: INFO: Got endpoints: latency-svc-njmbw [825.442112ms]
Feb 20 12:31:18.855: INFO: Created: latency-svc-q47j5
Feb 20 12:31:18.862: INFO: Created: latency-svc-t8dvz
Feb 20 12:31:18.865: INFO: Got endpoints: latency-svc-ppk2j [749.190651ms]
Feb 20 12:31:18.872: INFO: Created: latency-svc-sft5k
Feb 20 12:31:18.918: INFO: Got endpoints: latency-svc-gxr6v [750.041685ms]
Feb 20 12:31:18.929: INFO: Created: latency-svc-67spc
Feb 20 12:31:18.966: INFO: Got endpoints: latency-svc-bjzxn [747.652173ms]
Feb 20 12:31:18.976: INFO: Created: latency-svc-4hhxl
Feb 20 12:31:19.016: INFO: Got endpoints: latency-svc-pjbck [747.81329ms]
Feb 20 12:31:19.025: INFO: Created: latency-svc-dmjnp
Feb 20 12:31:19.067: INFO: Got endpoints: latency-svc-dk8lj [750.468332ms]
Feb 20 12:31:19.077: INFO: Created: latency-svc-2cbxc
Feb 20 12:31:19.116: INFO: Got endpoints: latency-svc-87bkk [749.976971ms]
Feb 20 12:31:19.124: INFO: Created: latency-svc-b9kg9
Feb 20 12:31:19.166: INFO: Got endpoints: latency-svc-h777g [748.352591ms]
Feb 20 12:31:19.180: INFO: Created: latency-svc-gxf59
Feb 20 12:31:19.217: INFO: Got endpoints: latency-svc-rsl62 [750.560973ms]
Feb 20 12:31:19.226: INFO: Created: latency-svc-ghgkb
Feb 20 12:31:19.266: INFO: Got endpoints: latency-svc-b5ww9 [747.408342ms]
Feb 20 12:31:19.276: INFO: Created: latency-svc-hvbvr
Feb 20 12:31:19.317: INFO: Got endpoints: latency-svc-8lrmt [747.877066ms]
Feb 20 12:31:19.328: INFO: Created: latency-svc-qj4qm
Feb 20 12:31:19.367: INFO: Got endpoints: latency-svc-hn2p5 [750.108186ms]
Feb 20 12:31:19.377: INFO: Created: latency-svc-s2bhj
Feb 20 12:31:19.421: INFO: Got endpoints: latency-svc-g4qxw [754.914626ms]
Feb 20 12:31:19.451: INFO: Created: latency-svc-2rxmg
Feb 20 12:31:19.467: INFO: Got endpoints: latency-svc-gzrp6 [751.245976ms]
Feb 20 12:31:19.487: INFO: Created: latency-svc-bvzqk
Feb 20 12:31:19.516: INFO: Got endpoints: latency-svc-q47j5 [669.522178ms]
Feb 20 12:31:19.535: INFO: Created: latency-svc-c5h78
Feb 20 12:31:19.567: INFO: Got endpoints: latency-svc-t8dvz [719.984239ms]
Feb 20 12:31:19.583: INFO: Created: latency-svc-rsj9q
Feb 20 12:31:19.616: INFO: Got endpoints: latency-svc-sft5k [750.630042ms]
Feb 20 12:31:19.626: INFO: Created: latency-svc-4ml7b
Feb 20 12:31:19.666: INFO: Got endpoints: latency-svc-67spc [748.410809ms]
Feb 20 12:31:19.677: INFO: Created: latency-svc-k2xdl
Feb 20 12:31:19.715: INFO: Got endpoints: latency-svc-4hhxl [749.56832ms]
Feb 20 12:31:19.725: INFO: Created: latency-svc-v68bv
Feb 20 12:31:19.766: INFO: Got endpoints: latency-svc-dmjnp [750.172913ms]
Feb 20 12:31:19.775: INFO: Created: latency-svc-s6vxg
Feb 20 12:31:19.817: INFO: Got endpoints: latency-svc-2cbxc [749.92532ms]
Feb 20 12:31:19.826: INFO: Created: latency-svc-dhcv5
Feb 20 12:31:19.871: INFO: Got endpoints: latency-svc-b9kg9 [754.430594ms]
Feb 20 12:31:19.881: INFO: Created: latency-svc-f6q4r
Feb 20 12:31:19.916: INFO: Got endpoints: latency-svc-gxf59 [749.930162ms]
Feb 20 12:31:19.924: INFO: Created: latency-svc-mgrqr
Feb 20 12:31:19.967: INFO: Got endpoints: latency-svc-ghgkb [750.008049ms]
Feb 20 12:31:19.976: INFO: Created: latency-svc-lhfv8
Feb 20 12:31:20.019: INFO: Got endpoints: latency-svc-hvbvr [753.100801ms]
Feb 20 12:31:20.029: INFO: Created: latency-svc-lmfbg
Feb 20 12:31:20.067: INFO: Got endpoints: latency-svc-qj4qm [750.046843ms]
Feb 20 12:31:20.076: INFO: Created: latency-svc-2mdtb
Feb 20 12:31:20.117: INFO: Got endpoints: latency-svc-s2bhj [749.708956ms]
Feb 20 12:31:20.136: INFO: Created: latency-svc-jfjjv
Feb 20 12:31:20.170: INFO: Got endpoints: latency-svc-2rxmg [748.887786ms]
Feb 20 12:31:20.182: INFO: Created: latency-svc-rv5tv
Feb 20 12:31:20.220: INFO: Got endpoints: latency-svc-bvzqk [752.243973ms]
Feb 20 12:31:20.231: INFO: Created: latency-svc-gh4kh
Feb 20 12:31:20.266: INFO: Got endpoints: latency-svc-c5h78 [750.226048ms]
Feb 20 12:31:20.316: INFO: Got endpoints: latency-svc-rsj9q [749.217577ms]
Feb 20 12:31:20.366: INFO: Got endpoints: latency-svc-4ml7b [749.629159ms]
Feb 20 12:31:20.417: INFO: Got endpoints: latency-svc-k2xdl [750.202824ms]
Feb 20 12:31:20.466: INFO: Got endpoints: latency-svc-v68bv [750.199723ms]
Feb 20 12:31:20.517: INFO: Got endpoints: latency-svc-s6vxg [750.194751ms]
Feb 20 12:31:20.567: INFO: Got endpoints: latency-svc-dhcv5 [749.493746ms]
Feb 20 12:31:20.617: INFO: Got endpoints: latency-svc-f6q4r [746.363211ms]
Feb 20 12:31:20.666: INFO: Got endpoints: latency-svc-mgrqr [750.266103ms]
Feb 20 12:31:20.717: INFO: Got endpoints: latency-svc-lhfv8 [749.543726ms]
Feb 20 12:31:20.766: INFO: Got endpoints: latency-svc-lmfbg [746.593389ms]
Feb 20 12:31:20.816: INFO: Got endpoints: latency-svc-2mdtb [748.752396ms]
Feb 20 12:31:20.867: INFO: Got endpoints: latency-svc-jfjjv [749.922677ms]
Feb 20 12:31:20.917: INFO: Got endpoints: latency-svc-rv5tv [746.782178ms]
Feb 20 12:31:20.966: INFO: Got endpoints: latency-svc-gh4kh [745.057212ms]
Feb 20 12:31:20.966: INFO: Latencies: [20.545867ms 23.356603ms 37.241977ms 38.793055ms 41.082449ms 47.626648ms 54.68807ms 61.826617ms 73.875653ms 80.191975ms 86.588754ms 112.751117ms 116.259233ms 121.834178ms 121.949767ms 124.926446ms 125.568265ms 125.727979ms 126.20016ms 128.841137ms 128.870298ms 129.16496ms 129.647555ms 133.898796ms 134.253496ms 134.847526ms 135.579652ms 136.581516ms 136.590407ms 137.268819ms 138.137331ms 138.54785ms 139.128867ms 140.501201ms 149.064108ms 170.222674ms 207.622658ms 246.858943ms 283.091587ms 325.631188ms 363.197476ms 394.443605ms 441.988501ms 482.84151ms 520.854068ms 577.85314ms 604.339103ms 654.076011ms 669.522178ms 693.249086ms 699.211201ms 718.0825ms 719.984239ms 738.66174ms 739.64535ms 739.871053ms 742.493979ms 743.004291ms 743.434678ms 743.464572ms 743.532865ms 745.057212ms 745.280253ms 745.328878ms 746.039882ms 746.363211ms 746.486421ms 746.593389ms 746.782178ms 746.910426ms 747.073604ms 747.166347ms 747.205187ms 747.408342ms 747.652173ms 747.81329ms 747.848087ms 747.85949ms 747.877066ms 748.058971ms 748.11834ms 748.174435ms 748.209849ms 748.283089ms 748.330214ms 748.352591ms 748.410809ms 748.541011ms 748.54953ms 748.685155ms 748.752396ms 748.820411ms 748.887786ms 749.019422ms 749.123151ms 749.14464ms 749.1523ms 749.190651ms 749.214253ms 749.217577ms 749.251597ms 749.302936ms 749.372907ms 749.462687ms 749.490685ms 749.493746ms 749.53366ms 749.543726ms 749.559834ms 749.56832ms 749.589732ms 749.629159ms 749.658395ms 749.682681ms 749.708956ms 749.764874ms 749.770458ms 749.787579ms 749.793031ms 749.808561ms 749.832979ms 749.838987ms 749.842784ms 749.851046ms 749.866143ms 749.868412ms 749.903958ms 749.922677ms 749.92532ms 749.930162ms 749.976971ms 750.003735ms 750.008049ms 750.020233ms 750.034134ms 750.041685ms 750.046843ms 750.066904ms 750.074558ms 750.096734ms 750.108186ms 750.110593ms 750.152562ms 750.172913ms 750.194751ms 750.199723ms 750.200294ms 750.202824ms 750.213067ms 750.226048ms 750.266103ms 750.302958ms 750.336356ms 750.34938ms 750.371492ms 750.432414ms 750.467757ms 750.468332ms 750.560973ms 750.630042ms 750.696321ms 750.764222ms 750.80684ms 750.812532ms 750.823031ms 750.890638ms 750.907882ms 750.944193ms 750.963987ms 750.971129ms 751.003234ms 751.070621ms 751.195317ms 751.216771ms 751.245976ms 751.2646ms 751.28707ms 751.6587ms 751.724103ms 751.761851ms 751.799767ms 751.95774ms 752.160018ms 752.243973ms 752.534251ms 752.864171ms 753.100801ms 753.212957ms 754.154858ms 754.338398ms 754.430594ms 754.914626ms 755.02463ms 757.63186ms 758.209932ms 758.497091ms 779.559306ms 782.162892ms 798.529354ms 825.442112ms]
Feb 20 12:31:20.966: INFO: 50 %ile: 749.251597ms
Feb 20 12:31:20.966: INFO: 90 %ile: 751.799767ms
Feb 20 12:31:20.966: INFO: 99 %ile: 798.529354ms
Feb 20 12:31:20.966: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:31:20.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-47" for this suite.
Feb 20 12:31:30.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:31:31.109: INFO: namespace svc-latency-47 deletion completed in 10.136597152s

• [SLOW TEST:21.020 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:31:31.114: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8334
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:31:42.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8334" for this suite.
Feb 20 12:31:48.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:31:48.451: INFO: namespace resourcequota-8334 deletion completed in 6.111866234s

• [SLOW TEST:17.338 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:31:48.468: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-878
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 20 12:31:48.616: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cb4ab90b-6841-457a-a885-a5e3487497ca" in namespace "projected-878" to be "success or failure"
Feb 20 12:31:48.624: INFO: Pod "downwardapi-volume-cb4ab90b-6841-457a-a885-a5e3487497ca": Phase="Pending", Reason="", readiness=false. Elapsed: 7.619853ms
Feb 20 12:31:50.630: INFO: Pod "downwardapi-volume-cb4ab90b-6841-457a-a885-a5e3487497ca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0130323s
Feb 20 12:31:52.634: INFO: Pod "downwardapi-volume-cb4ab90b-6841-457a-a885-a5e3487497ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017387119s
STEP: Saw pod success
Feb 20 12:31:52.634: INFO: Pod "downwardapi-volume-cb4ab90b-6841-457a-a885-a5e3487497ca" satisfied condition "success or failure"
Feb 20 12:31:52.637: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod downwardapi-volume-cb4ab90b-6841-457a-a885-a5e3487497ca container client-container: <nil>
STEP: delete the pod
Feb 20 12:31:52.656: INFO: Waiting for pod downwardapi-volume-cb4ab90b-6841-457a-a885-a5e3487497ca to disappear
Feb 20 12:31:52.659: INFO: Pod downwardapi-volume-cb4ab90b-6841-457a-a885-a5e3487497ca no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:31:52.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-878" for this suite.
Feb 20 12:31:58.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:31:58.866: INFO: namespace projected-878 deletion completed in 6.202093493s

• [SLOW TEST:10.400 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:31:58.875: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-4881
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 20 12:32:02.058: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:32:02.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4881" for this suite.
Feb 20 12:32:08.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:32:08.219: INFO: namespace container-runtime-4881 deletion completed in 6.135312724s

• [SLOW TEST:9.345 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:32:08.220: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-765
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:32:21.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-765" for this suite.
Feb 20 12:32:27.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:32:27.560: INFO: namespace resourcequota-765 deletion completed in 6.100341011s

• [SLOW TEST:19.341 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:32:27.564: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7966
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Feb 20 12:32:27.720: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Feb 20 12:32:51.194: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
Feb 20 12:32:56.560: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:33:20.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7966" for this suite.
Feb 20 12:33:26.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:33:26.566: INFO: namespace crd-publish-openapi-7966 deletion completed in 6.118663986s

• [SLOW TEST:59.003 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:33:26.572: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3323
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 12:33:26.748: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:33:28.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3323" for this suite.
Feb 20 12:34:12.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:34:13.014: INFO: namespace pods-3323 deletion completed in 44.144458051s

• [SLOW TEST:46.443 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:34:13.032: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2938
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Feb 20 12:34:13.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-2938 -- logs-generator --log-lines-total 100 --run-duration 20s'
Feb 20 12:34:13.388: INFO: stderr: ""
Feb 20 12:34:13.388: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Feb 20 12:34:13.388: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Feb 20 12:34:13.389: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-2938" to be "running and ready, or succeeded"
Feb 20 12:34:13.393: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.327206ms
Feb 20 12:34:15.399: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010477824s
Feb 20 12:34:17.405: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.016337648s
Feb 20 12:34:17.405: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Feb 20 12:34:17.405: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Feb 20 12:34:17.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 logs logs-generator logs-generator --namespace=kubectl-2938'
Feb 20 12:34:17.581: INFO: stderr: ""
Feb 20 12:34:17.581: INFO: stdout: "I0220 12:34:15.140640       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/6m5 202\nI0220 12:34:15.341044       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/zrr 445\nI0220 12:34:15.540812       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/l59 482\nI0220 12:34:15.740808       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/bqz 360\nI0220 12:34:15.940813       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/s5rv 403\nI0220 12:34:16.140802       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/dlq 574\nI0220 12:34:16.340828       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/smh 252\nI0220 12:34:16.541035       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/7qn 369\nI0220 12:34:16.740804       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/h7fx 507\nI0220 12:34:16.940819       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/j699 271\nI0220 12:34:17.140958       1 logs_generator.go:76] 10 POST /api/v1/namespaces/ns/pods/hdzm 333\nI0220 12:34:17.340823       1 logs_generator.go:76] 11 POST /api/v1/namespaces/default/pods/mpb7 521\nI0220 12:34:17.540773       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/cxkl 353\n"
STEP: limiting log lines
Feb 20 12:34:17.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 logs logs-generator logs-generator --namespace=kubectl-2938 --tail=1'
Feb 20 12:34:17.724: INFO: stderr: ""
Feb 20 12:34:17.724: INFO: stdout: "I0220 12:34:17.540773       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/cxkl 353\n"
STEP: limiting log bytes
Feb 20 12:34:17.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 logs logs-generator logs-generator --namespace=kubectl-2938 --limit-bytes=1'
Feb 20 12:34:17.873: INFO: stderr: ""
Feb 20 12:34:17.873: INFO: stdout: "I"
STEP: exposing timestamps
Feb 20 12:34:17.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 logs logs-generator logs-generator --namespace=kubectl-2938 --tail=1 --timestamps'
Feb 20 12:34:18.036: INFO: stderr: ""
Feb 20 12:34:18.036: INFO: stdout: "2020-02-20T12:34:17.940979784Z I0220 12:34:17.940789       1 logs_generator.go:76] 14 GET /api/v1/namespaces/ns/pods/h89b 404\n"
STEP: restricting to a time range
Feb 20 12:34:20.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 logs logs-generator logs-generator --namespace=kubectl-2938 --since=1s'
Feb 20 12:34:20.720: INFO: stderr: ""
Feb 20 12:34:20.720: INFO: stdout: "I0220 12:34:19.740793       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/default/pods/tnh 203\nI0220 12:34:19.940799       1 logs_generator.go:76] 24 POST /api/v1/namespaces/ns/pods/kqmv 390\nI0220 12:34:20.140803       1 logs_generator.go:76] 25 POST /api/v1/namespaces/kube-system/pods/v9g 237\nI0220 12:34:20.340798       1 logs_generator.go:76] 26 PUT /api/v1/namespaces/ns/pods/xndl 537\nI0220 12:34:20.540880       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/kube-system/pods/q9lc 519\n"
Feb 20 12:34:20.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 logs logs-generator logs-generator --namespace=kubectl-2938 --since=24h'
Feb 20 12:34:20.904: INFO: stderr: ""
Feb 20 12:34:20.904: INFO: stdout: "I0220 12:34:15.140640       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/6m5 202\nI0220 12:34:15.341044       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/zrr 445\nI0220 12:34:15.540812       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/l59 482\nI0220 12:34:15.740808       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/bqz 360\nI0220 12:34:15.940813       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/s5rv 403\nI0220 12:34:16.140802       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/dlq 574\nI0220 12:34:16.340828       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/smh 252\nI0220 12:34:16.541035       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/7qn 369\nI0220 12:34:16.740804       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/h7fx 507\nI0220 12:34:16.940819       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/j699 271\nI0220 12:34:17.140958       1 logs_generator.go:76] 10 POST /api/v1/namespaces/ns/pods/hdzm 333\nI0220 12:34:17.340823       1 logs_generator.go:76] 11 POST /api/v1/namespaces/default/pods/mpb7 521\nI0220 12:34:17.540773       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/cxkl 353\nI0220 12:34:17.740782       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/default/pods/7z7x 262\nI0220 12:34:17.940789       1 logs_generator.go:76] 14 GET /api/v1/namespaces/ns/pods/h89b 404\nI0220 12:34:18.140880       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/wb8 259\nI0220 12:34:18.340775       1 logs_generator.go:76] 16 GET /api/v1/namespaces/kube-system/pods/76z 445\nI0220 12:34:18.540812       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/7kq9 285\nI0220 12:34:18.749758       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/sw99 578\nI0220 12:34:18.940797       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/t8x 345\nI0220 12:34:19.140794       1 logs_generator.go:76] 20 POST /api/v1/namespaces/default/pods/v8j 421\nI0220 12:34:19.340813       1 logs_generator.go:76] 21 POST /api/v1/namespaces/default/pods/sdg 537\nI0220 12:34:19.540916       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/default/pods/c2r 562\nI0220 12:34:19.740793       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/default/pods/tnh 203\nI0220 12:34:19.940799       1 logs_generator.go:76] 24 POST /api/v1/namespaces/ns/pods/kqmv 390\nI0220 12:34:20.140803       1 logs_generator.go:76] 25 POST /api/v1/namespaces/kube-system/pods/v9g 237\nI0220 12:34:20.340798       1 logs_generator.go:76] 26 PUT /api/v1/namespaces/ns/pods/xndl 537\nI0220 12:34:20.540880       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/kube-system/pods/q9lc 519\nI0220 12:34:20.740807       1 logs_generator.go:76] 28 GET /api/v1/namespaces/ns/pods/g2r 559\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Feb 20 12:34:20.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 delete pod logs-generator --namespace=kubectl-2938'
Feb 20 12:34:23.870: INFO: stderr: ""
Feb 20 12:34:23.870: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:34:23.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2938" for this suite.
Feb 20 12:34:29.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:34:29.996: INFO: namespace kubectl-2938 deletion completed in 6.118875227s

• [SLOW TEST:16.966 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:34:30.007: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-6472
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Feb 20 12:34:30.172: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
Feb 20 12:34:35.893: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:34:58.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6472" for this suite.
Feb 20 12:35:04.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:35:04.758: INFO: namespace crd-publish-openapi-6472 deletion completed in 6.115171871s

• [SLOW TEST:34.752 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:35:04.773: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1807
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 12:35:04.932: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Feb 20 12:35:10.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 --namespace=crd-publish-openapi-1807 create -f -'
Feb 20 12:35:11.146: INFO: stderr: ""
Feb 20 12:35:11.146: INFO: stdout: "e2e-test-crd-publish-openapi-5578-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Feb 20 12:35:11.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 --namespace=crd-publish-openapi-1807 delete e2e-test-crd-publish-openapi-5578-crds test-cr'
Feb 20 12:35:11.292: INFO: stderr: ""
Feb 20 12:35:11.292: INFO: stdout: "e2e-test-crd-publish-openapi-5578-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Feb 20 12:35:11.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 --namespace=crd-publish-openapi-1807 apply -f -'
Feb 20 12:35:11.610: INFO: stderr: ""
Feb 20 12:35:11.610: INFO: stdout: "e2e-test-crd-publish-openapi-5578-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Feb 20 12:35:11.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 --namespace=crd-publish-openapi-1807 delete e2e-test-crd-publish-openapi-5578-crds test-cr'
Feb 20 12:35:11.797: INFO: stderr: ""
Feb 20 12:35:11.797: INFO: stdout: "e2e-test-crd-publish-openapi-5578-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Feb 20 12:35:11.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 explain e2e-test-crd-publish-openapi-5578-crds'
Feb 20 12:35:12.109: INFO: stderr: ""
Feb 20 12:35:12.109: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5578-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:35:17.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1807" for this suite.
Feb 20 12:35:23.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:35:23.648: INFO: namespace crd-publish-openapi-1807 deletion completed in 6.16892294s

• [SLOW TEST:18.876 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:35:23.656: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6032
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 20 12:35:28.054: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 12:35:28.057: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 12:35:30.057: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 12:35:30.061: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 20 12:35:32.057: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 20 12:35:32.061: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:35:32.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6032" for this suite.
Feb 20 12:36:00.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:36:00.266: INFO: namespace container-lifecycle-hook-6032 deletion completed in 28.150285342s

• [SLOW TEST:36.610 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:36:00.271: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6604
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 20 12:36:02.481: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:36:02.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6604" for this suite.
Feb 20 12:36:08.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:36:08.616: INFO: namespace container-runtime-6604 deletion completed in 6.115595187s

• [SLOW TEST:8.346 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:36:08.624: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9601
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 12:36:08.790: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"e31b5768-a3e1-424f-84a5-4ff6a754945b", Controller:(*bool)(0xc0047abeba), BlockOwnerDeletion:(*bool)(0xc0047abebb)}}
Feb 20 12:36:08.793: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"6ebac0c0-f78c-4e06-9c49-46c150ba386e", Controller:(*bool)(0xc003a5c11a), BlockOwnerDeletion:(*bool)(0xc003a5c11b)}}
Feb 20 12:36:08.798: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b494468b-9965-45ef-bc0c-6f832f761030", Controller:(*bool)(0xc003a5c2aa), BlockOwnerDeletion:(*bool)(0xc003a5c2ab)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:36:13.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9601" for this suite.
Feb 20 12:36:19.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:36:19.915: INFO: namespace gc-9601 deletion completed in 6.100880095s

• [SLOW TEST:11.292 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:36:19.921: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5382
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-cf3cceaa-e473-4529-9621-a4c38264acba
STEP: Creating secret with name secret-projected-all-test-volume-350f94ed-522b-4070-b4e9-8c2d5c5bf398
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 20 12:36:20.093: INFO: Waiting up to 5m0s for pod "projected-volume-5a850de8-606d-4ae5-bf7c-b3a8cb313ed6" in namespace "projected-5382" to be "success or failure"
Feb 20 12:36:20.097: INFO: Pod "projected-volume-5a850de8-606d-4ae5-bf7c-b3a8cb313ed6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.018991ms
Feb 20 12:36:22.100: INFO: Pod "projected-volume-5a850de8-606d-4ae5-bf7c-b3a8cb313ed6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006656455s
Feb 20 12:36:24.105: INFO: Pod "projected-volume-5a850de8-606d-4ae5-bf7c-b3a8cb313ed6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01113072s
STEP: Saw pod success
Feb 20 12:36:24.105: INFO: Pod "projected-volume-5a850de8-606d-4ae5-bf7c-b3a8cb313ed6" satisfied condition "success or failure"
Feb 20 12:36:24.108: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod projected-volume-5a850de8-606d-4ae5-bf7c-b3a8cb313ed6 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 20 12:36:24.122: INFO: Waiting for pod projected-volume-5a850de8-606d-4ae5-bf7c-b3a8cb313ed6 to disappear
Feb 20 12:36:24.125: INFO: Pod projected-volume-5a850de8-606d-4ae5-bf7c-b3a8cb313ed6 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:36:24.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5382" for this suite.
Feb 20 12:36:30.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:36:30.242: INFO: namespace projected-5382 deletion completed in 6.112913738s

• [SLOW TEST:10.322 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:36:30.251: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4108
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 12:36:30.405: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb 20 12:36:35.411: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 20 12:36:35.411: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 20 12:36:37.416: INFO: Creating deployment "test-rollover-deployment"
Feb 20 12:36:37.424: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 20 12:36:39.440: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 20 12:36:39.445: INFO: Ensure that both replica sets have 1 created replica
Feb 20 12:36:39.450: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb 20 12:36:39.456: INFO: Updating deployment test-rollover-deployment
Feb 20 12:36:39.456: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 20 12:36:41.462: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 20 12:36:41.468: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 20 12:36:41.473: INFO: all replica sets need to contain the pod-template-hash label
Feb 20 12:36:41.473: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798999, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 12:36:43.487: INFO: all replica sets need to contain the pod-template-hash label
Feb 20 12:36:43.488: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798999, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 12:36:45.484: INFO: all replica sets need to contain the pod-template-hash label
Feb 20 12:36:45.485: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798999, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 12:36:47.481: INFO: all replica sets need to contain the pod-template-hash label
Feb 20 12:36:47.481: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717799005, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 12:36:49.482: INFO: all replica sets need to contain the pod-template-hash label
Feb 20 12:36:49.482: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717799005, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 12:36:51.483: INFO: all replica sets need to contain the pod-template-hash label
Feb 20 12:36:51.484: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717799005, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 12:36:53.482: INFO: all replica sets need to contain the pod-template-hash label
Feb 20 12:36:53.483: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717799005, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 12:36:55.482: INFO: all replica sets need to contain the pod-template-hash label
Feb 20 12:36:55.483: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717799005, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717798997, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 12:36:57.481: INFO: 
Feb 20 12:36:57.481: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb 20 12:36:57.488: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-4108 /apis/apps/v1/namespaces/deployment-4108/deployments/test-rollover-deployment 5cffabc3-49bb-42c5-932b-6979e056e83c 221539 2 2020-02-20 12:36:37 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003e26ef8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-02-20 12:36:37 +0000 UTC,LastTransitionTime:2020-02-20 12:36:37 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2020-02-20 12:36:55 +0000 UTC,LastTransitionTime:2020-02-20 12:36:37 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Feb 20 12:36:57.492: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-4108 /apis/apps/v1/namespaces/deployment-4108/replicasets/test-rollover-deployment-7d7dc6548c 7d2a5e9c-e969-48ee-a457-66afb07784b3 221529 2 2020-02-20 12:36:39 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 5cffabc3-49bb-42c5-932b-6979e056e83c 0xc003e274f7 0xc003e274f8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003e27558 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb 20 12:36:57.493: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 20 12:36:57.493: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-4108 /apis/apps/v1/namespaces/deployment-4108/replicasets/test-rollover-controller 98989a2d-17ce-4ca3-a4f7-801a3083144b 221538 2 2020-02-20 12:36:30 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 5cffabc3-49bb-42c5-932b-6979e056e83c 0xc003e27427 0xc003e27428}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003e27488 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 20 12:36:57.494: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-4108 /apis/apps/v1/namespaces/deployment-4108/replicasets/test-rollover-deployment-f6c94f66c f5cf2aad-93b9-41b7-a97e-f395543423e0 221469 2 2020-02-20 12:36:37 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 5cffabc3-49bb-42c5-932b-6979e056e83c 0xc003e275d0 0xc003e275d1}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003e27648 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 20 12:36:57.498: INFO: Pod "test-rollover-deployment-7d7dc6548c-mw5pv" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-mw5pv test-rollover-deployment-7d7dc6548c- deployment-4108 /api/v1/namespaces/deployment-4108/pods/test-rollover-deployment-7d7dc6548c-mw5pv 22ccd627-e620-4db7-8102-6075e67aed32 221499 0 2020-02-20 12:36:39 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c 7d2a5e9c-e969-48ee-a457-66afb07784b3 0xc003e27bd7 0xc003e27bd8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rmk7q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rmk7q,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rmk7q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 12:36:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 12:36:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 12:36:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 12:36:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.29,PodIP:10.100.99.154,StartTime:2020-02-20 12:36:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-20 12:36:45 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://9cb66682b89c783e9ae9c41b1f63e5fdf97e600f24307d6b1a726573fddb7816,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.99.154,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:36:57.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4108" for this suite.
Feb 20 12:37:03.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:37:03.606: INFO: namespace deployment-4108 deletion completed in 6.102007817s

• [SLOW TEST:33.357 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:37:03.611: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4147
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 12:37:03.755: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Feb 20 12:37:09.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 --namespace=crd-publish-openapi-4147 create -f -'
Feb 20 12:37:10.790: INFO: stderr: ""
Feb 20 12:37:10.790: INFO: stdout: "e2e-test-crd-publish-openapi-5749-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Feb 20 12:37:10.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 --namespace=crd-publish-openapi-4147 delete e2e-test-crd-publish-openapi-5749-crds test-cr'
Feb 20 12:37:10.917: INFO: stderr: ""
Feb 20 12:37:10.917: INFO: stdout: "e2e-test-crd-publish-openapi-5749-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Feb 20 12:37:10.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 --namespace=crd-publish-openapi-4147 apply -f -'
Feb 20 12:37:11.420: INFO: stderr: ""
Feb 20 12:37:11.420: INFO: stdout: "e2e-test-crd-publish-openapi-5749-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Feb 20 12:37:11.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 --namespace=crd-publish-openapi-4147 delete e2e-test-crd-publish-openapi-5749-crds test-cr'
Feb 20 12:37:11.561: INFO: stderr: ""
Feb 20 12:37:11.561: INFO: stdout: "e2e-test-crd-publish-openapi-5749-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Feb 20 12:37:11.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 explain e2e-test-crd-publish-openapi-5749-crds'
Feb 20 12:37:11.921: INFO: stderr: ""
Feb 20 12:37:11.921: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5749-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:37:17.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4147" for this suite.
Feb 20 12:37:23.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:37:23.730: INFO: namespace crd-publish-openapi-4147 deletion completed in 6.110954086s

• [SLOW TEST:20.120 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:37:23.741: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8954
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:37:34.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8954" for this suite.
Feb 20 12:37:40.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:37:41.059: INFO: namespace resourcequota-8954 deletion completed in 6.125726764s

• [SLOW TEST:17.319 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:37:41.067: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-6394
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb 20 12:37:43.239: INFO: &Pod{ObjectMeta:{send-events-f75d16b5-15b0-4e9a-a891-9af61e9ad4de  events-6394 /api/v1/namespaces/events-6394/pods/send-events-f75d16b5-15b0-4e9a-a891-9af61e9ad4de 1493efd9-4246-43c3-976d-c865a4532bdc 221779 0 2020-02-20 12:37:41 +0000 UTC <nil> <nil> map[name:foo time:218599756] map[] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fh6zn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fh6zn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fh6zn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 12:37:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 12:37:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 12:37:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 12:37:41 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.8,PodIP:10.100.81.144,StartTime:2020-02-20 12:37:41 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-20 12:37:42 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:docker://54c609b4f8cf5a78e62896f4068f4fbc08ef2de28a0d987234a3f3f5cb0fe705,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.81.144,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Feb 20 12:37:45.247: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb 20 12:37:47.251: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:37:47.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6394" for this suite.
Feb 20 12:38:31.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:38:31.380: INFO: namespace events-6394 deletion completed in 44.121010608s

• [SLOW TEST:50.313 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:38:31.383: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6961
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb 20 12:38:31.552: INFO: Pod name pod-release: Found 0 pods out of 1
Feb 20 12:38:36.556: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:38:37.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6961" for this suite.
Feb 20 12:38:43.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:38:43.687: INFO: namespace replication-controller-6961 deletion completed in 6.109541273s

• [SLOW TEST:12.305 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:38:43.691: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4516
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Feb 20 12:38:47.860: INFO: Pod pod-hostip-6dd0f811-a0c0-477a-acf8-c927ed5c344a has hostIP: 10.0.0.29
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:38:47.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4516" for this suite.
Feb 20 12:39:15.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:39:15.985: INFO: namespace pods-4516 deletion completed in 28.118091316s

• [SLOW TEST:32.295 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:39:16.020: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2338
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 12:39:16.225: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Feb 20 12:39:21.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 --namespace=crd-publish-openapi-2338 create -f -'
Feb 20 12:39:22.618: INFO: stderr: ""
Feb 20 12:39:22.618: INFO: stdout: "e2e-test-crd-publish-openapi-7104-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Feb 20 12:39:22.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 --namespace=crd-publish-openapi-2338 delete e2e-test-crd-publish-openapi-7104-crds test-cr'
Feb 20 12:39:22.765: INFO: stderr: ""
Feb 20 12:39:22.765: INFO: stdout: "e2e-test-crd-publish-openapi-7104-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Feb 20 12:39:22.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 --namespace=crd-publish-openapi-2338 apply -f -'
Feb 20 12:39:23.124: INFO: stderr: ""
Feb 20 12:39:23.124: INFO: stdout: "e2e-test-crd-publish-openapi-7104-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Feb 20 12:39:23.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 --namespace=crd-publish-openapi-2338 delete e2e-test-crd-publish-openapi-7104-crds test-cr'
Feb 20 12:39:23.269: INFO: stderr: ""
Feb 20 12:39:23.269: INFO: stdout: "e2e-test-crd-publish-openapi-7104-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Feb 20 12:39:23.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 explain e2e-test-crd-publish-openapi-7104-crds'
Feb 20 12:39:23.669: INFO: stderr: ""
Feb 20 12:39:23.669: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7104-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:39:26.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2338" for this suite.
Feb 20 12:39:32.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:39:32.918: INFO: namespace crd-publish-openapi-2338 deletion completed in 6.105149451s

• [SLOW TEST:16.899 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:39:32.926: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-339
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 20 12:39:33.087: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-339 /api/v1/namespaces/watch-339/configmaps/e2e-watch-test-configmap-a d98f6c4a-5e1f-4012-bca5-370320d5bdbf 222223 0 2020-02-20 12:39:33 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 20 12:39:33.088: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-339 /api/v1/namespaces/watch-339/configmaps/e2e-watch-test-configmap-a d98f6c4a-5e1f-4012-bca5-370320d5bdbf 222223 0 2020-02-20 12:39:33 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 20 12:39:43.100: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-339 /api/v1/namespaces/watch-339/configmaps/e2e-watch-test-configmap-a d98f6c4a-5e1f-4012-bca5-370320d5bdbf 222250 0 2020-02-20 12:39:33 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 20 12:39:43.101: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-339 /api/v1/namespaces/watch-339/configmaps/e2e-watch-test-configmap-a d98f6c4a-5e1f-4012-bca5-370320d5bdbf 222250 0 2020-02-20 12:39:33 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 20 12:39:53.110: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-339 /api/v1/namespaces/watch-339/configmaps/e2e-watch-test-configmap-a d98f6c4a-5e1f-4012-bca5-370320d5bdbf 222277 0 2020-02-20 12:39:33 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 20 12:39:53.112: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-339 /api/v1/namespaces/watch-339/configmaps/e2e-watch-test-configmap-a d98f6c4a-5e1f-4012-bca5-370320d5bdbf 222277 0 2020-02-20 12:39:33 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 20 12:40:03.121: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-339 /api/v1/namespaces/watch-339/configmaps/e2e-watch-test-configmap-a d98f6c4a-5e1f-4012-bca5-370320d5bdbf 222306 0 2020-02-20 12:39:33 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 20 12:40:03.122: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-339 /api/v1/namespaces/watch-339/configmaps/e2e-watch-test-configmap-a d98f6c4a-5e1f-4012-bca5-370320d5bdbf 222306 0 2020-02-20 12:39:33 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 20 12:40:13.135: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-339 /api/v1/namespaces/watch-339/configmaps/e2e-watch-test-configmap-b e8d1e0dd-405d-41e8-a906-3140572cd8c8 222336 0 2020-02-20 12:40:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 20 12:40:13.135: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-339 /api/v1/namespaces/watch-339/configmaps/e2e-watch-test-configmap-b e8d1e0dd-405d-41e8-a906-3140572cd8c8 222336 0 2020-02-20 12:40:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 20 12:40:23.146: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-339 /api/v1/namespaces/watch-339/configmaps/e2e-watch-test-configmap-b e8d1e0dd-405d-41e8-a906-3140572cd8c8 222363 0 2020-02-20 12:40:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 20 12:40:23.146: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-339 /api/v1/namespaces/watch-339/configmaps/e2e-watch-test-configmap-b e8d1e0dd-405d-41e8-a906-3140572cd8c8 222363 0 2020-02-20 12:40:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:40:33.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-339" for this suite.
Feb 20 12:40:39.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:40:39.263: INFO: namespace watch-339 deletion completed in 6.104243884s

• [SLOW TEST:66.338 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:40:39.265: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3444
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-3444.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-3444.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-3444.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-3444.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3444.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-3444.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-3444.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-3444.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-3444.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3444.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 20 12:41:03.450: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:03.455: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:03.459: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:03.463: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:03.478: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:03.482: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:03.486: INFO: Unable to read jessie_udp@dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:03.490: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:03.498: INFO: Lookups using dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local wheezy_udp@dns-test-service-2.dns-3444.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-3444.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local jessie_udp@dns-test-service-2.dns-3444.svc.cluster.local jessie_tcp@dns-test-service-2.dns-3444.svc.cluster.local]

Feb 20 12:41:08.506: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:08.511: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:08.517: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:08.521: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:08.541: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:08.548: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:08.551: INFO: Unable to read jessie_udp@dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:08.555: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:08.561: INFO: Lookups using dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local wheezy_udp@dns-test-service-2.dns-3444.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-3444.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local jessie_udp@dns-test-service-2.dns-3444.svc.cluster.local jessie_tcp@dns-test-service-2.dns-3444.svc.cluster.local]

Feb 20 12:41:13.515: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:13.528: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:13.535: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:13.544: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:13.556: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:13.560: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:13.564: INFO: Unable to read jessie_udp@dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:13.568: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-3444.svc.cluster.local from pod dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22: the server could not find the requested resource (get pods dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22)
Feb 20 12:41:13.575: INFO: Lookups using dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local wheezy_udp@dns-test-service-2.dns-3444.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-3444.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3444.svc.cluster.local jessie_udp@dns-test-service-2.dns-3444.svc.cluster.local jessie_tcp@dns-test-service-2.dns-3444.svc.cluster.local]

Feb 20 12:41:18.558: INFO: DNS probes using dns-3444/dns-test-740e42c5-a59c-4214-a0da-a5e47a372f22 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:41:18.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3444" for this suite.
Feb 20 12:41:24.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:41:24.728: INFO: namespace dns-3444 deletion completed in 6.125541494s

• [SLOW TEST:45.465 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:41:24.740: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8646
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 20 12:41:24.896: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a6bd027c-ca8e-4534-9ca4-b2dd37975129" in namespace "downward-api-8646" to be "success or failure"
Feb 20 12:41:24.903: INFO: Pod "downwardapi-volume-a6bd027c-ca8e-4534-9ca4-b2dd37975129": Phase="Pending", Reason="", readiness=false. Elapsed: 6.553493ms
Feb 20 12:41:26.917: INFO: Pod "downwardapi-volume-a6bd027c-ca8e-4534-9ca4-b2dd37975129": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020795386s
STEP: Saw pod success
Feb 20 12:41:26.919: INFO: Pod "downwardapi-volume-a6bd027c-ca8e-4534-9ca4-b2dd37975129" satisfied condition "success or failure"
Feb 20 12:41:26.928: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod downwardapi-volume-a6bd027c-ca8e-4534-9ca4-b2dd37975129 container client-container: <nil>
STEP: delete the pod
Feb 20 12:41:27.006: INFO: Waiting for pod downwardapi-volume-a6bd027c-ca8e-4534-9ca4-b2dd37975129 to disappear
Feb 20 12:41:27.009: INFO: Pod downwardapi-volume-a6bd027c-ca8e-4534-9ca4-b2dd37975129 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:41:27.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8646" for this suite.
Feb 20 12:41:33.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:41:33.123: INFO: namespace downward-api-8646 deletion completed in 6.107765076s

• [SLOW TEST:8.384 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:41:33.126: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3377
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-60600cdc-4946-417f-837a-2b7cdc038ed3
STEP: Creating a pod to test consume secrets
Feb 20 12:41:33.316: INFO: Waiting up to 5m0s for pod "pod-secrets-7963bf39-3251-4923-b65a-614ea46d5897" in namespace "secrets-3377" to be "success or failure"
Feb 20 12:41:33.320: INFO: Pod "pod-secrets-7963bf39-3251-4923-b65a-614ea46d5897": Phase="Pending", Reason="", readiness=false. Elapsed: 3.685571ms
Feb 20 12:41:35.323: INFO: Pod "pod-secrets-7963bf39-3251-4923-b65a-614ea46d5897": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007496537s
Feb 20 12:41:37.330: INFO: Pod "pod-secrets-7963bf39-3251-4923-b65a-614ea46d5897": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014275703s
STEP: Saw pod success
Feb 20 12:41:37.331: INFO: Pod "pod-secrets-7963bf39-3251-4923-b65a-614ea46d5897" satisfied condition "success or failure"
Feb 20 12:41:37.334: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-secrets-7963bf39-3251-4923-b65a-614ea46d5897 container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 12:41:37.358: INFO: Waiting for pod pod-secrets-7963bf39-3251-4923-b65a-614ea46d5897 to disappear
Feb 20 12:41:37.367: INFO: Pod pod-secrets-7963bf39-3251-4923-b65a-614ea46d5897 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:41:37.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3377" for this suite.
Feb 20 12:41:43.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:41:43.509: INFO: namespace secrets-3377 deletion completed in 6.136969117s

• [SLOW TEST:10.383 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:41:43.514: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-724
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb 20 12:41:48.201: INFO: Successfully updated pod "labelsupdateb271413e-733b-4adb-9c8d-29045f392f4f"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:41:50.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-724" for this suite.
Feb 20 12:42:04.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:42:04.353: INFO: namespace downward-api-724 deletion completed in 14.124761561s

• [SLOW TEST:20.839 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:42:04.355: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2252
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Feb 20 12:42:04.514: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-673477187 proxy --unix-socket=/tmp/kubectl-proxy-unix614360366/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:42:04.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2252" for this suite.
Feb 20 12:42:10.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:42:10.770: INFO: namespace kubectl-2252 deletion completed in 6.112510589s

• [SLOW TEST:6.416 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:42:10.776: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-8074
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Feb 20 12:42:15.469: INFO: Successfully updated pod "adopt-release-88l8t"
STEP: Checking that the Job readopts the Pod
Feb 20 12:42:15.469: INFO: Waiting up to 15m0s for pod "adopt-release-88l8t" in namespace "job-8074" to be "adopted"
Feb 20 12:42:15.475: INFO: Pod "adopt-release-88l8t": Phase="Running", Reason="", readiness=true. Elapsed: 5.731933ms
Feb 20 12:42:17.479: INFO: Pod "adopt-release-88l8t": Phase="Running", Reason="", readiness=true. Elapsed: 2.009752245s
Feb 20 12:42:17.479: INFO: Pod "adopt-release-88l8t" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Feb 20 12:42:17.987: INFO: Successfully updated pod "adopt-release-88l8t"
STEP: Checking that the Job releases the Pod
Feb 20 12:42:17.988: INFO: Waiting up to 15m0s for pod "adopt-release-88l8t" in namespace "job-8074" to be "released"
Feb 20 12:42:18.020: INFO: Pod "adopt-release-88l8t": Phase="Running", Reason="", readiness=true. Elapsed: 32.001687ms
Feb 20 12:42:18.021: INFO: Pod "adopt-release-88l8t" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:42:18.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8074" for this suite.
Feb 20 12:43:06.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:43:06.202: INFO: namespace job-8074 deletion completed in 48.165324432s

• [SLOW TEST:55.427 seconds]
[sig-apps] Job
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:43:06.213: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-4402
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Feb 20 12:43:06.380: INFO: Waiting up to 5m0s for pod "client-containers-e65e722b-c35d-4ba8-aaf1-7b6328cb1ad0" in namespace "containers-4402" to be "success or failure"
Feb 20 12:43:06.383: INFO: Pod "client-containers-e65e722b-c35d-4ba8-aaf1-7b6328cb1ad0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.118396ms
Feb 20 12:43:08.392: INFO: Pod "client-containers-e65e722b-c35d-4ba8-aaf1-7b6328cb1ad0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011488264s
Feb 20 12:43:10.399: INFO: Pod "client-containers-e65e722b-c35d-4ba8-aaf1-7b6328cb1ad0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018559145s
STEP: Saw pod success
Feb 20 12:43:10.399: INFO: Pod "client-containers-e65e722b-c35d-4ba8-aaf1-7b6328cb1ad0" satisfied condition "success or failure"
Feb 20 12:43:10.402: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod client-containers-e65e722b-c35d-4ba8-aaf1-7b6328cb1ad0 container test-container: <nil>
STEP: delete the pod
Feb 20 12:43:10.475: INFO: Waiting for pod client-containers-e65e722b-c35d-4ba8-aaf1-7b6328cb1ad0 to disappear
Feb 20 12:43:10.479: INFO: Pod client-containers-e65e722b-c35d-4ba8-aaf1-7b6328cb1ad0 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:43:10.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4402" for this suite.
Feb 20 12:43:16.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:43:16.621: INFO: namespace containers-4402 deletion completed in 6.135753862s

• [SLOW TEST:10.410 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:43:16.631: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2366
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 20 12:43:17.466: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 20 12:43:19.481: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717799397, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717799397, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717799397, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717799397, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 20 12:43:22.500: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:43:32.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2366" for this suite.
Feb 20 12:43:38.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:43:38.949: INFO: namespace webhook-2366 deletion completed in 6.28448662s
STEP: Destroying namespace "webhook-2366-markers" for this suite.
Feb 20 12:43:44.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:43:45.110: INFO: namespace webhook-2366-markers deletion completed in 6.160789998s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.492 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:43:45.135: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5259
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 12:43:45.314: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 20 12:43:45.330: INFO: Number of nodes with available pods: 0
Feb 20 12:43:45.330: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 20 12:43:45.354: INFO: Number of nodes with available pods: 0
Feb 20 12:43:45.354: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 12:43:46.359: INFO: Number of nodes with available pods: 0
Feb 20 12:43:46.360: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 12:43:47.360: INFO: Number of nodes with available pods: 1
Feb 20 12:43:47.360: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 20 12:43:47.380: INFO: Number of nodes with available pods: 1
Feb 20 12:43:47.380: INFO: Number of running nodes: 0, number of available pods: 1
Feb 20 12:43:48.384: INFO: Number of nodes with available pods: 0
Feb 20 12:43:48.384: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 20 12:43:48.395: INFO: Number of nodes with available pods: 0
Feb 20 12:43:48.396: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 12:43:49.401: INFO: Number of nodes with available pods: 0
Feb 20 12:43:49.402: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 12:43:50.400: INFO: Number of nodes with available pods: 0
Feb 20 12:43:50.400: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 12:43:51.400: INFO: Number of nodes with available pods: 0
Feb 20 12:43:51.400: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 12:43:52.400: INFO: Number of nodes with available pods: 0
Feb 20 12:43:52.400: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 12:43:53.399: INFO: Number of nodes with available pods: 0
Feb 20 12:43:53.399: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 12:43:54.400: INFO: Number of nodes with available pods: 0
Feb 20 12:43:54.400: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 12:43:55.402: INFO: Number of nodes with available pods: 0
Feb 20 12:43:55.403: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 12:43:56.400: INFO: Number of nodes with available pods: 1
Feb 20 12:43:56.400: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5259, will wait for the garbage collector to delete the pods
Feb 20 12:43:56.466: INFO: Deleting DaemonSet.extensions daemon-set took: 5.651136ms
Feb 20 12:43:57.367: INFO: Terminating DaemonSet.extensions daemon-set pods took: 900.900513ms
Feb 20 12:44:03.772: INFO: Number of nodes with available pods: 0
Feb 20 12:44:03.772: INFO: Number of running nodes: 0, number of available pods: 0
Feb 20 12:44:03.784: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5259/daemonsets","resourceVersion":"223424"},"items":null}

Feb 20 12:44:03.790: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5259/pods","resourceVersion":"223424"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:44:03.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5259" for this suite.
Feb 20 12:44:09.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:44:09.972: INFO: namespace daemonsets-5259 deletion completed in 6.15156651s

• [SLOW TEST:24.838 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:44:09.984: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5622
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-mmc7
STEP: Creating a pod to test atomic-volume-subpath
Feb 20 12:44:10.182: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-mmc7" in namespace "subpath-5622" to be "success or failure"
Feb 20 12:44:10.191: INFO: Pod "pod-subpath-test-secret-mmc7": Phase="Pending", Reason="", readiness=false. Elapsed: 9.101916ms
Feb 20 12:44:12.197: INFO: Pod "pod-subpath-test-secret-mmc7": Phase="Running", Reason="", readiness=true. Elapsed: 2.014576563s
Feb 20 12:44:14.201: INFO: Pod "pod-subpath-test-secret-mmc7": Phase="Running", Reason="", readiness=true. Elapsed: 4.019159719s
Feb 20 12:44:16.206: INFO: Pod "pod-subpath-test-secret-mmc7": Phase="Running", Reason="", readiness=true. Elapsed: 6.023701754s
Feb 20 12:44:18.212: INFO: Pod "pod-subpath-test-secret-mmc7": Phase="Running", Reason="", readiness=true. Elapsed: 8.029287803s
Feb 20 12:44:20.216: INFO: Pod "pod-subpath-test-secret-mmc7": Phase="Running", Reason="", readiness=true. Elapsed: 10.034210651s
Feb 20 12:44:22.222: INFO: Pod "pod-subpath-test-secret-mmc7": Phase="Running", Reason="", readiness=true. Elapsed: 12.039473024s
Feb 20 12:44:24.226: INFO: Pod "pod-subpath-test-secret-mmc7": Phase="Running", Reason="", readiness=true. Elapsed: 14.043371667s
Feb 20 12:44:26.233: INFO: Pod "pod-subpath-test-secret-mmc7": Phase="Running", Reason="", readiness=true. Elapsed: 16.050395024s
Feb 20 12:44:28.237: INFO: Pod "pod-subpath-test-secret-mmc7": Phase="Running", Reason="", readiness=true. Elapsed: 18.055179168s
Feb 20 12:44:30.242: INFO: Pod "pod-subpath-test-secret-mmc7": Phase="Running", Reason="", readiness=true. Elapsed: 20.059532504s
Feb 20 12:44:32.246: INFO: Pod "pod-subpath-test-secret-mmc7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.063915066s
STEP: Saw pod success
Feb 20 12:44:32.247: INFO: Pod "pod-subpath-test-secret-mmc7" satisfied condition "success or failure"
Feb 20 12:44:32.250: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-subpath-test-secret-mmc7 container test-container-subpath-secret-mmc7: <nil>
STEP: delete the pod
Feb 20 12:44:32.303: INFO: Waiting for pod pod-subpath-test-secret-mmc7 to disappear
Feb 20 12:44:32.306: INFO: Pod pod-subpath-test-secret-mmc7 no longer exists
STEP: Deleting pod pod-subpath-test-secret-mmc7
Feb 20 12:44:32.307: INFO: Deleting pod "pod-subpath-test-secret-mmc7" in namespace "subpath-5622"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:44:32.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5622" for this suite.
Feb 20 12:44:38.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:44:38.457: INFO: namespace subpath-5622 deletion completed in 6.137588174s

• [SLOW TEST:28.474 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:44:38.465: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3193
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-cz9g
STEP: Creating a pod to test atomic-volume-subpath
Feb 20 12:44:38.673: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-cz9g" in namespace "subpath-3193" to be "success or failure"
Feb 20 12:44:38.678: INFO: Pod "pod-subpath-test-downwardapi-cz9g": Phase="Pending", Reason="", readiness=false. Elapsed: 4.216643ms
Feb 20 12:44:40.683: INFO: Pod "pod-subpath-test-downwardapi-cz9g": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009014484s
Feb 20 12:44:42.689: INFO: Pod "pod-subpath-test-downwardapi-cz9g": Phase="Running", Reason="", readiness=true. Elapsed: 4.015230768s
Feb 20 12:44:44.694: INFO: Pod "pod-subpath-test-downwardapi-cz9g": Phase="Running", Reason="", readiness=true. Elapsed: 6.020652225s
Feb 20 12:44:46.699: INFO: Pod "pod-subpath-test-downwardapi-cz9g": Phase="Running", Reason="", readiness=true. Elapsed: 8.025454363s
Feb 20 12:44:48.778: INFO: Pod "pod-subpath-test-downwardapi-cz9g": Phase="Running", Reason="", readiness=true. Elapsed: 10.104404159s
Feb 20 12:44:50.782: INFO: Pod "pod-subpath-test-downwardapi-cz9g": Phase="Running", Reason="", readiness=true. Elapsed: 12.108532344s
Feb 20 12:44:52.786: INFO: Pod "pod-subpath-test-downwardapi-cz9g": Phase="Running", Reason="", readiness=true. Elapsed: 14.112434891s
Feb 20 12:44:54.790: INFO: Pod "pod-subpath-test-downwardapi-cz9g": Phase="Running", Reason="", readiness=true. Elapsed: 16.116742174s
Feb 20 12:44:56.796: INFO: Pod "pod-subpath-test-downwardapi-cz9g": Phase="Running", Reason="", readiness=true. Elapsed: 18.122091216s
Feb 20 12:44:58.799: INFO: Pod "pod-subpath-test-downwardapi-cz9g": Phase="Running", Reason="", readiness=true. Elapsed: 20.125531851s
Feb 20 12:45:00.803: INFO: Pod "pod-subpath-test-downwardapi-cz9g": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.129643406s
STEP: Saw pod success
Feb 20 12:45:00.803: INFO: Pod "pod-subpath-test-downwardapi-cz9g" satisfied condition "success or failure"
Feb 20 12:45:00.810: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-subpath-test-downwardapi-cz9g container test-container-subpath-downwardapi-cz9g: <nil>
STEP: delete the pod
Feb 20 12:45:00.834: INFO: Waiting for pod pod-subpath-test-downwardapi-cz9g to disappear
Feb 20 12:45:00.838: INFO: Pod pod-subpath-test-downwardapi-cz9g no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-cz9g
Feb 20 12:45:00.838: INFO: Deleting pod "pod-subpath-test-downwardapi-cz9g" in namespace "subpath-3193"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:45:00.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3193" for this suite.
Feb 20 12:45:06.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:45:06.984: INFO: namespace subpath-3193 deletion completed in 6.135125672s

• [SLOW TEST:28.521 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:45:06.994: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7798
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-7798/secret-test-cbf24cb3-4557-48bb-8a81-2b6b9c388256
STEP: Creating a pod to test consume secrets
Feb 20 12:45:07.176: INFO: Waiting up to 5m0s for pod "pod-configmaps-72bcd843-d8cd-46f4-b812-a6cede46c72d" in namespace "secrets-7798" to be "success or failure"
Feb 20 12:45:07.180: INFO: Pod "pod-configmaps-72bcd843-d8cd-46f4-b812-a6cede46c72d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.798454ms
Feb 20 12:45:09.186: INFO: Pod "pod-configmaps-72bcd843-d8cd-46f4-b812-a6cede46c72d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009939906s
STEP: Saw pod success
Feb 20 12:45:09.186: INFO: Pod "pod-configmaps-72bcd843-d8cd-46f4-b812-a6cede46c72d" satisfied condition "success or failure"
Feb 20 12:45:09.188: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-configmaps-72bcd843-d8cd-46f4-b812-a6cede46c72d container env-test: <nil>
STEP: delete the pod
Feb 20 12:45:09.205: INFO: Waiting for pod pod-configmaps-72bcd843-d8cd-46f4-b812-a6cede46c72d to disappear
Feb 20 12:45:09.208: INFO: Pod pod-configmaps-72bcd843-d8cd-46f4-b812-a6cede46c72d no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:45:09.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7798" for this suite.
Feb 20 12:45:15.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:45:15.340: INFO: namespace secrets-7798 deletion completed in 6.124450887s

• [SLOW TEST:8.347 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:45:15.347: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8276
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-5bf3980b-b2ee-4db0-91f3-dee560f95336
STEP: Creating configMap with name cm-test-opt-upd-ff5560cc-347e-41fd-805f-9f1ece61d297
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-5bf3980b-b2ee-4db0-91f3-dee560f95336
STEP: Updating configmap cm-test-opt-upd-ff5560cc-347e-41fd-805f-9f1ece61d297
STEP: Creating configMap with name cm-test-opt-create-565a0129-6005-477f-9417-248bd090ff1c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:46:32.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8276" for this suite.
Feb 20 12:47:00.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:47:00.294: INFO: namespace configmap-8276 deletion completed in 28.14241518s

• [SLOW TEST:104.948 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:47:00.310: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5840
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:47:00.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5840" for this suite.
Feb 20 12:47:12.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:47:12.621: INFO: namespace pods-5840 deletion completed in 12.135678585s

• [SLOW TEST:12.312 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:47:12.628: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-342
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:47:16.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-342" for this suite.
Feb 20 12:48:06.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:48:06.989: INFO: namespace kubelet-test-342 deletion completed in 50.135549902s

• [SLOW TEST:54.363 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:48:06.998: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3154
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 20 12:48:07.154: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3dc4b606-aa45-4ba3-996e-9959958a7385" in namespace "projected-3154" to be "success or failure"
Feb 20 12:48:07.158: INFO: Pod "downwardapi-volume-3dc4b606-aa45-4ba3-996e-9959958a7385": Phase="Pending", Reason="", readiness=false. Elapsed: 3.351097ms
Feb 20 12:48:09.162: INFO: Pod "downwardapi-volume-3dc4b606-aa45-4ba3-996e-9959958a7385": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007284269s
STEP: Saw pod success
Feb 20 12:48:09.162: INFO: Pod "downwardapi-volume-3dc4b606-aa45-4ba3-996e-9959958a7385" satisfied condition "success or failure"
Feb 20 12:48:09.166: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod downwardapi-volume-3dc4b606-aa45-4ba3-996e-9959958a7385 container client-container: <nil>
STEP: delete the pod
Feb 20 12:48:09.185: INFO: Waiting for pod downwardapi-volume-3dc4b606-aa45-4ba3-996e-9959958a7385 to disappear
Feb 20 12:48:09.188: INFO: Pod downwardapi-volume-3dc4b606-aa45-4ba3-996e-9959958a7385 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:48:09.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3154" for this suite.
Feb 20 12:48:15.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:48:15.296: INFO: namespace projected-3154 deletion completed in 6.10227454s

• [SLOW TEST:8.299 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:48:15.309: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1132
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Feb 20 12:48:15.474: INFO: Waiting up to 5m0s for pod "client-containers-f850cb15-3315-478b-be6f-615c02822a92" in namespace "containers-1132" to be "success or failure"
Feb 20 12:48:15.480: INFO: Pod "client-containers-f850cb15-3315-478b-be6f-615c02822a92": Phase="Pending", Reason="", readiness=false. Elapsed: 5.43657ms
Feb 20 12:48:17.484: INFO: Pod "client-containers-f850cb15-3315-478b-be6f-615c02822a92": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009241439s
STEP: Saw pod success
Feb 20 12:48:17.484: INFO: Pod "client-containers-f850cb15-3315-478b-be6f-615c02822a92" satisfied condition "success or failure"
Feb 20 12:48:17.487: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod client-containers-f850cb15-3315-478b-be6f-615c02822a92 container test-container: <nil>
STEP: delete the pod
Feb 20 12:48:17.507: INFO: Waiting for pod client-containers-f850cb15-3315-478b-be6f-615c02822a92 to disappear
Feb 20 12:48:17.513: INFO: Pod client-containers-f850cb15-3315-478b-be6f-615c02822a92 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:48:17.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1132" for this suite.
Feb 20 12:48:23.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:48:23.635: INFO: namespace containers-1132 deletion completed in 6.115666759s

• [SLOW TEST:8.326 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:48:23.639: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1331
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 20 12:48:23.796: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0092df74-ed5c-4b46-a6e9-27bd218a0f00" in namespace "downward-api-1331" to be "success or failure"
Feb 20 12:48:23.801: INFO: Pod "downwardapi-volume-0092df74-ed5c-4b46-a6e9-27bd218a0f00": Phase="Pending", Reason="", readiness=false. Elapsed: 4.643292ms
Feb 20 12:48:25.807: INFO: Pod "downwardapi-volume-0092df74-ed5c-4b46-a6e9-27bd218a0f00": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010040254s
STEP: Saw pod success
Feb 20 12:48:25.807: INFO: Pod "downwardapi-volume-0092df74-ed5c-4b46-a6e9-27bd218a0f00" satisfied condition "success or failure"
Feb 20 12:48:25.810: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod downwardapi-volume-0092df74-ed5c-4b46-a6e9-27bd218a0f00 container client-container: <nil>
STEP: delete the pod
Feb 20 12:48:25.829: INFO: Waiting for pod downwardapi-volume-0092df74-ed5c-4b46-a6e9-27bd218a0f00 to disappear
Feb 20 12:48:25.831: INFO: Pod downwardapi-volume-0092df74-ed5c-4b46-a6e9-27bd218a0f00 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:48:25.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1331" for this suite.
Feb 20 12:48:31.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:48:31.951: INFO: namespace downward-api-1331 deletion completed in 6.114485075s

• [SLOW TEST:8.313 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:48:31.964: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-1276
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Feb 20 12:48:32.936: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Feb 20 12:48:34.947: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717799712, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717799712, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717799712, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717799712, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 20 12:48:37.973: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 12:48:37.977: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:48:39.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-1276" for this suite.
Feb 20 12:48:45.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:48:45.474: INFO: namespace crd-webhook-1276 deletion completed in 6.178342486s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:13.525 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:48:45.490: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1602
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-20396f27-11aa-44e0-b148-88a7c5abb943
STEP: Creating a pod to test consume configMaps
Feb 20 12:48:45.647: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-86bd2ff6-86e9-41b3-b2ac-d57b3aa6e4e3" in namespace "projected-1602" to be "success or failure"
Feb 20 12:48:45.652: INFO: Pod "pod-projected-configmaps-86bd2ff6-86e9-41b3-b2ac-d57b3aa6e4e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.949428ms
Feb 20 12:48:47.657: INFO: Pod "pod-projected-configmaps-86bd2ff6-86e9-41b3-b2ac-d57b3aa6e4e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008951177s
Feb 20 12:48:49.661: INFO: Pod "pod-projected-configmaps-86bd2ff6-86e9-41b3-b2ac-d57b3aa6e4e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012655722s
STEP: Saw pod success
Feb 20 12:48:49.661: INFO: Pod "pod-projected-configmaps-86bd2ff6-86e9-41b3-b2ac-d57b3aa6e4e3" satisfied condition "success or failure"
Feb 20 12:48:49.664: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod pod-projected-configmaps-86bd2ff6-86e9-41b3-b2ac-d57b3aa6e4e3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 12:48:49.716: INFO: Waiting for pod pod-projected-configmaps-86bd2ff6-86e9-41b3-b2ac-d57b3aa6e4e3 to disappear
Feb 20 12:48:49.722: INFO: Pod pod-projected-configmaps-86bd2ff6-86e9-41b3-b2ac-d57b3aa6e4e3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:48:49.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1602" for this suite.
Feb 20 12:48:55.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:48:55.837: INFO: namespace projected-1602 deletion completed in 6.109772085s

• [SLOW TEST:10.348 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:48:55.856: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5852
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 20 12:48:56.020: INFO: Waiting up to 5m0s for pod "downwardapi-volume-281a68fe-138f-4540-98f7-c9a8768d8373" in namespace "projected-5852" to be "success or failure"
Feb 20 12:48:56.024: INFO: Pod "downwardapi-volume-281a68fe-138f-4540-98f7-c9a8768d8373": Phase="Pending", Reason="", readiness=false. Elapsed: 3.289388ms
Feb 20 12:48:58.028: INFO: Pod "downwardapi-volume-281a68fe-138f-4540-98f7-c9a8768d8373": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007523806s
STEP: Saw pod success
Feb 20 12:48:58.029: INFO: Pod "downwardapi-volume-281a68fe-138f-4540-98f7-c9a8768d8373" satisfied condition "success or failure"
Feb 20 12:48:58.032: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod downwardapi-volume-281a68fe-138f-4540-98f7-c9a8768d8373 container client-container: <nil>
STEP: delete the pod
Feb 20 12:48:58.052: INFO: Waiting for pod downwardapi-volume-281a68fe-138f-4540-98f7-c9a8768d8373 to disappear
Feb 20 12:48:58.054: INFO: Pod downwardapi-volume-281a68fe-138f-4540-98f7-c9a8768d8373 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:48:58.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5852" for this suite.
Feb 20 12:49:04.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:49:04.174: INFO: namespace projected-5852 deletion completed in 6.115733573s

• [SLOW TEST:8.319 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:49:04.182: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-776
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0220 12:49:44.391442      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 20 12:49:44.393: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:49:44.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-776" for this suite.
Feb 20 12:49:50.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:49:50.559: INFO: namespace gc-776 deletion completed in 6.158271795s

• [SLOW TEST:46.377 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:49:50.574: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6727
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 20 12:49:50.790: INFO: Waiting up to 5m0s for pod "downwardapi-volume-60cbbaa6-f3d5-49dd-a4a1-e72ed948cffd" in namespace "projected-6727" to be "success or failure"
Feb 20 12:49:50.796: INFO: Pod "downwardapi-volume-60cbbaa6-f3d5-49dd-a4a1-e72ed948cffd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.541505ms
Feb 20 12:49:52.803: INFO: Pod "downwardapi-volume-60cbbaa6-f3d5-49dd-a4a1-e72ed948cffd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012406657s
Feb 20 12:49:54.810: INFO: Pod "downwardapi-volume-60cbbaa6-f3d5-49dd-a4a1-e72ed948cffd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019611522s
STEP: Saw pod success
Feb 20 12:49:54.811: INFO: Pod "downwardapi-volume-60cbbaa6-f3d5-49dd-a4a1-e72ed948cffd" satisfied condition "success or failure"
Feb 20 12:49:54.815: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod downwardapi-volume-60cbbaa6-f3d5-49dd-a4a1-e72ed948cffd container client-container: <nil>
STEP: delete the pod
Feb 20 12:49:54.831: INFO: Waiting for pod downwardapi-volume-60cbbaa6-f3d5-49dd-a4a1-e72ed948cffd to disappear
Feb 20 12:49:54.833: INFO: Pod downwardapi-volume-60cbbaa6-f3d5-49dd-a4a1-e72ed948cffd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:49:54.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6727" for this suite.
Feb 20 12:50:00.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:50:00.953: INFO: namespace projected-6727 deletion completed in 6.114339911s

• [SLOW TEST:10.380 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:50:00.961: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9521
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Feb 20 12:50:01.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 create -f - --namespace=kubectl-9521'
Feb 20 12:50:02.315: INFO: stderr: ""
Feb 20 12:50:02.315: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 20 12:50:03.322: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 12:50:03.322: INFO: Found 0 / 1
Feb 20 12:50:04.320: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 12:50:04.320: INFO: Found 0 / 1
Feb 20 12:50:05.319: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 12:50:05.319: INFO: Found 0 / 1
Feb 20 12:50:06.320: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 12:50:06.320: INFO: Found 0 / 1
Feb 20 12:50:07.320: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 12:50:07.321: INFO: Found 0 / 1
Feb 20 12:50:08.321: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 12:50:08.322: INFO: Found 0 / 1
Feb 20 12:50:09.320: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 12:50:09.321: INFO: Found 0 / 1
Feb 20 12:50:10.319: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 12:50:10.319: INFO: Found 0 / 1
Feb 20 12:50:11.319: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 12:50:11.319: INFO: Found 1 / 1
Feb 20 12:50:11.320: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 20 12:50:11.324: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 12:50:11.324: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 20 12:50:11.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 patch pod redis-master-zzq86 --namespace=kubectl-9521 -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 20 12:50:11.549: INFO: stderr: ""
Feb 20 12:50:11.549: INFO: stdout: "pod/redis-master-zzq86 patched\n"
STEP: checking annotations
Feb 20 12:50:11.553: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 12:50:11.553: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:50:11.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9521" for this suite.
Feb 20 12:50:23.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:50:23.726: INFO: namespace kubectl-9521 deletion completed in 12.167615207s

• [SLOW TEST:22.766 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:50:23.738: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-9121
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb 20 12:50:23.902: INFO: PodSpec: initContainers in spec.initContainers
Feb 20 12:51:11.010: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-1f9e48b9-2d25-40bb-8371-cbe10a52fb31", GenerateName:"", Namespace:"init-container-9121", SelfLink:"/api/v1/namespaces/init-container-9121/pods/pod-init-1f9e48b9-2d25-40bb-8371-cbe10a52fb31", UID:"9bada9aa-a1a4-4f1c-95aa-60b15a94e74b", ResourceVersion:"225456", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63717799823, loc:(*time.Location)(0x84bfb00)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"902115255"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-dgx8x", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002a8fa40), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-dgx8x", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-dgx8x", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-dgx8x", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001fc0158), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"kube16prod-img-kube16prod-img-minion-2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001b74a80), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration(nil), HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001fc02d0), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717799823, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717799823, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717799823, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717799823, loc:(*time.Location)(0x84bfb00)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.0.8", PodIP:"10.100.81.158", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.100.81.158"}}, StartTime:(*v1.Time)(0xc0037cdf60), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0006fbc70)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0006fbd50)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://bd342da7e1c836c577343ba81b9f7e8e42c4dd523fa92bb4ba59d060d2d14f91", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0037cdfa0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0037cdf80), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc001fc037c)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:51:11.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9121" for this suite.
Feb 20 12:51:39.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:51:39.159: INFO: namespace init-container-9121 deletion completed in 28.120914789s

• [SLOW TEST:75.422 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:51:39.172: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3594
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Feb 20 12:51:39.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 create -f - --namespace=kubectl-3594'
Feb 20 12:51:39.872: INFO: stderr: ""
Feb 20 12:51:39.872: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 20 12:51:39.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3594'
Feb 20 12:51:40.079: INFO: stderr: ""
Feb 20 12:51:40.079: INFO: stdout: "update-demo-nautilus-dd7db update-demo-nautilus-vljbn "
Feb 20 12:51:40.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-nautilus-dd7db -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3594'
Feb 20 12:51:40.357: INFO: stderr: ""
Feb 20 12:51:40.357: INFO: stdout: ""
Feb 20 12:51:40.357: INFO: update-demo-nautilus-dd7db is created but not running
Feb 20 12:51:45.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3594'
Feb 20 12:51:45.678: INFO: stderr: ""
Feb 20 12:51:45.678: INFO: stdout: "update-demo-nautilus-dd7db update-demo-nautilus-vljbn "
Feb 20 12:51:45.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-nautilus-dd7db -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3594'
Feb 20 12:51:45.812: INFO: stderr: ""
Feb 20 12:51:45.812: INFO: stdout: "true"
Feb 20 12:51:45.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-nautilus-dd7db -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3594'
Feb 20 12:51:45.958: INFO: stderr: ""
Feb 20 12:51:45.958: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 12:51:45.958: INFO: validating pod update-demo-nautilus-dd7db
Feb 20 12:51:45.968: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 12:51:45.969: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 12:51:45.969: INFO: update-demo-nautilus-dd7db is verified up and running
Feb 20 12:51:45.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-nautilus-vljbn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3594'
Feb 20 12:51:46.102: INFO: stderr: ""
Feb 20 12:51:46.102: INFO: stdout: "true"
Feb 20 12:51:46.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-nautilus-vljbn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3594'
Feb 20 12:51:46.231: INFO: stderr: ""
Feb 20 12:51:46.231: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 12:51:46.231: INFO: validating pod update-demo-nautilus-vljbn
Feb 20 12:51:46.237: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 12:51:46.237: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 12:51:46.237: INFO: update-demo-nautilus-vljbn is verified up and running
STEP: rolling-update to new replication controller
Feb 20 12:51:46.242: INFO: scanned /root for discovery docs: <nil>
Feb 20 12:51:46.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-3594'
Feb 20 12:52:09.165: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 20 12:52:09.165: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 20 12:52:09.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3594'
Feb 20 12:52:09.414: INFO: stderr: ""
Feb 20 12:52:09.414: INFO: stdout: "update-demo-kitten-bj49x update-demo-kitten-sm77v "
Feb 20 12:52:09.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-kitten-bj49x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3594'
Feb 20 12:52:09.607: INFO: stderr: ""
Feb 20 12:52:09.607: INFO: stdout: "true"
Feb 20 12:52:09.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-kitten-bj49x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3594'
Feb 20 12:52:09.742: INFO: stderr: ""
Feb 20 12:52:09.742: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 20 12:52:09.742: INFO: validating pod update-demo-kitten-bj49x
Feb 20 12:52:09.749: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 20 12:52:09.749: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 20 12:52:09.750: INFO: update-demo-kitten-bj49x is verified up and running
Feb 20 12:52:09.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-kitten-sm77v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3594'
Feb 20 12:52:09.938: INFO: stderr: ""
Feb 20 12:52:09.938: INFO: stdout: "true"
Feb 20 12:52:09.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-kitten-sm77v -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3594'
Feb 20 12:52:10.115: INFO: stderr: ""
Feb 20 12:52:10.115: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 20 12:52:10.115: INFO: validating pod update-demo-kitten-sm77v
Feb 20 12:52:10.126: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 20 12:52:10.126: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 20 12:52:10.126: INFO: update-demo-kitten-sm77v is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:52:10.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3594" for this suite.
Feb 20 12:52:38.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:52:38.275: INFO: namespace kubectl-3594 deletion completed in 28.139752728s

• [SLOW TEST:59.105 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:52:38.281: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-2804
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 12:52:38.436: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-c8e891b9-55e9-4b1e-89e6-ad27b7214026" in namespace "security-context-test-2804" to be "success or failure"
Feb 20 12:52:38.444: INFO: Pod "busybox-readonly-false-c8e891b9-55e9-4b1e-89e6-ad27b7214026": Phase="Pending", Reason="", readiness=false. Elapsed: 7.395069ms
Feb 20 12:52:40.449: INFO: Pod "busybox-readonly-false-c8e891b9-55e9-4b1e-89e6-ad27b7214026": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013071564s
Feb 20 12:52:40.450: INFO: Pod "busybox-readonly-false-c8e891b9-55e9-4b1e-89e6-ad27b7214026" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:52:40.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2804" for this suite.
Feb 20 12:52:46.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:52:46.573: INFO: namespace security-context-test-2804 deletion completed in 6.116918094s

• [SLOW TEST:8.292 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:52:46.580: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8696
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-8696
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-8696
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8696
Feb 20 12:52:46.797: INFO: Found 0 stateful pods, waiting for 1
Feb 20 12:52:56.804: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 20 12:52:56.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 20 12:52:57.115: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 20 12:52:57.115: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 20 12:52:57.115: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 20 12:52:57.120: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 20 12:53:07.125: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 12:53:07.125: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 12:53:07.221: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Feb 20 12:53:07.222: INFO: ss-0  kube16prod-img-kube16prod-img-minion-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:46 +0000 UTC  }]
Feb 20 12:53:07.222: INFO: 
Feb 20 12:53:07.223: INFO: StatefulSet ss has not reached scale 3, at 1
Feb 20 12:53:08.230: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.91153923s
Feb 20 12:53:09.236: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.904399441s
Feb 20 12:53:10.241: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.898200604s
Feb 20 12:53:11.247: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.893634059s
Feb 20 12:53:12.254: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.887485177s
Feb 20 12:53:13.261: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.880148965s
Feb 20 12:53:14.265: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.873607266s
Feb 20 12:53:15.273: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.8690123s
Feb 20 12:53:16.280: INFO: Verifying statefulset ss doesn't scale past 3 for another 860.668312ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8696
Feb 20 12:53:17.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:53:17.940: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 20 12:53:17.940: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 20 12:53:17.940: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 20 12:53:17.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:53:18.427: INFO: rc: 1
Feb 20 12:53:18.428: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  error: unable to upgrade connection: container not found ("webserver")
 [] <nil> 0xc0037a8450 exit status 1 <nil> <nil> true [0xc00364a520 0xc00364a540 0xc00364a558] [0xc00364a520 0xc00364a540 0xc00364a558] [0xc00364a538 0xc00364a550] [0x10efe30 0x10efe30] 0xc002d09980 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Feb 20 12:53:28.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:53:28.951: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb 20 12:53:28.951: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 20 12:53:28.951: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 20 12:53:28.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:53:29.303: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb 20 12:53:29.303: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 20 12:53:29.303: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 20 12:53:29.315: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 12:53:29.315: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 12:53:29.316: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 20 12:53:29.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 20 12:53:29.651: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 20 12:53:29.652: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 20 12:53:29.652: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 20 12:53:29.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 20 12:53:30.019: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 20 12:53:30.019: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 20 12:53:30.019: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 20 12:53:30.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 20 12:53:30.343: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 20 12:53:30.343: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 20 12:53:30.343: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 20 12:53:30.343: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 12:53:30.349: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb 20 12:53:40.367: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 12:53:40.368: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 12:53:40.368: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 12:53:40.382: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Feb 20 12:53:40.382: INFO: ss-0  kube16prod-img-kube16prod-img-minion-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:46 +0000 UTC  }]
Feb 20 12:53:40.382: INFO: ss-1  kube16prod-img-kube16prod-img-minion-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  }]
Feb 20 12:53:40.382: INFO: ss-2  kube16prod-img-kube16prod-img-minion-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  }]
Feb 20 12:53:40.383: INFO: 
Feb 20 12:53:40.383: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 20 12:53:41.390: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Feb 20 12:53:41.390: INFO: ss-0  kube16prod-img-kube16prod-img-minion-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:46 +0000 UTC  }]
Feb 20 12:53:41.390: INFO: ss-1  kube16prod-img-kube16prod-img-minion-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  }]
Feb 20 12:53:41.390: INFO: ss-2  kube16prod-img-kube16prod-img-minion-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  }]
Feb 20 12:53:41.390: INFO: 
Feb 20 12:53:41.390: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 20 12:53:42.396: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Feb 20 12:53:42.396: INFO: ss-0  kube16prod-img-kube16prod-img-minion-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:46 +0000 UTC  }]
Feb 20 12:53:42.396: INFO: ss-1  kube16prod-img-kube16prod-img-minion-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  }]
Feb 20 12:53:42.396: INFO: ss-2  kube16prod-img-kube16prod-img-minion-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  }]
Feb 20 12:53:42.396: INFO: 
Feb 20 12:53:42.396: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 20 12:53:43.401: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Feb 20 12:53:43.401: INFO: ss-0  kube16prod-img-kube16prod-img-minion-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:46 +0000 UTC  }]
Feb 20 12:53:43.401: INFO: ss-1  kube16prod-img-kube16prod-img-minion-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  }]
Feb 20 12:53:43.401: INFO: ss-2  kube16prod-img-kube16prod-img-minion-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  }]
Feb 20 12:53:43.402: INFO: 
Feb 20 12:53:43.402: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 20 12:53:44.406: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Feb 20 12:53:44.407: INFO: ss-0  kube16prod-img-kube16prod-img-minion-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:46 +0000 UTC  }]
Feb 20 12:53:44.407: INFO: ss-1  kube16prod-img-kube16prod-img-minion-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  }]
Feb 20 12:53:44.408: INFO: ss-2  kube16prod-img-kube16prod-img-minion-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  }]
Feb 20 12:53:44.408: INFO: 
Feb 20 12:53:44.409: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 20 12:53:45.423: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Feb 20 12:53:45.423: INFO: ss-0  kube16prod-img-kube16prod-img-minion-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:46 +0000 UTC  }]
Feb 20 12:53:45.423: INFO: ss-1  kube16prod-img-kube16prod-img-minion-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  }]
Feb 20 12:53:45.423: INFO: ss-2  kube16prod-img-kube16prod-img-minion-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  }]
Feb 20 12:53:45.423: INFO: 
Feb 20 12:53:45.423: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 20 12:53:46.428: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Feb 20 12:53:46.428: INFO: ss-0  kube16prod-img-kube16prod-img-minion-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:46 +0000 UTC  }]
Feb 20 12:53:46.429: INFO: ss-1  kube16prod-img-kube16prod-img-minion-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  }]
Feb 20 12:53:46.429: INFO: ss-2  kube16prod-img-kube16prod-img-minion-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  }]
Feb 20 12:53:46.429: INFO: 
Feb 20 12:53:46.429: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 20 12:53:47.434: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Feb 20 12:53:47.435: INFO: ss-0  kube16prod-img-kube16prod-img-minion-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:46 +0000 UTC  }]
Feb 20 12:53:47.435: INFO: ss-1  kube16prod-img-kube16prod-img-minion-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  }]
Feb 20 12:53:47.435: INFO: ss-2  kube16prod-img-kube16prod-img-minion-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  }]
Feb 20 12:53:47.435: INFO: 
Feb 20 12:53:47.435: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 20 12:53:48.439: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Feb 20 12:53:48.439: INFO: ss-0  kube16prod-img-kube16prod-img-minion-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:46 +0000 UTC  }]
Feb 20 12:53:48.439: INFO: ss-1  kube16prod-img-kube16prod-img-minion-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  }]
Feb 20 12:53:48.439: INFO: ss-2  kube16prod-img-kube16prod-img-minion-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  }]
Feb 20 12:53:48.439: INFO: 
Feb 20 12:53:48.439: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 20 12:53:49.444: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Feb 20 12:53:49.444: INFO: ss-0  kube16prod-img-kube16prod-img-minion-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:52:46 +0000 UTC  }]
Feb 20 12:53:49.445: INFO: ss-1  kube16prod-img-kube16prod-img-minion-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  }]
Feb 20 12:53:49.445: INFO: ss-2  kube16prod-img-kube16prod-img-minion-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-20 12:53:07 +0000 UTC  }]
Feb 20 12:53:49.445: INFO: 
Feb 20 12:53:49.445: INFO: StatefulSet ss has not reached scale 0, at 3
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8696
Feb 20 12:53:50.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:53:50.666: INFO: rc: 1
Feb 20 12:53:50.667: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  error: unable to upgrade connection: container not found ("webserver")
 [] <nil> 0xc0026ee7e0 exit status 1 <nil> <nil> true [0xc002482620 0xc002482660 0xc002482678] [0xc002482620 0xc002482660 0xc002482678] [0xc002482648 0xc002482670] [0x10efe30 0x10efe30] 0xc006543260 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Feb 20 12:54:00.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:54:00.846: INFO: rc: 1
Feb 20 12:54:00.846: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026eeba0 exit status 1 <nil> <nil> true [0xc002482680 0xc002482698 0xc0024826c8] [0xc002482680 0xc002482698 0xc0024826c8] [0xc002482690 0xc0024826b0] [0x10efe30 0x10efe30] 0xc006543620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:54:10.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:54:11.016: INFO: rc: 1
Feb 20 12:54:11.016: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026eef30 exit status 1 <nil> <nil> true [0xc0024826d0 0xc002482728 0xc002482768] [0xc0024826d0 0xc002482728 0xc002482768] [0xc002482708 0xc002482750] [0x10efe30 0x10efe30] 0xc006543980 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:54:21.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:54:21.154: INFO: rc: 1
Feb 20 12:54:21.155: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026ef2f0 exit status 1 <nil> <nil> true [0xc002482770 0xc002482788 0xc0024827a8] [0xc002482770 0xc002482788 0xc0024827a8] [0xc002482780 0xc0024827a0] [0x10efe30 0x10efe30] 0xc006543ce0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:54:31.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:54:31.310: INFO: rc: 1
Feb 20 12:54:31.316: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026ef680 exit status 1 <nil> <nil> true [0xc0024827b0 0xc0024827c8 0xc0024827e0] [0xc0024827b0 0xc0024827c8 0xc0024827e0] [0xc0024827c0 0xc0024827d8] [0x10efe30 0x10efe30] 0xc002dc6240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:54:41.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:54:41.565: INFO: rc: 1
Feb 20 12:54:41.566: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026efa10 exit status 1 <nil> <nil> true [0xc0024827e8 0xc002482818 0xc002482850] [0xc0024827e8 0xc002482818 0xc002482850] [0xc002482810 0xc002482830] [0x10efe30 0x10efe30] 0xc002dc65a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:54:51.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:54:51.721: INFO: rc: 1
Feb 20 12:54:51.722: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026efda0 exit status 1 <nil> <nil> true [0xc002482858 0xc002482898 0xc0024828b8] [0xc002482858 0xc002482898 0xc0024828b8] [0xc002482880 0xc0024828b0] [0x10efe30 0x10efe30] 0xc002dc6900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:55:01.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:55:01.900: INFO: rc: 1
Feb 20 12:55:01.900: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0025b41e0 exit status 1 <nil> <nil> true [0xc0024828c0 0xc0024828d8 0xc0024828f0] [0xc0024828c0 0xc0024828d8 0xc0024828f0] [0xc0024828d0 0xc0024828e8] [0x10efe30 0x10efe30] 0xc002dc6c60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:55:11.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:55:12.083: INFO: rc: 1
Feb 20 12:55:12.084: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0025b4570 exit status 1 <nil> <nil> true [0xc0024828f8 0xc002482910 0xc002482928] [0xc0024828f8 0xc002482910 0xc002482928] [0xc002482908 0xc002482920] [0x10efe30 0x10efe30] 0xc002dc7020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:55:22.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:55:22.275: INFO: rc: 1
Feb 20 12:55:22.276: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0025b4ae0 exit status 1 <nil> <nil> true [0xc002482930 0xc002482948 0xc002482960] [0xc002482930 0xc002482948 0xc002482960] [0xc002482940 0xc002482958] [0x10efe30 0x10efe30] 0xc002dc73e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:55:32.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:55:32.486: INFO: rc: 1
Feb 20 12:55:32.487: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0025b4ea0 exit status 1 <nil> <nil> true [0xc002482970 0xc002482988 0xc0024829a0] [0xc002482970 0xc002482988 0xc0024829a0] [0xc002482980 0xc002482998] [0x10efe30 0x10efe30] 0xc002dc7740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:55:42.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:55:42.669: INFO: rc: 1
Feb 20 12:55:42.670: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026ee840 exit status 1 <nil> <nil> true [0xc002482000 0xc002482018 0xc002482030] [0xc002482000 0xc002482018 0xc002482030] [0xc002482010 0xc002482028] [0x10efe30 0x10efe30] 0xc0065422a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:55:52.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:55:52.951: INFO: rc: 1
Feb 20 12:55:52.952: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026eec30 exit status 1 <nil> <nil> true [0xc002482038 0xc002482070 0xc002482088] [0xc002482038 0xc002482070 0xc002482088] [0xc002482048 0xc002482080] [0x10efe30 0x10efe30] 0xc006542600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:56:02.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:56:03.184: INFO: rc: 1
Feb 20 12:56:03.185: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026eeff0 exit status 1 <nil> <nil> true [0xc002482090 0xc0024820b0 0xc0024820c8] [0xc002482090 0xc0024820b0 0xc0024820c8] [0xc0024820a8 0xc0024820c0] [0x10efe30 0x10efe30] 0xc006542960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:56:13.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:56:13.332: INFO: rc: 1
Feb 20 12:56:13.332: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026ef3e0 exit status 1 <nil> <nil> true [0xc0024820d8 0xc002482118 0xc002482138] [0xc0024820d8 0xc002482118 0xc002482138] [0xc002482100 0xc002482128] [0x10efe30 0x10efe30] 0xc006542cc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:56:23.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:56:23.523: INFO: rc: 1
Feb 20 12:56:23.524: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026ef7a0 exit status 1 <nil> <nil> true [0xc002482140 0xc0024821a0 0xc0024821e0] [0xc002482140 0xc0024821a0 0xc0024821e0] [0xc002482178 0xc0024821c8] [0x10efe30 0x10efe30] 0xc006543140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:56:33.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:56:33.685: INFO: rc: 1
Feb 20 12:56:33.686: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026efb60 exit status 1 <nil> <nil> true [0xc002482200 0xc002482248 0xc0024822a0] [0xc002482200 0xc002482248 0xc0024822a0] [0xc002482230 0xc002482288] [0x10efe30 0x10efe30] 0xc0065434a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:56:43.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:56:43.831: INFO: rc: 1
Feb 20 12:56:43.832: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026eff20 exit status 1 <nil> <nil> true [0xc0024822a8 0xc0024822f8 0xc002482358] [0xc0024822a8 0xc0024822f8 0xc002482358] [0xc0024822d8 0xc002482338] [0x10efe30 0x10efe30] 0xc006543860 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:56:53.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:56:53.997: INFO: rc: 1
Feb 20 12:56:53.998: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00234c330 exit status 1 <nil> <nil> true [0xc002482370 0xc0024823b0 0xc0024823c8] [0xc002482370 0xc0024823b0 0xc0024823c8] [0xc0024823a8 0xc0024823c0] [0x10efe30 0x10efe30] 0xc006543bc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:57:04.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:57:04.137: INFO: rc: 1
Feb 20 12:57:04.137: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00234cb40 exit status 1 <nil> <nil> true [0xc0024823d0 0xc0024823e8 0xc002482428] [0xc0024823d0 0xc0024823e8 0xc002482428] [0xc0024823e0 0xc002482410] [0x10efe30 0x10efe30] 0xc001b74000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:57:14.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:57:14.300: INFO: rc: 1
Feb 20 12:57:14.301: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00234cf00 exit status 1 <nil> <nil> true [0xc002482448 0xc002482490 0xc0024824a8] [0xc002482448 0xc002482490 0xc0024824a8] [0xc002482478 0xc0024824a0] [0x10efe30 0x10efe30] 0xc001b746c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:57:24.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:57:24.465: INFO: rc: 1
Feb 20 12:57:24.466: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00234d2f0 exit status 1 <nil> <nil> true [0xc0024824b0 0xc0024824f0 0xc002482528] [0xc0024824b0 0xc0024824f0 0xc002482528] [0xc0024824d0 0xc002482510] [0x10efe30 0x10efe30] 0xc001b74ea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:57:34.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:57:34.679: INFO: rc: 1
Feb 20 12:57:34.681: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026ee7e0 exit status 1 <nil> <nil> true [0xc002482008 0xc002482020 0xc002482038] [0xc002482008 0xc002482020 0xc002482038] [0xc002482018 0xc002482030] [0x10efe30 0x10efe30] 0xc0065422a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:57:44.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:57:44.817: INFO: rc: 1
Feb 20 12:57:44.817: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026eebd0 exit status 1 <nil> <nil> true [0xc002482040 0xc002482078 0xc002482090] [0xc002482040 0xc002482078 0xc002482090] [0xc002482070 0xc002482088] [0x10efe30 0x10efe30] 0xc006542600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:57:54.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:57:54.959: INFO: rc: 1
Feb 20 12:57:54.960: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026eef90 exit status 1 <nil> <nil> true [0xc002482098 0xc0024820b8 0xc0024820d8] [0xc002482098 0xc0024820b8 0xc0024820d8] [0xc0024820b0 0xc0024820c8] [0x10efe30 0x10efe30] 0xc006542960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:58:04.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:58:05.134: INFO: rc: 1
Feb 20 12:58:05.135: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026ef380 exit status 1 <nil> <nil> true [0xc0024820f0 0xc002482120 0xc002482140] [0xc0024820f0 0xc002482120 0xc002482140] [0xc002482118 0xc002482138] [0x10efe30 0x10efe30] 0xc006542cc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:58:15.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:58:15.293: INFO: rc: 1
Feb 20 12:58:15.294: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026ef740 exit status 1 <nil> <nil> true [0xc002482158 0xc0024821b8 0xc002482200] [0xc002482158 0xc0024821b8 0xc002482200] [0xc0024821a0 0xc0024821e0] [0x10efe30 0x10efe30] 0xc006543140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:58:25.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:58:25.481: INFO: rc: 1
Feb 20 12:58:25.482: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026efb00 exit status 1 <nil> <nil> true [0xc002482218 0xc002482268 0xc0024822a8] [0xc002482218 0xc002482268 0xc0024822a8] [0xc002482248 0xc0024822a0] [0x10efe30 0x10efe30] 0xc0065434a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:58:35.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:58:35.623: INFO: rc: 1
Feb 20 12:58:35.623: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0026efec0 exit status 1 <nil> <nil> true [0xc0024822c0 0xc002482318 0xc002482370] [0xc0024822c0 0xc002482318 0xc002482370] [0xc0024822f8 0xc002482358] [0x10efe30 0x10efe30] 0xc006543860 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:58:45.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:58:45.802: INFO: rc: 1
Feb 20 12:58:45.802: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00234c300 exit status 1 <nil> <nil> true [0xc002482390 0xc0024823b8 0xc0024823d0] [0xc002482390 0xc0024823b8 0xc0024823d0] [0xc0024823b0 0xc0024823c8] [0x10efe30 0x10efe30] 0xc006543bc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 20 12:58:55.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8696 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 12:58:55.984: INFO: rc: 1
Feb 20 12:58:55.985: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: 
Feb 20 12:58:55.985: INFO: Scaling statefulset ss to 0
Feb 20 12:58:56.006: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 20 12:58:56.012: INFO: Deleting all statefulset in ns statefulset-8696
Feb 20 12:58:56.016: INFO: Scaling statefulset ss to 0
Feb 20 12:58:56.029: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 12:58:56.034: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:58:56.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8696" for this suite.
Feb 20 12:59:02.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:59:02.242: INFO: namespace statefulset-8696 deletion completed in 6.16518024s

• [SLOW TEST:375.664 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:59:02.259: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5737
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-5fb02af1-0770-4b35-8e48-a0b0b8b06c3a
STEP: Creating a pod to test consume configMaps
Feb 20 12:59:02.444: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-be40db90-4e0a-4345-be77-257789685fa9" in namespace "projected-5737" to be "success or failure"
Feb 20 12:59:02.449: INFO: Pod "pod-projected-configmaps-be40db90-4e0a-4345-be77-257789685fa9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009642ms
Feb 20 12:59:04.454: INFO: Pod "pod-projected-configmaps-be40db90-4e0a-4345-be77-257789685fa9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009584373s
Feb 20 12:59:06.459: INFO: Pod "pod-projected-configmaps-be40db90-4e0a-4345-be77-257789685fa9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014264101s
STEP: Saw pod success
Feb 20 12:59:06.459: INFO: Pod "pod-projected-configmaps-be40db90-4e0a-4345-be77-257789685fa9" satisfied condition "success or failure"
Feb 20 12:59:06.462: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod pod-projected-configmaps-be40db90-4e0a-4345-be77-257789685fa9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 12:59:06.527: INFO: Waiting for pod pod-projected-configmaps-be40db90-4e0a-4345-be77-257789685fa9 to disappear
Feb 20 12:59:06.531: INFO: Pod pod-projected-configmaps-be40db90-4e0a-4345-be77-257789685fa9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:59:06.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5737" for this suite.
Feb 20 12:59:12.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:59:12.651: INFO: namespace projected-5737 deletion completed in 6.111429952s

• [SLOW TEST:10.393 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:59:12.666: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3240
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 20 12:59:13.613: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 20 12:59:15.625: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717800353, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717800353, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717800353, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717800353, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 20 12:59:18.642: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:59:18.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3240" for this suite.
Feb 20 12:59:24.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:59:24.766: INFO: namespace webhook-3240 deletion completed in 6.107834811s
STEP: Destroying namespace "webhook-3240-markers" for this suite.
Feb 20 12:59:30.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:59:30.867: INFO: namespace webhook-3240-markers deletion completed in 6.100690716s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.213 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:59:30.884: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8469
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:59:38.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8469" for this suite.
Feb 20 12:59:44.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:59:44.188: INFO: namespace resourcequota-8469 deletion completed in 6.109603863s

• [SLOW TEST:13.304 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 12:59:44.189: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8831
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 20 12:59:44.776: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 20 12:59:46.788: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717800384, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717800384, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717800384, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717800384, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 20 12:59:49.811: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 12:59:49.816: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1663-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 12:59:50.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8831" for this suite.
Feb 20 12:59:56.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 12:59:57.077: INFO: namespace webhook-8831 deletion completed in 6.111456563s
STEP: Destroying namespace "webhook-8831-markers" for this suite.
Feb 20 13:00:03.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:00:03.218: INFO: namespace webhook-8831-markers deletion completed in 6.140021226s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.043 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:00:03.249: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9393
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb 20 13:00:03.396: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 20 13:00:03.408: INFO: Waiting for terminating namespaces to be deleted...
Feb 20 13:00:03.411: INFO: 
Logging pods the kubelet thinks is on node kube16prod-img-kube16prod-img-minion-1 before test
Feb 20 13:00:03.459: INFO: calico-node-vkbjk from kube-system started at 2020-02-20 10:28:15 +0000 UTC (2 container statuses recorded)
Feb 20 13:00:03.460: INFO: 	Container calico-node ready: true, restart count 0
Feb 20 13:00:03.460: INFO: 	Container install-cni ready: true, restart count 0
Feb 20 13:00:03.460: INFO: calico-kube-controllers-555d6f4bd9-xfg9t from kube-system started at 2020-02-20 10:56:19 +0000 UTC (1 container statuses recorded)
Feb 20 13:00:03.460: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 20 13:00:03.461: INFO: sonobuoy-systemd-logs-daemon-set-27e71f1a82d14495-ggbs7 from sonobuoy started at 2020-02-20 12:25:04 +0000 UTC (2 container statuses recorded)
Feb 20 13:00:03.461: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 20 13:00:03.461: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 20 13:00:03.461: INFO: prometheus-operator-prometheus-node-exporter-c2v94 from prometheus-monitoring started at 2020-02-20 10:28:15 +0000 UTC (1 container statuses recorded)
Feb 20 13:00:03.462: INFO: 	Container node-exporter ready: true, restart count 0
Feb 20 13:00:03.462: INFO: metrics-server-f96ddff8f-h2kx6 from kube-system started at 2020-02-20 10:40:28 +0000 UTC (1 container statuses recorded)
Feb 20 13:00:03.462: INFO: 	Container metrics-server ready: true, restart count 0
Feb 20 13:00:03.462: INFO: 
Logging pods the kubelet thinks is on node kube16prod-img-kube16prod-img-minion-2 before test
Feb 20 13:00:03.476: INFO: prometheus-operator-prometheus-node-exporter-wr9zk from prometheus-monitoring started at 2020-02-20 12:20:59 +0000 UTC (1 container statuses recorded)
Feb 20 13:00:03.476: INFO: 	Container node-exporter ready: true, restart count 0
Feb 20 13:00:03.476: INFO: sonobuoy from sonobuoy started at 2020-02-20 12:24:54 +0000 UTC (1 container statuses recorded)
Feb 20 13:00:03.477: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 20 13:00:03.477: INFO: sonobuoy-e2e-job-3610336cc2ba449a from sonobuoy started at 2020-02-20 12:25:05 +0000 UTC (2 container statuses recorded)
Feb 20 13:00:03.477: INFO: 	Container e2e ready: true, restart count 0
Feb 20 13:00:03.478: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 20 13:00:03.478: INFO: sonobuoy-systemd-logs-daemon-set-27e71f1a82d14495-fj7b9 from sonobuoy started at 2020-02-20 12:25:05 +0000 UTC (2 container statuses recorded)
Feb 20 13:00:03.478: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 20 13:00:03.479: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 20 13:00:03.479: INFO: calico-node-6fj4h from kube-system started at 2020-02-20 12:20:59 +0000 UTC (2 container statuses recorded)
Feb 20 13:00:03.479: INFO: 	Container calico-node ready: true, restart count 0
Feb 20 13:00:03.479: INFO: 	Container install-cni ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node kube16prod-img-kube16prod-img-minion-1
STEP: verifying the node has the label node kube16prod-img-kube16prod-img-minion-2
Feb 20 13:00:03.554: INFO: Pod calico-kube-controllers-555d6f4bd9-xfg9t requesting resource cpu=0m on Node kube16prod-img-kube16prod-img-minion-1
Feb 20 13:00:03.555: INFO: Pod calico-node-6fj4h requesting resource cpu=250m on Node kube16prod-img-kube16prod-img-minion-2
Feb 20 13:00:03.555: INFO: Pod calico-node-vkbjk requesting resource cpu=250m on Node kube16prod-img-kube16prod-img-minion-1
Feb 20 13:00:03.555: INFO: Pod metrics-server-f96ddff8f-h2kx6 requesting resource cpu=0m on Node kube16prod-img-kube16prod-img-minion-1
Feb 20 13:00:03.556: INFO: Pod prometheus-operator-prometheus-node-exporter-c2v94 requesting resource cpu=0m on Node kube16prod-img-kube16prod-img-minion-1
Feb 20 13:00:03.556: INFO: Pod prometheus-operator-prometheus-node-exporter-wr9zk requesting resource cpu=0m on Node kube16prod-img-kube16prod-img-minion-2
Feb 20 13:00:03.556: INFO: Pod sonobuoy requesting resource cpu=0m on Node kube16prod-img-kube16prod-img-minion-2
Feb 20 13:00:03.556: INFO: Pod sonobuoy-e2e-job-3610336cc2ba449a requesting resource cpu=0m on Node kube16prod-img-kube16prod-img-minion-2
Feb 20 13:00:03.556: INFO: Pod sonobuoy-systemd-logs-daemon-set-27e71f1a82d14495-fj7b9 requesting resource cpu=0m on Node kube16prod-img-kube16prod-img-minion-2
Feb 20 13:00:03.557: INFO: Pod sonobuoy-systemd-logs-daemon-set-27e71f1a82d14495-ggbs7 requesting resource cpu=0m on Node kube16prod-img-kube16prod-img-minion-1
STEP: Starting Pods to consume most of the cluster CPU.
Feb 20 13:00:03.557: INFO: Creating a pod which consumes cpu=385m on Node kube16prod-img-kube16prod-img-minion-1
Feb 20 13:00:03.567: INFO: Creating a pod which consumes cpu=385m on Node kube16prod-img-kube16prod-img-minion-2
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-01499ec0-be72-4ac2-a498-892b2c89cd0f.15f51dcb69cfb342], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9393/filler-pod-01499ec0-be72-4ac2-a498-892b2c89cd0f to kube16prod-img-kube16prod-img-minion-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-01499ec0-be72-4ac2-a498-892b2c89cd0f.15f51dcbd354599e], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-01499ec0-be72-4ac2-a498-892b2c89cd0f.15f51dcbe3b39bb7], Reason = [Created], Message = [Created container filler-pod-01499ec0-be72-4ac2-a498-892b2c89cd0f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-01499ec0-be72-4ac2-a498-892b2c89cd0f.15f51dcbef57e204], Reason = [Started], Message = [Started container filler-pod-01499ec0-be72-4ac2-a498-892b2c89cd0f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-33b30dae-f84d-4fe7-9f20-49bbda320fe0.15f51dcb691bf6fa], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9393/filler-pod-33b30dae-f84d-4fe7-9f20-49bbda320fe0 to kube16prod-img-kube16prod-img-minion-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-33b30dae-f84d-4fe7-9f20-49bbda320fe0.15f51dcbbe7c21ba], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-33b30dae-f84d-4fe7-9f20-49bbda320fe0.15f51dcbceb182e9], Reason = [Created], Message = [Created container filler-pod-33b30dae-f84d-4fe7-9f20-49bbda320fe0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-33b30dae-f84d-4fe7-9f20-49bbda320fe0.15f51dcbd8c407a3], Reason = [Started], Message = [Started container filler-pod-33b30dae-f84d-4fe7-9f20-49bbda320fe0]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15f51dcc59dea7c6], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node kube16prod-img-kube16prod-img-minion-2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node kube16prod-img-kube16prod-img-minion-1
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:00:08.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9393" for this suite.
Feb 20 13:00:14.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:00:14.892: INFO: namespace sched-pred-9393 deletion completed in 6.229780373s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:11.646 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:00:14.903: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5927
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Feb 20 13:00:15.054: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Feb 20 13:00:24.127: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:00:24.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5927" for this suite.
Feb 20 13:00:30.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:00:30.272: INFO: namespace pods-5927 deletion completed in 6.133261276s

• [SLOW TEST:15.371 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:00:30.290: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-3419
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb 20 13:00:30.440: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:00:33.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3419" for this suite.
Feb 20 13:00:39.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:00:39.549: INFO: namespace init-container-3419 deletion completed in 6.147984599s

• [SLOW TEST:9.260 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:00:39.550: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6608
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Feb 20 13:00:39.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 create -f - --namespace=kubectl-6608'
Feb 20 13:00:41.033: INFO: stderr: ""
Feb 20 13:00:41.033: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 20 13:00:41.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6608'
Feb 20 13:00:41.239: INFO: stderr: ""
Feb 20 13:00:41.239: INFO: stdout: "update-demo-nautilus-mzs8t update-demo-nautilus-ts5pv "
Feb 20 13:00:41.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-nautilus-mzs8t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6608'
Feb 20 13:00:41.428: INFO: stderr: ""
Feb 20 13:00:41.428: INFO: stdout: ""
Feb 20 13:00:41.428: INFO: update-demo-nautilus-mzs8t is created but not running
Feb 20 13:00:46.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6608'
Feb 20 13:00:46.616: INFO: stderr: ""
Feb 20 13:00:46.616: INFO: stdout: "update-demo-nautilus-mzs8t update-demo-nautilus-ts5pv "
Feb 20 13:00:46.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-nautilus-mzs8t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6608'
Feb 20 13:00:46.802: INFO: stderr: ""
Feb 20 13:00:46.802: INFO: stdout: "true"
Feb 20 13:00:46.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-nautilus-mzs8t -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6608'
Feb 20 13:00:47.003: INFO: stderr: ""
Feb 20 13:00:47.003: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 13:00:47.003: INFO: validating pod update-demo-nautilus-mzs8t
Feb 20 13:00:47.015: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 13:00:47.016: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 13:00:47.016: INFO: update-demo-nautilus-mzs8t is verified up and running
Feb 20 13:00:47.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-nautilus-ts5pv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6608'
Feb 20 13:00:47.184: INFO: stderr: ""
Feb 20 13:00:47.184: INFO: stdout: "true"
Feb 20 13:00:47.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-nautilus-ts5pv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6608'
Feb 20 13:00:47.394: INFO: stderr: ""
Feb 20 13:00:47.394: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 13:00:47.394: INFO: validating pod update-demo-nautilus-ts5pv
Feb 20 13:00:47.411: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 13:00:47.411: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 13:00:47.411: INFO: update-demo-nautilus-ts5pv is verified up and running
STEP: scaling down the replication controller
Feb 20 13:00:47.419: INFO: scanned /root for discovery docs: <nil>
Feb 20 13:00:47.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-6608'
Feb 20 13:00:47.657: INFO: stderr: ""
Feb 20 13:00:47.657: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 20 13:00:47.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6608'
Feb 20 13:00:48.049: INFO: stderr: ""
Feb 20 13:00:48.049: INFO: stdout: "update-demo-nautilus-mzs8t update-demo-nautilus-ts5pv "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 20 13:00:53.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6608'
Feb 20 13:00:53.217: INFO: stderr: ""
Feb 20 13:00:53.217: INFO: stdout: "update-demo-nautilus-mzs8t update-demo-nautilus-ts5pv "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 20 13:00:58.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6608'
Feb 20 13:00:58.380: INFO: stderr: ""
Feb 20 13:00:58.380: INFO: stdout: "update-demo-nautilus-mzs8t update-demo-nautilus-ts5pv "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 20 13:01:03.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6608'
Feb 20 13:01:03.585: INFO: stderr: ""
Feb 20 13:01:03.585: INFO: stdout: "update-demo-nautilus-ts5pv "
Feb 20 13:01:03.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-nautilus-ts5pv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6608'
Feb 20 13:01:03.787: INFO: stderr: ""
Feb 20 13:01:03.787: INFO: stdout: "true"
Feb 20 13:01:03.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-nautilus-ts5pv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6608'
Feb 20 13:01:03.968: INFO: stderr: ""
Feb 20 13:01:03.968: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 13:01:03.968: INFO: validating pod update-demo-nautilus-ts5pv
Feb 20 13:01:03.974: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 13:01:03.974: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 13:01:03.974: INFO: update-demo-nautilus-ts5pv is verified up and running
STEP: scaling up the replication controller
Feb 20 13:01:03.984: INFO: scanned /root for discovery docs: <nil>
Feb 20 13:01:03.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-6608'
Feb 20 13:01:04.204: INFO: stderr: ""
Feb 20 13:01:04.204: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 20 13:01:04.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6608'
Feb 20 13:01:04.536: INFO: stderr: ""
Feb 20 13:01:04.536: INFO: stdout: "update-demo-nautilus-lx7qr update-demo-nautilus-ts5pv "
Feb 20 13:01:04.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-nautilus-lx7qr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6608'
Feb 20 13:01:04.761: INFO: stderr: ""
Feb 20 13:01:04.761: INFO: stdout: ""
Feb 20 13:01:04.761: INFO: update-demo-nautilus-lx7qr is created but not running
Feb 20 13:01:09.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6608'
Feb 20 13:01:09.955: INFO: stderr: ""
Feb 20 13:01:09.955: INFO: stdout: "update-demo-nautilus-lx7qr update-demo-nautilus-ts5pv "
Feb 20 13:01:09.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-nautilus-lx7qr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6608'
Feb 20 13:01:10.157: INFO: stderr: ""
Feb 20 13:01:10.158: INFO: stdout: "true"
Feb 20 13:01:10.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-nautilus-lx7qr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6608'
Feb 20 13:01:10.412: INFO: stderr: ""
Feb 20 13:01:10.412: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 13:01:10.412: INFO: validating pod update-demo-nautilus-lx7qr
Feb 20 13:01:10.422: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 13:01:10.422: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 13:01:10.422: INFO: update-demo-nautilus-lx7qr is verified up and running
Feb 20 13:01:10.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-nautilus-ts5pv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6608'
Feb 20 13:01:10.643: INFO: stderr: ""
Feb 20 13:01:10.643: INFO: stdout: "true"
Feb 20 13:01:10.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-nautilus-ts5pv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6608'
Feb 20 13:01:10.875: INFO: stderr: ""
Feb 20 13:01:10.875: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 13:01:10.875: INFO: validating pod update-demo-nautilus-ts5pv
Feb 20 13:01:10.879: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 13:01:10.880: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 13:01:10.880: INFO: update-demo-nautilus-ts5pv is verified up and running
STEP: using delete to clean up resources
Feb 20 13:01:10.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 delete --grace-period=0 --force -f - --namespace=kubectl-6608'
Feb 20 13:01:11.050: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 13:01:11.050: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 20 13:01:11.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6608'
Feb 20 13:01:11.319: INFO: stderr: "No resources found in kubectl-6608 namespace.\n"
Feb 20 13:01:11.319: INFO: stdout: ""
Feb 20 13:01:11.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods -l name=update-demo --namespace=kubectl-6608 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 20 13:01:11.600: INFO: stderr: ""
Feb 20 13:01:11.600: INFO: stdout: "update-demo-nautilus-lx7qr\nupdate-demo-nautilus-ts5pv\n"
Feb 20 13:01:12.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6608'
Feb 20 13:01:12.526: INFO: stderr: "No resources found in kubectl-6608 namespace.\n"
Feb 20 13:01:12.526: INFO: stdout: ""
Feb 20 13:01:12.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods -l name=update-demo --namespace=kubectl-6608 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 20 13:01:13.045: INFO: stderr: ""
Feb 20 13:01:13.045: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:01:13.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6608" for this suite.
Feb 20 13:01:25.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:01:25.185: INFO: namespace kubectl-6608 deletion completed in 12.126282377s

• [SLOW TEST:45.635 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:01:25.192: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-2047
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 13:01:25.344: INFO: Creating ReplicaSet my-hostname-basic-e3386801-3583-4b5d-8826-5f47a8ae648a
Feb 20 13:01:25.359: INFO: Pod name my-hostname-basic-e3386801-3583-4b5d-8826-5f47a8ae648a: Found 0 pods out of 1
Feb 20 13:01:30.365: INFO: Pod name my-hostname-basic-e3386801-3583-4b5d-8826-5f47a8ae648a: Found 1 pods out of 1
Feb 20 13:01:30.365: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-e3386801-3583-4b5d-8826-5f47a8ae648a" is running
Feb 20 13:01:30.369: INFO: Pod "my-hostname-basic-e3386801-3583-4b5d-8826-5f47a8ae648a-25bc6" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-20 13:01:25 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-20 13:01:27 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-20 13:01:27 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-20 13:01:25 +0000 UTC Reason: Message:}])
Feb 20 13:01:30.369: INFO: Trying to dial the pod
Feb 20 13:01:35.416: INFO: Controller my-hostname-basic-e3386801-3583-4b5d-8826-5f47a8ae648a: Got expected result from replica 1 [my-hostname-basic-e3386801-3583-4b5d-8826-5f47a8ae648a-25bc6]: "my-hostname-basic-e3386801-3583-4b5d-8826-5f47a8ae648a-25bc6", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:01:35.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2047" for this suite.
Feb 20 13:01:41.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:01:41.544: INFO: namespace replicaset-2047 deletion completed in 6.116477922s

• [SLOW TEST:16.353 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:01:41.547: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9295
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-a9ca19dc-4f9a-4f3c-9dbe-eb7cdf904163
STEP: Creating a pod to test consume secrets
Feb 20 13:01:41.719: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-04839055-0983-4fd4-807a-418664d91ba1" in namespace "projected-9295" to be "success or failure"
Feb 20 13:01:41.723: INFO: Pod "pod-projected-secrets-04839055-0983-4fd4-807a-418664d91ba1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.071058ms
Feb 20 13:01:43.729: INFO: Pod "pod-projected-secrets-04839055-0983-4fd4-807a-418664d91ba1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009538119s
STEP: Saw pod success
Feb 20 13:01:43.730: INFO: Pod "pod-projected-secrets-04839055-0983-4fd4-807a-418664d91ba1" satisfied condition "success or failure"
Feb 20 13:01:43.733: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-projected-secrets-04839055-0983-4fd4-807a-418664d91ba1 container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 13:01:43.783: INFO: Waiting for pod pod-projected-secrets-04839055-0983-4fd4-807a-418664d91ba1 to disappear
Feb 20 13:01:43.786: INFO: Pod pod-projected-secrets-04839055-0983-4fd4-807a-418664d91ba1 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:01:43.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9295" for this suite.
Feb 20 13:01:49.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:01:49.926: INFO: namespace projected-9295 deletion completed in 6.133638307s

• [SLOW TEST:8.382 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:01:49.939: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3343
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-f42843cb-0bf2-4a18-9015-01ea3be763c3
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:01:50.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3343" for this suite.
Feb 20 13:01:56.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:01:56.208: INFO: namespace configmap-3343 deletion completed in 6.117344264s

• [SLOW TEST:6.269 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:01:56.215: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6255
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 13:01:56.477: INFO: Create a RollingUpdate DaemonSet
Feb 20 13:01:56.483: INFO: Check that daemon pods launch on every node of the cluster
Feb 20 13:01:56.489: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:01:56.493: INFO: Number of nodes with available pods: 0
Feb 20 13:01:56.493: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 13:01:57.500: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:01:57.507: INFO: Number of nodes with available pods: 0
Feb 20 13:01:57.507: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 13:01:58.502: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:01:58.506: INFO: Number of nodes with available pods: 0
Feb 20 13:01:58.507: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 13:01:59.500: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:01:59.504: INFO: Number of nodes with available pods: 2
Feb 20 13:01:59.504: INFO: Number of running nodes: 2, number of available pods: 2
Feb 20 13:01:59.505: INFO: Update the DaemonSet to trigger a rollout
Feb 20 13:01:59.511: INFO: Updating DaemonSet daemon-set
Feb 20 13:02:14.552: INFO: Roll back the DaemonSet before rollout is complete
Feb 20 13:02:14.561: INFO: Updating DaemonSet daemon-set
Feb 20 13:02:14.561: INFO: Make sure DaemonSet rollback is complete
Feb 20 13:02:14.565: INFO: Wrong image for pod: daemon-set-rv6kf. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb 20 13:02:14.565: INFO: Pod daemon-set-rv6kf is not available
Feb 20 13:02:14.573: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:02:15.578: INFO: Wrong image for pod: daemon-set-rv6kf. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb 20 13:02:15.578: INFO: Pod daemon-set-rv6kf is not available
Feb 20 13:02:15.584: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:02:16.581: INFO: Wrong image for pod: daemon-set-rv6kf. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb 20 13:02:16.581: INFO: Pod daemon-set-rv6kf is not available
Feb 20 13:02:16.590: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:02:17.578: INFO: Pod daemon-set-wwd7k is not available
Feb 20 13:02:17.585: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6255, will wait for the garbage collector to delete the pods
Feb 20 13:02:17.691: INFO: Deleting DaemonSet.extensions daemon-set took: 8.940952ms
Feb 20 13:02:18.592: INFO: Terminating DaemonSet.extensions daemon-set pods took: 900.820607ms
Feb 20 13:03:53.700: INFO: Number of nodes with available pods: 0
Feb 20 13:03:53.701: INFO: Number of running nodes: 0, number of available pods: 0
Feb 20 13:03:53.704: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6255/daemonsets","resourceVersion":"228581"},"items":null}

Feb 20 13:03:53.707: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6255/pods","resourceVersion":"228581"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:03:53.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6255" for this suite.
Feb 20 13:03:59.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:03:59.835: INFO: namespace daemonsets-6255 deletion completed in 6.110663745s

• [SLOW TEST:123.622 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:03:59.844: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2985
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 13:03:59.986: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:04:02.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2985" for this suite.
Feb 20 13:04:46.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:04:46.302: INFO: namespace pods-2985 deletion completed in 44.149851352s

• [SLOW TEST:46.460 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:04:46.316: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-624
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:04:48.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-624" for this suite.
Feb 20 13:05:36.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:05:36.802: INFO: namespace kubelet-test-624 deletion completed in 48.248571275s

• [SLOW TEST:50.488 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:05:36.815: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1786
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-e48331c6-2503-4103-ad6e-7b928248ba60
STEP: Creating a pod to test consume configMaps
Feb 20 13:05:37.101: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e9687211-0ceb-43d3-a814-346673975965" in namespace "projected-1786" to be "success or failure"
Feb 20 13:05:37.114: INFO: Pod "pod-projected-configmaps-e9687211-0ceb-43d3-a814-346673975965": Phase="Pending", Reason="", readiness=false. Elapsed: 12.787166ms
Feb 20 13:05:39.118: INFO: Pod "pod-projected-configmaps-e9687211-0ceb-43d3-a814-346673975965": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017074025s
STEP: Saw pod success
Feb 20 13:05:39.119: INFO: Pod "pod-projected-configmaps-e9687211-0ceb-43d3-a814-346673975965" satisfied condition "success or failure"
Feb 20 13:05:39.121: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-projected-configmaps-e9687211-0ceb-43d3-a814-346673975965 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 13:05:39.138: INFO: Waiting for pod pod-projected-configmaps-e9687211-0ceb-43d3-a814-346673975965 to disappear
Feb 20 13:05:39.141: INFO: Pod pod-projected-configmaps-e9687211-0ceb-43d3-a814-346673975965 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:05:39.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1786" for this suite.
Feb 20 13:05:45.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:05:45.262: INFO: namespace projected-1786 deletion completed in 6.115722017s

• [SLOW TEST:8.449 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:05:45.271: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1670
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-2de83302-5cc2-4fd2-9b95-8c244d55b6bd
STEP: Creating a pod to test consume secrets
Feb 20 13:05:45.480: INFO: Waiting up to 5m0s for pod "pod-secrets-685f2c44-b604-4cdf-931d-a12555120c57" in namespace "secrets-1670" to be "success or failure"
Feb 20 13:05:45.484: INFO: Pod "pod-secrets-685f2c44-b604-4cdf-931d-a12555120c57": Phase="Pending", Reason="", readiness=false. Elapsed: 3.858921ms
Feb 20 13:05:47.491: INFO: Pod "pod-secrets-685f2c44-b604-4cdf-931d-a12555120c57": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01062072s
Feb 20 13:05:49.498: INFO: Pod "pod-secrets-685f2c44-b604-4cdf-931d-a12555120c57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016966588s
STEP: Saw pod success
Feb 20 13:05:49.498: INFO: Pod "pod-secrets-685f2c44-b604-4cdf-931d-a12555120c57" satisfied condition "success or failure"
Feb 20 13:05:49.501: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod pod-secrets-685f2c44-b604-4cdf-931d-a12555120c57 container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 13:05:49.565: INFO: Waiting for pod pod-secrets-685f2c44-b604-4cdf-931d-a12555120c57 to disappear
Feb 20 13:05:49.570: INFO: Pod pod-secrets-685f2c44-b604-4cdf-931d-a12555120c57 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:05:49.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1670" for this suite.
Feb 20 13:05:55.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:05:55.720: INFO: namespace secrets-1670 deletion completed in 6.14328015s

• [SLOW TEST:10.450 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:05:55.739: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8710
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:06:12.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8710" for this suite.
Feb 20 13:06:18.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:06:18.187: INFO: namespace resourcequota-8710 deletion completed in 6.117979321s

• [SLOW TEST:22.449 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:06:18.195: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-7077
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-98h9p in namespace proxy-7077
I0220 13:06:18.365260      18 runners.go:184] Created replication controller with name: proxy-service-98h9p, namespace: proxy-7077, replica count: 1
I0220 13:06:19.416137      18 runners.go:184] proxy-service-98h9p Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0220 13:06:20.417238      18 runners.go:184] proxy-service-98h9p Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0220 13:06:21.418362      18 runners.go:184] proxy-service-98h9p Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0220 13:06:22.418938      18 runners.go:184] proxy-service-98h9p Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0220 13:06:23.419132      18 runners.go:184] proxy-service-98h9p Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0220 13:06:24.419871      18 runners.go:184] proxy-service-98h9p Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 20 13:06:24.426: INFO: setup took 6.083868353s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 20 13:06:24.457: INFO: (0) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">... (200; 29.25788ms)
Feb 20 13:06:24.458: INFO: (0) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/rewriteme">test</a> (200; 26.605169ms)
Feb 20 13:06:24.459: INFO: (0) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname1/proxy/: foo (200; 28.837113ms)
Feb 20 13:06:24.470: INFO: (0) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname2/proxy/: bar (200; 39.071806ms)
Feb 20 13:06:24.475: INFO: (0) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 45.545086ms)
Feb 20 13:06:24.475: INFO: (0) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 44.090013ms)
Feb 20 13:06:24.475: INFO: (0) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname1/proxy/: foo (200; 43.665801ms)
Feb 20 13:06:24.483: INFO: (0) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">test<... (200; 53.835413ms)
Feb 20 13:06:24.496: INFO: (0) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:462/proxy/: tls qux (200; 68.895032ms)
Feb 20 13:06:24.496: INFO: (0) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 66.850541ms)
Feb 20 13:06:24.500: INFO: (0) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname2/proxy/: bar (200; 69.462656ms)
Feb 20 13:06:24.500: INFO: (0) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 71.71723ms)
Feb 20 13:06:24.501: INFO: (0) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname2/proxy/: tls qux (200; 72.002511ms)
Feb 20 13:06:24.503: INFO: (0) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:460/proxy/: tls baz (200; 74.968065ms)
Feb 20 13:06:24.504: INFO: (0) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/tlsrewritem... (200; 71.82684ms)
Feb 20 13:06:24.504: INFO: (0) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname1/proxy/: tls baz (200; 73.435525ms)
Feb 20 13:06:24.511: INFO: (1) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 5.875279ms)
Feb 20 13:06:24.512: INFO: (1) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">... (200; 7.732423ms)
Feb 20 13:06:24.512: INFO: (1) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 6.89727ms)
Feb 20 13:06:24.513: INFO: (1) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 6.709634ms)
Feb 20 13:06:24.513: INFO: (1) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">test<... (200; 7.511056ms)
Feb 20 13:06:24.513: INFO: (1) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:460/proxy/: tls baz (200; 7.895649ms)
Feb 20 13:06:24.513: INFO: (1) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:462/proxy/: tls qux (200; 8.68973ms)
Feb 20 13:06:24.513: INFO: (1) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname1/proxy/: foo (200; 7.49579ms)
Feb 20 13:06:24.513: INFO: (1) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/rewriteme">test</a> (200; 6.849965ms)
Feb 20 13:06:24.513: INFO: (1) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname2/proxy/: bar (200; 7.507143ms)
Feb 20 13:06:24.513: INFO: (1) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 7.174213ms)
Feb 20 13:06:24.515: INFO: (1) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname1/proxy/: foo (200; 8.529822ms)
Feb 20 13:06:24.515: INFO: (1) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/tlsrewritem... (200; 8.270883ms)
Feb 20 13:06:24.515: INFO: (1) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname2/proxy/: bar (200; 9.191068ms)
Feb 20 13:06:24.518: INFO: (1) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname1/proxy/: tls baz (200; 12.360823ms)
Feb 20 13:06:24.522: INFO: (1) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname2/proxy/: tls qux (200; 16.85288ms)
Feb 20 13:06:24.532: INFO: (2) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/rewriteme">test</a> (200; 9.181159ms)
Feb 20 13:06:24.533: INFO: (2) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/tlsrewritem... (200; 9.912987ms)
Feb 20 13:06:24.533: INFO: (2) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">test<... (200; 8.529072ms)
Feb 20 13:06:24.533: INFO: (2) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:460/proxy/: tls baz (200; 8.844659ms)
Feb 20 13:06:24.535: INFO: (2) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">... (200; 10.414189ms)
Feb 20 13:06:24.560: INFO: (2) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 33.212807ms)
Feb 20 13:06:24.560: INFO: (2) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname1/proxy/: foo (200; 37.687371ms)
Feb 20 13:06:24.561: INFO: (2) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname1/proxy/: tls baz (200; 34.751033ms)
Feb 20 13:06:24.561: INFO: (2) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:462/proxy/: tls qux (200; 37.67426ms)
Feb 20 13:06:24.562: INFO: (2) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname2/proxy/: bar (200; 35.849415ms)
Feb 20 13:06:24.562: INFO: (2) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname2/proxy/: tls qux (200; 36.431526ms)
Feb 20 13:06:24.562: INFO: (2) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 38.025625ms)
Feb 20 13:06:24.562: INFO: (2) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname1/proxy/: foo (200; 38.602938ms)
Feb 20 13:06:24.562: INFO: (2) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 37.63966ms)
Feb 20 13:06:24.564: INFO: (2) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname2/proxy/: bar (200; 38.242084ms)
Feb 20 13:06:24.564: INFO: (2) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 37.922491ms)
Feb 20 13:06:24.576: INFO: (3) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname2/proxy/: tls qux (200; 9.410222ms)
Feb 20 13:06:24.576: INFO: (3) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 11.74987ms)
Feb 20 13:06:24.577: INFO: (3) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 11.783129ms)
Feb 20 13:06:24.577: INFO: (3) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 11.95363ms)
Feb 20 13:06:24.578: INFO: (3) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:460/proxy/: tls baz (200; 11.54403ms)
Feb 20 13:06:24.578: INFO: (3) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:462/proxy/: tls qux (200; 12.131516ms)
Feb 20 13:06:24.578: INFO: (3) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">... (200; 12.263111ms)
Feb 20 13:06:24.578: INFO: (3) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/rewriteme">test</a> (200; 12.934186ms)
Feb 20 13:06:24.579: INFO: (3) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/tlsrewritem... (200; 13.070793ms)
Feb 20 13:06:24.579: INFO: (3) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname1/proxy/: foo (200; 13.489092ms)
Feb 20 13:06:24.579: INFO: (3) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 13.103285ms)
Feb 20 13:06:24.579: INFO: (3) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname1/proxy/: tls baz (200; 14.516842ms)
Feb 20 13:06:24.579: INFO: (3) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">test<... (200; 13.151248ms)
Feb 20 13:06:24.580: INFO: (3) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname2/proxy/: bar (200; 14.986265ms)
Feb 20 13:06:24.580: INFO: (3) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname2/proxy/: bar (200; 14.932625ms)
Feb 20 13:06:24.580: INFO: (3) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname1/proxy/: foo (200; 15.223102ms)
Feb 20 13:06:24.586: INFO: (4) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:460/proxy/: tls baz (200; 5.477268ms)
Feb 20 13:06:24.587: INFO: (4) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 4.939369ms)
Feb 20 13:06:24.588: INFO: (4) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">test<... (200; 6.232601ms)
Feb 20 13:06:24.590: INFO: (4) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 7.206316ms)
Feb 20 13:06:24.593: INFO: (4) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/tlsrewritem... (200; 8.726588ms)
Feb 20 13:06:24.593: INFO: (4) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname2/proxy/: bar (200; 10.934563ms)
Feb 20 13:06:24.593: INFO: (4) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/rewriteme">test</a> (200; 9.646613ms)
Feb 20 13:06:24.594: INFO: (4) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname1/proxy/: foo (200; 12.423436ms)
Feb 20 13:06:24.594: INFO: (4) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 11.807872ms)
Feb 20 13:06:24.594: INFO: (4) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">... (200; 10.01313ms)
Feb 20 13:06:24.595: INFO: (4) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 10.019798ms)
Feb 20 13:06:24.595: INFO: (4) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname1/proxy/: tls baz (200; 12.284026ms)
Feb 20 13:06:24.595: INFO: (4) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:462/proxy/: tls qux (200; 10.543377ms)
Feb 20 13:06:24.595: INFO: (4) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname2/proxy/: tls qux (200; 13.55471ms)
Feb 20 13:06:24.596: INFO: (4) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname1/proxy/: foo (200; 12.429777ms)
Feb 20 13:06:24.596: INFO: (4) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname2/proxy/: bar (200; 14.157722ms)
Feb 20 13:06:24.608: INFO: (5) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 8.881993ms)
Feb 20 13:06:24.608: INFO: (5) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">test<... (200; 10.0833ms)
Feb 20 13:06:24.608: INFO: (5) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 9.964024ms)
Feb 20 13:06:24.608: INFO: (5) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname2/proxy/: bar (200; 9.689821ms)
Feb 20 13:06:24.608: INFO: (5) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 9.344866ms)
Feb 20 13:06:24.608: INFO: (5) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">... (200; 10.620524ms)
Feb 20 13:06:24.608: INFO: (5) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname2/proxy/: bar (200; 9.705607ms)
Feb 20 13:06:24.608: INFO: (5) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname1/proxy/: tls baz (200; 9.528753ms)
Feb 20 13:06:24.608: INFO: (5) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname2/proxy/: tls qux (200; 10.098079ms)
Feb 20 13:06:24.609: INFO: (5) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname1/proxy/: foo (200; 10.106134ms)
Feb 20 13:06:24.611: INFO: (5) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:462/proxy/: tls qux (200; 11.306273ms)
Feb 20 13:06:24.611: INFO: (5) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/rewriteme">test</a> (200; 12.002806ms)
Feb 20 13:06:24.612: INFO: (5) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/tlsrewritem... (200; 12.084973ms)
Feb 20 13:06:24.612: INFO: (5) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 11.984545ms)
Feb 20 13:06:24.614: INFO: (5) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname1/proxy/: foo (200; 13.745354ms)
Feb 20 13:06:24.614: INFO: (5) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:460/proxy/: tls baz (200; 13.829859ms)
Feb 20 13:06:24.621: INFO: (6) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:460/proxy/: tls baz (200; 6.642049ms)
Feb 20 13:06:24.625: INFO: (6) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname2/proxy/: tls qux (200; 7.223388ms)
Feb 20 13:06:24.625: INFO: (6) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">test<... (200; 7.660803ms)
Feb 20 13:06:24.625: INFO: (6) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 7.527861ms)
Feb 20 13:06:24.625: INFO: (6) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname1/proxy/: foo (200; 7.330966ms)
Feb 20 13:06:24.626: INFO: (6) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 7.330992ms)
Feb 20 13:06:24.627: INFO: (6) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/tlsrewritem... (200; 7.726913ms)
Feb 20 13:06:24.627: INFO: (6) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 7.260786ms)
Feb 20 13:06:24.627: INFO: (6) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 8.973328ms)
Feb 20 13:06:24.628: INFO: (6) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname2/proxy/: bar (200; 9.50109ms)
Feb 20 13:06:24.628: INFO: (6) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/rewriteme">test</a> (200; 8.187441ms)
Feb 20 13:06:24.628: INFO: (6) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname1/proxy/: foo (200; 8.370475ms)
Feb 20 13:06:24.628: INFO: (6) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname2/proxy/: bar (200; 9.454275ms)
Feb 20 13:06:24.629: INFO: (6) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">... (200; 9.07383ms)
Feb 20 13:06:24.629: INFO: (6) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:462/proxy/: tls qux (200; 9.267356ms)
Feb 20 13:06:24.633: INFO: (6) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname1/proxy/: tls baz (200; 14.336881ms)
Feb 20 13:06:24.647: INFO: (7) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname1/proxy/: tls baz (200; 7.4803ms)
Feb 20 13:06:24.647: INFO: (7) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/tlsrewritem... (200; 13.886548ms)
Feb 20 13:06:24.647: INFO: (7) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 8.850496ms)
Feb 20 13:06:24.650: INFO: (7) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:460/proxy/: tls baz (200; 11.233329ms)
Feb 20 13:06:24.652: INFO: (7) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">... (200; 19.324498ms)
Feb 20 13:06:24.652: INFO: (7) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">test<... (200; 13.765385ms)
Feb 20 13:06:24.653: INFO: (7) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 13.711742ms)
Feb 20 13:06:24.653: INFO: (7) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname2/proxy/: tls qux (200; 14.136343ms)
Feb 20 13:06:24.655: INFO: (7) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 11.739571ms)
Feb 20 13:06:24.655: INFO: (7) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname1/proxy/: foo (200; 10.480547ms)
Feb 20 13:06:24.656: INFO: (7) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname2/proxy/: bar (200; 11.425183ms)
Feb 20 13:06:24.656: INFO: (7) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname2/proxy/: bar (200; 10.989726ms)
Feb 20 13:06:24.656: INFO: (7) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/rewriteme">test</a> (200; 10.817991ms)
Feb 20 13:06:24.656: INFO: (7) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname1/proxy/: foo (200; 12.224821ms)
Feb 20 13:06:24.656: INFO: (7) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:462/proxy/: tls qux (200; 11.272222ms)
Feb 20 13:06:24.656: INFO: (7) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 17.072343ms)
Feb 20 13:06:24.663: INFO: (8) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">... (200; 6.101907ms)
Feb 20 13:06:24.663: INFO: (8) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname1/proxy/: foo (200; 6.720131ms)
Feb 20 13:06:24.663: INFO: (8) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 6.438339ms)
Feb 20 13:06:24.663: INFO: (8) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 7.170481ms)
Feb 20 13:06:24.664: INFO: (8) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:460/proxy/: tls baz (200; 6.578037ms)
Feb 20 13:06:24.664: INFO: (8) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:462/proxy/: tls qux (200; 7.024563ms)
Feb 20 13:06:24.669: INFO: (8) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname2/proxy/: tls qux (200; 11.795042ms)
Feb 20 13:06:24.670: INFO: (8) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/rewriteme">test</a> (200; 12.987667ms)
Feb 20 13:06:24.670: INFO: (8) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">test<... (200; 11.863087ms)
Feb 20 13:06:24.670: INFO: (8) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/tlsrewritem... (200; 12.994386ms)
Feb 20 13:06:24.670: INFO: (8) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 11.821365ms)
Feb 20 13:06:24.670: INFO: (8) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 11.491816ms)
Feb 20 13:06:24.670: INFO: (8) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname2/proxy/: bar (200; 11.683394ms)
Feb 20 13:06:24.670: INFO: (8) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname1/proxy/: tls baz (200; 11.611776ms)
Feb 20 13:06:24.670: INFO: (8) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname1/proxy/: foo (200; 11.903888ms)
Feb 20 13:06:24.670: INFO: (8) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname2/proxy/: bar (200; 11.879678ms)
Feb 20 13:06:24.681: INFO: (9) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 7.536826ms)
Feb 20 13:06:24.682: INFO: (9) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname2/proxy/: tls qux (200; 8.795303ms)
Feb 20 13:06:24.682: INFO: (9) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:460/proxy/: tls baz (200; 9.259093ms)
Feb 20 13:06:24.682: INFO: (9) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname2/proxy/: bar (200; 7.764588ms)
Feb 20 13:06:24.682: INFO: (9) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">test<... (200; 8.80111ms)
Feb 20 13:06:24.682: INFO: (9) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname2/proxy/: bar (200; 8.178485ms)
Feb 20 13:06:24.682: INFO: (9) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname1/proxy/: foo (200; 8.40863ms)
Feb 20 13:06:24.686: INFO: (9) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname1/proxy/: tls baz (200; 10.978715ms)
Feb 20 13:06:24.686: INFO: (9) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:462/proxy/: tls qux (200; 9.904108ms)
Feb 20 13:06:24.686: INFO: (9) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 11.33702ms)
Feb 20 13:06:24.686: INFO: (9) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/tlsrewritem... (200; 10.408368ms)
Feb 20 13:06:24.686: INFO: (9) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname1/proxy/: foo (200; 11.094175ms)
Feb 20 13:06:24.687: INFO: (9) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">... (200; 9.898894ms)
Feb 20 13:06:24.687: INFO: (9) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/rewriteme">test</a> (200; 10.893318ms)
Feb 20 13:06:24.687: INFO: (9) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 9.684825ms)
Feb 20 13:06:24.687: INFO: (9) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 11.43647ms)
Feb 20 13:06:24.695: INFO: (10) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">... (200; 5.625441ms)
Feb 20 13:06:24.695: INFO: (10) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">test<... (200; 5.338057ms)
Feb 20 13:06:24.695: INFO: (10) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 5.155627ms)
Feb 20 13:06:24.697: INFO: (10) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname2/proxy/: tls qux (200; 6.908097ms)
Feb 20 13:06:24.701: INFO: (10) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname2/proxy/: bar (200; 10.58313ms)
Feb 20 13:06:24.701: INFO: (10) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname2/proxy/: bar (200; 10.252209ms)
Feb 20 13:06:24.701: INFO: (10) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 9.447407ms)
Feb 20 13:06:24.701: INFO: (10) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/tlsrewritem... (200; 8.889561ms)
Feb 20 13:06:24.701: INFO: (10) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:460/proxy/: tls baz (200; 7.951771ms)
Feb 20 13:06:24.701: INFO: (10) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname1/proxy/: tls baz (200; 10.307294ms)
Feb 20 13:06:24.706: INFO: (10) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 15.478095ms)
Feb 20 13:06:24.708: INFO: (10) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 15.22095ms)
Feb 20 13:06:24.709: INFO: (10) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:462/proxy/: tls qux (200; 16.794128ms)
Feb 20 13:06:24.709: INFO: (10) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname1/proxy/: foo (200; 17.809297ms)
Feb 20 13:06:24.709: INFO: (10) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/rewriteme">test</a> (200; 17.680425ms)
Feb 20 13:06:24.709: INFO: (10) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname1/proxy/: foo (200; 17.127549ms)
Feb 20 13:06:24.717: INFO: (11) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/rewriteme">test</a> (200; 5.228429ms)
Feb 20 13:06:24.717: INFO: (11) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/tlsrewritem... (200; 5.942835ms)
Feb 20 13:06:24.717: INFO: (11) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:460/proxy/: tls baz (200; 5.240446ms)
Feb 20 13:06:24.721: INFO: (11) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname1/proxy/: tls baz (200; 7.163699ms)
Feb 20 13:06:24.721: INFO: (11) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">... (200; 8.410628ms)
Feb 20 13:06:24.721: INFO: (11) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname1/proxy/: foo (200; 10.047964ms)
Feb 20 13:06:24.721: INFO: (11) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:462/proxy/: tls qux (200; 9.21901ms)
Feb 20 13:06:24.721: INFO: (11) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 6.894144ms)
Feb 20 13:06:24.721: INFO: (11) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 8.170055ms)
Feb 20 13:06:24.721: INFO: (11) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 8.968673ms)
Feb 20 13:06:24.721: INFO: (11) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">test<... (200; 8.387806ms)
Feb 20 13:06:24.723: INFO: (11) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname2/proxy/: bar (200; 10.138262ms)
Feb 20 13:06:24.724: INFO: (11) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname2/proxy/: bar (200; 10.627984ms)
Feb 20 13:06:24.724: INFO: (11) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname1/proxy/: foo (200; 12.358976ms)
Feb 20 13:06:24.725: INFO: (11) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname2/proxy/: tls qux (200; 11.717627ms)
Feb 20 13:06:24.725: INFO: (11) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 11.181548ms)
Feb 20 13:06:24.735: INFO: (12) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">... (200; 9.512702ms)
Feb 20 13:06:24.736: INFO: (12) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 9.043295ms)
Feb 20 13:06:24.736: INFO: (12) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 10.550783ms)
Feb 20 13:06:24.737: INFO: (12) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 9.920872ms)
Feb 20 13:06:24.738: INFO: (12) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:460/proxy/: tls baz (200; 12.452535ms)
Feb 20 13:06:24.739: INFO: (12) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/rewriteme">test</a> (200; 10.705911ms)
Feb 20 13:06:24.739: INFO: (12) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 11.661961ms)
Feb 20 13:06:24.739: INFO: (12) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">test<... (200; 12.346572ms)
Feb 20 13:06:24.739: INFO: (12) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/tlsrewritem... (200; 10.622848ms)
Feb 20 13:06:24.739: INFO: (12) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:462/proxy/: tls qux (200; 13.48253ms)
Feb 20 13:06:24.739: INFO: (12) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname2/proxy/: tls qux (200; 12.65362ms)
Feb 20 13:06:24.741: INFO: (12) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname1/proxy/: tls baz (200; 12.832577ms)
Feb 20 13:06:24.741: INFO: (12) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname1/proxy/: foo (200; 13.357373ms)
Feb 20 13:06:24.741: INFO: (12) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname2/proxy/: bar (200; 13.270922ms)
Feb 20 13:06:24.741: INFO: (12) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname2/proxy/: bar (200; 13.168171ms)
Feb 20 13:06:24.741: INFO: (12) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname1/proxy/: foo (200; 12.903252ms)
Feb 20 13:06:24.751: INFO: (13) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 8.120465ms)
Feb 20 13:06:24.758: INFO: (13) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname1/proxy/: foo (200; 13.135071ms)
Feb 20 13:06:24.758: INFO: (13) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 14.741024ms)
Feb 20 13:06:24.758: INFO: (13) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:462/proxy/: tls qux (200; 13.585253ms)
Feb 20 13:06:24.760: INFO: (13) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname1/proxy/: foo (200; 15.983107ms)
Feb 20 13:06:24.760: INFO: (13) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">... (200; 13.599784ms)
Feb 20 13:06:24.760: INFO: (13) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname2/proxy/: bar (200; 15.924049ms)
Feb 20 13:06:24.760: INFO: (13) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 16.424342ms)
Feb 20 13:06:24.760: INFO: (13) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/tlsrewritem... (200; 14.00879ms)
Feb 20 13:06:24.760: INFO: (13) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname2/proxy/: bar (200; 15.574631ms)
Feb 20 13:06:24.760: INFO: (13) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:460/proxy/: tls baz (200; 13.564799ms)
Feb 20 13:06:24.760: INFO: (13) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname1/proxy/: tls baz (200; 17.119283ms)
Feb 20 13:06:24.760: INFO: (13) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/rewriteme">test</a> (200; 14.598211ms)
Feb 20 13:06:24.760: INFO: (13) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 13.884514ms)
Feb 20 13:06:24.760: INFO: (13) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">test<... (200; 13.14589ms)
Feb 20 13:06:24.760: INFO: (13) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname2/proxy/: tls qux (200; 13.368466ms)
Feb 20 13:06:24.767: INFO: (14) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/tlsrewritem... (200; 5.126043ms)
Feb 20 13:06:24.768: INFO: (14) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 7.757087ms)
Feb 20 13:06:24.772: INFO: (14) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname2/proxy/: tls qux (200; 9.10106ms)
Feb 20 13:06:24.773: INFO: (14) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 11.238501ms)
Feb 20 13:06:24.773: INFO: (14) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 11.492121ms)
Feb 20 13:06:24.773: INFO: (14) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">... (200; 10.598678ms)
Feb 20 13:06:24.773: INFO: (14) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname2/proxy/: bar (200; 12.248536ms)
Feb 20 13:06:24.773: INFO: (14) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 10.613761ms)
Feb 20 13:06:24.773: INFO: (14) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/rewriteme">test</a> (200; 11.511567ms)
Feb 20 13:06:24.773: INFO: (14) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname2/proxy/: bar (200; 12.650272ms)
Feb 20 13:06:24.774: INFO: (14) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:462/proxy/: tls qux (200; 11.144367ms)
Feb 20 13:06:24.774: INFO: (14) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">test<... (200; 10.35014ms)
Feb 20 13:06:24.774: INFO: (14) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:460/proxy/: tls baz (200; 10.759811ms)
Feb 20 13:06:24.774: INFO: (14) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname1/proxy/: tls baz (200; 12.435597ms)
Feb 20 13:06:24.775: INFO: (14) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname1/proxy/: foo (200; 12.922029ms)
Feb 20 13:06:24.775: INFO: (14) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname1/proxy/: foo (200; 14.110112ms)
Feb 20 13:06:24.786: INFO: (15) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname1/proxy/: tls baz (200; 7.522967ms)
Feb 20 13:06:24.788: INFO: (15) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/tlsrewritem... (200; 9.051857ms)
Feb 20 13:06:24.788: INFO: (15) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname1/proxy/: foo (200; 10.027121ms)
Feb 20 13:06:24.791: INFO: (15) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 12.55904ms)
Feb 20 13:06:24.792: INFO: (15) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/rewriteme">test</a> (200; 13.572016ms)
Feb 20 13:06:24.792: INFO: (15) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:460/proxy/: tls baz (200; 13.616438ms)
Feb 20 13:06:24.793: INFO: (15) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:462/proxy/: tls qux (200; 14.209521ms)
Feb 20 13:06:24.795: INFO: (15) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname1/proxy/: foo (200; 15.950677ms)
Feb 20 13:06:24.795: INFO: (15) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">test<... (200; 16.544977ms)
Feb 20 13:06:24.796: INFO: (15) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 16.810859ms)
Feb 20 13:06:24.796: INFO: (15) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname2/proxy/: bar (200; 16.623857ms)
Feb 20 13:06:24.796: INFO: (15) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">... (200; 17.763899ms)
Feb 20 13:06:24.797: INFO: (15) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 17.889932ms)
Feb 20 13:06:24.797: INFO: (15) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 18.039732ms)
Feb 20 13:06:24.797: INFO: (15) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname2/proxy/: tls qux (200; 18.342759ms)
Feb 20 13:06:24.797: INFO: (15) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname2/proxy/: bar (200; 17.913138ms)
Feb 20 13:06:24.808: INFO: (16) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:462/proxy/: tls qux (200; 7.856074ms)
Feb 20 13:06:24.808: INFO: (16) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 7.729936ms)
Feb 20 13:06:24.809: INFO: (16) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/tlsrewritem... (200; 9.14799ms)
Feb 20 13:06:24.809: INFO: (16) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:460/proxy/: tls baz (200; 9.023663ms)
Feb 20 13:06:24.809: INFO: (16) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 10.83552ms)
Feb 20 13:06:24.814: INFO: (16) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname2/proxy/: tls qux (200; 15.28996ms)
Feb 20 13:06:24.815: INFO: (16) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 15.089291ms)
Feb 20 13:06:24.815: INFO: (16) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">... (200; 16.470863ms)
Feb 20 13:06:24.815: INFO: (16) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 15.305149ms)
Feb 20 13:06:24.815: INFO: (16) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/rewriteme">test</a> (200; 15.02779ms)
Feb 20 13:06:24.815: INFO: (16) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname2/proxy/: bar (200; 16.215396ms)
Feb 20 13:06:24.815: INFO: (16) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">test<... (200; 16.754544ms)
Feb 20 13:06:24.815: INFO: (16) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname1/proxy/: tls baz (200; 15.973119ms)
Feb 20 13:06:24.815: INFO: (16) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname2/proxy/: bar (200; 16.253379ms)
Feb 20 13:06:24.815: INFO: (16) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname1/proxy/: foo (200; 15.315906ms)
Feb 20 13:06:24.815: INFO: (16) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname1/proxy/: foo (200; 15.842181ms)
Feb 20 13:06:24.844: INFO: (17) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/rewriteme">test</a> (200; 22.982755ms)
Feb 20 13:06:24.844: INFO: (17) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 24.720098ms)
Feb 20 13:06:24.844: INFO: (17) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 24.088726ms)
Feb 20 13:06:24.844: INFO: (17) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 23.588528ms)
Feb 20 13:06:24.847: INFO: (17) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">test<... (200; 26.934398ms)
Feb 20 13:06:24.847: INFO: (17) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:460/proxy/: tls baz (200; 27.303611ms)
Feb 20 13:06:24.847: INFO: (17) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:462/proxy/: tls qux (200; 28.122199ms)
Feb 20 13:06:24.847: INFO: (17) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 26.280233ms)
Feb 20 13:06:24.847: INFO: (17) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">... (200; 27.780874ms)
Feb 20 13:06:24.847: INFO: (17) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/tlsrewritem... (200; 25.895113ms)
Feb 20 13:06:24.847: INFO: (17) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname2/proxy/: bar (200; 27.259392ms)
Feb 20 13:06:24.847: INFO: (17) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname1/proxy/: foo (200; 27.473256ms)
Feb 20 13:06:24.847: INFO: (17) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname2/proxy/: tls qux (200; 27.954354ms)
Feb 20 13:06:24.849: INFO: (17) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname2/proxy/: bar (200; 28.885474ms)
Feb 20 13:06:24.849: INFO: (17) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname1/proxy/: foo (200; 28.431805ms)
Feb 20 13:06:24.849: INFO: (17) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname1/proxy/: tls baz (200; 28.80427ms)
Feb 20 13:06:24.854: INFO: (18) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 5.142792ms)
Feb 20 13:06:24.855: INFO: (18) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/rewriteme">test</a> (200; 5.836317ms)
Feb 20 13:06:24.856: INFO: (18) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname1/proxy/: foo (200; 6.69905ms)
Feb 20 13:06:24.859: INFO: (18) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 8.579414ms)
Feb 20 13:06:24.859: INFO: (18) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:462/proxy/: tls qux (200; 9.5173ms)
Feb 20 13:06:24.859: INFO: (18) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:460/proxy/: tls baz (200; 9.312411ms)
Feb 20 13:06:24.859: INFO: (18) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">test<... (200; 9.247968ms)
Feb 20 13:06:24.859: INFO: (18) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 9.607158ms)
Feb 20 13:06:24.864: INFO: (18) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname2/proxy/: tls qux (200; 13.910071ms)
Feb 20 13:06:24.864: INFO: (18) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/tlsrewritem... (200; 14.79373ms)
Feb 20 13:06:24.864: INFO: (18) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname1/proxy/: foo (200; 14.172347ms)
Feb 20 13:06:24.864: INFO: (18) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname2/proxy/: bar (200; 13.627242ms)
Feb 20 13:06:24.864: INFO: (18) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 13.161089ms)
Feb 20 13:06:24.865: INFO: (18) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname2/proxy/: bar (200; 13.594096ms)
Feb 20 13:06:24.865: INFO: (18) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">... (200; 14.889681ms)
Feb 20 13:06:24.865: INFO: (18) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname1/proxy/: tls baz (200; 13.405491ms)
Feb 20 13:06:24.878: INFO: (19) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 10.082437ms)
Feb 20 13:06:24.878: INFO: (19) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">test<... (200; 10.828767ms)
Feb 20 13:06:24.878: INFO: (19) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 10.215574ms)
Feb 20 13:06:24.883: INFO: (19) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname1/proxy/: foo (200; 15.191729ms)
Feb 20 13:06:24.884: INFO: (19) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:460/proxy/: tls baz (200; 16.17442ms)
Feb 20 13:06:24.884: INFO: (19) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname2/proxy/: bar (200; 16.87047ms)
Feb 20 13:06:24.885: INFO: (19) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:443/proxy/tlsrewritem... (200; 17.095389ms)
Feb 20 13:06:24.885: INFO: (19) /api/v1/namespaces/proxy-7077/services/proxy-service-98h9p:portname2/proxy/: bar (200; 17.275213ms)
Feb 20 13:06:24.887: INFO: (19) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn/proxy/rewriteme">test</a> (200; 19.420991ms)
Feb 20 13:06:24.888: INFO: (19) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:162/proxy/: bar (200; 19.880303ms)
Feb 20 13:06:24.888: INFO: (19) /api/v1/namespaces/proxy-7077/pods/https:proxy-service-98h9p-d6rkn:462/proxy/: tls qux (200; 20.774255ms)
Feb 20 13:06:24.889: INFO: (19) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname1/proxy/: tls baz (200; 21.364853ms)
Feb 20 13:06:24.889: INFO: (19) /api/v1/namespaces/proxy-7077/services/http:proxy-service-98h9p:portname1/proxy/: foo (200; 21.459105ms)
Feb 20 13:06:24.889: INFO: (19) /api/v1/namespaces/proxy-7077/pods/proxy-service-98h9p-d6rkn:160/proxy/: foo (200; 21.28034ms)
Feb 20 13:06:24.891: INFO: (19) /api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7077/pods/http:proxy-service-98h9p-d6rkn:1080/proxy/rewriteme">... (200; 22.950732ms)
Feb 20 13:06:24.891: INFO: (19) /api/v1/namespaces/proxy-7077/services/https:proxy-service-98h9p:tlsportname2/proxy/: tls qux (200; 23.432353ms)
STEP: deleting ReplicationController proxy-service-98h9p in namespace proxy-7077, will wait for the garbage collector to delete the pods
Feb 20 13:06:24.954: INFO: Deleting ReplicationController proxy-service-98h9p took: 7.477026ms
Feb 20 13:06:25.854: INFO: Terminating ReplicationController proxy-service-98h9p pods took: 900.366841ms
[AfterEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:06:27.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7077" for this suite.
Feb 20 13:06:33.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:06:33.900: INFO: namespace proxy-7077 deletion completed in 6.137271847s

• [SLOW TEST:15.707 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:06:33.906: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6444
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 20 13:06:34.066: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f91868e1-9982-4749-872e-deccd7a1ce29" in namespace "downward-api-6444" to be "success or failure"
Feb 20 13:06:34.075: INFO: Pod "downwardapi-volume-f91868e1-9982-4749-872e-deccd7a1ce29": Phase="Pending", Reason="", readiness=false. Elapsed: 9.04644ms
Feb 20 13:06:36.080: INFO: Pod "downwardapi-volume-f91868e1-9982-4749-872e-deccd7a1ce29": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013598149s
STEP: Saw pod success
Feb 20 13:06:36.080: INFO: Pod "downwardapi-volume-f91868e1-9982-4749-872e-deccd7a1ce29" satisfied condition "success or failure"
Feb 20 13:06:36.083: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod downwardapi-volume-f91868e1-9982-4749-872e-deccd7a1ce29 container client-container: <nil>
STEP: delete the pod
Feb 20 13:06:36.106: INFO: Waiting for pod downwardapi-volume-f91868e1-9982-4749-872e-deccd7a1ce29 to disappear
Feb 20 13:06:36.108: INFO: Pod downwardapi-volume-f91868e1-9982-4749-872e-deccd7a1ce29 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:06:36.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6444" for this suite.
Feb 20 13:06:42.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:06:42.248: INFO: namespace downward-api-6444 deletion completed in 6.133727934s

• [SLOW TEST:8.343 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:06:42.274: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3165
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 20 13:06:42.460: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bbcc2fd1-3eec-4b50-950a-36ce7e64b687" in namespace "downward-api-3165" to be "success or failure"
Feb 20 13:06:42.466: INFO: Pod "downwardapi-volume-bbcc2fd1-3eec-4b50-950a-36ce7e64b687": Phase="Pending", Reason="", readiness=false. Elapsed: 5.058392ms
Feb 20 13:06:44.471: INFO: Pod "downwardapi-volume-bbcc2fd1-3eec-4b50-950a-36ce7e64b687": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010023619s
STEP: Saw pod success
Feb 20 13:06:44.472: INFO: Pod "downwardapi-volume-bbcc2fd1-3eec-4b50-950a-36ce7e64b687" satisfied condition "success or failure"
Feb 20 13:06:44.476: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod downwardapi-volume-bbcc2fd1-3eec-4b50-950a-36ce7e64b687 container client-container: <nil>
STEP: delete the pod
Feb 20 13:06:44.605: INFO: Waiting for pod downwardapi-volume-bbcc2fd1-3eec-4b50-950a-36ce7e64b687 to disappear
Feb 20 13:06:44.632: INFO: Pod downwardapi-volume-bbcc2fd1-3eec-4b50-950a-36ce7e64b687 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:06:44.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3165" for this suite.
Feb 20 13:06:50.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:06:50.764: INFO: namespace downward-api-3165 deletion completed in 6.125313288s

• [SLOW TEST:8.491 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:06:50.774: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4822
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-55724585-05d2-4d93-a87f-65c8c479c20e
STEP: Creating a pod to test consume configMaps
Feb 20 13:06:50.977: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-934c4a2b-8bd0-4d8e-a358-2aa53f7fbcf1" in namespace "projected-4822" to be "success or failure"
Feb 20 13:06:50.980: INFO: Pod "pod-projected-configmaps-934c4a2b-8bd0-4d8e-a358-2aa53f7fbcf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.955034ms
Feb 20 13:06:52.984: INFO: Pod "pod-projected-configmaps-934c4a2b-8bd0-4d8e-a358-2aa53f7fbcf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007266642s
Feb 20 13:06:54.989: INFO: Pod "pod-projected-configmaps-934c4a2b-8bd0-4d8e-a358-2aa53f7fbcf1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012341226s
STEP: Saw pod success
Feb 20 13:06:54.990: INFO: Pod "pod-projected-configmaps-934c4a2b-8bd0-4d8e-a358-2aa53f7fbcf1" satisfied condition "success or failure"
Feb 20 13:06:54.994: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-projected-configmaps-934c4a2b-8bd0-4d8e-a358-2aa53f7fbcf1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 13:06:55.018: INFO: Waiting for pod pod-projected-configmaps-934c4a2b-8bd0-4d8e-a358-2aa53f7fbcf1 to disappear
Feb 20 13:06:55.021: INFO: Pod pod-projected-configmaps-934c4a2b-8bd0-4d8e-a358-2aa53f7fbcf1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:06:55.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4822" for this suite.
Feb 20 13:07:01.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:07:01.151: INFO: namespace projected-4822 deletion completed in 6.121450594s

• [SLOW TEST:10.378 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:07:01.160: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-162
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Feb 20 13:07:05.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec pod-sharedvolume-b92a4248-d3ac-4ace-a286-686b6c1b7bdb -c busybox-main-container --namespace=emptydir-162 -- cat /usr/share/volumeshare/shareddata.txt'
Feb 20 13:07:05.784: INFO: stderr: ""
Feb 20 13:07:05.784: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:07:05.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-162" for this suite.
Feb 20 13:07:11.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:07:11.926: INFO: namespace emptydir-162 deletion completed in 6.135506049s

• [SLOW TEST:10.767 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:07:11.931: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-6630
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 13:07:12.106: INFO: (0) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 11.305907ms)
Feb 20 13:07:12.112: INFO: (1) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 5.029469ms)
Feb 20 13:07:12.118: INFO: (2) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 6.21512ms)
Feb 20 13:07:12.123: INFO: (3) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 4.178858ms)
Feb 20 13:07:12.128: INFO: (4) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 3.84965ms)
Feb 20 13:07:12.131: INFO: (5) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 3.513119ms)
Feb 20 13:07:12.135: INFO: (6) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 3.621999ms)
Feb 20 13:07:12.140: INFO: (7) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 3.868274ms)
Feb 20 13:07:12.144: INFO: (8) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 3.753918ms)
Feb 20 13:07:12.148: INFO: (9) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 3.597995ms)
Feb 20 13:07:12.152: INFO: (10) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 4.448306ms)
Feb 20 13:07:12.157: INFO: (11) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 3.835085ms)
Feb 20 13:07:12.160: INFO: (12) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 3.262131ms)
Feb 20 13:07:12.164: INFO: (13) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 3.569077ms)
Feb 20 13:07:12.168: INFO: (14) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 4.750839ms)
Feb 20 13:07:12.173: INFO: (15) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 4.383933ms)
Feb 20 13:07:12.178: INFO: (16) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 4.610427ms)
Feb 20 13:07:12.184: INFO: (17) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 4.70552ms)
Feb 20 13:07:12.189: INFO: (18) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 4.495388ms)
Feb 20 13:07:12.194: INFO: (19) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 4.538395ms)
[AfterEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:07:12.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6630" for this suite.
Feb 20 13:07:18.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:07:18.307: INFO: namespace proxy-6630 deletion completed in 6.107821422s

• [SLOW TEST:6.377 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:07:18.313: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3074
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 20 13:07:19.163: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 20 13:07:22.190: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Feb 20 13:07:26.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 attach --namespace=webhook-3074 to-be-attached-pod -i -c=container1'
Feb 20 13:07:26.481: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:07:26.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3074" for this suite.
Feb 20 13:07:38.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:07:38.622: INFO: namespace webhook-3074 deletion completed in 12.128964959s
STEP: Destroying namespace "webhook-3074-markers" for this suite.
Feb 20 13:07:44.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:07:44.732: INFO: namespace webhook-3074-markers deletion completed in 6.108631987s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:26.431 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:07:44.748: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3797
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:07:44.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3797" for this suite.
Feb 20 13:07:50.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:07:51.061: INFO: namespace services-3797 deletion completed in 6.150011998s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.315 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:07:51.074: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3634
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:08:16.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3634" for this suite.
Feb 20 13:08:22.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:08:22.757: INFO: namespace container-runtime-3634 deletion completed in 6.129514595s

• [SLOW TEST:31.685 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:08:22.765: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7790
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0220 13:08:33.068651      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 20 13:08:33.070: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:08:33.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7790" for this suite.
Feb 20 13:08:39.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:08:39.230: INFO: namespace gc-7790 deletion completed in 6.153525209s

• [SLOW TEST:16.467 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:08:39.232: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4843
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Feb 20 13:08:39.396: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
Feb 20 13:08:45.160: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:09:09.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4843" for this suite.
Feb 20 13:09:15.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:09:15.467: INFO: namespace crd-publish-openapi-4843 deletion completed in 6.197041234s

• [SLOW TEST:36.236 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:09:15.475: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9713
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 20 13:09:16.234: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717800956, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717800956, loc:(*time.Location)(0x84bfb00)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-86d95b659d\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717800956, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717800956, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Feb 20 13:09:18.243: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717800956, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717800956, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717800956, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717800956, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 20 13:09:21.256: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:09:21.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9713" for this suite.
Feb 20 13:09:27.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:09:27.655: INFO: namespace webhook-9713 deletion completed in 6.197496842s
STEP: Destroying namespace "webhook-9713-markers" for this suite.
Feb 20 13:09:33.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:09:33.808: INFO: namespace webhook-9713-markers deletion completed in 6.15267853s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.344 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:09:33.819: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4987
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-115a6c8b-4b39-4185-9e10-c2557cf4eaab
STEP: Creating a pod to test consume configMaps
Feb 20 13:09:34.032: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-496dc168-221c-49ce-92fd-d0f42cbac640" in namespace "projected-4987" to be "success or failure"
Feb 20 13:09:34.042: INFO: Pod "pod-projected-configmaps-496dc168-221c-49ce-92fd-d0f42cbac640": Phase="Pending", Reason="", readiness=false. Elapsed: 8.799847ms
Feb 20 13:09:36.046: INFO: Pod "pod-projected-configmaps-496dc168-221c-49ce-92fd-d0f42cbac640": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01275307s
STEP: Saw pod success
Feb 20 13:09:36.046: INFO: Pod "pod-projected-configmaps-496dc168-221c-49ce-92fd-d0f42cbac640" satisfied condition "success or failure"
Feb 20 13:09:36.049: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-projected-configmaps-496dc168-221c-49ce-92fd-d0f42cbac640 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 13:09:36.141: INFO: Waiting for pod pod-projected-configmaps-496dc168-221c-49ce-92fd-d0f42cbac640 to disappear
Feb 20 13:09:36.144: INFO: Pod pod-projected-configmaps-496dc168-221c-49ce-92fd-d0f42cbac640 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:09:36.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4987" for this suite.
Feb 20 13:09:42.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:09:42.281: INFO: namespace projected-4987 deletion completed in 6.131727742s

• [SLOW TEST:8.462 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:09:42.286: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1340
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-36febb54-c9f5-4bb0-b3e5-1d728b6c71a3
STEP: Creating a pod to test consume configMaps
Feb 20 13:09:42.447: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c5813a62-2503-4358-b9e7-f4d62daec90c" in namespace "projected-1340" to be "success or failure"
Feb 20 13:09:42.451: INFO: Pod "pod-projected-configmaps-c5813a62-2503-4358-b9e7-f4d62daec90c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.955492ms
Feb 20 13:09:44.456: INFO: Pod "pod-projected-configmaps-c5813a62-2503-4358-b9e7-f4d62daec90c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009536924s
STEP: Saw pod success
Feb 20 13:09:44.457: INFO: Pod "pod-projected-configmaps-c5813a62-2503-4358-b9e7-f4d62daec90c" satisfied condition "success or failure"
Feb 20 13:09:44.460: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-projected-configmaps-c5813a62-2503-4358-b9e7-f4d62daec90c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 13:09:44.479: INFO: Waiting for pod pod-projected-configmaps-c5813a62-2503-4358-b9e7-f4d62daec90c to disappear
Feb 20 13:09:44.483: INFO: Pod pod-projected-configmaps-c5813a62-2503-4358-b9e7-f4d62daec90c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:09:44.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1340" for this suite.
Feb 20 13:09:50.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:09:50.614: INFO: namespace projected-1340 deletion completed in 6.125645843s

• [SLOW TEST:8.330 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:09:50.620: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1424
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-ggbr
STEP: Creating a pod to test atomic-volume-subpath
Feb 20 13:09:50.806: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ggbr" in namespace "subpath-1424" to be "success or failure"
Feb 20 13:09:50.815: INFO: Pod "pod-subpath-test-configmap-ggbr": Phase="Pending", Reason="", readiness=false. Elapsed: 8.307628ms
Feb 20 13:09:52.819: INFO: Pod "pod-subpath-test-configmap-ggbr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012671436s
Feb 20 13:09:54.825: INFO: Pod "pod-subpath-test-configmap-ggbr": Phase="Running", Reason="", readiness=true. Elapsed: 4.018513891s
Feb 20 13:09:56.833: INFO: Pod "pod-subpath-test-configmap-ggbr": Phase="Running", Reason="", readiness=true. Elapsed: 6.026553633s
Feb 20 13:09:58.839: INFO: Pod "pod-subpath-test-configmap-ggbr": Phase="Running", Reason="", readiness=true. Elapsed: 8.032496128s
Feb 20 13:10:00.843: INFO: Pod "pod-subpath-test-configmap-ggbr": Phase="Running", Reason="", readiness=true. Elapsed: 10.03637423s
Feb 20 13:10:02.849: INFO: Pod "pod-subpath-test-configmap-ggbr": Phase="Running", Reason="", readiness=true. Elapsed: 12.042270187s
Feb 20 13:10:04.853: INFO: Pod "pod-subpath-test-configmap-ggbr": Phase="Running", Reason="", readiness=true. Elapsed: 14.046500487s
Feb 20 13:10:06.857: INFO: Pod "pod-subpath-test-configmap-ggbr": Phase="Running", Reason="", readiness=true. Elapsed: 16.050707743s
Feb 20 13:10:08.862: INFO: Pod "pod-subpath-test-configmap-ggbr": Phase="Running", Reason="", readiness=true. Elapsed: 18.055174665s
Feb 20 13:10:10.866: INFO: Pod "pod-subpath-test-configmap-ggbr": Phase="Running", Reason="", readiness=true. Elapsed: 20.059270239s
Feb 20 13:10:12.872: INFO: Pod "pod-subpath-test-configmap-ggbr": Phase="Running", Reason="", readiness=true. Elapsed: 22.065586923s
Feb 20 13:10:14.880: INFO: Pod "pod-subpath-test-configmap-ggbr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.073620964s
STEP: Saw pod success
Feb 20 13:10:14.882: INFO: Pod "pod-subpath-test-configmap-ggbr" satisfied condition "success or failure"
Feb 20 13:10:14.886: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod pod-subpath-test-configmap-ggbr container test-container-subpath-configmap-ggbr: <nil>
STEP: delete the pod
Feb 20 13:10:14.951: INFO: Waiting for pod pod-subpath-test-configmap-ggbr to disappear
Feb 20 13:10:14.965: INFO: Pod pod-subpath-test-configmap-ggbr no longer exists
STEP: Deleting pod pod-subpath-test-configmap-ggbr
Feb 20 13:10:14.966: INFO: Deleting pod "pod-subpath-test-configmap-ggbr" in namespace "subpath-1424"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:10:14.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1424" for this suite.
Feb 20 13:10:20.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:10:21.098: INFO: namespace subpath-1424 deletion completed in 6.118405283s

• [SLOW TEST:30.478 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:10:21.105: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-7142
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-7142, will wait for the garbage collector to delete the pods
Feb 20 13:10:25.332: INFO: Deleting Job.batch foo took: 7.151293ms
Feb 20 13:10:26.233: INFO: Terminating Job.batch foo pods took: 900.543656ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:11:03.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7142" for this suite.
Feb 20 13:11:09.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:11:09.864: INFO: namespace job-7142 deletion completed in 6.11440429s

• [SLOW TEST:48.759 seconds]
[sig-apps] Job
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:11:09.871: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2029
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb 20 13:11:10.010: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 20 13:11:10.026: INFO: Waiting for terminating namespaces to be deleted...
Feb 20 13:11:10.029: INFO: 
Logging pods the kubelet thinks is on node kube16prod-img-kube16prod-img-minion-1 before test
Feb 20 13:11:10.040: INFO: calico-node-vkbjk from kube-system started at 2020-02-20 10:28:15 +0000 UTC (2 container statuses recorded)
Feb 20 13:11:10.041: INFO: 	Container calico-node ready: true, restart count 0
Feb 20 13:11:10.041: INFO: 	Container install-cni ready: true, restart count 0
Feb 20 13:11:10.041: INFO: calico-kube-controllers-555d6f4bd9-xfg9t from kube-system started at 2020-02-20 10:56:19 +0000 UTC (1 container statuses recorded)
Feb 20 13:11:10.041: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 20 13:11:10.042: INFO: sonobuoy-systemd-logs-daemon-set-27e71f1a82d14495-ggbs7 from sonobuoy started at 2020-02-20 12:25:04 +0000 UTC (2 container statuses recorded)
Feb 20 13:11:10.042: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 20 13:11:10.042: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 20 13:11:10.042: INFO: prometheus-operator-prometheus-node-exporter-c2v94 from prometheus-monitoring started at 2020-02-20 10:28:15 +0000 UTC (1 container statuses recorded)
Feb 20 13:11:10.042: INFO: 	Container node-exporter ready: true, restart count 0
Feb 20 13:11:10.042: INFO: metrics-server-f96ddff8f-h2kx6 from kube-system started at 2020-02-20 10:40:28 +0000 UTC (1 container statuses recorded)
Feb 20 13:11:10.043: INFO: 	Container metrics-server ready: true, restart count 0
Feb 20 13:11:10.043: INFO: 
Logging pods the kubelet thinks is on node kube16prod-img-kube16prod-img-minion-2 before test
Feb 20 13:11:10.056: INFO: prometheus-operator-prometheus-node-exporter-wr9zk from prometheus-monitoring started at 2020-02-20 12:20:59 +0000 UTC (1 container statuses recorded)
Feb 20 13:11:10.056: INFO: 	Container node-exporter ready: true, restart count 0
Feb 20 13:11:10.057: INFO: sonobuoy from sonobuoy started at 2020-02-20 12:24:54 +0000 UTC (1 container statuses recorded)
Feb 20 13:11:10.057: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 20 13:11:10.057: INFO: sonobuoy-e2e-job-3610336cc2ba449a from sonobuoy started at 2020-02-20 12:25:05 +0000 UTC (2 container statuses recorded)
Feb 20 13:11:10.058: INFO: 	Container e2e ready: true, restart count 0
Feb 20 13:11:10.058: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 20 13:11:10.058: INFO: sonobuoy-systemd-logs-daemon-set-27e71f1a82d14495-fj7b9 from sonobuoy started at 2020-02-20 12:25:05 +0000 UTC (2 container statuses recorded)
Feb 20 13:11:10.058: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 20 13:11:10.058: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 20 13:11:10.058: INFO: calico-node-6fj4h from kube-system started at 2020-02-20 12:20:59 +0000 UTC (2 container statuses recorded)
Feb 20 13:11:10.059: INFO: 	Container calico-node ready: true, restart count 0
Feb 20 13:11:10.059: INFO: 	Container install-cni ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-235d2fb1-5046-4277-8324-619d0dad8d30 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-235d2fb1-5046-4277-8324-619d0dad8d30 off the node kube16prod-img-kube16prod-img-minion-1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-235d2fb1-5046-4277-8324-619d0dad8d30
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:16:18.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2029" for this suite.
Feb 20 13:16:28.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:16:28.283: INFO: namespace sched-pred-2029 deletion completed in 10.114914143s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:318.414 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:16:28.291: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8473
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:16:39.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8473" for this suite.
Feb 20 13:16:45.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:16:45.601: INFO: namespace resourcequota-8473 deletion completed in 6.10550212s

• [SLOW TEST:17.311 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:16:45.603: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4867
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-f4bdfbe0-c630-4223-9098-02b248d1c8f6
STEP: Creating a pod to test consume secrets
Feb 20 13:16:45.764: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d491d51e-d77d-4234-ab6d-a4b007132aac" in namespace "projected-4867" to be "success or failure"
Feb 20 13:16:45.773: INFO: Pod "pod-projected-secrets-d491d51e-d77d-4234-ab6d-a4b007132aac": Phase="Pending", Reason="", readiness=false. Elapsed: 9.139192ms
Feb 20 13:16:47.778: INFO: Pod "pod-projected-secrets-d491d51e-d77d-4234-ab6d-a4b007132aac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013894682s
STEP: Saw pod success
Feb 20 13:16:47.779: INFO: Pod "pod-projected-secrets-d491d51e-d77d-4234-ab6d-a4b007132aac" satisfied condition "success or failure"
Feb 20 13:16:47.781: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod pod-projected-secrets-d491d51e-d77d-4234-ab6d-a4b007132aac container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 20 13:16:47.863: INFO: Waiting for pod pod-projected-secrets-d491d51e-d77d-4234-ab6d-a4b007132aac to disappear
Feb 20 13:16:47.888: INFO: Pod pod-projected-secrets-d491d51e-d77d-4234-ab6d-a4b007132aac no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:16:47.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4867" for this suite.
Feb 20 13:16:53.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:16:54.041: INFO: namespace projected-4867 deletion completed in 6.148251737s

• [SLOW TEST:8.439 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:16:54.062: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9459
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Feb 20 13:16:54.214: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-673477187 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:16:54.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9459" for this suite.
Feb 20 13:17:00.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:17:00.475: INFO: namespace kubectl-9459 deletion completed in 6.108554936s

• [SLOW TEST:6.413 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:17:00.484: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3766
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 20 13:17:00.647: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4f1b379f-357c-4650-ae07-5e523ea0fe2e" in namespace "projected-3766" to be "success or failure"
Feb 20 13:17:00.650: INFO: Pod "downwardapi-volume-4f1b379f-357c-4650-ae07-5e523ea0fe2e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.0397ms
Feb 20 13:17:02.656: INFO: Pod "downwardapi-volume-4f1b379f-357c-4650-ae07-5e523ea0fe2e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009383937s
Feb 20 13:17:04.663: INFO: Pod "downwardapi-volume-4f1b379f-357c-4650-ae07-5e523ea0fe2e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016446757s
STEP: Saw pod success
Feb 20 13:17:04.666: INFO: Pod "downwardapi-volume-4f1b379f-357c-4650-ae07-5e523ea0fe2e" satisfied condition "success or failure"
Feb 20 13:17:04.669: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod downwardapi-volume-4f1b379f-357c-4650-ae07-5e523ea0fe2e container client-container: <nil>
STEP: delete the pod
Feb 20 13:17:04.690: INFO: Waiting for pod downwardapi-volume-4f1b379f-357c-4650-ae07-5e523ea0fe2e to disappear
Feb 20 13:17:04.692: INFO: Pod downwardapi-volume-4f1b379f-357c-4650-ae07-5e523ea0fe2e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:17:04.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3766" for this suite.
Feb 20 13:17:10.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:17:10.820: INFO: namespace projected-3766 deletion completed in 6.112995028s

• [SLOW TEST:10.337 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:17:10.831: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6329
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:17:27.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6329" for this suite.
Feb 20 13:17:33.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:17:33.208: INFO: namespace resourcequota-6329 deletion completed in 6.109501075s

• [SLOW TEST:22.378 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:17:33.217: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5090
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:17:35.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5090" for this suite.
Feb 20 13:18:03.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:18:03.582: INFO: namespace containers-5090 deletion completed in 28.135266083s

• [SLOW TEST:30.366 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:18:03.586: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8992
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-dfe0b067-00cf-4e5f-b4b8-6f7259291a04
STEP: Creating a pod to test consume secrets
Feb 20 13:18:03.804: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7b316c8f-1114-4427-b8c7-ec1a8d048eab" in namespace "projected-8992" to be "success or failure"
Feb 20 13:18:03.815: INFO: Pod "pod-projected-secrets-7b316c8f-1114-4427-b8c7-ec1a8d048eab": Phase="Pending", Reason="", readiness=false. Elapsed: 9.939243ms
Feb 20 13:18:05.820: INFO: Pod "pod-projected-secrets-7b316c8f-1114-4427-b8c7-ec1a8d048eab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014997731s
Feb 20 13:18:07.824: INFO: Pod "pod-projected-secrets-7b316c8f-1114-4427-b8c7-ec1a8d048eab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018944905s
STEP: Saw pod success
Feb 20 13:18:07.824: INFO: Pod "pod-projected-secrets-7b316c8f-1114-4427-b8c7-ec1a8d048eab" satisfied condition "success or failure"
Feb 20 13:18:07.828: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod pod-projected-secrets-7b316c8f-1114-4427-b8c7-ec1a8d048eab container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 20 13:18:07.851: INFO: Waiting for pod pod-projected-secrets-7b316c8f-1114-4427-b8c7-ec1a8d048eab to disappear
Feb 20 13:18:07.853: INFO: Pod pod-projected-secrets-7b316c8f-1114-4427-b8c7-ec1a8d048eab no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:18:07.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8992" for this suite.
Feb 20 13:18:13.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:18:13.970: INFO: namespace projected-8992 deletion completed in 6.111886602s

• [SLOW TEST:10.386 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:18:13.979: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2159
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 13:18:14.144: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Feb 20 13:18:20.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 --namespace=crd-publish-openapi-2159 create -f -'
Feb 20 13:18:21.200: INFO: stderr: ""
Feb 20 13:18:21.200: INFO: stdout: "e2e-test-crd-publish-openapi-8362-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Feb 20 13:18:21.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 --namespace=crd-publish-openapi-2159 delete e2e-test-crd-publish-openapi-8362-crds test-foo'
Feb 20 13:18:21.351: INFO: stderr: ""
Feb 20 13:18:21.351: INFO: stdout: "e2e-test-crd-publish-openapi-8362-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Feb 20 13:18:21.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 --namespace=crd-publish-openapi-2159 apply -f -'
Feb 20 13:18:21.820: INFO: stderr: ""
Feb 20 13:18:21.820: INFO: stdout: "e2e-test-crd-publish-openapi-8362-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Feb 20 13:18:21.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 --namespace=crd-publish-openapi-2159 delete e2e-test-crd-publish-openapi-8362-crds test-foo'
Feb 20 13:18:21.968: INFO: stderr: ""
Feb 20 13:18:21.968: INFO: stdout: "e2e-test-crd-publish-openapi-8362-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Feb 20 13:18:21.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 --namespace=crd-publish-openapi-2159 create -f -'
Feb 20 13:18:22.323: INFO: rc: 1
Feb 20 13:18:22.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 --namespace=crd-publish-openapi-2159 apply -f -'
Feb 20 13:18:22.706: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Feb 20 13:18:22.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 --namespace=crd-publish-openapi-2159 create -f -'
Feb 20 13:18:23.039: INFO: rc: 1
Feb 20 13:18:23.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 --namespace=crd-publish-openapi-2159 apply -f -'
Feb 20 13:18:23.411: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Feb 20 13:18:23.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 explain e2e-test-crd-publish-openapi-8362-crds'
Feb 20 13:18:23.819: INFO: stderr: ""
Feb 20 13:18:23.819: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8362-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Feb 20 13:18:23.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 explain e2e-test-crd-publish-openapi-8362-crds.metadata'
Feb 20 13:18:24.177: INFO: stderr: ""
Feb 20 13:18:24.177: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8362-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Feb 20 13:18:24.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 explain e2e-test-crd-publish-openapi-8362-crds.spec'
Feb 20 13:18:24.536: INFO: stderr: ""
Feb 20 13:18:24.536: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8362-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Feb 20 13:18:24.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 explain e2e-test-crd-publish-openapi-8362-crds.spec.bars'
Feb 20 13:18:24.908: INFO: stderr: ""
Feb 20 13:18:24.908: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8362-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Feb 20 13:18:24.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 explain e2e-test-crd-publish-openapi-8362-crds.spec.bars2'
Feb 20 13:18:25.305: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:18:31.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2159" for this suite.
Feb 20 13:18:37.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:18:37.162: INFO: namespace crd-publish-openapi-2159 deletion completed in 6.133706739s

• [SLOW TEST:23.184 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:18:37.167: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2181
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-eb887231-a441-42a5-8ff5-2489cb726d4c in namespace container-probe-2181
Feb 20 13:18:41.325: INFO: Started pod liveness-eb887231-a441-42a5-8ff5-2489cb726d4c in namespace container-probe-2181
STEP: checking the pod's current state and verifying that restartCount is present
Feb 20 13:18:41.327: INFO: Initial restart count of pod liveness-eb887231-a441-42a5-8ff5-2489cb726d4c is 0
Feb 20 13:19:05.393: INFO: Restart count of pod container-probe-2181/liveness-eb887231-a441-42a5-8ff5-2489cb726d4c is now 1 (24.06579829s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:19:05.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2181" for this suite.
Feb 20 13:19:11.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:19:11.562: INFO: namespace container-probe-2181 deletion completed in 6.15031s

• [SLOW TEST:34.395 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:19:11.570: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8456
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb 20 13:19:11.756: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:19:16.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8456" for this suite.
Feb 20 13:19:22.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:19:22.320: INFO: namespace init-container-8456 deletion completed in 6.12637803s

• [SLOW TEST:10.751 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:19:22.330: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-6505
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Feb 20 13:19:22.501: INFO: Waiting up to 5m0s for pod "var-expansion-b90577a5-5770-40c4-bd14-5a50af0023c4" in namespace "var-expansion-6505" to be "success or failure"
Feb 20 13:19:22.510: INFO: Pod "var-expansion-b90577a5-5770-40c4-bd14-5a50af0023c4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.323625ms
Feb 20 13:19:24.515: INFO: Pod "var-expansion-b90577a5-5770-40c4-bd14-5a50af0023c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01330311s
Feb 20 13:19:26.524: INFO: Pod "var-expansion-b90577a5-5770-40c4-bd14-5a50af0023c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021806793s
STEP: Saw pod success
Feb 20 13:19:26.524: INFO: Pod "var-expansion-b90577a5-5770-40c4-bd14-5a50af0023c4" satisfied condition "success or failure"
Feb 20 13:19:26.527: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod var-expansion-b90577a5-5770-40c4-bd14-5a50af0023c4 container dapi-container: <nil>
STEP: delete the pod
Feb 20 13:19:26.581: INFO: Waiting for pod var-expansion-b90577a5-5770-40c4-bd14-5a50af0023c4 to disappear
Feb 20 13:19:26.584: INFO: Pod var-expansion-b90577a5-5770-40c4-bd14-5a50af0023c4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:19:26.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6505" for this suite.
Feb 20 13:19:32.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:19:32.701: INFO: namespace var-expansion-6505 deletion completed in 6.104347853s

• [SLOW TEST:10.372 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:19:32.706: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7333
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb 20 13:19:32.855: INFO: Waiting up to 5m0s for pod "downward-api-b93cefd3-064b-4be2-9d55-925862665b73" in namespace "downward-api-7333" to be "success or failure"
Feb 20 13:19:32.860: INFO: Pod "downward-api-b93cefd3-064b-4be2-9d55-925862665b73": Phase="Pending", Reason="", readiness=false. Elapsed: 5.004512ms
Feb 20 13:19:34.865: INFO: Pod "downward-api-b93cefd3-064b-4be2-9d55-925862665b73": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009498959s
Feb 20 13:19:36.870: INFO: Pod "downward-api-b93cefd3-064b-4be2-9d55-925862665b73": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014678962s
STEP: Saw pod success
Feb 20 13:19:36.870: INFO: Pod "downward-api-b93cefd3-064b-4be2-9d55-925862665b73" satisfied condition "success or failure"
Feb 20 13:19:36.873: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod downward-api-b93cefd3-064b-4be2-9d55-925862665b73 container dapi-container: <nil>
STEP: delete the pod
Feb 20 13:19:36.893: INFO: Waiting for pod downward-api-b93cefd3-064b-4be2-9d55-925862665b73 to disappear
Feb 20 13:19:36.897: INFO: Pod downward-api-b93cefd3-064b-4be2-9d55-925862665b73 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:19:36.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7333" for this suite.
Feb 20 13:19:42.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:19:43.028: INFO: namespace downward-api-7333 deletion completed in 6.123587966s

• [SLOW TEST:10.323 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:19:43.034: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-4421
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:19:45.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4421" for this suite.
Feb 20 13:19:51.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:19:51.449: INFO: namespace emptydir-wrapper-4421 deletion completed in 6.135807072s

• [SLOW TEST:8.416 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:19:51.456: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-1743
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 13:19:51.665: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:19:52.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1743" for this suite.
Feb 20 13:19:58.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:19:58.344: INFO: namespace custom-resource-definition-1743 deletion completed in 6.11185907s

• [SLOW TEST:6.889 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:19:58.351: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1337
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-2b3fd611-9409-4b81-8eb6-9f3c3264ae75 in namespace container-probe-1337
Feb 20 13:20:02.521: INFO: Started pod busybox-2b3fd611-9409-4b81-8eb6-9f3c3264ae75 in namespace container-probe-1337
STEP: checking the pod's current state and verifying that restartCount is present
Feb 20 13:20:02.527: INFO: Initial restart count of pod busybox-2b3fd611-9409-4b81-8eb6-9f3c3264ae75 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:24:03.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1337" for this suite.
Feb 20 13:24:09.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:24:09.382: INFO: namespace container-probe-1337 deletion completed in 6.145880485s

• [SLOW TEST:251.032 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:24:09.386: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9821
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Feb 20 13:24:09.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 --namespace=kubectl-9821 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb 20 13:24:12.481: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb 20 13:24:12.481: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:24:14.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9821" for this suite.
Feb 20 13:24:20.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:24:20.616: INFO: namespace kubectl-9821 deletion completed in 6.123257561s

• [SLOW TEST:11.231 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:24:20.618: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-4399
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 20 13:24:22.783: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:24:22.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4399" for this suite.
Feb 20 13:24:28.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:24:28.936: INFO: namespace container-runtime-4399 deletion completed in 6.135091123s

• [SLOW TEST:8.318 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:24:28.950: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-1724
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb 20 13:24:29.339: INFO: Pod name wrapped-volume-race-12db922a-81b4-4e53-b1ab-74c834d5f906: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-12db922a-81b4-4e53-b1ab-74c834d5f906 in namespace emptydir-wrapper-1724, will wait for the garbage collector to delete the pods
Feb 20 13:24:47.460: INFO: Deleting ReplicationController wrapped-volume-race-12db922a-81b4-4e53-b1ab-74c834d5f906 took: 6.833868ms
Feb 20 13:24:48.361: INFO: Terminating ReplicationController wrapped-volume-race-12db922a-81b4-4e53-b1ab-74c834d5f906 pods took: 900.483641ms
STEP: Creating RC which spawns configmap-volume pods
Feb 20 13:25:25.889: INFO: Pod name wrapped-volume-race-d5c51265-d3c2-42c1-9d28-e85b5ccc38f3: Found 0 pods out of 5
Feb 20 13:25:30.909: INFO: Pod name wrapped-volume-race-d5c51265-d3c2-42c1-9d28-e85b5ccc38f3: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d5c51265-d3c2-42c1-9d28-e85b5ccc38f3 in namespace emptydir-wrapper-1724, will wait for the garbage collector to delete the pods
Feb 20 13:25:44.999: INFO: Deleting ReplicationController wrapped-volume-race-d5c51265-d3c2-42c1-9d28-e85b5ccc38f3 took: 6.189533ms
Feb 20 13:25:45.901: INFO: Terminating ReplicationController wrapped-volume-race-d5c51265-d3c2-42c1-9d28-e85b5ccc38f3 pods took: 901.661341ms
STEP: Creating RC which spawns configmap-volume pods
Feb 20 13:26:24.138: INFO: Pod name wrapped-volume-race-74432942-4bf8-47a4-8535-79805be1e1ac: Found 0 pods out of 5
Feb 20 13:26:29.148: INFO: Pod name wrapped-volume-race-74432942-4bf8-47a4-8535-79805be1e1ac: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-74432942-4bf8-47a4-8535-79805be1e1ac in namespace emptydir-wrapper-1724, will wait for the garbage collector to delete the pods
Feb 20 13:26:43.274: INFO: Deleting ReplicationController wrapped-volume-race-74432942-4bf8-47a4-8535-79805be1e1ac took: 13.15806ms
Feb 20 13:26:46.475: INFO: Terminating ReplicationController wrapped-volume-race-74432942-4bf8-47a4-8535-79805be1e1ac pods took: 3.200905541s
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:27:24.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1724" for this suite.
Feb 20 13:27:30.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:27:30.229: INFO: namespace emptydir-wrapper-1724 deletion completed in 6.144165022s

• [SLOW TEST:181.280 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:27:30.237: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3674
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 13:27:30.393: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb 20 13:27:35.400: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 20 13:27:35.401: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb 20 13:27:39.434: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-3674 /apis/apps/v1/namespaces/deployment-3674/deployments/test-cleanup-deployment 07d76f8a-049e-45b1-b55e-9df89337baf6 235339 1 2020-02-20 13:27:35 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0029bd308 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-02-20 13:27:35 +0000 UTC,LastTransitionTime:2020-02-20 13:27:35 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-65db99849b" has successfully progressed.,LastUpdateTime:2020-02-20 13:27:37 +0000 UTC,LastTransitionTime:2020-02-20 13:27:35 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Feb 20 13:27:39.438: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-3674 /apis/apps/v1/namespaces/deployment-3674/replicasets/test-cleanup-deployment-65db99849b 348edeba-b806-4e24-8d13-5b3364f2d334 235329 1 2020-02-20 13:27:35 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 07d76f8a-049e-45b1-b55e-9df89337baf6 0xc0029bdd77 0xc0029bdd78}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0029bddd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb 20 13:27:39.442: INFO: Pod "test-cleanup-deployment-65db99849b-wr8s7" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-65db99849b-wr8s7 test-cleanup-deployment-65db99849b- deployment-3674 /api/v1/namespaces/deployment-3674/pods/test-cleanup-deployment-65db99849b-wr8s7 d694e10b-e662-49db-97be-42777a342272 235328 0 2020-02-20 13:27:35 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-65db99849b 348edeba-b806-4e24-8d13-5b3364f2d334 0xc00222e2f7 0xc00222e2f8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-lwgng,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-lwgng,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-lwgng,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 13:27:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 13:27:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 13:27:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 13:27:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.8,PodIP:10.100.81.190,StartTime:2020-02-20 13:27:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-20 13:27:36 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://b6c955e4a53e5ce0ae499c0fa271ef4b493efa704ae786e319c7c49a3574316d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.81.190,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:27:39.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3674" for this suite.
Feb 20 13:27:45.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:27:45.685: INFO: namespace deployment-3674 deletion completed in 6.235383681s

• [SLOW TEST:15.449 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:27:45.689: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6791
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 20 13:27:45.875: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1d3508b5-4584-4a57-adf6-f0bee25f8da3" in namespace "downward-api-6791" to be "success or failure"
Feb 20 13:27:45.878: INFO: Pod "downwardapi-volume-1d3508b5-4584-4a57-adf6-f0bee25f8da3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.460406ms
Feb 20 13:27:47.882: INFO: Pod "downwardapi-volume-1d3508b5-4584-4a57-adf6-f0bee25f8da3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006978702s
Feb 20 13:27:49.887: INFO: Pod "downwardapi-volume-1d3508b5-4584-4a57-adf6-f0bee25f8da3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011196501s
STEP: Saw pod success
Feb 20 13:27:49.887: INFO: Pod "downwardapi-volume-1d3508b5-4584-4a57-adf6-f0bee25f8da3" satisfied condition "success or failure"
Feb 20 13:27:49.890: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod downwardapi-volume-1d3508b5-4584-4a57-adf6-f0bee25f8da3 container client-container: <nil>
STEP: delete the pod
Feb 20 13:27:49.939: INFO: Waiting for pod downwardapi-volume-1d3508b5-4584-4a57-adf6-f0bee25f8da3 to disappear
Feb 20 13:27:49.941: INFO: Pod downwardapi-volume-1d3508b5-4584-4a57-adf6-f0bee25f8da3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:27:49.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6791" for this suite.
Feb 20 13:27:55.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:27:56.069: INFO: namespace downward-api-6791 deletion completed in 6.121833359s

• [SLOW TEST:10.380 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:27:56.078: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9746
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 20 13:27:56.275: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3ac944e0-bf47-42f4-8f31-654e286e3afc" in namespace "downward-api-9746" to be "success or failure"
Feb 20 13:27:56.283: INFO: Pod "downwardapi-volume-3ac944e0-bf47-42f4-8f31-654e286e3afc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.970197ms
Feb 20 13:27:58.289: INFO: Pod "downwardapi-volume-3ac944e0-bf47-42f4-8f31-654e286e3afc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013885357s
Feb 20 13:28:00.294: INFO: Pod "downwardapi-volume-3ac944e0-bf47-42f4-8f31-654e286e3afc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019132362s
STEP: Saw pod success
Feb 20 13:28:00.295: INFO: Pod "downwardapi-volume-3ac944e0-bf47-42f4-8f31-654e286e3afc" satisfied condition "success or failure"
Feb 20 13:28:00.298: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod downwardapi-volume-3ac944e0-bf47-42f4-8f31-654e286e3afc container client-container: <nil>
STEP: delete the pod
Feb 20 13:28:00.317: INFO: Waiting for pod downwardapi-volume-3ac944e0-bf47-42f4-8f31-654e286e3afc to disappear
Feb 20 13:28:00.320: INFO: Pod downwardapi-volume-3ac944e0-bf47-42f4-8f31-654e286e3afc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:28:00.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9746" for this suite.
Feb 20 13:28:06.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:28:06.451: INFO: namespace downward-api-9746 deletion completed in 6.120467509s

• [SLOW TEST:10.374 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:28:06.459: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8875
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-727833e6-61c6-49c7-93ec-df629cca48bf in namespace container-probe-8875
Feb 20 13:28:10.632: INFO: Started pod liveness-727833e6-61c6-49c7-93ec-df629cca48bf in namespace container-probe-8875
STEP: checking the pod's current state and verifying that restartCount is present
Feb 20 13:28:10.635: INFO: Initial restart count of pod liveness-727833e6-61c6-49c7-93ec-df629cca48bf is 0
Feb 20 13:28:22.674: INFO: Restart count of pod container-probe-8875/liveness-727833e6-61c6-49c7-93ec-df629cca48bf is now 1 (12.038911113s elapsed)
Feb 20 13:28:42.767: INFO: Restart count of pod container-probe-8875/liveness-727833e6-61c6-49c7-93ec-df629cca48bf is now 2 (32.132413533s elapsed)
Feb 20 13:29:00.813: INFO: Restart count of pod container-probe-8875/liveness-727833e6-61c6-49c7-93ec-df629cca48bf is now 3 (50.177689764s elapsed)
Feb 20 13:29:22.892: INFO: Restart count of pod container-probe-8875/liveness-727833e6-61c6-49c7-93ec-df629cca48bf is now 4 (1m12.256953222s elapsed)
Feb 20 13:30:23.058: INFO: Restart count of pod container-probe-8875/liveness-727833e6-61c6-49c7-93ec-df629cca48bf is now 5 (2m12.423027947s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:30:23.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8875" for this suite.
Feb 20 13:30:29.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:30:29.254: INFO: namespace container-probe-8875 deletion completed in 6.173680011s

• [SLOW TEST:142.796 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:30:29.260: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5370
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 13:30:29.420: INFO: Creating deployment "test-recreate-deployment"
Feb 20 13:30:29.427: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 20 13:30:29.485: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Feb 20 13:30:31.493: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 20 13:30:31.496: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717802229, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717802229, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717802229, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717802229, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-68fc85c7bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 13:30:33.503: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb 20 13:30:33.515: INFO: Updating deployment test-recreate-deployment
Feb 20 13:30:33.515: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb 20 13:30:33.614: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-5370 /apis/apps/v1/namespaces/deployment-5370/deployments/test-recreate-deployment 04b4e97c-69c2-4bb4-9808-295f53b73c65 236027 2 2020-02-20 13:30:29 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0023c64b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-02-20 13:30:33 +0000 UTC,LastTransitionTime:2020-02-20 13:30:33 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2020-02-20 13:30:33 +0000 UTC,LastTransitionTime:2020-02-20 13:30:29 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Feb 20 13:30:33.618: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-5370 /apis/apps/v1/namespaces/deployment-5370/replicasets/test-recreate-deployment-5f94c574ff 2513bc1c-d7cf-4596-a552-314119272100 236024 1 2020-02-20 13:30:33 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 04b4e97c-69c2-4bb4-9808-295f53b73c65 0xc0023c68c7 0xc0023c68c8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0023c6928 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 20 13:30:33.618: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 20 13:30:33.619: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-5370 /apis/apps/v1/namespaces/deployment-5370/replicasets/test-recreate-deployment-68fc85c7bb ee47b153-e8ee-4dc1-91d0-98e1c480bcae 236015 2 2020-02-20 13:30:29 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 04b4e97c-69c2-4bb4-9808-295f53b73c65 0xc0023c69a7 0xc0023c69a8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0023c6a28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 20 13:30:33.624: INFO: Pod "test-recreate-deployment-5f94c574ff-x9bm8" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-x9bm8 test-recreate-deployment-5f94c574ff- deployment-5370 /api/v1/namespaces/deployment-5370/pods/test-recreate-deployment-5f94c574ff-x9bm8 ef84512b-311e-4107-9757-05de52225f23 236028 0 2020-02-20 13:30:33 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff 2513bc1c-d7cf-4596-a552-314119272100 0xc0023c6f77 0xc0023c6f78}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zjvqv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zjvqv,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zjvqv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 13:30:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 13:30:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 13:30:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 13:30:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.29,PodIP:,StartTime:2020-02-20 13:30:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:30:33.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5370" for this suite.
Feb 20 13:30:39.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:30:39.767: INFO: namespace deployment-5370 deletion completed in 6.137120677s

• [SLOW TEST:10.508 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:30:39.775: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4695
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-58aff890-9ffe-4146-bd84-e9d3e3b493fa
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-58aff890-9ffe-4146-bd84-e9d3e3b493fa
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:30:44.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4695" for this suite.
Feb 20 13:30:56.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:30:56.233: INFO: namespace configmap-4695 deletion completed in 12.127250342s

• [SLOW TEST:16.459 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:30:56.238: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6899
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-2774468f-cc80-4f7b-8aca-a17e12e747fc
STEP: Creating a pod to test consume configMaps
Feb 20 13:30:56.417: INFO: Waiting up to 5m0s for pod "pod-configmaps-78d482cf-2461-43c5-962d-f364164cbdba" in namespace "configmap-6899" to be "success or failure"
Feb 20 13:30:56.425: INFO: Pod "pod-configmaps-78d482cf-2461-43c5-962d-f364164cbdba": Phase="Pending", Reason="", readiness=false. Elapsed: 7.636252ms
Feb 20 13:30:58.434: INFO: Pod "pod-configmaps-78d482cf-2461-43c5-962d-f364164cbdba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016536701s
Feb 20 13:31:00.442: INFO: Pod "pod-configmaps-78d482cf-2461-43c5-962d-f364164cbdba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024779683s
STEP: Saw pod success
Feb 20 13:31:00.443: INFO: Pod "pod-configmaps-78d482cf-2461-43c5-962d-f364164cbdba" satisfied condition "success or failure"
Feb 20 13:31:00.446: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod pod-configmaps-78d482cf-2461-43c5-962d-f364164cbdba container configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 13:31:00.519: INFO: Waiting for pod pod-configmaps-78d482cf-2461-43c5-962d-f364164cbdba to disappear
Feb 20 13:31:00.523: INFO: Pod pod-configmaps-78d482cf-2461-43c5-962d-f364164cbdba no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:31:00.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6899" for this suite.
Feb 20 13:31:06.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:31:06.634: INFO: namespace configmap-6899 deletion completed in 6.103200524s

• [SLOW TEST:10.396 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:31:06.649: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-326
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-326
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 20 13:31:06.825: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 20 13:31:26.925: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.100.99.180:8080/dial?request=hostName&protocol=udp&host=10.100.99.179&port=8081&tries=1'] Namespace:pod-network-test-326 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 13:31:26.926: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
Feb 20 13:31:27.177: INFO: Waiting for endpoints: map[]
Feb 20 13:31:27.181: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.100.99.180:8080/dial?request=hostName&protocol=udp&host=10.100.81.131&port=8081&tries=1'] Namespace:pod-network-test-326 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 13:31:27.181: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
Feb 20 13:31:27.404: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:31:27.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-326" for this suite.
Feb 20 13:31:39.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:31:39.540: INFO: namespace pod-network-test-326 deletion completed in 12.128718896s

• [SLOW TEST:32.893 seconds]
[sig-network] Networking
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:31:39.561: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6070
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 20 13:31:40.899: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 20 13:31:42.909: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717802300, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717802300, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717802300, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717802300, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 20 13:31:45.930: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:31:46.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6070" for this suite.
Feb 20 13:31:58.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:31:58.182: INFO: namespace webhook-6070 deletion completed in 12.172470194s
STEP: Destroying namespace "webhook-6070-markers" for this suite.
Feb 20 13:32:04.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:32:04.306: INFO: namespace webhook-6070-markers deletion completed in 6.123564235s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.759 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:32:04.325: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-2912
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2563
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-5274
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:32:10.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2912" for this suite.
Feb 20 13:32:16.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:32:17.009: INFO: namespace namespaces-2912 deletion completed in 6.133466854s
STEP: Destroying namespace "nsdeletetest-2563" for this suite.
Feb 20 13:32:17.012: INFO: Namespace nsdeletetest-2563 was already deleted
STEP: Destroying namespace "nsdeletetest-5274" for this suite.
Feb 20 13:32:23.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:32:23.126: INFO: namespace nsdeletetest-5274 deletion completed in 6.113843593s

• [SLOW TEST:18.802 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:32:23.133: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4254
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4254.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-4254.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4254.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4254.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-4254.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4254.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 20 13:32:27.346: INFO: DNS probes using dns-4254/dns-test-0bbef785-1707-4db0-8185-c8ab1d3a78f5 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:32:27.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4254" for this suite.
Feb 20 13:32:33.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:32:33.512: INFO: namespace dns-4254 deletion completed in 6.13261639s

• [SLOW TEST:10.380 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:32:33.518: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5474
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5474.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5474.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5474.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5474.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5474.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5474.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5474.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5474.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5474.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5474.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5474.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 90.88.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.88.90_udp@PTR;check="$$(dig +tcp +noall +answer +search 90.88.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.88.90_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5474.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5474.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5474.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5474.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5474.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5474.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5474.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5474.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5474.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5474.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5474.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 90.88.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.88.90_udp@PTR;check="$$(dig +tcp +noall +answer +search 90.88.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.88.90_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 20 13:32:37.736: INFO: Unable to read wheezy_udp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:37.744: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:37.749: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:37.753: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:37.784: INFO: Unable to read jessie_udp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:37.789: INFO: Unable to read jessie_tcp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:37.801: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:37.804: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:37.826: INFO: Lookups using dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3 failed for: [wheezy_udp@dns-test-service.dns-5474.svc.cluster.local wheezy_tcp@dns-test-service.dns-5474.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local jessie_udp@dns-test-service.dns-5474.svc.cluster.local jessie_tcp@dns-test-service.dns-5474.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local]

Feb 20 13:32:42.832: INFO: Unable to read wheezy_udp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:42.836: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:42.840: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:42.844: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:42.869: INFO: Unable to read jessie_udp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:42.873: INFO: Unable to read jessie_tcp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:42.879: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:42.884: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:42.907: INFO: Lookups using dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3 failed for: [wheezy_udp@dns-test-service.dns-5474.svc.cluster.local wheezy_tcp@dns-test-service.dns-5474.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local jessie_udp@dns-test-service.dns-5474.svc.cluster.local jessie_tcp@dns-test-service.dns-5474.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local]

Feb 20 13:32:47.835: INFO: Unable to read wheezy_udp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:47.840: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:47.844: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:47.849: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:47.880: INFO: Unable to read jessie_udp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:47.886: INFO: Unable to read jessie_tcp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:47.890: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:47.907: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:47.936: INFO: Lookups using dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3 failed for: [wheezy_udp@dns-test-service.dns-5474.svc.cluster.local wheezy_tcp@dns-test-service.dns-5474.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local jessie_udp@dns-test-service.dns-5474.svc.cluster.local jessie_tcp@dns-test-service.dns-5474.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local]

Feb 20 13:32:52.833: INFO: Unable to read wheezy_udp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:52.837: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:52.841: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:52.845: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:52.872: INFO: Unable to read jessie_udp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:52.880: INFO: Unable to read jessie_tcp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:52.885: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:52.889: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:52.907: INFO: Lookups using dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3 failed for: [wheezy_udp@dns-test-service.dns-5474.svc.cluster.local wheezy_tcp@dns-test-service.dns-5474.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local jessie_udp@dns-test-service.dns-5474.svc.cluster.local jessie_tcp@dns-test-service.dns-5474.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local]

Feb 20 13:32:57.832: INFO: Unable to read wheezy_udp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:57.836: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:57.840: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:57.844: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:57.874: INFO: Unable to read jessie_udp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:57.879: INFO: Unable to read jessie_tcp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:57.883: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:57.887: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:32:57.912: INFO: Lookups using dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3 failed for: [wheezy_udp@dns-test-service.dns-5474.svc.cluster.local wheezy_tcp@dns-test-service.dns-5474.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local jessie_udp@dns-test-service.dns-5474.svc.cluster.local jessie_tcp@dns-test-service.dns-5474.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local]

Feb 20 13:33:02.833: INFO: Unable to read wheezy_udp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:33:02.839: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:33:02.844: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:33:02.852: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:33:02.892: INFO: Unable to read jessie_udp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:33:02.897: INFO: Unable to read jessie_tcp@dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:33:02.903: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:33:02.910: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local from pod dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3: the server could not find the requested resource (get pods dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3)
Feb 20 13:33:02.938: INFO: Lookups using dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3 failed for: [wheezy_udp@dns-test-service.dns-5474.svc.cluster.local wheezy_tcp@dns-test-service.dns-5474.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local jessie_udp@dns-test-service.dns-5474.svc.cluster.local jessie_tcp@dns-test-service.dns-5474.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5474.svc.cluster.local]

Feb 20 13:33:07.913: INFO: DNS probes using dns-5474/dns-test-8c8b10f7-d06c-4421-a651-4d61867cf8a3 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:33:07.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5474" for this suite.
Feb 20 13:33:14.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:33:14.150: INFO: namespace dns-5474 deletion completed in 6.15134966s

• [SLOW TEST:40.634 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:33:14.156: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7467
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0220 13:33:15.855816      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 20 13:33:15.856: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:33:15.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7467" for this suite.
Feb 20 13:33:21.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:33:21.994: INFO: namespace gc-7467 deletion completed in 6.133774484s

• [SLOW TEST:7.839 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:33:22.004: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8665
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 20 13:33:22.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-8665'
Feb 20 13:33:22.785: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 20 13:33:22.785: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: rolling-update to same image controller
Feb 20 13:33:22.813: INFO: scanned /root for discovery docs: <nil>
Feb 20 13:33:22.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-8665'
Feb 20 13:33:38.781: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 20 13:33:38.781: INFO: stdout: "Created e2e-test-httpd-rc-8ab23f40592b54b44d210ca37679f3c3\nScaling up e2e-test-httpd-rc-8ab23f40592b54b44d210ca37679f3c3 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-8ab23f40592b54b44d210ca37679f3c3 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-8ab23f40592b54b44d210ca37679f3c3 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Feb 20 13:33:38.781: INFO: stdout: "Created e2e-test-httpd-rc-8ab23f40592b54b44d210ca37679f3c3\nScaling up e2e-test-httpd-rc-8ab23f40592b54b44d210ca37679f3c3 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-8ab23f40592b54b44d210ca37679f3c3 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-8ab23f40592b54b44d210ca37679f3c3 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Feb 20 13:33:38.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-8665'
Feb 20 13:33:38.977: INFO: stderr: ""
Feb 20 13:33:38.977: INFO: stdout: "e2e-test-httpd-rc-8ab23f40592b54b44d210ca37679f3c3-qq7tk "
Feb 20 13:33:38.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods e2e-test-httpd-rc-8ab23f40592b54b44d210ca37679f3c3-qq7tk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8665'
Feb 20 13:33:39.131: INFO: stderr: ""
Feb 20 13:33:39.131: INFO: stdout: "true"
Feb 20 13:33:39.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods e2e-test-httpd-rc-8ab23f40592b54b44d210ca37679f3c3-qq7tk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8665'
Feb 20 13:33:39.298: INFO: stderr: ""
Feb 20 13:33:39.299: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Feb 20 13:33:39.299: INFO: e2e-test-httpd-rc-8ab23f40592b54b44d210ca37679f3c3-qq7tk is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Feb 20 13:33:39.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 delete rc e2e-test-httpd-rc --namespace=kubectl-8665'
Feb 20 13:33:39.475: INFO: stderr: ""
Feb 20 13:33:39.475: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:33:39.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8665" for this suite.
Feb 20 13:33:45.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:33:45.599: INFO: namespace kubectl-8665 deletion completed in 6.110632371s

• [SLOW TEST:23.596 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:33:45.605: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1692
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb 20 13:33:50.364: INFO: Successfully updated pod "annotationupdate85b4b8f8-617e-4955-8fd1-05cb3266b0ca"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:33:52.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1692" for this suite.
Feb 20 13:34:04.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:34:04.501: INFO: namespace downward-api-1692 deletion completed in 12.112431564s

• [SLOW TEST:18.897 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:34:04.512: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5751
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Feb 20 13:34:04.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 create -f - --namespace=kubectl-5751'
Feb 20 13:34:05.213: INFO: stderr: ""
Feb 20 13:34:05.213: INFO: stdout: "pod/pause created\n"
Feb 20 13:34:05.213: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 20 13:34:05.213: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-5751" to be "running and ready"
Feb 20 13:34:05.218: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.689708ms
Feb 20 13:34:07.222: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009360011s
Feb 20 13:34:09.227: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.014126177s
Feb 20 13:34:09.227: INFO: Pod "pause" satisfied condition "running and ready"
Feb 20 13:34:09.227: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 20 13:34:09.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 label pods pause testing-label=testing-label-value --namespace=kubectl-5751'
Feb 20 13:34:09.384: INFO: stderr: ""
Feb 20 13:34:09.385: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 20 13:34:09.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pod pause -L testing-label --namespace=kubectl-5751'
Feb 20 13:34:09.562: INFO: stderr: ""
Feb 20 13:34:09.562: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 20 13:34:09.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 label pods pause testing-label- --namespace=kubectl-5751'
Feb 20 13:34:09.688: INFO: stderr: ""
Feb 20 13:34:09.688: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 20 13:34:09.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pod pause -L testing-label --namespace=kubectl-5751'
Feb 20 13:34:09.815: INFO: stderr: ""
Feb 20 13:34:09.815: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Feb 20 13:34:09.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 delete --grace-period=0 --force -f - --namespace=kubectl-5751'
Feb 20 13:34:09.977: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 13:34:09.977: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 20 13:34:09.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get rc,svc -l name=pause --no-headers --namespace=kubectl-5751'
Feb 20 13:34:10.125: INFO: stderr: "No resources found in kubectl-5751 namespace.\n"
Feb 20 13:34:10.125: INFO: stdout: ""
Feb 20 13:34:10.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods -l name=pause --namespace=kubectl-5751 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 20 13:34:10.257: INFO: stderr: ""
Feb 20 13:34:10.257: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:34:10.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5751" for this suite.
Feb 20 13:34:16.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:34:16.393: INFO: namespace kubectl-5751 deletion completed in 6.121085441s

• [SLOW TEST:11.882 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:34:16.398: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-7971
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9175
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-6826
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:34:32.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7971" for this suite.
Feb 20 13:34:38.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:34:38.159: INFO: namespace namespaces-7971 deletion completed in 6.127786752s
STEP: Destroying namespace "nsdeletetest-9175" for this suite.
Feb 20 13:34:38.162: INFO: Namespace nsdeletetest-9175 was already deleted
STEP: Destroying namespace "nsdeletetest-6826" for this suite.
Feb 20 13:34:44.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:34:44.280: INFO: namespace nsdeletetest-6826 deletion completed in 6.118446359s

• [SLOW TEST:27.883 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:34:44.287: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9922
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 20 13:34:44.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-9922'
Feb 20 13:34:44.604: INFO: stderr: ""
Feb 20 13:34:44.604: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Feb 20 13:34:44.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 delete pods e2e-test-httpd-pod --namespace=kubectl-9922'
Feb 20 13:34:51.388: INFO: stderr: ""
Feb 20 13:34:51.388: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:34:51.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9922" for this suite.
Feb 20 13:34:57.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:34:57.509: INFO: namespace kubectl-9922 deletion completed in 6.113755485s

• [SLOW TEST:13.223 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:34:57.521: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-75
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 13:34:57.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 version'
Feb 20 13:34:57.820: INFO: stderr: ""
Feb 20 13:34:57.820: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.4\", GitCommit:\"224be7bdce5a9dd0c2fd0d46b83865648e2fe0ba\", GitTreeState:\"clean\", BuildDate:\"2019-12-11T12:47:40Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.4\", GitCommit:\"2bba0127d85d5a46ab4b778548be28623b32d0b0\", GitTreeState:\"clean\", BuildDate:\"2020-01-15T12:55:44Z\", GoVersion:\"go1.12.7\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:34:57.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-75" for this suite.
Feb 20 13:35:03.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:35:03.932: INFO: namespace kubectl-75 deletion completed in 6.106332738s

• [SLOW TEST:6.412 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:35:03.938: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4618
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 13:35:04.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 create -f - --namespace=kubectl-4618'
Feb 20 13:35:04.675: INFO: stderr: ""
Feb 20 13:35:04.675: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb 20 13:35:04.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 create -f - --namespace=kubectl-4618'
Feb 20 13:35:05.204: INFO: stderr: ""
Feb 20 13:35:05.204: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 20 13:35:06.209: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 13:35:06.209: INFO: Found 0 / 1
Feb 20 13:35:07.258: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 13:35:07.258: INFO: Found 0 / 1
Feb 20 13:35:08.208: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 13:35:08.208: INFO: Found 1 / 1
Feb 20 13:35:08.208: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 20 13:35:08.211: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 13:35:08.211: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 20 13:35:08.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 describe pod redis-master-dwkbg --namespace=kubectl-4618'
Feb 20 13:35:08.365: INFO: stderr: ""
Feb 20 13:35:08.365: INFO: stdout: "Name:         redis-master-dwkbg\nNamespace:    kubectl-4618\nNode:         kube16prod-img-kube16prod-img-minion-2/10.0.0.8\nStart Time:   Thu, 20 Feb 2020 13:35:04 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nStatus:       Running\nIP:           10.100.81.136\nIPs:\n  IP:           10.100.81.136\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://1605d83794f261d441613f25fc068e24c49ed25e78fdbc8e25a0210559ea6a56\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 20 Feb 2020 13:35:07 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-4zbdh (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-4zbdh:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-4zbdh\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     <none>\nEvents:\n  Type    Reason     Age   From                                             Message\n  ----    ------     ----  ----                                             -------\n  Normal  Scheduled  4s    default-scheduler                                Successfully assigned kubectl-4618/redis-master-dwkbg to kube16prod-img-kube16prod-img-minion-2\n  Normal  Pulled     1s    kubelet, kube16prod-img-kube16prod-img-minion-2  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    1s    kubelet, kube16prod-img-kube16prod-img-minion-2  Created container redis-master\n  Normal  Started    1s    kubelet, kube16prod-img-kube16prod-img-minion-2  Started container redis-master\n"
Feb 20 13:35:08.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 describe rc redis-master --namespace=kubectl-4618'
Feb 20 13:35:08.547: INFO: stderr: ""
Feb 20 13:35:08.547: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-4618\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-dwkbg\n"
Feb 20 13:35:08.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 describe service redis-master --namespace=kubectl-4618'
Feb 20 13:35:08.822: INFO: stderr: ""
Feb 20 13:35:08.822: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-4618\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.254.166.23\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.100.81.136:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 20 13:35:08.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 describe node kube16prod-img-kube16prod-img-minion-1'
Feb 20 13:35:09.064: INFO: stderr: ""
Feb 20 13:35:09.064: INFO: stdout: "Name:               kube16prod-img-kube16prod-img-minion-1\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=25ae869c-be29-4840-8e12-99e046d2dbd4\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/zone=MS1\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=kube16prod-img-kube16prod-img-minion-1\n                    kubernetes.io/os=linux\n                    mcs.mail.ru/mcs-nodepool=kube16prod-img-minion\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 20 Feb 2020 10:28:10 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Thu, 20 Feb 2020 13:34:10 +0000   Thu, 20 Feb 2020 10:28:10 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Thu, 20 Feb 2020 13:34:10 +0000   Thu, 20 Feb 2020 10:28:10 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Thu, 20 Feb 2020 13:34:10 +0000   Thu, 20 Feb 2020 10:28:10 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Thu, 20 Feb 2020 13:34:10 +0000   Thu, 20 Feb 2020 10:28:30 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.0.0.29\n  Hostname:    kube16prod-img-kube16prod-img-minion-1\nCapacity:\n attachable-volumes-cinder:  256\n cpu:                        1\n ephemeral-storage:          50162Mi\n hugepages-1Gi:              0\n hugepages-2Mi:              0\n memory:                     2040196Ki\n pods:                       110\nAllocatable:\n attachable-volumes-cinder:  256\n cpu:                        800m\n ephemeral-storage:          43043835007\n hugepages-1Gi:              0\n hugepages-2Mi:              0\n memory:                     1323396Ki\n pods:                       110\nSystem Info:\n Machine ID:                 ac866e45b3734ba49152c18379c3ae4d\n System UUID:                3fdce615-cb7e-4941-ad4b-30c2e0fe1cda\n Boot ID:                    e5252f86-3ed1-4eba-8cdd-4edd252fdbdb\n Kernel Version:             4.18.11-200.fc28.x86_64\n OS Image:                   Fedora 28.20181007.0 (Atomic Host)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.3.1\n Kubelet Version:            v1.16.4\n Kube-Proxy Version:         v1.16.4\nProviderID:                  openstack:///3fdce615-cb7e-4941-ad4b-30c2e0fe1cda\nNon-terminated Pods:         (5 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                calico-kube-controllers-555d6f4bd9-xfg9t                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         158m\n  kube-system                calico-node-vkbjk                                          250m (31%)    0 (0%)      0 (0%)           0 (0%)         3h6m\n  kube-system                metrics-server-f96ddff8f-h2kx6                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         174m\n  prometheus-monitoring      prometheus-operator-prometheus-node-exporter-c2v94         0 (0%)        0 (0%)      0 (0%)           0 (0%)         3h6m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-27e71f1a82d14495-ggbs7    0 (0%)        0 (0%)      0 (0%)           0 (0%)         70m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                   Requests    Limits\n  --------                   --------    ------\n  cpu                        250m (31%)  0 (0%)\n  memory                     0 (0%)      0 (0%)\n  ephemeral-storage          0 (0%)      0 (0%)\n  attachable-volumes-cinder  0           0\nEvents:                      <none>\n"
Feb 20 13:35:09.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 describe namespace kubectl-4618'
Feb 20 13:35:09.218: INFO: stderr: ""
Feb 20 13:35:09.218: INFO: stdout: "Name:         kubectl-4618\nLabels:       e2e-framework=kubectl\n              e2e-run=12997d22-1f8a-4b40-b29e-175ec55fa231\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:35:09.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4618" for this suite.
Feb 20 13:35:37.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:35:37.347: INFO: namespace kubectl-4618 deletion completed in 28.123178237s

• [SLOW TEST:33.411 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:35:37.356: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-9721
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Feb 20 13:35:37.725: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Feb 20 13:35:39.739: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717802537, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717802537, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717802537, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717802537, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 20 13:35:42.761: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 13:35:42.766: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:35:43.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-9721" for this suite.
Feb 20 13:35:49.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:35:50.097: INFO: namespace crd-webhook-9721 deletion completed in 6.151240509s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:12.767 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:35:50.132: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-561
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb 20 13:35:52.905: INFO: Successfully updated pod "labelsupdatec46a36b5-b7d8-4e60-95d4-5f77d1822ff6"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:35:54.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-561" for this suite.
Feb 20 13:36:06.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:36:07.052: INFO: namespace projected-561 deletion completed in 12.122270353s

• [SLOW TEST:16.921 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:36:07.067: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-55
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 20 13:36:07.220: INFO: Waiting up to 5m0s for pod "pod-ebb3a9e8-2c3a-43c3-b392-e26f91268e90" in namespace "emptydir-55" to be "success or failure"
Feb 20 13:36:07.228: INFO: Pod "pod-ebb3a9e8-2c3a-43c3-b392-e26f91268e90": Phase="Pending", Reason="", readiness=false. Elapsed: 7.816737ms
Feb 20 13:36:09.240: INFO: Pod "pod-ebb3a9e8-2c3a-43c3-b392-e26f91268e90": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019055575s
Feb 20 13:36:11.246: INFO: Pod "pod-ebb3a9e8-2c3a-43c3-b392-e26f91268e90": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025024952s
STEP: Saw pod success
Feb 20 13:36:11.246: INFO: Pod "pod-ebb3a9e8-2c3a-43c3-b392-e26f91268e90" satisfied condition "success or failure"
Feb 20 13:36:11.250: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod pod-ebb3a9e8-2c3a-43c3-b392-e26f91268e90 container test-container: <nil>
STEP: delete the pod
Feb 20 13:36:11.304: INFO: Waiting for pod pod-ebb3a9e8-2c3a-43c3-b392-e26f91268e90 to disappear
Feb 20 13:36:11.309: INFO: Pod pod-ebb3a9e8-2c3a-43c3-b392-e26f91268e90 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:36:11.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-55" for this suite.
Feb 20 13:36:17.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:36:17.450: INFO: namespace emptydir-55 deletion completed in 6.136996654s

• [SLOW TEST:10.384 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:36:17.455: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2832
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 20 13:36:17.645: INFO: Waiting up to 5m0s for pod "downwardapi-volume-48b95043-17ed-455e-b1e5-fc8720dc8ade" in namespace "downward-api-2832" to be "success or failure"
Feb 20 13:36:17.651: INFO: Pod "downwardapi-volume-48b95043-17ed-455e-b1e5-fc8720dc8ade": Phase="Pending", Reason="", readiness=false. Elapsed: 5.209527ms
Feb 20 13:36:19.657: INFO: Pod "downwardapi-volume-48b95043-17ed-455e-b1e5-fc8720dc8ade": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011661006s
STEP: Saw pod success
Feb 20 13:36:19.658: INFO: Pod "downwardapi-volume-48b95043-17ed-455e-b1e5-fc8720dc8ade" satisfied condition "success or failure"
Feb 20 13:36:19.662: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod downwardapi-volume-48b95043-17ed-455e-b1e5-fc8720dc8ade container client-container: <nil>
STEP: delete the pod
Feb 20 13:36:19.681: INFO: Waiting for pod downwardapi-volume-48b95043-17ed-455e-b1e5-fc8720dc8ade to disappear
Feb 20 13:36:19.684: INFO: Pod downwardapi-volume-48b95043-17ed-455e-b1e5-fc8720dc8ade no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:36:19.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2832" for this suite.
Feb 20 13:36:25.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:36:25.799: INFO: namespace downward-api-2832 deletion completed in 6.109531469s

• [SLOW TEST:8.345 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:36:25.811: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1081
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-acaec66e-b8d2-4d5a-a5ec-c4bc60891f95
STEP: Creating a pod to test consume secrets
Feb 20 13:36:25.991: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-22c2a0e5-a738-491d-bb95-ac9385332d8f" in namespace "projected-1081" to be "success or failure"
Feb 20 13:36:26.003: INFO: Pod "pod-projected-secrets-22c2a0e5-a738-491d-bb95-ac9385332d8f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.968871ms
Feb 20 13:36:28.025: INFO: Pod "pod-projected-secrets-22c2a0e5-a738-491d-bb95-ac9385332d8f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033663991s
Feb 20 13:36:30.032: INFO: Pod "pod-projected-secrets-22c2a0e5-a738-491d-bb95-ac9385332d8f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040375162s
STEP: Saw pod success
Feb 20 13:36:30.032: INFO: Pod "pod-projected-secrets-22c2a0e5-a738-491d-bb95-ac9385332d8f" satisfied condition "success or failure"
Feb 20 13:36:30.035: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod pod-projected-secrets-22c2a0e5-a738-491d-bb95-ac9385332d8f container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 20 13:36:30.064: INFO: Waiting for pod pod-projected-secrets-22c2a0e5-a738-491d-bb95-ac9385332d8f to disappear
Feb 20 13:36:30.066: INFO: Pod pod-projected-secrets-22c2a0e5-a738-491d-bb95-ac9385332d8f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:36:30.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1081" for this suite.
Feb 20 13:36:36.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:36:36.188: INFO: namespace projected-1081 deletion completed in 6.115886397s

• [SLOW TEST:10.378 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:36:36.196: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4655
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 20 13:36:36.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-4655'
Feb 20 13:36:36.536: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 20 13:36:36.536: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Feb 20 13:36:36.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 delete deployment e2e-test-httpd-deployment --namespace=kubectl-4655'
Feb 20 13:36:36.710: INFO: stderr: ""
Feb 20 13:36:36.710: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:36:36.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4655" for this suite.
Feb 20 13:36:42.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:36:42.825: INFO: namespace kubectl-4655 deletion completed in 6.111754803s

• [SLOW TEST:6.631 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:36:42.830: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6524
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 20 13:36:44.192: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717802604, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717802604, loc:(*time.Location)(0x84bfb00)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-86d95b659d\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717802604, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717802604, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Feb 20 13:36:46.197: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717802604, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717802604, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717802604, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717802604, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 20 13:36:49.211: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:36:49.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6524" for this suite.
Feb 20 13:36:55.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:36:55.417: INFO: namespace webhook-6524 deletion completed in 6.148967129s
STEP: Destroying namespace "webhook-6524-markers" for this suite.
Feb 20 13:37:01.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:37:01.564: INFO: namespace webhook-6524-markers deletion completed in 6.146472267s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.754 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:37:01.593: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-534
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 20 13:37:01.804: INFO: Waiting up to 5m0s for pod "pod-9b93b82d-4fc5-44a4-91e8-505a4c071621" in namespace "emptydir-534" to be "success or failure"
Feb 20 13:37:01.811: INFO: Pod "pod-9b93b82d-4fc5-44a4-91e8-505a4c071621": Phase="Pending", Reason="", readiness=false. Elapsed: 5.833173ms
Feb 20 13:37:03.821: INFO: Pod "pod-9b93b82d-4fc5-44a4-91e8-505a4c071621": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015789136s
STEP: Saw pod success
Feb 20 13:37:03.822: INFO: Pod "pod-9b93b82d-4fc5-44a4-91e8-505a4c071621" satisfied condition "success or failure"
Feb 20 13:37:03.825: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod pod-9b93b82d-4fc5-44a4-91e8-505a4c071621 container test-container: <nil>
STEP: delete the pod
Feb 20 13:37:03.844: INFO: Waiting for pod pod-9b93b82d-4fc5-44a4-91e8-505a4c071621 to disappear
Feb 20 13:37:03.852: INFO: Pod pod-9b93b82d-4fc5-44a4-91e8-505a4c071621 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:37:03.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-534" for this suite.
Feb 20 13:37:09.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:37:09.993: INFO: namespace emptydir-534 deletion completed in 6.135237389s

• [SLOW TEST:8.401 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:37:09.998: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7710
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Feb 20 13:37:10.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 create -f - --namespace=kubectl-7710'
Feb 20 13:37:10.663: INFO: stderr: ""
Feb 20 13:37:10.663: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 20 13:37:10.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7710'
Feb 20 13:37:10.863: INFO: stderr: ""
Feb 20 13:37:10.863: INFO: stdout: "update-demo-nautilus-nqvzw update-demo-nautilus-v5nw5 "
Feb 20 13:37:10.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-nautilus-nqvzw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7710'
Feb 20 13:37:11.101: INFO: stderr: ""
Feb 20 13:37:11.102: INFO: stdout: ""
Feb 20 13:37:11.102: INFO: update-demo-nautilus-nqvzw is created but not running
Feb 20 13:37:16.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7710'
Feb 20 13:37:16.273: INFO: stderr: ""
Feb 20 13:37:16.273: INFO: stdout: "update-demo-nautilus-nqvzw update-demo-nautilus-v5nw5 "
Feb 20 13:37:16.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-nautilus-nqvzw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7710'
Feb 20 13:37:16.421: INFO: stderr: ""
Feb 20 13:37:16.421: INFO: stdout: "true"
Feb 20 13:37:16.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-nautilus-nqvzw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7710'
Feb 20 13:37:16.561: INFO: stderr: ""
Feb 20 13:37:16.561: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 13:37:16.561: INFO: validating pod update-demo-nautilus-nqvzw
Feb 20 13:37:16.571: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 13:37:16.572: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 13:37:16.572: INFO: update-demo-nautilus-nqvzw is verified up and running
Feb 20 13:37:16.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-nautilus-v5nw5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7710'
Feb 20 13:37:16.694: INFO: stderr: ""
Feb 20 13:37:16.695: INFO: stdout: "true"
Feb 20 13:37:16.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods update-demo-nautilus-v5nw5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7710'
Feb 20 13:37:16.825: INFO: stderr: ""
Feb 20 13:37:16.825: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 20 13:37:16.825: INFO: validating pod update-demo-nautilus-v5nw5
Feb 20 13:37:16.832: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 20 13:37:16.832: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 20 13:37:16.832: INFO: update-demo-nautilus-v5nw5 is verified up and running
STEP: using delete to clean up resources
Feb 20 13:37:16.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 delete --grace-period=0 --force -f - --namespace=kubectl-7710'
Feb 20 13:37:16.975: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 13:37:16.975: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 20 13:37:16.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7710'
Feb 20 13:37:17.133: INFO: stderr: "No resources found in kubectl-7710 namespace.\n"
Feb 20 13:37:17.133: INFO: stdout: ""
Feb 20 13:37:17.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods -l name=update-demo --namespace=kubectl-7710 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 20 13:37:17.316: INFO: stderr: ""
Feb 20 13:37:17.316: INFO: stdout: "update-demo-nautilus-nqvzw\nupdate-demo-nautilus-v5nw5\n"
Feb 20 13:37:17.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7710'
Feb 20 13:37:18.053: INFO: stderr: "No resources found in kubectl-7710 namespace.\n"
Feb 20 13:37:18.053: INFO: stdout: ""
Feb 20 13:37:18.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 get pods -l name=update-demo --namespace=kubectl-7710 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 20 13:37:18.359: INFO: stderr: ""
Feb 20 13:37:18.359: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:37:18.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7710" for this suite.
Feb 20 13:37:46.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:37:46.555: INFO: namespace kubectl-7710 deletion completed in 28.182874231s

• [SLOW TEST:36.559 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:37:46.563: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-4008
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 13:37:46.714: INFO: Waiting up to 5m0s for pod "busybox-user-65534-e6915fc3-ef46-405b-ac01-2cb79b2d8568" in namespace "security-context-test-4008" to be "success or failure"
Feb 20 13:37:46.717: INFO: Pod "busybox-user-65534-e6915fc3-ef46-405b-ac01-2cb79b2d8568": Phase="Pending", Reason="", readiness=false. Elapsed: 3.398086ms
Feb 20 13:37:48.762: INFO: Pod "busybox-user-65534-e6915fc3-ef46-405b-ac01-2cb79b2d8568": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048367007s
Feb 20 13:37:50.769: INFO: Pod "busybox-user-65534-e6915fc3-ef46-405b-ac01-2cb79b2d8568": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055393317s
Feb 20 13:37:50.770: INFO: Pod "busybox-user-65534-e6915fc3-ef46-405b-ac01-2cb79b2d8568" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:37:50.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4008" for this suite.
Feb 20 13:37:56.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:37:56.907: INFO: namespace security-context-test-4008 deletion completed in 6.129577493s

• [SLOW TEST:10.346 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:37:56.930: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-7800
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-7800
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Feb 20 13:37:57.094: INFO: Found 0 stateful pods, waiting for 3
Feb 20 13:38:07.109: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 13:38:07.110: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 13:38:07.110: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 13:38:07.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-7800 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 20 13:38:07.408: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 20 13:38:07.408: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 20 13:38:07.408: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Feb 20 13:38:17.446: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 20 13:38:27.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-7800 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 13:38:27.755: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 20 13:38:27.755: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 20 13:38:27.755: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 20 13:38:37.782: INFO: Waiting for StatefulSet statefulset-7800/ss2 to complete update
Feb 20 13:38:37.784: INFO: Waiting for Pod statefulset-7800/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb 20 13:38:37.784: INFO: Waiting for Pod statefulset-7800/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb 20 13:38:37.784: INFO: Waiting for Pod statefulset-7800/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb 20 13:38:47.802: INFO: Waiting for StatefulSet statefulset-7800/ss2 to complete update
Feb 20 13:38:47.804: INFO: Waiting for Pod statefulset-7800/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb 20 13:38:47.804: INFO: Waiting for Pod statefulset-7800/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb 20 13:38:57.799: INFO: Waiting for StatefulSet statefulset-7800/ss2 to complete update
Feb 20 13:38:57.800: INFO: Waiting for Pod statefulset-7800/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb 20 13:38:57.800: INFO: Waiting for Pod statefulset-7800/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb 20 13:39:07.794: INFO: Waiting for StatefulSet statefulset-7800/ss2 to complete update
Feb 20 13:39:07.794: INFO: Waiting for Pod statefulset-7800/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb 20 13:39:17.794: INFO: Waiting for StatefulSet statefulset-7800/ss2 to complete update
Feb 20 13:39:17.796: INFO: Waiting for Pod statefulset-7800/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Feb 20 13:39:27.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-7800 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 20 13:39:28.089: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 20 13:39:28.089: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 20 13:39:28.089: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 20 13:39:38.133: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 20 13:39:48.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-7800 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 13:39:48.447: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 20 13:39:48.447: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 20 13:39:48.447: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 20 13:40:08.477: INFO: Waiting for StatefulSet statefulset-7800/ss2 to complete update
Feb 20 13:40:08.479: INFO: Waiting for Pod statefulset-7800/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 20 13:40:18.495: INFO: Deleting all statefulset in ns statefulset-7800
Feb 20 13:40:18.498: INFO: Scaling statefulset ss2 to 0
Feb 20 13:40:38.527: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 13:40:38.532: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:40:38.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7800" for this suite.
Feb 20 13:40:44.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:40:44.692: INFO: namespace statefulset-7800 deletion completed in 6.138306159s

• [SLOW TEST:167.763 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:40:44.700: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-789
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-8f14183e-477a-4257-9160-6b6b9f6d9a4f
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:40:49.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-789" for this suite.
Feb 20 13:41:17.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:41:17.152: INFO: namespace configmap-789 deletion completed in 28.144491257s

• [SLOW TEST:32.454 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:41:17.162: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4424
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 20 13:41:17.307: INFO: Waiting up to 5m0s for pod "pod-eb3287b6-7d15-4175-96d0-a04b43d4bdad" in namespace "emptydir-4424" to be "success or failure"
Feb 20 13:41:17.318: INFO: Pod "pod-eb3287b6-7d15-4175-96d0-a04b43d4bdad": Phase="Pending", Reason="", readiness=false. Elapsed: 10.843453ms
Feb 20 13:41:19.323: INFO: Pod "pod-eb3287b6-7d15-4175-96d0-a04b43d4bdad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015640397s
Feb 20 13:41:21.330: INFO: Pod "pod-eb3287b6-7d15-4175-96d0-a04b43d4bdad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02310261s
STEP: Saw pod success
Feb 20 13:41:21.333: INFO: Pod "pod-eb3287b6-7d15-4175-96d0-a04b43d4bdad" satisfied condition "success or failure"
Feb 20 13:41:21.338: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod pod-eb3287b6-7d15-4175-96d0-a04b43d4bdad container test-container: <nil>
STEP: delete the pod
Feb 20 13:41:21.366: INFO: Waiting for pod pod-eb3287b6-7d15-4175-96d0-a04b43d4bdad to disappear
Feb 20 13:41:21.372: INFO: Pod pod-eb3287b6-7d15-4175-96d0-a04b43d4bdad no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:41:21.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4424" for this suite.
Feb 20 13:41:27.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:41:27.512: INFO: namespace emptydir-4424 deletion completed in 6.134053289s

• [SLOW TEST:10.352 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:41:27.528: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3164
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3164
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Feb 20 13:41:27.725: INFO: Found 0 stateful pods, waiting for 3
Feb 20 13:41:37.741: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 13:41:37.745: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 13:41:37.745: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Feb 20 13:41:37.783: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 20 13:41:47.822: INFO: Updating stateful set ss2
Feb 20 13:41:47.835: INFO: Waiting for Pod statefulset-3164/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Feb 20 13:41:57.898: INFO: Found 1 stateful pods, waiting for 3
Feb 20 13:42:07.907: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 13:42:07.908: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 13:42:07.908: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 20 13:42:07.936: INFO: Updating stateful set ss2
Feb 20 13:42:07.969: INFO: Waiting for Pod statefulset-3164/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb 20 13:42:17.983: INFO: Waiting for Pod statefulset-3164/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb 20 13:42:28.009: INFO: Updating stateful set ss2
Feb 20 13:42:28.026: INFO: Waiting for StatefulSet statefulset-3164/ss2 to complete update
Feb 20 13:42:28.026: INFO: Waiting for Pod statefulset-3164/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 20 13:42:38.041: INFO: Deleting all statefulset in ns statefulset-3164
Feb 20 13:42:38.045: INFO: Scaling statefulset ss2 to 0
Feb 20 13:43:08.064: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 13:43:08.072: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:43:08.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3164" for this suite.
Feb 20 13:43:14.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:43:14.256: INFO: namespace statefulset-3164 deletion completed in 6.158079889s

• [SLOW TEST:106.729 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:43:14.259: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7754
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-c5p8
STEP: Creating a pod to test atomic-volume-subpath
Feb 20 13:43:14.446: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-c5p8" in namespace "subpath-7754" to be "success or failure"
Feb 20 13:43:14.455: INFO: Pod "pod-subpath-test-projected-c5p8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.056319ms
Feb 20 13:43:16.463: INFO: Pod "pod-subpath-test-projected-c5p8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016461809s
Feb 20 13:43:18.468: INFO: Pod "pod-subpath-test-projected-c5p8": Phase="Running", Reason="", readiness=true. Elapsed: 4.021687181s
Feb 20 13:43:20.474: INFO: Pod "pod-subpath-test-projected-c5p8": Phase="Running", Reason="", readiness=true. Elapsed: 6.02781212s
Feb 20 13:43:22.479: INFO: Pod "pod-subpath-test-projected-c5p8": Phase="Running", Reason="", readiness=true. Elapsed: 8.03297448s
Feb 20 13:43:24.486: INFO: Pod "pod-subpath-test-projected-c5p8": Phase="Running", Reason="", readiness=true. Elapsed: 10.040137181s
Feb 20 13:43:26.492: INFO: Pod "pod-subpath-test-projected-c5p8": Phase="Running", Reason="", readiness=true. Elapsed: 12.045825586s
Feb 20 13:43:28.497: INFO: Pod "pod-subpath-test-projected-c5p8": Phase="Running", Reason="", readiness=true. Elapsed: 14.051117376s
Feb 20 13:43:30.502: INFO: Pod "pod-subpath-test-projected-c5p8": Phase="Running", Reason="", readiness=true. Elapsed: 16.05597533s
Feb 20 13:43:32.507: INFO: Pod "pod-subpath-test-projected-c5p8": Phase="Running", Reason="", readiness=true. Elapsed: 18.060952793s
Feb 20 13:43:34.511: INFO: Pod "pod-subpath-test-projected-c5p8": Phase="Running", Reason="", readiness=true. Elapsed: 20.064762031s
Feb 20 13:43:36.518: INFO: Pod "pod-subpath-test-projected-c5p8": Phase="Running", Reason="", readiness=true. Elapsed: 22.071390709s
Feb 20 13:43:38.524: INFO: Pod "pod-subpath-test-projected-c5p8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.077358535s
STEP: Saw pod success
Feb 20 13:43:38.525: INFO: Pod "pod-subpath-test-projected-c5p8" satisfied condition "success or failure"
Feb 20 13:43:38.529: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod pod-subpath-test-projected-c5p8 container test-container-subpath-projected-c5p8: <nil>
STEP: delete the pod
Feb 20 13:43:38.594: INFO: Waiting for pod pod-subpath-test-projected-c5p8 to disappear
Feb 20 13:43:38.597: INFO: Pod pod-subpath-test-projected-c5p8 no longer exists
STEP: Deleting pod pod-subpath-test-projected-c5p8
Feb 20 13:43:38.598: INFO: Deleting pod "pod-subpath-test-projected-c5p8" in namespace "subpath-7754"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:43:38.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7754" for this suite.
Feb 20 13:43:44.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:43:44.748: INFO: namespace subpath-7754 deletion completed in 6.139771542s

• [SLOW TEST:30.491 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:43:44.758: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6890
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:43:49.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6890" for this suite.
Feb 20 13:44:17.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:44:18.100: INFO: namespace replication-controller-6890 deletion completed in 28.159573262s

• [SLOW TEST:33.344 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:44:18.107: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-3096
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 13:44:18.287: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Feb 20 13:44:20.343: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:44:20.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3096" for this suite.
Feb 20 13:44:26.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:44:26.565: INFO: namespace replication-controller-3096 deletion completed in 6.20112814s

• [SLOW TEST:8.459 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:44:26.592: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9350
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:44:43.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9350" for this suite.
Feb 20 13:44:49.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:44:50.004: INFO: namespace resourcequota-9350 deletion completed in 6.142873774s

• [SLOW TEST:23.413 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:44:50.024: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-1484
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:44:50.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1484" for this suite.
Feb 20 13:44:56.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:44:56.352: INFO: namespace custom-resource-definition-1484 deletion completed in 6.144467525s

• [SLOW TEST:6.329 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:44:56.363: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-2883
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:44:56.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-2883" for this suite.
Feb 20 13:45:02.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:45:02.679: INFO: namespace tables-2883 deletion completed in 6.134562669s

• [SLOW TEST:6.317 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:45:02.687: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9141
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-d1b056ce-16b1-4c5a-90b4-1fde58d895e6
STEP: Creating secret with name s-test-opt-upd-74c298e5-7498-431b-a194-6faef5bfc9b5
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-d1b056ce-16b1-4c5a-90b4-1fde58d895e6
STEP: Updating secret s-test-opt-upd-74c298e5-7498-431b-a194-6faef5bfc9b5
STEP: Creating secret with name s-test-opt-create-f147df36-68e9-46e2-9528-6af1133883bf
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:45:11.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9141" for this suite.
Feb 20 13:45:23.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:45:23.223: INFO: namespace projected-9141 deletion completed in 12.128153205s

• [SLOW TEST:20.538 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:45:23.229: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9946
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 20 13:45:23.391: INFO: Waiting up to 5m0s for pod "pod-c7628c99-8f1a-45ab-9d30-2e903dce6e2c" in namespace "emptydir-9946" to be "success or failure"
Feb 20 13:45:23.397: INFO: Pod "pod-c7628c99-8f1a-45ab-9d30-2e903dce6e2c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.618648ms
Feb 20 13:45:25.403: INFO: Pod "pod-c7628c99-8f1a-45ab-9d30-2e903dce6e2c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012498286s
Feb 20 13:45:27.409: INFO: Pod "pod-c7628c99-8f1a-45ab-9d30-2e903dce6e2c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018025669s
STEP: Saw pod success
Feb 20 13:45:27.409: INFO: Pod "pod-c7628c99-8f1a-45ab-9d30-2e903dce6e2c" satisfied condition "success or failure"
Feb 20 13:45:27.412: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod pod-c7628c99-8f1a-45ab-9d30-2e903dce6e2c container test-container: <nil>
STEP: delete the pod
Feb 20 13:45:27.437: INFO: Waiting for pod pod-c7628c99-8f1a-45ab-9d30-2e903dce6e2c to disappear
Feb 20 13:45:27.439: INFO: Pod pod-c7628c99-8f1a-45ab-9d30-2e903dce6e2c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:45:27.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9946" for this suite.
Feb 20 13:45:33.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:45:33.619: INFO: namespace emptydir-9946 deletion completed in 6.175381665s

• [SLOW TEST:10.392 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:45:33.627: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8071
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-8071
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-8071
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8071
Feb 20 13:45:33.820: INFO: Found 0 stateful pods, waiting for 1
Feb 20 13:45:43.827: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 20 13:45:43.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8071 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 20 13:45:44.703: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 20 13:45:44.703: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 20 13:45:44.703: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 20 13:45:44.719: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 20 13:45:54.728: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 13:45:54.729: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 13:45:54.743: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999347s
Feb 20 13:45:55.748: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.99630777s
Feb 20 13:45:56.752: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.992088936s
Feb 20 13:45:57.757: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.987781418s
Feb 20 13:45:58.762: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.982776317s
Feb 20 13:45:59.767: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.977162889s
Feb 20 13:46:00.772: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.972624271s
Feb 20 13:46:01.780: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.967836317s
Feb 20 13:46:02.786: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.959375112s
Feb 20 13:46:03.791: INFO: Verifying statefulset ss doesn't scale past 1 for another 953.654897ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8071
Feb 20 13:46:04.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8071 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 13:46:05.430: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 20 13:46:05.430: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 20 13:46:05.430: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 20 13:46:05.434: INFO: Found 1 stateful pods, waiting for 3
Feb 20 13:46:15.442: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 13:46:15.443: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 20 13:46:15.443: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 20 13:46:15.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8071 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 20 13:46:16.116: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 20 13:46:16.116: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 20 13:46:16.116: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 20 13:46:16.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8071 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 20 13:46:16.435: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 20 13:46:16.435: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 20 13:46:16.435: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 20 13:46:16.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8071 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 20 13:46:16.817: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 20 13:46:16.817: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 20 13:46:16.817: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 20 13:46:16.817: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 13:46:16.822: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb 20 13:46:26.835: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 13:46:26.836: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 13:46:26.837: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 20 13:46:26.864: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999629s
Feb 20 13:46:27.869: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992377346s
Feb 20 13:46:28.875: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.986920082s
Feb 20 13:46:29.880: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.981198544s
Feb 20 13:46:30.884: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.977072034s
Feb 20 13:46:31.890: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.972198263s
Feb 20 13:46:32.907: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.965537561s
Feb 20 13:46:33.916: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.945189844s
Feb 20 13:46:34.921: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.940325891s
Feb 20 13:46:35.926: INFO: Verifying statefulset ss doesn't scale past 3 for another 935.28239ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8071
Feb 20 13:46:36.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8071 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 13:46:37.517: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 20 13:46:37.517: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 20 13:46:37.517: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 20 13:46:37.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8071 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 13:46:37.810: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 20 13:46:37.810: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 20 13:46:37.810: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 20 13:46:37.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=statefulset-8071 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 20 13:46:38.181: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 20 13:46:38.181: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 20 13:46:38.181: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 20 13:46:38.181: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 20 13:47:08.219: INFO: Deleting all statefulset in ns statefulset-8071
Feb 20 13:47:08.224: INFO: Scaling statefulset ss to 0
Feb 20 13:47:08.233: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 13:47:08.236: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:47:08.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8071" for this suite.
Feb 20 13:47:14.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:47:14.387: INFO: namespace statefulset-8071 deletion completed in 6.127368955s

• [SLOW TEST:100.761 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:47:14.395: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6555
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 20 13:47:19.104: INFO: Successfully updated pod "pod-update-1d400676-0844-4a3c-9282-7c1194f59dfe"
STEP: verifying the updated pod is in kubernetes
Feb 20 13:47:19.113: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:47:19.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6555" for this suite.
Feb 20 13:47:47.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:47:47.310: INFO: namespace pods-6555 deletion completed in 28.186703129s

• [SLOW TEST:32.916 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:47:47.327: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7629
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 13:48:05.496: INFO: Container started at 2020-02-20 13:47:48 +0000 UTC, pod became ready at 2020-02-20 13:48:03 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:48:05.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7629" for this suite.
Feb 20 13:48:17.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:48:17.647: INFO: namespace container-probe-7629 deletion completed in 12.142400412s

• [SLOW TEST:30.322 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:48:17.660: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7423
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 20 13:48:17.825: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7423 /api/v1/namespaces/watch-7423/configmaps/e2e-watch-test-label-changed 267ae9da-7b93-4b60-92c3-15638d8b35dc 241659 0 2020-02-20 13:48:17 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 20 13:48:17.826: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7423 /api/v1/namespaces/watch-7423/configmaps/e2e-watch-test-label-changed 267ae9da-7b93-4b60-92c3-15638d8b35dc 241660 0 2020-02-20 13:48:17 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 20 13:48:17.827: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7423 /api/v1/namespaces/watch-7423/configmaps/e2e-watch-test-label-changed 267ae9da-7b93-4b60-92c3-15638d8b35dc 241661 0 2020-02-20 13:48:17 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 20 13:48:27.863: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7423 /api/v1/namespaces/watch-7423/configmaps/e2e-watch-test-label-changed 267ae9da-7b93-4b60-92c3-15638d8b35dc 241690 0 2020-02-20 13:48:17 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 20 13:48:27.864: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7423 /api/v1/namespaces/watch-7423/configmaps/e2e-watch-test-label-changed 267ae9da-7b93-4b60-92c3-15638d8b35dc 241691 0 2020-02-20 13:48:17 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb 20 13:48:27.864: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7423 /api/v1/namespaces/watch-7423/configmaps/e2e-watch-test-label-changed 267ae9da-7b93-4b60-92c3-15638d8b35dc 241692 0 2020-02-20 13:48:17 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:48:27.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7423" for this suite.
Feb 20 13:48:33.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:48:34.090: INFO: namespace watch-7423 deletion completed in 6.218295241s

• [SLOW TEST:16.431 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:48:34.098: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7484
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7484.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7484.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7484.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7484.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 20 13:48:38.293: INFO: DNS probes using dns-test-2c9bc69e-eb49-49c7-bb70-f6d88c168c5f succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7484.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7484.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7484.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7484.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 20 13:48:42.375: INFO: DNS probes using dns-test-660acfb5-60fd-46bd-8103-4edba8b58ca6 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7484.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-7484.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7484.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-7484.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 20 13:48:46.460: INFO: DNS probes using dns-test-baf190b8-9be4-42d4-a7f6-4b7db7b8dd5b succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:48:46.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7484" for this suite.
Feb 20 13:48:52.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:48:52.702: INFO: namespace dns-7484 deletion completed in 6.1833952s

• [SLOW TEST:18.605 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:48:52.723: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5786
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 20 13:48:52.926: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:48:52.935: INFO: Number of nodes with available pods: 0
Feb 20 13:48:52.940: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 13:48:53.949: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:48:53.971: INFO: Number of nodes with available pods: 0
Feb 20 13:48:53.971: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 13:48:54.968: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:48:54.983: INFO: Number of nodes with available pods: 1
Feb 20 13:48:54.983: INFO: Node kube16prod-img-kube16prod-img-minion-2 is running more than one daemon pod
Feb 20 13:48:55.948: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:48:55.952: INFO: Number of nodes with available pods: 2
Feb 20 13:48:55.953: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 20 13:48:55.973: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:48:55.979: INFO: Number of nodes with available pods: 1
Feb 20 13:48:55.980: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 13:48:56.986: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:48:56.990: INFO: Number of nodes with available pods: 1
Feb 20 13:48:56.990: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 13:48:57.987: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:48:57.991: INFO: Number of nodes with available pods: 2
Feb 20 13:48:57.992: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5786, will wait for the garbage collector to delete the pods
Feb 20 13:48:58.064: INFO: Deleting DaemonSet.extensions daemon-set took: 5.223982ms
Feb 20 13:48:58.965: INFO: Terminating DaemonSet.extensions daemon-set pods took: 900.997588ms
Feb 20 13:49:11.470: INFO: Number of nodes with available pods: 0
Feb 20 13:49:11.471: INFO: Number of running nodes: 0, number of available pods: 0
Feb 20 13:49:11.477: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5786/daemonsets","resourceVersion":"242039"},"items":null}

Feb 20 13:49:11.480: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5786/pods","resourceVersion":"242039"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:49:11.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5786" for this suite.
Feb 20 13:49:17.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:49:17.660: INFO: namespace daemonsets-5786 deletion completed in 6.156447869s

• [SLOW TEST:24.939 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:49:17.667: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3621
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-060f974a-c723-4727-aff2-0611faa6ca83
STEP: Creating a pod to test consume secrets
Feb 20 13:49:17.874: INFO: Waiting up to 5m0s for pod "pod-secrets-25a1558f-d190-49f2-92e3-a14dd26c3191" in namespace "secrets-3621" to be "success or failure"
Feb 20 13:49:17.877: INFO: Pod "pod-secrets-25a1558f-d190-49f2-92e3-a14dd26c3191": Phase="Pending", Reason="", readiness=false. Elapsed: 3.760455ms
Feb 20 13:49:19.881: INFO: Pod "pod-secrets-25a1558f-d190-49f2-92e3-a14dd26c3191": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00772703s
Feb 20 13:49:21.886: INFO: Pod "pod-secrets-25a1558f-d190-49f2-92e3-a14dd26c3191": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011884202s
STEP: Saw pod success
Feb 20 13:49:21.886: INFO: Pod "pod-secrets-25a1558f-d190-49f2-92e3-a14dd26c3191" satisfied condition "success or failure"
Feb 20 13:49:21.888: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-secrets-25a1558f-d190-49f2-92e3-a14dd26c3191 container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 13:49:21.973: INFO: Waiting for pod pod-secrets-25a1558f-d190-49f2-92e3-a14dd26c3191 to disappear
Feb 20 13:49:21.977: INFO: Pod pod-secrets-25a1558f-d190-49f2-92e3-a14dd26c3191 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:49:21.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3621" for this suite.
Feb 20 13:49:27.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:49:28.128: INFO: namespace secrets-3621 deletion completed in 6.14090091s

• [SLOW TEST:10.462 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:49:28.139: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3065
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 20 13:49:28.371: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:49:28.378: INFO: Number of nodes with available pods: 0
Feb 20 13:49:28.378: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 13:49:29.388: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:49:29.396: INFO: Number of nodes with available pods: 0
Feb 20 13:49:29.396: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 13:49:30.386: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:49:30.392: INFO: Number of nodes with available pods: 1
Feb 20 13:49:30.392: INFO: Node kube16prod-img-kube16prod-img-minion-2 is running more than one daemon pod
Feb 20 13:49:31.388: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:49:31.392: INFO: Number of nodes with available pods: 2
Feb 20 13:49:31.392: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 20 13:49:31.417: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:49:31.421: INFO: Number of nodes with available pods: 1
Feb 20 13:49:31.421: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 13:49:32.430: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:49:32.435: INFO: Number of nodes with available pods: 1
Feb 20 13:49:32.435: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 13:49:33.427: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:49:33.430: INFO: Number of nodes with available pods: 1
Feb 20 13:49:33.430: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 13:49:34.429: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:49:34.435: INFO: Number of nodes with available pods: 1
Feb 20 13:49:34.435: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 13:49:35.428: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:49:35.432: INFO: Number of nodes with available pods: 1
Feb 20 13:49:35.432: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 13:49:36.428: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 13:49:36.433: INFO: Number of nodes with available pods: 2
Feb 20 13:49:36.435: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3065, will wait for the garbage collector to delete the pods
Feb 20 13:49:36.499: INFO: Deleting DaemonSet.extensions daemon-set took: 6.399401ms
Feb 20 13:49:37.400: INFO: Terminating DaemonSet.extensions daemon-set pods took: 900.816505ms
Feb 20 13:49:40.404: INFO: Number of nodes with available pods: 0
Feb 20 13:49:40.404: INFO: Number of running nodes: 0, number of available pods: 0
Feb 20 13:49:40.406: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3065/daemonsets","resourceVersion":"242252"},"items":null}

Feb 20 13:49:40.409: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3065/pods","resourceVersion":"242252"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:49:40.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3065" for this suite.
Feb 20 13:49:46.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:49:46.556: INFO: namespace daemonsets-3065 deletion completed in 6.125846914s

• [SLOW TEST:18.418 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:49:46.563: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-2384
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-2384
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-2384
STEP: Deleting pre-stop pod
Feb 20 13:49:55.792: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:49:55.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-2384" for this suite.
Feb 20 13:50:35.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:50:35.930: INFO: namespace prestop-2384 deletion completed in 40.12487062s

• [SLOW TEST:49.368 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:50:35.936: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3286
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-3286/configmap-test-0e717b4a-ed50-4f98-bc16-2ff422d21d49
STEP: Creating a pod to test consume configMaps
Feb 20 13:50:36.092: INFO: Waiting up to 5m0s for pod "pod-configmaps-b36744b6-8137-41a1-bd7c-df4314bdaa02" in namespace "configmap-3286" to be "success or failure"
Feb 20 13:50:36.098: INFO: Pod "pod-configmaps-b36744b6-8137-41a1-bd7c-df4314bdaa02": Phase="Pending", Reason="", readiness=false. Elapsed: 5.142792ms
Feb 20 13:50:38.104: INFO: Pod "pod-configmaps-b36744b6-8137-41a1-bd7c-df4314bdaa02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011266653s
Feb 20 13:50:40.128: INFO: Pod "pod-configmaps-b36744b6-8137-41a1-bd7c-df4314bdaa02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035026613s
STEP: Saw pod success
Feb 20 13:50:40.129: INFO: Pod "pod-configmaps-b36744b6-8137-41a1-bd7c-df4314bdaa02" satisfied condition "success or failure"
Feb 20 13:50:40.134: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod pod-configmaps-b36744b6-8137-41a1-bd7c-df4314bdaa02 container env-test: <nil>
STEP: delete the pod
Feb 20 13:50:40.207: INFO: Waiting for pod pod-configmaps-b36744b6-8137-41a1-bd7c-df4314bdaa02 to disappear
Feb 20 13:50:40.210: INFO: Pod pod-configmaps-b36744b6-8137-41a1-bd7c-df4314bdaa02 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:50:40.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3286" for this suite.
Feb 20 13:50:46.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:50:46.360: INFO: namespace configmap-3286 deletion completed in 6.143202074s

• [SLOW TEST:10.425 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:50:46.369: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7488
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 20 13:50:46.548: INFO: Waiting up to 5m0s for pod "downwardapi-volume-44d49107-cafb-45da-a81b-77bfa8ed6975" in namespace "projected-7488" to be "success or failure"
Feb 20 13:50:46.557: INFO: Pod "downwardapi-volume-44d49107-cafb-45da-a81b-77bfa8ed6975": Phase="Pending", Reason="", readiness=false. Elapsed: 9.552762ms
Feb 20 13:50:48.563: INFO: Pod "downwardapi-volume-44d49107-cafb-45da-a81b-77bfa8ed6975": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014630468s
Feb 20 13:50:50.570: INFO: Pod "downwardapi-volume-44d49107-cafb-45da-a81b-77bfa8ed6975": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022161637s
STEP: Saw pod success
Feb 20 13:50:50.571: INFO: Pod "downwardapi-volume-44d49107-cafb-45da-a81b-77bfa8ed6975" satisfied condition "success or failure"
Feb 20 13:50:50.574: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod downwardapi-volume-44d49107-cafb-45da-a81b-77bfa8ed6975 container client-container: <nil>
STEP: delete the pod
Feb 20 13:50:50.599: INFO: Waiting for pod downwardapi-volume-44d49107-cafb-45da-a81b-77bfa8ed6975 to disappear
Feb 20 13:50:50.601: INFO: Pod downwardapi-volume-44d49107-cafb-45da-a81b-77bfa8ed6975 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:50:50.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7488" for this suite.
Feb 20 13:50:56.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:50:56.714: INFO: namespace projected-7488 deletion completed in 6.105599951s

• [SLOW TEST:10.346 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:50:56.721: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5593
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-fb34c639-083e-4854-8bf0-7226e90d3ee7
STEP: Creating a pod to test consume secrets
Feb 20 13:50:56.887: INFO: Waiting up to 5m0s for pod "pod-secrets-f47c57f3-9e24-42ac-95b2-c6160f90fe1b" in namespace "secrets-5593" to be "success or failure"
Feb 20 13:50:56.896: INFO: Pod "pod-secrets-f47c57f3-9e24-42ac-95b2-c6160f90fe1b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.044146ms
Feb 20 13:50:58.900: INFO: Pod "pod-secrets-f47c57f3-9e24-42ac-95b2-c6160f90fe1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012948548s
Feb 20 13:51:00.906: INFO: Pod "pod-secrets-f47c57f3-9e24-42ac-95b2-c6160f90fe1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01886638s
STEP: Saw pod success
Feb 20 13:51:00.906: INFO: Pod "pod-secrets-f47c57f3-9e24-42ac-95b2-c6160f90fe1b" satisfied condition "success or failure"
Feb 20 13:51:00.909: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod pod-secrets-f47c57f3-9e24-42ac-95b2-c6160f90fe1b container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 13:51:00.933: INFO: Waiting for pod pod-secrets-f47c57f3-9e24-42ac-95b2-c6160f90fe1b to disappear
Feb 20 13:51:00.936: INFO: Pod pod-secrets-f47c57f3-9e24-42ac-95b2-c6160f90fe1b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:51:00.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5593" for this suite.
Feb 20 13:51:06.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:51:07.080: INFO: namespace secrets-5593 deletion completed in 6.138987517s

• [SLOW TEST:10.361 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:51:07.086: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9478
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 20 13:51:07.253: INFO: Waiting up to 5m0s for pod "pod-7bf5bd97-2c80-4706-a09a-8f45b219e82a" in namespace "emptydir-9478" to be "success or failure"
Feb 20 13:51:07.260: INFO: Pod "pod-7bf5bd97-2c80-4706-a09a-8f45b219e82a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.056198ms
Feb 20 13:51:09.264: INFO: Pod "pod-7bf5bd97-2c80-4706-a09a-8f45b219e82a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010805177s
Feb 20 13:51:11.276: INFO: Pod "pod-7bf5bd97-2c80-4706-a09a-8f45b219e82a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022843643s
STEP: Saw pod success
Feb 20 13:51:11.277: INFO: Pod "pod-7bf5bd97-2c80-4706-a09a-8f45b219e82a" satisfied condition "success or failure"
Feb 20 13:51:11.280: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-7bf5bd97-2c80-4706-a09a-8f45b219e82a container test-container: <nil>
STEP: delete the pod
Feb 20 13:51:11.358: INFO: Waiting for pod pod-7bf5bd97-2c80-4706-a09a-8f45b219e82a to disappear
Feb 20 13:51:11.366: INFO: Pod pod-7bf5bd97-2c80-4706-a09a-8f45b219e82a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:51:11.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9478" for this suite.
Feb 20 13:51:17.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:51:17.519: INFO: namespace emptydir-9478 deletion completed in 6.147258107s

• [SLOW TEST:10.433 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:51:17.530: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8883
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-8883
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 20 13:51:17.677: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 20 13:51:41.768: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.100.81.166:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8883 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 13:51:41.770: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
Feb 20 13:51:42.046: INFO: Found all expected endpoints: [netserver-0]
Feb 20 13:51:42.050: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.100.99.152:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8883 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 13:51:42.050: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
Feb 20 13:51:42.197: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:51:42.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8883" for this suite.
Feb 20 13:51:54.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:51:54.322: INFO: namespace pod-network-test-8883 deletion completed in 12.119293778s

• [SLOW TEST:36.793 seconds]
[sig-network] Networking
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:51:54.337: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2569
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-0765b18e-13a0-4b12-a5e9-051a6363c759
STEP: Creating a pod to test consume configMaps
Feb 20 13:51:54.510: INFO: Waiting up to 5m0s for pod "pod-configmaps-72568768-eff6-4a43-846b-24c67a6718b6" in namespace "configmap-2569" to be "success or failure"
Feb 20 13:51:54.530: INFO: Pod "pod-configmaps-72568768-eff6-4a43-846b-24c67a6718b6": Phase="Pending", Reason="", readiness=false. Elapsed: 20.159369ms
Feb 20 13:51:56.536: INFO: Pod "pod-configmaps-72568768-eff6-4a43-846b-24c67a6718b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025621804s
STEP: Saw pod success
Feb 20 13:51:56.537: INFO: Pod "pod-configmaps-72568768-eff6-4a43-846b-24c67a6718b6" satisfied condition "success or failure"
Feb 20 13:51:56.539: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-configmaps-72568768-eff6-4a43-846b-24c67a6718b6 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 13:51:56.560: INFO: Waiting for pod pod-configmaps-72568768-eff6-4a43-846b-24c67a6718b6 to disappear
Feb 20 13:51:56.562: INFO: Pod pod-configmaps-72568768-eff6-4a43-846b-24c67a6718b6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:51:56.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2569" for this suite.
Feb 20 13:52:02.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:52:02.688: INFO: namespace configmap-2569 deletion completed in 6.12074883s

• [SLOW TEST:8.352 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:52:02.697: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2618
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-b91a62aa-5242-4cc5-ae48-a252bff63dbb
STEP: Creating a pod to test consume configMaps
Feb 20 13:52:02.885: INFO: Waiting up to 5m0s for pod "pod-configmaps-bcf6fe38-12b8-44ba-8cdc-16ec51058e43" in namespace "configmap-2618" to be "success or failure"
Feb 20 13:52:02.900: INFO: Pod "pod-configmaps-bcf6fe38-12b8-44ba-8cdc-16ec51058e43": Phase="Pending", Reason="", readiness=false. Elapsed: 13.571291ms
Feb 20 13:52:04.904: INFO: Pod "pod-configmaps-bcf6fe38-12b8-44ba-8cdc-16ec51058e43": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017990196s
Feb 20 13:52:06.909: INFO: Pod "pod-configmaps-bcf6fe38-12b8-44ba-8cdc-16ec51058e43": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022727528s
STEP: Saw pod success
Feb 20 13:52:06.910: INFO: Pod "pod-configmaps-bcf6fe38-12b8-44ba-8cdc-16ec51058e43" satisfied condition "success or failure"
Feb 20 13:52:06.913: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod pod-configmaps-bcf6fe38-12b8-44ba-8cdc-16ec51058e43 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 13:52:06.944: INFO: Waiting for pod pod-configmaps-bcf6fe38-12b8-44ba-8cdc-16ec51058e43 to disappear
Feb 20 13:52:06.948: INFO: Pod pod-configmaps-bcf6fe38-12b8-44ba-8cdc-16ec51058e43 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:52:06.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2618" for this suite.
Feb 20 13:52:12.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:52:13.094: INFO: namespace configmap-2618 deletion completed in 6.141608652s

• [SLOW TEST:10.399 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:52:13.100: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4644
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 20 13:52:13.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-4644'
Feb 20 13:52:13.549: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 20 13:52:13.549: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Feb 20 13:52:13.563: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-v759p]
Feb 20 13:52:13.563: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-v759p" in namespace "kubectl-4644" to be "running and ready"
Feb 20 13:52:13.570: INFO: Pod "e2e-test-httpd-rc-v759p": Phase="Pending", Reason="", readiness=false. Elapsed: 4.852358ms
Feb 20 13:52:15.574: INFO: Pod "e2e-test-httpd-rc-v759p": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009178479s
Feb 20 13:52:17.585: INFO: Pod "e2e-test-httpd-rc-v759p": Phase="Running", Reason="", readiness=true. Elapsed: 4.019603954s
Feb 20 13:52:17.585: INFO: Pod "e2e-test-httpd-rc-v759p" satisfied condition "running and ready"
Feb 20 13:52:17.585: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-v759p]
Feb 20 13:52:17.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 logs rc/e2e-test-httpd-rc --namespace=kubectl-4644'
Feb 20 13:52:17.844: INFO: stderr: ""
Feb 20 13:52:17.844: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.100.81.169. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.100.81.169. Set the 'ServerName' directive globally to suppress this message\n[Thu Feb 20 13:52:15.419271 2020] [mpm_event:notice] [pid 1:tid 140318134360936] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Thu Feb 20 13:52:15.419504 2020] [core:notice] [pid 1:tid 140318134360936] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Feb 20 13:52:17.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 delete rc e2e-test-httpd-rc --namespace=kubectl-4644'
Feb 20 13:52:18.044: INFO: stderr: ""
Feb 20 13:52:18.044: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:52:18.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4644" for this suite.
Feb 20 13:52:24.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:52:24.163: INFO: namespace kubectl-4644 deletion completed in 6.113299371s

• [SLOW TEST:11.064 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:52:24.170: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7673
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 20 13:52:24.341: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7673 /api/v1/namespaces/watch-7673/configmaps/e2e-watch-test-watch-closed 1b68b8cf-87fb-4d3a-948a-c1332f132344 243131 0 2020-02-20 13:52:24 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 20 13:52:24.343: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7673 /api/v1/namespaces/watch-7673/configmaps/e2e-watch-test-watch-closed 1b68b8cf-87fb-4d3a-948a-c1332f132344 243132 0 2020-02-20 13:52:24 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 20 13:52:24.364: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7673 /api/v1/namespaces/watch-7673/configmaps/e2e-watch-test-watch-closed 1b68b8cf-87fb-4d3a-948a-c1332f132344 243133 0 2020-02-20 13:52:24 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 20 13:52:24.365: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7673 /api/v1/namespaces/watch-7673/configmaps/e2e-watch-test-watch-closed 1b68b8cf-87fb-4d3a-948a-c1332f132344 243134 0 2020-02-20 13:52:24 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:52:24.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7673" for this suite.
Feb 20 13:52:30.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:52:30.486: INFO: namespace watch-7673 deletion completed in 6.114761438s

• [SLOW TEST:6.317 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:52:30.498: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-4722
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-4722
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 20 13:52:30.659: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 20 13:52:56.740: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.100.99.156:8080/dial?request=hostName&protocol=http&host=10.100.81.170&port=8080&tries=1'] Namespace:pod-network-test-4722 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 13:52:56.741: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
Feb 20 13:52:56.971: INFO: Waiting for endpoints: map[]
Feb 20 13:52:56.975: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.100.99.156:8080/dial?request=hostName&protocol=http&host=10.100.99.155&port=8080&tries=1'] Namespace:pod-network-test-4722 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 13:52:56.975: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
Feb 20 13:52:57.141: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:52:57.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4722" for this suite.
Feb 20 13:53:09.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:53:09.268: INFO: namespace pod-network-test-4722 deletion completed in 12.12116511s

• [SLOW TEST:38.772 seconds]
[sig-network] Networking
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:53:09.278: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3628
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 20 13:53:15.480: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 20 13:53:15.483: INFO: Pod pod-with-prestop-http-hook still exists
Feb 20 13:53:17.484: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 20 13:53:17.488: INFO: Pod pod-with-prestop-http-hook still exists
Feb 20 13:53:19.484: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 20 13:53:19.488: INFO: Pod pod-with-prestop-http-hook still exists
Feb 20 13:53:21.484: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 20 13:53:21.487: INFO: Pod pod-with-prestop-http-hook still exists
Feb 20 13:53:23.484: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 20 13:53:23.489: INFO: Pod pod-with-prestop-http-hook still exists
Feb 20 13:53:25.484: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 20 13:53:25.488: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:53:25.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3628" for this suite.
Feb 20 13:53:53.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:53:53.662: INFO: namespace container-lifecycle-hook-3628 deletion completed in 28.155656218s

• [SLOW TEST:44.385 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:53:53.675: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2934
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:53:57.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2934" for this suite.
Feb 20 13:54:03.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:54:04.006: INFO: namespace kubelet-test-2934 deletion completed in 6.146729784s

• [SLOW TEST:10.335 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:54:04.028: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7322
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-0d3a9b18-992b-48a1-8e9f-a644add47bf6
Feb 20 13:54:04.211: INFO: Pod name my-hostname-basic-0d3a9b18-992b-48a1-8e9f-a644add47bf6: Found 1 pods out of 1
Feb 20 13:54:04.211: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-0d3a9b18-992b-48a1-8e9f-a644add47bf6" are running
Feb 20 13:54:08.226: INFO: Pod "my-hostname-basic-0d3a9b18-992b-48a1-8e9f-a644add47bf6-7ggmh" is running (conditions: [])
Feb 20 13:54:08.227: INFO: Trying to dial the pod
Feb 20 13:54:13.245: INFO: Controller my-hostname-basic-0d3a9b18-992b-48a1-8e9f-a644add47bf6: Got expected result from replica 1 [my-hostname-basic-0d3a9b18-992b-48a1-8e9f-a644add47bf6-7ggmh]: "my-hostname-basic-0d3a9b18-992b-48a1-8e9f-a644add47bf6-7ggmh", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:54:13.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7322" for this suite.
Feb 20 13:54:19.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:54:19.370: INFO: namespace replication-controller-7322 deletion completed in 6.116316339s

• [SLOW TEST:15.344 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:54:19.373: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9253
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-9253/configmap-test-7bb90f45-ea79-4b69-9d05-810ba2cec889
STEP: Creating a pod to test consume configMaps
Feb 20 13:54:19.577: INFO: Waiting up to 5m0s for pod "pod-configmaps-d9969dad-06ee-4893-ad4f-def2fc94b197" in namespace "configmap-9253" to be "success or failure"
Feb 20 13:54:19.582: INFO: Pod "pod-configmaps-d9969dad-06ee-4893-ad4f-def2fc94b197": Phase="Pending", Reason="", readiness=false. Elapsed: 5.184704ms
Feb 20 13:54:21.588: INFO: Pod "pod-configmaps-d9969dad-06ee-4893-ad4f-def2fc94b197": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011354004s
Feb 20 13:54:23.612: INFO: Pod "pod-configmaps-d9969dad-06ee-4893-ad4f-def2fc94b197": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035634165s
STEP: Saw pod success
Feb 20 13:54:23.614: INFO: Pod "pod-configmaps-d9969dad-06ee-4893-ad4f-def2fc94b197" satisfied condition "success or failure"
Feb 20 13:54:23.624: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-configmaps-d9969dad-06ee-4893-ad4f-def2fc94b197 container env-test: <nil>
STEP: delete the pod
Feb 20 13:54:23.696: INFO: Waiting for pod pod-configmaps-d9969dad-06ee-4893-ad4f-def2fc94b197 to disappear
Feb 20 13:54:23.699: INFO: Pod pod-configmaps-d9969dad-06ee-4893-ad4f-def2fc94b197 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:54:23.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9253" for this suite.
Feb 20 13:54:29.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:54:29.868: INFO: namespace configmap-9253 deletion completed in 6.16224704s

• [SLOW TEST:10.496 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:54:29.873: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3206
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-60d7f8b1-a525-47a1-b13d-28f471e04e13
STEP: Creating secret with name s-test-opt-upd-d4c2bb91-fec7-4701-b663-e7a1de48d586
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-60d7f8b1-a525-47a1-b13d-28f471e04e13
STEP: Updating secret s-test-opt-upd-d4c2bb91-fec7-4701-b663-e7a1de48d586
STEP: Creating secret with name s-test-opt-create-af982447-3fa4-45eb-bd7d-31c26fc09a7c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:54:38.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3206" for this suite.
Feb 20 13:55:06.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:55:06.362: INFO: namespace secrets-3206 deletion completed in 28.137323828s

• [SLOW TEST:36.491 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:55:06.378: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5878
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 20 13:55:07.017: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 20 13:55:09.032: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717803707, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717803707, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717803707, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717803707, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 20 13:55:12.057: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:55:12.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5878" for this suite.
Feb 20 13:55:18.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:55:18.421: INFO: namespace webhook-5878 deletion completed in 6.142593747s
STEP: Destroying namespace "webhook-5878-markers" for this suite.
Feb 20 13:55:24.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:55:24.618: INFO: namespace webhook-5878-markers deletion completed in 6.196663247s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.256 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:55:24.643: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4837
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:56:24.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4837" for this suite.
Feb 20 13:56:36.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:56:37.007: INFO: namespace container-probe-4837 deletion completed in 12.174099326s

• [SLOW TEST:72.366 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:56:37.038: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4372
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-4372
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-4372
STEP: Creating statefulset with conflicting port in namespace statefulset-4372
STEP: Waiting until pod test-pod will start running in namespace statefulset-4372
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-4372
Feb 20 13:56:41.267: INFO: Observed stateful pod in namespace: statefulset-4372, name: ss-0, uid: ba7a643a-5805-4731-8f6f-85cb1ebc0bc2, status phase: Pending. Waiting for statefulset controller to delete.
Feb 20 13:56:41.617: INFO: Observed stateful pod in namespace: statefulset-4372, name: ss-0, uid: ba7a643a-5805-4731-8f6f-85cb1ebc0bc2, status phase: Failed. Waiting for statefulset controller to delete.
Feb 20 13:56:41.625: INFO: Observed stateful pod in namespace: statefulset-4372, name: ss-0, uid: ba7a643a-5805-4731-8f6f-85cb1ebc0bc2, status phase: Failed. Waiting for statefulset controller to delete.
Feb 20 13:56:41.632: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-4372
STEP: Removing pod with conflicting port in namespace statefulset-4372
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-4372 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 20 13:56:45.659: INFO: Deleting all statefulset in ns statefulset-4372
Feb 20 13:56:45.662: INFO: Scaling statefulset ss to 0
Feb 20 13:56:55.680: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 13:56:55.687: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:56:55.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4372" for this suite.
Feb 20 13:57:01.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:57:01.870: INFO: namespace statefulset-4372 deletion completed in 6.156132254s

• [SLOW TEST:24.833 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:57:01.875: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7764
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-79dl
STEP: Creating a pod to test atomic-volume-subpath
Feb 20 13:57:02.071: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-79dl" in namespace "subpath-7764" to be "success or failure"
Feb 20 13:57:02.084: INFO: Pod "pod-subpath-test-configmap-79dl": Phase="Pending", Reason="", readiness=false. Elapsed: 12.426757ms
Feb 20 13:57:04.092: INFO: Pod "pod-subpath-test-configmap-79dl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020534712s
Feb 20 13:57:06.098: INFO: Pod "pod-subpath-test-configmap-79dl": Phase="Running", Reason="", readiness=true. Elapsed: 4.026487832s
Feb 20 13:57:08.102: INFO: Pod "pod-subpath-test-configmap-79dl": Phase="Running", Reason="", readiness=true. Elapsed: 6.030330258s
Feb 20 13:57:10.107: INFO: Pod "pod-subpath-test-configmap-79dl": Phase="Running", Reason="", readiness=true. Elapsed: 8.035118836s
Feb 20 13:57:12.111: INFO: Pod "pod-subpath-test-configmap-79dl": Phase="Running", Reason="", readiness=true. Elapsed: 10.039436228s
Feb 20 13:57:14.115: INFO: Pod "pod-subpath-test-configmap-79dl": Phase="Running", Reason="", readiness=true. Elapsed: 12.043565631s
Feb 20 13:57:16.119: INFO: Pod "pod-subpath-test-configmap-79dl": Phase="Running", Reason="", readiness=true. Elapsed: 14.047514995s
Feb 20 13:57:18.123: INFO: Pod "pod-subpath-test-configmap-79dl": Phase="Running", Reason="", readiness=true. Elapsed: 16.051557934s
Feb 20 13:57:20.128: INFO: Pod "pod-subpath-test-configmap-79dl": Phase="Running", Reason="", readiness=true. Elapsed: 18.056838931s
Feb 20 13:57:22.132: INFO: Pod "pod-subpath-test-configmap-79dl": Phase="Running", Reason="", readiness=true. Elapsed: 20.060840149s
Feb 20 13:57:24.137: INFO: Pod "pod-subpath-test-configmap-79dl": Phase="Running", Reason="", readiness=true. Elapsed: 22.065406136s
Feb 20 13:57:26.142: INFO: Pod "pod-subpath-test-configmap-79dl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.070615389s
STEP: Saw pod success
Feb 20 13:57:26.143: INFO: Pod "pod-subpath-test-configmap-79dl" satisfied condition "success or failure"
Feb 20 13:57:26.146: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod pod-subpath-test-configmap-79dl container test-container-subpath-configmap-79dl: <nil>
STEP: delete the pod
Feb 20 13:57:26.205: INFO: Waiting for pod pod-subpath-test-configmap-79dl to disappear
Feb 20 13:57:26.207: INFO: Pod pod-subpath-test-configmap-79dl no longer exists
STEP: Deleting pod pod-subpath-test-configmap-79dl
Feb 20 13:57:26.208: INFO: Deleting pod "pod-subpath-test-configmap-79dl" in namespace "subpath-7764"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:57:26.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7764" for this suite.
Feb 20 13:57:32.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:57:32.389: INFO: namespace subpath-7764 deletion completed in 6.161620962s

• [SLOW TEST:30.515 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:57:32.397: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-196
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-63c75f38-758e-4c4f-9c76-602edc64713d
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-63c75f38-758e-4c4f-9c76-602edc64713d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:59:05.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-196" for this suite.
Feb 20 13:59:17.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:59:17.335: INFO: namespace projected-196 deletion completed in 12.144004264s

• [SLOW TEST:104.938 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:59:17.343: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4599
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 20 13:59:17.502: INFO: Waiting up to 5m0s for pod "pod-292446b2-599d-4bd0-9a2d-73990fe0e39f" in namespace "emptydir-4599" to be "success or failure"
Feb 20 13:59:17.509: INFO: Pod "pod-292446b2-599d-4bd0-9a2d-73990fe0e39f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.6353ms
Feb 20 13:59:19.520: INFO: Pod "pod-292446b2-599d-4bd0-9a2d-73990fe0e39f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017353253s
Feb 20 13:59:21.531: INFO: Pod "pod-292446b2-599d-4bd0-9a2d-73990fe0e39f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028420615s
STEP: Saw pod success
Feb 20 13:59:21.532: INFO: Pod "pod-292446b2-599d-4bd0-9a2d-73990fe0e39f" satisfied condition "success or failure"
Feb 20 13:59:21.535: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod pod-292446b2-599d-4bd0-9a2d-73990fe0e39f container test-container: <nil>
STEP: delete the pod
Feb 20 13:59:21.591: INFO: Waiting for pod pod-292446b2-599d-4bd0-9a2d-73990fe0e39f to disappear
Feb 20 13:59:21.593: INFO: Pod pod-292446b2-599d-4bd0-9a2d-73990fe0e39f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:59:21.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4599" for this suite.
Feb 20 13:59:27.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:59:27.715: INFO: namespace emptydir-4599 deletion completed in 6.115715656s

• [SLOW TEST:10.373 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:59:27.725: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-1751
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 13:59:27.867: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:59:27.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1751" for this suite.
Feb 20 13:59:33.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 13:59:34.062: INFO: namespace custom-resource-definition-1751 deletion completed in 6.134793594s

• [SLOW TEST:6.339 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 13:59:34.075: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-219
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Feb 20 13:59:34.209: INFO: namespace kubectl-219
Feb 20 13:59:34.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 create -f - --namespace=kubectl-219'
Feb 20 13:59:35.434: INFO: stderr: ""
Feb 20 13:59:35.434: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 20 13:59:36.440: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 13:59:36.441: INFO: Found 0 / 1
Feb 20 13:59:37.439: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 13:59:37.440: INFO: Found 1 / 1
Feb 20 13:59:37.440: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 20 13:59:37.445: INFO: Selector matched 1 pods for map[app:redis]
Feb 20 13:59:37.445: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 20 13:59:37.445: INFO: wait on redis-master startup in kubectl-219 
Feb 20 13:59:37.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 logs redis-master-snvxm redis-master --namespace=kubectl-219'
Feb 20 13:59:37.659: INFO: stderr: ""
Feb 20 13:59:37.659: INFO: stdout: "1:C 20 Feb 2020 13:59:36.771 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 20 Feb 2020 13:59:36.771 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 20 Feb 2020 13:59:36.771 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 20 Feb 2020 13:59:36.774 * Running mode=standalone, port=6379.\n1:M 20 Feb 2020 13:59:36.774 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 20 Feb 2020 13:59:36.774 # Server initialized\n1:M 20 Feb 2020 13:59:36.774 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 20 Feb 2020 13:59:36.774 * Ready to accept connections\n"
STEP: exposing RC
Feb 20 13:59:37.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-219'
Feb 20 13:59:37.895: INFO: stderr: ""
Feb 20 13:59:37.895: INFO: stdout: "service/rm2 exposed\n"
Feb 20 13:59:37.899: INFO: Service rm2 in namespace kubectl-219 found.
STEP: exposing service
Feb 20 13:59:39.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-219'
Feb 20 13:59:40.101: INFO: stderr: ""
Feb 20 13:59:40.101: INFO: stdout: "service/rm3 exposed\n"
Feb 20 13:59:40.107: INFO: Service rm3 in namespace kubectl-219 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 13:59:42.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-219" for this suite.
Feb 20 14:00:10.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:00:10.261: INFO: namespace kubectl-219 deletion completed in 28.138574378s

• [SLOW TEST:36.187 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:00:10.278: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3021
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 20 14:00:11.229: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 20 14:00:13.259: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804011, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804011, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804011, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804011, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 20 14:00:16.285: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 14:00:16.291: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8296-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:00:17.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3021" for this suite.
Feb 20 14:00:23.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:00:23.203: INFO: namespace webhook-3021 deletion completed in 6.140718097s
STEP: Destroying namespace "webhook-3021-markers" for this suite.
Feb 20 14:00:29.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:00:29.330: INFO: namespace webhook-3021-markers deletion completed in 6.125815542s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.066 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:00:29.347: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4636
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4636.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4636.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 20 14:00:33.577: INFO: DNS probes using dns-4636/dns-test-3165b539-434d-43e2-8a92-516b7b5b547b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:00:33.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4636" for this suite.
Feb 20 14:00:39.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:00:39.705: INFO: namespace dns-4636 deletion completed in 6.107251571s

• [SLOW TEST:10.359 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:00:39.707: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9056
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-a80eafcc-da71-4214-9937-c4d2bd75463c
STEP: Creating a pod to test consume configMaps
Feb 20 14:00:39.866: INFO: Waiting up to 5m0s for pod "pod-configmaps-9eba0648-9a71-4bb6-ade4-cc4aacfaf464" in namespace "configmap-9056" to be "success or failure"
Feb 20 14:00:39.868: INFO: Pod "pod-configmaps-9eba0648-9a71-4bb6-ade4-cc4aacfaf464": Phase="Pending", Reason="", readiness=false. Elapsed: 2.234756ms
Feb 20 14:00:41.873: INFO: Pod "pod-configmaps-9eba0648-9a71-4bb6-ade4-cc4aacfaf464": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00663595s
Feb 20 14:00:43.878: INFO: Pod "pod-configmaps-9eba0648-9a71-4bb6-ade4-cc4aacfaf464": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012171512s
STEP: Saw pod success
Feb 20 14:00:43.879: INFO: Pod "pod-configmaps-9eba0648-9a71-4bb6-ade4-cc4aacfaf464" satisfied condition "success or failure"
Feb 20 14:00:43.882: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-configmaps-9eba0648-9a71-4bb6-ade4-cc4aacfaf464 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 14:00:43.900: INFO: Waiting for pod pod-configmaps-9eba0648-9a71-4bb6-ade4-cc4aacfaf464 to disappear
Feb 20 14:00:43.903: INFO: Pod pod-configmaps-9eba0648-9a71-4bb6-ade4-cc4aacfaf464 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:00:43.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9056" for this suite.
Feb 20 14:00:49.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:00:50.032: INFO: namespace configmap-9056 deletion completed in 6.124313793s

• [SLOW TEST:10.326 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:00:50.036: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-81
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 20 14:00:50.829: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 20 14:00:52.840: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804050, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804050, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804050, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804050, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 20 14:00:55.870: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:00:55.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-81" for this suite.
Feb 20 14:01:01.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:01:02.162: INFO: namespace webhook-81 deletion completed in 6.235603617s
STEP: Destroying namespace "webhook-81-markers" for this suite.
Feb 20 14:01:08.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:01:08.282: INFO: namespace webhook-81-markers deletion completed in 6.119891684s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.261 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:01:08.304: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-3338
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb 20 14:01:14.505: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3338 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 14:01:14.506: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
Feb 20 14:01:14.722: INFO: Exec stderr: ""
Feb 20 14:01:14.722: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3338 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 14:01:14.722: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
Feb 20 14:01:14.863: INFO: Exec stderr: ""
Feb 20 14:01:14.863: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3338 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 14:01:14.863: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
Feb 20 14:01:15.103: INFO: Exec stderr: ""
Feb 20 14:01:15.103: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3338 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 14:01:15.103: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
Feb 20 14:01:15.251: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb 20 14:01:15.252: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3338 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 14:01:15.252: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
Feb 20 14:01:15.618: INFO: Exec stderr: ""
Feb 20 14:01:15.618: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3338 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 14:01:15.618: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
Feb 20 14:01:15.767: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb 20 14:01:15.767: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3338 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 14:01:15.767: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
Feb 20 14:01:15.920: INFO: Exec stderr: ""
Feb 20 14:01:15.920: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3338 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 14:01:15.921: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
Feb 20 14:01:16.035: INFO: Exec stderr: ""
Feb 20 14:01:16.035: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3338 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 14:01:16.035: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
Feb 20 14:01:16.181: INFO: Exec stderr: ""
Feb 20 14:01:16.182: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3338 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 14:01:16.182: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
Feb 20 14:01:16.314: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:01:16.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-3338" for this suite.
Feb 20 14:02:00.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:02:00.450: INFO: namespace e2e-kubelet-etc-hosts-3338 deletion completed in 44.127970929s

• [SLOW TEST:52.147 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:02:00.452: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-4424
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Feb 20 14:02:00.640: INFO: Waiting up to 5m0s for pod "var-expansion-5908df80-ac44-48a1-a1c6-05ead62af39d" in namespace "var-expansion-4424" to be "success or failure"
Feb 20 14:02:00.660: INFO: Pod "var-expansion-5908df80-ac44-48a1-a1c6-05ead62af39d": Phase="Pending", Reason="", readiness=false. Elapsed: 19.777067ms
Feb 20 14:02:02.665: INFO: Pod "var-expansion-5908df80-ac44-48a1-a1c6-05ead62af39d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025119044s
Feb 20 14:02:04.672: INFO: Pod "var-expansion-5908df80-ac44-48a1-a1c6-05ead62af39d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031935614s
STEP: Saw pod success
Feb 20 14:02:04.673: INFO: Pod "var-expansion-5908df80-ac44-48a1-a1c6-05ead62af39d" satisfied condition "success or failure"
Feb 20 14:02:04.676: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod var-expansion-5908df80-ac44-48a1-a1c6-05ead62af39d container dapi-container: <nil>
STEP: delete the pod
Feb 20 14:02:04.709: INFO: Waiting for pod var-expansion-5908df80-ac44-48a1-a1c6-05ead62af39d to disappear
Feb 20 14:02:04.712: INFO: Pod var-expansion-5908df80-ac44-48a1-a1c6-05ead62af39d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:02:04.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4424" for this suite.
Feb 20 14:02:10.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:02:10.841: INFO: namespace var-expansion-4424 deletion completed in 6.114650341s

• [SLOW TEST:10.390 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:02:10.850: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-955
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 14:02:11.060: INFO: (0) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 10.405857ms)
Feb 20 14:02:11.065: INFO: (1) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 4.407169ms)
Feb 20 14:02:11.070: INFO: (2) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 4.319951ms)
Feb 20 14:02:11.075: INFO: (3) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 4.432847ms)
Feb 20 14:02:11.080: INFO: (4) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 4.679028ms)
Feb 20 14:02:11.084: INFO: (5) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 3.683234ms)
Feb 20 14:02:11.089: INFO: (6) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 3.782915ms)
Feb 20 14:02:11.092: INFO: (7) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 3.325765ms)
Feb 20 14:02:11.096: INFO: (8) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 3.710144ms)
Feb 20 14:02:11.101: INFO: (9) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 3.904357ms)
Feb 20 14:02:11.105: INFO: (10) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 3.299813ms)
Feb 20 14:02:11.108: INFO: (11) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 3.200439ms)
Feb 20 14:02:11.112: INFO: (12) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 3.259931ms)
Feb 20 14:02:11.115: INFO: (13) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 2.945012ms)
Feb 20 14:02:11.118: INFO: (14) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 2.913301ms)
Feb 20 14:02:11.123: INFO: (15) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 4.001114ms)
Feb 20 14:02:11.126: INFO: (16) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 3.406743ms)
Feb 20 14:02:11.130: INFO: (17) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 3.513034ms)
Feb 20 14:02:11.134: INFO: (18) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 3.488235ms)
Feb 20 14:02:11.138: INFO: (19) /api/v1/nodes/kube16prod-img-kube16prod-img-minion-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="atop/">atop/</a>
<a href="audit/">audit/</a>
<a ... (200; 3.701227ms)
[AfterEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:02:11.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-955" for this suite.
Feb 20 14:02:17.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:02:17.240: INFO: namespace proxy-955 deletion completed in 6.096765853s

• [SLOW TEST:6.390 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:02:17.248: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4965
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-4965
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-4965
Feb 20 14:02:17.407: INFO: Found 0 stateful pods, waiting for 1
Feb 20 14:02:27.415: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 20 14:02:27.439: INFO: Deleting all statefulset in ns statefulset-4965
Feb 20 14:02:27.446: INFO: Scaling statefulset ss to 0
Feb 20 14:02:37.468: INFO: Waiting for statefulset status.replicas updated to 0
Feb 20 14:02:37.472: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:02:37.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4965" for this suite.
Feb 20 14:02:43.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:02:43.614: INFO: namespace statefulset-4965 deletion completed in 6.121624107s

• [SLOW TEST:26.366 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:02:43.620: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-744
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 20 14:02:51.870: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 14:02:51.874: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 14:02:53.874: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 14:02:53.881: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 20 14:02:55.874: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 20 14:02:55.881: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:02:55.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-744" for this suite.
Feb 20 14:03:23.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:03:24.027: INFO: namespace container-lifecycle-hook-744 deletion completed in 28.139010816s

• [SLOW TEST:40.408 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:03:24.041: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-506
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 20 14:03:24.202: INFO: Waiting up to 5m0s for pod "pod-5a360fda-5596-4481-b31f-063cf40aecda" in namespace "emptydir-506" to be "success or failure"
Feb 20 14:03:24.208: INFO: Pod "pod-5a360fda-5596-4481-b31f-063cf40aecda": Phase="Pending", Reason="", readiness=false. Elapsed: 5.138007ms
Feb 20 14:03:26.212: INFO: Pod "pod-5a360fda-5596-4481-b31f-063cf40aecda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009172718s
Feb 20 14:03:28.215: INFO: Pod "pod-5a360fda-5596-4481-b31f-063cf40aecda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012857075s
STEP: Saw pod success
Feb 20 14:03:28.216: INFO: Pod "pod-5a360fda-5596-4481-b31f-063cf40aecda" satisfied condition "success or failure"
Feb 20 14:03:28.219: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-5a360fda-5596-4481-b31f-063cf40aecda container test-container: <nil>
STEP: delete the pod
Feb 20 14:03:28.236: INFO: Waiting for pod pod-5a360fda-5596-4481-b31f-063cf40aecda to disappear
Feb 20 14:03:28.240: INFO: Pod pod-5a360fda-5596-4481-b31f-063cf40aecda no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:03:28.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-506" for this suite.
Feb 20 14:03:34.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:03:34.351: INFO: namespace emptydir-506 deletion completed in 6.10675206s

• [SLOW TEST:10.311 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:03:34.360: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8048
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-8048
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8048 to expose endpoints map[]
Feb 20 14:03:34.538: INFO: successfully validated that service endpoint-test2 in namespace services-8048 exposes endpoints map[] (11.317043ms elapsed)
STEP: Creating pod pod1 in namespace services-8048
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8048 to expose endpoints map[pod1:[80]]
Feb 20 14:03:37.586: INFO: successfully validated that service endpoint-test2 in namespace services-8048 exposes endpoints map[pod1:[80]] (3.027521071s elapsed)
STEP: Creating pod pod2 in namespace services-8048
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8048 to expose endpoints map[pod1:[80] pod2:[80]]
Feb 20 14:03:40.632: INFO: successfully validated that service endpoint-test2 in namespace services-8048 exposes endpoints map[pod1:[80] pod2:[80]] (3.041940012s elapsed)
STEP: Deleting pod pod1 in namespace services-8048
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8048 to expose endpoints map[pod2:[80]]
Feb 20 14:03:40.651: INFO: successfully validated that service endpoint-test2 in namespace services-8048 exposes endpoints map[pod2:[80]] (8.259838ms elapsed)
STEP: Deleting pod pod2 in namespace services-8048
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8048 to expose endpoints map[]
Feb 20 14:03:41.664: INFO: successfully validated that service endpoint-test2 in namespace services-8048 exposes endpoints map[] (1.009247349s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:03:41.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8048" for this suite.
Feb 20 14:03:53.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:03:53.816: INFO: namespace services-8048 deletion completed in 12.122805554s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:19.458 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:03:53.826: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-996
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 20 14:03:53.983: INFO: Waiting up to 5m0s for pod "pod-1c61aaa9-2357-4d69-9a48-08c93f4fd75e" in namespace "emptydir-996" to be "success or failure"
Feb 20 14:03:53.987: INFO: Pod "pod-1c61aaa9-2357-4d69-9a48-08c93f4fd75e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.108587ms
Feb 20 14:03:55.991: INFO: Pod "pod-1c61aaa9-2357-4d69-9a48-08c93f4fd75e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008195126s
STEP: Saw pod success
Feb 20 14:03:55.991: INFO: Pod "pod-1c61aaa9-2357-4d69-9a48-08c93f4fd75e" satisfied condition "success or failure"
Feb 20 14:03:55.994: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-1c61aaa9-2357-4d69-9a48-08c93f4fd75e container test-container: <nil>
STEP: delete the pod
Feb 20 14:03:56.014: INFO: Waiting for pod pod-1c61aaa9-2357-4d69-9a48-08c93f4fd75e to disappear
Feb 20 14:03:56.017: INFO: Pod pod-1c61aaa9-2357-4d69-9a48-08c93f4fd75e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:03:56.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-996" for this suite.
Feb 20 14:04:02.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:04:02.154: INFO: namespace emptydir-996 deletion completed in 6.132292758s

• [SLOW TEST:8.329 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:04:02.158: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1332
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-1332
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1332 to expose endpoints map[]
Feb 20 14:04:02.336: INFO: successfully validated that service multi-endpoint-test in namespace services-1332 exposes endpoints map[] (18.316997ms elapsed)
STEP: Creating pod pod1 in namespace services-1332
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1332 to expose endpoints map[pod1:[100]]
Feb 20 14:04:05.395: INFO: successfully validated that service multi-endpoint-test in namespace services-1332 exposes endpoints map[pod1:[100]] (3.04944355s elapsed)
STEP: Creating pod pod2 in namespace services-1332
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1332 to expose endpoints map[pod1:[100] pod2:[101]]
Feb 20 14:04:07.431: INFO: successfully validated that service multi-endpoint-test in namespace services-1332 exposes endpoints map[pod1:[100] pod2:[101]] (2.030518584s elapsed)
STEP: Deleting pod pod1 in namespace services-1332
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1332 to expose endpoints map[pod2:[101]]
Feb 20 14:04:08.461: INFO: successfully validated that service multi-endpoint-test in namespace services-1332 exposes endpoints map[pod2:[101]] (1.023734238s elapsed)
STEP: Deleting pod pod2 in namespace services-1332
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1332 to expose endpoints map[]
Feb 20 14:04:08.471: INFO: successfully validated that service multi-endpoint-test in namespace services-1332 exposes endpoints map[] (3.709421ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:04:08.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1332" for this suite.
Feb 20 14:04:20.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:04:20.628: INFO: namespace services-1332 deletion completed in 12.135973011s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:18.471 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:04:20.633: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4714
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Feb 20 14:04:20.782: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb 20 14:04:20.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 create -f - --namespace=kubectl-4714'
Feb 20 14:04:21.350: INFO: stderr: ""
Feb 20 14:04:21.350: INFO: stdout: "service/redis-slave created\n"
Feb 20 14:04:21.351: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb 20 14:04:21.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 create -f - --namespace=kubectl-4714'
Feb 20 14:04:21.904: INFO: stderr: ""
Feb 20 14:04:21.905: INFO: stdout: "service/redis-master created\n"
Feb 20 14:04:21.905: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 20 14:04:21.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 create -f - --namespace=kubectl-4714'
Feb 20 14:04:22.405: INFO: stderr: ""
Feb 20 14:04:22.405: INFO: stdout: "service/frontend created\n"
Feb 20 14:04:22.406: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb 20 14:04:22.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 create -f - --namespace=kubectl-4714'
Feb 20 14:04:22.842: INFO: stderr: ""
Feb 20 14:04:22.842: INFO: stdout: "deployment.apps/frontend created\n"
Feb 20 14:04:22.843: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 20 14:04:22.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 create -f - --namespace=kubectl-4714'
Feb 20 14:04:23.340: INFO: stderr: ""
Feb 20 14:04:23.340: INFO: stdout: "deployment.apps/redis-master created\n"
Feb 20 14:04:23.342: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb 20 14:04:23.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 create -f - --namespace=kubectl-4714'
Feb 20 14:04:23.990: INFO: stderr: ""
Feb 20 14:04:23.990: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Feb 20 14:04:23.990: INFO: Waiting for all frontend pods to be Running.
Feb 20 14:04:49.049: INFO: Waiting for frontend to serve content.
Feb 20 14:04:49.073: INFO: Trying to add a new entry to the guestbook.
Feb 20 14:04:49.087: INFO: Verifying that added entry can be retrieved.
Feb 20 14:04:49.099: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 20 14:04:54.114: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 20 14:04:59.129: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 20 14:05:04.160: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 20 14:05:09.178: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 20 14:05:14.193: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 20 14:05:19.207: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 20 14:05:24.241: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Feb 20 14:05:29.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 delete --grace-period=0 --force -f - --namespace=kubectl-4714'
Feb 20 14:05:29.563: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 14:05:29.563: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 20 14:05:29.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 delete --grace-period=0 --force -f - --namespace=kubectl-4714'
Feb 20 14:05:29.805: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 14:05:29.805: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 20 14:05:29.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 delete --grace-period=0 --force -f - --namespace=kubectl-4714'
Feb 20 14:05:30.025: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 14:05:30.025: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 20 14:05:30.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 delete --grace-period=0 --force -f - --namespace=kubectl-4714'
Feb 20 14:05:30.245: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 14:05:30.245: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 20 14:05:30.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 delete --grace-period=0 --force -f - --namespace=kubectl-4714'
Feb 20 14:05:30.375: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 14:05:30.375: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 20 14:05:30.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 delete --grace-period=0 --force -f - --namespace=kubectl-4714'
Feb 20 14:05:30.519: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 20 14:05:30.519: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:05:30.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4714" for this suite.
Feb 20 14:05:58.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:05:58.670: INFO: namespace kubectl-4714 deletion completed in 28.139635584s

• [SLOW TEST:98.038 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:05:58.676: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-7657
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Feb 20 14:06:03.435: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7657 pod-service-account-6c12c38e-642b-4417-a548-fe6d56950469 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Feb 20 14:06:03.759: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7657 pod-service-account-6c12c38e-642b-4417-a548-fe6d56950469 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Feb 20 14:06:04.064: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7657 pod-service-account-6c12c38e-642b-4417-a548-fe6d56950469 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:06:04.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7657" for this suite.
Feb 20 14:06:10.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:06:10.491: INFO: namespace svcaccounts-7657 deletion completed in 6.107890261s

• [SLOW TEST:11.815 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:06:10.495: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4386
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb 20 14:06:10.637: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 20 14:06:10.647: INFO: Waiting for terminating namespaces to be deleted...
Feb 20 14:06:10.650: INFO: 
Logging pods the kubelet thinks is on node kube16prod-img-kube16prod-img-minion-1 before test
Feb 20 14:06:10.692: INFO: prometheus-operator-prometheus-node-exporter-c2v94 from prometheus-monitoring started at 2020-02-20 10:28:15 +0000 UTC (1 container statuses recorded)
Feb 20 14:06:10.693: INFO: 	Container node-exporter ready: true, restart count 0
Feb 20 14:06:10.693: INFO: metrics-server-f96ddff8f-h2kx6 from kube-system started at 2020-02-20 10:40:28 +0000 UTC (1 container statuses recorded)
Feb 20 14:06:10.693: INFO: 	Container metrics-server ready: true, restart count 0
Feb 20 14:06:10.693: INFO: calico-node-vkbjk from kube-system started at 2020-02-20 10:28:15 +0000 UTC (2 container statuses recorded)
Feb 20 14:06:10.694: INFO: 	Container calico-node ready: true, restart count 0
Feb 20 14:06:10.694: INFO: 	Container install-cni ready: true, restart count 0
Feb 20 14:06:10.694: INFO: calico-kube-controllers-555d6f4bd9-xfg9t from kube-system started at 2020-02-20 10:56:19 +0000 UTC (1 container statuses recorded)
Feb 20 14:06:10.694: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 20 14:06:10.694: INFO: sonobuoy-systemd-logs-daemon-set-27e71f1a82d14495-ggbs7 from sonobuoy started at 2020-02-20 12:25:04 +0000 UTC (2 container statuses recorded)
Feb 20 14:06:10.694: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 20 14:06:10.695: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 20 14:06:10.695: INFO: 
Logging pods the kubelet thinks is on node kube16prod-img-kube16prod-img-minion-2 before test
Feb 20 14:06:10.736: INFO: calico-node-6fj4h from kube-system started at 2020-02-20 12:20:59 +0000 UTC (2 container statuses recorded)
Feb 20 14:06:10.736: INFO: 	Container calico-node ready: true, restart count 0
Feb 20 14:06:10.736: INFO: 	Container install-cni ready: true, restart count 0
Feb 20 14:06:10.736: INFO: prometheus-operator-prometheus-node-exporter-wr9zk from prometheus-monitoring started at 2020-02-20 12:20:59 +0000 UTC (1 container statuses recorded)
Feb 20 14:06:10.736: INFO: 	Container node-exporter ready: true, restart count 0
Feb 20 14:06:10.736: INFO: sonobuoy from sonobuoy started at 2020-02-20 12:24:54 +0000 UTC (1 container statuses recorded)
Feb 20 14:06:10.736: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 20 14:06:10.736: INFO: sonobuoy-e2e-job-3610336cc2ba449a from sonobuoy started at 2020-02-20 12:25:05 +0000 UTC (2 container statuses recorded)
Feb 20 14:06:10.736: INFO: 	Container e2e ready: true, restart count 0
Feb 20 14:06:10.736: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 20 14:06:10.736: INFO: sonobuoy-systemd-logs-daemon-set-27e71f1a82d14495-fj7b9 from sonobuoy started at 2020-02-20 12:25:05 +0000 UTC (2 container statuses recorded)
Feb 20 14:06:10.736: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 20 14:06:10.736: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15f5216718114e2c], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:06:11.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4386" for this suite.
Feb 20 14:06:17.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:06:17.877: INFO: namespace sched-pred-4386 deletion completed in 6.106451714s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:7.384 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:06:17.882: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1977
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 14:06:18.057: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 20 14:06:18.065: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 14:06:18.068: INFO: Number of nodes with available pods: 0
Feb 20 14:06:18.068: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 14:06:19.073: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 14:06:19.078: INFO: Number of nodes with available pods: 0
Feb 20 14:06:19.078: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 14:06:20.078: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 14:06:20.084: INFO: Number of nodes with available pods: 1
Feb 20 14:06:20.084: INFO: Node kube16prod-img-kube16prod-img-minion-2 is running more than one daemon pod
Feb 20 14:06:21.073: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 14:06:21.079: INFO: Number of nodes with available pods: 2
Feb 20 14:06:21.079: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 20 14:06:21.112: INFO: Wrong image for pod: daemon-set-bgcqp. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:21.112: INFO: Wrong image for pod: daemon-set-zppm4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:21.116: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 14:06:22.120: INFO: Wrong image for pod: daemon-set-bgcqp. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:22.121: INFO: Wrong image for pod: daemon-set-zppm4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:22.126: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 14:06:23.121: INFO: Wrong image for pod: daemon-set-bgcqp. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:23.122: INFO: Wrong image for pod: daemon-set-zppm4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:23.126: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 14:06:24.121: INFO: Wrong image for pod: daemon-set-bgcqp. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:24.122: INFO: Wrong image for pod: daemon-set-zppm4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:24.122: INFO: Pod daemon-set-zppm4 is not available
Feb 20 14:06:24.127: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 14:06:25.120: INFO: Wrong image for pod: daemon-set-bgcqp. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:25.120: INFO: Wrong image for pod: daemon-set-zppm4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:25.120: INFO: Pod daemon-set-zppm4 is not available
Feb 20 14:06:25.125: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 14:06:26.120: INFO: Wrong image for pod: daemon-set-bgcqp. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:26.121: INFO: Wrong image for pod: daemon-set-zppm4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:26.121: INFO: Pod daemon-set-zppm4 is not available
Feb 20 14:06:26.126: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 14:06:27.121: INFO: Wrong image for pod: daemon-set-bgcqp. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:27.121: INFO: Wrong image for pod: daemon-set-zppm4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:27.121: INFO: Pod daemon-set-zppm4 is not available
Feb 20 14:06:27.127: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 14:06:28.120: INFO: Wrong image for pod: daemon-set-bgcqp. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:28.120: INFO: Wrong image for pod: daemon-set-zppm4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:28.120: INFO: Pod daemon-set-zppm4 is not available
Feb 20 14:06:28.124: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 14:06:29.121: INFO: Wrong image for pod: daemon-set-bgcqp. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:29.122: INFO: Wrong image for pod: daemon-set-zppm4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:29.122: INFO: Pod daemon-set-zppm4 is not available
Feb 20 14:06:29.127: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 14:06:30.120: INFO: Wrong image for pod: daemon-set-bgcqp. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:30.120: INFO: Wrong image for pod: daemon-set-zppm4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:30.120: INFO: Pod daemon-set-zppm4 is not available
Feb 20 14:06:30.124: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 14:06:31.121: INFO: Wrong image for pod: daemon-set-bgcqp. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:31.121: INFO: Wrong image for pod: daemon-set-zppm4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:31.121: INFO: Pod daemon-set-zppm4 is not available
Feb 20 14:06:31.127: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 14:06:32.120: INFO: Wrong image for pod: daemon-set-bgcqp. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:32.120: INFO: Pod daemon-set-cmtvr is not available
Feb 20 14:06:32.127: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 14:06:33.122: INFO: Wrong image for pod: daemon-set-bgcqp. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:33.124: INFO: Pod daemon-set-cmtvr is not available
Feb 20 14:06:33.137: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 14:06:34.120: INFO: Wrong image for pod: daemon-set-bgcqp. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:34.125: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 14:06:35.121: INFO: Wrong image for pod: daemon-set-bgcqp. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 20 14:06:35.121: INFO: Pod daemon-set-bgcqp is not available
Feb 20 14:06:35.126: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 14:06:36.120: INFO: Pod daemon-set-7b4z6 is not available
Feb 20 14:06:36.125: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 20 14:06:36.131: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 14:06:36.135: INFO: Number of nodes with available pods: 1
Feb 20 14:06:36.135: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 14:06:37.141: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 14:06:37.146: INFO: Number of nodes with available pods: 1
Feb 20 14:06:37.147: INFO: Node kube16prod-img-kube16prod-img-minion-1 is running more than one daemon pod
Feb 20 14:06:38.142: INFO: DaemonSet pods can't tolerate node kube16prod-img-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 20 14:06:38.146: INFO: Number of nodes with available pods: 2
Feb 20 14:06:38.146: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1977, will wait for the garbage collector to delete the pods
Feb 20 14:06:38.222: INFO: Deleting DaemonSet.extensions daemon-set took: 5.449768ms
Feb 20 14:06:39.125: INFO: Terminating DaemonSet.extensions daemon-set pods took: 902.470604ms
Feb 20 14:06:42.131: INFO: Number of nodes with available pods: 0
Feb 20 14:06:42.132: INFO: Number of running nodes: 0, number of available pods: 0
Feb 20 14:06:42.136: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1977/daemonsets","resourceVersion":"247369"},"items":null}

Feb 20 14:06:42.139: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1977/pods","resourceVersion":"247369"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:06:42.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1977" for this suite.
Feb 20 14:06:48.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:06:48.272: INFO: namespace daemonsets-1977 deletion completed in 6.115301381s

• [SLOW TEST:30.391 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:06:48.280: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5171
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 14:06:48.439: INFO: Creating deployment "webserver-deployment"
Feb 20 14:06:48.443: INFO: Waiting for observed generation 1
Feb 20 14:06:50.451: INFO: Waiting for all required pods to come up
Feb 20 14:06:50.457: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb 20 14:06:56.490: INFO: Waiting for deployment "webserver-deployment" to complete
Feb 20 14:06:56.500: INFO: Updating deployment "webserver-deployment" with a non-existent image
Feb 20 14:06:56.508: INFO: Updating deployment webserver-deployment
Feb 20 14:06:56.508: INFO: Waiting for observed generation 2
Feb 20 14:06:58.531: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 20 14:06:58.535: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 20 14:06:58.546: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Feb 20 14:06:58.564: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 20 14:06:58.564: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 20 14:06:58.573: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Feb 20 14:06:58.579: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Feb 20 14:06:58.581: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Feb 20 14:06:58.587: INFO: Updating deployment webserver-deployment
Feb 20 14:06:58.587: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Feb 20 14:06:58.595: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 20 14:06:58.601: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb 20 14:07:00.627: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-5171 /apis/apps/v1/namespaces/deployment-5171/deployments/webserver-deployment 14183162-29ff-4573-90b9-0926bfff35a6 247747 3 2020-02-20 14:06:48 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0005b8d58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-02-20 14:06:58 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2020-02-20 14:06:58 +0000 UTC,LastTransitionTime:2020-02-20 14:06:48 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Feb 20 14:07:00.632: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-5171 /apis/apps/v1/namespaces/deployment-5171/replicasets/webserver-deployment-c7997dcc8 150030c1-946d-4a9e-bc86-cdbb822d17c8 247730 3 2020-02-20 14:06:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 14183162-29ff-4573-90b9-0926bfff35a6 0xc0005b93d7 0xc0005b93d8}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0005b9448 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 20 14:07:00.632: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Feb 20 14:07:00.632: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-5171 /apis/apps/v1/namespaces/deployment-5171/replicasets/webserver-deployment-595b5b9587 45b69661-f6a6-489e-9c04-24a940a8898a 247746 3 2020-02-20 14:06:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 14183162-29ff-4573-90b9-0926bfff35a6 0xc0005b9297 0xc0005b9298}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0005b9378 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Feb 20 14:07:00.659: INFO: Pod "webserver-deployment-595b5b9587-5pgh4" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-5pgh4 webserver-deployment-595b5b9587- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-595b5b9587-5pgh4 4feb455f-769a-40db-af48-315672cf1939 247783 0 2020-02-20 14:06:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 45b69661-f6a6-489e-9c04-24a940a8898a 0xc002a162f7 0xc002a162f8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.29,PodIP:,StartTime:2020-02-20 14:06:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.660: INFO: Pod "webserver-deployment-595b5b9587-5tl7d" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-5tl7d webserver-deployment-595b5b9587- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-595b5b9587-5tl7d 1e87d8a6-d101-44a1-8749-ad9180794b0f 247722 0 2020-02-20 14:06:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 45b69661-f6a6-489e-9c04-24a940a8898a 0xc002a16410 0xc002a16411}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.660: INFO: Pod "webserver-deployment-595b5b9587-7tw98" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-7tw98 webserver-deployment-595b5b9587- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-595b5b9587-7tw98 ea0fce57-f2b7-457c-82f1-0ce164dac16f 247779 0 2020-02-20 14:06:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 45b69661-f6a6-489e-9c04-24a940a8898a 0xc002a164d0 0xc002a164d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.8,PodIP:,StartTime:2020-02-20 14:06:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.666: INFO: Pod "webserver-deployment-595b5b9587-bpxch" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-bpxch webserver-deployment-595b5b9587- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-595b5b9587-bpxch 28c55c92-5fcd-4ff5-9ac1-0c2bee34d35e 247748 0 2020-02-20 14:06:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 45b69661-f6a6-489e-9c04-24a940a8898a 0xc002a165d0 0xc002a165d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.29,PodIP:,StartTime:2020-02-20 14:06:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.666: INFO: Pod "webserver-deployment-595b5b9587-f8fvh" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-f8fvh webserver-deployment-595b5b9587- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-595b5b9587-f8fvh e7497a01-1f60-472b-afd7-736708f210d2 247549 0 2020-02-20 14:06:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 45b69661-f6a6-489e-9c04-24a940a8898a 0xc002a16710 0xc002a16711}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.29,PodIP:10.100.99.174,StartTime:2020-02-20 14:06:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-20 14:06:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://b5f6e6f3d8e3a27e0a2375c7d02eb754c4d5c48dcfd62ed1390189730c8d6641,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.99.174,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.667: INFO: Pod "webserver-deployment-595b5b9587-fnmfv" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-fnmfv webserver-deployment-595b5b9587- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-595b5b9587-fnmfv 50e87402-2437-4b56-952b-f3cb27b61fed 247583 0 2020-02-20 14:06:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 45b69661-f6a6-489e-9c04-24a940a8898a 0xc002a16850 0xc002a16851}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.8,PodIP:10.100.81.133,StartTime:2020-02-20 14:06:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-20 14:06:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://7be2bf07b4dd6eeaab6c4d37a71bc8ce56ff9781264d9bf4371975e6c2ece42e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.81.133,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.667: INFO: Pod "webserver-deployment-595b5b9587-gn6hx" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gn6hx webserver-deployment-595b5b9587- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-595b5b9587-gn6hx a3616557-bb0b-4e05-89ea-a2f97013d651 247763 0 2020-02-20 14:06:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 45b69661-f6a6-489e-9c04-24a940a8898a 0xc002a16990 0xc002a16991}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.8,PodIP:,StartTime:2020-02-20 14:06:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.681: INFO: Pod "webserver-deployment-595b5b9587-gphcn" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gphcn webserver-deployment-595b5b9587- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-595b5b9587-gphcn 77bad07d-27ea-4061-9f22-ff58893ba2be 247728 0 2020-02-20 14:06:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 45b69661-f6a6-489e-9c04-24a940a8898a 0xc002a16a90 0xc002a16a91}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.8,PodIP:,StartTime:2020-02-20 14:06:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.682: INFO: Pod "webserver-deployment-595b5b9587-hs75l" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-hs75l webserver-deployment-595b5b9587- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-595b5b9587-hs75l fba46bcd-c261-41ac-837c-b40e037feef8 247555 0 2020-02-20 14:06:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 45b69661-f6a6-489e-9c04-24a940a8898a 0xc002a16ba0 0xc002a16ba1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.29,PodIP:10.100.99.175,StartTime:2020-02-20 14:06:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-20 14:06:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://61bc7c9f585300b150d8bc2dcb5a7ae154a2d7b788347e019b50e7abcc9c4775,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.99.175,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.683: INFO: Pod "webserver-deployment-595b5b9587-jbq4w" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-jbq4w webserver-deployment-595b5b9587- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-595b5b9587-jbq4w 8873b723-ddee-4288-8db5-037020d3a079 247573 0 2020-02-20 14:06:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 45b69661-f6a6-489e-9c04-24a940a8898a 0xc002a16cc0 0xc002a16cc1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.29,PodIP:10.100.99.180,StartTime:2020-02-20 14:06:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-20 14:06:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://a58e89b51ae79e9c6a1e6b23a593b2378bd95ba4fe8a6bc056c02cb33a483202,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.99.180,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.683: INFO: Pod "webserver-deployment-595b5b9587-pgftl" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pgftl webserver-deployment-595b5b9587- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-595b5b9587-pgftl 60259600-7a0a-4fb8-86c3-5c787855bf99 247776 0 2020-02-20 14:06:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 45b69661-f6a6-489e-9c04-24a940a8898a 0xc002a16de0 0xc002a16de1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.8,PodIP:,StartTime:2020-02-20 14:06:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.684: INFO: Pod "webserver-deployment-595b5b9587-ptsgs" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-ptsgs webserver-deployment-595b5b9587- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-595b5b9587-ptsgs a8683475-b8a8-4748-b938-1847c1b215d6 247566 0 2020-02-20 14:06:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 45b69661-f6a6-489e-9c04-24a940a8898a 0xc002a16ef0 0xc002a16ef1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.29,PodIP:10.100.99.181,StartTime:2020-02-20 14:06:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-20 14:06:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://46452bda9ccdacfb2110c5f2e69efec8124be79e64a798e03032fe05a9327d25,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.99.181,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.684: INFO: Pod "webserver-deployment-595b5b9587-q4qzl" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-q4qzl webserver-deployment-595b5b9587- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-595b5b9587-q4qzl 149c59b4-8698-4f07-84a0-33455c5c84f8 247756 0 2020-02-20 14:06:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 45b69661-f6a6-489e-9c04-24a940a8898a 0xc002a17040 0xc002a17041}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.29,PodIP:,StartTime:2020-02-20 14:06:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.684: INFO: Pod "webserver-deployment-595b5b9587-qm2vs" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-qm2vs webserver-deployment-595b5b9587- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-595b5b9587-qm2vs 7567e423-8e0d-46b1-9322-7eaf304fe25c 247586 0 2020-02-20 14:06:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 45b69661-f6a6-489e-9c04-24a940a8898a 0xc002a17140 0xc002a17141}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.8,PodIP:10.100.81.131,StartTime:2020-02-20 14:06:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-20 14:06:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://650d230216aa868a85e5cf3f05e8dee456f796799a6485d3d90ccb34f1911bbf,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.81.131,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.687: INFO: Pod "webserver-deployment-595b5b9587-rkjrg" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-rkjrg webserver-deployment-595b5b9587- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-595b5b9587-rkjrg ebce5c0c-4bef-4a15-9164-845bcfaaedf9 247778 0 2020-02-20 14:06:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 45b69661-f6a6-489e-9c04-24a940a8898a 0xc002a17260 0xc002a17261}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.29,PodIP:,StartTime:2020-02-20 14:06:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.688: INFO: Pod "webserver-deployment-595b5b9587-s6bv2" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-s6bv2 webserver-deployment-595b5b9587- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-595b5b9587-s6bv2 db2d32e2-a80a-4636-a2cf-976dcd05749b 247754 0 2020-02-20 14:06:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 45b69661-f6a6-489e-9c04-24a940a8898a 0xc002a173a0 0xc002a173a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.8,PodIP:,StartTime:2020-02-20 14:06:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.688: INFO: Pod "webserver-deployment-595b5b9587-sdt9b" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-sdt9b webserver-deployment-595b5b9587- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-595b5b9587-sdt9b f1613c86-edb8-43d8-86c7-4e2cc0a9a688 247580 0 2020-02-20 14:06:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 45b69661-f6a6-489e-9c04-24a940a8898a 0xc002a17650 0xc002a17651}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.8,PodIP:10.100.81.191,StartTime:2020-02-20 14:06:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-20 14:06:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://a4b81fdd6c0da39818da2d6dfca6c6202b2bfc20142b347a083c30bff7cf8af5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.81.191,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.689: INFO: Pod "webserver-deployment-595b5b9587-v2hlc" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-v2hlc webserver-deployment-595b5b9587- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-595b5b9587-v2hlc 55554a9b-b765-42cb-b19d-77c77c8e78b8 247751 0 2020-02-20 14:06:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 45b69661-f6a6-489e-9c04-24a940a8898a 0xc002a17770 0xc002a17771}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.29,PodIP:,StartTime:2020-02-20 14:06:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.690: INFO: Pod "webserver-deployment-595b5b9587-xl5s8" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-xl5s8 webserver-deployment-595b5b9587- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-595b5b9587-xl5s8 ae67c157-c9b8-483f-bfea-e63619761bbb 247570 0 2020-02-20 14:06:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 45b69661-f6a6-489e-9c04-24a940a8898a 0xc002a17920 0xc002a17921}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.29,PodIP:10.100.99.179,StartTime:2020-02-20 14:06:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-20 14:06:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://3ce7ea48bc3f2bd6d403e11c75b2adf1389664e07d5ffc272715cfaa49862fe9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.99.179,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.693: INFO: Pod "webserver-deployment-595b5b9587-xt4sc" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-xt4sc webserver-deployment-595b5b9587- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-595b5b9587-xt4sc e37b1239-3ef3-41cb-ac7c-2e93a5fce30c 247768 0 2020-02-20 14:06:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 45b69661-f6a6-489e-9c04-24a940a8898a 0xc002a17bb0 0xc002a17bb1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.8,PodIP:,StartTime:2020-02-20 14:06:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.694: INFO: Pod "webserver-deployment-c7997dcc8-5z4lb" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-5z4lb webserver-deployment-c7997dcc8- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-c7997dcc8-5z4lb b4f02371-69b9-491a-bbe5-3ef1431dea19 247724 0 2020-02-20 14:06:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 150030c1-946d-4a9e-bc86-cdbb822d17c8 0xc002a17cb0 0xc002a17cb1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.29,PodIP:,StartTime:2020-02-20 14:06:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.695: INFO: Pod "webserver-deployment-c7997dcc8-9wvjs" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-9wvjs webserver-deployment-c7997dcc8- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-c7997dcc8-9wvjs 445e4dd9-e548-4b43-bb46-4d6e1c433c4f 247780 0 2020-02-20 14:06:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 150030c1-946d-4a9e-bc86-cdbb822d17c8 0xc002a17e60 0xc002a17e61}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.8,PodIP:,StartTime:2020-02-20 14:06:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.695: INFO: Pod "webserver-deployment-c7997dcc8-bfdzt" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-bfdzt webserver-deployment-c7997dcc8- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-c7997dcc8-bfdzt af7fb259-99e0-4d36-8f01-a802c90432e5 247647 0 2020-02-20 14:06:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 150030c1-946d-4a9e-bc86-cdbb822d17c8 0xc002a17f80 0xc002a17f81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.8,PodIP:,StartTime:2020-02-20 14:06:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.697: INFO: Pod "webserver-deployment-c7997dcc8-fkqk6" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-fkqk6 webserver-deployment-c7997dcc8- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-c7997dcc8-fkqk6 4907cd61-99d8-4b18-bbbe-6b83ebcbf34f 247725 0 2020-02-20 14:06:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 150030c1-946d-4a9e-bc86-cdbb822d17c8 0xc0026160d0 0xc0026160d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.698: INFO: Pod "webserver-deployment-c7997dcc8-fps64" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-fps64 webserver-deployment-c7997dcc8- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-c7997dcc8-fps64 9cc28c1f-d41b-4543-800e-780a877a2aff 247648 0 2020-02-20 14:06:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 150030c1-946d-4a9e-bc86-cdbb822d17c8 0xc0026161a0 0xc0026161a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.8,PodIP:,StartTime:2020-02-20 14:06:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.698: INFO: Pod "webserver-deployment-c7997dcc8-frjc5" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-frjc5 webserver-deployment-c7997dcc8- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-c7997dcc8-frjc5 24f07754-ae0d-4e4c-bd86-3e91dcdcfbf1 247782 0 2020-02-20 14:06:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 150030c1-946d-4a9e-bc86-cdbb822d17c8 0xc0026163d0 0xc0026163d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.8,PodIP:,StartTime:2020-02-20 14:06:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.699: INFO: Pod "webserver-deployment-c7997dcc8-fs8ds" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-fs8ds webserver-deployment-c7997dcc8- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-c7997dcc8-fs8ds 95931391-a55b-41ad-b0e6-d3cbfe24cd19 247766 0 2020-02-20 14:06:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 150030c1-946d-4a9e-bc86-cdbb822d17c8 0xc002616720 0xc002616721}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.29,PodIP:,StartTime:2020-02-20 14:06:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.702: INFO: Pod "webserver-deployment-c7997dcc8-g5xmd" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-g5xmd webserver-deployment-c7997dcc8- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-c7997dcc8-g5xmd 901cda7e-d8f9-4608-801b-7c09546275b4 247627 0 2020-02-20 14:06:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 150030c1-946d-4a9e-bc86-cdbb822d17c8 0xc002616900 0xc002616901}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.29,PodIP:,StartTime:2020-02-20 14:06:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.702: INFO: Pod "webserver-deployment-c7997dcc8-g7zrp" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-g7zrp webserver-deployment-c7997dcc8- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-c7997dcc8-g7zrp b5c4d3d8-2ecb-43d7-8e41-6734b09f2377 247643 0 2020-02-20 14:06:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 150030c1-946d-4a9e-bc86-cdbb822d17c8 0xc002616a30 0xc002616a31}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.29,PodIP:,StartTime:2020-02-20 14:06:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.703: INFO: Pod "webserver-deployment-c7997dcc8-kdfp7" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-kdfp7 webserver-deployment-c7997dcc8- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-c7997dcc8-kdfp7 3bce6e31-6672-4174-a5a9-3cfdbff83c39 247781 0 2020-02-20 14:06:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 150030c1-946d-4a9e-bc86-cdbb822d17c8 0xc002616b80 0xc002616b81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.8,PodIP:,StartTime:2020-02-20 14:06:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.703: INFO: Pod "webserver-deployment-c7997dcc8-vxw26" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-vxw26 webserver-deployment-c7997dcc8- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-c7997dcc8-vxw26 a8ee264b-0918-41a0-88d8-5330b995c744 247646 0 2020-02-20 14:06:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 150030c1-946d-4a9e-bc86-cdbb822d17c8 0xc002616e10 0xc002616e11}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.8,PodIP:,StartTime:2020-02-20 14:06:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.703: INFO: Pod "webserver-deployment-c7997dcc8-wzr48" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-wzr48 webserver-deployment-c7997dcc8- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-c7997dcc8-wzr48 2f959fcb-e570-49e4-9646-d453a1c65329 247749 0 2020-02-20 14:06:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 150030c1-946d-4a9e-bc86-cdbb822d17c8 0xc002616f30 0xc002616f31}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.29,PodIP:,StartTime:2020-02-20 14:06:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 20 14:07:00.704: INFO: Pod "webserver-deployment-c7997dcc8-x2cnw" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-x2cnw webserver-deployment-c7997dcc8- deployment-5171 /api/v1/namespaces/deployment-5171/pods/webserver-deployment-c7997dcc8-x2cnw 8794846e-b678-4f4e-a654-57efdf70218e 247752 0 2020-02-20 14:06:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 150030c1-946d-4a9e-bc86-cdbb822d17c8 0xc002617070 0xc002617071}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z85q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z85q9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z85q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:06:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.29,PodIP:,StartTime:2020-02-20 14:06:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:07:00.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5171" for this suite.
Feb 20 14:07:08.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:07:08.901: INFO: namespace deployment-5171 deletion completed in 8.168053918s

• [SLOW TEST:20.622 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:07:08.903: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-393
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 20 14:07:09.089: INFO: Waiting up to 5m0s for pod "pod-e1fb988a-5cb8-44ee-8406-d88a87fef114" in namespace "emptydir-393" to be "success or failure"
Feb 20 14:07:09.091: INFO: Pod "pod-e1fb988a-5cb8-44ee-8406-d88a87fef114": Phase="Pending", Reason="", readiness=false. Elapsed: 2.609008ms
Feb 20 14:07:11.098: INFO: Pod "pod-e1fb988a-5cb8-44ee-8406-d88a87fef114": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009051345s
Feb 20 14:07:13.110: INFO: Pod "pod-e1fb988a-5cb8-44ee-8406-d88a87fef114": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020876169s
Feb 20 14:07:15.115: INFO: Pod "pod-e1fb988a-5cb8-44ee-8406-d88a87fef114": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026600669s
STEP: Saw pod success
Feb 20 14:07:15.116: INFO: Pod "pod-e1fb988a-5cb8-44ee-8406-d88a87fef114" satisfied condition "success or failure"
Feb 20 14:07:15.119: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-e1fb988a-5cb8-44ee-8406-d88a87fef114 container test-container: <nil>
STEP: delete the pod
Feb 20 14:07:15.173: INFO: Waiting for pod pod-e1fb988a-5cb8-44ee-8406-d88a87fef114 to disappear
Feb 20 14:07:15.186: INFO: Pod pod-e1fb988a-5cb8-44ee-8406-d88a87fef114 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:07:15.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-393" for this suite.
Feb 20 14:07:21.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:07:21.292: INFO: namespace emptydir-393 deletion completed in 6.0998672s

• [SLOW TEST:12.390 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:07:21.302: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8514
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Feb 20 14:07:21.489: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:07:55.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8514" for this suite.
Feb 20 14:08:01.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:08:01.186: INFO: namespace crd-publish-openapi-8514 deletion completed in 6.126814027s

• [SLOW TEST:39.884 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:08:01.194: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5901
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 20 14:08:02.493: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 20 14:08:04.506: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804482, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804482, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804482, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804482, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 20 14:08:07.525: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Feb 20 14:08:07.557: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:08:07.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5901" for this suite.
Feb 20 14:08:13.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:08:13.679: INFO: namespace webhook-5901 deletion completed in 6.099447202s
STEP: Destroying namespace "webhook-5901-markers" for this suite.
Feb 20 14:08:19.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:08:19.805: INFO: namespace webhook-5901-markers deletion completed in 6.124590977s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.624 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:08:19.831: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5911
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb 20 14:08:19.990: INFO: Waiting up to 5m0s for pod "downward-api-bcf822d8-8e4b-45b0-a2d7-c8ec3cddf6c3" in namespace "downward-api-5911" to be "success or failure"
Feb 20 14:08:20.000: INFO: Pod "downward-api-bcf822d8-8e4b-45b0-a2d7-c8ec3cddf6c3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.886761ms
Feb 20 14:08:22.008: INFO: Pod "downward-api-bcf822d8-8e4b-45b0-a2d7-c8ec3cddf6c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018127732s
Feb 20 14:08:24.013: INFO: Pod "downward-api-bcf822d8-8e4b-45b0-a2d7-c8ec3cddf6c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023050467s
STEP: Saw pod success
Feb 20 14:08:24.014: INFO: Pod "downward-api-bcf822d8-8e4b-45b0-a2d7-c8ec3cddf6c3" satisfied condition "success or failure"
Feb 20 14:08:24.016: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod downward-api-bcf822d8-8e4b-45b0-a2d7-c8ec3cddf6c3 container dapi-container: <nil>
STEP: delete the pod
Feb 20 14:08:24.043: INFO: Waiting for pod downward-api-bcf822d8-8e4b-45b0-a2d7-c8ec3cddf6c3 to disappear
Feb 20 14:08:24.045: INFO: Pod downward-api-bcf822d8-8e4b-45b0-a2d7-c8ec3cddf6c3 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:08:24.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5911" for this suite.
Feb 20 14:08:30.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:08:30.185: INFO: namespace downward-api-5911 deletion completed in 6.135618376s

• [SLOW TEST:10.356 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:08:30.191: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8486
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 20 14:08:38.469: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 20 14:08:38.475: INFO: Pod pod-with-poststart-http-hook still exists
Feb 20 14:08:40.475: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 20 14:08:40.480: INFO: Pod pod-with-poststart-http-hook still exists
Feb 20 14:08:42.475: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 20 14:08:42.479: INFO: Pod pod-with-poststart-http-hook still exists
Feb 20 14:08:44.475: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 20 14:08:44.482: INFO: Pod pod-with-poststart-http-hook still exists
Feb 20 14:08:46.475: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 20 14:08:46.480: INFO: Pod pod-with-poststart-http-hook still exists
Feb 20 14:08:48.475: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 20 14:08:48.481: INFO: Pod pod-with-poststart-http-hook still exists
Feb 20 14:08:50.475: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 20 14:08:50.481: INFO: Pod pod-with-poststart-http-hook still exists
Feb 20 14:08:52.475: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 20 14:08:52.481: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:08:52.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8486" for this suite.
Feb 20 14:09:04.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:09:04.608: INFO: namespace container-lifecycle-hook-8486 deletion completed in 12.119441868s

• [SLOW TEST:34.418 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:09:04.613: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2353
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-e4d876e8-7169-4876-aa23-28409db55a80
STEP: Creating a pod to test consume secrets
Feb 20 14:09:04.793: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-280ac446-428f-48c7-b7e3-07342b0536f5" in namespace "projected-2353" to be "success or failure"
Feb 20 14:09:04.800: INFO: Pod "pod-projected-secrets-280ac446-428f-48c7-b7e3-07342b0536f5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.09278ms
Feb 20 14:09:06.805: INFO: Pod "pod-projected-secrets-280ac446-428f-48c7-b7e3-07342b0536f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011972421s
STEP: Saw pod success
Feb 20 14:09:06.805: INFO: Pod "pod-projected-secrets-280ac446-428f-48c7-b7e3-07342b0536f5" satisfied condition "success or failure"
Feb 20 14:09:06.808: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-projected-secrets-280ac446-428f-48c7-b7e3-07342b0536f5 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 20 14:09:06.829: INFO: Waiting for pod pod-projected-secrets-280ac446-428f-48c7-b7e3-07342b0536f5 to disappear
Feb 20 14:09:06.832: INFO: Pod pod-projected-secrets-280ac446-428f-48c7-b7e3-07342b0536f5 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:09:06.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2353" for this suite.
Feb 20 14:09:12.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:09:12.953: INFO: namespace projected-2353 deletion completed in 6.114980804s

• [SLOW TEST:8.340 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:09:12.968: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3100
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 20 14:09:13.122: INFO: Waiting up to 5m0s for pod "pod-82773603-1934-4f82-9626-248fa946ab5e" in namespace "emptydir-3100" to be "success or failure"
Feb 20 14:09:13.126: INFO: Pod "pod-82773603-1934-4f82-9626-248fa946ab5e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.334726ms
Feb 20 14:09:15.130: INFO: Pod "pod-82773603-1934-4f82-9626-248fa946ab5e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007419677s
Feb 20 14:09:17.134: INFO: Pod "pod-82773603-1934-4f82-9626-248fa946ab5e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011218658s
STEP: Saw pod success
Feb 20 14:09:17.134: INFO: Pod "pod-82773603-1934-4f82-9626-248fa946ab5e" satisfied condition "success or failure"
Feb 20 14:09:17.137: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-82773603-1934-4f82-9626-248fa946ab5e container test-container: <nil>
STEP: delete the pod
Feb 20 14:09:17.154: INFO: Waiting for pod pod-82773603-1934-4f82-9626-248fa946ab5e to disappear
Feb 20 14:09:17.156: INFO: Pod pod-82773603-1934-4f82-9626-248fa946ab5e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:09:17.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3100" for this suite.
Feb 20 14:09:23.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:09:23.284: INFO: namespace emptydir-3100 deletion completed in 6.12229957s

• [SLOW TEST:10.317 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:09:23.296: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5894
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0220 14:09:33.491887      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 20 14:09:33.492: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:09:33.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5894" for this suite.
Feb 20 14:09:39.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:09:39.600: INFO: namespace gc-5894 deletion completed in 6.101631221s

• [SLOW TEST:16.305 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:09:39.612: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-2493
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 20 14:09:42.842: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:09:42.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2493" for this suite.
Feb 20 14:09:48.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:09:48.986: INFO: namespace container-runtime-2493 deletion completed in 6.125579431s

• [SLOW TEST:9.376 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:09:48.999: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9248
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb 20 14:09:49.150: INFO: Waiting up to 5m0s for pod "downward-api-0daf48ae-0aa3-4f97-97fd-ea3f8a2d9526" in namespace "downward-api-9248" to be "success or failure"
Feb 20 14:09:49.153: INFO: Pod "downward-api-0daf48ae-0aa3-4f97-97fd-ea3f8a2d9526": Phase="Pending", Reason="", readiness=false. Elapsed: 2.480237ms
Feb 20 14:09:51.164: INFO: Pod "downward-api-0daf48ae-0aa3-4f97-97fd-ea3f8a2d9526": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013509622s
Feb 20 14:09:53.174: INFO: Pod "downward-api-0daf48ae-0aa3-4f97-97fd-ea3f8a2d9526": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023989205s
STEP: Saw pod success
Feb 20 14:09:53.176: INFO: Pod "downward-api-0daf48ae-0aa3-4f97-97fd-ea3f8a2d9526" satisfied condition "success or failure"
Feb 20 14:09:53.181: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod downward-api-0daf48ae-0aa3-4f97-97fd-ea3f8a2d9526 container dapi-container: <nil>
STEP: delete the pod
Feb 20 14:09:53.211: INFO: Waiting for pod downward-api-0daf48ae-0aa3-4f97-97fd-ea3f8a2d9526 to disappear
Feb 20 14:09:53.217: INFO: Pod downward-api-0daf48ae-0aa3-4f97-97fd-ea3f8a2d9526 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:09:53.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9248" for this suite.
Feb 20 14:09:59.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:09:59.329: INFO: namespace downward-api-9248 deletion completed in 6.104961522s

• [SLOW TEST:10.331 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:09:59.336: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5380
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 20 14:09:59.492: INFO: Waiting up to 5m0s for pod "pod-f1e9052e-df03-4ba4-8e48-5c202ef65b29" in namespace "emptydir-5380" to be "success or failure"
Feb 20 14:09:59.496: INFO: Pod "pod-f1e9052e-df03-4ba4-8e48-5c202ef65b29": Phase="Pending", Reason="", readiness=false. Elapsed: 3.914638ms
Feb 20 14:10:01.506: INFO: Pod "pod-f1e9052e-df03-4ba4-8e48-5c202ef65b29": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013831092s
STEP: Saw pod success
Feb 20 14:10:01.507: INFO: Pod "pod-f1e9052e-df03-4ba4-8e48-5c202ef65b29" satisfied condition "success or failure"
Feb 20 14:10:01.517: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-f1e9052e-df03-4ba4-8e48-5c202ef65b29 container test-container: <nil>
STEP: delete the pod
Feb 20 14:10:01.541: INFO: Waiting for pod pod-f1e9052e-df03-4ba4-8e48-5c202ef65b29 to disappear
Feb 20 14:10:01.544: INFO: Pod pod-f1e9052e-df03-4ba4-8e48-5c202ef65b29 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:10:01.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5380" for this suite.
Feb 20 14:10:07.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:10:07.695: INFO: namespace emptydir-5380 deletion completed in 6.144921627s

• [SLOW TEST:8.360 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:10:07.700: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4604
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb 20 14:10:07.844: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 20 14:10:07.859: INFO: Waiting for terminating namespaces to be deleted...
Feb 20 14:10:07.862: INFO: 
Logging pods the kubelet thinks is on node kube16prod-img-kube16prod-img-minion-1 before test
Feb 20 14:10:07.874: INFO: calico-node-vkbjk from kube-system started at 2020-02-20 10:28:15 +0000 UTC (2 container statuses recorded)
Feb 20 14:10:07.874: INFO: 	Container calico-node ready: true, restart count 0
Feb 20 14:10:07.875: INFO: 	Container install-cni ready: true, restart count 0
Feb 20 14:10:07.875: INFO: prometheus-operator-prometheus-node-exporter-c2v94 from prometheus-monitoring started at 2020-02-20 10:28:15 +0000 UTC (1 container statuses recorded)
Feb 20 14:10:07.875: INFO: 	Container node-exporter ready: true, restart count 0
Feb 20 14:10:07.875: INFO: calico-kube-controllers-555d6f4bd9-xfg9t from kube-system started at 2020-02-20 10:56:19 +0000 UTC (1 container statuses recorded)
Feb 20 14:10:07.875: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 20 14:10:07.876: INFO: sonobuoy-systemd-logs-daemon-set-27e71f1a82d14495-ggbs7 from sonobuoy started at 2020-02-20 12:25:04 +0000 UTC (2 container statuses recorded)
Feb 20 14:10:07.876: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 20 14:10:07.876: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 20 14:10:07.876: INFO: metrics-server-f96ddff8f-h2kx6 from kube-system started at 2020-02-20 10:40:28 +0000 UTC (1 container statuses recorded)
Feb 20 14:10:07.876: INFO: 	Container metrics-server ready: true, restart count 0
Feb 20 14:10:07.876: INFO: 
Logging pods the kubelet thinks is on node kube16prod-img-kube16prod-img-minion-2 before test
Feb 20 14:10:07.896: INFO: calico-node-6fj4h from kube-system started at 2020-02-20 12:20:59 +0000 UTC (2 container statuses recorded)
Feb 20 14:10:07.897: INFO: 	Container calico-node ready: true, restart count 0
Feb 20 14:10:07.897: INFO: 	Container install-cni ready: true, restart count 0
Feb 20 14:10:07.897: INFO: sonobuoy from sonobuoy started at 2020-02-20 12:24:54 +0000 UTC (1 container statuses recorded)
Feb 20 14:10:07.898: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 20 14:10:07.898: INFO: sonobuoy-e2e-job-3610336cc2ba449a from sonobuoy started at 2020-02-20 12:25:05 +0000 UTC (2 container statuses recorded)
Feb 20 14:10:07.898: INFO: 	Container e2e ready: true, restart count 0
Feb 20 14:10:07.898: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 20 14:10:07.899: INFO: sonobuoy-systemd-logs-daemon-set-27e71f1a82d14495-fj7b9 from sonobuoy started at 2020-02-20 12:25:05 +0000 UTC (2 container statuses recorded)
Feb 20 14:10:07.899: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 20 14:10:07.899: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 20 14:10:07.900: INFO: prometheus-operator-prometheus-node-exporter-wr9zk from prometheus-monitoring started at 2020-02-20 12:20:59 +0000 UTC (1 container statuses recorded)
Feb 20 14:10:07.900: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-d6d6d87e-9dc7-4af6-855c-2b4cbf6a8315 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-d6d6d87e-9dc7-4af6-855c-2b4cbf6a8315 off the node kube16prod-img-kube16prod-img-minion-2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-d6d6d87e-9dc7-4af6-855c-2b4cbf6a8315
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:10:22.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4604" for this suite.
Feb 20 14:10:50.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:10:50.151: INFO: namespace sched-pred-4604 deletion completed in 28.120692416s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:42.453 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:10:50.153: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7331
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-7331
STEP: creating replication controller nodeport-test in namespace services-7331
I0220 14:10:50.329448      18 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-7331, replica count: 2
I0220 14:10:53.381989      18 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 20 14:10:53.385: INFO: Creating new exec pod
Feb 20 14:10:56.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=services-7331 execpod8vwkn -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Feb 20 14:10:57.322: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Feb 20 14:10:57.322: INFO: stdout: ""
Feb 20 14:10:57.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=services-7331 execpod8vwkn -- /bin/sh -x -c nc -zv -t -w 2 10.254.208.148 80'
Feb 20 14:10:57.626: INFO: stderr: "+ nc -zv -t -w 2 10.254.208.148 80\nConnection to 10.254.208.148 80 port [tcp/http] succeeded!\n"
Feb 20 14:10:57.626: INFO: stdout: ""
Feb 20 14:10:57.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=services-7331 execpod8vwkn -- /bin/sh -x -c nc -zv -t -w 2 10.0.0.29 31734'
Feb 20 14:10:57.921: INFO: stderr: "+ nc -zv -t -w 2 10.0.0.29 31734\nConnection to 10.0.0.29 31734 port [tcp/31734] succeeded!\n"
Feb 20 14:10:57.921: INFO: stdout: ""
Feb 20 14:10:57.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=services-7331 execpod8vwkn -- /bin/sh -x -c nc -zv -t -w 2 10.0.0.8 31734'
Feb 20 14:10:58.174: INFO: stderr: "+ nc -zv -t -w 2 10.0.0.8 31734\nConnection to 10.0.0.8 31734 port [tcp/31734] succeeded!\n"
Feb 20 14:10:58.174: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:10:58.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7331" for this suite.
Feb 20 14:11:04.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:11:04.288: INFO: namespace services-7331 deletion completed in 6.106861199s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:14.136 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:11:04.295: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2131
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Feb 20 14:11:04.454: INFO: Waiting up to 5m0s for pod "var-expansion-f6a5f470-b2a5-4ce1-b278-ac68507e1a95" in namespace "var-expansion-2131" to be "success or failure"
Feb 20 14:11:04.458: INFO: Pod "var-expansion-f6a5f470-b2a5-4ce1-b278-ac68507e1a95": Phase="Pending", Reason="", readiness=false. Elapsed: 3.128405ms
Feb 20 14:11:06.467: INFO: Pod "var-expansion-f6a5f470-b2a5-4ce1-b278-ac68507e1a95": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012562571s
Feb 20 14:11:08.476: INFO: Pod "var-expansion-f6a5f470-b2a5-4ce1-b278-ac68507e1a95": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021272758s
STEP: Saw pod success
Feb 20 14:11:08.476: INFO: Pod "var-expansion-f6a5f470-b2a5-4ce1-b278-ac68507e1a95" satisfied condition "success or failure"
Feb 20 14:11:08.478: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod var-expansion-f6a5f470-b2a5-4ce1-b278-ac68507e1a95 container dapi-container: <nil>
STEP: delete the pod
Feb 20 14:11:08.499: INFO: Waiting for pod var-expansion-f6a5f470-b2a5-4ce1-b278-ac68507e1a95 to disappear
Feb 20 14:11:08.501: INFO: Pod var-expansion-f6a5f470-b2a5-4ce1-b278-ac68507e1a95 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:11:08.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2131" for this suite.
Feb 20 14:11:14.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:11:14.634: INFO: namespace var-expansion-2131 deletion completed in 6.12263843s

• [SLOW TEST:10.340 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:11:14.642: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2602
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 20 14:11:15.691: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 20 14:11:17.702: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804675, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804675, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804675, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804675, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 20 14:11:20.724: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:11:20.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2602" for this suite.
Feb 20 14:11:26.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:11:26.983: INFO: namespace webhook-2602 deletion completed in 6.159510517s
STEP: Destroying namespace "webhook-2602-markers" for this suite.
Feb 20 14:11:32.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:11:33.094: INFO: namespace webhook-2602-markers deletion completed in 6.109827027s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.466 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:11:33.117: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8995
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Feb 20 14:11:33.278: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:12:05.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8995" for this suite.
Feb 20 14:12:11.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:12:11.990: INFO: namespace crd-publish-openapi-8995 deletion completed in 6.126387225s

• [SLOW TEST:38.873 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:12:11.993: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7062
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Feb 20 14:12:12.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 api-versions'
Feb 20 14:12:12.353: INFO: stderr: ""
Feb 20 14:12:12.353: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauditregistration.k8s.io/v1alpha1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ndiscovery.k8s.io/v1alpha1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nmonitoring.coreos.com/v1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1alpha1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1alpha1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1alpha1\nscheduling.k8s.io/v1beta1\nsettings.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1alpha1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:12:12.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7062" for this suite.
Feb 20 14:12:18.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:12:18.486: INFO: namespace kubectl-7062 deletion completed in 6.127863674s

• [SLOW TEST:6.494 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:12:18.493: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6873
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-f3d42665-6324-4eb0-b28d-1424cd3a9905
STEP: Creating a pod to test consume secrets
Feb 20 14:12:18.687: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e992ad60-60f8-4959-a185-9cc717cde42e" in namespace "projected-6873" to be "success or failure"
Feb 20 14:12:18.694: INFO: Pod "pod-projected-secrets-e992ad60-60f8-4959-a185-9cc717cde42e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.234837ms
Feb 20 14:12:20.698: INFO: Pod "pod-projected-secrets-e992ad60-60f8-4959-a185-9cc717cde42e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010959978s
Feb 20 14:12:22.703: INFO: Pod "pod-projected-secrets-e992ad60-60f8-4959-a185-9cc717cde42e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015378005s
STEP: Saw pod success
Feb 20 14:12:22.703: INFO: Pod "pod-projected-secrets-e992ad60-60f8-4959-a185-9cc717cde42e" satisfied condition "success or failure"
Feb 20 14:12:22.709: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod pod-projected-secrets-e992ad60-60f8-4959-a185-9cc717cde42e container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 20 14:12:22.738: INFO: Waiting for pod pod-projected-secrets-e992ad60-60f8-4959-a185-9cc717cde42e to disappear
Feb 20 14:12:22.741: INFO: Pod pod-projected-secrets-e992ad60-60f8-4959-a185-9cc717cde42e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:12:22.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6873" for this suite.
Feb 20 14:12:28.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:12:28.882: INFO: namespace projected-6873 deletion completed in 6.136686917s

• [SLOW TEST:10.390 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:12:28.892: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4138
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 20 14:12:30.032: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 20 14:12:32.051: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804750, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804750, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804750, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804750, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 20 14:12:35.075: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:12:35.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4138" for this suite.
Feb 20 14:12:41.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:12:41.328: INFO: namespace webhook-4138 deletion completed in 6.152565191s
STEP: Destroying namespace "webhook-4138-markers" for this suite.
Feb 20 14:12:47.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:12:47.458: INFO: namespace webhook-4138-markers deletion completed in 6.129696215s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.580 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:12:47.478: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-2237
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 14:12:47.649: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-7a13c13f-4116-4183-bf10-63ba64361f59" in namespace "security-context-test-2237" to be "success or failure"
Feb 20 14:12:47.658: INFO: Pod "alpine-nnp-false-7a13c13f-4116-4183-bf10-63ba64361f59": Phase="Pending", Reason="", readiness=false. Elapsed: 8.655236ms
Feb 20 14:12:49.662: INFO: Pod "alpine-nnp-false-7a13c13f-4116-4183-bf10-63ba64361f59": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012573514s
Feb 20 14:12:51.673: INFO: Pod "alpine-nnp-false-7a13c13f-4116-4183-bf10-63ba64361f59": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023350407s
Feb 20 14:12:53.679: INFO: Pod "alpine-nnp-false-7a13c13f-4116-4183-bf10-63ba64361f59": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029514074s
Feb 20 14:12:53.680: INFO: Pod "alpine-nnp-false-7a13c13f-4116-4183-bf10-63ba64361f59" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:12:53.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2237" for this suite.
Feb 20 14:12:59.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:12:59.830: INFO: namespace security-context-test-2237 deletion completed in 6.129273059s

• [SLOW TEST:12.353 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:12:59.839: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8884
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 20 14:13:00.069: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8884 /api/v1/namespaces/watch-8884/configmaps/e2e-watch-test-resource-version 2243329b-2b52-473b-9d99-080ad28b72ee 250076 0 2020-02-20 14:13:00 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 20 14:13:00.070: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8884 /api/v1/namespaces/watch-8884/configmaps/e2e-watch-test-resource-version 2243329b-2b52-473b-9d99-080ad28b72ee 250077 0 2020-02-20 14:13:00 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:13:00.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8884" for this suite.
Feb 20 14:13:06.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:13:06.187: INFO: namespace watch-8884 deletion completed in 6.11324004s

• [SLOW TEST:6.349 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:13:06.188: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-854
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:13:16.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-854" for this suite.
Feb 20 14:13:22.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:13:22.477: INFO: namespace job-854 deletion completed in 6.121127652s

• [SLOW TEST:16.289 seconds]
[sig-apps] Job
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:13:22.485: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8342
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0220 14:13:28.700262      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 20 14:13:28.701: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:13:28.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8342" for this suite.
Feb 20 14:13:34.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:13:34.820: INFO: namespace gc-8342 deletion completed in 6.106832233s

• [SLOW TEST:12.335 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:13:34.826: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8055
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 20 14:13:34.981: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fcee831d-c0e6-405a-9074-84c6470e7421" in namespace "projected-8055" to be "success or failure"
Feb 20 14:13:34.984: INFO: Pod "downwardapi-volume-fcee831d-c0e6-405a-9074-84c6470e7421": Phase="Pending", Reason="", readiness=false. Elapsed: 2.522271ms
Feb 20 14:13:36.993: INFO: Pod "downwardapi-volume-fcee831d-c0e6-405a-9074-84c6470e7421": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011830719s
Feb 20 14:13:38.998: INFO: Pod "downwardapi-volume-fcee831d-c0e6-405a-9074-84c6470e7421": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017199099s
STEP: Saw pod success
Feb 20 14:13:38.999: INFO: Pod "downwardapi-volume-fcee831d-c0e6-405a-9074-84c6470e7421" satisfied condition "success or failure"
Feb 20 14:13:39.003: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod downwardapi-volume-fcee831d-c0e6-405a-9074-84c6470e7421 container client-container: <nil>
STEP: delete the pod
Feb 20 14:13:39.030: INFO: Waiting for pod downwardapi-volume-fcee831d-c0e6-405a-9074-84c6470e7421 to disappear
Feb 20 14:13:39.032: INFO: Pod downwardapi-volume-fcee831d-c0e6-405a-9074-84c6470e7421 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:13:39.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8055" for this suite.
Feb 20 14:13:45.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:13:45.167: INFO: namespace projected-8055 deletion completed in 6.129678343s

• [SLOW TEST:10.342 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:13:45.175: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-532
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:13:50.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-532" for this suite.
Feb 20 14:13:56.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:13:56.684: INFO: namespace watch-532 deletion completed in 6.24708955s

• [SLOW TEST:11.509 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:13:56.693: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3368
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-62b627fe-1c69-4cde-bddb-b652edb7a792
STEP: Creating a pod to test consume secrets
Feb 20 14:13:56.862: INFO: Waiting up to 5m0s for pod "pod-secrets-979b1750-2e97-4db5-b82a-192b5e1a4984" in namespace "secrets-3368" to be "success or failure"
Feb 20 14:13:56.866: INFO: Pod "pod-secrets-979b1750-2e97-4db5-b82a-192b5e1a4984": Phase="Pending", Reason="", readiness=false. Elapsed: 3.250973ms
Feb 20 14:13:58.870: INFO: Pod "pod-secrets-979b1750-2e97-4db5-b82a-192b5e1a4984": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00716386s
Feb 20 14:14:00.875: INFO: Pod "pod-secrets-979b1750-2e97-4db5-b82a-192b5e1a4984": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011812182s
STEP: Saw pod success
Feb 20 14:14:00.875: INFO: Pod "pod-secrets-979b1750-2e97-4db5-b82a-192b5e1a4984" satisfied condition "success or failure"
Feb 20 14:14:00.878: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-secrets-979b1750-2e97-4db5-b82a-192b5e1a4984 container secret-volume-test: <nil>
STEP: delete the pod
Feb 20 14:14:00.935: INFO: Waiting for pod pod-secrets-979b1750-2e97-4db5-b82a-192b5e1a4984 to disappear
Feb 20 14:14:00.938: INFO: Pod pod-secrets-979b1750-2e97-4db5-b82a-192b5e1a4984 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:14:00.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3368" for this suite.
Feb 20 14:14:06.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:14:07.056: INFO: namespace secrets-3368 deletion completed in 6.112040862s

• [SLOW TEST:10.364 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:14:07.062: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6248
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-33f9cd0c-1028-4dc9-a57d-5f49481c4f0b
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:14:07.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6248" for this suite.
Feb 20 14:14:13.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:14:13.400: INFO: namespace secrets-6248 deletion completed in 6.121975879s

• [SLOW TEST:6.339 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:14:13.409: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4923
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Feb 20 14:14:17.589: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-673477187 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Feb 20 14:14:32.764: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:14:32.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4923" for this suite.
Feb 20 14:14:38.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:14:38.915: INFO: namespace pods-4923 deletion completed in 6.135022882s

• [SLOW TEST:25.507 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:14:38.931: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2675
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 14:14:39.087: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb 20 14:14:39.094: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb 20 14:14:44.101: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 20 14:14:44.102: INFO: Creating deployment "test-rolling-update-deployment"
Feb 20 14:14:44.107: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 20 14:14:44.127: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb 20 14:14:46.137: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 20 14:14:46.143: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804884, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804884, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804884, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717804884, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 20 14:14:48.150: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb 20 14:14:48.164: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-2675 /apis/apps/v1/namespaces/deployment-2675/deployments/test-rolling-update-deployment 13626077-6417-4aa5-b10d-2cd02c4744e1 251051 1 2020-02-20 14:14:44 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003eb3ca8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-02-20 14:14:44 +0000 UTC,LastTransitionTime:2020-02-20 14:14:44 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2020-02-20 14:14:46 +0000 UTC,LastTransitionTime:2020-02-20 14:14:44 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Feb 20 14:14:48.169: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-2675 /apis/apps/v1/namespaces/deployment-2675/replicasets/test-rolling-update-deployment-55d946486 f1f3adea-6022-4ac3-b3c9-13a014db2bca 251040 1 2020-02-20 14:14:44 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 13626077-6417-4aa5-b10d-2cd02c4744e1 0xc00315e1c0 0xc00315e1c1}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00315e248 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb 20 14:14:48.169: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 20 14:14:48.169: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-2675 /apis/apps/v1/namespaces/deployment-2675/replicasets/test-rolling-update-controller e45ea231-eaca-4999-9cb6-9fe80a967569 251050 2 2020-02-20 14:14:39 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 13626077-6417-4aa5-b10d-2cd02c4744e1 0xc00315e0d7 0xc00315e0d8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00315e138 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 20 14:14:48.175: INFO: Pod "test-rolling-update-deployment-55d946486-zj8m8" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-zj8m8 test-rolling-update-deployment-55d946486- deployment-2675 /api/v1/namespaces/deployment-2675/pods/test-rolling-update-deployment-55d946486-zj8m8 fb28dd11-02ae-49c7-b775-ce55563bc948 251039 0 2020-02-20 14:14:44 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 f1f3adea-6022-4ac3-b3c9-13a014db2bca 0xc00315eb80 0xc00315eb81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-xksll,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-xksll,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-xksll,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube16prod-img-kube16prod-img-minion-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{},HostAliases:[]HostAlias{},PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:14:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:14:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:14:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-20 14:14:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.8,PodIP:10.100.81.165,StartTime:2020-02-20 14:14:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-20 14:14:45 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://fddc8335a11308edd06345b224f922da6a63e5f289054044b9243e6cbce3e758,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.81.165,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:14:48.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2675" for this suite.
Feb 20 14:14:54.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:14:54.368: INFO: namespace deployment-2675 deletion completed in 6.185802648s

• [SLOW TEST:15.438 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:14:54.376: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7346
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-8e5bc14b-58b4-47e0-ad1e-d0ae50f0af47
STEP: Creating a pod to test consume configMaps
Feb 20 14:14:54.544: INFO: Waiting up to 5m0s for pod "pod-configmaps-615f3630-de95-45d3-9bb5-8c60170ed429" in namespace "configmap-7346" to be "success or failure"
Feb 20 14:14:54.551: INFO: Pod "pod-configmaps-615f3630-de95-45d3-9bb5-8c60170ed429": Phase="Pending", Reason="", readiness=false. Elapsed: 6.13236ms
Feb 20 14:14:56.557: INFO: Pod "pod-configmaps-615f3630-de95-45d3-9bb5-8c60170ed429": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011847829s
STEP: Saw pod success
Feb 20 14:14:56.557: INFO: Pod "pod-configmaps-615f3630-de95-45d3-9bb5-8c60170ed429" satisfied condition "success or failure"
Feb 20 14:14:56.561: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-configmaps-615f3630-de95-45d3-9bb5-8c60170ed429 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 14:14:56.585: INFO: Waiting for pod pod-configmaps-615f3630-de95-45d3-9bb5-8c60170ed429 to disappear
Feb 20 14:14:56.588: INFO: Pod pod-configmaps-615f3630-de95-45d3-9bb5-8c60170ed429 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:14:56.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7346" for this suite.
Feb 20 14:15:02.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:15:02.746: INFO: namespace configmap-7346 deletion completed in 6.1525802s

• [SLOW TEST:8.371 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:15:02.750: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2076
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 14:15:06.953: INFO: Waiting up to 5m0s for pod "client-envvars-0efcf005-ceef-4be8-8ac1-9f120bfde630" in namespace "pods-2076" to be "success or failure"
Feb 20 14:15:06.959: INFO: Pod "client-envvars-0efcf005-ceef-4be8-8ac1-9f120bfde630": Phase="Pending", Reason="", readiness=false. Elapsed: 5.1864ms
Feb 20 14:15:08.963: INFO: Pod "client-envvars-0efcf005-ceef-4be8-8ac1-9f120bfde630": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009564709s
STEP: Saw pod success
Feb 20 14:15:08.963: INFO: Pod "client-envvars-0efcf005-ceef-4be8-8ac1-9f120bfde630" satisfied condition "success or failure"
Feb 20 14:15:08.965: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod client-envvars-0efcf005-ceef-4be8-8ac1-9f120bfde630 container env3cont: <nil>
STEP: delete the pod
Feb 20 14:15:08.983: INFO: Waiting for pod client-envvars-0efcf005-ceef-4be8-8ac1-9f120bfde630 to disappear
Feb 20 14:15:08.986: INFO: Pod client-envvars-0efcf005-ceef-4be8-8ac1-9f120bfde630 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:15:08.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2076" for this suite.
Feb 20 14:15:37.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:15:37.131: INFO: namespace pods-2076 deletion completed in 28.137967927s

• [SLOW TEST:34.382 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:15:37.149: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-9125
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb 20 14:15:42.339: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:15:42.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9125" for this suite.
Feb 20 14:15:54.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:15:54.528: INFO: namespace replicaset-9125 deletion completed in 12.144021115s

• [SLOW TEST:17.379 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:15:54.538: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3225
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 20 14:15:54.704: INFO: Waiting up to 5m0s for pod "pod-2a96e72b-0bb3-48f6-b07c-9de16ced3e90" in namespace "emptydir-3225" to be "success or failure"
Feb 20 14:15:54.709: INFO: Pod "pod-2a96e72b-0bb3-48f6-b07c-9de16ced3e90": Phase="Pending", Reason="", readiness=false. Elapsed: 2.818703ms
Feb 20 14:15:56.728: INFO: Pod "pod-2a96e72b-0bb3-48f6-b07c-9de16ced3e90": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021551796s
Feb 20 14:15:58.813: INFO: Pod "pod-2a96e72b-0bb3-48f6-b07c-9de16ced3e90": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.10624706s
STEP: Saw pod success
Feb 20 14:15:58.814: INFO: Pod "pod-2a96e72b-0bb3-48f6-b07c-9de16ced3e90" satisfied condition "success or failure"
Feb 20 14:15:58.817: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod pod-2a96e72b-0bb3-48f6-b07c-9de16ced3e90 container test-container: <nil>
STEP: delete the pod
Feb 20 14:15:58.839: INFO: Waiting for pod pod-2a96e72b-0bb3-48f6-b07c-9de16ced3e90 to disappear
Feb 20 14:15:58.841: INFO: Pod pod-2a96e72b-0bb3-48f6-b07c-9de16ced3e90 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:15:58.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3225" for this suite.
Feb 20 14:16:04.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:16:04.949: INFO: namespace emptydir-3225 deletion completed in 6.102129462s

• [SLOW TEST:10.412 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:16:04.954: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4334
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 20 14:16:05.121: INFO: Waiting up to 5m0s for pod "pod-c402937e-85c4-4a6c-940c-68dc9bf84ff2" in namespace "emptydir-4334" to be "success or failure"
Feb 20 14:16:05.125: INFO: Pod "pod-c402937e-85c4-4a6c-940c-68dc9bf84ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.47557ms
Feb 20 14:16:07.134: INFO: Pod "pod-c402937e-85c4-4a6c-940c-68dc9bf84ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012481057s
Feb 20 14:16:09.142: INFO: Pod "pod-c402937e-85c4-4a6c-940c-68dc9bf84ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019970291s
Feb 20 14:16:11.147: INFO: Pod "pod-c402937e-85c4-4a6c-940c-68dc9bf84ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025234735s
STEP: Saw pod success
Feb 20 14:16:11.148: INFO: Pod "pod-c402937e-85c4-4a6c-940c-68dc9bf84ff2" satisfied condition "success or failure"
Feb 20 14:16:11.151: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod pod-c402937e-85c4-4a6c-940c-68dc9bf84ff2 container test-container: <nil>
STEP: delete the pod
Feb 20 14:16:11.175: INFO: Waiting for pod pod-c402937e-85c4-4a6c-940c-68dc9bf84ff2 to disappear
Feb 20 14:16:11.177: INFO: Pod pod-c402937e-85c4-4a6c-940c-68dc9bf84ff2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:16:11.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4334" for this suite.
Feb 20 14:16:17.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:16:17.303: INFO: namespace emptydir-4334 deletion completed in 6.120902358s

• [SLOW TEST:12.349 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:16:17.310: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5800
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-12898aa1-5682-4472-9884-911df4ac644d
STEP: Creating configMap with name cm-test-opt-upd-d6979632-69c1-4a08-815f-84456cbe7b90
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-12898aa1-5682-4472-9884-911df4ac644d
STEP: Updating configmap cm-test-opt-upd-d6979632-69c1-4a08-815f-84456cbe7b90
STEP: Creating configMap with name cm-test-opt-create-48a4b5fd-9237-4cda-9da7-d45fdaa29e68
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:17:33.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5800" for this suite.
Feb 20 14:17:45.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:17:46.117: INFO: namespace projected-5800 deletion completed in 12.146412024s

• [SLOW TEST:88.808 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:17:46.122: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-437
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 20 14:17:46.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-437'
Feb 20 14:17:46.439: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 20 14:17:46.439: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Feb 20 14:17:48.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 delete deployment e2e-test-httpd-deployment --namespace=kubectl-437'
Feb 20 14:17:48.611: INFO: stderr: ""
Feb 20 14:17:48.611: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:17:48.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-437" for this suite.
Feb 20 14:17:54.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:17:54.753: INFO: namespace kubectl-437 deletion completed in 6.134599437s

• [SLOW TEST:8.632 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:17:54.761: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3565
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-c38a2221-a0f7-4428-a3f0-043b1e2a8d49
STEP: Creating a pod to test consume configMaps
Feb 20 14:17:54.930: INFO: Waiting up to 5m0s for pod "pod-configmaps-6cbf07a0-3d3b-4346-aa08-3823b8a8d867" in namespace "configmap-3565" to be "success or failure"
Feb 20 14:17:54.935: INFO: Pod "pod-configmaps-6cbf07a0-3d3b-4346-aa08-3823b8a8d867": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044908ms
Feb 20 14:17:56.941: INFO: Pod "pod-configmaps-6cbf07a0-3d3b-4346-aa08-3823b8a8d867": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010395593s
STEP: Saw pod success
Feb 20 14:17:56.942: INFO: Pod "pod-configmaps-6cbf07a0-3d3b-4346-aa08-3823b8a8d867" satisfied condition "success or failure"
Feb 20 14:17:56.947: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-configmaps-6cbf07a0-3d3b-4346-aa08-3823b8a8d867 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 14:17:56.971: INFO: Waiting for pod pod-configmaps-6cbf07a0-3d3b-4346-aa08-3823b8a8d867 to disappear
Feb 20 14:17:56.974: INFO: Pod pod-configmaps-6cbf07a0-3d3b-4346-aa08-3823b8a8d867 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:17:56.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3565" for this suite.
Feb 20 14:18:02.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:18:03.091: INFO: namespace configmap-3565 deletion completed in 6.107075044s

• [SLOW TEST:8.331 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:18:03.101: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8879
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:18:19.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8879" for this suite.
Feb 20 14:18:25.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:18:25.424: INFO: namespace resourcequota-8879 deletion completed in 6.137258908s

• [SLOW TEST:22.324 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:18:25.425: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-3816
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 14:18:25.575: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:18:28.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3816" for this suite.
Feb 20 14:18:34.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:18:34.685: INFO: namespace custom-resource-definition-3816 deletion completed in 6.12880779s

• [SLOW TEST:9.260 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:18:34.705: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-4943
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 14:18:34.858: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Creating first CR 
Feb 20 14:18:35.457: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-20T14:18:35Z generation:1 name:name1 resourceVersion:252166 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:6ceec5d2-3597-48d0-9795-b2bf1a7a477e] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Feb 20 14:18:45.472: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-20T14:18:45Z generation:1 name:name2 resourceVersion:252194 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:2cbab6c9-e0a5-4601-ab01-b073ec9e331f] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Feb 20 14:18:55.480: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-20T14:18:35Z generation:2 name:name1 resourceVersion:252221 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:6ceec5d2-3597-48d0-9795-b2bf1a7a477e] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Feb 20 14:19:05.492: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-20T14:18:45Z generation:2 name:name2 resourceVersion:252248 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:2cbab6c9-e0a5-4601-ab01-b073ec9e331f] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Feb 20 14:19:15.502: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-20T14:18:35Z generation:2 name:name1 resourceVersion:252278 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:6ceec5d2-3597-48d0-9795-b2bf1a7a477e] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Feb 20 14:19:25.516: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-20T14:18:45Z generation:2 name:name2 resourceVersion:252305 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:2cbab6c9-e0a5-4601-ab01-b073ec9e331f] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:19:36.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-4943" for this suite.
Feb 20 14:19:42.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:19:42.172: INFO: namespace crd-watch-4943 deletion completed in 6.128668616s

• [SLOW TEST:67.469 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:19:42.188: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9892
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 20 14:19:42.347: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2bdc94e8-ab95-43a7-94d9-b902b97d2d34" in namespace "downward-api-9892" to be "success or failure"
Feb 20 14:19:42.351: INFO: Pod "downwardapi-volume-2bdc94e8-ab95-43a7-94d9-b902b97d2d34": Phase="Pending", Reason="", readiness=false. Elapsed: 3.852649ms
Feb 20 14:19:44.359: INFO: Pod "downwardapi-volume-2bdc94e8-ab95-43a7-94d9-b902b97d2d34": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011372612s
STEP: Saw pod success
Feb 20 14:19:44.359: INFO: Pod "downwardapi-volume-2bdc94e8-ab95-43a7-94d9-b902b97d2d34" satisfied condition "success or failure"
Feb 20 14:19:44.362: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod downwardapi-volume-2bdc94e8-ab95-43a7-94d9-b902b97d2d34 container client-container: <nil>
STEP: delete the pod
Feb 20 14:19:44.421: INFO: Waiting for pod downwardapi-volume-2bdc94e8-ab95-43a7-94d9-b902b97d2d34 to disappear
Feb 20 14:19:44.425: INFO: Pod downwardapi-volume-2bdc94e8-ab95-43a7-94d9-b902b97d2d34 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:19:44.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9892" for this suite.
Feb 20 14:19:50.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:19:50.550: INFO: namespace downward-api-9892 deletion completed in 6.118711125s

• [SLOW TEST:8.363 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:19:50.576: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9907
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 20 14:19:51.359: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 20 14:19:53.378: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717805191, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717805191, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717805191, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717805191, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 20 14:19:56.399: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:19:56.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9907" for this suite.
Feb 20 14:20:02.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:20:02.661: INFO: namespace webhook-9907 deletion completed in 6.161030043s
STEP: Destroying namespace "webhook-9907-markers" for this suite.
Feb 20 14:20:08.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:20:08.872: INFO: namespace webhook-9907-markers deletion completed in 6.210577409s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.310 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:20:08.892: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-750
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:20:09.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-750" for this suite.
Feb 20 14:20:15.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:20:15.242: INFO: namespace kubelet-test-750 deletion completed in 6.14461055s

• [SLOW TEST:6.351 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:20:15.247: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1290
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-82ce4ba5-3e9c-43ed-a6c8-f75f7f78ecbb
STEP: Creating a pod to test consume secrets
Feb 20 14:20:15.452: INFO: Waiting up to 5m0s for pod "pod-secrets-689d0a32-5c63-470a-8327-4897c227cf5f" in namespace "secrets-1290" to be "success or failure"
Feb 20 14:20:15.458: INFO: Pod "pod-secrets-689d0a32-5c63-470a-8327-4897c227cf5f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.618383ms
Feb 20 14:20:17.468: INFO: Pod "pod-secrets-689d0a32-5c63-470a-8327-4897c227cf5f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015657091s
STEP: Saw pod success
Feb 20 14:20:17.468: INFO: Pod "pod-secrets-689d0a32-5c63-470a-8327-4897c227cf5f" satisfied condition "success or failure"
Feb 20 14:20:17.471: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-secrets-689d0a32-5c63-470a-8327-4897c227cf5f container secret-env-test: <nil>
STEP: delete the pod
Feb 20 14:20:17.487: INFO: Waiting for pod pod-secrets-689d0a32-5c63-470a-8327-4897c227cf5f to disappear
Feb 20 14:20:17.490: INFO: Pod pod-secrets-689d0a32-5c63-470a-8327-4897c227cf5f no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:20:17.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1290" for this suite.
Feb 20 14:20:23.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:20:23.619: INFO: namespace secrets-1290 deletion completed in 6.124458893s

• [SLOW TEST:8.373 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:20:23.625: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2212
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0220 14:20:54.331382      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 20 14:20:54.333: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:20:54.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2212" for this suite.
Feb 20 14:21:00.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:21:00.510: INFO: namespace gc-2212 deletion completed in 6.169578235s

• [SLOW TEST:36.886 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:21:00.518: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1939
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 20 14:21:01.943: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 20 14:21:03.956: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717805261, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717805261, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717805262, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717805261, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 20 14:21:06.976: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:21:19.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1939" for this suite.
Feb 20 14:21:25.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:21:25.322: INFO: namespace webhook-1939 deletion completed in 6.188252866s
STEP: Destroying namespace "webhook-1939-markers" for this suite.
Feb 20 14:21:31.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:21:31.446: INFO: namespace webhook-1939-markers deletion completed in 6.123698763s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:30.939 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:21:31.465: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4254
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb 20 14:21:31.639: INFO: Waiting up to 5m0s for pod "downward-api-3715a1f9-2742-4a03-aaaa-3b7f1427f429" in namespace "downward-api-4254" to be "success or failure"
Feb 20 14:21:31.647: INFO: Pod "downward-api-3715a1f9-2742-4a03-aaaa-3b7f1427f429": Phase="Pending", Reason="", readiness=false. Elapsed: 7.807839ms
Feb 20 14:21:33.652: INFO: Pod "downward-api-3715a1f9-2742-4a03-aaaa-3b7f1427f429": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01277971s
Feb 20 14:21:35.658: INFO: Pod "downward-api-3715a1f9-2742-4a03-aaaa-3b7f1427f429": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018666482s
STEP: Saw pod success
Feb 20 14:21:35.659: INFO: Pod "downward-api-3715a1f9-2742-4a03-aaaa-3b7f1427f429" satisfied condition "success or failure"
Feb 20 14:21:35.666: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod downward-api-3715a1f9-2742-4a03-aaaa-3b7f1427f429 container dapi-container: <nil>
STEP: delete the pod
Feb 20 14:21:35.734: INFO: Waiting for pod downward-api-3715a1f9-2742-4a03-aaaa-3b7f1427f429 to disappear
Feb 20 14:21:35.737: INFO: Pod downward-api-3715a1f9-2742-4a03-aaaa-3b7f1427f429 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:21:35.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4254" for this suite.
Feb 20 14:21:41.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:21:41.872: INFO: namespace downward-api-4254 deletion completed in 6.127560705s

• [SLOW TEST:10.408 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:21:41.894: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8795
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:21:42.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8795" for this suite.
Feb 20 14:21:48.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:21:48.218: INFO: namespace resourcequota-8795 deletion completed in 6.104224396s

• [SLOW TEST:6.325 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:21:48.223: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9836
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 20 14:21:52.909: INFO: Successfully updated pod "pod-update-activedeadlineseconds-965bc408-36f9-4164-8518-0d916500aae3"
Feb 20 14:21:52.910: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-965bc408-36f9-4164-8518-0d916500aae3" in namespace "pods-9836" to be "terminated due to deadline exceeded"
Feb 20 14:21:52.913: INFO: Pod "pod-update-activedeadlineseconds-965bc408-36f9-4164-8518-0d916500aae3": Phase="Running", Reason="", readiness=true. Elapsed: 3.194221ms
Feb 20 14:21:54.920: INFO: Pod "pod-update-activedeadlineseconds-965bc408-36f9-4164-8518-0d916500aae3": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.010233393s
Feb 20 14:21:54.921: INFO: Pod "pod-update-activedeadlineseconds-965bc408-36f9-4164-8518-0d916500aae3" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:21:54.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9836" for this suite.
Feb 20 14:22:00.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:22:01.052: INFO: namespace pods-9836 deletion completed in 6.122753676s

• [SLOW TEST:12.830 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:22:01.059: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4460
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 20 14:22:01.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-4460'
Feb 20 14:22:02.330: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 20 14:22:02.330: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Feb 20 14:22:02.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 delete jobs e2e-test-httpd-job --namespace=kubectl-4460'
Feb 20 14:22:02.538: INFO: stderr: ""
Feb 20 14:22:02.539: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:22:02.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4460" for this suite.
Feb 20 14:22:08.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:22:08.802: INFO: namespace kubectl-4460 deletion completed in 6.258079018s

• [SLOW TEST:7.744 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:22:08.812: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-1970
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-1970
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 20 14:22:08.968: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 20 14:22:27.042: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.100.99.158 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1970 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 14:22:27.044: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
Feb 20 14:22:28.269: INFO: Found all expected endpoints: [netserver-0]
Feb 20 14:22:28.273: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.100.81.179 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1970 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 20 14:22:28.273: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
Feb 20 14:22:29.432: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:22:29.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1970" for this suite.
Feb 20 14:22:41.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:22:41.611: INFO: namespace pod-network-test-1970 deletion completed in 12.165354666s

• [SLOW TEST:32.800 seconds]
[sig-network] Networking
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:22:41.630: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9208
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 20 14:22:42.973: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 20 14:22:46.001: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 20 14:22:46.006: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9587-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:22:47.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9208" for this suite.
Feb 20 14:22:53.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:22:53.249: INFO: namespace webhook-9208 deletion completed in 6.109311026s
STEP: Destroying namespace "webhook-9208-markers" for this suite.
Feb 20 14:22:59.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:22:59.374: INFO: namespace webhook-9208-markers deletion completed in 6.124241819s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.758 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:22:59.390: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-7313
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Feb 20 14:22:59.557: INFO: Waiting up to 5m0s for pod "client-containers-b744a520-02bb-481a-9358-2ce9483dcb15" in namespace "containers-7313" to be "success or failure"
Feb 20 14:22:59.564: INFO: Pod "client-containers-b744a520-02bb-481a-9358-2ce9483dcb15": Phase="Pending", Reason="", readiness=false. Elapsed: 6.480937ms
Feb 20 14:23:01.577: INFO: Pod "client-containers-b744a520-02bb-481a-9358-2ce9483dcb15": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018862653s
Feb 20 14:23:03.585: INFO: Pod "client-containers-b744a520-02bb-481a-9358-2ce9483dcb15": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027503383s
STEP: Saw pod success
Feb 20 14:23:03.586: INFO: Pod "client-containers-b744a520-02bb-481a-9358-2ce9483dcb15" satisfied condition "success or failure"
Feb 20 14:23:03.589: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod client-containers-b744a520-02bb-481a-9358-2ce9483dcb15 container test-container: <nil>
STEP: delete the pod
Feb 20 14:23:03.613: INFO: Waiting for pod client-containers-b744a520-02bb-481a-9358-2ce9483dcb15 to disappear
Feb 20 14:23:03.615: INFO: Pod client-containers-b744a520-02bb-481a-9358-2ce9483dcb15 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:23:03.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7313" for this suite.
Feb 20 14:23:09.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:23:09.788: INFO: namespace containers-7313 deletion completed in 6.167514124s

• [SLOW TEST:10.398 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:23:09.794: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3874
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 20 14:23:10.021: INFO: Waiting up to 5m0s for pod "pod-5336ff56-f05b-455b-ba3d-7989bf14d13e" in namespace "emptydir-3874" to be "success or failure"
Feb 20 14:23:10.026: INFO: Pod "pod-5336ff56-f05b-455b-ba3d-7989bf14d13e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.558915ms
Feb 20 14:23:12.031: INFO: Pod "pod-5336ff56-f05b-455b-ba3d-7989bf14d13e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009525948s
STEP: Saw pod success
Feb 20 14:23:12.031: INFO: Pod "pod-5336ff56-f05b-455b-ba3d-7989bf14d13e" satisfied condition "success or failure"
Feb 20 14:23:12.034: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-5336ff56-f05b-455b-ba3d-7989bf14d13e container test-container: <nil>
STEP: delete the pod
Feb 20 14:23:12.092: INFO: Waiting for pod pod-5336ff56-f05b-455b-ba3d-7989bf14d13e to disappear
Feb 20 14:23:12.095: INFO: Pod pod-5336ff56-f05b-455b-ba3d-7989bf14d13e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:23:12.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3874" for this suite.
Feb 20 14:23:18.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:23:18.206: INFO: namespace emptydir-3874 deletion completed in 6.102132581s

• [SLOW TEST:8.412 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:23:18.210: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3580
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb 20 14:23:18.354: INFO: Waiting up to 5m0s for pod "downward-api-2db07c50-84c7-4811-b601-2d88a610030c" in namespace "downward-api-3580" to be "success or failure"
Feb 20 14:23:18.361: INFO: Pod "downward-api-2db07c50-84c7-4811-b601-2d88a610030c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.724408ms
Feb 20 14:23:20.366: INFO: Pod "downward-api-2db07c50-84c7-4811-b601-2d88a610030c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011234395s
Feb 20 14:23:22.370: INFO: Pod "downward-api-2db07c50-84c7-4811-b601-2d88a610030c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014937905s
STEP: Saw pod success
Feb 20 14:23:22.370: INFO: Pod "downward-api-2db07c50-84c7-4811-b601-2d88a610030c" satisfied condition "success or failure"
Feb 20 14:23:22.378: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod downward-api-2db07c50-84c7-4811-b601-2d88a610030c container dapi-container: <nil>
STEP: delete the pod
Feb 20 14:23:22.402: INFO: Waiting for pod downward-api-2db07c50-84c7-4811-b601-2d88a610030c to disappear
Feb 20 14:23:22.405: INFO: Pod downward-api-2db07c50-84c7-4811-b601-2d88a610030c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:23:22.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3580" for this suite.
Feb 20 14:23:28.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:23:28.571: INFO: namespace downward-api-3580 deletion completed in 6.16244629s

• [SLOW TEST:10.362 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:23:28.573: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6556
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-6556
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-6556
I0220 14:23:28.824497      18 runners.go:184] Created replication controller with name: externalname-service, namespace: services-6556, replica count: 2
Feb 20 14:23:31.877: INFO: Creating new exec pod
I0220 14:23:31.877332      18 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 20 14:23:36.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=services-6556 execpodxfgxq -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Feb 20 14:23:37.458: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Feb 20 14:23:37.458: INFO: stdout: ""
Feb 20 14:23:37.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=services-6556 execpodxfgxq -- /bin/sh -x -c nc -zv -t -w 2 10.254.221.7 80'
Feb 20 14:23:37.818: INFO: stderr: "+ nc -zv -t -w 2 10.254.221.7 80\nConnection to 10.254.221.7 80 port [tcp/http] succeeded!\n"
Feb 20 14:23:37.820: INFO: stdout: ""
Feb 20 14:23:37.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=services-6556 execpodxfgxq -- /bin/sh -x -c nc -zv -t -w 2 10.0.0.29 31153'
Feb 20 14:23:38.166: INFO: stderr: "+ nc -zv -t -w 2 10.0.0.29 31153\nConnection to 10.0.0.29 31153 port [tcp/31153] succeeded!\n"
Feb 20 14:23:38.166: INFO: stdout: ""
Feb 20 14:23:38.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=services-6556 execpodxfgxq -- /bin/sh -x -c nc -zv -t -w 2 10.0.0.8 31153'
Feb 20 14:23:38.493: INFO: stderr: "+ nc -zv -t -w 2 10.0.0.8 31153\nConnection to 10.0.0.8 31153 port [tcp/31153] succeeded!\n"
Feb 20 14:23:38.493: INFO: stdout: ""
Feb 20 14:23:38.493: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:23:38.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6556" for this suite.
Feb 20 14:23:44.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:23:44.676: INFO: namespace services-6556 deletion completed in 6.152395445s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:16.104 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:23:44.678: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5676
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-2644c366-053c-46cb-b088-049aa8bf91ed
STEP: Creating a pod to test consume configMaps
Feb 20 14:23:44.839: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d16d7de3-7c77-45e7-8af3-cc5fa0a58ebb" in namespace "projected-5676" to be "success or failure"
Feb 20 14:23:44.852: INFO: Pod "pod-projected-configmaps-d16d7de3-7c77-45e7-8af3-cc5fa0a58ebb": Phase="Pending", Reason="", readiness=false. Elapsed: 12.759396ms
Feb 20 14:23:46.876: INFO: Pod "pod-projected-configmaps-d16d7de3-7c77-45e7-8af3-cc5fa0a58ebb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036597312s
Feb 20 14:23:48.942: INFO: Pod "pod-projected-configmaps-d16d7de3-7c77-45e7-8af3-cc5fa0a58ebb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.102361526s
STEP: Saw pod success
Feb 20 14:23:48.943: INFO: Pod "pod-projected-configmaps-d16d7de3-7c77-45e7-8af3-cc5fa0a58ebb" satisfied condition "success or failure"
Feb 20 14:23:48.951: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-2 pod pod-projected-configmaps-d16d7de3-7c77-45e7-8af3-cc5fa0a58ebb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 14:23:48.981: INFO: Waiting for pod pod-projected-configmaps-d16d7de3-7c77-45e7-8af3-cc5fa0a58ebb to disappear
Feb 20 14:23:48.984: INFO: Pod pod-projected-configmaps-d16d7de3-7c77-45e7-8af3-cc5fa0a58ebb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:23:48.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5676" for this suite.
Feb 20 14:23:55.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:23:55.116: INFO: namespace projected-5676 deletion completed in 6.11417361s

• [SLOW TEST:10.439 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:23:55.124: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9253
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-1230f6f1-8ea8-4a01-b2ed-f6139cc76d9a in namespace container-probe-9253
Feb 20 14:23:57.289: INFO: Started pod busybox-1230f6f1-8ea8-4a01-b2ed-f6139cc76d9a in namespace container-probe-9253
STEP: checking the pod's current state and verifying that restartCount is present
Feb 20 14:23:57.292: INFO: Initial restart count of pod busybox-1230f6f1-8ea8-4a01-b2ed-f6139cc76d9a is 0
Feb 20 14:24:47.430: INFO: Restart count of pod container-probe-9253/busybox-1230f6f1-8ea8-4a01-b2ed-f6139cc76d9a is now 1 (50.137631824s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:24:47.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9253" for this suite.
Feb 20 14:24:53.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:24:53.600: INFO: namespace container-probe-9253 deletion completed in 6.144051865s

• [SLOW TEST:58.477 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:24:53.607: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-7766
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Feb 20 14:24:53.782: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-7766" to be "success or failure"
Feb 20 14:24:53.784: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.834738ms
Feb 20 14:24:55.791: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009689281s
STEP: Saw pod success
Feb 20 14:24:55.792: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb 20 14:24:55.801: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb 20 14:24:55.862: INFO: Waiting for pod pod-host-path-test to disappear
Feb 20 14:24:55.865: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:24:55.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-7766" for this suite.
Feb 20 14:25:01.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:25:02.068: INFO: namespace hostpath-7766 deletion completed in 6.198204688s

• [SLOW TEST:8.463 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:25:02.080: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-6992
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Feb 20 14:25:02.778: INFO: created pod pod-service-account-defaultsa
Feb 20 14:25:02.778: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 20 14:25:02.786: INFO: created pod pod-service-account-mountsa
Feb 20 14:25:02.786: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 20 14:25:02.796: INFO: created pod pod-service-account-nomountsa
Feb 20 14:25:02.796: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 20 14:25:02.802: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 20 14:25:02.802: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 20 14:25:02.808: INFO: created pod pod-service-account-mountsa-mountspec
Feb 20 14:25:02.808: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 20 14:25:02.816: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 20 14:25:02.816: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 20 14:25:02.822: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 20 14:25:02.822: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 20 14:25:02.827: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 20 14:25:02.827: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 20 14:25:02.839: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 20 14:25:02.840: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:25:02.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6992" for this suite.
Feb 20 14:25:14.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:25:15.008: INFO: namespace svcaccounts-6992 deletion completed in 12.156068616s

• [SLOW TEST:12.929 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:25:15.011: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1990
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-1990
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-1990
STEP: creating replication controller externalsvc in namespace services-1990
I0220 14:25:15.209589      18 runners.go:184] Created replication controller with name: externalsvc, namespace: services-1990, replica count: 2
I0220 14:25:18.274620      18 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Feb 20 14:25:18.313: INFO: Creating new exec pod
Feb 20 14:25:22.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-673477187 exec --namespace=services-1990 execpod26w7n -- /bin/sh -x -c nslookup nodeport-service'
Feb 20 14:25:22.809: INFO: stderr: "+ nslookup nodeport-service\n"
Feb 20 14:25:22.809: INFO: stdout: "Server:\t\t10.254.0.10\nAddress:\t10.254.0.10#53\n\nnodeport-service.services-1990.svc.cluster.local\tcanonical name = externalsvc.services-1990.svc.cluster.local.\nName:\texternalsvc.services-1990.svc.cluster.local\nAddress: 10.254.73.236\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-1990, will wait for the garbage collector to delete the pods
Feb 20 14:25:22.870: INFO: Deleting ReplicationController externalsvc took: 6.106222ms
Feb 20 14:25:23.771: INFO: Terminating ReplicationController externalsvc pods took: 900.73696ms
Feb 20 14:25:28.492: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:25:28.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1990" for this suite.
Feb 20 14:25:34.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:25:34.696: INFO: namespace services-1990 deletion completed in 6.179030124s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:19.685 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:25:34.700: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7004
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-a3f0c5e5-b6bc-48ba-a3d9-55dd8c4844c0 in namespace container-probe-7004
Feb 20 14:25:36.943: INFO: Started pod test-webserver-a3f0c5e5-b6bc-48ba-a3d9-55dd8c4844c0 in namespace container-probe-7004
STEP: checking the pod's current state and verifying that restartCount is present
Feb 20 14:25:36.946: INFO: Initial restart count of pod test-webserver-a3f0c5e5-b6bc-48ba-a3d9-55dd8c4844c0 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:29:37.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7004" for this suite.
Feb 20 14:29:43.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:29:43.666: INFO: namespace container-probe-7004 deletion completed in 6.115620015s

• [SLOW TEST:248.969 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 20 14:29:43.671: INFO: >>> kubeConfig: /tmp/kubeconfig-673477187
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5286
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-b6e4e5c3-acb3-4e52-831d-9fecb708acf5
STEP: Creating a pod to test consume configMaps
Feb 20 14:29:43.832: INFO: Waiting up to 5m0s for pod "pod-configmaps-c7e50d0f-c916-4979-b601-c50cbfdc78c4" in namespace "configmap-5286" to be "success or failure"
Feb 20 14:29:43.835: INFO: Pod "pod-configmaps-c7e50d0f-c916-4979-b601-c50cbfdc78c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.576553ms
Feb 20 14:29:45.842: INFO: Pod "pod-configmaps-c7e50d0f-c916-4979-b601-c50cbfdc78c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009626514s
STEP: Saw pod success
Feb 20 14:29:45.843: INFO: Pod "pod-configmaps-c7e50d0f-c916-4979-b601-c50cbfdc78c4" satisfied condition "success or failure"
Feb 20 14:29:45.847: INFO: Trying to get logs from node kube16prod-img-kube16prod-img-minion-1 pod pod-configmaps-c7e50d0f-c916-4979-b601-c50cbfdc78c4 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 20 14:29:45.922: INFO: Waiting for pod pod-configmaps-c7e50d0f-c916-4979-b601-c50cbfdc78c4 to disappear
Feb 20 14:29:45.937: INFO: Pod pod-configmaps-c7e50d0f-c916-4979-b601-c50cbfdc78c4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 20 14:29:45.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5286" for this suite.
Feb 20 14:29:51.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 20 14:29:52.114: INFO: namespace configmap-5286 deletion completed in 6.168772893s

• [SLOW TEST:8.443 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSFeb 20 14:29:52.126: INFO: Running AfterSuite actions on all nodes
Feb 20 14:29:52.128: INFO: Running AfterSuite actions on node 1
Feb 20 14:29:52.128: INFO: Skipping dumping logs from cluster

Ran 274 of 4731 Specs in 7440.298 seconds
SUCCESS! -- 274 Passed | 0 Failed | 0 Pending | 4457 Skipped
PASS

Ginkgo ran 1 suite in 2h4m3.253194532s
Test Suite Passed
