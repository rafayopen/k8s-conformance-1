I1001 09:21:48.468620      17 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-021449899
I1001 09:21:48.468852      17 e2e.go:92] Starting e2e run "0840d0fe-da9e-4ecf-b72d-312e1c590bed" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1569921707 - Will randomize all specs
Will run 274 of 4897 specs

Oct  1 09:21:48.533: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 09:21:48.535: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Oct  1 09:21:48.547: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Oct  1 09:21:48.566: INFO: 1 / 1 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Oct  1 09:21:48.566: INFO: expected 1 pod replicas in namespace 'kube-system', 1 are Running and Ready.
Oct  1 09:21:48.566: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Oct  1 09:21:48.571: INFO: e2e test version: v1.16.0
Oct  1 09:21:48.572: INFO: kube-apiserver version: v1.16.0
Oct  1 09:21:48.572: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 09:21:48.576: INFO: Cluster IP family: ipv4
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:21:48.576: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename init-container
Oct  1 09:21:48.615: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Oct  1 09:21:48.616: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:21:53.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1994" for this suite.
Oct  1 09:21:59.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:21:59.268: INFO: namespace init-container-1994 deletion completed in 6.064222755s

• [SLOW TEST:10.692 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:21:59.268: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
I1001 09:21:59.294914      17 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/client-go/tools/watch/informerwatcher.go:146
I1001 09:21:59.294944      17 reflector.go:158] Listing and watching *v1.Pod from k8s.io/client-go/tools/watch/informerwatcher.go:146
Oct  1 09:21:59.296: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:22:09.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1873" for this suite.
Oct  1 09:22:15.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:22:15.073: INFO: namespace pods-1873 deletion completed in 6.053526954s

• [SLOW TEST:15.805 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:22:15.073: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct  1 09:22:23.119: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  1 09:22:23.121: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  1 09:22:25.121: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  1 09:22:25.124: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  1 09:22:27.121: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  1 09:22:27.124: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  1 09:22:29.121: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  1 09:22:29.124: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:22:29.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5505" for this suite.
Oct  1 09:22:41.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:22:41.196: INFO: namespace container-lifecycle-hook-5505 deletion completed in 12.058070007s

• [SLOW TEST:26.123 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:22:41.196: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  1 09:22:41.659: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct  1 09:22:43.666: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705518561, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705518561, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705518561, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705518561, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  1 09:22:46.674: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 09:22:46.677: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1748-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:22:47.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2623" for this suite.
Oct  1 09:22:53.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:22:53.343: INFO: namespace webhook-2623 deletion completed in 6.062614126s
STEP: Destroying namespace "webhook-2623-markers" for this suite.
Oct  1 09:22:59.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:22:59.401: INFO: namespace webhook-2623-markers deletion completed in 6.057798856s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.213 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:22:59.410: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Oct  1 09:22:59.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 cluster-info'
Oct  1 09:23:00.214: INFO: stderr: ""
Oct  1 09:23:00.214: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:23:00.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6354" for this suite.
Oct  1 09:23:06.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:23:06.275: INFO: namespace kubectl-6354 deletion completed in 6.058256019s

• [SLOW TEST:6.866 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:23:06.276: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-5308
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct  1 09:23:06.296: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct  1 09:23:26.352: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.63.10:8080/dial?request=hostName&protocol=http&host=10.1.2.4&port=8080&tries=1'] Namespace:pod-network-test-5308 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 09:23:26.352: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 09:25:35.875: INFO: Failed to execute "curl -g -q -s 'http://10.1.63.10:8080/dial?request=hostName&protocol=http&host=10.1.2.4&port=8080&tries=1'": command terminated with exit code 7, stdout: "", stderr ""
Oct  1 09:25:35.875: INFO: Waiting for endpoints: map[netserver-0:{}]
Oct  1 09:25:37.883: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.63.10:8080/dial?request=hostName&protocol=http&host=10.1.2.4&port=8080&tries=1'] Namespace:pod-network-test-5308 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 09:25:37.883: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 09:27:48.992: INFO: Failed to execute "curl -g -q -s 'http://10.1.63.10:8080/dial?request=hostName&protocol=http&host=10.1.2.4&port=8080&tries=1'": command terminated with exit code 7, stdout: "", stderr ""
Oct  1 09:27:48.992: INFO: Waiting for endpoints: map[netserver-0:{}]
Oct  1 09:27:51.000: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.63.10:8080/dial?request=hostName&protocol=http&host=10.1.2.4&port=8080&tries=1'] Namespace:pod-network-test-5308 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 09:27:51.000: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 09:30:02.123: INFO: Failed to execute "curl -g -q -s 'http://10.1.63.10:8080/dial?request=hostName&protocol=http&host=10.1.2.4&port=8080&tries=1'": command terminated with exit code 7, stdout: "", stderr ""
Oct  1 09:30:02.123: INFO: Waiting for endpoints: map[netserver-0:{}]
Oct  1 09:30:04.131: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.63.10:8080/dial?request=hostName&protocol=http&host=10.1.2.4&port=8080&tries=1'] Namespace:pod-network-test-5308 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 09:30:04.131: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 09:30:05.283: INFO: Waiting for endpoints: map[]
Oct  1 09:30:05.286: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.63.10:8080/dial?request=hostName&protocol=http&host=10.1.63.9&port=8080&tries=1'] Namespace:pod-network-test-5308 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 09:30:05.286: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 09:30:05.409: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:30:05.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5308" for this suite.
Oct  1 09:30:17.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:30:17.473: INFO: namespace pod-network-test-5308 deletion completed in 12.061007145s

• [SLOW TEST:431.197 seconds]
[sig-network] Networking
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:30:17.473: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 09:30:17.498: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Oct  1 09:30:19.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 --namespace=crd-publish-openapi-3613 create -f -'
Oct  1 09:30:20.934: INFO: stderr: ""
Oct  1 09:30:20.934: INFO: stdout: "e2e-test-crd-publish-openapi-6270-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Oct  1 09:30:20.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 --namespace=crd-publish-openapi-3613 delete e2e-test-crd-publish-openapi-6270-crds test-cr'
Oct  1 09:30:21.004: INFO: stderr: ""
Oct  1 09:30:21.004: INFO: stdout: "e2e-test-crd-publish-openapi-6270-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Oct  1 09:30:21.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 --namespace=crd-publish-openapi-3613 apply -f -'
Oct  1 09:30:21.168: INFO: stderr: ""
Oct  1 09:30:21.168: INFO: stdout: "e2e-test-crd-publish-openapi-6270-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Oct  1 09:30:21.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 --namespace=crd-publish-openapi-3613 delete e2e-test-crd-publish-openapi-6270-crds test-cr'
Oct  1 09:30:21.238: INFO: stderr: ""
Oct  1 09:30:21.238: INFO: stdout: "e2e-test-crd-publish-openapi-6270-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Oct  1 09:30:21.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 explain e2e-test-crd-publish-openapi-6270-crds'
Oct  1 09:30:21.390: INFO: stderr: ""
Oct  1 09:30:21.390: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-6270-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:30:24.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3613" for this suite.
Oct  1 09:30:30.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:30:30.372: INFO: namespace crd-publish-openapi-3613 deletion completed in 6.061419884s

• [SLOW TEST:12.899 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:30:30.372: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-7bb2569c-4f8f-4c04-8fa5-2ef48198ed88
STEP: Creating a pod to test consume secrets
Oct  1 09:30:30.425: INFO: Waiting up to 5m0s for pod "pod-secrets-bb732236-231d-464c-8ca0-22c40c298699" in namespace "secrets-9465" to be "success or failure"
Oct  1 09:30:30.427: INFO: Pod "pod-secrets-bb732236-231d-464c-8ca0-22c40c298699": Phase="Pending", Reason="", readiness=false. Elapsed: 2.497939ms
Oct  1 09:30:32.430: INFO: Pod "pod-secrets-bb732236-231d-464c-8ca0-22c40c298699": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005284641s
Oct  1 09:30:34.433: INFO: Pod "pod-secrets-bb732236-231d-464c-8ca0-22c40c298699": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008201174s
STEP: Saw pod success
Oct  1 09:30:34.433: INFO: Pod "pod-secrets-bb732236-231d-464c-8ca0-22c40c298699" satisfied condition "success or failure"
Oct  1 09:30:34.435: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-secrets-bb732236-231d-464c-8ca0-22c40c298699 container secret-volume-test: <nil>
STEP: delete the pod
Oct  1 09:30:34.452: INFO: Waiting for pod pod-secrets-bb732236-231d-464c-8ca0-22c40c298699 to disappear
Oct  1 09:30:34.455: INFO: Pod pod-secrets-bb732236-231d-464c-8ca0-22c40c298699 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:30:34.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9465" for this suite.
Oct  1 09:30:40.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:30:40.516: INFO: namespace secrets-9465 deletion completed in 6.058461658s
STEP: Destroying namespace "secret-namespace-1467" for this suite.
Oct  1 09:30:46.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:30:46.573: INFO: namespace secret-namespace-1467 deletion completed in 6.056704551s

• [SLOW TEST:16.201 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:30:46.573: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 09:31:12.610: INFO: Container started at 2019-10-01 09:30:48 +0000 UTC, pod became ready at 2019-10-01 09:31:12 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:31:12.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-317" for this suite.
Oct  1 09:31:24.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:31:24.668: INFO: namespace container-probe-317 deletion completed in 12.055754777s

• [SLOW TEST:38.095 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:31:24.668: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-42e84e23-623e-49a0-ae5a-47eac065fcb5
STEP: Creating a pod to test consume secrets
Oct  1 09:31:24.700: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8bc74f81-4ab4-4722-bfbb-24aa52a8d0c0" in namespace "projected-2226" to be "success or failure"
Oct  1 09:31:24.702: INFO: Pod "pod-projected-secrets-8bc74f81-4ab4-4722-bfbb-24aa52a8d0c0": Phase="Pending", Reason="", readiness=false. Elapsed: 1.868929ms
Oct  1 09:31:26.705: INFO: Pod "pod-projected-secrets-8bc74f81-4ab4-4722-bfbb-24aa52a8d0c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00492976s
STEP: Saw pod success
Oct  1 09:31:26.706: INFO: Pod "pod-projected-secrets-8bc74f81-4ab4-4722-bfbb-24aa52a8d0c0" satisfied condition "success or failure"
Oct  1 09:31:26.707: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-projected-secrets-8bc74f81-4ab4-4722-bfbb-24aa52a8d0c0 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct  1 09:31:26.717: INFO: Waiting for pod pod-projected-secrets-8bc74f81-4ab4-4722-bfbb-24aa52a8d0c0 to disappear
Oct  1 09:31:26.719: INFO: Pod pod-projected-secrets-8bc74f81-4ab4-4722-bfbb-24aa52a8d0c0 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:31:26.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2226" for this suite.
Oct  1 09:31:32.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:31:32.779: INFO: namespace projected-2226 deletion completed in 6.057926795s

• [SLOW TEST:8.111 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:31:32.779: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Oct  1 09:31:32.798: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:31:48.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6495" for this suite.
Oct  1 09:31:54.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:31:54.603: INFO: namespace crd-publish-openapi-6495 deletion completed in 6.060309174s

• [SLOW TEST:21.824 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:31:54.603: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:32:18.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9504" for this suite.
Oct  1 09:32:24.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:32:24.822: INFO: namespace container-runtime-9504 deletion completed in 6.057233022s

• [SLOW TEST:30.219 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:32:24.822: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Oct  1 09:32:31.864: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:32:32.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7418" for this suite.
Oct  1 09:33:00.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:33:00.934: INFO: namespace replicaset-7418 deletion completed in 28.058683836s

• [SLOW TEST:36.112 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:33:00.934: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:33:00.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8841" for this suite.
Oct  1 09:33:06.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:33:07.018: INFO: namespace services-8841 deletion completed in 6.057621895s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.084 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:33:07.018: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 09:33:07.042: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Oct  1 09:33:09.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 --namespace=crd-publish-openapi-3662 create -f -'
Oct  1 09:33:10.968: INFO: stderr: ""
Oct  1 09:33:10.968: INFO: stdout: "e2e-test-crd-publish-openapi-6717-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Oct  1 09:33:10.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 --namespace=crd-publish-openapi-3662 delete e2e-test-crd-publish-openapi-6717-crds test-cr'
Oct  1 09:33:11.039: INFO: stderr: ""
Oct  1 09:33:11.039: INFO: stdout: "e2e-test-crd-publish-openapi-6717-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Oct  1 09:33:11.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 --namespace=crd-publish-openapi-3662 apply -f -'
Oct  1 09:33:11.197: INFO: stderr: ""
Oct  1 09:33:11.197: INFO: stdout: "e2e-test-crd-publish-openapi-6717-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Oct  1 09:33:11.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 --namespace=crd-publish-openapi-3662 delete e2e-test-crd-publish-openapi-6717-crds test-cr'
Oct  1 09:33:11.266: INFO: stderr: ""
Oct  1 09:33:11.266: INFO: stdout: "e2e-test-crd-publish-openapi-6717-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Oct  1 09:33:11.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 explain e2e-test-crd-publish-openapi-6717-crds'
Oct  1 09:33:11.411: INFO: stderr: ""
Oct  1 09:33:11.411: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-6717-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:33:13.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3662" for this suite.
Oct  1 09:33:19.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:33:19.364: INFO: namespace crd-publish-openapi-3662 deletion completed in 6.05969587s

• [SLOW TEST:12.346 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:33:19.364: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct  1 09:33:23.425: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  1 09:33:23.427: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  1 09:33:25.428: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  1 09:33:25.430: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  1 09:33:27.427: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  1 09:33:27.430: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  1 09:33:29.428: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  1 09:33:29.431: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  1 09:33:31.428: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  1 09:33:31.430: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  1 09:33:33.428: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  1 09:33:33.430: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:33:33.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7307" for this suite.
Oct  1 09:34:01.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:34:01.489: INFO: namespace container-lifecycle-hook-7307 deletion completed in 28.057369806s

• [SLOW TEST:42.125 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:34:01.489: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:34:04.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9851" for this suite.
Oct  1 09:34:16.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:34:16.601: INFO: namespace replication-controller-9851 deletion completed in 12.058932281s

• [SLOW TEST:15.112 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:34:16.602: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  1 09:34:17.234: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  1 09:34:20.246: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:34:20.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7951" for this suite.
Oct  1 09:34:26.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:34:26.354: INFO: namespace webhook-7951 deletion completed in 6.058771529s
STEP: Destroying namespace "webhook-7951-markers" for this suite.
Oct  1 09:34:32.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:34:32.411: INFO: namespace webhook-7951-markers deletion completed in 6.057231509s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:15.818 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:34:32.420: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  1 09:34:32.449: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9833fbaa-975c-401e-8afe-758af80bbf44" in namespace "downward-api-6187" to be "success or failure"
Oct  1 09:34:32.451: INFO: Pod "downwardapi-volume-9833fbaa-975c-401e-8afe-758af80bbf44": Phase="Pending", Reason="", readiness=false. Elapsed: 2.388651ms
Oct  1 09:34:34.454: INFO: Pod "downwardapi-volume-9833fbaa-975c-401e-8afe-758af80bbf44": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005395034s
Oct  1 09:34:36.457: INFO: Pod "downwardapi-volume-9833fbaa-975c-401e-8afe-758af80bbf44": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008532153s
STEP: Saw pod success
Oct  1 09:34:36.457: INFO: Pod "downwardapi-volume-9833fbaa-975c-401e-8afe-758af80bbf44" satisfied condition "success or failure"
Oct  1 09:34:36.459: INFO: Trying to get logs from node ip-172-31-16-136 pod downwardapi-volume-9833fbaa-975c-401e-8afe-758af80bbf44 container client-container: <nil>
STEP: delete the pod
Oct  1 09:34:36.472: INFO: Waiting for pod downwardapi-volume-9833fbaa-975c-401e-8afe-758af80bbf44 to disappear
Oct  1 09:34:36.478: INFO: Pod downwardapi-volume-9833fbaa-975c-401e-8afe-758af80bbf44 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:34:36.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6187" for this suite.
Oct  1 09:34:42.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:34:42.538: INFO: namespace downward-api-6187 deletion completed in 6.057799689s

• [SLOW TEST:10.118 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:34:42.538: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 09:34:42.557: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:34:48.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2086" for this suite.
Oct  1 09:34:54.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:34:54.280: INFO: namespace custom-resource-definition-2086 deletion completed in 6.056279725s

• [SLOW TEST:11.742 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:34:54.281: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Oct  1 09:34:54.757: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  1 09:34:57.767: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 09:34:57.770: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:34:58.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-2845" for this suite.
Oct  1 09:35:04.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:35:05.009: INFO: namespace crd-webhook-2845 deletion completed in 6.060884338s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:10.737 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:35:05.017: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Oct  1 09:35:05.048: INFO: Waiting up to 5m0s for pod "var-expansion-c798a24b-5db4-4380-a1a2-470e442ad0cc" in namespace "var-expansion-8803" to be "success or failure"
Oct  1 09:35:05.059: INFO: Pod "var-expansion-c798a24b-5db4-4380-a1a2-470e442ad0cc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.898286ms
Oct  1 09:35:07.062: INFO: Pod "var-expansion-c798a24b-5db4-4380-a1a2-470e442ad0cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014105002s
STEP: Saw pod success
Oct  1 09:35:07.062: INFO: Pod "var-expansion-c798a24b-5db4-4380-a1a2-470e442ad0cc" satisfied condition "success or failure"
Oct  1 09:35:07.064: INFO: Trying to get logs from node ip-172-31-16-136 pod var-expansion-c798a24b-5db4-4380-a1a2-470e442ad0cc container dapi-container: <nil>
STEP: delete the pod
Oct  1 09:35:07.075: INFO: Waiting for pod var-expansion-c798a24b-5db4-4380-a1a2-470e442ad0cc to disappear
Oct  1 09:35:07.078: INFO: Pod var-expansion-c798a24b-5db4-4380-a1a2-470e442ad0cc no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:35:07.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8803" for this suite.
Oct  1 09:35:13.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:35:13.144: INFO: namespace var-expansion-8803 deletion completed in 6.064015378s

• [SLOW TEST:8.127 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:35:13.144: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9061.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-9061.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9061.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9061.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-9061.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9061.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct  1 09:35:23.216: INFO: DNS probes using dns-9061/dns-test-14315255-2856-4dc4-b039-a6412cc4c2b6 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:35:23.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9061" for this suite.
Oct  1 09:35:29.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:35:29.320: INFO: namespace dns-9061 deletion completed in 6.060897412s

• [SLOW TEST:16.175 seconds]
[sig-network] DNS
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:35:29.320: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct  1 09:35:29.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-1517'
Oct  1 09:35:29.411: INFO: stderr: ""
Oct  1 09:35:29.411: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
I1001 09:35:29.411984      17 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 09:35:29.412007      17 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
STEP: verifying the pod e2e-test-httpd-pod was created
Oct  1 09:35:34.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pod e2e-test-httpd-pod --namespace=kubectl-1517 -o json'
Oct  1 09:35:34.528: INFO: stderr: ""
Oct  1 09:35:34.528: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-10-01T09:35:29Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-1517\",\n        \"resourceVersion\": \"3850\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-1517/pods/e2e-test-httpd-pod\",\n        \"uid\": \"6b825cd4-5e92-4dd3-ad18-3bf8897fd291\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-xpgmd\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-16-136\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-xpgmd\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-xpgmd\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-01T09:35:29Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-01T09:35:30Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-01T09:35:30Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-01T09:35:29Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://eb7f4d3a150da351c90d8d37ff5bbedc5c583403db2f7a92168e061894e100ac\",\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imageID\": \"docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-10-01T09:35:30Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.16.136\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.1.63.26\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.1.63.26\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-10-01T09:35:29Z\"\n    }\n}\n"
STEP: replace the image in the pod
Oct  1 09:35:34.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 replace -f - --namespace=kubectl-1517'
Oct  1 09:35:34.726: INFO: stderr: ""
Oct  1 09:35:34.726: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Oct  1 09:35:34.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 delete pods e2e-test-httpd-pod --namespace=kubectl-1517'
Oct  1 09:35:39.012: INFO: stderr: ""
Oct  1 09:35:39.012: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:35:39.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1517" for this suite.
Oct  1 09:35:45.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:35:45.078: INFO: namespace kubectl-1517 deletion completed in 6.059156436s

• [SLOW TEST:15.758 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:35:45.078: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Oct  1 09:36:25.125: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W1001 09:36:25.124964      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct  1 09:36:25.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9096" for this suite.
Oct  1 09:36:31.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:36:31.195: INFO: namespace gc-9096 deletion completed in 6.068226987s

• [SLOW TEST:46.116 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:36:31.195: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-89421c02-a748-423e-97d1-426f58c1239d
STEP: Creating a pod to test consume configMaps
Oct  1 09:36:31.231: INFO: Waiting up to 5m0s for pod "pod-configmaps-5713fc74-a848-4295-bf68-24bf955e935b" in namespace "configmap-6231" to be "success or failure"
Oct  1 09:36:31.232: INFO: Pod "pod-configmaps-5713fc74-a848-4295-bf68-24bf955e935b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.72069ms
Oct  1 09:36:33.235: INFO: Pod "pod-configmaps-5713fc74-a848-4295-bf68-24bf955e935b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004867844s
STEP: Saw pod success
Oct  1 09:36:33.236: INFO: Pod "pod-configmaps-5713fc74-a848-4295-bf68-24bf955e935b" satisfied condition "success or failure"
Oct  1 09:36:33.238: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-configmaps-5713fc74-a848-4295-bf68-24bf955e935b container configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 09:36:33.251: INFO: Waiting for pod pod-configmaps-5713fc74-a848-4295-bf68-24bf955e935b to disappear
Oct  1 09:36:33.259: INFO: Pod pod-configmaps-5713fc74-a848-4295-bf68-24bf955e935b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:36:33.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6231" for this suite.
Oct  1 09:36:39.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:36:39.318: INFO: namespace configmap-6231 deletion completed in 6.056987072s

• [SLOW TEST:8.123 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:36:39.318: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:36:44.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7201" for this suite.
Oct  1 09:36:50.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:36:50.530: INFO: namespace watch-7201 deletion completed in 6.156930667s

• [SLOW TEST:11.211 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:36:50.530: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-85f2dc2d-b13d-4dfa-aeb7-ee4d3803c7f8
STEP: Creating a pod to test consume secrets
Oct  1 09:36:50.606: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ac4751b3-e2c2-4301-961e-8897a5ef9ec4" in namespace "projected-4768" to be "success or failure"
Oct  1 09:36:50.609: INFO: Pod "pod-projected-secrets-ac4751b3-e2c2-4301-961e-8897a5ef9ec4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.739875ms
Oct  1 09:36:52.612: INFO: Pod "pod-projected-secrets-ac4751b3-e2c2-4301-961e-8897a5ef9ec4": Phase="Running", Reason="", readiness=true. Elapsed: 2.005738687s
Oct  1 09:36:54.615: INFO: Pod "pod-projected-secrets-ac4751b3-e2c2-4301-961e-8897a5ef9ec4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008781591s
STEP: Saw pod success
Oct  1 09:36:54.615: INFO: Pod "pod-projected-secrets-ac4751b3-e2c2-4301-961e-8897a5ef9ec4" satisfied condition "success or failure"
Oct  1 09:36:54.617: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-projected-secrets-ac4751b3-e2c2-4301-961e-8897a5ef9ec4 container secret-volume-test: <nil>
STEP: delete the pod
Oct  1 09:36:54.626: INFO: Waiting for pod pod-projected-secrets-ac4751b3-e2c2-4301-961e-8897a5ef9ec4 to disappear
Oct  1 09:36:54.628: INFO: Pod pod-projected-secrets-ac4751b3-e2c2-4301-961e-8897a5ef9ec4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:36:54.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4768" for this suite.
Oct  1 09:37:00.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:37:00.687: INFO: namespace projected-4768 deletion completed in 6.057725875s

• [SLOW TEST:10.158 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:37:00.688: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct  1 09:37:00.718: INFO: Waiting up to 5m0s for pod "pod-9cb3fadf-a4a5-4143-93db-7501e58b6e04" in namespace "emptydir-2388" to be "success or failure"
Oct  1 09:37:00.721: INFO: Pod "pod-9cb3fadf-a4a5-4143-93db-7501e58b6e04": Phase="Pending", Reason="", readiness=false. Elapsed: 2.347423ms
Oct  1 09:37:02.724: INFO: Pod "pod-9cb3fadf-a4a5-4143-93db-7501e58b6e04": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005494474s
Oct  1 09:37:04.727: INFO: Pod "pod-9cb3fadf-a4a5-4143-93db-7501e58b6e04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008245345s
STEP: Saw pod success
Oct  1 09:37:04.727: INFO: Pod "pod-9cb3fadf-a4a5-4143-93db-7501e58b6e04" satisfied condition "success or failure"
Oct  1 09:37:04.728: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-9cb3fadf-a4a5-4143-93db-7501e58b6e04 container test-container: <nil>
STEP: delete the pod
Oct  1 09:37:04.738: INFO: Waiting for pod pod-9cb3fadf-a4a5-4143-93db-7501e58b6e04 to disappear
Oct  1 09:37:04.742: INFO: Pod pod-9cb3fadf-a4a5-4143-93db-7501e58b6e04 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:37:04.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2388" for this suite.
Oct  1 09:37:10.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:37:10.804: INFO: namespace emptydir-2388 deletion completed in 6.060156882s

• [SLOW TEST:10.116 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:37:10.804: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  1 09:37:10.833: INFO: Waiting up to 5m0s for pod "downwardapi-volume-53967e60-ef4d-492d-90dc-44e6e4514ae5" in namespace "projected-8085" to be "success or failure"
Oct  1 09:37:10.835: INFO: Pod "downwardapi-volume-53967e60-ef4d-492d-90dc-44e6e4514ae5": Phase="Pending", Reason="", readiness=false. Elapsed: 1.928828ms
Oct  1 09:37:12.838: INFO: Pod "downwardapi-volume-53967e60-ef4d-492d-90dc-44e6e4514ae5": Phase="Running", Reason="", readiness=true. Elapsed: 2.005095511s
Oct  1 09:37:14.841: INFO: Pod "downwardapi-volume-53967e60-ef4d-492d-90dc-44e6e4514ae5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008293029s
STEP: Saw pod success
Oct  1 09:37:14.841: INFO: Pod "downwardapi-volume-53967e60-ef4d-492d-90dc-44e6e4514ae5" satisfied condition "success or failure"
Oct  1 09:37:14.843: INFO: Trying to get logs from node ip-172-31-16-136 pod downwardapi-volume-53967e60-ef4d-492d-90dc-44e6e4514ae5 container client-container: <nil>
STEP: delete the pod
Oct  1 09:37:14.852: INFO: Waiting for pod downwardapi-volume-53967e60-ef4d-492d-90dc-44e6e4514ae5 to disappear
Oct  1 09:37:14.854: INFO: Pod downwardapi-volume-53967e60-ef4d-492d-90dc-44e6e4514ae5 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:37:14.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8085" for this suite.
Oct  1 09:37:20.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:37:20.915: INFO: namespace projected-8085 deletion completed in 6.059207948s

• [SLOW TEST:10.111 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:37:20.915: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-a31a0728-42db-4c7a-ad66-9bb026e97d56 in namespace container-probe-8685
Oct  1 09:37:24.947: INFO: Started pod liveness-a31a0728-42db-4c7a-ad66-9bb026e97d56 in namespace container-probe-8685
STEP: checking the pod's current state and verifying that restartCount is present
Oct  1 09:37:24.949: INFO: Initial restart count of pod liveness-a31a0728-42db-4c7a-ad66-9bb026e97d56 is 0
Oct  1 09:37:46.988: INFO: Restart count of pod container-probe-8685/liveness-a31a0728-42db-4c7a-ad66-9bb026e97d56 is now 1 (22.039406051s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:37:46.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8685" for this suite.
Oct  1 09:37:53.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:37:53.067: INFO: namespace container-probe-8685 deletion completed in 6.066991093s

• [SLOW TEST:32.152 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:37:53.067: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Oct  1 09:37:53.090: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct  1 09:37:53.095: INFO: Waiting for terminating namespaces to be deleted...
Oct  1 09:37:53.097: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-16-136 before test
Oct  1 09:37:53.100: INFO: sonobuoy from sonobuoy started at 2019-10-01 09:21:20 +0000 UTC (1 container statuses recorded)
Oct  1 09:37:53.100: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct  1 09:37:53.100: INFO: sonobuoy-systemd-logs-daemon-set-c998de73b1b44522-6mdfj from sonobuoy started at 2019-10-01 09:21:21 +0000 UTC (2 container statuses recorded)
Oct  1 09:37:53.100: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  1 09:37:53.100: INFO: 	Container systemd-logs ready: true, restart count 0
Oct  1 09:37:53.100: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-29-44 before test
Oct  1 09:37:53.114: INFO: coredns-9b8997588-8dd8w from kube-system started at 2019-10-01 09:06:34 +0000 UTC (1 container statuses recorded)
Oct  1 09:37:53.114: INFO: 	Container coredns ready: true, restart count 0
Oct  1 09:37:53.114: INFO: sonobuoy-e2e-job-41fbe38c4f734fd3 from sonobuoy started at 2019-10-01 09:21:21 +0000 UTC (2 container statuses recorded)
Oct  1 09:37:53.114: INFO: 	Container e2e ready: true, restart count 0
Oct  1 09:37:53.114: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  1 09:37:53.114: INFO: sonobuoy-systemd-logs-daemon-set-c998de73b1b44522-4jgxd from sonobuoy started at 2019-10-01 09:21:21 +0000 UTC (2 container statuses recorded)
Oct  1 09:37:53.114: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  1 09:37:53.114: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-6fccd8b9-8ff7-4653-8150-a7a6728f80d6 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-6fccd8b9-8ff7-4653-8150-a7a6728f80d6 off the node ip-172-31-16-136
STEP: verifying the node doesn't have the label kubernetes.io/e2e-6fccd8b9-8ff7-4653-8150-a7a6728f80d6
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:42:57.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8140" for this suite.
Oct  1 09:43:15.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:43:15.238: INFO: namespace sched-pred-8140 deletion completed in 18.058934788s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

I1001 09:43:15.238816      17 request.go:706] Error in request: resource name may not be empty
• [SLOW TEST:322.171 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:43:15.239: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Oct  1 09:43:15.267: INFO: Waiting up to 5m0s for pod "var-expansion-9ab1d2f3-eafb-4b74-9a29-6ea813a70675" in namespace "var-expansion-1737" to be "success or failure"
Oct  1 09:43:15.269: INFO: Pod "var-expansion-9ab1d2f3-eafb-4b74-9a29-6ea813a70675": Phase="Pending", Reason="", readiness=false. Elapsed: 1.992182ms
Oct  1 09:43:17.272: INFO: Pod "var-expansion-9ab1d2f3-eafb-4b74-9a29-6ea813a70675": Phase="Running", Reason="", readiness=true. Elapsed: 2.005061053s
Oct  1 09:43:19.275: INFO: Pod "var-expansion-9ab1d2f3-eafb-4b74-9a29-6ea813a70675": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008120615s
STEP: Saw pod success
Oct  1 09:43:19.275: INFO: Pod "var-expansion-9ab1d2f3-eafb-4b74-9a29-6ea813a70675" satisfied condition "success or failure"
Oct  1 09:43:19.277: INFO: Trying to get logs from node ip-172-31-16-136 pod var-expansion-9ab1d2f3-eafb-4b74-9a29-6ea813a70675 container dapi-container: <nil>
STEP: delete the pod
Oct  1 09:43:19.297: INFO: Waiting for pod var-expansion-9ab1d2f3-eafb-4b74-9a29-6ea813a70675 to disappear
Oct  1 09:43:19.304: INFO: Pod var-expansion-9ab1d2f3-eafb-4b74-9a29-6ea813a70675 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:43:19.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1737" for this suite.
Oct  1 09:43:25.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:43:25.369: INFO: namespace var-expansion-1737 deletion completed in 6.062048952s

• [SLOW TEST:10.130 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:43:25.369: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:43:54.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8620" for this suite.
Oct  1 09:44:00.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:44:00.524: INFO: namespace namespaces-8620 deletion completed in 6.059667919s
STEP: Destroying namespace "nsdeletetest-4993" for this suite.
Oct  1 09:44:00.526: INFO: Namespace nsdeletetest-4993 was already deleted
STEP: Destroying namespace "nsdeletetest-4102" for this suite.
Oct  1 09:44:06.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:44:06.588: INFO: namespace nsdeletetest-4102 deletion completed in 6.061647302s

• [SLOW TEST:41.219 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:44:06.588: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-5818/secret-test-141936b4-97c4-4f46-b487-73476c32bb1e
STEP: Creating a pod to test consume secrets
Oct  1 09:44:06.621: INFO: Waiting up to 5m0s for pod "pod-configmaps-ad4342fd-962b-4fa6-be8c-5381121d8415" in namespace "secrets-5818" to be "success or failure"
Oct  1 09:44:06.628: INFO: Pod "pod-configmaps-ad4342fd-962b-4fa6-be8c-5381121d8415": Phase="Pending", Reason="", readiness=false. Elapsed: 7.157221ms
Oct  1 09:44:08.631: INFO: Pod "pod-configmaps-ad4342fd-962b-4fa6-be8c-5381121d8415": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010134734s
STEP: Saw pod success
Oct  1 09:44:08.631: INFO: Pod "pod-configmaps-ad4342fd-962b-4fa6-be8c-5381121d8415" satisfied condition "success or failure"
Oct  1 09:44:08.633: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-configmaps-ad4342fd-962b-4fa6-be8c-5381121d8415 container env-test: <nil>
STEP: delete the pod
Oct  1 09:44:08.643: INFO: Waiting for pod pod-configmaps-ad4342fd-962b-4fa6-be8c-5381121d8415 to disappear
Oct  1 09:44:08.650: INFO: Pod pod-configmaps-ad4342fd-962b-4fa6-be8c-5381121d8415 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:44:08.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5818" for this suite.
Oct  1 09:44:14.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:44:14.710: INFO: namespace secrets-5818 deletion completed in 6.057730702s

• [SLOW TEST:8.122 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:44:14.710: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-5170
I1001 09:44:14.738726      17 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5170, replica count: 1
I1001 09:44:14.738821      17 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 09:44:14.738841      17 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 09:44:15.789264      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1001 09:44:16.789540      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1001 09:44:16.789729      17 reflector.go:120] Starting reflector *v1.Endpoints (0s) from k8s.io/kubernetes/test/e2e/network/service_latency.go:323
I1001 09:44:16.789751      17 reflector.go:158] Listing and watching *v1.Endpoints from k8s.io/kubernetes/test/e2e/network/service_latency.go:323
Oct  1 09:44:16.896: INFO: Created: latency-svc-6ztdq
Oct  1 09:44:16.901: INFO: Got endpoints: latency-svc-6ztdq [11.842606ms]
Oct  1 09:44:16.910: INFO: Created: latency-svc-tjg29
Oct  1 09:44:16.913: INFO: Got endpoints: latency-svc-tjg29 [11.860812ms]
Oct  1 09:44:16.914: INFO: Created: latency-svc-wclz8
Oct  1 09:44:16.932: INFO: Got endpoints: latency-svc-wclz8 [29.951739ms]
Oct  1 09:44:16.934: INFO: Created: latency-svc-wwrbq
Oct  1 09:44:16.936: INFO: Got endpoints: latency-svc-wwrbq [33.943422ms]
Oct  1 09:44:16.937: INFO: Created: latency-svc-rsvq9
Oct  1 09:44:16.939: INFO: Created: latency-svc-p2x8f
Oct  1 09:44:16.941: INFO: Got endpoints: latency-svc-rsvq9 [39.537555ms]
Oct  1 09:44:16.942: INFO: Got endpoints: latency-svc-p2x8f [39.971874ms]
Oct  1 09:44:16.951: INFO: Created: latency-svc-64j5n
Oct  1 09:44:16.952: INFO: Got endpoints: latency-svc-64j5n [50.186008ms]
Oct  1 09:44:16.953: INFO: Created: latency-svc-mrfv6
Oct  1 09:44:16.955: INFO: Got endpoints: latency-svc-mrfv6 [52.986023ms]
Oct  1 09:44:16.958: INFO: Created: latency-svc-w7x2b
Oct  1 09:44:16.968: INFO: Got endpoints: latency-svc-w7x2b [65.687451ms]
Oct  1 09:44:16.970: INFO: Created: latency-svc-85wt6
Oct  1 09:44:16.972: INFO: Got endpoints: latency-svc-85wt6 [19.180515ms]
Oct  1 09:44:16.973: INFO: Created: latency-svc-2xfzc
Oct  1 09:44:16.975: INFO: Created: latency-svc-4zlbp
Oct  1 09:44:16.976: INFO: Got endpoints: latency-svc-2xfzc [73.591978ms]
Oct  1 09:44:16.978: INFO: Got endpoints: latency-svc-4zlbp [75.933592ms]
Oct  1 09:44:16.988: INFO: Created: latency-svc-qqdlr
Oct  1 09:44:16.992: INFO: Created: latency-svc-twvwn
Oct  1 09:44:16.992: INFO: Got endpoints: latency-svc-qqdlr [89.422175ms]
Oct  1 09:44:16.999: INFO: Created: latency-svc-mh6t2
Oct  1 09:44:17.001: INFO: Got endpoints: latency-svc-mh6t2 [98.836144ms]
Oct  1 09:44:17.002: INFO: Got endpoints: latency-svc-twvwn [99.078688ms]
Oct  1 09:44:17.011: INFO: Created: latency-svc-5h9ww
Oct  1 09:44:17.013: INFO: Created: latency-svc-g667t
Oct  1 09:44:17.015: INFO: Got endpoints: latency-svc-g667t [101.424736ms]
Oct  1 09:44:17.016: INFO: Got endpoints: latency-svc-5h9ww [113.948756ms]
Oct  1 09:44:17.019: INFO: Created: latency-svc-75vpx
Oct  1 09:44:17.027: INFO: Got endpoints: latency-svc-75vpx [95.550196ms]
Oct  1 09:44:17.029: INFO: Created: latency-svc-97xt7
Oct  1 09:44:17.032: INFO: Created: latency-svc-tljdf
Oct  1 09:44:17.033: INFO: Got endpoints: latency-svc-97xt7 [97.104316ms]
Oct  1 09:44:17.034: INFO: Got endpoints: latency-svc-tljdf [92.865803ms]
Oct  1 09:44:17.036: INFO: Created: latency-svc-7xmmx
Oct  1 09:44:17.046: INFO: Got endpoints: latency-svc-7xmmx [103.968274ms]
Oct  1 09:44:17.047: INFO: Created: latency-svc-xccs7
Oct  1 09:44:17.050: INFO: Created: latency-svc-d7v48
Oct  1 09:44:17.051: INFO: Got endpoints: latency-svc-xccs7 [148.693215ms]
Oct  1 09:44:17.053: INFO: Got endpoints: latency-svc-d7v48 [97.364092ms]
Oct  1 09:44:17.056: INFO: Created: latency-svc-928rc
Oct  1 09:44:17.065: INFO: Got endpoints: latency-svc-928rc [96.656184ms]
Oct  1 09:44:17.066: INFO: Created: latency-svc-dvhns
Oct  1 09:44:17.070: INFO: Got endpoints: latency-svc-dvhns [98.392347ms]
Oct  1 09:44:17.071: INFO: Created: latency-svc-4st5l
Oct  1 09:44:17.073: INFO: Created: latency-svc-x6xmd
Oct  1 09:44:17.075: INFO: Got endpoints: latency-svc-4st5l [99.250019ms]
Oct  1 09:44:17.077: INFO: Got endpoints: latency-svc-x6xmd [98.483252ms]
Oct  1 09:44:17.086: INFO: Created: latency-svc-5cgg9
Oct  1 09:44:17.088: INFO: Got endpoints: latency-svc-5cgg9 [96.463324ms]
Oct  1 09:44:17.089: INFO: Created: latency-svc-scjww
Oct  1 09:44:17.092: INFO: Got endpoints: latency-svc-scjww [90.455232ms]
Oct  1 09:44:17.095: INFO: Created: latency-svc-r9w6l
Oct  1 09:44:17.103: INFO: Got endpoints: latency-svc-r9w6l [101.692023ms]
Oct  1 09:44:17.105: INFO: Created: latency-svc-2t65b
Oct  1 09:44:17.107: INFO: Created: latency-svc-wt2jc
Oct  1 09:44:17.108: INFO: Got endpoints: latency-svc-2t65b [93.25025ms]
Oct  1 09:44:17.109: INFO: Got endpoints: latency-svc-wt2jc [92.882315ms]
Oct  1 09:44:17.113: INFO: Created: latency-svc-c6wzh
Oct  1 09:44:17.121: INFO: Got endpoints: latency-svc-c6wzh [93.881476ms]
Oct  1 09:44:17.123: INFO: Created: latency-svc-t6qkl
Oct  1 09:44:17.125: INFO: Got endpoints: latency-svc-t6qkl [92.456352ms]
Oct  1 09:44:17.127: INFO: Created: latency-svc-mpl9f
Oct  1 09:44:17.129: INFO: Created: latency-svc-42w92
Oct  1 09:44:17.133: INFO: Created: latency-svc-pqptr
Oct  1 09:44:17.142: INFO: Created: latency-svc-7kdnk
Oct  1 09:44:17.145: INFO: Created: latency-svc-7tjcb
Oct  1 09:44:17.148: INFO: Created: latency-svc-jxzmw
Oct  1 09:44:17.150: INFO: Created: latency-svc-npnp7
Oct  1 09:44:17.151: INFO: Got endpoints: latency-svc-mpl9f [116.856719ms]
Oct  1 09:44:17.162: INFO: Created: latency-svc-svb68
Oct  1 09:44:17.165: INFO: Created: latency-svc-2qq54
Oct  1 09:44:17.166: INFO: Created: latency-svc-5zz92
Oct  1 09:44:17.169: INFO: Created: latency-svc-6lws5
Oct  1 09:44:17.173: INFO: Created: latency-svc-qppvh
Oct  1 09:44:17.183: INFO: Created: latency-svc-wmczr
Oct  1 09:44:17.185: INFO: Created: latency-svc-2tt52
Oct  1 09:44:17.186: INFO: Created: latency-svc-hwbqm
Oct  1 09:44:17.188: INFO: Created: latency-svc-zt649
Oct  1 09:44:17.200: INFO: Got endpoints: latency-svc-42w92 [154.252977ms]
Oct  1 09:44:17.205: INFO: Created: latency-svc-2wb56
Oct  1 09:44:17.251: INFO: Got endpoints: latency-svc-pqptr [199.975668ms]
Oct  1 09:44:17.256: INFO: Created: latency-svc-wjfgz
Oct  1 09:44:17.301: INFO: Got endpoints: latency-svc-7kdnk [248.766674ms]
Oct  1 09:44:17.306: INFO: Created: latency-svc-wpwbc
Oct  1 09:44:17.351: INFO: Got endpoints: latency-svc-7tjcb [286.385455ms]
Oct  1 09:44:17.358: INFO: Created: latency-svc-rkn2x
Oct  1 09:44:17.402: INFO: Got endpoints: latency-svc-jxzmw [332.119604ms]
Oct  1 09:44:17.408: INFO: Created: latency-svc-jm5pc
Oct  1 09:44:17.452: INFO: Got endpoints: latency-svc-npnp7 [376.865834ms]
Oct  1 09:44:17.459: INFO: Created: latency-svc-qlr6d
Oct  1 09:44:17.501: INFO: Got endpoints: latency-svc-svb68 [424.121429ms]
Oct  1 09:44:17.514: INFO: Created: latency-svc-8vpvh
Oct  1 09:44:17.551: INFO: Got endpoints: latency-svc-2qq54 [462.480276ms]
Oct  1 09:44:17.556: INFO: Created: latency-svc-tf4kb
Oct  1 09:44:17.601: INFO: Got endpoints: latency-svc-5zz92 [509.010496ms]
Oct  1 09:44:17.605: INFO: Created: latency-svc-gwxbt
Oct  1 09:44:17.651: INFO: Got endpoints: latency-svc-6lws5 [547.647519ms]
Oct  1 09:44:17.663: INFO: Created: latency-svc-jd9w2
Oct  1 09:44:17.701: INFO: Got endpoints: latency-svc-qppvh [592.62149ms]
Oct  1 09:44:17.706: INFO: Created: latency-svc-spzgp
Oct  1 09:44:17.750: INFO: Got endpoints: latency-svc-wmczr [641.108776ms]
Oct  1 09:44:17.754: INFO: Created: latency-svc-4hg2g
Oct  1 09:44:17.801: INFO: Got endpoints: latency-svc-2tt52 [679.555258ms]
Oct  1 09:44:17.812: INFO: Created: latency-svc-tcl4l
Oct  1 09:44:17.851: INFO: Got endpoints: latency-svc-hwbqm [725.115441ms]
Oct  1 09:44:17.856: INFO: Created: latency-svc-fcqg9
Oct  1 09:44:17.901: INFO: Got endpoints: latency-svc-zt649 [749.50696ms]
Oct  1 09:44:17.906: INFO: Created: latency-svc-sfjqr
Oct  1 09:44:17.951: INFO: Got endpoints: latency-svc-2wb56 [750.384793ms]
Oct  1 09:44:17.963: INFO: Created: latency-svc-vj5fn
Oct  1 09:44:18.001: INFO: Got endpoints: latency-svc-wjfgz [749.634666ms]
Oct  1 09:44:18.005: INFO: Created: latency-svc-jj79k
Oct  1 09:44:18.051: INFO: Got endpoints: latency-svc-wpwbc [749.200296ms]
Oct  1 09:44:18.055: INFO: Created: latency-svc-mcvg2
Oct  1 09:44:18.101: INFO: Got endpoints: latency-svc-rkn2x [749.792343ms]
Oct  1 09:44:18.115: INFO: Created: latency-svc-c8zqr
Oct  1 09:44:18.151: INFO: Got endpoints: latency-svc-jm5pc [748.613388ms]
Oct  1 09:44:18.155: INFO: Created: latency-svc-xkkfl
Oct  1 09:44:18.201: INFO: Got endpoints: latency-svc-qlr6d [748.952914ms]
Oct  1 09:44:18.207: INFO: Created: latency-svc-sx5tp
Oct  1 09:44:18.251: INFO: Got endpoints: latency-svc-8vpvh [749.865855ms]
Oct  1 09:44:18.255: INFO: Created: latency-svc-gfk64
Oct  1 09:44:18.301: INFO: Got endpoints: latency-svc-tf4kb [750.117775ms]
Oct  1 09:44:18.306: INFO: Created: latency-svc-pb7st
Oct  1 09:44:18.351: INFO: Got endpoints: latency-svc-gwxbt [749.898484ms]
Oct  1 09:44:18.357: INFO: Created: latency-svc-4gpmb
Oct  1 09:44:18.401: INFO: Got endpoints: latency-svc-jd9w2 [750.071259ms]
Oct  1 09:44:18.406: INFO: Created: latency-svc-qqpfd
Oct  1 09:44:18.451: INFO: Got endpoints: latency-svc-spzgp [749.938838ms]
Oct  1 09:44:18.455: INFO: Created: latency-svc-vgn94
Oct  1 09:44:18.502: INFO: Got endpoints: latency-svc-4hg2g [751.473816ms]
Oct  1 09:44:18.508: INFO: Created: latency-svc-h86h4
Oct  1 09:44:18.553: INFO: Got endpoints: latency-svc-tcl4l [751.653767ms]
Oct  1 09:44:18.557: INFO: Created: latency-svc-5zmt9
Oct  1 09:44:18.601: INFO: Got endpoints: latency-svc-fcqg9 [750.384695ms]
Oct  1 09:44:18.606: INFO: Created: latency-svc-hkv9t
Oct  1 09:44:18.651: INFO: Got endpoints: latency-svc-sfjqr [749.941781ms]
Oct  1 09:44:18.663: INFO: Created: latency-svc-gvfkh
Oct  1 09:44:18.701: INFO: Got endpoints: latency-svc-vj5fn [750.212458ms]
Oct  1 09:44:18.707: INFO: Created: latency-svc-vh8n2
Oct  1 09:44:18.751: INFO: Got endpoints: latency-svc-jj79k [750.53691ms]
Oct  1 09:44:18.756: INFO: Created: latency-svc-b555h
Oct  1 09:44:18.801: INFO: Got endpoints: latency-svc-mcvg2 [750.648999ms]
Oct  1 09:44:18.815: INFO: Created: latency-svc-2m2gf
Oct  1 09:44:18.851: INFO: Got endpoints: latency-svc-c8zqr [750.148086ms]
Oct  1 09:44:18.855: INFO: Created: latency-svc-bwdd8
Oct  1 09:44:18.901: INFO: Got endpoints: latency-svc-xkkfl [749.734047ms]
Oct  1 09:44:18.905: INFO: Created: latency-svc-x9bpn
Oct  1 09:44:18.950: INFO: Got endpoints: latency-svc-sx5tp [749.324857ms]
Oct  1 09:44:18.962: INFO: Created: latency-svc-xcp8f
Oct  1 09:44:19.000: INFO: Got endpoints: latency-svc-gfk64 [749.403356ms]
Oct  1 09:44:19.005: INFO: Created: latency-svc-lfh84
Oct  1 09:44:19.051: INFO: Got endpoints: latency-svc-pb7st [749.857202ms]
Oct  1 09:44:19.055: INFO: Created: latency-svc-n7nzg
Oct  1 09:44:19.101: INFO: Got endpoints: latency-svc-4gpmb [749.933549ms]
Oct  1 09:44:19.114: INFO: Created: latency-svc-mk74w
Oct  1 09:44:19.151: INFO: Got endpoints: latency-svc-qqpfd [749.777746ms]
Oct  1 09:44:19.155: INFO: Created: latency-svc-qcvf2
Oct  1 09:44:19.201: INFO: Got endpoints: latency-svc-vgn94 [750.339809ms]
Oct  1 09:44:19.206: INFO: Created: latency-svc-cctbt
Oct  1 09:44:19.251: INFO: Got endpoints: latency-svc-h86h4 [748.891443ms]
Oct  1 09:44:19.263: INFO: Created: latency-svc-62ljz
Oct  1 09:44:19.301: INFO: Got endpoints: latency-svc-5zmt9 [748.280235ms]
Oct  1 09:44:19.305: INFO: Created: latency-svc-vqwxz
Oct  1 09:44:19.351: INFO: Got endpoints: latency-svc-hkv9t [749.739688ms]
Oct  1 09:44:19.355: INFO: Created: latency-svc-gfrnc
Oct  1 09:44:19.401: INFO: Got endpoints: latency-svc-gvfkh [750.19579ms]
Oct  1 09:44:19.413: INFO: Created: latency-svc-qjbnv
Oct  1 09:44:19.451: INFO: Got endpoints: latency-svc-vh8n2 [749.575694ms]
Oct  1 09:44:19.455: INFO: Created: latency-svc-9dpnk
Oct  1 09:44:19.501: INFO: Got endpoints: latency-svc-b555h [749.796019ms]
Oct  1 09:44:19.513: INFO: Created: latency-svc-hknw4
Oct  1 09:44:19.551: INFO: Got endpoints: latency-svc-2m2gf [749.911146ms]
Oct  1 09:44:19.556: INFO: Created: latency-svc-5dgvh
Oct  1 09:44:19.601: INFO: Got endpoints: latency-svc-bwdd8 [750.234709ms]
Oct  1 09:44:19.606: INFO: Created: latency-svc-6d84s
Oct  1 09:44:19.651: INFO: Got endpoints: latency-svc-x9bpn [749.896525ms]
Oct  1 09:44:19.662: INFO: Created: latency-svc-s8kv2
Oct  1 09:44:19.701: INFO: Got endpoints: latency-svc-xcp8f [750.444538ms]
Oct  1 09:44:19.705: INFO: Created: latency-svc-fl2m2
Oct  1 09:44:19.751: INFO: Got endpoints: latency-svc-lfh84 [750.747691ms]
Oct  1 09:44:19.757: INFO: Created: latency-svc-dgnsb
Oct  1 09:44:19.801: INFO: Got endpoints: latency-svc-n7nzg [750.254052ms]
Oct  1 09:44:19.813: INFO: Created: latency-svc-854sj
Oct  1 09:44:19.851: INFO: Got endpoints: latency-svc-mk74w [750.211974ms]
Oct  1 09:44:19.855: INFO: Created: latency-svc-hmrsw
Oct  1 09:44:19.901: INFO: Got endpoints: latency-svc-qcvf2 [750.37697ms]
Oct  1 09:44:19.907: INFO: Created: latency-svc-cqcpl
Oct  1 09:44:19.951: INFO: Got endpoints: latency-svc-cctbt [749.831702ms]
Oct  1 09:44:19.962: INFO: Created: latency-svc-wbkn7
Oct  1 09:44:20.001: INFO: Got endpoints: latency-svc-62ljz [750.200271ms]
Oct  1 09:44:20.005: INFO: Created: latency-svc-t6xh9
Oct  1 09:44:20.051: INFO: Got endpoints: latency-svc-vqwxz [749.88603ms]
Oct  1 09:44:20.055: INFO: Created: latency-svc-wclfn
Oct  1 09:44:20.101: INFO: Got endpoints: latency-svc-gfrnc [750.045799ms]
Oct  1 09:44:20.114: INFO: Created: latency-svc-9w9qr
Oct  1 09:44:20.151: INFO: Got endpoints: latency-svc-qjbnv [749.823464ms]
Oct  1 09:44:20.155: INFO: Created: latency-svc-8j7vk
Oct  1 09:44:20.201: INFO: Got endpoints: latency-svc-9dpnk [750.664629ms]
Oct  1 09:44:20.207: INFO: Created: latency-svc-phsz9
Oct  1 09:44:20.251: INFO: Got endpoints: latency-svc-hknw4 [749.534975ms]
Oct  1 09:44:20.255: INFO: Created: latency-svc-cdx2h
Oct  1 09:44:20.300: INFO: Got endpoints: latency-svc-5dgvh [749.120177ms]
Oct  1 09:44:20.305: INFO: Created: latency-svc-wcvmz
Oct  1 09:44:20.350: INFO: Got endpoints: latency-svc-6d84s [749.127354ms]
Oct  1 09:44:20.357: INFO: Created: latency-svc-22hwh
Oct  1 09:44:20.401: INFO: Got endpoints: latency-svc-s8kv2 [750.028617ms]
Oct  1 09:44:20.404: INFO: Created: latency-svc-l6q4z
Oct  1 09:44:20.450: INFO: Got endpoints: latency-svc-fl2m2 [749.417697ms]
Oct  1 09:44:20.455: INFO: Created: latency-svc-tj4ml
Oct  1 09:44:20.501: INFO: Got endpoints: latency-svc-dgnsb [749.60144ms]
Oct  1 09:44:20.507: INFO: Created: latency-svc-86299
Oct  1 09:44:20.554: INFO: Got endpoints: latency-svc-854sj [752.776122ms]
Oct  1 09:44:20.558: INFO: Created: latency-svc-hp5pw
Oct  1 09:44:20.601: INFO: Got endpoints: latency-svc-hmrsw [750.390386ms]
Oct  1 09:44:20.606: INFO: Created: latency-svc-sc88g
Oct  1 09:44:20.652: INFO: Got endpoints: latency-svc-cqcpl [750.947553ms]
Oct  1 09:44:20.659: INFO: Created: latency-svc-xnfw6
Oct  1 09:44:20.701: INFO: Got endpoints: latency-svc-wbkn7 [750.10352ms]
Oct  1 09:44:20.705: INFO: Created: latency-svc-6hrvr
Oct  1 09:44:20.751: INFO: Got endpoints: latency-svc-t6xh9 [749.752435ms]
Oct  1 09:44:20.756: INFO: Created: latency-svc-jcg6d
Oct  1 09:44:20.801: INFO: Got endpoints: latency-svc-wclfn [749.841558ms]
Oct  1 09:44:20.807: INFO: Created: latency-svc-kp2s5
Oct  1 09:44:20.851: INFO: Got endpoints: latency-svc-9w9qr [749.90188ms]
Oct  1 09:44:20.856: INFO: Created: latency-svc-ng4fx
Oct  1 09:44:20.901: INFO: Got endpoints: latency-svc-8j7vk [749.8268ms]
Oct  1 09:44:20.905: INFO: Created: latency-svc-79xwq
Oct  1 09:44:20.951: INFO: Got endpoints: latency-svc-phsz9 [749.358001ms]
Oct  1 09:44:20.967: INFO: Created: latency-svc-ktgvv
Oct  1 09:44:21.001: INFO: Got endpoints: latency-svc-cdx2h [750.134541ms]
Oct  1 09:44:21.005: INFO: Created: latency-svc-5nmcw
Oct  1 09:44:21.051: INFO: Got endpoints: latency-svc-wcvmz [750.408551ms]
Oct  1 09:44:21.055: INFO: Created: latency-svc-fskbr
Oct  1 09:44:21.101: INFO: Got endpoints: latency-svc-22hwh [750.548719ms]
Oct  1 09:44:21.114: INFO: Created: latency-svc-7nwtn
Oct  1 09:44:21.151: INFO: Got endpoints: latency-svc-l6q4z [750.271058ms]
Oct  1 09:44:21.155: INFO: Created: latency-svc-md5c4
Oct  1 09:44:21.202: INFO: Got endpoints: latency-svc-tj4ml [751.670595ms]
Oct  1 09:44:21.208: INFO: Created: latency-svc-978tm
Oct  1 09:44:21.251: INFO: Got endpoints: latency-svc-86299 [750.154931ms]
Oct  1 09:44:21.262: INFO: Created: latency-svc-dz654
Oct  1 09:44:21.301: INFO: Got endpoints: latency-svc-hp5pw [746.993384ms]
Oct  1 09:44:21.306: INFO: Created: latency-svc-f4b6g
Oct  1 09:44:21.351: INFO: Got endpoints: latency-svc-sc88g [749.322278ms]
Oct  1 09:44:21.360: INFO: Created: latency-svc-c9vpw
Oct  1 09:44:21.401: INFO: Got endpoints: latency-svc-xnfw6 [748.899215ms]
Oct  1 09:44:21.412: INFO: Created: latency-svc-b7bv4
Oct  1 09:44:21.451: INFO: Got endpoints: latency-svc-6hrvr [749.920865ms]
Oct  1 09:44:21.455: INFO: Created: latency-svc-phvhk
Oct  1 09:44:21.501: INFO: Got endpoints: latency-svc-jcg6d [750.216611ms]
Oct  1 09:44:21.506: INFO: Created: latency-svc-87stq
Oct  1 09:44:21.551: INFO: Got endpoints: latency-svc-kp2s5 [749.94114ms]
Oct  1 09:44:21.555: INFO: Created: latency-svc-jbv4g
Oct  1 09:44:21.601: INFO: Got endpoints: latency-svc-ng4fx [749.796225ms]
Oct  1 09:44:21.606: INFO: Created: latency-svc-9k5vh
Oct  1 09:44:21.651: INFO: Got endpoints: latency-svc-79xwq [750.671982ms]
Oct  1 09:44:21.656: INFO: Created: latency-svc-c2xx2
Oct  1 09:44:21.701: INFO: Got endpoints: latency-svc-ktgvv [750.114359ms]
Oct  1 09:44:21.705: INFO: Created: latency-svc-nlkxq
Oct  1 09:44:21.750: INFO: Got endpoints: latency-svc-5nmcw [749.318838ms]
Oct  1 09:44:21.756: INFO: Created: latency-svc-l7swk
Oct  1 09:44:21.801: INFO: Got endpoints: latency-svc-fskbr [749.914963ms]
Oct  1 09:44:21.807: INFO: Created: latency-svc-ghb6k
Oct  1 09:44:21.851: INFO: Got endpoints: latency-svc-7nwtn [749.674602ms]
Oct  1 09:44:21.855: INFO: Created: latency-svc-c44xg
Oct  1 09:44:21.901: INFO: Got endpoints: latency-svc-md5c4 [749.890283ms]
Oct  1 09:44:21.905: INFO: Created: latency-svc-r27v2
Oct  1 09:44:21.951: INFO: Got endpoints: latency-svc-978tm [748.786603ms]
Oct  1 09:44:21.956: INFO: Created: latency-svc-94ttp
Oct  1 09:44:22.001: INFO: Got endpoints: latency-svc-dz654 [749.726867ms]
Oct  1 09:44:22.006: INFO: Created: latency-svc-sqxtz
Oct  1 09:44:22.051: INFO: Got endpoints: latency-svc-f4b6g [749.81941ms]
Oct  1 09:44:22.056: INFO: Created: latency-svc-42wjc
Oct  1 09:44:22.101: INFO: Got endpoints: latency-svc-c9vpw [749.889831ms]
Oct  1 09:44:22.105: INFO: Created: latency-svc-fhw8j
Oct  1 09:44:22.151: INFO: Got endpoints: latency-svc-b7bv4 [749.720122ms]
Oct  1 09:44:22.156: INFO: Created: latency-svc-rk868
Oct  1 09:44:22.201: INFO: Got endpoints: latency-svc-phvhk [750.097537ms]
Oct  1 09:44:22.207: INFO: Created: latency-svc-wmpz7
Oct  1 09:44:22.251: INFO: Got endpoints: latency-svc-87stq [750.029766ms]
Oct  1 09:44:22.263: INFO: Created: latency-svc-7dcwb
Oct  1 09:44:22.302: INFO: Got endpoints: latency-svc-jbv4g [750.708961ms]
Oct  1 09:44:22.306: INFO: Created: latency-svc-kxcrm
Oct  1 09:44:22.351: INFO: Got endpoints: latency-svc-9k5vh [750.031717ms]
Oct  1 09:44:22.355: INFO: Created: latency-svc-kt78z
Oct  1 09:44:22.401: INFO: Got endpoints: latency-svc-c2xx2 [749.965503ms]
Oct  1 09:44:22.417: INFO: Created: latency-svc-r48xx
Oct  1 09:44:22.451: INFO: Got endpoints: latency-svc-nlkxq [749.868001ms]
Oct  1 09:44:22.455: INFO: Created: latency-svc-tplxk
Oct  1 09:44:22.501: INFO: Got endpoints: latency-svc-l7swk [750.601698ms]
Oct  1 09:44:22.505: INFO: Created: latency-svc-xgsch
Oct  1 09:44:22.551: INFO: Got endpoints: latency-svc-ghb6k [749.978217ms]
Oct  1 09:44:22.563: INFO: Created: latency-svc-r8lxg
Oct  1 09:44:22.600: INFO: Got endpoints: latency-svc-c44xg [749.580132ms]
Oct  1 09:44:22.605: INFO: Created: latency-svc-dfnhf
Oct  1 09:44:22.651: INFO: Got endpoints: latency-svc-r27v2 [749.894783ms]
Oct  1 09:44:22.655: INFO: Created: latency-svc-4krb2
Oct  1 09:44:22.701: INFO: Got endpoints: latency-svc-94ttp [749.5298ms]
Oct  1 09:44:22.712: INFO: Created: latency-svc-9wg72
Oct  1 09:44:22.751: INFO: Got endpoints: latency-svc-sqxtz [750.047143ms]
Oct  1 09:44:22.756: INFO: Created: latency-svc-dxdlr
Oct  1 09:44:22.801: INFO: Got endpoints: latency-svc-42wjc [749.812667ms]
Oct  1 09:44:22.805: INFO: Created: latency-svc-ds2z8
Oct  1 09:44:22.851: INFO: Got endpoints: latency-svc-fhw8j [749.802643ms]
Oct  1 09:44:22.862: INFO: Created: latency-svc-qmwdr
Oct  1 09:44:22.900: INFO: Got endpoints: latency-svc-rk868 [749.374693ms]
Oct  1 09:44:22.905: INFO: Created: latency-svc-r9pqj
Oct  1 09:44:22.951: INFO: Got endpoints: latency-svc-wmpz7 [749.580229ms]
Oct  1 09:44:22.955: INFO: Created: latency-svc-swl8b
Oct  1 09:44:23.001: INFO: Got endpoints: latency-svc-7dcwb [749.397109ms]
Oct  1 09:44:23.012: INFO: Created: latency-svc-r7l4d
Oct  1 09:44:23.051: INFO: Got endpoints: latency-svc-kxcrm [748.965397ms]
Oct  1 09:44:23.056: INFO: Created: latency-svc-ggnnh
Oct  1 09:44:23.101: INFO: Got endpoints: latency-svc-kt78z [749.806271ms]
Oct  1 09:44:23.105: INFO: Created: latency-svc-t79z5
Oct  1 09:44:23.151: INFO: Got endpoints: latency-svc-r48xx [749.366541ms]
Oct  1 09:44:23.163: INFO: Created: latency-svc-q7w7h
Oct  1 09:44:23.201: INFO: Got endpoints: latency-svc-tplxk [749.962057ms]
Oct  1 09:44:23.205: INFO: Created: latency-svc-vr89j
Oct  1 09:44:23.250: INFO: Got endpoints: latency-svc-xgsch [749.224312ms]
Oct  1 09:44:23.254: INFO: Created: latency-svc-lfhsq
Oct  1 09:44:23.301: INFO: Got endpoints: latency-svc-r8lxg [749.808654ms]
Oct  1 09:44:23.305: INFO: Created: latency-svc-f9h8c
Oct  1 09:44:23.351: INFO: Got endpoints: latency-svc-dfnhf [750.180301ms]
Oct  1 09:44:23.355: INFO: Created: latency-svc-796rt
Oct  1 09:44:23.402: INFO: Got endpoints: latency-svc-4krb2 [750.726732ms]
Oct  1 09:44:23.407: INFO: Created: latency-svc-5hkmr
Oct  1 09:44:23.451: INFO: Got endpoints: latency-svc-9wg72 [750.305428ms]
Oct  1 09:44:23.456: INFO: Created: latency-svc-sr7wz
Oct  1 09:44:23.501: INFO: Got endpoints: latency-svc-dxdlr [750.519297ms]
Oct  1 09:44:23.506: INFO: Created: latency-svc-gnk6l
Oct  1 09:44:23.551: INFO: Got endpoints: latency-svc-ds2z8 [750.174682ms]
Oct  1 09:44:23.557: INFO: Created: latency-svc-9xtj4
Oct  1 09:44:23.601: INFO: Got endpoints: latency-svc-qmwdr [750.273557ms]
Oct  1 09:44:23.606: INFO: Created: latency-svc-9nxbv
Oct  1 09:44:23.651: INFO: Got endpoints: latency-svc-r9pqj [750.258215ms]
Oct  1 09:44:23.655: INFO: Created: latency-svc-jtd2c
Oct  1 09:44:23.701: INFO: Got endpoints: latency-svc-swl8b [750.065938ms]
Oct  1 09:44:23.713: INFO: Created: latency-svc-rsfqc
Oct  1 09:44:23.751: INFO: Got endpoints: latency-svc-r7l4d [750.250453ms]
Oct  1 09:44:23.758: INFO: Created: latency-svc-cr8ds
Oct  1 09:44:23.801: INFO: Got endpoints: latency-svc-ggnnh [750.384651ms]
Oct  1 09:44:23.805: INFO: Created: latency-svc-xwvmh
Oct  1 09:44:23.851: INFO: Got endpoints: latency-svc-t79z5 [750.344047ms]
Oct  1 09:44:23.863: INFO: Created: latency-svc-ln92h
Oct  1 09:44:23.901: INFO: Got endpoints: latency-svc-q7w7h [750.132194ms]
Oct  1 09:44:23.908: INFO: Created: latency-svc-vfd9x
Oct  1 09:44:23.951: INFO: Got endpoints: latency-svc-vr89j [749.824076ms]
Oct  1 09:44:23.955: INFO: Created: latency-svc-lgpbd
Oct  1 09:44:24.002: INFO: Got endpoints: latency-svc-lfhsq [751.56567ms]
Oct  1 09:44:24.013: INFO: Created: latency-svc-fjdz6
Oct  1 09:44:24.051: INFO: Got endpoints: latency-svc-f9h8c [750.252805ms]
Oct  1 09:44:24.055: INFO: Created: latency-svc-rvpwt
Oct  1 09:44:24.101: INFO: Got endpoints: latency-svc-796rt [750.337592ms]
Oct  1 09:44:24.105: INFO: Created: latency-svc-qmfdn
Oct  1 09:44:24.152: INFO: Got endpoints: latency-svc-5hkmr [750.229358ms]
Oct  1 09:44:24.156: INFO: Created: latency-svc-5zpzq
Oct  1 09:44:24.201: INFO: Got endpoints: latency-svc-sr7wz [750.311352ms]
Oct  1 09:44:24.206: INFO: Created: latency-svc-qx7h6
Oct  1 09:44:24.251: INFO: Got endpoints: latency-svc-gnk6l [749.415437ms]
Oct  1 09:44:24.266: INFO: Created: latency-svc-xmjxn
Oct  1 09:44:24.301: INFO: Got endpoints: latency-svc-9xtj4 [749.965404ms]
Oct  1 09:44:24.306: INFO: Created: latency-svc-5g6sd
Oct  1 09:44:24.351: INFO: Got endpoints: latency-svc-9nxbv [749.945575ms]
Oct  1 09:44:24.355: INFO: Created: latency-svc-vqg2b
Oct  1 09:44:24.401: INFO: Got endpoints: latency-svc-jtd2c [750.043475ms]
Oct  1 09:44:24.412: INFO: Created: latency-svc-mnqd9
Oct  1 09:44:24.451: INFO: Got endpoints: latency-svc-rsfqc [750.039699ms]
Oct  1 09:44:24.455: INFO: Created: latency-svc-jvv96
Oct  1 09:44:24.501: INFO: Got endpoints: latency-svc-cr8ds [749.994865ms]
Oct  1 09:44:24.506: INFO: Created: latency-svc-kwwq9
Oct  1 09:44:24.551: INFO: Got endpoints: latency-svc-xwvmh [750.200349ms]
Oct  1 09:44:24.565: INFO: Created: latency-svc-9ltkb
Oct  1 09:44:24.601: INFO: Got endpoints: latency-svc-ln92h [749.472084ms]
Oct  1 09:44:24.610: INFO: Created: latency-svc-jtbbg
Oct  1 09:44:24.651: INFO: Got endpoints: latency-svc-vfd9x [749.901803ms]
Oct  1 09:44:24.655: INFO: Created: latency-svc-k58z9
Oct  1 09:44:24.701: INFO: Got endpoints: latency-svc-lgpbd [750.087663ms]
Oct  1 09:44:24.713: INFO: Created: latency-svc-7mdbr
Oct  1 09:44:24.751: INFO: Got endpoints: latency-svc-fjdz6 [749.146366ms]
Oct  1 09:44:24.801: INFO: Got endpoints: latency-svc-rvpwt [750.035239ms]
Oct  1 09:44:24.851: INFO: Got endpoints: latency-svc-qmfdn [749.790605ms]
Oct  1 09:44:24.901: INFO: Got endpoints: latency-svc-5zpzq [748.991364ms]
Oct  1 09:44:24.951: INFO: Got endpoints: latency-svc-qx7h6 [749.669656ms]
Oct  1 09:44:25.001: INFO: Got endpoints: latency-svc-xmjxn [750.041681ms]
Oct  1 09:44:25.051: INFO: Got endpoints: latency-svc-5g6sd [749.809983ms]
Oct  1 09:44:25.101: INFO: Got endpoints: latency-svc-vqg2b [749.952994ms]
Oct  1 09:44:25.151: INFO: Got endpoints: latency-svc-mnqd9 [750.509447ms]
Oct  1 09:44:25.201: INFO: Got endpoints: latency-svc-jvv96 [749.614085ms]
Oct  1 09:44:25.251: INFO: Got endpoints: latency-svc-kwwq9 [749.969442ms]
Oct  1 09:44:25.301: INFO: Got endpoints: latency-svc-9ltkb [749.793765ms]
Oct  1 09:44:25.351: INFO: Got endpoints: latency-svc-jtbbg [750.184046ms]
Oct  1 09:44:25.401: INFO: Got endpoints: latency-svc-k58z9 [749.535198ms]
Oct  1 09:44:25.451: INFO: Got endpoints: latency-svc-7mdbr [749.88562ms]
Oct  1 09:44:25.451: INFO: Latencies: [11.860812ms 19.180515ms 29.951739ms 33.943422ms 39.537555ms 39.971874ms 50.186008ms 52.986023ms 65.687451ms 73.591978ms 75.933592ms 89.422175ms 90.455232ms 92.456352ms 92.865803ms 92.882315ms 93.25025ms 93.881476ms 95.550196ms 96.463324ms 96.656184ms 97.104316ms 97.364092ms 98.392347ms 98.483252ms 98.836144ms 99.078688ms 99.250019ms 101.424736ms 101.692023ms 103.968274ms 113.948756ms 116.856719ms 148.693215ms 154.252977ms 199.975668ms 248.766674ms 286.385455ms 332.119604ms 376.865834ms 424.121429ms 462.480276ms 509.010496ms 547.647519ms 592.62149ms 641.108776ms 679.555258ms 725.115441ms 746.993384ms 748.280235ms 748.613388ms 748.786603ms 748.891443ms 748.899215ms 748.952914ms 748.965397ms 748.991364ms 749.120177ms 749.127354ms 749.146366ms 749.200296ms 749.224312ms 749.318838ms 749.322278ms 749.324857ms 749.358001ms 749.366541ms 749.374693ms 749.397109ms 749.403356ms 749.415437ms 749.417697ms 749.472084ms 749.50696ms 749.5298ms 749.534975ms 749.535198ms 749.575694ms 749.580132ms 749.580229ms 749.60144ms 749.614085ms 749.634666ms 749.669656ms 749.674602ms 749.720122ms 749.726867ms 749.734047ms 749.739688ms 749.752435ms 749.777746ms 749.790605ms 749.792343ms 749.793765ms 749.796019ms 749.796225ms 749.802643ms 749.806271ms 749.808654ms 749.809983ms 749.812667ms 749.81941ms 749.823464ms 749.824076ms 749.8268ms 749.831702ms 749.841558ms 749.857202ms 749.865855ms 749.868001ms 749.88562ms 749.88603ms 749.889831ms 749.890283ms 749.894783ms 749.896525ms 749.898484ms 749.901803ms 749.90188ms 749.911146ms 749.914963ms 749.920865ms 749.933549ms 749.938838ms 749.94114ms 749.941781ms 749.945575ms 749.952994ms 749.962057ms 749.965404ms 749.965503ms 749.969442ms 749.978217ms 749.994865ms 750.028617ms 750.029766ms 750.031717ms 750.035239ms 750.039699ms 750.041681ms 750.043475ms 750.045799ms 750.047143ms 750.065938ms 750.071259ms 750.087663ms 750.097537ms 750.10352ms 750.114359ms 750.117775ms 750.132194ms 750.134541ms 750.148086ms 750.154931ms 750.174682ms 750.180301ms 750.184046ms 750.19579ms 750.200271ms 750.200349ms 750.211974ms 750.212458ms 750.216611ms 750.229358ms 750.234709ms 750.250453ms 750.252805ms 750.254052ms 750.258215ms 750.271058ms 750.273557ms 750.305428ms 750.311352ms 750.337592ms 750.339809ms 750.344047ms 750.37697ms 750.384651ms 750.384695ms 750.384793ms 750.390386ms 750.408551ms 750.444538ms 750.509447ms 750.519297ms 750.53691ms 750.548719ms 750.601698ms 750.648999ms 750.664629ms 750.671982ms 750.708961ms 750.726732ms 750.747691ms 750.947553ms 751.473816ms 751.56567ms 751.653767ms 751.670595ms 752.776122ms]
Oct  1 09:44:25.451: INFO: 50 %ile: 749.812667ms
Oct  1 09:44:25.451: INFO: 90 %ile: 750.390386ms
Oct  1 09:44:25.451: INFO: 99 %ile: 751.670595ms
Oct  1 09:44:25.451: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:44:25.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-5170" for this suite.
Oct  1 09:44:37.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:44:37.514: INFO: namespace svc-latency-5170 deletion completed in 12.060665599s

• [SLOW TEST:22.804 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:44:37.514: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-421c9f42-967e-4838-bcc8-b3e72491c5ec
STEP: Creating a pod to test consume secrets
Oct  1 09:44:37.550: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-75756a76-3271-47dc-88c9-194e67409fea" in namespace "projected-9474" to be "success or failure"
Oct  1 09:44:37.552: INFO: Pod "pod-projected-secrets-75756a76-3271-47dc-88c9-194e67409fea": Phase="Pending", Reason="", readiness=false. Elapsed: 1.745903ms
Oct  1 09:44:39.555: INFO: Pod "pod-projected-secrets-75756a76-3271-47dc-88c9-194e67409fea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004810412s
Oct  1 09:44:41.557: INFO: Pod "pod-projected-secrets-75756a76-3271-47dc-88c9-194e67409fea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007232921s
STEP: Saw pod success
Oct  1 09:44:41.557: INFO: Pod "pod-projected-secrets-75756a76-3271-47dc-88c9-194e67409fea" satisfied condition "success or failure"
Oct  1 09:44:41.559: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-projected-secrets-75756a76-3271-47dc-88c9-194e67409fea container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct  1 09:44:41.571: INFO: Waiting for pod pod-projected-secrets-75756a76-3271-47dc-88c9-194e67409fea to disappear
Oct  1 09:44:41.580: INFO: Pod pod-projected-secrets-75756a76-3271-47dc-88c9-194e67409fea no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:44:41.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9474" for this suite.
Oct  1 09:44:47.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:44:47.639: INFO: namespace projected-9474 deletion completed in 6.057123942s

• [SLOW TEST:10.125 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:44:47.639: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 09:44:47.671: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-5aa86386-89ed-47a9-84f4-890db5862ea9" in namespace "security-context-test-2786" to be "success or failure"
Oct  1 09:44:47.673: INFO: Pod "busybox-privileged-false-5aa86386-89ed-47a9-84f4-890db5862ea9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.172165ms
Oct  1 09:44:49.676: INFO: Pod "busybox-privileged-false-5aa86386-89ed-47a9-84f4-890db5862ea9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005207969s
Oct  1 09:44:51.679: INFO: Pod "busybox-privileged-false-5aa86386-89ed-47a9-84f4-890db5862ea9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008385213s
Oct  1 09:44:51.679: INFO: Pod "busybox-privileged-false-5aa86386-89ed-47a9-84f4-890db5862ea9" satisfied condition "success or failure"
Oct  1 09:44:51.683: INFO: Got logs for pod "busybox-privileged-false-5aa86386-89ed-47a9-84f4-890db5862ea9": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:44:51.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2786" for this suite.
Oct  1 09:44:57.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:44:57.741: INFO: namespace security-context-test-2786 deletion completed in 6.056471198s

• [SLOW TEST:10.102 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:44:57.742: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  1 09:44:57.770: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9dd150d1-f72c-4454-ac30-1074579dc495" in namespace "projected-8687" to be "success or failure"
Oct  1 09:44:57.773: INFO: Pod "downwardapi-volume-9dd150d1-f72c-4454-ac30-1074579dc495": Phase="Pending", Reason="", readiness=false. Elapsed: 2.12058ms
Oct  1 09:44:59.776: INFO: Pod "downwardapi-volume-9dd150d1-f72c-4454-ac30-1074579dc495": Phase="Running", Reason="", readiness=true. Elapsed: 2.005225222s
Oct  1 09:45:01.779: INFO: Pod "downwardapi-volume-9dd150d1-f72c-4454-ac30-1074579dc495": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008397567s
STEP: Saw pod success
Oct  1 09:45:01.779: INFO: Pod "downwardapi-volume-9dd150d1-f72c-4454-ac30-1074579dc495" satisfied condition "success or failure"
Oct  1 09:45:01.781: INFO: Trying to get logs from node ip-172-31-16-136 pod downwardapi-volume-9dd150d1-f72c-4454-ac30-1074579dc495 container client-container: <nil>
STEP: delete the pod
Oct  1 09:45:01.791: INFO: Waiting for pod downwardapi-volume-9dd150d1-f72c-4454-ac30-1074579dc495 to disappear
Oct  1 09:45:01.792: INFO: Pod downwardapi-volume-9dd150d1-f72c-4454-ac30-1074579dc495 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:45:01.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8687" for this suite.
Oct  1 09:45:07.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:45:07.854: INFO: namespace projected-8687 deletion completed in 6.0588896s

• [SLOW TEST:10.113 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:45:07.854: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-d6d15de7-799a-4ece-9bb1-100e783636cb
STEP: Creating configMap with name cm-test-opt-upd-5b216151-2e61-4f86-b0f4-2cdb97a25943
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-d6d15de7-799a-4ece-9bb1-100e783636cb
STEP: Updating configmap cm-test-opt-upd-5b216151-2e61-4f86-b0f4-2cdb97a25943
STEP: Creating configMap with name cm-test-opt-create-3d53ca7b-6f66-4095-ad0f-89e0f8ce9e2f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:46:16.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2119" for this suite.
Oct  1 09:46:28.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:46:28.158: INFO: namespace configmap-2119 deletion completed in 12.060022146s

• [SLOW TEST:80.303 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:46:28.158: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-715
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Oct  1 09:46:28.190: INFO: Found 0 stateful pods, waiting for 3
Oct  1 09:46:38.193: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 09:46:38.194: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 09:46:38.194: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Oct  1 09:46:48.194: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 09:46:48.194: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 09:46:48.194: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Oct  1 09:46:48.215: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Oct  1 09:46:58.241: INFO: Updating stateful set ss2
Oct  1 09:46:58.256: INFO: Waiting for Pod statefulset-715/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Oct  1 09:47:08.262: INFO: Waiting for Pod statefulset-715/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Oct  1 09:47:18.313: INFO: Found 2 stateful pods, waiting for 3
Oct  1 09:47:28.316: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 09:47:28.316: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 09:47:28.316: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Oct  1 09:47:28.337: INFO: Updating stateful set ss2
Oct  1 09:47:28.344: INFO: Waiting for Pod statefulset-715/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Oct  1 09:47:38.364: INFO: Updating stateful set ss2
Oct  1 09:47:38.370: INFO: Waiting for StatefulSet statefulset-715/ss2 to complete update
Oct  1 09:47:38.370: INFO: Waiting for Pod statefulset-715/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct  1 09:47:48.376: INFO: Deleting all statefulset in ns statefulset-715
Oct  1 09:47:48.378: INFO: Scaling statefulset ss2 to 0
Oct  1 09:48:18.388: INFO: Waiting for statefulset status.replicas updated to 0
Oct  1 09:48:18.390: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:48:18.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-715" for this suite.
Oct  1 09:48:24.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:48:24.668: INFO: namespace statefulset-715 deletion completed in 6.26821683s

• [SLOW TEST:116.511 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:48:24.669: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Oct  1 09:48:24.688: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-021449899 proxy --unix-socket=/tmp/kubectl-proxy-unix627598090/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:48:24.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5948" for this suite.
Oct  1 09:48:30.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:48:30.809: INFO: namespace kubectl-5948 deletion completed in 6.066509807s

• [SLOW TEST:6.140 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:48:30.809: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-gh8l
STEP: Creating a pod to test atomic-volume-subpath
Oct  1 09:48:30.842: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-gh8l" in namespace "subpath-8735" to be "success or failure"
Oct  1 09:48:30.845: INFO: Pod "pod-subpath-test-configmap-gh8l": Phase="Pending", Reason="", readiness=false. Elapsed: 3.099367ms
Oct  1 09:48:32.848: INFO: Pod "pod-subpath-test-configmap-gh8l": Phase="Running", Reason="", readiness=true. Elapsed: 2.006119213s
Oct  1 09:48:34.851: INFO: Pod "pod-subpath-test-configmap-gh8l": Phase="Running", Reason="", readiness=true. Elapsed: 4.009064317s
Oct  1 09:48:36.854: INFO: Pod "pod-subpath-test-configmap-gh8l": Phase="Running", Reason="", readiness=true. Elapsed: 6.011968382s
Oct  1 09:48:38.857: INFO: Pod "pod-subpath-test-configmap-gh8l": Phase="Running", Reason="", readiness=true. Elapsed: 8.014863792s
Oct  1 09:48:40.860: INFO: Pod "pod-subpath-test-configmap-gh8l": Phase="Running", Reason="", readiness=true. Elapsed: 10.017799142s
Oct  1 09:48:42.863: INFO: Pod "pod-subpath-test-configmap-gh8l": Phase="Running", Reason="", readiness=true. Elapsed: 12.02093204s
Oct  1 09:48:44.866: INFO: Pod "pod-subpath-test-configmap-gh8l": Phase="Running", Reason="", readiness=true. Elapsed: 14.023924245s
Oct  1 09:48:46.869: INFO: Pod "pod-subpath-test-configmap-gh8l": Phase="Running", Reason="", readiness=true. Elapsed: 16.026942656s
Oct  1 09:48:48.872: INFO: Pod "pod-subpath-test-configmap-gh8l": Phase="Running", Reason="", readiness=true. Elapsed: 18.029929345s
Oct  1 09:48:50.875: INFO: Pod "pod-subpath-test-configmap-gh8l": Phase="Running", Reason="", readiness=true. Elapsed: 20.033009616s
Oct  1 09:48:52.878: INFO: Pod "pod-subpath-test-configmap-gh8l": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.036027225s
STEP: Saw pod success
Oct  1 09:48:52.878: INFO: Pod "pod-subpath-test-configmap-gh8l" satisfied condition "success or failure"
Oct  1 09:48:52.880: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-subpath-test-configmap-gh8l container test-container-subpath-configmap-gh8l: <nil>
STEP: delete the pod
Oct  1 09:48:52.897: INFO: Waiting for pod pod-subpath-test-configmap-gh8l to disappear
Oct  1 09:48:52.908: INFO: Pod pod-subpath-test-configmap-gh8l no longer exists
STEP: Deleting pod pod-subpath-test-configmap-gh8l
Oct  1 09:48:52.909: INFO: Deleting pod "pod-subpath-test-configmap-gh8l" in namespace "subpath-8735"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:48:52.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8735" for this suite.
Oct  1 09:48:58.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:48:58.968: INFO: namespace subpath-8735 deletion completed in 6.055526825s

• [SLOW TEST:28.159 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:48:58.968: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  1 09:48:58.998: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e70d6e1a-ac24-4a9e-8e20-00a03da57b30" in namespace "projected-7656" to be "success or failure"
Oct  1 09:48:59.001: INFO: Pod "downwardapi-volume-e70d6e1a-ac24-4a9e-8e20-00a03da57b30": Phase="Pending", Reason="", readiness=false. Elapsed: 2.356615ms
Oct  1 09:49:01.004: INFO: Pod "downwardapi-volume-e70d6e1a-ac24-4a9e-8e20-00a03da57b30": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005583455s
STEP: Saw pod success
Oct  1 09:49:01.004: INFO: Pod "downwardapi-volume-e70d6e1a-ac24-4a9e-8e20-00a03da57b30" satisfied condition "success or failure"
Oct  1 09:49:01.006: INFO: Trying to get logs from node ip-172-31-16-136 pod downwardapi-volume-e70d6e1a-ac24-4a9e-8e20-00a03da57b30 container client-container: <nil>
STEP: delete the pod
Oct  1 09:49:01.019: INFO: Waiting for pod downwardapi-volume-e70d6e1a-ac24-4a9e-8e20-00a03da57b30 to disappear
Oct  1 09:49:01.026: INFO: Pod downwardapi-volume-e70d6e1a-ac24-4a9e-8e20-00a03da57b30 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:49:01.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7656" for this suite.
Oct  1 09:49:07.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:49:07.087: INFO: namespace projected-7656 deletion completed in 6.058489012s

• [SLOW TEST:8.119 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:49:07.087: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-8549
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-8549
I1001 09:49:07.132054      17 runners.go:184] Created replication controller with name: externalname-service, namespace: services-8549, replica count: 2
I1001 09:49:07.132142      17 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 09:49:07.132170      17 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Oct  1 09:49:10.182: INFO: Creating new exec pod
I1001 09:49:10.182584      17 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1001 09:49:14.190049      17 reflector.go:120] Starting reflector *v1.Endpoints (0s) from k8s.io/kubernetes/test/e2e/framework/service/jig.go:389
I1001 09:49:14.190079      17 reflector.go:158] Listing and watching *v1.Endpoints from k8s.io/kubernetes/test/e2e/framework/service/jig.go:389
Oct  1 09:49:15.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=services-8549 execpodrqwhc -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Oct  1 09:49:16.129: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Oct  1 09:49:16.129: INFO: stdout: ""
Oct  1 09:49:16.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=services-8549 execpodrqwhc -- /bin/sh -x -c nc -zv -t -w 2 10.152.183.161 80'
Oct  1 09:49:16.332: INFO: stderr: "+ nc -zv -t -w 2 10.152.183.161 80\nConnection to 10.152.183.161 80 port [tcp/http] succeeded!\n"
Oct  1 09:49:16.332: INFO: stdout: ""
Oct  1 09:49:16.332: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:49:16.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8549" for this suite.
Oct  1 09:49:22.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:49:22.402: INFO: namespace services-8549 deletion completed in 6.058539521s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:15.314 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:49:22.402: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct  1 09:49:24.945: INFO: Successfully updated pod "pod-update-activedeadlineseconds-e054f71c-f4e6-4247-96fd-b72cf9e07ecb"
Oct  1 09:49:24.945: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-e054f71c-f4e6-4247-96fd-b72cf9e07ecb" in namespace "pods-124" to be "terminated due to deadline exceeded"
Oct  1 09:49:24.947: INFO: Pod "pod-update-activedeadlineseconds-e054f71c-f4e6-4247-96fd-b72cf9e07ecb": Phase="Running", Reason="", readiness=true. Elapsed: 1.568541ms
Oct  1 09:49:26.950: INFO: Pod "pod-update-activedeadlineseconds-e054f71c-f4e6-4247-96fd-b72cf9e07ecb": Phase="Running", Reason="", readiness=true. Elapsed: 2.004573682s
Oct  1 09:49:28.953: INFO: Pod "pod-update-activedeadlineseconds-e054f71c-f4e6-4247-96fd-b72cf9e07ecb": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.007730336s
Oct  1 09:49:28.953: INFO: Pod "pod-update-activedeadlineseconds-e054f71c-f4e6-4247-96fd-b72cf9e07ecb" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:49:28.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-124" for this suite.
Oct  1 09:49:34.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:49:35.012: INFO: namespace pods-124 deletion completed in 6.056690821s

• [SLOW TEST:12.610 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:49:35.012: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-e0ae2a70-5fcb-4729-b4fd-1dfa58302f7d
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:49:35.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5976" for this suite.
Oct  1 09:49:41.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:49:41.097: INFO: namespace secrets-5976 deletion completed in 6.057847213s

• [SLOW TEST:6.085 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:49:41.097: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:49:57.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7134" for this suite.
Oct  1 09:50:03.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:50:03.261: INFO: namespace resourcequota-7134 deletion completed in 6.071332399s

• [SLOW TEST:22.164 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:50:03.261: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct  1 09:50:07.309: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  1 09:50:07.312: INFO: Pod pod-with-prestop-http-hook still exists
Oct  1 09:50:09.313: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  1 09:50:09.315: INFO: Pod pod-with-prestop-http-hook still exists
Oct  1 09:50:11.313: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  1 09:50:11.316: INFO: Pod pod-with-prestop-http-hook still exists
Oct  1 09:50:13.313: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  1 09:50:13.316: INFO: Pod pod-with-prestop-http-hook still exists
Oct  1 09:50:15.313: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  1 09:50:15.315: INFO: Pod pod-with-prestop-http-hook still exists
Oct  1 09:50:17.313: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  1 09:50:17.316: INFO: Pod pod-with-prestop-http-hook still exists
Oct  1 09:50:19.313: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  1 09:50:19.315: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:50:19.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7881" for this suite.
Oct  1 09:50:31.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:50:31.380: INFO: namespace container-lifecycle-hook-7881 deletion completed in 12.05908223s

• [SLOW TEST:28.119 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:50:31.380: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Oct  1 09:50:33.929: INFO: Successfully updated pod "annotationupdatea1d2868d-c823-4906-9854-20f8bc795403"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:50:37.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-98" for this suite.
Oct  1 09:50:49.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:50:50.006: INFO: namespace projected-98 deletion completed in 12.05971166s

• [SLOW TEST:18.625 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:50:50.006: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct  1 09:50:50.036: INFO: Waiting up to 5m0s for pod "pod-c929cd58-95b4-4b79-9583-b5be2ab62f52" in namespace "emptydir-54" to be "success or failure"
Oct  1 09:50:50.038: INFO: Pod "pod-c929cd58-95b4-4b79-9583-b5be2ab62f52": Phase="Pending", Reason="", readiness=false. Elapsed: 1.968401ms
Oct  1 09:50:52.041: INFO: Pod "pod-c929cd58-95b4-4b79-9583-b5be2ab62f52": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00526404s
Oct  1 09:50:54.044: INFO: Pod "pod-c929cd58-95b4-4b79-9583-b5be2ab62f52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008397487s
STEP: Saw pod success
Oct  1 09:50:54.044: INFO: Pod "pod-c929cd58-95b4-4b79-9583-b5be2ab62f52" satisfied condition "success or failure"
Oct  1 09:50:54.046: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-c929cd58-95b4-4b79-9583-b5be2ab62f52 container test-container: <nil>
STEP: delete the pod
Oct  1 09:50:54.058: INFO: Waiting for pod pod-c929cd58-95b4-4b79-9583-b5be2ab62f52 to disappear
Oct  1 09:50:54.066: INFO: Pod pod-c929cd58-95b4-4b79-9583-b5be2ab62f52 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:50:54.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-54" for this suite.
Oct  1 09:51:00.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:51:00.127: INFO: namespace emptydir-54 deletion completed in 6.058477898s

• [SLOW TEST:10.121 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:51:00.127: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  1 09:51:00.533: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  1 09:51:03.545: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:51:03.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4380" for this suite.
Oct  1 09:51:09.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:51:09.661: INFO: namespace webhook-4380 deletion completed in 6.060164413s
STEP: Destroying namespace "webhook-4380-markers" for this suite.
Oct  1 09:51:15.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:51:15.717: INFO: namespace webhook-4380-markers deletion completed in 6.056518676s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:15.599 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:51:15.726: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Oct  1 09:51:15.754: INFO: Waiting up to 5m0s for pod "client-containers-e9276ec5-a81f-4e7a-a8b1-42edfd1ec58f" in namespace "containers-9130" to be "success or failure"
Oct  1 09:51:15.755: INFO: Pod "client-containers-e9276ec5-a81f-4e7a-a8b1-42edfd1ec58f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.551386ms
Oct  1 09:51:17.758: INFO: Pod "client-containers-e9276ec5-a81f-4e7a-a8b1-42edfd1ec58f": Phase="Running", Reason="", readiness=true. Elapsed: 2.004535871s
Oct  1 09:51:19.761: INFO: Pod "client-containers-e9276ec5-a81f-4e7a-a8b1-42edfd1ec58f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00740877s
STEP: Saw pod success
Oct  1 09:51:19.761: INFO: Pod "client-containers-e9276ec5-a81f-4e7a-a8b1-42edfd1ec58f" satisfied condition "success or failure"
Oct  1 09:51:19.763: INFO: Trying to get logs from node ip-172-31-16-136 pod client-containers-e9276ec5-a81f-4e7a-a8b1-42edfd1ec58f container test-container: <nil>
STEP: delete the pod
Oct  1 09:51:19.775: INFO: Waiting for pod client-containers-e9276ec5-a81f-4e7a-a8b1-42edfd1ec58f to disappear
Oct  1 09:51:19.782: INFO: Pod client-containers-e9276ec5-a81f-4e7a-a8b1-42edfd1ec58f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:51:19.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9130" for this suite.
Oct  1 09:51:25.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:51:25.840: INFO: namespace containers-9130 deletion completed in 6.05593032s

• [SLOW TEST:10.114 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:51:25.841: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-0a79e99b-b75d-4f82-8b03-550ac9bcd02c in namespace container-probe-77
Oct  1 09:51:29.878: INFO: Started pod busybox-0a79e99b-b75d-4f82-8b03-550ac9bcd02c in namespace container-probe-77
STEP: checking the pod's current state and verifying that restartCount is present
Oct  1 09:51:29.880: INFO: Initial restart count of pod busybox-0a79e99b-b75d-4f82-8b03-550ac9bcd02c is 0
Oct  1 09:52:17.952: INFO: Restart count of pod container-probe-77/busybox-0a79e99b-b75d-4f82-8b03-550ac9bcd02c is now 1 (48.072526491s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:52:17.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-77" for this suite.
Oct  1 09:52:23.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:52:24.018: INFO: namespace container-probe-77 deletion completed in 6.057637786s

• [SLOW TEST:58.178 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:52:24.019: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:52:32.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7692" for this suite.
Oct  1 09:52:38.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:52:38.113: INFO: namespace job-7692 deletion completed in 6.058995301s

• [SLOW TEST:14.094 seconds]
[sig-apps] Job
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:52:38.113: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 09:52:38.160: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"87451142-8f29-445a-b28e-bd62a9aa5660", Controller:(*bool)(0xc002539fde), BlockOwnerDeletion:(*bool)(0xc002539fdf)}}
Oct  1 09:52:38.175: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"841b6bd8-c738-41ef-b583-53f5aa2384b5", Controller:(*bool)(0xc000ca4c36), BlockOwnerDeletion:(*bool)(0xc000ca4c37)}}
Oct  1 09:52:38.189: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"e0cf0d7c-6b57-453a-8348-48710a4c8ff1", Controller:(*bool)(0xc002b73b76), BlockOwnerDeletion:(*bool)(0xc002b73b77)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:52:43.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4097" for this suite.
Oct  1 09:52:49.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:52:49.260: INFO: namespace gc-4097 deletion completed in 6.057681183s

• [SLOW TEST:11.147 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:52:49.260: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct  1 09:52:52.302: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:52:52.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4075" for this suite.
Oct  1 09:52:58.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:52:58.381: INFO: namespace container-runtime-4075 deletion completed in 6.060061315s

• [SLOW TEST:9.121 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:52:58.381: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-3766
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct  1 09:52:58.400: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct  1 09:53:20.445: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.1.63.71:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3766 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 09:53:20.445: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 09:53:20.574: INFO: Found all expected endpoints: [netserver-0]
Oct  1 09:53:20.577: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.1.2.20:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3766 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 09:53:20.577: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 09:53:20.714: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:53:20.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3766" for this suite.
Oct  1 09:53:32.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:53:32.775: INFO: namespace pod-network-test-3766 deletion completed in 12.058626889s

• [SLOW TEST:34.394 seconds]
[sig-network] Networking
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:53:32.776: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-474
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-474
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-474
Oct  1 09:53:32.815: INFO: Found 0 stateful pods, waiting for 1
Oct  1 09:53:42.818: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Oct  1 09:53:42.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=statefulset-474 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  1 09:53:43.018: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  1 09:53:43.018: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  1 09:53:43.018: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  1 09:53:43.021: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct  1 09:53:53.024: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct  1 09:53:53.024: INFO: Waiting for statefulset status.replicas updated to 0
Oct  1 09:53:53.033: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998573s
Oct  1 09:53:54.036: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997818956s
Oct  1 09:53:55.039: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.994477192s
Oct  1 09:53:56.043: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.991405887s
Oct  1 09:53:57.046: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.988041533s
Oct  1 09:53:58.050: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.984514781s
Oct  1 09:53:59.053: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.980994472s
Oct  1 09:54:00.056: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.977535936s
Oct  1 09:54:01.060: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.974281978s
Oct  1 09:54:02.064: INFO: Verifying statefulset ss doesn't scale past 1 for another 970.849041ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-474
Oct  1 09:54:03.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=statefulset-474 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  1 09:54:03.263: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct  1 09:54:03.263: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  1 09:54:03.263: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  1 09:54:03.266: INFO: Found 1 stateful pods, waiting for 3
Oct  1 09:54:13.269: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 09:54:13.269: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 09:54:13.269: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Oct  1 09:54:13.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=statefulset-474 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  1 09:54:13.481: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  1 09:54:13.481: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  1 09:54:13.481: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  1 09:54:13.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=statefulset-474 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  1 09:54:13.674: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  1 09:54:13.674: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  1 09:54:13.674: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  1 09:54:13.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=statefulset-474 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  1 09:54:13.861: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  1 09:54:13.861: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  1 09:54:13.861: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  1 09:54:13.861: INFO: Waiting for statefulset status.replicas updated to 0
Oct  1 09:54:13.864: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Oct  1 09:54:23.869: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct  1 09:54:23.869: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct  1 09:54:23.869: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct  1 09:54:23.877: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998573s
Oct  1 09:54:24.879: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997394775s
Oct  1 09:54:25.882: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994871082s
Oct  1 09:54:26.886: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.991836505s
Oct  1 09:54:27.889: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.988232036s
Oct  1 09:54:28.893: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.984849266s
Oct  1 09:54:29.896: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.981309389s
Oct  1 09:54:30.899: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.978199104s
Oct  1 09:54:31.902: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.974993232s
Oct  1 09:54:32.906: INFO: Verifying statefulset ss doesn't scale past 3 for another 971.595696ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-474
Oct  1 09:54:33.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=statefulset-474 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  1 09:54:34.105: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct  1 09:54:34.105: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  1 09:54:34.105: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  1 09:54:34.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=statefulset-474 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  1 09:54:34.301: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct  1 09:54:34.301: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  1 09:54:34.301: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  1 09:54:34.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=statefulset-474 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  1 09:54:34.496: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct  1 09:54:34.496: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  1 09:54:34.496: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  1 09:54:34.496: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct  1 09:54:54.507: INFO: Deleting all statefulset in ns statefulset-474
Oct  1 09:54:54.509: INFO: Scaling statefulset ss to 0
Oct  1 09:54:54.515: INFO: Waiting for statefulset status.replicas updated to 0
Oct  1 09:54:54.516: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:54:54.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-474" for this suite.
Oct  1 09:55:00.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:55:00.590: INFO: namespace statefulset-474 deletion completed in 6.064357842s

• [SLOW TEST:87.814 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:55:00.590: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9556.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9556.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct  1 09:55:04.641: INFO: DNS probes using dns-9556/dns-test-68d05d7e-f08f-44d0-b7d5-479ab89cba00 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:55:04.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9556" for this suite.
Oct  1 09:55:10.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:55:10.714: INFO: namespace dns-9556 deletion completed in 6.057654651s

• [SLOW TEST:10.124 seconds]
[sig-network] DNS
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:55:10.714: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct  1 09:55:10.743: INFO: Waiting up to 5m0s for pod "pod-cfaa9b66-55d6-44f7-b65c-6daaf7ccad9f" in namespace "emptydir-6463" to be "success or failure"
Oct  1 09:55:10.744: INFO: Pod "pod-cfaa9b66-55d6-44f7-b65c-6daaf7ccad9f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.676595ms
Oct  1 09:55:12.747: INFO: Pod "pod-cfaa9b66-55d6-44f7-b65c-6daaf7ccad9f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004646783s
Oct  1 09:55:14.750: INFO: Pod "pod-cfaa9b66-55d6-44f7-b65c-6daaf7ccad9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007456448s
STEP: Saw pod success
Oct  1 09:55:14.750: INFO: Pod "pod-cfaa9b66-55d6-44f7-b65c-6daaf7ccad9f" satisfied condition "success or failure"
Oct  1 09:55:14.752: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-cfaa9b66-55d6-44f7-b65c-6daaf7ccad9f container test-container: <nil>
STEP: delete the pod
Oct  1 09:55:14.769: INFO: Waiting for pod pod-cfaa9b66-55d6-44f7-b65c-6daaf7ccad9f to disappear
Oct  1 09:55:14.772: INFO: Pod pod-cfaa9b66-55d6-44f7-b65c-6daaf7ccad9f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:55:14.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6463" for this suite.
Oct  1 09:55:20.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:55:20.835: INFO: namespace emptydir-6463 deletion completed in 6.059736973s

• [SLOW TEST:10.121 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:55:20.836: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:55:20.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5194" for this suite.
Oct  1 09:55:26.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:55:26.920: INFO: namespace custom-resource-definition-5194 deletion completed in 6.057120927s

• [SLOW TEST:6.084 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:55:26.920: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-824b8750-3a3c-42f6-babb-2ff21f2ac9be
STEP: Creating a pod to test consume configMaps
Oct  1 09:55:26.951: INFO: Waiting up to 5m0s for pod "pod-configmaps-7c86625e-2ae1-4ddd-860d-d165c3aaeb47" in namespace "configmap-9956" to be "success or failure"
Oct  1 09:55:26.952: INFO: Pod "pod-configmaps-7c86625e-2ae1-4ddd-860d-d165c3aaeb47": Phase="Pending", Reason="", readiness=false. Elapsed: 1.688714ms
Oct  1 09:55:28.955: INFO: Pod "pod-configmaps-7c86625e-2ae1-4ddd-860d-d165c3aaeb47": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004663526s
Oct  1 09:55:30.959: INFO: Pod "pod-configmaps-7c86625e-2ae1-4ddd-860d-d165c3aaeb47": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007898672s
STEP: Saw pod success
Oct  1 09:55:30.959: INFO: Pod "pod-configmaps-7c86625e-2ae1-4ddd-860d-d165c3aaeb47" satisfied condition "success or failure"
Oct  1 09:55:30.961: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-configmaps-7c86625e-2ae1-4ddd-860d-d165c3aaeb47 container configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 09:55:30.976: INFO: Waiting for pod pod-configmaps-7c86625e-2ae1-4ddd-860d-d165c3aaeb47 to disappear
Oct  1 09:55:30.983: INFO: Pod pod-configmaps-7c86625e-2ae1-4ddd-860d-d165c3aaeb47 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:55:30.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9956" for this suite.
Oct  1 09:55:36.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:55:37.042: INFO: namespace configmap-9956 deletion completed in 6.056976146s

• [SLOW TEST:10.123 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:55:37.043: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  1 09:55:37.072: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7724da7e-24fe-4aee-b94e-0d2b34dd9ff2" in namespace "downward-api-2358" to be "success or failure"
Oct  1 09:55:37.074: INFO: Pod "downwardapi-volume-7724da7e-24fe-4aee-b94e-0d2b34dd9ff2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.103655ms
Oct  1 09:55:39.077: INFO: Pod "downwardapi-volume-7724da7e-24fe-4aee-b94e-0d2b34dd9ff2": Phase="Running", Reason="", readiness=true. Elapsed: 2.005041475s
Oct  1 09:55:41.080: INFO: Pod "downwardapi-volume-7724da7e-24fe-4aee-b94e-0d2b34dd9ff2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008049026s
STEP: Saw pod success
Oct  1 09:55:41.080: INFO: Pod "downwardapi-volume-7724da7e-24fe-4aee-b94e-0d2b34dd9ff2" satisfied condition "success or failure"
Oct  1 09:55:41.082: INFO: Trying to get logs from node ip-172-31-16-136 pod downwardapi-volume-7724da7e-24fe-4aee-b94e-0d2b34dd9ff2 container client-container: <nil>
STEP: delete the pod
Oct  1 09:55:41.094: INFO: Waiting for pod downwardapi-volume-7724da7e-24fe-4aee-b94e-0d2b34dd9ff2 to disappear
Oct  1 09:55:41.101: INFO: Pod downwardapi-volume-7724da7e-24fe-4aee-b94e-0d2b34dd9ff2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:55:41.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2358" for this suite.
Oct  1 09:55:47.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:55:47.167: INFO: namespace downward-api-2358 deletion completed in 6.063883379s

• [SLOW TEST:10.125 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:55:47.168: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  1 09:55:47.220: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a2a773f7-a2a8-4f99-9620-4f167e6a8ce1" in namespace "projected-8827" to be "success or failure"
Oct  1 09:55:47.222: INFO: Pod "downwardapi-volume-a2a773f7-a2a8-4f99-9620-4f167e6a8ce1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.248782ms
Oct  1 09:55:49.225: INFO: Pod "downwardapi-volume-a2a773f7-a2a8-4f99-9620-4f167e6a8ce1": Phase="Running", Reason="", readiness=true. Elapsed: 2.005197294s
Oct  1 09:55:51.228: INFO: Pod "downwardapi-volume-a2a773f7-a2a8-4f99-9620-4f167e6a8ce1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008022311s
STEP: Saw pod success
Oct  1 09:55:51.228: INFO: Pod "downwardapi-volume-a2a773f7-a2a8-4f99-9620-4f167e6a8ce1" satisfied condition "success or failure"
Oct  1 09:55:51.229: INFO: Trying to get logs from node ip-172-31-16-136 pod downwardapi-volume-a2a773f7-a2a8-4f99-9620-4f167e6a8ce1 container client-container: <nil>
STEP: delete the pod
Oct  1 09:55:51.241: INFO: Waiting for pod downwardapi-volume-a2a773f7-a2a8-4f99-9620-4f167e6a8ce1 to disappear
Oct  1 09:55:51.248: INFO: Pod downwardapi-volume-a2a773f7-a2a8-4f99-9620-4f167e6a8ce1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:55:51.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8827" for this suite.
Oct  1 09:55:57.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:55:57.308: INFO: namespace projected-8827 deletion completed in 6.057229214s

• [SLOW TEST:10.140 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:55:57.308: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct  1 09:56:01.361: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct  1 09:56:01.364: INFO: Pod pod-with-poststart-http-hook still exists
Oct  1 09:56:03.364: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct  1 09:56:03.367: INFO: Pod pod-with-poststart-http-hook still exists
Oct  1 09:56:05.364: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct  1 09:56:05.367: INFO: Pod pod-with-poststart-http-hook still exists
Oct  1 09:56:07.364: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct  1 09:56:07.366: INFO: Pod pod-with-poststart-http-hook still exists
Oct  1 09:56:09.364: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct  1 09:56:09.367: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:56:09.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4949" for this suite.
Oct  1 09:56:21.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:56:21.429: INFO: namespace container-lifecycle-hook-4949 deletion completed in 12.060344826s

• [SLOW TEST:24.122 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:56:21.430: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Oct  1 09:56:21.449: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct  1 09:56:21.462: INFO: Waiting for terminating namespaces to be deleted...
Oct  1 09:56:21.463: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-16-136 before test
Oct  1 09:56:21.467: INFO: sonobuoy from sonobuoy started at 2019-10-01 09:21:20 +0000 UTC (1 container statuses recorded)
Oct  1 09:56:21.467: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct  1 09:56:21.467: INFO: sonobuoy-systemd-logs-daemon-set-c998de73b1b44522-6mdfj from sonobuoy started at 2019-10-01 09:21:21 +0000 UTC (2 container statuses recorded)
Oct  1 09:56:21.467: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  1 09:56:21.467: INFO: 	Container systemd-logs ready: true, restart count 0
Oct  1 09:56:21.467: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-29-44 before test
Oct  1 09:56:21.501: INFO: coredns-9b8997588-8dd8w from kube-system started at 2019-10-01 09:06:34 +0000 UTC (1 container statuses recorded)
Oct  1 09:56:21.501: INFO: 	Container coredns ready: true, restart count 0
Oct  1 09:56:21.501: INFO: sonobuoy-e2e-job-41fbe38c4f734fd3 from sonobuoy started at 2019-10-01 09:21:21 +0000 UTC (2 container statuses recorded)
Oct  1 09:56:21.501: INFO: 	Container e2e ready: true, restart count 0
Oct  1 09:56:21.501: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  1 09:56:21.501: INFO: sonobuoy-systemd-logs-daemon-set-c998de73b1b44522-4jgxd from sonobuoy started at 2019-10-01 09:21:21 +0000 UTC (2 container statuses recorded)
Oct  1 09:56:21.501: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  1 09:56:21.501: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-d1170781-49ae-4983-9710-a73370cad56d 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-d1170781-49ae-4983-9710-a73370cad56d off the node ip-172-31-16-136
STEP: verifying the node doesn't have the label kubernetes.io/e2e-d1170781-49ae-4983-9710-a73370cad56d
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:56:31.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6799" for this suite.
Oct  1 09:56:59.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:56:59.623: INFO: namespace sched-pred-6799 deletion completed in 28.058281485s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

I1001 09:56:59.623257      17 request.go:706] Error in request: resource name may not be empty
• [SLOW TEST:38.193 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:56:59.623: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct  1 09:57:02.167: INFO: Successfully updated pod "pod-update-9005187c-821f-4b2a-a585-0f89c4a2e85f"
STEP: verifying the updated pod is in kubernetes
Oct  1 09:57:02.171: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:57:02.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6803" for this suite.
Oct  1 09:57:30.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:57:30.231: INFO: namespace pods-6803 deletion completed in 28.057552463s

• [SLOW TEST:30.608 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:57:30.231: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 09:57:30.251: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:57:30.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2952" for this suite.
Oct  1 09:57:36.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:57:36.860: INFO: namespace custom-resource-definition-2952 deletion completed in 6.060568608s

• [SLOW TEST:6.629 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:57:36.860: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-4bce7389-1731-43f8-a721-a9b254871149
STEP: Creating a pod to test consume secrets
Oct  1 09:57:36.892: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fc3f06f3-3e9d-4858-8c5a-5f0b590846e6" in namespace "projected-9577" to be "success or failure"
Oct  1 09:57:36.894: INFO: Pod "pod-projected-secrets-fc3f06f3-3e9d-4858-8c5a-5f0b590846e6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.726813ms
Oct  1 09:57:38.897: INFO: Pod "pod-projected-secrets-fc3f06f3-3e9d-4858-8c5a-5f0b590846e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004803284s
STEP: Saw pod success
Oct  1 09:57:38.897: INFO: Pod "pod-projected-secrets-fc3f06f3-3e9d-4858-8c5a-5f0b590846e6" satisfied condition "success or failure"
Oct  1 09:57:38.898: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-projected-secrets-fc3f06f3-3e9d-4858-8c5a-5f0b590846e6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct  1 09:57:38.911: INFO: Waiting for pod pod-projected-secrets-fc3f06f3-3e9d-4858-8c5a-5f0b590846e6 to disappear
Oct  1 09:57:38.918: INFO: Pod pod-projected-secrets-fc3f06f3-3e9d-4858-8c5a-5f0b590846e6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:57:38.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9577" for this suite.
Oct  1 09:57:44.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:57:44.980: INFO: namespace projected-9577 deletion completed in 6.057769727s

• [SLOW TEST:8.120 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:57:44.980: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-4604, will wait for the garbage collector to delete the pods
I1001 09:57:47.018055      17 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 09:57:47.018087      17 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Oct  1 09:57:47.072: INFO: Deleting Job.batch foo took: 4.1775ms
Oct  1 09:57:47.372: INFO: Terminating Job.batch foo pods took: 300.405689ms
I1001 09:57:47.372782      17 controller_utils.go:810] Ignoring inactive pod job-4604/foo-kjxsx in state Running, deletion time 2019-10-01 09:58:17 +0000 UTC
I1001 09:57:47.372820      17 controller_utils.go:810] Ignoring inactive pod job-4604/foo-kq72z in state Running, deletion time 2019-10-01 09:58:17 +0000 UTC
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:58:29.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4604" for this suite.
Oct  1 09:58:35.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:58:35.135: INFO: namespace job-4604 deletion completed in 6.058102444s

• [SLOW TEST:50.155 seconds]
[sig-apps] Job
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:58:35.135: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Oct  1 09:58:35.162: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7457 /api/v1/namespaces/watch-7457/configmaps/e2e-watch-test-configmap-a d35c0918-70e5-4edd-bb69-5ecdd0ce4789 9306 0 2019-10-01 09:58:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct  1 09:58:35.162: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7457 /api/v1/namespaces/watch-7457/configmaps/e2e-watch-test-configmap-a d35c0918-70e5-4edd-bb69-5ecdd0ce4789 9306 0 2019-10-01 09:58:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Oct  1 09:58:45.168: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7457 /api/v1/namespaces/watch-7457/configmaps/e2e-watch-test-configmap-a d35c0918-70e5-4edd-bb69-5ecdd0ce4789 9320 0 2019-10-01 09:58:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct  1 09:58:45.168: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7457 /api/v1/namespaces/watch-7457/configmaps/e2e-watch-test-configmap-a d35c0918-70e5-4edd-bb69-5ecdd0ce4789 9320 0 2019-10-01 09:58:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Oct  1 09:58:55.174: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7457 /api/v1/namespaces/watch-7457/configmaps/e2e-watch-test-configmap-a d35c0918-70e5-4edd-bb69-5ecdd0ce4789 9335 0 2019-10-01 09:58:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct  1 09:58:55.174: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7457 /api/v1/namespaces/watch-7457/configmaps/e2e-watch-test-configmap-a d35c0918-70e5-4edd-bb69-5ecdd0ce4789 9335 0 2019-10-01 09:58:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Oct  1 09:59:05.178: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7457 /api/v1/namespaces/watch-7457/configmaps/e2e-watch-test-configmap-a d35c0918-70e5-4edd-bb69-5ecdd0ce4789 9349 0 2019-10-01 09:58:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct  1 09:59:05.178: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7457 /api/v1/namespaces/watch-7457/configmaps/e2e-watch-test-configmap-a d35c0918-70e5-4edd-bb69-5ecdd0ce4789 9349 0 2019-10-01 09:58:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Oct  1 09:59:15.183: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7457 /api/v1/namespaces/watch-7457/configmaps/e2e-watch-test-configmap-b 54c3fb09-db0e-42ed-b4ee-d39cf388d719 9363 0 2019-10-01 09:59:15 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct  1 09:59:15.183: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7457 /api/v1/namespaces/watch-7457/configmaps/e2e-watch-test-configmap-b 54c3fb09-db0e-42ed-b4ee-d39cf388d719 9363 0 2019-10-01 09:59:15 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Oct  1 09:59:25.188: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7457 /api/v1/namespaces/watch-7457/configmaps/e2e-watch-test-configmap-b 54c3fb09-db0e-42ed-b4ee-d39cf388d719 9378 0 2019-10-01 09:59:15 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct  1 09:59:25.188: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7457 /api/v1/namespaces/watch-7457/configmaps/e2e-watch-test-configmap-b 54c3fb09-db0e-42ed-b4ee-d39cf388d719 9378 0 2019-10-01 09:59:15 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:59:35.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7457" for this suite.
Oct  1 09:59:41.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:59:41.249: INFO: namespace watch-7457 deletion completed in 6.058274194s

• [SLOW TEST:66.114 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:59:41.250: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  1 09:59:41.283: INFO: Waiting up to 5m0s for pod "downwardapi-volume-43612181-3dfc-4df5-95a0-7c65bb4c297e" in namespace "downward-api-3598" to be "success or failure"
Oct  1 09:59:41.285: INFO: Pod "downwardapi-volume-43612181-3dfc-4df5-95a0-7c65bb4c297e": Phase="Pending", Reason="", readiness=false. Elapsed: 1.622493ms
Oct  1 09:59:43.288: INFO: Pod "downwardapi-volume-43612181-3dfc-4df5-95a0-7c65bb4c297e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004592924s
STEP: Saw pod success
Oct  1 09:59:43.288: INFO: Pod "downwardapi-volume-43612181-3dfc-4df5-95a0-7c65bb4c297e" satisfied condition "success or failure"
Oct  1 09:59:43.290: INFO: Trying to get logs from node ip-172-31-16-136 pod downwardapi-volume-43612181-3dfc-4df5-95a0-7c65bb4c297e container client-container: <nil>
STEP: delete the pod
Oct  1 09:59:43.307: INFO: Waiting for pod downwardapi-volume-43612181-3dfc-4df5-95a0-7c65bb4c297e to disappear
Oct  1 09:59:43.308: INFO: Pod downwardapi-volume-43612181-3dfc-4df5-95a0-7c65bb4c297e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 09:59:43.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3598" for this suite.
Oct  1 09:59:49.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 09:59:49.369: INFO: namespace downward-api-3598 deletion completed in 6.058737085s

• [SLOW TEST:8.119 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 09:59:49.369: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Oct  1 09:59:49.389: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Oct  1 09:59:49.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 create -f - --namespace=kubectl-9284'
Oct  1 09:59:50.312: INFO: stderr: ""
Oct  1 09:59:50.312: INFO: stdout: "service/redis-slave created\n"
Oct  1 09:59:50.312: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Oct  1 09:59:50.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 create -f - --namespace=kubectl-9284'
Oct  1 09:59:50.470: INFO: stderr: ""
Oct  1 09:59:50.470: INFO: stdout: "service/redis-master created\n"
Oct  1 09:59:50.471: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Oct  1 09:59:50.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 create -f - --namespace=kubectl-9284'
Oct  1 09:59:50.637: INFO: stderr: ""
Oct  1 09:59:50.637: INFO: stdout: "service/frontend created\n"
Oct  1 09:59:50.637: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Oct  1 09:59:50.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 create -f - --namespace=kubectl-9284'
Oct  1 09:59:50.794: INFO: stderr: ""
Oct  1 09:59:50.794: INFO: stdout: "deployment.apps/frontend created\n"
Oct  1 09:59:50.794: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Oct  1 09:59:50.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 create -f - --namespace=kubectl-9284'
Oct  1 09:59:50.944: INFO: stderr: ""
Oct  1 09:59:50.944: INFO: stdout: "deployment.apps/redis-master created\n"
Oct  1 09:59:50.945: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Oct  1 09:59:50.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 create -f - --namespace=kubectl-9284'
Oct  1 09:59:51.101: INFO: stderr: ""
Oct  1 09:59:51.101: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Oct  1 09:59:51.101: INFO: Waiting for all frontend pods to be Running.
I1001 09:59:51.101650      17 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 09:59:51.101676      17 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Oct  1 10:00:11.152: INFO: Waiting for frontend to serve content.
Oct  1 10:00:11.164: INFO: Trying to add a new entry to the guestbook.
Oct  1 10:00:11.176: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Oct  1 10:00:11.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 delete --grace-period=0 --force -f - --namespace=kubectl-9284'
Oct  1 10:00:11.257: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  1 10:00:11.257: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Oct  1 10:00:11.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 delete --grace-period=0 --force -f - --namespace=kubectl-9284'
Oct  1 10:00:11.342: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  1 10:00:11.343: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct  1 10:00:11.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 delete --grace-period=0 --force -f - --namespace=kubectl-9284'
Oct  1 10:00:11.416: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  1 10:00:11.416: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct  1 10:00:11.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 delete --grace-period=0 --force -f - --namespace=kubectl-9284'
Oct  1 10:00:11.486: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  1 10:00:11.486: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct  1 10:00:11.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 delete --grace-period=0 --force -f - --namespace=kubectl-9284'
Oct  1 10:00:11.551: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  1 10:00:11.551: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct  1 10:00:11.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 delete --grace-period=0 --force -f - --namespace=kubectl-9284'
Oct  1 10:00:11.620: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  1 10:00:11.620: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:00:11.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9284" for this suite.
Oct  1 10:00:23.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:00:23.680: INFO: namespace kubectl-9284 deletion completed in 12.058200384s

• [SLOW TEST:34.311 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:00:23.681: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-1f6d6f81-4268-454e-b6c5-6678c7db626d
STEP: Creating secret with name s-test-opt-upd-29972fdc-1e8c-445b-9cec-88a68fe37449
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-1f6d6f81-4268-454e-b6c5-6678c7db626d
STEP: Updating secret s-test-opt-upd-29972fdc-1e8c-445b-9cec-88a68fe37449
STEP: Creating secret with name s-test-opt-create-b96d94b8-245e-4950-8314-db882d1e71e5
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:01:33.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9823" for this suite.
Oct  1 10:01:45.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:01:45.989: INFO: namespace projected-9823 deletion completed in 12.058096743s

• [SLOW TEST:82.308 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:01:45.989: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  1 10:01:46.727: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  1 10:01:49.741: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:01:49.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5008" for this suite.
Oct  1 10:01:55.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:01:55.954: INFO: namespace webhook-5008 deletion completed in 6.057667893s
STEP: Destroying namespace "webhook-5008-markers" for this suite.
Oct  1 10:02:01.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:02:02.017: INFO: namespace webhook-5008-markers deletion completed in 6.063054823s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.037 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:02:02.026: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct  1 10:02:02.056: INFO: Waiting up to 5m0s for pod "pod-cf312107-ea7e-4a78-894b-7140d9622939" in namespace "emptydir-6214" to be "success or failure"
Oct  1 10:02:02.057: INFO: Pod "pod-cf312107-ea7e-4a78-894b-7140d9622939": Phase="Pending", Reason="", readiness=false. Elapsed: 1.625081ms
Oct  1 10:02:04.060: INFO: Pod "pod-cf312107-ea7e-4a78-894b-7140d9622939": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004607993s
Oct  1 10:02:06.063: INFO: Pod "pod-cf312107-ea7e-4a78-894b-7140d9622939": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007566482s
STEP: Saw pod success
Oct  1 10:02:06.063: INFO: Pod "pod-cf312107-ea7e-4a78-894b-7140d9622939" satisfied condition "success or failure"
Oct  1 10:02:06.065: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-cf312107-ea7e-4a78-894b-7140d9622939 container test-container: <nil>
STEP: delete the pod
Oct  1 10:02:06.080: INFO: Waiting for pod pod-cf312107-ea7e-4a78-894b-7140d9622939 to disappear
Oct  1 10:02:06.088: INFO: Pod pod-cf312107-ea7e-4a78-894b-7140d9622939 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:02:06.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6214" for this suite.
Oct  1 10:02:12.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:02:12.150: INFO: namespace emptydir-6214 deletion completed in 6.059212787s

• [SLOW TEST:10.124 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:02:12.150: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-a262ea6d-34f1-4f25-a7c1-d4607d368f81
STEP: Creating a pod to test consume secrets
Oct  1 10:02:12.178: INFO: Waiting up to 5m0s for pod "pod-secrets-49c3b580-8d9f-4008-b8e1-e11c0ee50235" in namespace "secrets-3051" to be "success or failure"
Oct  1 10:02:12.180: INFO: Pod "pod-secrets-49c3b580-8d9f-4008-b8e1-e11c0ee50235": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041616ms
Oct  1 10:02:14.184: INFO: Pod "pod-secrets-49c3b580-8d9f-4008-b8e1-e11c0ee50235": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005163844s
STEP: Saw pod success
Oct  1 10:02:14.184: INFO: Pod "pod-secrets-49c3b580-8d9f-4008-b8e1-e11c0ee50235" satisfied condition "success or failure"
Oct  1 10:02:14.185: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-secrets-49c3b580-8d9f-4008-b8e1-e11c0ee50235 container secret-volume-test: <nil>
STEP: delete the pod
Oct  1 10:02:14.198: INFO: Waiting for pod pod-secrets-49c3b580-8d9f-4008-b8e1-e11c0ee50235 to disappear
Oct  1 10:02:14.205: INFO: Pod pod-secrets-49c3b580-8d9f-4008-b8e1-e11c0ee50235 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:02:14.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3051" for this suite.
Oct  1 10:02:20.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:02:20.265: INFO: namespace secrets-3051 deletion completed in 6.057904287s

• [SLOW TEST:8.116 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:02:20.266: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:02:22.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2997" for this suite.
Oct  1 10:03:06.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:03:06.369: INFO: namespace kubelet-test-2997 deletion completed in 44.058893316s

• [SLOW TEST:46.103 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:03:06.369: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct  1 10:03:06.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-6889'
Oct  1 10:03:06.460: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct  1 10:03:06.460: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: rolling-update to same image controller
Oct  1 10:03:06.467: INFO: scanned /root for discovery docs: <nil>
Oct  1 10:03:06.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-6889'
Oct  1 10:03:22.195: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct  1 10:03:22.195: INFO: stdout: "Created e2e-test-httpd-rc-fd226e19f58416dcc596674dc5198022\nScaling up e2e-test-httpd-rc-fd226e19f58416dcc596674dc5198022 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-fd226e19f58416dcc596674dc5198022 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-fd226e19f58416dcc596674dc5198022 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Oct  1 10:03:22.195: INFO: stdout: "Created e2e-test-httpd-rc-fd226e19f58416dcc596674dc5198022\nScaling up e2e-test-httpd-rc-fd226e19f58416dcc596674dc5198022 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-fd226e19f58416dcc596674dc5198022 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-fd226e19f58416dcc596674dc5198022 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Oct  1 10:03:22.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-6889'
Oct  1 10:03:22.262: INFO: stderr: ""
Oct  1 10:03:22.262: INFO: stdout: "e2e-test-httpd-rc-fd226e19f58416dcc596674dc5198022-phd7q "
Oct  1 10:03:22.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods e2e-test-httpd-rc-fd226e19f58416dcc596674dc5198022-phd7q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6889'
Oct  1 10:03:22.329: INFO: stderr: ""
Oct  1 10:03:22.329: INFO: stdout: "true"
Oct  1 10:03:22.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods e2e-test-httpd-rc-fd226e19f58416dcc596674dc5198022-phd7q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6889'
Oct  1 10:03:22.395: INFO: stderr: ""
Oct  1 10:03:22.395: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Oct  1 10:03:22.395: INFO: e2e-test-httpd-rc-fd226e19f58416dcc596674dc5198022-phd7q is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Oct  1 10:03:22.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 delete rc e2e-test-httpd-rc --namespace=kubectl-6889'
Oct  1 10:03:22.464: INFO: stderr: ""
Oct  1 10:03:22.464: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:03:22.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6889" for this suite.
Oct  1 10:03:34.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:03:34.537: INFO: namespace kubectl-6889 deletion completed in 12.070115536s

• [SLOW TEST:28.168 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:03:34.537: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Oct  1 10:03:44.610: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1001 10:03:44.610135      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:03:44.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6612" for this suite.
Oct  1 10:03:50.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:03:50.673: INFO: namespace gc-6612 deletion completed in 6.060561337s

• [SLOW TEST:16.135 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:03:50.673: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Oct  1 10:03:52.714: INFO: &Pod{ObjectMeta:{send-events-7ab10c26-b0ee-4443-ba4c-fdc9ec1883d9  events-2700 /api/v1/namespaces/events-2700/pods/send-events-7ab10c26-b0ee-4443-ba4c-fdc9ec1883d9 d13186a2-bce6-41b2-bf06-83c8d2f69b61 10488 0 2019-10-01 10:03:50 +0000 UTC <nil> <nil> map[name:foo time:693749515] map[] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fwfdg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fwfdg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fwfdg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-16-136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:03:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:03:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:03:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:03:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.16.136,PodIP:10.1.63.105,StartTime:2019-10-01 10:03:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-01 10:03:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:containerd://68e68455ed41ec084fd5f71797319aa2ed208d24ce026072b798354b9382a9c8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.63.105,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Oct  1 10:03:54.718: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Oct  1 10:03:56.721: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:03:56.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2700" for this suite.
Oct  1 10:04:40.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:04:40.784: INFO: namespace events-2700 deletion completed in 44.056680517s

• [SLOW TEST:50.111 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:04:40.784: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4888.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4888.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4888.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4888.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4888.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4888.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4888.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4888.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4888.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4888.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4888.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4888.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4888.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 167.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.167_udp@PTR;check="$$(dig +tcp +noall +answer +search 167.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.167_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4888.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4888.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4888.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4888.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4888.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4888.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4888.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4888.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4888.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4888.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4888.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4888.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4888.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 167.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.167_udp@PTR;check="$$(dig +tcp +noall +answer +search 167.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.167_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct  1 10:04:44.840: INFO: Unable to read wheezy_udp@dns-test-service.dns-4888.svc.cluster.local from pod dns-4888/dns-test-11e88b4a-8ec7-4a2e-b24f-b651f448a157: the server could not find the requested resource (get pods dns-test-11e88b4a-8ec7-4a2e-b24f-b651f448a157)
Oct  1 10:04:44.842: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4888.svc.cluster.local from pod dns-4888/dns-test-11e88b4a-8ec7-4a2e-b24f-b651f448a157: the server could not find the requested resource (get pods dns-test-11e88b4a-8ec7-4a2e-b24f-b651f448a157)
Oct  1 10:04:44.844: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4888.svc.cluster.local from pod dns-4888/dns-test-11e88b4a-8ec7-4a2e-b24f-b651f448a157: the server could not find the requested resource (get pods dns-test-11e88b4a-8ec7-4a2e-b24f-b651f448a157)
Oct  1 10:04:44.847: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4888.svc.cluster.local from pod dns-4888/dns-test-11e88b4a-8ec7-4a2e-b24f-b651f448a157: the server could not find the requested resource (get pods dns-test-11e88b4a-8ec7-4a2e-b24f-b651f448a157)
Oct  1 10:04:44.862: INFO: Unable to read jessie_udp@dns-test-service.dns-4888.svc.cluster.local from pod dns-4888/dns-test-11e88b4a-8ec7-4a2e-b24f-b651f448a157: the server could not find the requested resource (get pods dns-test-11e88b4a-8ec7-4a2e-b24f-b651f448a157)
Oct  1 10:04:44.864: INFO: Unable to read jessie_tcp@dns-test-service.dns-4888.svc.cluster.local from pod dns-4888/dns-test-11e88b4a-8ec7-4a2e-b24f-b651f448a157: the server could not find the requested resource (get pods dns-test-11e88b4a-8ec7-4a2e-b24f-b651f448a157)
Oct  1 10:04:44.866: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4888.svc.cluster.local from pod dns-4888/dns-test-11e88b4a-8ec7-4a2e-b24f-b651f448a157: the server could not find the requested resource (get pods dns-test-11e88b4a-8ec7-4a2e-b24f-b651f448a157)
Oct  1 10:04:44.868: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4888.svc.cluster.local from pod dns-4888/dns-test-11e88b4a-8ec7-4a2e-b24f-b651f448a157: the server could not find the requested resource (get pods dns-test-11e88b4a-8ec7-4a2e-b24f-b651f448a157)
Oct  1 10:04:44.880: INFO: Lookups using dns-4888/dns-test-11e88b4a-8ec7-4a2e-b24f-b651f448a157 failed for: [wheezy_udp@dns-test-service.dns-4888.svc.cluster.local wheezy_tcp@dns-test-service.dns-4888.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4888.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4888.svc.cluster.local jessie_udp@dns-test-service.dns-4888.svc.cluster.local jessie_tcp@dns-test-service.dns-4888.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4888.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4888.svc.cluster.local]

Oct  1 10:04:49.924: INFO: DNS probes using dns-4888/dns-test-11e88b4a-8ec7-4a2e-b24f-b651f448a157 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:04:49.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4888" for this suite.
Oct  1 10:04:55.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:04:56.051: INFO: namespace dns-4888 deletion completed in 6.059248993s

• [SLOW TEST:15.267 seconds]
[sig-network] DNS
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:04:56.051: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-272e4cbc-de5f-4647-8762-c4282d5811e6
STEP: Creating a pod to test consume configMaps
Oct  1 10:04:56.083: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7d421ae7-217f-4688-ab47-063c62d5320b" in namespace "projected-4931" to be "success or failure"
Oct  1 10:04:56.087: INFO: Pod "pod-projected-configmaps-7d421ae7-217f-4688-ab47-063c62d5320b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017825ms
Oct  1 10:04:58.090: INFO: Pod "pod-projected-configmaps-7d421ae7-217f-4688-ab47-063c62d5320b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007100706s
STEP: Saw pod success
Oct  1 10:04:58.090: INFO: Pod "pod-projected-configmaps-7d421ae7-217f-4688-ab47-063c62d5320b" satisfied condition "success or failure"
Oct  1 10:04:58.092: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-projected-configmaps-7d421ae7-217f-4688-ab47-063c62d5320b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 10:04:58.111: INFO: Waiting for pod pod-projected-configmaps-7d421ae7-217f-4688-ab47-063c62d5320b to disappear
Oct  1 10:04:58.119: INFO: Pod pod-projected-configmaps-7d421ae7-217f-4688-ab47-063c62d5320b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:04:58.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4931" for this suite.
Oct  1 10:05:04.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:05:04.182: INFO: namespace projected-4931 deletion completed in 6.060750895s

• [SLOW TEST:8.131 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:05:04.183: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Oct  1 10:05:04.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 create -f - --namespace=kubectl-5442'
Oct  1 10:05:04.362: INFO: stderr: ""
Oct  1 10:05:04.362: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  1 10:05:04.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5442'
Oct  1 10:05:04.430: INFO: stderr: ""
Oct  1 10:05:04.430: INFO: stdout: "update-demo-nautilus-4rtwp update-demo-nautilus-kl2mj "
Oct  1 10:05:04.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-nautilus-4rtwp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5442'
Oct  1 10:05:04.495: INFO: stderr: ""
Oct  1 10:05:04.495: INFO: stdout: ""
Oct  1 10:05:04.495: INFO: update-demo-nautilus-4rtwp is created but not running
Oct  1 10:05:09.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5442'
Oct  1 10:05:09.561: INFO: stderr: ""
Oct  1 10:05:09.561: INFO: stdout: "update-demo-nautilus-4rtwp update-demo-nautilus-kl2mj "
Oct  1 10:05:09.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-nautilus-4rtwp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5442'
Oct  1 10:05:09.624: INFO: stderr: ""
Oct  1 10:05:09.624: INFO: stdout: "true"
Oct  1 10:05:09.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-nautilus-4rtwp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5442'
Oct  1 10:05:09.689: INFO: stderr: ""
Oct  1 10:05:09.689: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  1 10:05:09.689: INFO: validating pod update-demo-nautilus-4rtwp
Oct  1 10:05:09.692: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  1 10:05:09.692: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  1 10:05:09.692: INFO: update-demo-nautilus-4rtwp is verified up and running
Oct  1 10:05:09.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-nautilus-kl2mj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5442'
Oct  1 10:05:09.757: INFO: stderr: ""
Oct  1 10:05:09.757: INFO: stdout: "true"
Oct  1 10:05:09.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-nautilus-kl2mj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5442'
Oct  1 10:05:09.821: INFO: stderr: ""
Oct  1 10:05:09.821: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  1 10:05:09.821: INFO: validating pod update-demo-nautilus-kl2mj
Oct  1 10:05:09.824: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  1 10:05:09.824: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  1 10:05:09.824: INFO: update-demo-nautilus-kl2mj is verified up and running
STEP: rolling-update to new replication controller
Oct  1 10:05:09.826: INFO: scanned /root for discovery docs: <nil>
Oct  1 10:05:09.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-5442'
Oct  1 10:05:32.130: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct  1 10:05:32.131: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  1 10:05:32.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5442'
Oct  1 10:05:32.198: INFO: stderr: ""
Oct  1 10:05:32.198: INFO: stdout: "update-demo-kitten-dj5b2 update-demo-kitten-nncbb "
Oct  1 10:05:32.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-kitten-dj5b2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5442'
Oct  1 10:05:32.263: INFO: stderr: ""
Oct  1 10:05:32.263: INFO: stdout: "true"
Oct  1 10:05:32.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-kitten-dj5b2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5442'
Oct  1 10:05:32.328: INFO: stderr: ""
Oct  1 10:05:32.328: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct  1 10:05:32.328: INFO: validating pod update-demo-kitten-dj5b2
Oct  1 10:05:32.331: INFO: got data: {
  "image": "kitten.jpg"
}

Oct  1 10:05:32.331: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct  1 10:05:32.331: INFO: update-demo-kitten-dj5b2 is verified up and running
Oct  1 10:05:32.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-kitten-nncbb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5442'
Oct  1 10:05:32.395: INFO: stderr: ""
Oct  1 10:05:32.395: INFO: stdout: "true"
Oct  1 10:05:32.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-kitten-nncbb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5442'
Oct  1 10:05:32.461: INFO: stderr: ""
Oct  1 10:05:32.461: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct  1 10:05:32.461: INFO: validating pod update-demo-kitten-nncbb
Oct  1 10:05:32.465: INFO: got data: {
  "image": "kitten.jpg"
}

Oct  1 10:05:32.465: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct  1 10:05:32.465: INFO: update-demo-kitten-nncbb is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:05:32.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5442" for this suite.
Oct  1 10:05:44.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:05:44.530: INFO: namespace kubectl-5442 deletion completed in 12.062597384s

• [SLOW TEST:40.347 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:05:44.530: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  1 10:05:44.553: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8ded9976-d67f-46bb-8b0d-9932cccbdb3b" in namespace "projected-6867" to be "success or failure"
Oct  1 10:05:44.556: INFO: Pod "downwardapi-volume-8ded9976-d67f-46bb-8b0d-9932cccbdb3b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.331612ms
Oct  1 10:05:46.559: INFO: Pod "downwardapi-volume-8ded9976-d67f-46bb-8b0d-9932cccbdb3b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005343513s
Oct  1 10:05:48.562: INFO: Pod "downwardapi-volume-8ded9976-d67f-46bb-8b0d-9932cccbdb3b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008382368s
STEP: Saw pod success
Oct  1 10:05:48.562: INFO: Pod "downwardapi-volume-8ded9976-d67f-46bb-8b0d-9932cccbdb3b" satisfied condition "success or failure"
Oct  1 10:05:48.564: INFO: Trying to get logs from node ip-172-31-16-136 pod downwardapi-volume-8ded9976-d67f-46bb-8b0d-9932cccbdb3b container client-container: <nil>
STEP: delete the pod
Oct  1 10:05:48.573: INFO: Waiting for pod downwardapi-volume-8ded9976-d67f-46bb-8b0d-9932cccbdb3b to disappear
Oct  1 10:05:48.575: INFO: Pod downwardapi-volume-8ded9976-d67f-46bb-8b0d-9932cccbdb3b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:05:48.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6867" for this suite.
Oct  1 10:05:54.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:05:54.636: INFO: namespace projected-6867 deletion completed in 6.05891736s

• [SLOW TEST:10.106 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:05:54.637: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  1 10:05:55.170: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  1 10:05:58.181: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:05:58.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6131" for this suite.
Oct  1 10:06:10.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:06:10.300: INFO: namespace webhook-6131 deletion completed in 12.069634337s
STEP: Destroying namespace "webhook-6131-markers" for this suite.
Oct  1 10:06:16.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:06:16.357: INFO: namespace webhook-6131-markers deletion completed in 6.057451329s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.728 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:06:16.365: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:06:16.396: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:06:18.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4293" for this suite.
Oct  1 10:07:02.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:07:02.604: INFO: namespace pods-4293 deletion completed in 44.059022502s

• [SLOW TEST:46.239 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:07:02.604: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:07:18.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2017" for this suite.
Oct  1 10:07:24.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:07:24.727: INFO: namespace resourcequota-2017 deletion completed in 6.060478431s

• [SLOW TEST:22.123 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:07:24.728: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Oct  1 10:07:25.265: INFO: created pod pod-service-account-defaultsa
Oct  1 10:07:25.265: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Oct  1 10:07:25.269: INFO: created pod pod-service-account-mountsa
Oct  1 10:07:25.269: INFO: pod pod-service-account-mountsa service account token volume mount: true
Oct  1 10:07:25.278: INFO: created pod pod-service-account-nomountsa
Oct  1 10:07:25.278: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Oct  1 10:07:25.282: INFO: created pod pod-service-account-defaultsa-mountspec
Oct  1 10:07:25.282: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Oct  1 10:07:25.293: INFO: created pod pod-service-account-mountsa-mountspec
Oct  1 10:07:25.293: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Oct  1 10:07:25.296: INFO: created pod pod-service-account-nomountsa-mountspec
Oct  1 10:07:25.296: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Oct  1 10:07:25.305: INFO: created pod pod-service-account-defaultsa-nomountspec
Oct  1 10:07:25.305: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Oct  1 10:07:25.320: INFO: created pod pod-service-account-mountsa-nomountspec
Oct  1 10:07:25.320: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Oct  1 10:07:25.333: INFO: created pod pod-service-account-nomountsa-nomountspec
Oct  1 10:07:25.333: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:07:25.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9318" for this suite.
Oct  1 10:07:31.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:07:31.435: INFO: namespace svcaccounts-9318 deletion completed in 6.083441323s

• [SLOW TEST:6.708 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:07:31.435: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:07:31.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9116" for this suite.
Oct  1 10:07:37.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:07:37.537: INFO: namespace resourcequota-9116 deletion completed in 6.060704563s

• [SLOW TEST:6.102 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:07:37.538: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-ec940eee-84dc-464c-b7e1-ea23f3f7f01d
STEP: Creating configMap with name cm-test-opt-upd-ef306d93-7f25-4594-a6f7-763f7d88b706
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-ec940eee-84dc-464c-b7e1-ea23f3f7f01d
STEP: Updating configmap cm-test-opt-upd-ef306d93-7f25-4594-a6f7-763f7d88b706
STEP: Creating configMap with name cm-test-opt-create-236980a2-32b7-4b85-bc5b-af4ea2307d17
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:08:57.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1226" for this suite.
Oct  1 10:09:09.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:09:09.875: INFO: namespace projected-1226 deletion completed in 12.057997697s

• [SLOW TEST:92.337 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:09:09.875: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-ad1087fc-8a33-4497-a72e-4e781da8dfca
STEP: Creating a pod to test consume configMaps
Oct  1 10:09:09.916: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d296164f-631d-40e1-a239-2d968d3d9dd2" in namespace "projected-3168" to be "success or failure"
Oct  1 10:09:09.918: INFO: Pod "pod-projected-configmaps-d296164f-631d-40e1-a239-2d968d3d9dd2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.230693ms
Oct  1 10:09:11.921: INFO: Pod "pod-projected-configmaps-d296164f-631d-40e1-a239-2d968d3d9dd2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005163984s
STEP: Saw pod success
Oct  1 10:09:11.921: INFO: Pod "pod-projected-configmaps-d296164f-631d-40e1-a239-2d968d3d9dd2" satisfied condition "success or failure"
Oct  1 10:09:11.923: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-projected-configmaps-d296164f-631d-40e1-a239-2d968d3d9dd2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 10:09:11.935: INFO: Waiting for pod pod-projected-configmaps-d296164f-631d-40e1-a239-2d968d3d9dd2 to disappear
Oct  1 10:09:11.938: INFO: Pod pod-projected-configmaps-d296164f-631d-40e1-a239-2d968d3d9dd2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:09:11.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3168" for this suite.
Oct  1 10:09:17.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:09:17.999: INFO: namespace projected-3168 deletion completed in 6.058380101s

• [SLOW TEST:8.124 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:09:17.999: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Oct  1 10:09:20.537: INFO: Successfully updated pod "adopt-release-577sz"
STEP: Checking that the Job readopts the Pod
Oct  1 10:09:20.537: INFO: Waiting up to 15m0s for pod "adopt-release-577sz" in namespace "job-6446" to be "adopted"
Oct  1 10:09:20.539: INFO: Pod "adopt-release-577sz": Phase="Running", Reason="", readiness=true. Elapsed: 2.165867ms
Oct  1 10:09:22.542: INFO: Pod "adopt-release-577sz": Phase="Running", Reason="", readiness=true. Elapsed: 2.005083252s
Oct  1 10:09:22.542: INFO: Pod "adopt-release-577sz" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Oct  1 10:09:23.048: INFO: Successfully updated pod "adopt-release-577sz"
STEP: Checking that the Job releases the Pod
Oct  1 10:09:23.048: INFO: Waiting up to 15m0s for pod "adopt-release-577sz" in namespace "job-6446" to be "released"
Oct  1 10:09:23.050: INFO: Pod "adopt-release-577sz": Phase="Running", Reason="", readiness=true. Elapsed: 1.815473ms
Oct  1 10:09:25.053: INFO: Pod "adopt-release-577sz": Phase="Running", Reason="", readiness=true. Elapsed: 2.004846487s
Oct  1 10:09:25.053: INFO: Pod "adopt-release-577sz" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:09:25.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6446" for this suite.
Oct  1 10:10:15.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:10:15.116: INFO: namespace job-6446 deletion completed in 50.06052667s

• [SLOW TEST:57.117 seconds]
[sig-apps] Job
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:10:15.116: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-ca747364-ab4e-47d7-b758-50f1ff21ca0a
STEP: Creating a pod to test consume secrets
Oct  1 10:10:15.148: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-813f9b8f-532a-4056-82cc-3363dfc7189d" in namespace "projected-7064" to be "success or failure"
Oct  1 10:10:15.151: INFO: Pod "pod-projected-secrets-813f9b8f-532a-4056-82cc-3363dfc7189d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.403332ms
Oct  1 10:10:17.154: INFO: Pod "pod-projected-secrets-813f9b8f-532a-4056-82cc-3363dfc7189d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006633131s
STEP: Saw pod success
Oct  1 10:10:17.154: INFO: Pod "pod-projected-secrets-813f9b8f-532a-4056-82cc-3363dfc7189d" satisfied condition "success or failure"
Oct  1 10:10:17.156: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-projected-secrets-813f9b8f-532a-4056-82cc-3363dfc7189d container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct  1 10:10:17.166: INFO: Waiting for pod pod-projected-secrets-813f9b8f-532a-4056-82cc-3363dfc7189d to disappear
Oct  1 10:10:17.169: INFO: Pod pod-projected-secrets-813f9b8f-532a-4056-82cc-3363dfc7189d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:10:17.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7064" for this suite.
Oct  1 10:10:23.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:10:23.235: INFO: namespace projected-7064 deletion completed in 6.063790649s

• [SLOW TEST:8.119 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:10:23.235: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  1 10:10:23.264: INFO: Waiting up to 5m0s for pod "downwardapi-volume-00afd75b-29aa-42f6-acda-f1101c3256f1" in namespace "downward-api-8150" to be "success or failure"
Oct  1 10:10:23.270: INFO: Pod "downwardapi-volume-00afd75b-29aa-42f6-acda-f1101c3256f1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.101624ms
Oct  1 10:10:25.273: INFO: Pod "downwardapi-volume-00afd75b-29aa-42f6-acda-f1101c3256f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008248169s
STEP: Saw pod success
Oct  1 10:10:25.273: INFO: Pod "downwardapi-volume-00afd75b-29aa-42f6-acda-f1101c3256f1" satisfied condition "success or failure"
Oct  1 10:10:25.275: INFO: Trying to get logs from node ip-172-31-16-136 pod downwardapi-volume-00afd75b-29aa-42f6-acda-f1101c3256f1 container client-container: <nil>
STEP: delete the pod
Oct  1 10:10:25.288: INFO: Waiting for pod downwardapi-volume-00afd75b-29aa-42f6-acda-f1101c3256f1 to disappear
Oct  1 10:10:25.295: INFO: Pod downwardapi-volume-00afd75b-29aa-42f6-acda-f1101c3256f1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:10:25.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8150" for this suite.
Oct  1 10:10:31.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:10:31.356: INFO: namespace downward-api-8150 deletion completed in 6.058733555s

• [SLOW TEST:8.120 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:10:31.356: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct  1 10:10:31.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-540'
Oct  1 10:10:32.189: INFO: stderr: ""
Oct  1 10:10:32.189: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Oct  1 10:10:32.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 delete pods e2e-test-httpd-pod --namespace=kubectl-540'
Oct  1 10:10:38.984: INFO: stderr: ""
Oct  1 10:10:38.984: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:10:38.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-540" for this suite.
Oct  1 10:10:45.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:10:45.050: INFO: namespace kubectl-540 deletion completed in 6.05670106s

• [SLOW TEST:13.694 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:10:45.050: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  1 10:10:45.076: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b656813d-1104-42b1-be7a-5a907a40aeb2" in namespace "downward-api-7424" to be "success or failure"
Oct  1 10:10:45.079: INFO: Pod "downwardapi-volume-b656813d-1104-42b1-be7a-5a907a40aeb2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.392243ms
Oct  1 10:10:47.082: INFO: Pod "downwardapi-volume-b656813d-1104-42b1-be7a-5a907a40aeb2": Phase="Running", Reason="", readiness=true. Elapsed: 2.005623275s
Oct  1 10:10:49.085: INFO: Pod "downwardapi-volume-b656813d-1104-42b1-be7a-5a907a40aeb2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008743608s
STEP: Saw pod success
Oct  1 10:10:49.085: INFO: Pod "downwardapi-volume-b656813d-1104-42b1-be7a-5a907a40aeb2" satisfied condition "success or failure"
Oct  1 10:10:49.087: INFO: Trying to get logs from node ip-172-31-16-136 pod downwardapi-volume-b656813d-1104-42b1-be7a-5a907a40aeb2 container client-container: <nil>
STEP: delete the pod
Oct  1 10:10:49.098: INFO: Waiting for pod downwardapi-volume-b656813d-1104-42b1-be7a-5a907a40aeb2 to disappear
Oct  1 10:10:49.106: INFO: Pod downwardapi-volume-b656813d-1104-42b1-be7a-5a907a40aeb2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:10:49.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7424" for this suite.
Oct  1 10:10:55.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:10:55.165: INFO: namespace downward-api-7424 deletion completed in 6.057220903s

• [SLOW TEST:10.115 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:10:55.165: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-1711
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct  1 10:10:55.189: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct  1 10:11:15.237: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.63.129:8080/dial?request=hostName&protocol=udp&host=10.1.2.37&port=8081&tries=1'] Namespace:pod-network-test-1711 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 10:11:15.237: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 10:11:15.371: INFO: Waiting for endpoints: map[]
Oct  1 10:11:15.374: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.63.129:8080/dial?request=hostName&protocol=udp&host=10.1.63.128&port=8081&tries=1'] Namespace:pod-network-test-1711 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 10:11:15.374: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 10:11:15.501: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:11:15.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1711" for this suite.
Oct  1 10:11:27.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:11:27.569: INFO: namespace pod-network-test-1711 deletion completed in 12.064896598s

• [SLOW TEST:32.404 seconds]
[sig-network] Networking
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:11:27.569: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:11:27.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 create -f - --namespace=kubectl-3098'
Oct  1 10:11:27.741: INFO: stderr: ""
Oct  1 10:11:27.741: INFO: stdout: "replicationcontroller/redis-master created\n"
Oct  1 10:11:27.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 create -f - --namespace=kubectl-3098'
Oct  1 10:11:27.893: INFO: stderr: ""
Oct  1 10:11:27.893: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct  1 10:11:28.897: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 10:11:28.897: INFO: Found 0 / 1
Oct  1 10:11:29.896: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 10:11:29.896: INFO: Found 1 / 1
Oct  1 10:11:29.896: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct  1 10:11:29.898: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 10:11:29.898: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct  1 10:11:29.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 describe pod redis-master-6jr62 --namespace=kubectl-3098'
Oct  1 10:11:29.974: INFO: stderr: ""
Oct  1 10:11:29.974: INFO: stdout: "Name:         redis-master-6jr62\nNamespace:    kubectl-3098\nPriority:     0\nNode:         ip-172-31-16-136/172.31.16.136\nStart Time:   Tue, 01 Oct 2019 10:11:27 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nStatus:       Running\nIP:           10.1.63.130\nIPs:\n  IP:           10.1.63.130\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://a6f5b54cb33e0ec11da70509060bad40d5d82cf894ab1351a3663e685dfc2885\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 01 Oct 2019 10:11:28 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-cvp9b (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-cvp9b:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-cvp9b\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                       Message\n  ----    ------     ----       ----                       -------\n  Normal  Scheduled  <unknown>  default-scheduler          Successfully assigned kubectl-3098/redis-master-6jr62 to ip-172-31-16-136\n  Normal  Pulled     1s         kubelet, ip-172-31-16-136  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    1s         kubelet, ip-172-31-16-136  Created container redis-master\n  Normal  Started    1s         kubelet, ip-172-31-16-136  Started container redis-master\n"
Oct  1 10:11:29.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 describe rc redis-master --namespace=kubectl-3098'
Oct  1 10:11:30.056: INFO: stderr: ""
Oct  1 10:11:30.056: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-3098\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-6jr62\n"
Oct  1 10:11:30.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 describe service redis-master --namespace=kubectl-3098'
Oct  1 10:11:30.129: INFO: stderr: ""
Oct  1 10:11:30.129: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-3098\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.152.183.111\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.1.63.130:6379\nSession Affinity:  None\nEvents:            <none>\n"
Oct  1 10:11:30.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 describe node ip-172-31-16-136'
Oct  1 10:11:30.214: INFO: stderr: ""
Oct  1 10:11:30.215: INFO: stdout: "Name:               ip-172-31-16-136\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-16-136\n                    kubernetes.io/os=linux\n                    microk8s.io/cluster=true\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 01 Oct 2019 09:01:57 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Tue, 01 Oct 2019 10:11:20 +0000   Tue, 01 Oct 2019 09:01:55 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 01 Oct 2019 10:11:20 +0000   Tue, 01 Oct 2019 09:01:55 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 01 Oct 2019 10:11:20 +0000   Tue, 01 Oct 2019 09:01:55 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 01 Oct 2019 10:11:20 +0000   Tue, 01 Oct 2019 09:01:57 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.16.136\n  Hostname:    ip-172-31-16-136\nCapacity:\n cpu:                4\n ephemeral-storage:  81253764Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16424480Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  80205188Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16322080Ki\n pods:               110\nSystem Info:\n Machine ID:                 d8ed78a186154c2d8a4acdf5aa23d9a3\n System UUID:                EC256EC5-51EB-B52D-2D17-8B311E16FA97\n Boot ID:                    dc9129bf-ed96-4aa9-90ce-d0fe3ca11023\n Kernel Version:             4.15.0-1044-aws\n OS Image:                   Ubuntu 18.04.2 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.2.5\n Kubelet Version:            v1.16.0\n Kube-Proxy Version:         v1.16.0\nNon-terminated Pods:         (3 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kubectl-3098               redis-master-6jr62                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  sonobuoy                   sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         50m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-c998de73b1b44522-6mdfj    0 (0%)        0 (0%)      0 (0%)           0 (0%)         50m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests  Limits\n  --------           --------  ------\n  cpu                0 (0%)    0 (0%)\n  memory             0 (0%)    0 (0%)\n  ephemeral-storage  0 (0%)    0 (0%)\nEvents:\n  Type     Reason                   Age                From                          Message\n  ----     ------                   ----               ----                          -------\n  Normal   Starting                 69m                kube-proxy, ip-172-31-16-136  Starting kube-proxy.\n  Normal   NodeHasSufficientPID     69m (x2 over 69m)  kubelet, ip-172-31-16-136     Node ip-172-31-16-136 status is now: NodeHasSufficientPID\n  Normal   Starting                 69m                kubelet, ip-172-31-16-136     Starting kubelet.\n  Warning  InvalidDiskCapacity      69m                kubelet, ip-172-31-16-136     invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  69m (x2 over 69m)  kubelet, ip-172-31-16-136     Node ip-172-31-16-136 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    69m (x2 over 69m)  kubelet, ip-172-31-16-136     Node ip-172-31-16-136 status is now: NodeHasNoDiskPressure\n  Normal   NodeAllocatableEnforced  69m                kubelet, ip-172-31-16-136     Updated Node Allocatable limit across pods\n  Normal   Starting                 69m                kube-proxy, ip-172-31-16-136  Starting kube-proxy.\n  Normal   NodeAllocatableEnforced  66m                kubelet, ip-172-31-16-136     Updated Node Allocatable limit across pods\n  Warning  InvalidDiskCapacity      66m                kubelet, ip-172-31-16-136     invalid capacity 0 on image filesystem\n  Normal   Starting                 66m                kubelet, ip-172-31-16-136     Starting kubelet.\n  Normal   NodeHasNoDiskPressure    66m (x2 over 66m)  kubelet, ip-172-31-16-136     Node ip-172-31-16-136 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     66m (x2 over 66m)  kubelet, ip-172-31-16-136     Node ip-172-31-16-136 status is now: NodeHasSufficientPID\n  Normal   NodeHasSufficientMemory  66m (x2 over 66m)  kubelet, ip-172-31-16-136     Node ip-172-31-16-136 status is now: NodeHasSufficientMemory\n  Normal   Starting                 66m                kube-proxy, ip-172-31-16-136  Starting kube-proxy.\n  Normal   Starting                 64m                kubelet, ip-172-31-16-136     Starting kubelet.\n  Warning  InvalidDiskCapacity      64m                kubelet, ip-172-31-16-136     invalid capacity 0 on image filesystem\n  Normal   NodeAllocatableEnforced  64m                kubelet, ip-172-31-16-136     Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientMemory  64m                kubelet, ip-172-31-16-136     Node ip-172-31-16-136 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    64m                kubelet, ip-172-31-16-136     Node ip-172-31-16-136 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     64m                kubelet, ip-172-31-16-136     Node ip-172-31-16-136 status is now: NodeHasSufficientPID\n  Warning  InvalidDiskCapacity      63m                kubelet, ip-172-31-16-136     invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  63m (x2 over 63m)  kubelet, ip-172-31-16-136     Node ip-172-31-16-136 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    63m (x2 over 63m)  kubelet, ip-172-31-16-136     Node ip-172-31-16-136 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     63m (x2 over 63m)  kubelet, ip-172-31-16-136     Node ip-172-31-16-136 status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced  63m                kubelet, ip-172-31-16-136     Updated Node Allocatable limit across pods\n  Normal   Starting                 63m                kubelet, ip-172-31-16-136     Starting kubelet.\n  Normal   Starting                 63m                kube-proxy, ip-172-31-16-136  Starting kube-proxy.\n  Normal   NodeAllocatableEnforced  55m                kubelet, ip-172-31-16-136     Updated Node Allocatable limit across pods\n  Normal   Starting                 55m                kubelet, ip-172-31-16-136     Starting kubelet.\n  Warning  InvalidDiskCapacity      55m                kubelet, ip-172-31-16-136     invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  55m (x2 over 55m)  kubelet, ip-172-31-16-136     Node ip-172-31-16-136 status is now: NodeHasSufficientMemory\n  Normal   NodeHasSufficientPID     55m (x2 over 55m)  kubelet, ip-172-31-16-136     Node ip-172-31-16-136 status is now: NodeHasSufficientPID\n  Normal   NodeHasNoDiskPressure    55m (x2 over 55m)  kubelet, ip-172-31-16-136     Node ip-172-31-16-136 status is now: NodeHasNoDiskPressure\n  Normal   Starting                 55m                kube-proxy, ip-172-31-16-136  Starting kube-proxy.\n  Normal   Starting                 51m                kubelet, ip-172-31-16-136     Starting kubelet.\n  Normal   NodeHasSufficientPID     51m                kubelet, ip-172-31-16-136     Node ip-172-31-16-136 status is now: NodeHasSufficientPID\n  Warning  InvalidDiskCapacity      51m                kubelet, ip-172-31-16-136     invalid capacity 0 on image filesystem\n  Normal   NodeAllocatableEnforced  51m                kubelet, ip-172-31-16-136     Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientMemory  51m                kubelet, ip-172-31-16-136     Node ip-172-31-16-136 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    51m                kubelet, ip-172-31-16-136     Node ip-172-31-16-136 status is now: NodeHasNoDiskPressure\n"
Oct  1 10:11:30.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 describe namespace kubectl-3098'
Oct  1 10:11:30.288: INFO: stderr: ""
Oct  1 10:11:30.288: INFO: stdout: "Name:         kubectl-3098\nLabels:       e2e-framework=kubectl\n              e2e-run=0840d0fe-da9e-4ecf-b72d-312e1c590bed\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:11:30.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3098" for this suite.
Oct  1 10:11:42.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:11:42.357: INFO: namespace kubectl-3098 deletion completed in 12.065343829s

• [SLOW TEST:14.788 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:11:42.357: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct  1 10:11:42.401: INFO: Number of nodes with available pods: 0
Oct  1 10:11:42.401: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:11:43.407: INFO: Number of nodes with available pods: 0
Oct  1 10:11:43.407: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:11:44.406: INFO: Number of nodes with available pods: 2
Oct  1 10:11:44.406: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Oct  1 10:11:44.417: INFO: Number of nodes with available pods: 1
Oct  1 10:11:44.417: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:11:45.422: INFO: Number of nodes with available pods: 1
Oct  1 10:11:45.422: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:11:46.422: INFO: Number of nodes with available pods: 1
Oct  1 10:11:46.422: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:11:47.422: INFO: Number of nodes with available pods: 1
Oct  1 10:11:47.422: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:11:48.422: INFO: Number of nodes with available pods: 1
Oct  1 10:11:48.422: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:11:49.422: INFO: Number of nodes with available pods: 2
Oct  1 10:11:49.422: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8399, will wait for the garbage collector to delete the pods
I1001 10:11:49.426220      17 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 10:11:49.426246      17 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Oct  1 10:11:49.480: INFO: Deleting DaemonSet.extensions daemon-set took: 4.0209ms
Oct  1 10:11:49.780: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.326113ms
I1001 10:11:49.780720      17 controller_utils.go:810] Ignoring inactive pod daemonsets-8399/daemon-set-hh7rq in state Running, deletion time 2019-10-01 10:12:19 +0000 UTC
I1001 10:11:49.780757      17 controller_utils.go:810] Ignoring inactive pod daemonsets-8399/daemon-set-hpx2g in state Running, deletion time 2019-10-01 10:12:19 +0000 UTC
Oct  1 10:11:59.083: INFO: Number of nodes with available pods: 0
Oct  1 10:11:59.083: INFO: Number of running nodes: 0, number of available pods: 0
Oct  1 10:11:59.086: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8399/daemonsets","resourceVersion":"12040"},"items":null}

Oct  1 10:11:59.088: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8399/pods","resourceVersion":"12040"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:11:59.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8399" for this suite.
Oct  1 10:12:05.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:12:05.160: INFO: namespace daemonsets-8399 deletion completed in 6.064334632s

• [SLOW TEST:22.803 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:12:05.160: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Oct  1 10:12:06.217: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:12:06.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1001 10:12:06.217256      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-4761" for this suite.
Oct  1 10:12:12.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:12:12.280: INFO: namespace gc-4761 deletion completed in 6.060793523s

• [SLOW TEST:7.120 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:12:12.280: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-4179
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-4179
STEP: Creating statefulset with conflicting port in namespace statefulset-4179
STEP: Waiting until pod test-pod will start running in namespace statefulset-4179
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-4179
Oct  1 10:12:14.342: INFO: Observed stateful pod in namespace: statefulset-4179, name: ss-0, uid: 5279ad3a-45b9-4da9-abdc-11e1832b68d7, status phase: Pending. Waiting for statefulset controller to delete.
Oct  1 10:12:18.984: INFO: Observed stateful pod in namespace: statefulset-4179, name: ss-0, uid: 5279ad3a-45b9-4da9-abdc-11e1832b68d7, status phase: Failed. Waiting for statefulset controller to delete.
Oct  1 10:12:18.988: INFO: Observed stateful pod in namespace: statefulset-4179, name: ss-0, uid: 5279ad3a-45b9-4da9-abdc-11e1832b68d7, status phase: Failed. Waiting for statefulset controller to delete.
Oct  1 10:12:18.997: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-4179
STEP: Removing pod with conflicting port in namespace statefulset-4179
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-4179 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct  1 10:12:21.029: INFO: Deleting all statefulset in ns statefulset-4179
Oct  1 10:12:21.031: INFO: Scaling statefulset ss to 0
Oct  1 10:12:31.041: INFO: Waiting for statefulset status.replicas updated to 0
Oct  1 10:12:31.043: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:12:31.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4179" for this suite.
Oct  1 10:12:37.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:12:37.111: INFO: namespace statefulset-4179 deletion completed in 6.057343726s

• [SLOW TEST:24.831 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:12:37.111: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Oct  1 10:12:37.132: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 10:12:39.051: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:12:50.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5474" for this suite.
Oct  1 10:12:56.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:12:56.670: INFO: namespace crd-publish-openapi-5474 deletion completed in 6.057648565s

• [SLOW TEST:19.558 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:12:56.670: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-8488
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-8488
STEP: creating replication controller externalsvc in namespace services-8488
I1001 10:12:56.715869      17 runners.go:184] Created replication controller with name: externalsvc, namespace: services-8488, replica count: 2
I1001 10:12:56.715979      17 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 10:12:56.716001      17 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 10:12:59.766334      17 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Oct  1 10:12:59.785: INFO: Creating new exec pod
Oct  1 10:13:01.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=services-8488 execpodd2nsx -- /bin/sh -x -c nslookup nodeport-service'
Oct  1 10:13:02.002: INFO: stderr: "+ nslookup nodeport-service\n"
Oct  1 10:13:02.002: INFO: stdout: "Server:\t\t10.152.183.10\nAddress:\t10.152.183.10#53\n\nnodeport-service.services-8488.svc.cluster.local\tcanonical name = externalsvc.services-8488.svc.cluster.local.\nName:\texternalsvc.services-8488.svc.cluster.local\nAddress: 10.152.183.12\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8488, will wait for the garbage collector to delete the pods
I1001 10:13:02.005190      17 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 10:13:02.005218      17 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Oct  1 10:13:02.059: INFO: Deleting ReplicationController externalsvc took: 4.393573ms
Oct  1 10:13:02.360: INFO: Terminating ReplicationController externalsvc pods took: 300.369004ms
I1001 10:13:02.360111      17 controller_utils.go:810] Ignoring inactive pod services-8488/externalsvc-r2nq8 in state Running, deletion time 2019-10-01 10:13:03 +0000 UTC
I1001 10:13:02.360155      17 controller_utils.go:810] Ignoring inactive pod services-8488/externalsvc-tg55g in state Running, deletion time 2019-10-01 10:13:03 +0000 UTC
Oct  1 10:13:09.069: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:13:09.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8488" for this suite.
Oct  1 10:13:15.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:13:15.134: INFO: namespace services-8488 deletion completed in 6.057842849s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:18.464 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:13:15.135: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-a99f3f4a-62c4-43cc-ac77-6b9db7886b09 in namespace container-probe-4338
Oct  1 10:13:17.169: INFO: Started pod liveness-a99f3f4a-62c4-43cc-ac77-6b9db7886b09 in namespace container-probe-4338
STEP: checking the pod's current state and verifying that restartCount is present
Oct  1 10:13:17.176: INFO: Initial restart count of pod liveness-a99f3f4a-62c4-43cc-ac77-6b9db7886b09 is 0
Oct  1 10:13:35.205: INFO: Restart count of pod container-probe-4338/liveness-a99f3f4a-62c4-43cc-ac77-6b9db7886b09 is now 1 (18.028651582s elapsed)
Oct  1 10:13:55.235: INFO: Restart count of pod container-probe-4338/liveness-a99f3f4a-62c4-43cc-ac77-6b9db7886b09 is now 2 (38.059266101s elapsed)
Oct  1 10:14:15.266: INFO: Restart count of pod container-probe-4338/liveness-a99f3f4a-62c4-43cc-ac77-6b9db7886b09 is now 3 (58.089475027s elapsed)
Oct  1 10:14:35.296: INFO: Restart count of pod container-probe-4338/liveness-a99f3f4a-62c4-43cc-ac77-6b9db7886b09 is now 4 (1m18.119790434s elapsed)
Oct  1 10:15:37.390: INFO: Restart count of pod container-probe-4338/liveness-a99f3f4a-62c4-43cc-ac77-6b9db7886b09 is now 5 (2m20.214259796s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:15:37.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4338" for this suite.
Oct  1 10:15:43.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:15:43.466: INFO: namespace container-probe-4338 deletion completed in 6.05858968s

• [SLOW TEST:148.331 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:15:43.466: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  1 10:15:43.709: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  1 10:15:46.722: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:15:46.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4021" for this suite.
Oct  1 10:15:52.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:15:52.787: INFO: namespace webhook-4021 deletion completed in 6.056893808s
STEP: Destroying namespace "webhook-4021-markers" for this suite.
Oct  1 10:15:58.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:15:58.844: INFO: namespace webhook-4021-markers deletion completed in 6.056898497s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:15.386 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:15:58.852: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-4ac4507c-c6c9-4039-91a0-1997bffc65a2
STEP: Creating a pod to test consume configMaps
Oct  1 10:15:58.882: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e1c5521e-4bfb-40c2-99d6-31133d69d46d" in namespace "projected-585" to be "success or failure"
Oct  1 10:15:58.884: INFO: Pod "pod-projected-configmaps-e1c5521e-4bfb-40c2-99d6-31133d69d46d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.753261ms
Oct  1 10:16:00.887: INFO: Pod "pod-projected-configmaps-e1c5521e-4bfb-40c2-99d6-31133d69d46d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004762902s
STEP: Saw pod success
Oct  1 10:16:00.887: INFO: Pod "pod-projected-configmaps-e1c5521e-4bfb-40c2-99d6-31133d69d46d" satisfied condition "success or failure"
Oct  1 10:16:00.889: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-projected-configmaps-e1c5521e-4bfb-40c2-99d6-31133d69d46d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 10:16:00.909: INFO: Waiting for pod pod-projected-configmaps-e1c5521e-4bfb-40c2-99d6-31133d69d46d to disappear
Oct  1 10:16:00.917: INFO: Pod pod-projected-configmaps-e1c5521e-4bfb-40c2-99d6-31133d69d46d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:16:00.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-585" for this suite.
Oct  1 10:16:06.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:16:06.975: INFO: namespace projected-585 deletion completed in 6.055742047s

• [SLOW TEST:8.122 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:16:06.975: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:16:07.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9430" for this suite.
Oct  1 10:16:35.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:16:35.094: INFO: namespace kubelet-test-9430 deletion completed in 28.073211975s

• [SLOW TEST:28.119 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:16:35.094: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  1 10:16:35.653: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct  1 10:16:37.660: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705521795, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705521795, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705521795, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705521795, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  1 10:16:40.669: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:16:40.672: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:16:41.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5737" for this suite.
Oct  1 10:16:47.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:16:47.830: INFO: namespace webhook-5737 deletion completed in 6.061405937s
STEP: Destroying namespace "webhook-5737-markers" for this suite.
Oct  1 10:16:53.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:16:53.888: INFO: namespace webhook-5737-markers deletion completed in 6.057588752s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.801 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:16:53.896: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-f1291f43-2aed-48b2-a368-0afe30c62edf
STEP: Creating a pod to test consume secrets
Oct  1 10:16:53.924: INFO: Waiting up to 5m0s for pod "pod-secrets-ee426886-e6e7-4b22-a8d1-bda0c760b786" in namespace "secrets-9059" to be "success or failure"
Oct  1 10:16:53.932: INFO: Pod "pod-secrets-ee426886-e6e7-4b22-a8d1-bda0c760b786": Phase="Pending", Reason="", readiness=false. Elapsed: 7.463323ms
Oct  1 10:16:55.935: INFO: Pod "pod-secrets-ee426886-e6e7-4b22-a8d1-bda0c760b786": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010631902s
STEP: Saw pod success
Oct  1 10:16:55.935: INFO: Pod "pod-secrets-ee426886-e6e7-4b22-a8d1-bda0c760b786" satisfied condition "success or failure"
Oct  1 10:16:55.937: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-secrets-ee426886-e6e7-4b22-a8d1-bda0c760b786 container secret-env-test: <nil>
STEP: delete the pod
Oct  1 10:16:55.954: INFO: Waiting for pod pod-secrets-ee426886-e6e7-4b22-a8d1-bda0c760b786 to disappear
Oct  1 10:16:55.957: INFO: Pod pod-secrets-ee426886-e6e7-4b22-a8d1-bda0c760b786 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:16:55.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9059" for this suite.
Oct  1 10:17:01.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:17:02.023: INFO: namespace secrets-9059 deletion completed in 6.063170162s

• [SLOW TEST:8.127 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:17:02.023: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Oct  1 10:17:02.055: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7894 /api/v1/namespaces/watch-7894/configmaps/e2e-watch-test-watch-closed b2f4815c-bf2f-441a-991a-415ea93d018a 13009 0 2019-10-01 10:17:02 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct  1 10:17:02.056: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7894 /api/v1/namespaces/watch-7894/configmaps/e2e-watch-test-watch-closed b2f4815c-bf2f-441a-991a-415ea93d018a 13010 0 2019-10-01 10:17:02 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Oct  1 10:17:02.065: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7894 /api/v1/namespaces/watch-7894/configmaps/e2e-watch-test-watch-closed b2f4815c-bf2f-441a-991a-415ea93d018a 13011 0 2019-10-01 10:17:02 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct  1 10:17:02.065: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7894 /api/v1/namespaces/watch-7894/configmaps/e2e-watch-test-watch-closed b2f4815c-bf2f-441a-991a-415ea93d018a 13012 0 2019-10-01 10:17:02 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:17:02.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7894" for this suite.
Oct  1 10:17:08.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:17:08.126: INFO: namespace watch-7894 deletion completed in 6.058853906s

• [SLOW TEST:6.103 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:17:08.126: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:17:08.163: INFO: Create a RollingUpdate DaemonSet
Oct  1 10:17:08.166: INFO: Check that daemon pods launch on every node of the cluster
Oct  1 10:17:08.171: INFO: Number of nodes with available pods: 0
Oct  1 10:17:08.171: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:17:09.176: INFO: Number of nodes with available pods: 0
Oct  1 10:17:09.176: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:17:10.176: INFO: Number of nodes with available pods: 1
Oct  1 10:17:10.176: INFO: Node ip-172-31-29-44 is running more than one daemon pod
Oct  1 10:17:11.176: INFO: Number of nodes with available pods: 2
Oct  1 10:17:11.176: INFO: Number of running nodes: 2, number of available pods: 2
Oct  1 10:17:11.176: INFO: Update the DaemonSet to trigger a rollout
Oct  1 10:17:11.181: INFO: Updating DaemonSet daemon-set
Oct  1 10:17:14.191: INFO: Roll back the DaemonSet before rollout is complete
Oct  1 10:17:14.196: INFO: Updating DaemonSet daemon-set
Oct  1 10:17:14.196: INFO: Make sure DaemonSet rollback is complete
Oct  1 10:17:14.198: INFO: Wrong image for pod: daemon-set-zx9s9. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Oct  1 10:17:14.198: INFO: Pod daemon-set-zx9s9 is not available
Oct  1 10:17:15.209: INFO: Wrong image for pod: daemon-set-zx9s9. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Oct  1 10:17:15.209: INFO: Pod daemon-set-zx9s9 is not available
Oct  1 10:17:16.209: INFO: Pod daemon-set-vbxtb is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1492, will wait for the garbage collector to delete the pods
I1001 10:17:16.216595      17 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 10:17:16.216622      17 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Oct  1 10:17:16.271: INFO: Deleting DaemonSet.extensions daemon-set took: 4.691193ms
Oct  1 10:17:16.571: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.312335ms
I1001 10:17:16.571723      17 controller_utils.go:810] Ignoring inactive pod daemonsets-1492/daemon-set-sq6wt in state Running, deletion time 2019-10-01 10:17:46 +0000 UTC
I1001 10:17:16.571765      17 controller_utils.go:810] Ignoring inactive pod daemonsets-1492/daemon-set-vbxtb in state Pending, deletion time 2019-10-01 10:17:46 +0000 UTC
Oct  1 10:17:29.074: INFO: Number of nodes with available pods: 0
Oct  1 10:17:29.074: INFO: Number of running nodes: 0, number of available pods: 0
Oct  1 10:17:29.076: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1492/daemonsets","resourceVersion":"13129"},"items":null}

Oct  1 10:17:29.078: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1492/pods","resourceVersion":"13129"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:17:29.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1492" for this suite.
Oct  1 10:17:35.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:17:35.143: INFO: namespace daemonsets-1492 deletion completed in 6.05799413s

• [SLOW TEST:27.017 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:17:35.143: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Oct  1 10:17:35.170: INFO: Waiting up to 5m0s for pod "downward-api-f0f796be-28cf-4c86-b35b-81b827e8cb99" in namespace "downward-api-8443" to be "success or failure"
Oct  1 10:17:35.181: INFO: Pod "downward-api-f0f796be-28cf-4c86-b35b-81b827e8cb99": Phase="Pending", Reason="", readiness=false. Elapsed: 11.542243ms
Oct  1 10:17:37.184: INFO: Pod "downward-api-f0f796be-28cf-4c86-b35b-81b827e8cb99": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014610958s
STEP: Saw pod success
Oct  1 10:17:37.184: INFO: Pod "downward-api-f0f796be-28cf-4c86-b35b-81b827e8cb99" satisfied condition "success or failure"
Oct  1 10:17:37.187: INFO: Trying to get logs from node ip-172-31-16-136 pod downward-api-f0f796be-28cf-4c86-b35b-81b827e8cb99 container dapi-container: <nil>
STEP: delete the pod
Oct  1 10:17:37.197: INFO: Waiting for pod downward-api-f0f796be-28cf-4c86-b35b-81b827e8cb99 to disappear
Oct  1 10:17:37.198: INFO: Pod downward-api-f0f796be-28cf-4c86-b35b-81b827e8cb99 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:17:37.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8443" for this suite.
Oct  1 10:17:43.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:17:43.273: INFO: namespace downward-api-8443 deletion completed in 6.073257869s

• [SLOW TEST:8.130 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:17:43.274: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Oct  1 10:17:43.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 create -f - --namespace=kubectl-899'
Oct  1 10:17:43.570: INFO: stderr: ""
Oct  1 10:17:43.570: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  1 10:17:43.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-899'
Oct  1 10:17:43.638: INFO: stderr: ""
Oct  1 10:17:43.638: INFO: stdout: "update-demo-nautilus-qhln8 update-demo-nautilus-rgr58 "
Oct  1 10:17:43.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-nautilus-qhln8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-899'
Oct  1 10:17:43.702: INFO: stderr: ""
Oct  1 10:17:43.702: INFO: stdout: ""
Oct  1 10:17:43.702: INFO: update-demo-nautilus-qhln8 is created but not running
Oct  1 10:17:48.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-899'
Oct  1 10:17:48.769: INFO: stderr: ""
Oct  1 10:17:48.769: INFO: stdout: "update-demo-nautilus-qhln8 update-demo-nautilus-rgr58 "
Oct  1 10:17:48.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-nautilus-qhln8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-899'
Oct  1 10:17:48.834: INFO: stderr: ""
Oct  1 10:17:48.834: INFO: stdout: "true"
Oct  1 10:17:48.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-nautilus-qhln8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-899'
Oct  1 10:17:48.897: INFO: stderr: ""
Oct  1 10:17:48.897: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  1 10:17:48.898: INFO: validating pod update-demo-nautilus-qhln8
Oct  1 10:17:48.901: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  1 10:17:48.901: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  1 10:17:48.901: INFO: update-demo-nautilus-qhln8 is verified up and running
Oct  1 10:17:48.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-nautilus-rgr58 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-899'
Oct  1 10:17:48.966: INFO: stderr: ""
Oct  1 10:17:48.966: INFO: stdout: "true"
Oct  1 10:17:48.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-nautilus-rgr58 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-899'
Oct  1 10:17:49.030: INFO: stderr: ""
Oct  1 10:17:49.030: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  1 10:17:49.030: INFO: validating pod update-demo-nautilus-rgr58
Oct  1 10:17:49.033: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  1 10:17:49.033: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  1 10:17:49.033: INFO: update-demo-nautilus-rgr58 is verified up and running
STEP: using delete to clean up resources
Oct  1 10:17:49.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 delete --grace-period=0 --force -f - --namespace=kubectl-899'
Oct  1 10:17:49.099: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  1 10:17:49.099: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct  1 10:17:49.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-899'
Oct  1 10:17:49.166: INFO: stderr: "No resources found in kubectl-899 namespace.\n"
Oct  1 10:17:49.166: INFO: stdout: ""
Oct  1 10:17:49.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods -l name=update-demo --namespace=kubectl-899 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct  1 10:17:49.232: INFO: stderr: ""
Oct  1 10:17:49.232: INFO: stdout: "update-demo-nautilus-qhln8\nupdate-demo-nautilus-rgr58\n"
Oct  1 10:17:49.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-899'
Oct  1 10:17:49.803: INFO: stderr: "No resources found in kubectl-899 namespace.\n"
Oct  1 10:17:49.803: INFO: stdout: ""
Oct  1 10:17:49.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods -l name=update-demo --namespace=kubectl-899 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct  1 10:17:49.872: INFO: stderr: ""
Oct  1 10:17:49.872: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:17:49.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-899" for this suite.
Oct  1 10:18:17.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:18:17.933: INFO: namespace kubectl-899 deletion completed in 28.05866802s

• [SLOW TEST:34.659 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:18:17.933: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Oct  1 10:18:17.953: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Oct  1 10:18:28.366: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 10:18:31.294: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:18:40.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8874" for this suite.
Oct  1 10:18:46.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:18:46.927: INFO: namespace crd-publish-openapi-8874 deletion completed in 6.071623354s

• [SLOW TEST:28.994 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:18:46.928: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-8399acab-4edd-42f1-8e3f-35b404bfbe05
STEP: Creating a pod to test consume configMaps
Oct  1 10:18:46.954: INFO: Waiting up to 5m0s for pod "pod-configmaps-e817e4df-348a-47ab-9cd0-b1f01fd47b0f" in namespace "configmap-9407" to be "success or failure"
Oct  1 10:18:46.962: INFO: Pod "pod-configmaps-e817e4df-348a-47ab-9cd0-b1f01fd47b0f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.790035ms
Oct  1 10:18:48.966: INFO: Pod "pod-configmaps-e817e4df-348a-47ab-9cd0-b1f01fd47b0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011057643s
STEP: Saw pod success
Oct  1 10:18:48.966: INFO: Pod "pod-configmaps-e817e4df-348a-47ab-9cd0-b1f01fd47b0f" satisfied condition "success or failure"
Oct  1 10:18:48.968: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-configmaps-e817e4df-348a-47ab-9cd0-b1f01fd47b0f container configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 10:18:48.980: INFO: Waiting for pod pod-configmaps-e817e4df-348a-47ab-9cd0-b1f01fd47b0f to disappear
Oct  1 10:18:48.988: INFO: Pod pod-configmaps-e817e4df-348a-47ab-9cd0-b1f01fd47b0f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:18:48.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9407" for this suite.
Oct  1 10:18:54.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:18:55.046: INFO: namespace configmap-9407 deletion completed in 6.056829404s

• [SLOW TEST:8.119 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:18:55.047: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:18:55.067: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:18:56.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9634" for this suite.
Oct  1 10:19:02.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:19:02.153: INFO: namespace custom-resource-definition-9634 deletion completed in 6.06164842s

• [SLOW TEST:7.106 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:19:02.153: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct  1 10:19:02.183: INFO: Waiting up to 5m0s for pod "pod-75d55912-da00-497a-9cb1-ce762d61741a" in namespace "emptydir-7633" to be "success or failure"
Oct  1 10:19:02.188: INFO: Pod "pod-75d55912-da00-497a-9cb1-ce762d61741a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.900023ms
Oct  1 10:19:04.191: INFO: Pod "pod-75d55912-da00-497a-9cb1-ce762d61741a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00800595s
STEP: Saw pod success
Oct  1 10:19:04.191: INFO: Pod "pod-75d55912-da00-497a-9cb1-ce762d61741a" satisfied condition "success or failure"
Oct  1 10:19:04.193: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-75d55912-da00-497a-9cb1-ce762d61741a container test-container: <nil>
STEP: delete the pod
Oct  1 10:19:04.202: INFO: Waiting for pod pod-75d55912-da00-497a-9cb1-ce762d61741a to disappear
Oct  1 10:19:04.204: INFO: Pod pod-75d55912-da00-497a-9cb1-ce762d61741a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:19:04.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7633" for this suite.
Oct  1 10:19:10.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:19:10.265: INFO: namespace emptydir-7633 deletion completed in 6.058863558s

• [SLOW TEST:8.112 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:19:10.265: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-8995
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-8995
I1001 10:19:10.303069      17 runners.go:184] Created replication controller with name: externalname-service, namespace: services-8995, replica count: 2
I1001 10:19:10.303162      17 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 10:19:10.303183      17 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Oct  1 10:19:13.353: INFO: Creating new exec pod
I1001 10:19:13.353547      17 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1001 10:19:15.364350      17 reflector.go:120] Starting reflector *v1.Endpoints (0s) from k8s.io/kubernetes/test/e2e/framework/service/jig.go:389
I1001 10:19:15.364380      17 reflector.go:158] Listing and watching *v1.Endpoints from k8s.io/kubernetes/test/e2e/framework/service/jig.go:389
Oct  1 10:19:16.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=services-8995 execpodjtgmh -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Oct  1 10:19:16.580: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Oct  1 10:19:16.580: INFO: stdout: ""
Oct  1 10:19:16.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=services-8995 execpodjtgmh -- /bin/sh -x -c nc -zv -t -w 2 10.152.183.126 80'
Oct  1 10:19:16.774: INFO: stderr: "+ nc -zv -t -w 2 10.152.183.126 80\nConnection to 10.152.183.126 80 port [tcp/http] succeeded!\n"
Oct  1 10:19:16.774: INFO: stdout: ""
Oct  1 10:19:16.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=services-8995 execpodjtgmh -- /bin/sh -x -c nc -zv -t -w 2 172.31.16.136 31517'
Oct  1 10:19:16.976: INFO: stderr: "+ nc -zv -t -w 2 172.31.16.136 31517\nConnection to 172.31.16.136 31517 port [tcp/31517] succeeded!\n"
Oct  1 10:19:16.976: INFO: stdout: ""
Oct  1 10:19:16.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=services-8995 execpodjtgmh -- /bin/sh -x -c nc -zv -t -w 2 172.31.29.44 31517'
Oct  1 10:19:17.165: INFO: stderr: "+ nc -zv -t -w 2 172.31.29.44 31517\nConnection to 172.31.29.44 31517 port [tcp/31517] succeeded!\n"
Oct  1 10:19:17.165: INFO: stdout: ""
Oct  1 10:19:17.165: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:19:17.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8995" for this suite.
Oct  1 10:19:23.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:19:23.238: INFO: namespace services-8995 deletion completed in 6.05988602s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:12.974 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:19:23.238: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-97240844-a397-4c2d-8c05-8ad9300e93d3
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-97240844-a397-4c2d-8c05-8ad9300e93d3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:19:27.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1690" for this suite.
Oct  1 10:19:41.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:19:41.354: INFO: namespace configmap-1690 deletion completed in 14.058288939s

• [SLOW TEST:18.116 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:19:41.355: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Oct  1 10:19:41.386: INFO: Waiting up to 5m0s for pod "downward-api-f44b91e6-0aee-4202-8c4c-ddc402981aac" in namespace "downward-api-9641" to be "success or failure"
Oct  1 10:19:41.390: INFO: Pod "downward-api-f44b91e6-0aee-4202-8c4c-ddc402981aac": Phase="Pending", Reason="", readiness=false. Elapsed: 3.897455ms
Oct  1 10:19:43.393: INFO: Pod "downward-api-f44b91e6-0aee-4202-8c4c-ddc402981aac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006961357s
STEP: Saw pod success
Oct  1 10:19:43.393: INFO: Pod "downward-api-f44b91e6-0aee-4202-8c4c-ddc402981aac" satisfied condition "success or failure"
Oct  1 10:19:43.395: INFO: Trying to get logs from node ip-172-31-16-136 pod downward-api-f44b91e6-0aee-4202-8c4c-ddc402981aac container dapi-container: <nil>
STEP: delete the pod
Oct  1 10:19:43.404: INFO: Waiting for pod downward-api-f44b91e6-0aee-4202-8c4c-ddc402981aac to disappear
Oct  1 10:19:43.406: INFO: Pod downward-api-f44b91e6-0aee-4202-8c4c-ddc402981aac no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:19:43.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9641" for this suite.
Oct  1 10:19:49.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:19:49.468: INFO: namespace downward-api-9641 deletion completed in 6.058759563s

• [SLOW TEST:8.113 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:19:49.468: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  1 10:19:50.052: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct  1 10:19:52.059: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705521990, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705521990, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705521990, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705521990, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  1 10:19:55.068: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:20:05.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2480" for this suite.
Oct  1 10:20:11.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:20:11.241: INFO: namespace webhook-2480 deletion completed in 6.059423452s
STEP: Destroying namespace "webhook-2480-markers" for this suite.
Oct  1 10:20:17.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:20:17.303: INFO: namespace webhook-2480-markers deletion completed in 6.062197229s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:27.843 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:20:17.311: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-9183/configmap-test-4eaa9757-6840-4b1d-91c3-efa4d6426b7b
STEP: Creating a pod to test consume configMaps
Oct  1 10:20:17.342: INFO: Waiting up to 5m0s for pod "pod-configmaps-7f20070a-a65d-4ffd-9dc7-418aa00648d2" in namespace "configmap-9183" to be "success or failure"
Oct  1 10:20:17.344: INFO: Pod "pod-configmaps-7f20070a-a65d-4ffd-9dc7-418aa00648d2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.842364ms
Oct  1 10:20:19.347: INFO: Pod "pod-configmaps-7f20070a-a65d-4ffd-9dc7-418aa00648d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004981623s
STEP: Saw pod success
Oct  1 10:20:19.347: INFO: Pod "pod-configmaps-7f20070a-a65d-4ffd-9dc7-418aa00648d2" satisfied condition "success or failure"
Oct  1 10:20:19.349: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-configmaps-7f20070a-a65d-4ffd-9dc7-418aa00648d2 container env-test: <nil>
STEP: delete the pod
Oct  1 10:20:19.361: INFO: Waiting for pod pod-configmaps-7f20070a-a65d-4ffd-9dc7-418aa00648d2 to disappear
Oct  1 10:20:19.369: INFO: Pod pod-configmaps-7f20070a-a65d-4ffd-9dc7-418aa00648d2 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:20:19.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9183" for this suite.
Oct  1 10:20:25.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:20:25.428: INFO: namespace configmap-9183 deletion completed in 6.056760554s

• [SLOW TEST:8.116 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:20:25.428: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-94d394fd-7245-49c7-bad5-baf1315cd7ff
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:20:25.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8298" for this suite.
Oct  1 10:20:31.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:20:31.517: INFO: namespace configmap-8298 deletion completed in 6.057976561s

• [SLOW TEST:6.090 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:20:31.518: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Oct  1 10:20:31.540: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-1291" to be "success or failure"
Oct  1 10:20:31.547: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 6.393515ms
Oct  1 10:20:33.549: INFO: Pod "pod-host-path-test": Phase="Running", Reason="", readiness=false. Elapsed: 2.008914576s
Oct  1 10:20:35.552: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011645312s
STEP: Saw pod success
Oct  1 10:20:35.552: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Oct  1 10:20:35.554: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Oct  1 10:20:35.566: INFO: Waiting for pod pod-host-path-test to disappear
Oct  1 10:20:35.573: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:20:35.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-1291" for this suite.
Oct  1 10:20:41.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:20:41.637: INFO: namespace hostpath-1291 deletion completed in 6.061767867s

• [SLOW TEST:10.119 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:20:41.637: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:20:54.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9647" for this suite.
Oct  1 10:21:00.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:21:00.765: INFO: namespace resourcequota-9647 deletion completed in 6.067927951s

• [SLOW TEST:19.128 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:21:00.765: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Oct  1 10:21:00.802: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-324 /api/v1/namespaces/watch-324/configmaps/e2e-watch-test-label-changed f433ba19-489d-4b91-aba7-6af991005165 13913 0 2019-10-01 10:21:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct  1 10:21:00.802: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-324 /api/v1/namespaces/watch-324/configmaps/e2e-watch-test-label-changed f433ba19-489d-4b91-aba7-6af991005165 13914 0 2019-10-01 10:21:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct  1 10:21:00.802: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-324 /api/v1/namespaces/watch-324/configmaps/e2e-watch-test-label-changed f433ba19-489d-4b91-aba7-6af991005165 13915 0 2019-10-01 10:21:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Oct  1 10:21:10.819: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-324 /api/v1/namespaces/watch-324/configmaps/e2e-watch-test-label-changed f433ba19-489d-4b91-aba7-6af991005165 13930 0 2019-10-01 10:21:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct  1 10:21:10.819: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-324 /api/v1/namespaces/watch-324/configmaps/e2e-watch-test-label-changed f433ba19-489d-4b91-aba7-6af991005165 13931 0 2019-10-01 10:21:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Oct  1 10:21:10.819: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-324 /api/v1/namespaces/watch-324/configmaps/e2e-watch-test-label-changed f433ba19-489d-4b91-aba7-6af991005165 13932 0 2019-10-01 10:21:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:21:10.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-324" for this suite.
Oct  1 10:21:16.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:21:16.878: INFO: namespace watch-324 deletion completed in 6.057264729s

• [SLOW TEST:16.113 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:21:16.879: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct  1 10:21:19.918: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:21:19.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9480" for this suite.
Oct  1 10:21:25.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:21:25.988: INFO: namespace container-runtime-9480 deletion completed in 6.060716296s

• [SLOW TEST:9.110 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:21:25.989: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  1 10:21:26.462: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct  1 10:21:28.469: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705522086, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705522086, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705522086, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705522086, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  1 10:21:31.477: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:21:31.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5320" for this suite.
Oct  1 10:21:37.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:21:37.567: INFO: namespace webhook-5320 deletion completed in 6.058575502s
STEP: Destroying namespace "webhook-5320-markers" for this suite.
Oct  1 10:21:43.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:21:43.623: INFO: namespace webhook-5320-markers deletion completed in 6.055744617s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.642 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:21:43.631: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Oct  1 10:21:43.649: INFO: namespace kubectl-4185
Oct  1 10:21:43.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 create -f - --namespace=kubectl-4185'
Oct  1 10:21:44.576: INFO: stderr: ""
Oct  1 10:21:44.576: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct  1 10:21:45.579: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 10:21:45.580: INFO: Found 0 / 1
Oct  1 10:21:46.580: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 10:21:46.580: INFO: Found 1 / 1
Oct  1 10:21:46.580: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct  1 10:21:46.582: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 10:21:46.582: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct  1 10:21:46.582: INFO: wait on redis-master startup in kubectl-4185 
Oct  1 10:21:46.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 logs redis-master-bnmc6 redis-master --namespace=kubectl-4185'
Oct  1 10:21:46.654: INFO: stderr: ""
Oct  1 10:21:46.654: INFO: stdout: "1:C 01 Oct 2019 10:21:45.715 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 01 Oct 2019 10:21:45.715 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 01 Oct 2019 10:21:45.715 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 01 Oct 2019 10:21:45.717 * Running mode=standalone, port=6379.\n1:M 01 Oct 2019 10:21:45.717 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Oct 2019 10:21:45.717 # Server initialized\n1:M 01 Oct 2019 10:21:45.717 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Oct 2019 10:21:45.717 * Ready to accept connections\n"
STEP: exposing RC
Oct  1 10:21:46.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-4185'
Oct  1 10:21:46.731: INFO: stderr: ""
Oct  1 10:21:46.731: INFO: stdout: "service/rm2 exposed\n"
Oct  1 10:21:46.734: INFO: Service rm2 in namespace kubectl-4185 found.
STEP: exposing service
Oct  1 10:21:48.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-4185'
Oct  1 10:21:48.815: INFO: stderr: ""
Oct  1 10:21:48.815: INFO: stdout: "service/rm3 exposed\n"
Oct  1 10:21:48.823: INFO: Service rm3 in namespace kubectl-4185 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:21:50.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4185" for this suite.
Oct  1 10:22:18.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:22:18.890: INFO: namespace kubectl-4185 deletion completed in 28.060251339s

• [SLOW TEST:35.259 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:22:18.890: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Oct  1 10:22:18.909: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:22:33.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2680" for this suite.
Oct  1 10:22:39.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:22:39.241: INFO: namespace crd-publish-openapi-2680 deletion completed in 6.059423693s

• [SLOW TEST:20.351 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:22:39.241: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-413f9a38-7b12-4298-9c64-4439106c141e
STEP: Creating a pod to test consume configMaps
Oct  1 10:22:39.273: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2a2c7817-37fd-46c3-8e02-d5fbea778dea" in namespace "projected-9094" to be "success or failure"
Oct  1 10:22:39.275: INFO: Pod "pod-projected-configmaps-2a2c7817-37fd-46c3-8e02-d5fbea778dea": Phase="Pending", Reason="", readiness=false. Elapsed: 1.903033ms
Oct  1 10:22:41.278: INFO: Pod "pod-projected-configmaps-2a2c7817-37fd-46c3-8e02-d5fbea778dea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005235921s
STEP: Saw pod success
Oct  1 10:22:41.278: INFO: Pod "pod-projected-configmaps-2a2c7817-37fd-46c3-8e02-d5fbea778dea" satisfied condition "success or failure"
Oct  1 10:22:41.283: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-projected-configmaps-2a2c7817-37fd-46c3-8e02-d5fbea778dea container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 10:22:41.295: INFO: Waiting for pod pod-projected-configmaps-2a2c7817-37fd-46c3-8e02-d5fbea778dea to disappear
Oct  1 10:22:41.303: INFO: Pod pod-projected-configmaps-2a2c7817-37fd-46c3-8e02-d5fbea778dea no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:22:41.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9094" for this suite.
Oct  1 10:22:47.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:22:47.365: INFO: namespace projected-9094 deletion completed in 6.060027774s

• [SLOW TEST:8.124 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:22:47.365: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-1ebdf790-f727-4768-92f0-54cf62a7951e in namespace container-probe-1597
Oct  1 10:22:49.404: INFO: Started pod busybox-1ebdf790-f727-4768-92f0-54cf62a7951e in namespace container-probe-1597
STEP: checking the pod's current state and verifying that restartCount is present
Oct  1 10:22:49.406: INFO: Initial restart count of pod busybox-1ebdf790-f727-4768-92f0-54cf62a7951e is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:26:49.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1597" for this suite.
Oct  1 10:26:55.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:26:55.894: INFO: namespace container-probe-1597 deletion completed in 6.060787598s

• [SLOW TEST:248.528 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:26:55.894: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:26:55.918: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Oct  1 10:26:58.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 --namespace=crd-publish-openapi-7526 create -f -'
Oct  1 10:26:59.837: INFO: stderr: ""
Oct  1 10:26:59.837: INFO: stdout: "e2e-test-crd-publish-openapi-95-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Oct  1 10:26:59.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 --namespace=crd-publish-openapi-7526 delete e2e-test-crd-publish-openapi-95-crds test-foo'
Oct  1 10:26:59.906: INFO: stderr: ""
Oct  1 10:26:59.906: INFO: stdout: "e2e-test-crd-publish-openapi-95-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Oct  1 10:26:59.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 --namespace=crd-publish-openapi-7526 apply -f -'
Oct  1 10:27:00.068: INFO: stderr: ""
Oct  1 10:27:00.068: INFO: stdout: "e2e-test-crd-publish-openapi-95-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Oct  1 10:27:00.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 --namespace=crd-publish-openapi-7526 delete e2e-test-crd-publish-openapi-95-crds test-foo'
Oct  1 10:27:00.138: INFO: stderr: ""
Oct  1 10:27:00.138: INFO: stdout: "e2e-test-crd-publish-openapi-95-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Oct  1 10:27:00.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 --namespace=crd-publish-openapi-7526 create -f -'
Oct  1 10:27:00.285: INFO: rc: 1
Oct  1 10:27:00.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 --namespace=crd-publish-openapi-7526 apply -f -'
Oct  1 10:27:00.546: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Oct  1 10:27:00.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 --namespace=crd-publish-openapi-7526 create -f -'
Oct  1 10:27:00.699: INFO: rc: 1
Oct  1 10:27:00.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 --namespace=crd-publish-openapi-7526 apply -f -'
Oct  1 10:27:00.878: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Oct  1 10:27:00.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 explain e2e-test-crd-publish-openapi-95-crds'
Oct  1 10:27:01.054: INFO: stderr: ""
Oct  1 10:27:01.054: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-95-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Oct  1 10:27:01.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 explain e2e-test-crd-publish-openapi-95-crds.metadata'
Oct  1 10:27:01.207: INFO: stderr: ""
Oct  1 10:27:01.207: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-95-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Oct  1 10:27:01.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 explain e2e-test-crd-publish-openapi-95-crds.spec'
Oct  1 10:27:01.359: INFO: stderr: ""
Oct  1 10:27:01.359: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-95-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Oct  1 10:27:01.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 explain e2e-test-crd-publish-openapi-95-crds.spec.bars'
Oct  1 10:27:01.512: INFO: stderr: ""
Oct  1 10:27:01.512: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-95-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Oct  1 10:27:01.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 explain e2e-test-crd-publish-openapi-95-crds.spec.bars2'
Oct  1 10:27:01.660: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:27:04.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7526" for this suite.
Oct  1 10:27:10.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:27:10.624: INFO: namespace crd-publish-openapi-7526 deletion completed in 6.059565568s

• [SLOW TEST:14.730 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:27:10.624: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Oct  1 10:27:10.654: INFO: Waiting up to 5m0s for pod "pod-0b7e9e7f-6856-4cbe-88ef-c92c0b992460" in namespace "emptydir-9066" to be "success or failure"
Oct  1 10:27:10.660: INFO: Pod "pod-0b7e9e7f-6856-4cbe-88ef-c92c0b992460": Phase="Pending", Reason="", readiness=false. Elapsed: 5.726114ms
Oct  1 10:27:12.663: INFO: Pod "pod-0b7e9e7f-6856-4cbe-88ef-c92c0b992460": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008810242s
STEP: Saw pod success
Oct  1 10:27:12.663: INFO: Pod "pod-0b7e9e7f-6856-4cbe-88ef-c92c0b992460" satisfied condition "success or failure"
Oct  1 10:27:12.665: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-0b7e9e7f-6856-4cbe-88ef-c92c0b992460 container test-container: <nil>
STEP: delete the pod
Oct  1 10:27:12.682: INFO: Waiting for pod pod-0b7e9e7f-6856-4cbe-88ef-c92c0b992460 to disappear
Oct  1 10:27:12.684: INFO: Pod pod-0b7e9e7f-6856-4cbe-88ef-c92c0b992460 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:27:12.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9066" for this suite.
Oct  1 10:27:18.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:27:18.749: INFO: namespace emptydir-9066 deletion completed in 6.059933318s

• [SLOW TEST:8.125 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:27:18.749: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-fb8ebaa2-4663-4bad-81b3-1c1e54cf81ef
STEP: Creating a pod to test consume secrets
Oct  1 10:27:18.780: INFO: Waiting up to 5m0s for pod "pod-secrets-6b0038fa-9642-4e61-9248-17df81bf2de2" in namespace "secrets-5921" to be "success or failure"
Oct  1 10:27:18.782: INFO: Pod "pod-secrets-6b0038fa-9642-4e61-9248-17df81bf2de2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.121828ms
Oct  1 10:27:20.785: INFO: Pod "pod-secrets-6b0038fa-9642-4e61-9248-17df81bf2de2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005242634s
STEP: Saw pod success
Oct  1 10:27:20.785: INFO: Pod "pod-secrets-6b0038fa-9642-4e61-9248-17df81bf2de2" satisfied condition "success or failure"
Oct  1 10:27:20.787: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-secrets-6b0038fa-9642-4e61-9248-17df81bf2de2 container secret-volume-test: <nil>
STEP: delete the pod
Oct  1 10:27:20.800: INFO: Waiting for pod pod-secrets-6b0038fa-9642-4e61-9248-17df81bf2de2 to disappear
Oct  1 10:27:20.807: INFO: Pod pod-secrets-6b0038fa-9642-4e61-9248-17df81bf2de2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:27:20.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5921" for this suite.
Oct  1 10:27:26.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:27:26.868: INFO: namespace secrets-5921 deletion completed in 6.058831627s

• [SLOW TEST:8.119 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:27:26.868: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:27:26.887: INFO: Creating deployment "webserver-deployment"
Oct  1 10:27:26.890: INFO: Waiting for observed generation 1
Oct  1 10:27:28.901: INFO: Waiting for all required pods to come up
Oct  1 10:27:28.904: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Oct  1 10:27:30.909: INFO: Waiting for deployment "webserver-deployment" to complete
Oct  1 10:27:30.913: INFO: Updating deployment "webserver-deployment" with a non-existent image
Oct  1 10:27:30.917: INFO: Updating deployment webserver-deployment
Oct  1 10:27:30.917: INFO: Waiting for observed generation 2
Oct  1 10:27:32.922: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Oct  1 10:27:32.924: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Oct  1 10:27:32.926: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Oct  1 10:27:32.932: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Oct  1 10:27:32.932: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Oct  1 10:27:32.934: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Oct  1 10:27:32.937: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Oct  1 10:27:32.937: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Oct  1 10:27:32.942: INFO: Updating deployment webserver-deployment
Oct  1 10:27:32.942: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Oct  1 10:27:32.960: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Oct  1 10:27:34.974: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Oct  1 10:27:34.993: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-9503 /apis/apps/v1/namespaces/deployment-9503/deployments/webserver-deployment 72981c44-9f2c-4377-b758-1a52ee2d1566 15040 3 2019-10-01 10:27:26 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc007064368 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-10-01 10:27:32 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2019-10-01 10:27:33 +0000 UTC,LastTransitionTime:2019-10-01 10:27:26 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Oct  1 10:27:34.997: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-9503 /apis/apps/v1/namespaces/deployment-9503/replicasets/webserver-deployment-c7997dcc8 3758a7ce-bf37-49d6-8171-fdd7ca5ab50f 15037 3 2019-10-01 10:27:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 72981c44-9f2c-4377-b758-1a52ee2d1566 0xc007064987 0xc007064988}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc007064a18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct  1 10:27:34.997: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Oct  1 10:27:34.997: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-9503 /apis/apps/v1/namespaces/deployment-9503/replicasets/webserver-deployment-595b5b9587 c2d6f311-f0af-4ed9-8704-ab640b5b8074 15023 3 2019-10-01 10:27:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 72981c44-9f2c-4377-b758-1a52ee2d1566 0xc0070648b7 0xc0070648b8}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc007064918 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Oct  1 10:27:35.001: INFO: Pod "webserver-deployment-595b5b9587-2hrxb" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-2hrxb webserver-deployment-595b5b9587- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-595b5b9587-2hrxb b53fd7d2-bc59-47f3-9607-090e119df9a4 14835 0 2019-10-01 10:27:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c2d6f311-f0af-4ed9-8704-ab640b5b8074 0xc007064f37 0xc007064f38}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.44,PodIP:10.1.2.48,StartTime:2019-10-01 10:27:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-01 10:27:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://0d93d91a4c6462390087118217eca01e5eb3347f63d9c723e066915f5a16e375,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.2.48,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.001: INFO: Pod "webserver-deployment-595b5b9587-2ptr2" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-2ptr2 webserver-deployment-595b5b9587- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-595b5b9587-2ptr2 6776b04d-91a0-45a0-92a6-9f25a0dbeebb 15019 0 2019-10-01 10:27:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c2d6f311-f0af-4ed9-8704-ab640b5b8074 0xc0070650b0 0xc0070650b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-16-136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.001: INFO: Pod "webserver-deployment-595b5b9587-4ddbx" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-4ddbx webserver-deployment-595b5b9587- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-595b5b9587-4ddbx 82e82c9c-c019-46aa-9c5b-b92885676280 15038 0 2019-10-01 10:27:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c2d6f311-f0af-4ed9-8704-ab640b5b8074 0xc0070651c0 0xc0070651c1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-16-136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.16.136,PodIP:,StartTime:2019-10-01 10:27:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.001: INFO: Pod "webserver-deployment-595b5b9587-569nj" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-569nj webserver-deployment-595b5b9587- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-595b5b9587-569nj 1e07a4bd-1c07-4cb5-b3b8-4df5263f20e5 15036 0 2019-10-01 10:27:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c2d6f311-f0af-4ed9-8704-ab640b5b8074 0xc007065317 0xc007065318}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.44,PodIP:,StartTime:2019-10-01 10:27:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.002: INFO: Pod "webserver-deployment-595b5b9587-69lwj" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-69lwj webserver-deployment-595b5b9587- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-595b5b9587-69lwj 3f89b98e-a215-4121-986e-e843d5a2d2b2 15013 0 2019-10-01 10:27:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c2d6f311-f0af-4ed9-8704-ab640b5b8074 0xc007065477 0xc007065478}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-16-136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.16.136,PodIP:,StartTime:2019-10-01 10:27:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.002: INFO: Pod "webserver-deployment-595b5b9587-9d865" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-9d865 webserver-deployment-595b5b9587- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-595b5b9587-9d865 b0997954-2b5e-4ba5-84a8-7145a0aa1028 15061 0 2019-10-01 10:27:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c2d6f311-f0af-4ed9-8704-ab640b5b8074 0xc0070655d7 0xc0070655d8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-16-136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.16.136,PodIP:,StartTime:2019-10-01 10:27:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.002: INFO: Pod "webserver-deployment-595b5b9587-fsrz9" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-fsrz9 webserver-deployment-595b5b9587- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-595b5b9587-fsrz9 727c373e-0936-4095-b976-d75c8209f7e8 14839 0 2019-10-01 10:27:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c2d6f311-f0af-4ed9-8704-ab640b5b8074 0xc007065737 0xc007065738}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.44,PodIP:10.1.2.47,StartTime:2019-10-01 10:27:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-01 10:27:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://1e1edee4cc8b87b45c12f3e27c18bad54414b25ccf5d1aca712474d4de5e1d5d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.2.47,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.002: INFO: Pod "webserver-deployment-595b5b9587-g22ng" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-g22ng webserver-deployment-595b5b9587- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-595b5b9587-g22ng 8c1cef68-abe4-40df-b4ba-4cb6287df83c 15054 0 2019-10-01 10:27:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c2d6f311-f0af-4ed9-8704-ab640b5b8074 0xc0070658b0 0xc0070658b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-16-136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.16.136,PodIP:,StartTime:2019-10-01 10:27:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.002: INFO: Pod "webserver-deployment-595b5b9587-hzhm9" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-hzhm9 webserver-deployment-595b5b9587- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-595b5b9587-hzhm9 b2973665-e563-477a-9b71-b323c088d3a5 14856 0 2019-10-01 10:27:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c2d6f311-f0af-4ed9-8704-ab640b5b8074 0xc007065a07 0xc007065a08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.44,PodIP:10.1.2.50,StartTime:2019-10-01 10:27:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-01 10:27:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://570b3e40e9abe9384f0109742c6331507b6dc4874025ae21c2abba5c3a475d03,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.2.50,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.002: INFO: Pod "webserver-deployment-595b5b9587-krl95" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-krl95 webserver-deployment-595b5b9587- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-595b5b9587-krl95 0e1ce679-9364-4044-8618-384c15ad4375 14848 0 2019-10-01 10:27:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c2d6f311-f0af-4ed9-8704-ab640b5b8074 0xc007065b80 0xc007065b81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-16-136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.16.136,PodIP:10.1.63.165,StartTime:2019-10-01 10:27:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-01 10:27:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://85baecd640a40416aae17c9aca0c025193dc94ab3a915b6e822414e0faf7ef34,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.63.165,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.002: INFO: Pod "webserver-deployment-595b5b9587-s5t7x" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-s5t7x webserver-deployment-595b5b9587- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-595b5b9587-s5t7x 7b876aaa-5438-483c-96b3-c1b4ff543dba 14845 0 2019-10-01 10:27:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c2d6f311-f0af-4ed9-8704-ab640b5b8074 0xc007065cf0 0xc007065cf1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-16-136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.16.136,PodIP:10.1.63.164,StartTime:2019-10-01 10:27:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-01 10:27:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://d747ad6f77caa29e30f776c1081ddd0ed4a1f333412fbae896e573fb37e0a8e9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.63.164,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.002: INFO: Pod "webserver-deployment-595b5b9587-sv5wr" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-sv5wr webserver-deployment-595b5b9587- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-595b5b9587-sv5wr e82789c1-1362-4e69-adcd-a94ac9c81233 15092 0 2019-10-01 10:27:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c2d6f311-f0af-4ed9-8704-ab640b5b8074 0xc007065e60 0xc007065e61}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.44,PodIP:,StartTime:2019-10-01 10:27:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.003: INFO: Pod "webserver-deployment-595b5b9587-tdzf5" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-tdzf5 webserver-deployment-595b5b9587- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-595b5b9587-tdzf5 771c92b7-a05b-4ab6-8d8d-df22deca7111 15084 0 2019-10-01 10:27:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c2d6f311-f0af-4ed9-8704-ab640b5b8074 0xc007784007 0xc007784008}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.44,PodIP:,StartTime:2019-10-01 10:27:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.003: INFO: Pod "webserver-deployment-595b5b9587-v2fg5" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-v2fg5 webserver-deployment-595b5b9587- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-595b5b9587-v2fg5 3d88f571-5eb7-4c66-b5da-fa9f1b92e5bc 15017 0 2019-10-01 10:27:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c2d6f311-f0af-4ed9-8704-ab640b5b8074 0xc0077841c7 0xc0077841c8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-16-136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.003: INFO: Pod "webserver-deployment-595b5b9587-vdhd2" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-vdhd2 webserver-deployment-595b5b9587- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-595b5b9587-vdhd2 ccc2afda-a6c3-458e-a6c2-2944334a3891 15020 0 2019-10-01 10:27:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c2d6f311-f0af-4ed9-8704-ab640b5b8074 0xc007784300 0xc007784301}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.003: INFO: Pod "webserver-deployment-595b5b9587-vfblg" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-vfblg webserver-deployment-595b5b9587- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-595b5b9587-vfblg 4e245c73-11ad-41e4-bb6d-33b7c4c411fa 14832 0 2019-10-01 10:27:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c2d6f311-f0af-4ed9-8704-ab640b5b8074 0xc007784420 0xc007784421}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.44,PodIP:10.1.2.49,StartTime:2019-10-01 10:27:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-01 10:27:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://b4db8ffaeb6532ab4218f1dbbd08c6b0ad203e7fed604dfa27209afd1e3ed61c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.2.49,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.003: INFO: Pod "webserver-deployment-595b5b9587-wl6j2" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-wl6j2 webserver-deployment-595b5b9587- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-595b5b9587-wl6j2 44c59231-ffe4-4913-b137-eea8ac2501a1 15043 0 2019-10-01 10:27:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c2d6f311-f0af-4ed9-8704-ab640b5b8074 0xc007784590 0xc007784591}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.44,PodIP:,StartTime:2019-10-01 10:27:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.003: INFO: Pod "webserver-deployment-595b5b9587-xm8r6" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-xm8r6 webserver-deployment-595b5b9587- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-595b5b9587-xm8r6 dd68e957-41a8-4d38-9cdc-99ed5a7cc8e6 15047 0 2019-10-01 10:27:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c2d6f311-f0af-4ed9-8704-ab640b5b8074 0xc0077846e7 0xc0077846e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.44,PodIP:,StartTime:2019-10-01 10:27:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.003: INFO: Pod "webserver-deployment-595b5b9587-xq8hw" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-xq8hw webserver-deployment-595b5b9587- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-595b5b9587-xq8hw f8857001-f1cb-4f1b-8133-94c3704abefa 14843 0 2019-10-01 10:27:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c2d6f311-f0af-4ed9-8704-ab640b5b8074 0xc007784897 0xc007784898}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-16-136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.16.136,PodIP:10.1.63.166,StartTime:2019-10-01 10:27:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-01 10:27:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://f754c8654b175ffa793ab4bae9eeaae1957e52079988cb2814227e44ffb4eba2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.63.166,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.003: INFO: Pod "webserver-deployment-595b5b9587-z2pkf" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-z2pkf webserver-deployment-595b5b9587- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-595b5b9587-z2pkf e86a60f7-afa5-4bf6-b0cd-00b523d87585 14853 0 2019-10-01 10:27:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c2d6f311-f0af-4ed9-8704-ab640b5b8074 0xc007784a30 0xc007784a31}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-16-136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.16.136,PodIP:10.1.63.162,StartTime:2019-10-01 10:27:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-01 10:27:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://ed30d552af49bff81ac26ac1c8ce28e30607ad363d699e881642fb9cf337e712,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.63.162,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.003: INFO: Pod "webserver-deployment-c7997dcc8-5d2dx" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-5d2dx webserver-deployment-c7997dcc8- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-c7997dcc8-5d2dx d8fed840-a0e4-4e0e-b239-71296a25a750 14944 0 2019-10-01 10:27:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3758a7ce-bf37-49d6-8171-fdd7ca5ab50f 0xc007784ba0 0xc007784ba1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.44,PodIP:10.1.2.51,StartTime:2019-10-01 10:27:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": no available registry endpoint: pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.2.51,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.003: INFO: Pod "webserver-deployment-c7997dcc8-75p7f" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-75p7f webserver-deployment-c7997dcc8- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-c7997dcc8-75p7f 01c1fc09-944c-4ca4-9a8a-6292628eced2 14949 0 2019-10-01 10:27:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3758a7ce-bf37-49d6-8171-fdd7ca5ab50f 0xc007784d40 0xc007784d41}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-16-136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.16.136,PodIP:10.1.63.169,StartTime:2019-10-01 10:27:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": no available registry endpoint: pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.63.169,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.009: INFO: Pod "webserver-deployment-c7997dcc8-fmsdg" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-fmsdg webserver-deployment-c7997dcc8- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-c7997dcc8-fmsdg e42562be-324f-4f0d-86f0-57e7020a8a9c 15042 0 2019-10-01 10:27:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3758a7ce-bf37-49d6-8171-fdd7ca5ab50f 0xc007784ee0 0xc007784ee1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-16-136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.16.136,PodIP:,StartTime:2019-10-01 10:27:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.009: INFO: Pod "webserver-deployment-c7997dcc8-hpbq5" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-hpbq5 webserver-deployment-c7997dcc8- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-c7997dcc8-hpbq5 793fee93-d7b2-4684-966e-bd9aff738f83 15064 0 2019-10-01 10:27:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3758a7ce-bf37-49d6-8171-fdd7ca5ab50f 0xc007785057 0xc007785058}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.44,PodIP:,StartTime:2019-10-01 10:27:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.009: INFO: Pod "webserver-deployment-c7997dcc8-hxdh4" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-hxdh4 webserver-deployment-c7997dcc8- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-c7997dcc8-hxdh4 f7845113-43f6-4795-9293-ae4fa0009c80 15024 0 2019-10-01 10:27:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3758a7ce-bf37-49d6-8171-fdd7ca5ab50f 0xc0077851d7 0xc0077851d8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-16-136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.009: INFO: Pod "webserver-deployment-c7997dcc8-m77kc" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-m77kc webserver-deployment-c7997dcc8- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-c7997dcc8-m77kc 496fd001-f2d5-4f42-931d-a8f31b220e7c 15079 0 2019-10-01 10:27:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3758a7ce-bf37-49d6-8171-fdd7ca5ab50f 0xc007785300 0xc007785301}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-16-136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.16.136,PodIP:,StartTime:2019-10-01 10:27:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.009: INFO: Pod "webserver-deployment-c7997dcc8-n8djw" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-n8djw webserver-deployment-c7997dcc8- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-c7997dcc8-n8djw 4cb5908d-c9e7-402c-947a-0f654711c80e 14955 0 2019-10-01 10:27:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3758a7ce-bf37-49d6-8171-fdd7ca5ab50f 0xc007785477 0xc007785478}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-16-136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.16.136,PodIP:10.1.63.168,StartTime:2019-10-01 10:27:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": no available registry endpoint: pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.63.168,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.010: INFO: Pod "webserver-deployment-c7997dcc8-nqm5g" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-nqm5g webserver-deployment-c7997dcc8- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-c7997dcc8-nqm5g b13cb85d-26ce-408d-af1e-28d7714d1c89 15015 0 2019-10-01 10:27:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3758a7ce-bf37-49d6-8171-fdd7ca5ab50f 0xc007785620 0xc007785621}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.44,PodIP:,StartTime:2019-10-01 10:27:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.010: INFO: Pod "webserver-deployment-c7997dcc8-sk5fp" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-sk5fp webserver-deployment-c7997dcc8- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-c7997dcc8-sk5fp 83d2a3c1-7b48-46e9-95f2-b286a7fa9d98 15057 0 2019-10-01 10:27:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3758a7ce-bf37-49d6-8171-fdd7ca5ab50f 0xc007785797 0xc007785798}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.44,PodIP:,StartTime:2019-10-01 10:27:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.010: INFO: Pod "webserver-deployment-c7997dcc8-t2p4n" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-t2p4n webserver-deployment-c7997dcc8- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-c7997dcc8-t2p4n 39db7d57-cb38-4383-9c23-47c2351b5338 15089 0 2019-10-01 10:27:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3758a7ce-bf37-49d6-8171-fdd7ca5ab50f 0xc007785917 0xc007785918}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-16-136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.16.136,PodIP:,StartTime:2019-10-01 10:27:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.011: INFO: Pod "webserver-deployment-c7997dcc8-tbfk8" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-tbfk8 webserver-deployment-c7997dcc8- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-c7997dcc8-tbfk8 6338f603-874b-4442-832a-8a557eeac25d 14947 0 2019-10-01 10:27:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3758a7ce-bf37-49d6-8171-fdd7ca5ab50f 0xc007785a97 0xc007785a98}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.44,PodIP:10.1.2.52,StartTime:2019-10-01 10:27:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": no available registry endpoint: pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.2.52,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.013: INFO: Pod "webserver-deployment-c7997dcc8-wxvbd" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-wxvbd webserver-deployment-c7997dcc8- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-c7997dcc8-wxvbd 2e6a4828-b0ef-4377-b657-8194439dfd63 14953 0 2019-10-01 10:27:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3758a7ce-bf37-49d6-8171-fdd7ca5ab50f 0xc007785cb0 0xc007785cb1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-16-136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.16.136,PodIP:10.1.63.167,StartTime:2019-10-01 10:27:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": no available registry endpoint: pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.63.167,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:27:35.014: INFO: Pod "webserver-deployment-c7997dcc8-x95gl" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-x95gl webserver-deployment-c7997dcc8- deployment-9503 /api/v1/namespaces/deployment-9503/pods/webserver-deployment-c7997dcc8-x95gl 1eedfa09-3b5d-4df5-b6ea-73681aa8dcda 15045 0 2019-10-01 10:27:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3758a7ce-bf37-49d6-8171-fdd7ca5ab50f 0xc007785e80 0xc007785e81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-z4mcr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-z4mcr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-z4mcr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:27:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.44,PodIP:,StartTime:2019-10-01 10:27:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:27:35.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9503" for this suite.
Oct  1 10:27:43.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:27:43.123: INFO: namespace deployment-9503 deletion completed in 8.101265552s

• [SLOW TEST:16.254 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:27:43.123: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-45eca0d5-82bb-4986-a176-27c612930318
STEP: Creating a pod to test consume configMaps
Oct  1 10:27:43.160: INFO: Waiting up to 5m0s for pod "pod-configmaps-ef76523f-5906-4e37-8981-abbd6dae6525" in namespace "configmap-8865" to be "success or failure"
Oct  1 10:27:43.177: INFO: Pod "pod-configmaps-ef76523f-5906-4e37-8981-abbd6dae6525": Phase="Pending", Reason="", readiness=false. Elapsed: 17.6516ms
Oct  1 10:27:45.180: INFO: Pod "pod-configmaps-ef76523f-5906-4e37-8981-abbd6dae6525": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020428931s
STEP: Saw pod success
Oct  1 10:27:45.180: INFO: Pod "pod-configmaps-ef76523f-5906-4e37-8981-abbd6dae6525" satisfied condition "success or failure"
Oct  1 10:27:45.182: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-configmaps-ef76523f-5906-4e37-8981-abbd6dae6525 container configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 10:27:45.193: INFO: Waiting for pod pod-configmaps-ef76523f-5906-4e37-8981-abbd6dae6525 to disappear
Oct  1 10:27:45.205: INFO: Pod pod-configmaps-ef76523f-5906-4e37-8981-abbd6dae6525 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:27:45.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8865" for this suite.
Oct  1 10:27:51.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:27:51.267: INFO: namespace configmap-8865 deletion completed in 6.059213709s

• [SLOW TEST:8.144 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:27:51.267: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Oct  1 10:27:51.315: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7272 /api/v1/namespaces/watch-7272/configmaps/e2e-watch-test-resource-version 532cc41c-f148-460d-af70-ea4c3d6c3201 15413 0 2019-10-01 10:27:51 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct  1 10:27:51.315: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7272 /api/v1/namespaces/watch-7272/configmaps/e2e-watch-test-resource-version 532cc41c-f148-460d-af70-ea4c3d6c3201 15414 0 2019-10-01 10:27:51 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:27:51.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7272" for this suite.
Oct  1 10:27:57.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:27:57.374: INFO: namespace watch-7272 deletion completed in 6.057138015s

• [SLOW TEST:6.107 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:27:57.375: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct  1 10:27:57.406: INFO: Waiting up to 5m0s for pod "pod-25592e9b-2391-4a6f-ae08-786d4185880f" in namespace "emptydir-5687" to be "success or failure"
Oct  1 10:27:57.408: INFO: Pod "pod-25592e9b-2391-4a6f-ae08-786d4185880f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.316066ms
Oct  1 10:27:59.411: INFO: Pod "pod-25592e9b-2391-4a6f-ae08-786d4185880f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005199213s
STEP: Saw pod success
Oct  1 10:27:59.411: INFO: Pod "pod-25592e9b-2391-4a6f-ae08-786d4185880f" satisfied condition "success or failure"
Oct  1 10:27:59.413: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-25592e9b-2391-4a6f-ae08-786d4185880f container test-container: <nil>
STEP: delete the pod
Oct  1 10:27:59.425: INFO: Waiting for pod pod-25592e9b-2391-4a6f-ae08-786d4185880f to disappear
Oct  1 10:27:59.433: INFO: Pod pod-25592e9b-2391-4a6f-ae08-786d4185880f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:27:59.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5687" for this suite.
Oct  1 10:28:05.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:28:05.490: INFO: namespace emptydir-5687 deletion completed in 6.054927444s

• [SLOW TEST:8.115 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:28:05.490: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  1 10:28:05.512: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e7186116-3d87-4aab-9641-b3c51018da7b" in namespace "downward-api-3127" to be "success or failure"
Oct  1 10:28:05.518: INFO: Pod "downwardapi-volume-e7186116-3d87-4aab-9641-b3c51018da7b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.218969ms
Oct  1 10:28:07.521: INFO: Pod "downwardapi-volume-e7186116-3d87-4aab-9641-b3c51018da7b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009305607s
STEP: Saw pod success
Oct  1 10:28:07.521: INFO: Pod "downwardapi-volume-e7186116-3d87-4aab-9641-b3c51018da7b" satisfied condition "success or failure"
Oct  1 10:28:07.523: INFO: Trying to get logs from node ip-172-31-16-136 pod downwardapi-volume-e7186116-3d87-4aab-9641-b3c51018da7b container client-container: <nil>
STEP: delete the pod
Oct  1 10:28:07.535: INFO: Waiting for pod downwardapi-volume-e7186116-3d87-4aab-9641-b3c51018da7b to disappear
Oct  1 10:28:07.543: INFO: Pod downwardapi-volume-e7186116-3d87-4aab-9641-b3c51018da7b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:28:07.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3127" for this suite.
Oct  1 10:28:13.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:28:13.602: INFO: namespace downward-api-3127 deletion completed in 6.05689816s

• [SLOW TEST:8.112 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:28:13.602: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-lhmdt in namespace proxy-6429
I1001 10:28:13.639740      17 runners.go:184] Created replication controller with name: proxy-service-lhmdt, namespace: proxy-6429, replica count: 1
I1001 10:28:13.639812      17 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 10:28:13.639834      17 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 10:28:14.690267      17 runners.go:184] proxy-service-lhmdt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1001 10:28:15.690579      17 runners.go:184] proxy-service-lhmdt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1001 10:28:16.690881      17 runners.go:184] proxy-service-lhmdt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1001 10:28:17.691137      17 runners.go:184] proxy-service-lhmdt Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct  1 10:28:17.693: INFO: setup took 4.063744117s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Oct  1 10:28:17.702: INFO: (0) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/rewriteme">test</a> (200; 7.983039ms)
Oct  1 10:28:17.702: INFO: (0) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname2/proxy/: bar (200; 8.099519ms)
Oct  1 10:28:17.703: INFO: (0) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:460/proxy/: tls baz (200; 9.658546ms)
Oct  1 10:28:17.705: INFO: (0) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname2/proxy/: bar (200; 11.058287ms)
Oct  1 10:28:17.706: INFO: (0) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">test<... (200; 11.566179ms)
Oct  1 10:28:17.706: INFO: (0) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 11.981723ms)
Oct  1 10:28:17.706: INFO: (0) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname1/proxy/: foo (200; 12.000932ms)
Oct  1 10:28:17.706: INFO: (0) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 12.253067ms)
Oct  1 10:28:17.706: INFO: (0) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 11.256025ms)
Oct  1 10:28:17.706: INFO: (0) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 11.347304ms)
Oct  1 10:28:17.710: INFO: (0) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname1/proxy/: tls baz (200; 15.725052ms)
Oct  1 10:28:17.711: INFO: (0) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">... (200; 17.948132ms)
Oct  1 10:28:17.714: INFO: (0) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname1/proxy/: foo (200; 20.085757ms)
Oct  1 10:28:17.717: INFO: (0) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:462/proxy/: tls qux (200; 23.125363ms)
Oct  1 10:28:17.717: INFO: (0) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname2/proxy/: tls qux (200; 23.937105ms)
Oct  1 10:28:17.719: INFO: (0) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/tlsrewritem... (200; 25.52045ms)
Oct  1 10:28:17.727: INFO: (1) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 6.836949ms)
Oct  1 10:28:17.728: INFO: (1) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 7.742262ms)
Oct  1 10:28:17.728: INFO: (1) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname2/proxy/: bar (200; 7.778473ms)
Oct  1 10:28:17.728: INFO: (1) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 7.821081ms)
Oct  1 10:28:17.728: INFO: (1) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">... (200; 8.807463ms)
Oct  1 10:28:17.729: INFO: (1) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname2/proxy/: bar (200; 9.176119ms)
Oct  1 10:28:17.729: INFO: (1) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 9.507609ms)
Oct  1 10:28:17.729: INFO: (1) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:460/proxy/: tls baz (200; 9.526013ms)
Oct  1 10:28:17.742: INFO: (1) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname1/proxy/: foo (200; 22.698768ms)
Oct  1 10:28:17.742: INFO: (1) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname1/proxy/: foo (200; 22.63927ms)
Oct  1 10:28:17.744: INFO: (1) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/rewriteme">test</a> (200; 24.258946ms)
Oct  1 10:28:17.744: INFO: (1) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname1/proxy/: tls baz (200; 24.29425ms)
Oct  1 10:28:17.744: INFO: (1) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">test<... (200; 24.280649ms)
Oct  1 10:28:17.744: INFO: (1) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname2/proxy/: tls qux (200; 24.11913ms)
Oct  1 10:28:17.744: INFO: (1) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/tlsrewritem... (200; 24.389626ms)
Oct  1 10:28:17.744: INFO: (1) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:462/proxy/: tls qux (200; 24.466238ms)
Oct  1 10:28:17.750: INFO: (2) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 5.561443ms)
Oct  1 10:28:17.750: INFO: (2) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">test<... (200; 5.520258ms)
Oct  1 10:28:17.752: INFO: (2) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 7.79748ms)
Oct  1 10:28:17.754: INFO: (2) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 9.526144ms)
Oct  1 10:28:17.754: INFO: (2) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">... (200; 9.738102ms)
Oct  1 10:28:17.754: INFO: (2) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname2/proxy/: bar (200; 9.72282ms)
Oct  1 10:28:17.754: INFO: (2) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname1/proxy/: foo (200; 10.370101ms)
Oct  1 10:28:17.754: INFO: (2) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname2/proxy/: bar (200; 10.088586ms)
Oct  1 10:28:17.754: INFO: (2) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/tlsrewritem... (200; 10.223325ms)
Oct  1 10:28:17.755: INFO: (2) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:462/proxy/: tls qux (200; 10.338969ms)
Oct  1 10:28:17.755: INFO: (2) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname1/proxy/: tls baz (200; 10.59458ms)
Oct  1 10:28:17.755: INFO: (2) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:460/proxy/: tls baz (200; 10.48102ms)
Oct  1 10:28:17.755: INFO: (2) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname2/proxy/: tls qux (200; 10.441857ms)
Oct  1 10:28:17.755: INFO: (2) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/rewriteme">test</a> (200; 10.704673ms)
Oct  1 10:28:17.755: INFO: (2) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 10.840311ms)
Oct  1 10:28:17.755: INFO: (2) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname1/proxy/: foo (200; 10.935218ms)
Oct  1 10:28:17.763: INFO: (3) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 7.605209ms)
Oct  1 10:28:17.764: INFO: (3) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname2/proxy/: tls qux (200; 7.966049ms)
Oct  1 10:28:17.764: INFO: (3) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 8.071934ms)
Oct  1 10:28:17.764: INFO: (3) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">... (200; 8.308586ms)
Oct  1 10:28:17.764: INFO: (3) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname1/proxy/: foo (200; 8.414216ms)
Oct  1 10:28:17.764: INFO: (3) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:462/proxy/: tls qux (200; 8.403762ms)
Oct  1 10:28:17.764: INFO: (3) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/rewriteme">test</a> (200; 8.668304ms)
Oct  1 10:28:17.764: INFO: (3) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">test<... (200; 8.624396ms)
Oct  1 10:28:17.764: INFO: (3) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname2/proxy/: bar (200; 8.528963ms)
Oct  1 10:28:17.764: INFO: (3) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/tlsrewritem... (200; 8.93739ms)
Oct  1 10:28:17.764: INFO: (3) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 9.19352ms)
Oct  1 10:28:17.765: INFO: (3) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname1/proxy/: tls baz (200; 9.11634ms)
Oct  1 10:28:17.765: INFO: (3) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 9.205923ms)
Oct  1 10:28:17.765: INFO: (3) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname1/proxy/: foo (200; 9.205538ms)
Oct  1 10:28:17.765: INFO: (3) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname2/proxy/: bar (200; 9.780313ms)
Oct  1 10:28:17.778: INFO: (3) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:460/proxy/: tls baz (200; 22.862994ms)
Oct  1 10:28:17.784: INFO: (4) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 5.619961ms)
Oct  1 10:28:17.784: INFO: (4) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 5.649923ms)
Oct  1 10:28:17.785: INFO: (4) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:462/proxy/: tls qux (200; 6.061252ms)
Oct  1 10:28:17.785: INFO: (4) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname2/proxy/: tls qux (200; 6.1588ms)
Oct  1 10:28:17.785: INFO: (4) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:460/proxy/: tls baz (200; 6.293028ms)
Oct  1 10:28:17.785: INFO: (4) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 6.23864ms)
Oct  1 10:28:17.785: INFO: (4) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">... (200; 6.350174ms)
Oct  1 10:28:17.799: INFO: (4) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">test<... (200; 20.280869ms)
Oct  1 10:28:17.799: INFO: (4) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname1/proxy/: tls baz (200; 20.300147ms)
Oct  1 10:28:17.799: INFO: (4) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname1/proxy/: foo (200; 20.543788ms)
Oct  1 10:28:17.799: INFO: (4) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname1/proxy/: foo (200; 20.323885ms)
Oct  1 10:28:17.799: INFO: (4) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname2/proxy/: bar (200; 20.359287ms)
Oct  1 10:28:17.799: INFO: (4) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname2/proxy/: bar (200; 20.461132ms)
Oct  1 10:28:17.799: INFO: (4) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 20.930878ms)
Oct  1 10:28:17.799: INFO: (4) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/tlsrewritem... (200; 20.895909ms)
Oct  1 10:28:17.800: INFO: (4) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/rewriteme">test</a> (200; 20.889366ms)
Oct  1 10:28:17.804: INFO: (5) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">... (200; 4.017072ms)
Oct  1 10:28:17.806: INFO: (5) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:460/proxy/: tls baz (200; 5.765568ms)
Oct  1 10:28:17.806: INFO: (5) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:462/proxy/: tls qux (200; 5.853701ms)
Oct  1 10:28:17.806: INFO: (5) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 6.082238ms)
Oct  1 10:28:17.807: INFO: (5) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 7.190799ms)
Oct  1 10:28:17.808: INFO: (5) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/tlsrewritem... (200; 7.850225ms)
Oct  1 10:28:17.808: INFO: (5) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname1/proxy/: foo (200; 7.819039ms)
Oct  1 10:28:17.808: INFO: (5) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname2/proxy/: bar (200; 7.799696ms)
Oct  1 10:28:17.808: INFO: (5) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">test<... (200; 7.610077ms)
Oct  1 10:28:17.808: INFO: (5) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname2/proxy/: tls qux (200; 8.111918ms)
Oct  1 10:28:17.808: INFO: (5) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname2/proxy/: bar (200; 8.28886ms)
Oct  1 10:28:17.808: INFO: (5) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname1/proxy/: foo (200; 8.14249ms)
Oct  1 10:28:17.808: INFO: (5) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname1/proxy/: tls baz (200; 8.120301ms)
Oct  1 10:28:17.808: INFO: (5) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 8.228055ms)
Oct  1 10:28:17.808: INFO: (5) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 8.30275ms)
Oct  1 10:28:17.808: INFO: (5) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/rewriteme">test</a> (200; 8.223169ms)
Oct  1 10:28:17.814: INFO: (6) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:460/proxy/: tls baz (200; 5.566029ms)
Oct  1 10:28:17.814: INFO: (6) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">... (200; 6.139553ms)
Oct  1 10:28:17.814: INFO: (6) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 6.101332ms)
Oct  1 10:28:17.815: INFO: (6) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 6.680839ms)
Oct  1 10:28:17.815: INFO: (6) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 6.808837ms)
Oct  1 10:28:17.815: INFO: (6) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/tlsrewritem... (200; 6.865401ms)
Oct  1 10:28:17.815: INFO: (6) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname2/proxy/: tls qux (200; 6.805686ms)
Oct  1 10:28:17.815: INFO: (6) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">test<... (200; 6.90048ms)
Oct  1 10:28:17.815: INFO: (6) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:462/proxy/: tls qux (200; 7.156224ms)
Oct  1 10:28:17.815: INFO: (6) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname2/proxy/: bar (200; 7.124315ms)
Oct  1 10:28:17.816: INFO: (6) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 7.5995ms)
Oct  1 10:28:17.816: INFO: (6) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname2/proxy/: bar (200; 7.761443ms)
Oct  1 10:28:17.816: INFO: (6) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/rewriteme">test</a> (200; 7.728204ms)
Oct  1 10:28:17.816: INFO: (6) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname1/proxy/: tls baz (200; 7.879626ms)
Oct  1 10:28:17.816: INFO: (6) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname1/proxy/: foo (200; 8.170614ms)
Oct  1 10:28:17.817: INFO: (6) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname1/proxy/: foo (200; 8.399899ms)
Oct  1 10:28:17.826: INFO: (7) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname2/proxy/: bar (200; 9.405288ms)
Oct  1 10:28:17.826: INFO: (7) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 9.528998ms)
Oct  1 10:28:17.826: INFO: (7) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">... (200; 9.337071ms)
Oct  1 10:28:17.826: INFO: (7) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 9.554232ms)
Oct  1 10:28:17.826: INFO: (7) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:460/proxy/: tls baz (200; 9.417001ms)
Oct  1 10:28:17.826: INFO: (7) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname1/proxy/: foo (200; 9.423137ms)
Oct  1 10:28:17.826: INFO: (7) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname2/proxy/: tls qux (200; 9.409269ms)
Oct  1 10:28:17.826: INFO: (7) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname1/proxy/: tls baz (200; 9.47622ms)
Oct  1 10:28:17.826: INFO: (7) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 9.413949ms)
Oct  1 10:28:17.826: INFO: (7) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/tlsrewritem... (200; 9.546268ms)
Oct  1 10:28:17.826: INFO: (7) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:462/proxy/: tls qux (200; 9.531793ms)
Oct  1 10:28:17.826: INFO: (7) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/rewriteme">test</a> (200; 9.569408ms)
Oct  1 10:28:17.826: INFO: (7) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">test<... (200; 9.559247ms)
Oct  1 10:28:17.826: INFO: (7) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 9.528737ms)
Oct  1 10:28:17.826: INFO: (7) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname2/proxy/: bar (200; 9.661003ms)
Oct  1 10:28:17.826: INFO: (7) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname1/proxy/: foo (200; 9.782587ms)
Oct  1 10:28:17.831: INFO: (8) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 4.355856ms)
Oct  1 10:28:17.831: INFO: (8) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">test<... (200; 4.314104ms)
Oct  1 10:28:17.832: INFO: (8) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/tlsrewritem... (200; 5.366568ms)
Oct  1 10:28:17.832: INFO: (8) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 5.43507ms)
Oct  1 10:28:17.833: INFO: (8) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">... (200; 5.910016ms)
Oct  1 10:28:17.833: INFO: (8) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:460/proxy/: tls baz (200; 5.794112ms)
Oct  1 10:28:17.833: INFO: (8) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 5.91607ms)
Oct  1 10:28:17.833: INFO: (8) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 6.212831ms)
Oct  1 10:28:17.833: INFO: (8) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname1/proxy/: foo (200; 6.113978ms)
Oct  1 10:28:17.833: INFO: (8) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/rewriteme">test</a> (200; 6.542497ms)
Oct  1 10:28:17.833: INFO: (8) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname2/proxy/: bar (200; 6.391999ms)
Oct  1 10:28:17.834: INFO: (8) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:462/proxy/: tls qux (200; 6.98966ms)
Oct  1 10:28:17.834: INFO: (8) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname1/proxy/: tls baz (200; 7.532483ms)
Oct  1 10:28:17.834: INFO: (8) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname1/proxy/: foo (200; 7.635186ms)
Oct  1 10:28:17.834: INFO: (8) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname2/proxy/: tls qux (200; 7.872657ms)
Oct  1 10:28:17.835: INFO: (8) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname2/proxy/: bar (200; 7.927796ms)
Oct  1 10:28:17.842: INFO: (9) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 6.962904ms)
Oct  1 10:28:17.842: INFO: (9) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname1/proxy/: tls baz (200; 7.221272ms)
Oct  1 10:28:17.842: INFO: (9) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:460/proxy/: tls baz (200; 7.349429ms)
Oct  1 10:28:17.842: INFO: (9) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/rewriteme">test</a> (200; 7.034995ms)
Oct  1 10:28:17.842: INFO: (9) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">test<... (200; 7.128517ms)
Oct  1 10:28:17.842: INFO: (9) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname1/proxy/: foo (200; 7.10429ms)
Oct  1 10:28:17.842: INFO: (9) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">... (200; 7.26928ms)
Oct  1 10:28:17.842: INFO: (9) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/tlsrewritem... (200; 7.184171ms)
Oct  1 10:28:17.842: INFO: (9) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname2/proxy/: bar (200; 7.030965ms)
Oct  1 10:28:17.842: INFO: (9) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 7.288934ms)
Oct  1 10:28:17.843: INFO: (9) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 7.348466ms)
Oct  1 10:28:17.843: INFO: (9) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname2/proxy/: bar (200; 7.350182ms)
Oct  1 10:28:17.843: INFO: (9) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:462/proxy/: tls qux (200; 7.446522ms)
Oct  1 10:28:17.843: INFO: (9) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname2/proxy/: tls qux (200; 7.704856ms)
Oct  1 10:28:17.843: INFO: (9) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname1/proxy/: foo (200; 7.805075ms)
Oct  1 10:28:17.843: INFO: (9) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 8.439537ms)
Oct  1 10:28:17.847: INFO: (10) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 4.001287ms)
Oct  1 10:28:17.848: INFO: (10) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">... (200; 3.985932ms)
Oct  1 10:28:17.849: INFO: (10) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/tlsrewritem... (200; 4.999457ms)
Oct  1 10:28:17.849: INFO: (10) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname2/proxy/: bar (200; 5.795173ms)
Oct  1 10:28:17.850: INFO: (10) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname2/proxy/: tls qux (200; 5.930101ms)
Oct  1 10:28:17.850: INFO: (10) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:462/proxy/: tls qux (200; 5.845224ms)
Oct  1 10:28:17.851: INFO: (10) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 7.262844ms)
Oct  1 10:28:17.851: INFO: (10) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname1/proxy/: tls baz (200; 7.222243ms)
Oct  1 10:28:17.851: INFO: (10) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname1/proxy/: foo (200; 7.336104ms)
Oct  1 10:28:17.852: INFO: (10) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname2/proxy/: bar (200; 8.344719ms)
Oct  1 10:28:17.852: INFO: (10) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname1/proxy/: foo (200; 8.607217ms)
Oct  1 10:28:17.852: INFO: (10) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 8.873466ms)
Oct  1 10:28:17.852: INFO: (10) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/rewriteme">test</a> (200; 8.752563ms)
Oct  1 10:28:17.853: INFO: (10) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:460/proxy/: tls baz (200; 8.934016ms)
Oct  1 10:28:17.853: INFO: (10) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 8.777522ms)
Oct  1 10:28:17.853: INFO: (10) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">test<... (200; 8.785187ms)
Oct  1 10:28:17.856: INFO: (11) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">... (200; 3.358412ms)
Oct  1 10:28:17.856: INFO: (11) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/rewriteme">test</a> (200; 3.343274ms)
Oct  1 10:28:17.856: INFO: (11) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">test<... (200; 3.472669ms)
Oct  1 10:28:17.856: INFO: (11) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/tlsrewritem... (200; 3.823688ms)
Oct  1 10:28:17.859: INFO: (11) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname1/proxy/: tls baz (200; 5.778447ms)
Oct  1 10:28:17.859: INFO: (11) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 5.80017ms)
Oct  1 10:28:17.859: INFO: (11) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 5.867638ms)
Oct  1 10:28:17.859: INFO: (11) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:460/proxy/: tls baz (200; 5.846789ms)
Oct  1 10:28:17.859: INFO: (11) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname2/proxy/: tls qux (200; 5.838926ms)
Oct  1 10:28:17.859: INFO: (11) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:462/proxy/: tls qux (200; 5.914318ms)
Oct  1 10:28:17.859: INFO: (11) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 5.919696ms)
Oct  1 10:28:17.859: INFO: (11) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname1/proxy/: foo (200; 6.25999ms)
Oct  1 10:28:17.859: INFO: (11) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 6.265381ms)
Oct  1 10:28:17.859: INFO: (11) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname2/proxy/: bar (200; 6.313831ms)
Oct  1 10:28:17.859: INFO: (11) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname1/proxy/: foo (200; 6.551465ms)
Oct  1 10:28:17.860: INFO: (11) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname2/proxy/: bar (200; 6.933973ms)
Oct  1 10:28:17.864: INFO: (12) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">test<... (200; 4.042704ms)
Oct  1 10:28:17.864: INFO: (12) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 4.026115ms)
Oct  1 10:28:17.864: INFO: (12) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 3.97664ms)
Oct  1 10:28:17.864: INFO: (12) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:460/proxy/: tls baz (200; 4.507673ms)
Oct  1 10:28:17.864: INFO: (12) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 3.897179ms)
Oct  1 10:28:17.864: INFO: (12) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">... (200; 4.502446ms)
Oct  1 10:28:17.864: INFO: (12) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname2/proxy/: bar (200; 4.046367ms)
Oct  1 10:28:17.865: INFO: (12) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/rewriteme">test</a> (200; 4.617284ms)
Oct  1 10:28:17.865: INFO: (12) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname1/proxy/: foo (200; 4.344878ms)
Oct  1 10:28:17.865: INFO: (12) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:462/proxy/: tls qux (200; 4.132394ms)
Oct  1 10:28:17.865: INFO: (12) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/tlsrewritem... (200; 4.440287ms)
Oct  1 10:28:17.865: INFO: (12) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 4.318796ms)
Oct  1 10:28:17.866: INFO: (12) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname2/proxy/: bar (200; 5.482692ms)
Oct  1 10:28:17.866: INFO: (12) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname2/proxy/: tls qux (200; 6.492374ms)
Oct  1 10:28:17.866: INFO: (12) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname1/proxy/: tls baz (200; 5.990562ms)
Oct  1 10:28:17.866: INFO: (12) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname1/proxy/: foo (200; 5.837195ms)
Oct  1 10:28:17.870: INFO: (13) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">test<... (200; 3.271639ms)
Oct  1 10:28:17.871: INFO: (13) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">... (200; 3.83534ms)
Oct  1 10:28:17.871: INFO: (13) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 3.969924ms)
Oct  1 10:28:17.871: INFO: (13) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/rewriteme">test</a> (200; 4.776894ms)
Oct  1 10:28:17.872: INFO: (13) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:460/proxy/: tls baz (200; 4.976567ms)
Oct  1 10:28:17.872: INFO: (13) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 5.231307ms)
Oct  1 10:28:17.872: INFO: (13) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname2/proxy/: tls qux (200; 5.097499ms)
Oct  1 10:28:17.872: INFO: (13) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:462/proxy/: tls qux (200; 5.391998ms)
Oct  1 10:28:17.872: INFO: (13) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname2/proxy/: bar (200; 5.15441ms)
Oct  1 10:28:17.872: INFO: (13) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 5.474002ms)
Oct  1 10:28:17.872: INFO: (13) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname1/proxy/: foo (200; 5.661226ms)
Oct  1 10:28:17.872: INFO: (13) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname2/proxy/: bar (200; 5.629646ms)
Oct  1 10:28:17.873: INFO: (13) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/tlsrewritem... (200; 5.789872ms)
Oct  1 10:28:17.873: INFO: (13) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 5.720873ms)
Oct  1 10:28:17.873: INFO: (13) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname1/proxy/: tls baz (200; 6.078239ms)
Oct  1 10:28:17.873: INFO: (13) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname1/proxy/: foo (200; 6.141323ms)
Oct  1 10:28:17.876: INFO: (14) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">... (200; 2.530855ms)
Oct  1 10:28:17.877: INFO: (14) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/rewriteme">test</a> (200; 3.569756ms)
Oct  1 10:28:17.877: INFO: (14) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 3.777814ms)
Oct  1 10:28:17.877: INFO: (14) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">test<... (200; 3.95105ms)
Oct  1 10:28:17.877: INFO: (14) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 3.894127ms)
Oct  1 10:28:17.878: INFO: (14) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:462/proxy/: tls qux (200; 3.734086ms)
Oct  1 10:28:17.878: INFO: (14) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 3.694393ms)
Oct  1 10:28:17.878: INFO: (14) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/tlsrewritem... (200; 4.158806ms)
Oct  1 10:28:17.878: INFO: (14) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 3.903308ms)
Oct  1 10:28:17.879: INFO: (14) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:460/proxy/: tls baz (200; 4.328423ms)
Oct  1 10:28:17.879: INFO: (14) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname1/proxy/: tls baz (200; 5.289637ms)
Oct  1 10:28:17.880: INFO: (14) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname1/proxy/: foo (200; 6.596835ms)
Oct  1 10:28:17.880: INFO: (14) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname2/proxy/: bar (200; 6.058259ms)
Oct  1 10:28:17.880: INFO: (14) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname1/proxy/: foo (200; 6.140576ms)
Oct  1 10:28:17.880: INFO: (14) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname2/proxy/: bar (200; 6.024942ms)
Oct  1 10:28:17.880: INFO: (14) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname2/proxy/: tls qux (200; 5.747505ms)
Oct  1 10:28:17.883: INFO: (15) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">... (200; 2.649016ms)
Oct  1 10:28:17.886: INFO: (15) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/tlsrewritem... (200; 5.643436ms)
Oct  1 10:28:17.886: INFO: (15) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:462/proxy/: tls qux (200; 5.534513ms)
Oct  1 10:28:17.886: INFO: (15) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">test<... (200; 5.613721ms)
Oct  1 10:28:17.886: INFO: (15) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:460/proxy/: tls baz (200; 5.758701ms)
Oct  1 10:28:17.886: INFO: (15) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 5.757385ms)
Oct  1 10:28:17.887: INFO: (15) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname2/proxy/: tls qux (200; 6.444054ms)
Oct  1 10:28:17.887: INFO: (15) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname1/proxy/: foo (200; 6.582381ms)
Oct  1 10:28:17.887: INFO: (15) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 6.499479ms)
Oct  1 10:28:17.887: INFO: (15) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 6.622753ms)
Oct  1 10:28:17.887: INFO: (15) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 6.783351ms)
Oct  1 10:28:17.887: INFO: (15) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname1/proxy/: tls baz (200; 6.912569ms)
Oct  1 10:28:17.887: INFO: (15) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname1/proxy/: foo (200; 6.982949ms)
Oct  1 10:28:17.887: INFO: (15) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/rewriteme">test</a> (200; 7.060338ms)
Oct  1 10:28:17.887: INFO: (15) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname2/proxy/: bar (200; 7.141889ms)
Oct  1 10:28:17.887: INFO: (15) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname2/proxy/: bar (200; 7.13495ms)
Oct  1 10:28:17.892: INFO: (16) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 4.694934ms)
Oct  1 10:28:17.892: INFO: (16) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/rewriteme">test</a> (200; 4.606444ms)
Oct  1 10:28:17.892: INFO: (16) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">... (200; 5.02869ms)
Oct  1 10:28:17.893: INFO: (16) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname2/proxy/: tls qux (200; 4.943152ms)
Oct  1 10:28:17.893: INFO: (16) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:462/proxy/: tls qux (200; 5.077591ms)
Oct  1 10:28:17.893: INFO: (16) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 5.602742ms)
Oct  1 10:28:17.894: INFO: (16) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname2/proxy/: bar (200; 6.056052ms)
Oct  1 10:28:17.894: INFO: (16) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname1/proxy/: foo (200; 6.160427ms)
Oct  1 10:28:17.894: INFO: (16) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 6.248453ms)
Oct  1 10:28:17.894: INFO: (16) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 6.289026ms)
Oct  1 10:28:17.894: INFO: (16) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname2/proxy/: bar (200; 6.446167ms)
Oct  1 10:28:17.894: INFO: (16) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">test<... (200; 6.433361ms)
Oct  1 10:28:17.894: INFO: (16) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname1/proxy/: tls baz (200; 6.588924ms)
Oct  1 10:28:17.894: INFO: (16) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/tlsrewritem... (200; 6.633741ms)
Oct  1 10:28:17.894: INFO: (16) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:460/proxy/: tls baz (200; 6.732834ms)
Oct  1 10:28:17.894: INFO: (16) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname1/proxy/: foo (200; 6.698779ms)
Oct  1 10:28:17.897: INFO: (17) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:462/proxy/: tls qux (200; 2.556953ms)
Oct  1 10:28:17.897: INFO: (17) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">... (200; 2.908008ms)
Oct  1 10:28:17.898: INFO: (17) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/tlsrewritem... (200; 2.850347ms)
Oct  1 10:28:17.898: INFO: (17) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 3.205163ms)
Oct  1 10:28:17.901: INFO: (17) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname2/proxy/: tls qux (200; 6.07939ms)
Oct  1 10:28:17.901: INFO: (17) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 6.149488ms)
Oct  1 10:28:17.901: INFO: (17) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname1/proxy/: foo (200; 6.518673ms)
Oct  1 10:28:17.901: INFO: (17) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:460/proxy/: tls baz (200; 6.206298ms)
Oct  1 10:28:17.901: INFO: (17) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">test<... (200; 6.240795ms)
Oct  1 10:28:17.901: INFO: (17) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname1/proxy/: tls baz (200; 6.450234ms)
Oct  1 10:28:17.901: INFO: (17) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 6.595987ms)
Oct  1 10:28:17.901: INFO: (17) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname2/proxy/: bar (200; 6.711755ms)
Oct  1 10:28:17.901: INFO: (17) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 6.670408ms)
Oct  1 10:28:17.902: INFO: (17) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname1/proxy/: foo (200; 6.725806ms)
Oct  1 10:28:17.902: INFO: (17) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname2/proxy/: bar (200; 6.911658ms)
Oct  1 10:28:17.902: INFO: (17) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/rewriteme">test</a> (200; 7.287069ms)
Oct  1 10:28:17.908: INFO: (18) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 5.673461ms)
Oct  1 10:28:17.908: INFO: (18) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 5.728261ms)
Oct  1 10:28:17.908: INFO: (18) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname2/proxy/: tls qux (200; 5.934381ms)
Oct  1 10:28:17.908: INFO: (18) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/rewriteme">test</a> (200; 5.820092ms)
Oct  1 10:28:17.908: INFO: (18) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname1/proxy/: foo (200; 5.972769ms)
Oct  1 10:28:17.908: INFO: (18) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/tlsrewritem... (200; 5.884672ms)
Oct  1 10:28:17.908: INFO: (18) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 5.831713ms)
Oct  1 10:28:17.908: INFO: (18) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:460/proxy/: tls baz (200; 5.808543ms)
Oct  1 10:28:17.908: INFO: (18) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">... (200; 6.003016ms)
Oct  1 10:28:17.908: INFO: (18) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname1/proxy/: tls baz (200; 5.928332ms)
Oct  1 10:28:17.908: INFO: (18) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:462/proxy/: tls qux (200; 5.881696ms)
Oct  1 10:28:17.909: INFO: (18) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 6.249476ms)
Oct  1 10:28:17.909: INFO: (18) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname2/proxy/: bar (200; 6.730804ms)
Oct  1 10:28:17.909: INFO: (18) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname1/proxy/: foo (200; 6.789737ms)
Oct  1 10:28:17.909: INFO: (18) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">test<... (200; 6.617923ms)
Oct  1 10:28:17.909: INFO: (18) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname2/proxy/: bar (200; 6.877887ms)
Oct  1 10:28:17.913: INFO: (19) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 3.988868ms)
Oct  1 10:28:17.914: INFO: (19) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:460/proxy/: tls baz (200; 4.093395ms)
Oct  1 10:28:17.915: INFO: (19) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">... (200; 5.299309ms)
Oct  1 10:28:17.915: INFO: (19) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 5.388523ms)
Oct  1 10:28:17.915: INFO: (19) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname2/proxy/: bar (200; 5.883098ms)
Oct  1 10:28:17.915: INFO: (19) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz/proxy/rewriteme">test</a> (200; 5.182625ms)
Oct  1 10:28:17.916: INFO: (19) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname1/proxy/: foo (200; 5.336372ms)
Oct  1 10:28:17.916: INFO: (19) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:443/proxy/tlsrewritem... (200; 5.730034ms)
Oct  1 10:28:17.916: INFO: (19) /api/v1/namespaces/proxy-6429/services/proxy-service-lhmdt:portname2/proxy/: bar (200; 5.30188ms)
Oct  1 10:28:17.916: INFO: (19) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:162/proxy/: bar (200; 5.923499ms)
Oct  1 10:28:17.916: INFO: (19) /api/v1/namespaces/proxy-6429/pods/http:proxy-service-lhmdt-rfhpz:160/proxy/: foo (200; 5.543472ms)
Oct  1 10:28:17.916: INFO: (19) /api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/: <a href="/api/v1/namespaces/proxy-6429/pods/proxy-service-lhmdt-rfhpz:1080/proxy/rewriteme">test<... (200; 5.993791ms)
Oct  1 10:28:17.916: INFO: (19) /api/v1/namespaces/proxy-6429/services/http:proxy-service-lhmdt:portname1/proxy/: foo (200; 5.912792ms)
Oct  1 10:28:17.916: INFO: (19) /api/v1/namespaces/proxy-6429/pods/https:proxy-service-lhmdt-rfhpz:462/proxy/: tls qux (200; 5.78758ms)
Oct  1 10:28:17.916: INFO: (19) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname2/proxy/: tls qux (200; 6.518303ms)
Oct  1 10:28:17.916: INFO: (19) /api/v1/namespaces/proxy-6429/services/https:proxy-service-lhmdt:tlsportname1/proxy/: tls baz (200; 6.471669ms)
STEP: deleting ReplicationController proxy-service-lhmdt in namespace proxy-6429, will wait for the garbage collector to delete the pods
I1001 10:28:17.918957      17 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 10:28:17.918983      17 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Oct  1 10:28:17.973: INFO: Deleting ReplicationController proxy-service-lhmdt took: 4.579978ms
Oct  1 10:28:18.274: INFO: Terminating ReplicationController proxy-service-lhmdt pods took: 300.365053ms
I1001 10:28:18.274061      17 controller_utils.go:810] Ignoring inactive pod proxy-6429/proxy-service-lhmdt-rfhpz in state Running, deletion time 2019-10-01 10:28:19 +0000 UTC
[AfterEach] version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:28:19.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6429" for this suite.
Oct  1 10:28:25.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:28:25.942: INFO: namespace proxy-6429 deletion completed in 6.065481964s

• [SLOW TEST:12.340 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:28:25.942: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:28:25.964: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:28:27.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6582" for this suite.
Oct  1 10:29:11.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:29:12.048: INFO: namespace pods-6582 deletion completed in 44.057734411s

• [SLOW TEST:46.106 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:29:12.049: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:30:12.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1742" for this suite.
Oct  1 10:30:40.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:30:40.144: INFO: namespace container-probe-1742 deletion completed in 28.062490067s

• [SLOW TEST:88.096 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:30:40.145: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:30:40.168: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Creating first CR 
Oct  1 10:30:40.269: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-01T10:30:40Z generation:1 name:name1 resourceVersion:15811 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:4cb1506e-1025-49b3-856c-0ca64b442d58] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Oct  1 10:30:50.273: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-01T10:30:50Z generation:1 name:name2 resourceVersion:15827 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:ce8a92b1-db93-458c-a61a-07fde5540806] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Oct  1 10:31:00.277: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-01T10:30:40Z generation:2 name:name1 resourceVersion:15841 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:4cb1506e-1025-49b3-856c-0ca64b442d58] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Oct  1 10:31:10.281: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-01T10:30:50Z generation:2 name:name2 resourceVersion:15855 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:ce8a92b1-db93-458c-a61a-07fde5540806] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Oct  1 10:31:20.286: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-01T10:30:40Z generation:2 name:name1 resourceVersion:15869 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:4cb1506e-1025-49b3-856c-0ca64b442d58] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Oct  1 10:31:30.292: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-01T10:30:50Z generation:2 name:name2 resourceVersion:15884 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:ce8a92b1-db93-458c-a61a-07fde5540806] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:31:40.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-7352" for this suite.
Oct  1 10:31:46.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:31:46.862: INFO: namespace crd-watch-7352 deletion completed in 6.059516942s

• [SLOW TEST:66.717 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:31:46.862: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:31:46.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-6942" for this suite.
Oct  1 10:31:52.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:31:52.945: INFO: namespace tables-6942 deletion completed in 6.06019833s

• [SLOW TEST:6.083 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:31:52.945: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  1 10:31:52.967: INFO: Waiting up to 5m0s for pod "downwardapi-volume-298b43e6-e374-481b-aa9d-8edc6fdb5b01" in namespace "projected-9901" to be "success or failure"
Oct  1 10:31:52.969: INFO: Pod "downwardapi-volume-298b43e6-e374-481b-aa9d-8edc6fdb5b01": Phase="Pending", Reason="", readiness=false. Elapsed: 2.379131ms
Oct  1 10:31:54.972: INFO: Pod "downwardapi-volume-298b43e6-e374-481b-aa9d-8edc6fdb5b01": Phase="Running", Reason="", readiness=true. Elapsed: 2.005521547s
Oct  1 10:31:56.975: INFO: Pod "downwardapi-volume-298b43e6-e374-481b-aa9d-8edc6fdb5b01": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008530549s
STEP: Saw pod success
Oct  1 10:31:56.975: INFO: Pod "downwardapi-volume-298b43e6-e374-481b-aa9d-8edc6fdb5b01" satisfied condition "success or failure"
Oct  1 10:31:56.977: INFO: Trying to get logs from node ip-172-31-16-136 pod downwardapi-volume-298b43e6-e374-481b-aa9d-8edc6fdb5b01 container client-container: <nil>
STEP: delete the pod
Oct  1 10:31:56.998: INFO: Waiting for pod downwardapi-volume-298b43e6-e374-481b-aa9d-8edc6fdb5b01 to disappear
Oct  1 10:31:57.004: INFO: Pod downwardapi-volume-298b43e6-e374-481b-aa9d-8edc6fdb5b01 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:31:57.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9901" for this suite.
Oct  1 10:32:03.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:32:03.066: INFO: namespace projected-9901 deletion completed in 6.060231582s

• [SLOW TEST:10.122 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:32:03.067: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Oct  1 10:32:05.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec pod-sharedvolume-c0af2302-34a4-440e-82c1-646fff5f6208 -c busybox-main-container --namespace=emptydir-11 -- cat /usr/share/volumeshare/shareddata.txt'
Oct  1 10:32:05.368: INFO: stderr: ""
Oct  1 10:32:05.368: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:32:05.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-11" for this suite.
Oct  1 10:32:11.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:32:11.435: INFO: namespace emptydir-11 deletion completed in 6.063289349s

• [SLOW TEST:8.368 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:32:11.435: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Oct  1 10:32:13.471: INFO: Pod pod-hostip-28e170dc-e51c-432d-a046-a479264a5aea has hostIP: 172.31.16.136
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:32:13.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2638" for this suite.
Oct  1 10:32:41.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:32:41.530: INFO: namespace pods-2638 deletion completed in 28.056497549s

• [SLOW TEST:30.095 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:32:41.530: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Oct  1 10:32:41.547: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct  1 10:32:41.553: INFO: Waiting for terminating namespaces to be deleted...
Oct  1 10:32:41.555: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-16-136 before test
Oct  1 10:32:41.558: INFO: sonobuoy-systemd-logs-daemon-set-c998de73b1b44522-6mdfj from sonobuoy started at 2019-10-01 09:21:21 +0000 UTC (2 container statuses recorded)
Oct  1 10:32:41.558: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct  1 10:32:41.558: INFO: 	Container systemd-logs ready: true, restart count 1
Oct  1 10:32:41.558: INFO: sonobuoy from sonobuoy started at 2019-10-01 09:21:20 +0000 UTC (1 container statuses recorded)
Oct  1 10:32:41.558: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct  1 10:32:41.558: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-29-44 before test
Oct  1 10:32:41.570: INFO: sonobuoy-e2e-job-41fbe38c4f734fd3 from sonobuoy started at 2019-10-01 09:21:21 +0000 UTC (2 container statuses recorded)
Oct  1 10:32:41.570: INFO: 	Container e2e ready: true, restart count 0
Oct  1 10:32:41.570: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  1 10:32:41.570: INFO: coredns-9b8997588-8dd8w from kube-system started at 2019-10-01 09:06:34 +0000 UTC (1 container statuses recorded)
Oct  1 10:32:41.570: INFO: 	Container coredns ready: true, restart count 0
Oct  1 10:32:41.570: INFO: sonobuoy-systemd-logs-daemon-set-c998de73b1b44522-4jgxd from sonobuoy started at 2019-10-01 09:21:21 +0000 UTC (2 container statuses recorded)
Oct  1 10:32:41.570: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct  1 10:32:41.570: INFO: 	Container systemd-logs ready: true, restart count 1
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
I1001 10:32:41.573063      17 reflector.go:120] Starting reflector *v1.Event (0s) from k8s.io/kubernetes/test/e2e/common/events.go:136
I1001 10:32:41.573090      17 reflector.go:158] Listing and watching *v1.Event from k8s.io/kubernetes/test/e2e/common/events.go:136
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15c97f581e406db5], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15c97f581ef47632], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:32:42.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1369" for this suite.
Oct  1 10:32:48.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:32:48.643: INFO: namespace sched-pred-1369 deletion completed in 6.05878926s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

I1001 10:32:48.643849      17 request.go:706] Error in request: resource name may not be empty
• [SLOW TEST:7.114 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:32:48.644: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Oct  1 10:32:48.672: INFO: Waiting up to 5m0s for pod "downward-api-eea08288-dd06-49f0-8af3-0c6e1090dcfb" in namespace "downward-api-9104" to be "success or failure"
Oct  1 10:32:48.674: INFO: Pod "downward-api-eea08288-dd06-49f0-8af3-0c6e1090dcfb": Phase="Pending", Reason="", readiness=false. Elapsed: 1.693425ms
Oct  1 10:32:50.677: INFO: Pod "downward-api-eea08288-dd06-49f0-8af3-0c6e1090dcfb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004899047s
STEP: Saw pod success
Oct  1 10:32:50.677: INFO: Pod "downward-api-eea08288-dd06-49f0-8af3-0c6e1090dcfb" satisfied condition "success or failure"
Oct  1 10:32:50.679: INFO: Trying to get logs from node ip-172-31-16-136 pod downward-api-eea08288-dd06-49f0-8af3-0c6e1090dcfb container dapi-container: <nil>
STEP: delete the pod
Oct  1 10:32:50.691: INFO: Waiting for pod downward-api-eea08288-dd06-49f0-8af3-0c6e1090dcfb to disappear
Oct  1 10:32:50.693: INFO: Pod downward-api-eea08288-dd06-49f0-8af3-0c6e1090dcfb no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:32:50.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9104" for this suite.
Oct  1 10:32:56.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:32:56.757: INFO: namespace downward-api-9104 deletion completed in 6.061506653s

• [SLOW TEST:8.113 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:32:56.757: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Oct  1 10:33:00.803: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5394 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 10:33:00.803: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 10:33:00.933: INFO: Exec stderr: ""
Oct  1 10:33:00.933: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5394 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 10:33:00.933: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 10:33:01.100: INFO: Exec stderr: ""
Oct  1 10:33:01.100: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5394 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 10:33:01.100: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 10:33:01.232: INFO: Exec stderr: ""
Oct  1 10:33:01.232: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5394 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 10:33:01.232: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 10:33:01.351: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Oct  1 10:33:01.351: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5394 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 10:33:01.351: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 10:33:01.476: INFO: Exec stderr: ""
Oct  1 10:33:01.476: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5394 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 10:33:01.476: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 10:33:01.611: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Oct  1 10:33:01.611: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5394 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 10:33:01.611: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 10:33:01.753: INFO: Exec stderr: ""
Oct  1 10:33:01.753: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5394 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 10:33:01.753: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 10:33:01.889: INFO: Exec stderr: ""
Oct  1 10:33:01.889: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5394 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 10:33:01.889: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 10:33:02.019: INFO: Exec stderr: ""
Oct  1 10:33:02.019: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5394 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 10:33:02.019: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 10:33:02.157: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:33:02.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5394" for this suite.
Oct  1 10:33:46.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:33:46.217: INFO: namespace e2e-kubelet-etc-hosts-5394 deletion completed in 44.057560527s

• [SLOW TEST:49.460 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:33:46.217: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:34:03.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7017" for this suite.
Oct  1 10:34:09.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:34:09.327: INFO: namespace resourcequota-7017 deletion completed in 6.056941453s

• [SLOW TEST:23.109 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:34:09.327: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:34:09.353: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Oct  1 10:34:09.361: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct  1 10:34:14.364: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct  1 10:34:14.364: INFO: Creating deployment "test-rolling-update-deployment"
Oct  1 10:34:14.367: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Oct  1 10:34:14.371: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Oct  1 10:34:16.376: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Oct  1 10:34:16.378: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Oct  1 10:34:16.383: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-5566 /apis/apps/v1/namespaces/deployment-5566/deployments/test-rolling-update-deployment edebca26-2d50-48f9-9665-ef46da9f8aab 16371 1 2019-10-01 10:34:14 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002ecbd38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-10-01 10:34:14 +0000 UTC,LastTransitionTime:2019-10-01 10:34:14 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2019-10-01 10:34:15 +0000 UTC,LastTransitionTime:2019-10-01 10:34:14 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Oct  1 10:34:16.385: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-5566 /apis/apps/v1/namespaces/deployment-5566/replicasets/test-rolling-update-deployment-55d946486 5db7ceb1-5328-4205-bc55-91c4192b2d73 16360 1 2019-10-01 10:34:14 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment edebca26-2d50-48f9-9665-ef46da9f8aab 0xc004bd2230 0xc004bd2231}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004bd2298 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct  1 10:34:16.385: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Oct  1 10:34:16.385: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-5566 /apis/apps/v1/namespaces/deployment-5566/replicasets/test-rolling-update-controller 336c64bf-980f-455b-8246-1adf2f83ea07 16370 2 2019-10-01 10:34:09 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment edebca26-2d50-48f9-9665-ef46da9f8aab 0xc004bd2167 0xc004bd2168}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004bd21c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct  1 10:34:16.388: INFO: Pod "test-rolling-update-deployment-55d946486-7ngc6" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-7ngc6 test-rolling-update-deployment-55d946486- deployment-5566 /api/v1/namespaces/deployment-5566/pods/test-rolling-update-deployment-55d946486-7ngc6 a940fb54-7a7e-4e93-9241-6218fd637d9f 16359 0 2019-10-01 10:34:14 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 5db7ceb1-5328-4205-bc55-91c4192b2d73 0xc004bd2720 0xc004bd2721}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-47x5q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-47x5q,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-47x5q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-16-136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:34:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:34:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:34:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:34:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.16.136,PodIP:10.1.63.191,StartTime:2019-10-01 10:34:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-01 10:34:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://8e215b3312cab487d88a6f8093c0d89f9da7b7bfb92444b27363271cc41d6346,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.63.191,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:34:16.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5566" for this suite.
Oct  1 10:34:22.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:34:22.446: INFO: namespace deployment-5566 deletion completed in 6.056537055s

• [SLOW TEST:13.119 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:34:22.446: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Oct  1 10:34:22.693: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  1 10:34:25.704: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:34:25.707: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:34:26.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-5142" for this suite.
Oct  1 10:34:32.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:34:32.872: INFO: namespace crd-webhook-5142 deletion completed in 6.05938662s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:10.434 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:34:32.881: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-c2fba557-0a7b-4d5e-a8bf-7bf9498871df
STEP: Creating a pod to test consume configMaps
Oct  1 10:34:32.913: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f8e61b68-c2cd-4831-8eb5-3bab8fb76b77" in namespace "projected-4436" to be "success or failure"
Oct  1 10:34:32.916: INFO: Pod "pod-projected-configmaps-f8e61b68-c2cd-4831-8eb5-3bab8fb76b77": Phase="Pending", Reason="", readiness=false. Elapsed: 2.603276ms
Oct  1 10:34:34.919: INFO: Pod "pod-projected-configmaps-f8e61b68-c2cd-4831-8eb5-3bab8fb76b77": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005553784s
STEP: Saw pod success
Oct  1 10:34:34.919: INFO: Pod "pod-projected-configmaps-f8e61b68-c2cd-4831-8eb5-3bab8fb76b77" satisfied condition "success or failure"
Oct  1 10:34:34.921: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-projected-configmaps-f8e61b68-c2cd-4831-8eb5-3bab8fb76b77 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 10:34:34.943: INFO: Waiting for pod pod-projected-configmaps-f8e61b68-c2cd-4831-8eb5-3bab8fb76b77 to disappear
Oct  1 10:34:34.950: INFO: Pod pod-projected-configmaps-f8e61b68-c2cd-4831-8eb5-3bab8fb76b77 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:34:34.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4436" for this suite.
Oct  1 10:34:40.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:34:41.011: INFO: namespace projected-4436 deletion completed in 6.058770311s

• [SLOW TEST:8.130 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:34:41.011: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-520.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-520.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-520.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-520.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct  1 10:34:43.057: INFO: DNS probes using dns-test-0d8ef1e0-7384-4390-99cb-0e0b5b6849c2 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-520.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-520.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-520.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-520.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct  1 10:34:45.102: INFO: File wheezy_udp@dns-test-service-3.dns-520.svc.cluster.local from pod  dns-520/dns-test-4f93e37f-4455-49cf-a1fe-8de447360888 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct  1 10:34:45.105: INFO: File jessie_udp@dns-test-service-3.dns-520.svc.cluster.local from pod  dns-520/dns-test-4f93e37f-4455-49cf-a1fe-8de447360888 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct  1 10:34:45.105: INFO: Lookups using dns-520/dns-test-4f93e37f-4455-49cf-a1fe-8de447360888 failed for: [wheezy_udp@dns-test-service-3.dns-520.svc.cluster.local jessie_udp@dns-test-service-3.dns-520.svc.cluster.local]

Oct  1 10:34:50.111: INFO: DNS probes using dns-test-4f93e37f-4455-49cf-a1fe-8de447360888 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-520.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-520.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-520.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-520.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct  1 10:34:52.176: INFO: DNS probes using dns-test-a36a4e0d-50bf-457c-aed2-bfbc0863aa25 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:34:52.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-520" for this suite.
Oct  1 10:34:58.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:34:58.259: INFO: namespace dns-520 deletion completed in 6.059376207s

• [SLOW TEST:17.248 seconds]
[sig-network] DNS
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:34:58.260: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Oct  1 10:35:08.301: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1001 10:35:08.301593      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:35:08.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1844" for this suite.
Oct  1 10:35:14.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:35:14.362: INFO: namespace gc-1844 deletion completed in 6.058852911s

• [SLOW TEST:16.102 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:35:14.362: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-5053/configmap-test-0e1798ee-8d36-4bf8-ba49-be7cf1bc261f
STEP: Creating a pod to test consume configMaps
Oct  1 10:35:14.395: INFO: Waiting up to 5m0s for pod "pod-configmaps-40f7e49b-1792-4f4c-9e9b-74bdbe0e79cf" in namespace "configmap-5053" to be "success or failure"
Oct  1 10:35:14.397: INFO: Pod "pod-configmaps-40f7e49b-1792-4f4c-9e9b-74bdbe0e79cf": Phase="Pending", Reason="", readiness=false. Elapsed: 1.698371ms
Oct  1 10:35:16.400: INFO: Pod "pod-configmaps-40f7e49b-1792-4f4c-9e9b-74bdbe0e79cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004804687s
STEP: Saw pod success
Oct  1 10:35:16.400: INFO: Pod "pod-configmaps-40f7e49b-1792-4f4c-9e9b-74bdbe0e79cf" satisfied condition "success or failure"
Oct  1 10:35:16.402: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-configmaps-40f7e49b-1792-4f4c-9e9b-74bdbe0e79cf container env-test: <nil>
STEP: delete the pod
Oct  1 10:35:16.411: INFO: Waiting for pod pod-configmaps-40f7e49b-1792-4f4c-9e9b-74bdbe0e79cf to disappear
Oct  1 10:35:16.413: INFO: Pod pod-configmaps-40f7e49b-1792-4f4c-9e9b-74bdbe0e79cf no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:35:16.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5053" for this suite.
Oct  1 10:35:22.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:35:22.476: INFO: namespace configmap-5053 deletion completed in 6.060554842s

• [SLOW TEST:8.114 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:35:22.476: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct  1 10:35:24.515: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:35:24.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7021" for this suite.
Oct  1 10:35:30.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:35:30.585: INFO: namespace container-runtime-7021 deletion completed in 6.057299669s

• [SLOW TEST:8.109 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:35:30.586: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct  1 10:35:32.634: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:35:32.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3120" for this suite.
Oct  1 10:35:38.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:35:38.701: INFO: namespace container-runtime-3120 deletion completed in 6.058235353s

• [SLOW TEST:8.116 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:35:38.702: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  1 10:35:38.729: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d2cc7429-ddf3-4990-8fd7-1cf1f8008222" in namespace "downward-api-4833" to be "success or failure"
Oct  1 10:35:38.731: INFO: Pod "downwardapi-volume-d2cc7429-ddf3-4990-8fd7-1cf1f8008222": Phase="Pending", Reason="", readiness=false. Elapsed: 1.644411ms
Oct  1 10:35:40.734: INFO: Pod "downwardapi-volume-d2cc7429-ddf3-4990-8fd7-1cf1f8008222": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004766633s
STEP: Saw pod success
Oct  1 10:35:40.734: INFO: Pod "downwardapi-volume-d2cc7429-ddf3-4990-8fd7-1cf1f8008222" satisfied condition "success or failure"
Oct  1 10:35:40.736: INFO: Trying to get logs from node ip-172-31-16-136 pod downwardapi-volume-d2cc7429-ddf3-4990-8fd7-1cf1f8008222 container client-container: <nil>
STEP: delete the pod
Oct  1 10:35:40.746: INFO: Waiting for pod downwardapi-volume-d2cc7429-ddf3-4990-8fd7-1cf1f8008222 to disappear
Oct  1 10:35:40.747: INFO: Pod downwardapi-volume-d2cc7429-ddf3-4990-8fd7-1cf1f8008222 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:35:40.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4833" for this suite.
Oct  1 10:35:46.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:35:46.816: INFO: namespace downward-api-4833 deletion completed in 6.066508427s

• [SLOW TEST:8.115 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:35:46.816: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4496.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-4496.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4496.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4496.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4496.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-4496.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4496.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-4496.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4496.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4496.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-4496.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4496.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-4496.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4496.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-4496.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4496.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-4496.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4496.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct  1 10:35:48.861: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4496.svc.cluster.local from pod dns-4496/dns-test-537e29cb-933a-43da-9187-1556c8825f96: the server could not find the requested resource (get pods dns-test-537e29cb-933a-43da-9187-1556c8825f96)
Oct  1 10:35:48.863: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4496.svc.cluster.local from pod dns-4496/dns-test-537e29cb-933a-43da-9187-1556c8825f96: the server could not find the requested resource (get pods dns-test-537e29cb-933a-43da-9187-1556c8825f96)
Oct  1 10:35:48.865: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4496.svc.cluster.local from pod dns-4496/dns-test-537e29cb-933a-43da-9187-1556c8825f96: the server could not find the requested resource (get pods dns-test-537e29cb-933a-43da-9187-1556c8825f96)
Oct  1 10:35:48.867: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4496.svc.cluster.local from pod dns-4496/dns-test-537e29cb-933a-43da-9187-1556c8825f96: the server could not find the requested resource (get pods dns-test-537e29cb-933a-43da-9187-1556c8825f96)
Oct  1 10:35:48.873: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4496.svc.cluster.local from pod dns-4496/dns-test-537e29cb-933a-43da-9187-1556c8825f96: the server could not find the requested resource (get pods dns-test-537e29cb-933a-43da-9187-1556c8825f96)
Oct  1 10:35:48.876: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4496.svc.cluster.local from pod dns-4496/dns-test-537e29cb-933a-43da-9187-1556c8825f96: the server could not find the requested resource (get pods dns-test-537e29cb-933a-43da-9187-1556c8825f96)
Oct  1 10:35:48.878: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4496.svc.cluster.local from pod dns-4496/dns-test-537e29cb-933a-43da-9187-1556c8825f96: the server could not find the requested resource (get pods dns-test-537e29cb-933a-43da-9187-1556c8825f96)
Oct  1 10:35:48.880: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4496.svc.cluster.local from pod dns-4496/dns-test-537e29cb-933a-43da-9187-1556c8825f96: the server could not find the requested resource (get pods dns-test-537e29cb-933a-43da-9187-1556c8825f96)
Oct  1 10:35:48.884: INFO: Lookups using dns-4496/dns-test-537e29cb-933a-43da-9187-1556c8825f96 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4496.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4496.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4496.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4496.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4496.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4496.svc.cluster.local jessie_udp@dns-test-service-2.dns-4496.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4496.svc.cluster.local]

Oct  1 10:35:53.910: INFO: DNS probes using dns-4496/dns-test-537e29cb-933a-43da-9187-1556c8825f96 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:35:53.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4496" for this suite.
Oct  1 10:35:59.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:36:00.010: INFO: namespace dns-4496 deletion completed in 6.059011575s

• [SLOW TEST:13.194 seconds]
[sig-network] DNS
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:36:00.010: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Oct  1 10:36:00.036: INFO: PodSpec: initContainers in spec.initContainers
Oct  1 10:36:45.070: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-5d7521b9-2ac6-4f77-bb6f-c22d481b1283", GenerateName:"", Namespace:"init-container-5575", SelfLink:"/api/v1/namespaces/init-container-5575/pods/pod-init-5d7521b9-2ac6-4f77-bb6f-c22d481b1283", UID:"784f359e-6acf-434b-a4ab-7eee9f8802b6", ResourceVersion:"17037", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63705522960, loc:(*time.Location)(0x84be2c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"36932240"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-5vf4z", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc003490940), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5vf4z", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5vf4z", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5vf4z", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc005b50308), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-16-136", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00338f200), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc005b50390)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc005b503b0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc005b503b8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc005b503bc), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705522960, loc:(*time.Location)(0x84be2c0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705522960, loc:(*time.Location)(0x84be2c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705522960, loc:(*time.Location)(0x84be2c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705522960, loc:(*time.Location)(0x84be2c0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.16.136", PodIP:"10.1.63.204", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.1.63.204"}}, StartTime:(*v1.Time)(0xc004b3fa40), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0032d7810)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0032d7880)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://97c873093ca068ee4be73c54545de150b8ef0ce637feb5a83b9b6e9666436176", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004b3fa80), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004b3fa60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc005b5043f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:36:45.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5575" for this suite.
Oct  1 10:37:13.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:37:13.146: INFO: namespace init-container-5575 deletion completed in 28.063013368s

• [SLOW TEST:73.136 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:37:13.146: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct  1 10:37:13.188: INFO: Number of nodes with available pods: 0
Oct  1 10:37:13.188: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:37:14.194: INFO: Number of nodes with available pods: 0
Oct  1 10:37:14.194: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:37:15.194: INFO: Number of nodes with available pods: 2
Oct  1 10:37:15.194: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Oct  1 10:37:15.213: INFO: Number of nodes with available pods: 1
Oct  1 10:37:15.213: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:37:16.219: INFO: Number of nodes with available pods: 1
Oct  1 10:37:16.219: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:37:17.218: INFO: Number of nodes with available pods: 2
Oct  1 10:37:17.218: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6325, will wait for the garbage collector to delete the pods
I1001 10:37:17.224035      17 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 10:37:17.224063      17 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Oct  1 10:37:17.278: INFO: Deleting DaemonSet.extensions daemon-set took: 4.420499ms
Oct  1 10:37:17.579: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.380963ms
I1001 10:37:17.578987      17 controller_utils.go:810] Ignoring inactive pod daemonsets-6325/daemon-set-gffff in state Running, deletion time 2019-10-01 10:37:47 +0000 UTC
I1001 10:37:17.579023      17 controller_utils.go:810] Ignoring inactive pod daemonsets-6325/daemon-set-thjtm in state Running, deletion time 2019-10-01 10:37:47 +0000 UTC
Oct  1 10:37:29.082: INFO: Number of nodes with available pods: 0
Oct  1 10:37:29.082: INFO: Number of running nodes: 0, number of available pods: 0
Oct  1 10:37:29.083: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6325/daemonsets","resourceVersion":"17169"},"items":null}

Oct  1 10:37:29.085: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6325/pods","resourceVersion":"17169"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:37:29.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6325" for this suite.
Oct  1 10:37:35.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:37:35.153: INFO: namespace daemonsets-6325 deletion completed in 6.060554169s

• [SLOW TEST:22.007 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:37:35.154: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  1 10:37:36.199: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  1 10:37:39.211: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:37:39.213: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2734-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:37:40.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7201" for this suite.
Oct  1 10:37:46.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:37:46.370: INFO: namespace webhook-7201 deletion completed in 6.059298487s
STEP: Destroying namespace "webhook-7201-markers" for this suite.
Oct  1 10:37:52.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:37:52.427: INFO: namespace webhook-7201-markers deletion completed in 6.057175373s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.281 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:37:52.435: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:37:52.539: INFO: (0) /api/v1/nodes/ip-172-31-16-136/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 11.248667ms)
Oct  1 10:37:52.542: INFO: (1) /api/v1/nodes/ip-172-31-16-136/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.731481ms)
Oct  1 10:37:52.544: INFO: (2) /api/v1/nodes/ip-172-31-16-136/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.455707ms)
Oct  1 10:37:52.546: INFO: (3) /api/v1/nodes/ip-172-31-16-136/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.403667ms)
Oct  1 10:37:52.549: INFO: (4) /api/v1/nodes/ip-172-31-16-136/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.425879ms)
Oct  1 10:37:52.551: INFO: (5) /api/v1/nodes/ip-172-31-16-136/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.412328ms)
Oct  1 10:37:52.554: INFO: (6) /api/v1/nodes/ip-172-31-16-136/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.346917ms)
Oct  1 10:37:52.556: INFO: (7) /api/v1/nodes/ip-172-31-16-136/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.233907ms)
Oct  1 10:37:52.558: INFO: (8) /api/v1/nodes/ip-172-31-16-136/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.151803ms)
Oct  1 10:37:52.560: INFO: (9) /api/v1/nodes/ip-172-31-16-136/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.146452ms)
Oct  1 10:37:52.563: INFO: (10) /api/v1/nodes/ip-172-31-16-136/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.172129ms)
Oct  1 10:37:52.565: INFO: (11) /api/v1/nodes/ip-172-31-16-136/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.128358ms)
Oct  1 10:37:52.568: INFO: (12) /api/v1/nodes/ip-172-31-16-136/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.84146ms)
Oct  1 10:37:52.570: INFO: (13) /api/v1/nodes/ip-172-31-16-136/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.240353ms)
Oct  1 10:37:52.572: INFO: (14) /api/v1/nodes/ip-172-31-16-136/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.324604ms)
Oct  1 10:37:52.574: INFO: (15) /api/v1/nodes/ip-172-31-16-136/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.082975ms)
Oct  1 10:37:52.577: INFO: (16) /api/v1/nodes/ip-172-31-16-136/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.872823ms)
Oct  1 10:37:52.579: INFO: (17) /api/v1/nodes/ip-172-31-16-136/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.241746ms)
Oct  1 10:37:52.582: INFO: (18) /api/v1/nodes/ip-172-31-16-136/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.229986ms)
Oct  1 10:37:52.585: INFO: (19) /api/v1/nodes/ip-172-31-16-136/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.135543ms)
[AfterEach] version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:37:52.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9911" for this suite.
Oct  1 10:37:58.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:37:58.642: INFO: namespace proxy-9911 deletion completed in 6.054707811s

• [SLOW TEST:6.206 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:37:58.642: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-g97r
STEP: Creating a pod to test atomic-volume-subpath
Oct  1 10:37:58.675: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-g97r" in namespace "subpath-7346" to be "success or failure"
Oct  1 10:37:58.676: INFO: Pod "pod-subpath-test-projected-g97r": Phase="Pending", Reason="", readiness=false. Elapsed: 1.623529ms
Oct  1 10:38:00.680: INFO: Pod "pod-subpath-test-projected-g97r": Phase="Running", Reason="", readiness=true. Elapsed: 2.004708982s
Oct  1 10:38:02.683: INFO: Pod "pod-subpath-test-projected-g97r": Phase="Running", Reason="", readiness=true. Elapsed: 4.0077864s
Oct  1 10:38:04.686: INFO: Pod "pod-subpath-test-projected-g97r": Phase="Running", Reason="", readiness=true. Elapsed: 6.010885737s
Oct  1 10:38:06.689: INFO: Pod "pod-subpath-test-projected-g97r": Phase="Running", Reason="", readiness=true. Elapsed: 8.013862416s
Oct  1 10:38:08.692: INFO: Pod "pod-subpath-test-projected-g97r": Phase="Running", Reason="", readiness=true. Elapsed: 10.016740719s
Oct  1 10:38:10.694: INFO: Pod "pod-subpath-test-projected-g97r": Phase="Running", Reason="", readiness=true. Elapsed: 12.01960558s
Oct  1 10:38:12.698: INFO: Pod "pod-subpath-test-projected-g97r": Phase="Running", Reason="", readiness=true. Elapsed: 14.022661582s
Oct  1 10:38:14.701: INFO: Pod "pod-subpath-test-projected-g97r": Phase="Running", Reason="", readiness=true. Elapsed: 16.025668343s
Oct  1 10:38:16.704: INFO: Pod "pod-subpath-test-projected-g97r": Phase="Running", Reason="", readiness=true. Elapsed: 18.028676583s
Oct  1 10:38:18.707: INFO: Pod "pod-subpath-test-projected-g97r": Phase="Running", Reason="", readiness=true. Elapsed: 20.031705311s
Oct  1 10:38:20.710: INFO: Pod "pod-subpath-test-projected-g97r": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.034849027s
STEP: Saw pod success
Oct  1 10:38:20.710: INFO: Pod "pod-subpath-test-projected-g97r" satisfied condition "success or failure"
Oct  1 10:38:20.712: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-subpath-test-projected-g97r container test-container-subpath-projected-g97r: <nil>
STEP: delete the pod
Oct  1 10:38:20.725: INFO: Waiting for pod pod-subpath-test-projected-g97r to disappear
Oct  1 10:38:20.733: INFO: Pod pod-subpath-test-projected-g97r no longer exists
STEP: Deleting pod pod-subpath-test-projected-g97r
Oct  1 10:38:20.733: INFO: Deleting pod "pod-subpath-test-projected-g97r" in namespace "subpath-7346"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:38:20.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7346" for this suite.
Oct  1 10:38:26.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:38:26.804: INFO: namespace subpath-7346 deletion completed in 6.064429452s

• [SLOW TEST:28.162 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:38:26.804: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-db6be70b-531e-414c-87e3-63017916a101
STEP: Creating a pod to test consume configMaps
Oct  1 10:38:26.835: INFO: Waiting up to 5m0s for pod "pod-configmaps-01f64024-fa7f-483d-ae57-d88b8bf92d4a" in namespace "configmap-3890" to be "success or failure"
Oct  1 10:38:26.837: INFO: Pod "pod-configmaps-01f64024-fa7f-483d-ae57-d88b8bf92d4a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.919658ms
Oct  1 10:38:28.840: INFO: Pod "pod-configmaps-01f64024-fa7f-483d-ae57-d88b8bf92d4a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005079758s
STEP: Saw pod success
Oct  1 10:38:28.840: INFO: Pod "pod-configmaps-01f64024-fa7f-483d-ae57-d88b8bf92d4a" satisfied condition "success or failure"
Oct  1 10:38:28.842: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-configmaps-01f64024-fa7f-483d-ae57-d88b8bf92d4a container configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 10:38:28.853: INFO: Waiting for pod pod-configmaps-01f64024-fa7f-483d-ae57-d88b8bf92d4a to disappear
Oct  1 10:38:28.855: INFO: Pod pod-configmaps-01f64024-fa7f-483d-ae57-d88b8bf92d4a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:38:28.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3890" for this suite.
Oct  1 10:38:34.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:38:34.916: INFO: namespace configmap-3890 deletion completed in 6.058573554s

• [SLOW TEST:8.112 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:38:34.916: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-3e84d4bd-dad6-4ce3-8a24-5823b784d134
STEP: Creating a pod to test consume secrets
Oct  1 10:38:34.949: INFO: Waiting up to 5m0s for pod "pod-secrets-e5d82d1d-7a93-4e93-8a47-2f3803107a84" in namespace "secrets-4869" to be "success or failure"
Oct  1 10:38:34.951: INFO: Pod "pod-secrets-e5d82d1d-7a93-4e93-8a47-2f3803107a84": Phase="Pending", Reason="", readiness=false. Elapsed: 2.594525ms
Oct  1 10:38:36.955: INFO: Pod "pod-secrets-e5d82d1d-7a93-4e93-8a47-2f3803107a84": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005754047s
STEP: Saw pod success
Oct  1 10:38:36.955: INFO: Pod "pod-secrets-e5d82d1d-7a93-4e93-8a47-2f3803107a84" satisfied condition "success or failure"
Oct  1 10:38:36.957: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-secrets-e5d82d1d-7a93-4e93-8a47-2f3803107a84 container secret-volume-test: <nil>
STEP: delete the pod
Oct  1 10:38:36.966: INFO: Waiting for pod pod-secrets-e5d82d1d-7a93-4e93-8a47-2f3803107a84 to disappear
Oct  1 10:38:36.968: INFO: Pod pod-secrets-e5d82d1d-7a93-4e93-8a47-2f3803107a84 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:38:36.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4869" for this suite.
Oct  1 10:38:42.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:38:43.029: INFO: namespace secrets-4869 deletion completed in 6.05860513s

• [SLOW TEST:8.113 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:38:43.029: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:38:43.069: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Oct  1 10:38:43.079: INFO: Number of nodes with available pods: 0
Oct  1 10:38:43.079: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Oct  1 10:38:43.088: INFO: Number of nodes with available pods: 0
Oct  1 10:38:43.088: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:38:44.091: INFO: Number of nodes with available pods: 0
Oct  1 10:38:44.091: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:38:45.091: INFO: Number of nodes with available pods: 1
Oct  1 10:38:45.091: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Oct  1 10:38:45.117: INFO: Number of nodes with available pods: 1
Oct  1 10:38:45.117: INFO: Number of running nodes: 0, number of available pods: 1
Oct  1 10:38:46.121: INFO: Number of nodes with available pods: 0
Oct  1 10:38:46.121: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Oct  1 10:38:46.128: INFO: Number of nodes with available pods: 0
Oct  1 10:38:46.128: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:38:47.132: INFO: Number of nodes with available pods: 0
Oct  1 10:38:47.132: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:38:48.132: INFO: Number of nodes with available pods: 0
Oct  1 10:38:48.132: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:38:49.131: INFO: Number of nodes with available pods: 0
Oct  1 10:38:49.131: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:38:50.132: INFO: Number of nodes with available pods: 0
Oct  1 10:38:50.132: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:38:51.132: INFO: Number of nodes with available pods: 0
Oct  1 10:38:51.132: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:38:52.131: INFO: Number of nodes with available pods: 0
Oct  1 10:38:52.131: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:38:53.132: INFO: Number of nodes with available pods: 0
Oct  1 10:38:53.132: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:38:54.131: INFO: Number of nodes with available pods: 0
Oct  1 10:38:54.131: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:38:55.132: INFO: Number of nodes with available pods: 0
Oct  1 10:38:55.132: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:38:56.132: INFO: Number of nodes with available pods: 0
Oct  1 10:38:56.132: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:38:57.131: INFO: Number of nodes with available pods: 0
Oct  1 10:38:57.131: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:38:58.131: INFO: Number of nodes with available pods: 0
Oct  1 10:38:58.132: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:38:59.131: INFO: Number of nodes with available pods: 0
Oct  1 10:38:59.131: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:39:00.131: INFO: Number of nodes with available pods: 0
Oct  1 10:39:00.131: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:39:01.131: INFO: Number of nodes with available pods: 1
Oct  1 10:39:01.132: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7910, will wait for the garbage collector to delete the pods
I1001 10:39:01.137694      17 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 10:39:01.137721      17 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Oct  1 10:39:01.192: INFO: Deleting DaemonSet.extensions daemon-set took: 4.709408ms
Oct  1 10:39:01.492: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.393105ms
I1001 10:39:01.492943      17 controller_utils.go:810] Ignoring inactive pod daemonsets-7910/daemon-set-w6jnz in state Running, deletion time 2019-10-01 10:39:31 +0000 UTC
Oct  1 10:39:09.095: INFO: Number of nodes with available pods: 0
Oct  1 10:39:09.095: INFO: Number of running nodes: 0, number of available pods: 0
Oct  1 10:39:09.097: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7910/daemonsets","resourceVersion":"17548"},"items":null}

Oct  1 10:39:09.099: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7910/pods","resourceVersion":"17548"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:39:09.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7910" for this suite.
Oct  1 10:39:15.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:39:15.174: INFO: namespace daemonsets-7910 deletion completed in 6.063465693s

• [SLOW TEST:32.146 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:39:15.175: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:39:15.207: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Oct  1 10:39:15.213: INFO: Number of nodes with available pods: 0
Oct  1 10:39:15.213: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:39:16.218: INFO: Number of nodes with available pods: 0
Oct  1 10:39:16.218: INFO: Node ip-172-31-16-136 is running more than one daemon pod
Oct  1 10:39:17.218: INFO: Number of nodes with available pods: 2
Oct  1 10:39:17.218: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Oct  1 10:39:17.232: INFO: Wrong image for pod: daemon-set-8jmpg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  1 10:39:17.232: INFO: Wrong image for pod: daemon-set-hf8n9. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  1 10:39:18.241: INFO: Wrong image for pod: daemon-set-8jmpg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  1 10:39:18.241: INFO: Wrong image for pod: daemon-set-hf8n9. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  1 10:39:19.241: INFO: Wrong image for pod: daemon-set-8jmpg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  1 10:39:19.241: INFO: Wrong image for pod: daemon-set-hf8n9. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  1 10:39:20.240: INFO: Wrong image for pod: daemon-set-8jmpg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  1 10:39:20.240: INFO: Wrong image for pod: daemon-set-hf8n9. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  1 10:39:20.240: INFO: Pod daemon-set-hf8n9 is not available
Oct  1 10:39:21.241: INFO: Wrong image for pod: daemon-set-8jmpg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  1 10:39:21.241: INFO: Pod daemon-set-8sczl is not available
Oct  1 10:39:22.240: INFO: Wrong image for pod: daemon-set-8jmpg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  1 10:39:22.240: INFO: Pod daemon-set-8sczl is not available
Oct  1 10:39:23.248: INFO: Wrong image for pod: daemon-set-8jmpg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  1 10:39:24.241: INFO: Wrong image for pod: daemon-set-8jmpg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  1 10:39:25.241: INFO: Wrong image for pod: daemon-set-8jmpg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  1 10:39:25.241: INFO: Pod daemon-set-8jmpg is not available
Oct  1 10:39:26.241: INFO: Wrong image for pod: daemon-set-8jmpg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  1 10:39:26.241: INFO: Pod daemon-set-8jmpg is not available
Oct  1 10:39:27.241: INFO: Wrong image for pod: daemon-set-8jmpg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  1 10:39:27.241: INFO: Pod daemon-set-8jmpg is not available
Oct  1 10:39:28.241: INFO: Wrong image for pod: daemon-set-8jmpg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  1 10:39:28.241: INFO: Pod daemon-set-8jmpg is not available
Oct  1 10:39:29.241: INFO: Wrong image for pod: daemon-set-8jmpg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  1 10:39:29.241: INFO: Pod daemon-set-8jmpg is not available
Oct  1 10:39:30.241: INFO: Wrong image for pod: daemon-set-8jmpg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  1 10:39:30.241: INFO: Pod daemon-set-8jmpg is not available
Oct  1 10:39:31.241: INFO: Wrong image for pod: daemon-set-8jmpg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  1 10:39:31.241: INFO: Pod daemon-set-8jmpg is not available
Oct  1 10:39:32.241: INFO: Pod daemon-set-2z9x9 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Oct  1 10:39:32.246: INFO: Number of nodes with available pods: 1
Oct  1 10:39:32.246: INFO: Node ip-172-31-29-44 is running more than one daemon pod
Oct  1 10:39:33.252: INFO: Number of nodes with available pods: 2
Oct  1 10:39:33.252: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-761, will wait for the garbage collector to delete the pods
I1001 10:39:33.263398      17 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 10:39:33.263428      17 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Oct  1 10:39:33.317: INFO: Deleting DaemonSet.extensions daemon-set took: 4.170542ms
Oct  1 10:39:33.618: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.375512ms
I1001 10:39:33.618044      17 controller_utils.go:810] Ignoring inactive pod daemonsets-761/daemon-set-2z9x9 in state Running, deletion time 2019-10-01 10:40:03 +0000 UTC
I1001 10:39:33.618086      17 controller_utils.go:810] Ignoring inactive pod daemonsets-761/daemon-set-8sczl in state Running, deletion time 2019-10-01 10:40:03 +0000 UTC
Oct  1 10:39:41.720: INFO: Number of nodes with available pods: 0
Oct  1 10:39:41.720: INFO: Number of running nodes: 0, number of available pods: 0
Oct  1 10:39:41.721: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-761/daemonsets","resourceVersion":"17690"},"items":null}

Oct  1 10:39:41.723: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-761/pods","resourceVersion":"17690"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:39:41.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-761" for this suite.
Oct  1 10:39:47.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:39:47.792: INFO: namespace daemonsets-761 deletion completed in 6.061271832s

• [SLOW TEST:32.617 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:39:47.792: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:39:58.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4557" for this suite.
Oct  1 10:40:04.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:40:04.909: INFO: namespace resourcequota-4557 deletion completed in 6.059090204s

• [SLOW TEST:17.117 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:40:04.910: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  1 10:40:04.942: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5265e11b-68c1-4f0f-b0f7-26f5c6abd4f7" in namespace "downward-api-5361" to be "success or failure"
Oct  1 10:40:04.944: INFO: Pod "downwardapi-volume-5265e11b-68c1-4f0f-b0f7-26f5c6abd4f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.342979ms
Oct  1 10:40:06.947: INFO: Pod "downwardapi-volume-5265e11b-68c1-4f0f-b0f7-26f5c6abd4f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005603562s
STEP: Saw pod success
Oct  1 10:40:06.947: INFO: Pod "downwardapi-volume-5265e11b-68c1-4f0f-b0f7-26f5c6abd4f7" satisfied condition "success or failure"
Oct  1 10:40:06.949: INFO: Trying to get logs from node ip-172-31-16-136 pod downwardapi-volume-5265e11b-68c1-4f0f-b0f7-26f5c6abd4f7 container client-container: <nil>
STEP: delete the pod
Oct  1 10:40:06.962: INFO: Waiting for pod downwardapi-volume-5265e11b-68c1-4f0f-b0f7-26f5c6abd4f7 to disappear
Oct  1 10:40:06.969: INFO: Pod downwardapi-volume-5265e11b-68c1-4f0f-b0f7-26f5c6abd4f7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:40:06.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5361" for this suite.
Oct  1 10:40:12.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:40:13.029: INFO: namespace downward-api-5361 deletion completed in 6.05819036s

• [SLOW TEST:8.119 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:40:13.029: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct  1 10:40:13.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-6265'
Oct  1 10:40:13.949: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct  1 10:40:13.949: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Oct  1 10:40:15.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 delete deployment e2e-test-httpd-deployment --namespace=kubectl-6265'
Oct  1 10:40:16.038: INFO: stderr: ""
Oct  1 10:40:16.038: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:40:16.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6265" for this suite.
Oct  1 10:40:22.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:40:22.103: INFO: namespace kubectl-6265 deletion completed in 6.063147083s

• [SLOW TEST:9.074 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:40:22.104: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-b5md
STEP: Creating a pod to test atomic-volume-subpath
Oct  1 10:40:22.141: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-b5md" in namespace "subpath-6721" to be "success or failure"
Oct  1 10:40:22.152: INFO: Pod "pod-subpath-test-downwardapi-b5md": Phase="Pending", Reason="", readiness=false. Elapsed: 11.572505ms
Oct  1 10:40:24.156: INFO: Pod "pod-subpath-test-downwardapi-b5md": Phase="Running", Reason="", readiness=true. Elapsed: 2.014723875s
Oct  1 10:40:26.159: INFO: Pod "pod-subpath-test-downwardapi-b5md": Phase="Running", Reason="", readiness=true. Elapsed: 4.017785197s
Oct  1 10:40:28.162: INFO: Pod "pod-subpath-test-downwardapi-b5md": Phase="Running", Reason="", readiness=true. Elapsed: 6.020741287s
Oct  1 10:40:30.165: INFO: Pod "pod-subpath-test-downwardapi-b5md": Phase="Running", Reason="", readiness=true. Elapsed: 8.023851153s
Oct  1 10:40:32.168: INFO: Pod "pod-subpath-test-downwardapi-b5md": Phase="Running", Reason="", readiness=true. Elapsed: 10.02684663s
Oct  1 10:40:34.171: INFO: Pod "pod-subpath-test-downwardapi-b5md": Phase="Running", Reason="", readiness=true. Elapsed: 12.029992061s
Oct  1 10:40:36.174: INFO: Pod "pod-subpath-test-downwardapi-b5md": Phase="Running", Reason="", readiness=true. Elapsed: 14.032967237s
Oct  1 10:40:38.177: INFO: Pod "pod-subpath-test-downwardapi-b5md": Phase="Running", Reason="", readiness=true. Elapsed: 16.0359126s
Oct  1 10:40:40.180: INFO: Pod "pod-subpath-test-downwardapi-b5md": Phase="Running", Reason="", readiness=true. Elapsed: 18.03885429s
Oct  1 10:40:42.183: INFO: Pod "pod-subpath-test-downwardapi-b5md": Phase="Running", Reason="", readiness=true. Elapsed: 20.041978233s
Oct  1 10:40:44.186: INFO: Pod "pod-subpath-test-downwardapi-b5md": Phase="Running", Reason="", readiness=true. Elapsed: 22.045076091s
Oct  1 10:40:46.189: INFO: Pod "pod-subpath-test-downwardapi-b5md": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.048257392s
STEP: Saw pod success
Oct  1 10:40:46.189: INFO: Pod "pod-subpath-test-downwardapi-b5md" satisfied condition "success or failure"
Oct  1 10:40:46.191: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-subpath-test-downwardapi-b5md container test-container-subpath-downwardapi-b5md: <nil>
STEP: delete the pod
Oct  1 10:40:46.212: INFO: Waiting for pod pod-subpath-test-downwardapi-b5md to disappear
Oct  1 10:40:46.220: INFO: Pod pod-subpath-test-downwardapi-b5md no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-b5md
Oct  1 10:40:46.221: INFO: Deleting pod "pod-subpath-test-downwardapi-b5md" in namespace "subpath-6721"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:40:46.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6721" for this suite.
Oct  1 10:40:52.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:40:52.285: INFO: namespace subpath-6721 deletion completed in 6.058899773s

• [SLOW TEST:30.181 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:40:52.285: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Oct  1 10:40:56.833: INFO: Successfully updated pod "labelsupdate31bca9a9-49ab-4c04-af5f-da0d066227de"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:40:58.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4366" for this suite.
Oct  1 10:41:10.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:41:10.902: INFO: namespace projected-4366 deletion completed in 12.057177653s

• [SLOW TEST:18.617 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:41:10.903: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-1186
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1186 to expose endpoints map[]
Oct  1 10:41:10.934: INFO: Get endpoints failed (1.908317ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Oct  1 10:41:11.937: INFO: successfully validated that service multi-endpoint-test in namespace services-1186 exposes endpoints map[] (1.004898618s elapsed)
STEP: Creating pod pod1 in namespace services-1186
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1186 to expose endpoints map[pod1:[100]]
Oct  1 10:41:13.965: INFO: successfully validated that service multi-endpoint-test in namespace services-1186 exposes endpoints map[pod1:[100]] (2.023198296s elapsed)
STEP: Creating pod pod2 in namespace services-1186
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1186 to expose endpoints map[pod1:[100] pod2:[101]]
Oct  1 10:41:15.994: INFO: successfully validated that service multi-endpoint-test in namespace services-1186 exposes endpoints map[pod1:[100] pod2:[101]] (2.025990923s elapsed)
STEP: Deleting pod pod1 in namespace services-1186
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1186 to expose endpoints map[pod2:[101]]
Oct  1 10:41:17.008: INFO: successfully validated that service multi-endpoint-test in namespace services-1186 exposes endpoints map[pod2:[101]] (1.011020756s elapsed)
STEP: Deleting pod pod2 in namespace services-1186
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1186 to expose endpoints map[]
Oct  1 10:41:18.018: INFO: successfully validated that service multi-endpoint-test in namespace services-1186 exposes endpoints map[] (1.006417905s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:41:18.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1186" for this suite.
Oct  1 10:41:24.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:41:24.098: INFO: namespace services-1186 deletion completed in 6.062086233s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.195 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:41:24.099: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:41:24.129: INFO: (0) /api/v1/nodes/ip-172-31-16-136:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.709973ms)
Oct  1 10:41:24.131: INFO: (1) /api/v1/nodes/ip-172-31-16-136:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.214086ms)
Oct  1 10:41:24.133: INFO: (2) /api/v1/nodes/ip-172-31-16-136:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.380958ms)
Oct  1 10:41:24.136: INFO: (3) /api/v1/nodes/ip-172-31-16-136:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.017828ms)
Oct  1 10:41:24.139: INFO: (4) /api/v1/nodes/ip-172-31-16-136:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.283618ms)
Oct  1 10:41:24.141: INFO: (5) /api/v1/nodes/ip-172-31-16-136:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.189891ms)
Oct  1 10:41:24.144: INFO: (6) /api/v1/nodes/ip-172-31-16-136:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.952827ms)
Oct  1 10:41:24.146: INFO: (7) /api/v1/nodes/ip-172-31-16-136:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.477348ms)
Oct  1 10:41:24.149: INFO: (8) /api/v1/nodes/ip-172-31-16-136:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.839109ms)
Oct  1 10:41:24.152: INFO: (9) /api/v1/nodes/ip-172-31-16-136:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.377219ms)
Oct  1 10:41:24.154: INFO: (10) /api/v1/nodes/ip-172-31-16-136:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.131731ms)
Oct  1 10:41:24.156: INFO: (11) /api/v1/nodes/ip-172-31-16-136:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.219999ms)
Oct  1 10:41:24.158: INFO: (12) /api/v1/nodes/ip-172-31-16-136:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.097573ms)
Oct  1 10:41:24.160: INFO: (13) /api/v1/nodes/ip-172-31-16-136:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.206125ms)
Oct  1 10:41:24.163: INFO: (14) /api/v1/nodes/ip-172-31-16-136:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.210705ms)
Oct  1 10:41:24.165: INFO: (15) /api/v1/nodes/ip-172-31-16-136:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.119188ms)
Oct  1 10:41:24.167: INFO: (16) /api/v1/nodes/ip-172-31-16-136:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.126635ms)
Oct  1 10:41:24.169: INFO: (17) /api/v1/nodes/ip-172-31-16-136:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.293727ms)
Oct  1 10:41:24.172: INFO: (18) /api/v1/nodes/ip-172-31-16-136:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.196019ms)
Oct  1 10:41:24.174: INFO: (19) /api/v1/nodes/ip-172-31-16-136:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.175758ms)
[AfterEach] version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:41:24.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-387" for this suite.
Oct  1 10:41:30.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:41:30.233: INFO: namespace proxy-387 deletion completed in 6.056665717s

• [SLOW TEST:6.134 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:41:30.233: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Oct  1 10:41:30.255: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:41:34.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9096" for this suite.
Oct  1 10:41:46.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:41:46.651: INFO: namespace init-container-9096 deletion completed in 12.059252054s

• [SLOW TEST:16.418 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:41:46.651: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:41:57.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8467" for this suite.
Oct  1 10:42:03.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:42:03.756: INFO: namespace resourcequota-8467 deletion completed in 6.057954385s

• [SLOW TEST:17.105 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:42:03.756: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-0c66a451-90db-4bc9-a777-f5bb57397436
STEP: Creating secret with name secret-projected-all-test-volume-f31b46e2-5656-4ace-a147-16b5f8c63e07
STEP: Creating a pod to test Check all projections for projected volume plugin
Oct  1 10:42:03.791: INFO: Waiting up to 5m0s for pod "projected-volume-2d369be6-994e-4e35-8a0a-c486342445be" in namespace "projected-5153" to be "success or failure"
Oct  1 10:42:03.793: INFO: Pod "projected-volume-2d369be6-994e-4e35-8a0a-c486342445be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077671ms
Oct  1 10:42:05.796: INFO: Pod "projected-volume-2d369be6-994e-4e35-8a0a-c486342445be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005289117s
STEP: Saw pod success
Oct  1 10:42:05.796: INFO: Pod "projected-volume-2d369be6-994e-4e35-8a0a-c486342445be" satisfied condition "success or failure"
Oct  1 10:42:05.798: INFO: Trying to get logs from node ip-172-31-16-136 pod projected-volume-2d369be6-994e-4e35-8a0a-c486342445be container projected-all-volume-test: <nil>
STEP: delete the pod
Oct  1 10:42:05.808: INFO: Waiting for pod projected-volume-2d369be6-994e-4e35-8a0a-c486342445be to disappear
Oct  1 10:42:05.810: INFO: Pod projected-volume-2d369be6-994e-4e35-8a0a-c486342445be no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:42:05.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5153" for this suite.
Oct  1 10:42:11.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:42:11.874: INFO: namespace projected-5153 deletion completed in 6.062240015s

• [SLOW TEST:8.118 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:42:11.874: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-wl42
STEP: Creating a pod to test atomic-volume-subpath
Oct  1 10:42:11.908: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-wl42" in namespace "subpath-2657" to be "success or failure"
Oct  1 10:42:11.913: INFO: Pod "pod-subpath-test-secret-wl42": Phase="Pending", Reason="", readiness=false. Elapsed: 5.274012ms
Oct  1 10:42:13.917: INFO: Pod "pod-subpath-test-secret-wl42": Phase="Running", Reason="", readiness=true. Elapsed: 2.008390468s
Oct  1 10:42:15.919: INFO: Pod "pod-subpath-test-secret-wl42": Phase="Running", Reason="", readiness=true. Elapsed: 4.011248205s
Oct  1 10:42:17.922: INFO: Pod "pod-subpath-test-secret-wl42": Phase="Running", Reason="", readiness=true. Elapsed: 6.014283043s
Oct  1 10:42:19.925: INFO: Pod "pod-subpath-test-secret-wl42": Phase="Running", Reason="", readiness=true. Elapsed: 8.017239658s
Oct  1 10:42:21.928: INFO: Pod "pod-subpath-test-secret-wl42": Phase="Running", Reason="", readiness=true. Elapsed: 10.019907819s
Oct  1 10:42:23.931: INFO: Pod "pod-subpath-test-secret-wl42": Phase="Running", Reason="", readiness=true. Elapsed: 12.023050344s
Oct  1 10:42:25.934: INFO: Pod "pod-subpath-test-secret-wl42": Phase="Running", Reason="", readiness=true. Elapsed: 14.026101439s
Oct  1 10:42:27.937: INFO: Pod "pod-subpath-test-secret-wl42": Phase="Running", Reason="", readiness=true. Elapsed: 16.029341543s
Oct  1 10:42:29.941: INFO: Pod "pod-subpath-test-secret-wl42": Phase="Running", Reason="", readiness=true. Elapsed: 18.032557699s
Oct  1 10:42:31.944: INFO: Pod "pod-subpath-test-secret-wl42": Phase="Running", Reason="", readiness=true. Elapsed: 20.035648762s
Oct  1 10:42:33.947: INFO: Pod "pod-subpath-test-secret-wl42": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.038828834s
STEP: Saw pod success
Oct  1 10:42:33.947: INFO: Pod "pod-subpath-test-secret-wl42" satisfied condition "success or failure"
Oct  1 10:42:33.949: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-subpath-test-secret-wl42 container test-container-subpath-secret-wl42: <nil>
STEP: delete the pod
Oct  1 10:42:33.962: INFO: Waiting for pod pod-subpath-test-secret-wl42 to disappear
Oct  1 10:42:33.970: INFO: Pod pod-subpath-test-secret-wl42 no longer exists
STEP: Deleting pod pod-subpath-test-secret-wl42
Oct  1 10:42:33.970: INFO: Deleting pod "pod-subpath-test-secret-wl42" in namespace "subpath-2657"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:42:33.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2657" for this suite.
Oct  1 10:42:39.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:42:40.036: INFO: namespace subpath-2657 deletion completed in 6.062350297s

• [SLOW TEST:28.162 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:42:40.036: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-994ddea1-855b-49c5-b4db-1c16fdd4cfe6 in namespace container-probe-4073
Oct  1 10:42:42.071: INFO: Started pod test-webserver-994ddea1-855b-49c5-b4db-1c16fdd4cfe6 in namespace container-probe-4073
STEP: checking the pod's current state and verifying that restartCount is present
Oct  1 10:42:42.073: INFO: Initial restart count of pod test-webserver-994ddea1-855b-49c5-b4db-1c16fdd4cfe6 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:46:42.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4073" for this suite.
Oct  1 10:46:48.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:46:48.526: INFO: namespace container-probe-4073 deletion completed in 6.065676962s

• [SLOW TEST:248.490 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:46:48.526: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-8524
STEP: creating replication controller nodeport-test in namespace services-8524
I1001 10:46:48.564123      17 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-8524, replica count: 2
I1001 10:46:48.564221      17 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 10:46:48.564243      17 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Oct  1 10:46:51.614: INFO: Creating new exec pod
I1001 10:46:51.614659      17 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1001 10:46:53.633620      17 reflector.go:120] Starting reflector *v1.Endpoints (0s) from k8s.io/kubernetes/test/e2e/framework/service/jig.go:389
I1001 10:46:53.633649      17 reflector.go:158] Listing and watching *v1.Endpoints from k8s.io/kubernetes/test/e2e/framework/service/jig.go:389
Oct  1 10:46:54.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=services-8524 execpodl4bw8 -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Oct  1 10:46:54.842: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Oct  1 10:46:54.842: INFO: stdout: ""
Oct  1 10:46:54.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=services-8524 execpodl4bw8 -- /bin/sh -x -c nc -zv -t -w 2 10.152.183.209 80'
Oct  1 10:46:55.044: INFO: stderr: "+ nc -zv -t -w 2 10.152.183.209 80\nConnection to 10.152.183.209 80 port [tcp/http] succeeded!\n"
Oct  1 10:46:55.044: INFO: stdout: ""
Oct  1 10:46:55.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=services-8524 execpodl4bw8 -- /bin/sh -x -c nc -zv -t -w 2 172.31.16.136 32752'
Oct  1 10:46:55.253: INFO: stderr: "+ nc -zv -t -w 2 172.31.16.136 32752\nConnection to 172.31.16.136 32752 port [tcp/32752] succeeded!\n"
Oct  1 10:46:55.253: INFO: stdout: ""
Oct  1 10:46:55.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=services-8524 execpodl4bw8 -- /bin/sh -x -c nc -zv -t -w 2 172.31.29.44 32752'
Oct  1 10:46:55.466: INFO: stderr: "+ nc -zv -t -w 2 172.31.29.44 32752\nConnection to 172.31.29.44 32752 port [tcp/32752] succeeded!\n"
Oct  1 10:46:55.466: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:46:55.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8524" for this suite.
Oct  1 10:47:01.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:47:01.530: INFO: namespace services-8524 deletion completed in 6.061341776s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.003 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:47:01.530: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-eb87b5a2-10c5-4622-a9e2-a2213a7e315a
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-eb87b5a2-10c5-4622-a9e2-a2213a7e315a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:47:05.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1010" for this suite.
Oct  1 10:47:23.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:47:23.654: INFO: namespace projected-1010 deletion completed in 18.058101119s

• [SLOW TEST:22.125 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:47:23.654: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-78dae6f6-413a-438e-8e83-2799452b851d
STEP: Creating a pod to test consume secrets
Oct  1 10:47:23.684: INFO: Waiting up to 5m0s for pod "pod-secrets-162fbf18-e5ae-4e9c-b366-8332a6c5e22f" in namespace "secrets-1354" to be "success or failure"
Oct  1 10:47:23.687: INFO: Pod "pod-secrets-162fbf18-e5ae-4e9c-b366-8332a6c5e22f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.756655ms
Oct  1 10:47:25.690: INFO: Pod "pod-secrets-162fbf18-e5ae-4e9c-b366-8332a6c5e22f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005924855s
STEP: Saw pod success
Oct  1 10:47:25.690: INFO: Pod "pod-secrets-162fbf18-e5ae-4e9c-b366-8332a6c5e22f" satisfied condition "success or failure"
Oct  1 10:47:25.692: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-secrets-162fbf18-e5ae-4e9c-b366-8332a6c5e22f container secret-volume-test: <nil>
STEP: delete the pod
Oct  1 10:47:25.702: INFO: Waiting for pod pod-secrets-162fbf18-e5ae-4e9c-b366-8332a6c5e22f to disappear
Oct  1 10:47:25.704: INFO: Pod pod-secrets-162fbf18-e5ae-4e9c-b366-8332a6c5e22f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:47:25.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1354" for this suite.
Oct  1 10:47:31.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:47:31.775: INFO: namespace secrets-1354 deletion completed in 6.068295791s

• [SLOW TEST:8.120 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:47:31.775: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Oct  1 10:47:31.803: INFO: Waiting up to 5m0s for pod "downward-api-c087ec52-9891-4c96-b095-b62958ea77f7" in namespace "downward-api-6847" to be "success or failure"
Oct  1 10:47:31.806: INFO: Pod "downward-api-c087ec52-9891-4c96-b095-b62958ea77f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.54782ms
Oct  1 10:47:33.809: INFO: Pod "downward-api-c087ec52-9891-4c96-b095-b62958ea77f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005908095s
STEP: Saw pod success
Oct  1 10:47:33.809: INFO: Pod "downward-api-c087ec52-9891-4c96-b095-b62958ea77f7" satisfied condition "success or failure"
Oct  1 10:47:33.811: INFO: Trying to get logs from node ip-172-31-16-136 pod downward-api-c087ec52-9891-4c96-b095-b62958ea77f7 container dapi-container: <nil>
STEP: delete the pod
Oct  1 10:47:33.822: INFO: Waiting for pod downward-api-c087ec52-9891-4c96-b095-b62958ea77f7 to disappear
Oct  1 10:47:33.824: INFO: Pod downward-api-c087ec52-9891-4c96-b095-b62958ea77f7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:47:33.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6847" for this suite.
Oct  1 10:47:39.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:47:39.884: INFO: namespace downward-api-6847 deletion completed in 6.058172939s

• [SLOW TEST:8.109 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:47:39.884: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-2789
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2789 to expose endpoints map[]
Oct  1 10:47:39.916: INFO: Get endpoints failed (8.722085ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Oct  1 10:47:40.919: INFO: successfully validated that service endpoint-test2 in namespace services-2789 exposes endpoints map[] (1.011708862s elapsed)
STEP: Creating pod pod1 in namespace services-2789
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2789 to expose endpoints map[pod1:[80]]
Oct  1 10:47:42.937: INFO: successfully validated that service endpoint-test2 in namespace services-2789 exposes endpoints map[pod1:[80]] (2.014065926s elapsed)
STEP: Creating pod pod2 in namespace services-2789
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2789 to expose endpoints map[pod1:[80] pod2:[80]]
Oct  1 10:47:44.968: INFO: successfully validated that service endpoint-test2 in namespace services-2789 exposes endpoints map[pod1:[80] pod2:[80]] (2.02820569s elapsed)
STEP: Deleting pod pod1 in namespace services-2789
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2789 to expose endpoints map[pod2:[80]]
Oct  1 10:47:45.986: INFO: successfully validated that service endpoint-test2 in namespace services-2789 exposes endpoints map[pod2:[80]] (1.014256831s elapsed)
STEP: Deleting pod pod2 in namespace services-2789
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2789 to expose endpoints map[]
Oct  1 10:47:46.993: INFO: successfully validated that service endpoint-test2 in namespace services-2789 exposes endpoints map[] (1.004377605s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:47:47.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2789" for this suite.
Oct  1 10:47:53.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:47:53.068: INFO: namespace services-2789 deletion completed in 6.063980486s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.184 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:47:53.068: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Oct  1 10:47:53.344: INFO: Pod name wrapped-volume-race-d40cd163-c585-4094-bd2e-6911dc52b6ff: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d40cd163-c585-4094-bd2e-6911dc52b6ff in namespace emptydir-wrapper-9468, will wait for the garbage collector to delete the pods
I1001 10:48:07.434042      17 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 10:48:07.434068      17 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Oct  1 10:48:07.488: INFO: Deleting ReplicationController wrapped-volume-race-d40cd163-c585-4094-bd2e-6911dc52b6ff took: 4.700708ms
I1001 10:48:07.789208      17 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-9468/wrapped-volume-race-d40cd163-c585-4094-bd2e-6911dc52b6ff-l6vcj in state Running, deletion time 2019-10-01 10:48:37 +0000 UTC
I1001 10:48:07.789251      17 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-9468/wrapped-volume-race-d40cd163-c585-4094-bd2e-6911dc52b6ff-xjpwc in state Running, deletion time 2019-10-01 10:48:37 +0000 UTC
I1001 10:48:07.789260      17 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-9468/wrapped-volume-race-d40cd163-c585-4094-bd2e-6911dc52b6ff-4db4h in state Running, deletion time 2019-10-01 10:48:37 +0000 UTC
I1001 10:48:07.789268      17 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-9468/wrapped-volume-race-d40cd163-c585-4094-bd2e-6911dc52b6ff-pbpl7 in state Running, deletion time 2019-10-01 10:48:37 +0000 UTC
I1001 10:48:07.789276      17 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-9468/wrapped-volume-race-d40cd163-c585-4094-bd2e-6911dc52b6ff-jzm4v in state Running, deletion time 2019-10-01 10:48:37 +0000 UTC
Oct  1 10:48:07.789: INFO: Terminating ReplicationController wrapped-volume-race-d40cd163-c585-4094-bd2e-6911dc52b6ff pods took: 300.368827ms
STEP: Creating RC which spawns configmap-volume pods
Oct  1 10:48:49.501: INFO: Pod name wrapped-volume-race-34457da5-6495-4879-9646-d6c175ee48fd: Found 0 pods out of 5
Oct  1 10:48:54.505: INFO: Pod name wrapped-volume-race-34457da5-6495-4879-9646-d6c175ee48fd: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-34457da5-6495-4879-9646-d6c175ee48fd in namespace emptydir-wrapper-9468, will wait for the garbage collector to delete the pods
I1001 10:49:04.520903      17 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 10:49:04.520930      17 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Oct  1 10:49:04.575: INFO: Deleting ReplicationController wrapped-volume-race-34457da5-6495-4879-9646-d6c175ee48fd took: 4.655986ms
I1001 10:49:04.876110      17 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-9468/wrapped-volume-race-34457da5-6495-4879-9646-d6c175ee48fd-2t22l in state Running, deletion time 2019-10-01 10:49:34 +0000 UTC
I1001 10:49:04.876150      17 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-9468/wrapped-volume-race-34457da5-6495-4879-9646-d6c175ee48fd-8g4jz in state Running, deletion time 2019-10-01 10:49:34 +0000 UTC
I1001 10:49:04.876159      17 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-9468/wrapped-volume-race-34457da5-6495-4879-9646-d6c175ee48fd-6lmqm in state Running, deletion time 2019-10-01 10:49:34 +0000 UTC
I1001 10:49:04.876166      17 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-9468/wrapped-volume-race-34457da5-6495-4879-9646-d6c175ee48fd-lps26 in state Running, deletion time 2019-10-01 10:49:34 +0000 UTC
I1001 10:49:04.876172      17 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-9468/wrapped-volume-race-34457da5-6495-4879-9646-d6c175ee48fd-pb847 in state Running, deletion time 2019-10-01 10:49:34 +0000 UTC
Oct  1 10:49:04.876: INFO: Terminating ReplicationController wrapped-volume-race-34457da5-6495-4879-9646-d6c175ee48fd pods took: 300.41657ms
STEP: Creating RC which spawns configmap-volume pods
Oct  1 10:49:49.086: INFO: Pod name wrapped-volume-race-0b1ceb21-2434-4283-8d9d-0811a5bfc40d: Found 0 pods out of 5
Oct  1 10:49:54.091: INFO: Pod name wrapped-volume-race-0b1ceb21-2434-4283-8d9d-0811a5bfc40d: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-0b1ceb21-2434-4283-8d9d-0811a5bfc40d in namespace emptydir-wrapper-9468, will wait for the garbage collector to delete the pods
I1001 10:50:04.107475      17 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 10:50:04.107503      17 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Oct  1 10:50:04.163: INFO: Deleting ReplicationController wrapped-volume-race-0b1ceb21-2434-4283-8d9d-0811a5bfc40d took: 5.301258ms
I1001 10:50:04.463420      17 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-9468/wrapped-volume-race-0b1ceb21-2434-4283-8d9d-0811a5bfc40d-p7n52 in state Running, deletion time 2019-10-01 10:50:34 +0000 UTC
I1001 10:50:04.463460      17 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-9468/wrapped-volume-race-0b1ceb21-2434-4283-8d9d-0811a5bfc40d-q6x97 in state Running, deletion time 2019-10-01 10:50:34 +0000 UTC
I1001 10:50:04.463469      17 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-9468/wrapped-volume-race-0b1ceb21-2434-4283-8d9d-0811a5bfc40d-db5sl in state Running, deletion time 2019-10-01 10:50:34 +0000 UTC
I1001 10:50:04.463475      17 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-9468/wrapped-volume-race-0b1ceb21-2434-4283-8d9d-0811a5bfc40d-m6nlt in state Running, deletion time 2019-10-01 10:50:34 +0000 UTC
I1001 10:50:04.463482      17 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-9468/wrapped-volume-race-0b1ceb21-2434-4283-8d9d-0811a5bfc40d-bbz5x in state Running, deletion time 2019-10-01 10:50:34 +0000 UTC
Oct  1 10:50:04.463: INFO: Terminating ReplicationController wrapped-volume-race-0b1ceb21-2434-4283-8d9d-0811a5bfc40d pods took: 300.474832ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:50:39.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9468" for this suite.
Oct  1 10:50:45.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:50:45.735: INFO: namespace emptydir-wrapper-9468 deletion completed in 6.061972043s

• [SLOW TEST:172.667 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:50:45.735: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-220b1660-ff6a-42bd-ad18-1d9402c53bf2
Oct  1 10:50:45.764: INFO: Pod name my-hostname-basic-220b1660-ff6a-42bd-ad18-1d9402c53bf2: Found 0 pods out of 1
Oct  1 10:50:50.767: INFO: Pod name my-hostname-basic-220b1660-ff6a-42bd-ad18-1d9402c53bf2: Found 1 pods out of 1
Oct  1 10:50:50.767: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-220b1660-ff6a-42bd-ad18-1d9402c53bf2" are running
Oct  1 10:50:50.768: INFO: Pod "my-hostname-basic-220b1660-ff6a-42bd-ad18-1d9402c53bf2-5fpkz" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-01 10:50:45 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-01 10:50:47 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-01 10:50:47 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-01 10:50:45 +0000 UTC Reason: Message:}])
Oct  1 10:50:50.768: INFO: Trying to dial the pod
Oct  1 10:50:55.776: INFO: Controller my-hostname-basic-220b1660-ff6a-42bd-ad18-1d9402c53bf2: Got expected result from replica 1 [my-hostname-basic-220b1660-ff6a-42bd-ad18-1d9402c53bf2-5fpkz]: "my-hostname-basic-220b1660-ff6a-42bd-ad18-1d9402c53bf2-5fpkz", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:50:55.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-986" for this suite.
Oct  1 10:51:01.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:51:01.847: INFO: namespace replication-controller-986 deletion completed in 6.068770836s

• [SLOW TEST:16.112 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:51:01.848: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:51:01.874: INFO: Creating ReplicaSet my-hostname-basic-98daf35b-34ff-4873-bbfe-d19a94b3175b
Oct  1 10:51:01.880: INFO: Pod name my-hostname-basic-98daf35b-34ff-4873-bbfe-d19a94b3175b: Found 0 pods out of 1
Oct  1 10:51:06.883: INFO: Pod name my-hostname-basic-98daf35b-34ff-4873-bbfe-d19a94b3175b: Found 1 pods out of 1
Oct  1 10:51:06.883: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-98daf35b-34ff-4873-bbfe-d19a94b3175b" is running
Oct  1 10:51:06.885: INFO: Pod "my-hostname-basic-98daf35b-34ff-4873-bbfe-d19a94b3175b-s2vh2" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-01 10:51:01 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-01 10:51:03 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-01 10:51:03 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-01 10:51:01 +0000 UTC Reason: Message:}])
Oct  1 10:51:06.885: INFO: Trying to dial the pod
Oct  1 10:51:11.893: INFO: Controller my-hostname-basic-98daf35b-34ff-4873-bbfe-d19a94b3175b: Got expected result from replica 1 [my-hostname-basic-98daf35b-34ff-4873-bbfe-d19a94b3175b-s2vh2]: "my-hostname-basic-98daf35b-34ff-4873-bbfe-d19a94b3175b-s2vh2", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:51:11.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6297" for this suite.
Oct  1 10:51:17.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:51:17.954: INFO: namespace replicaset-6297 deletion completed in 6.058167393s

• [SLOW TEST:16.106 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:51:17.954: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Oct  1 10:51:17.974: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct  1 10:51:17.986: INFO: Waiting for terminating namespaces to be deleted...
Oct  1 10:51:17.988: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-16-136 before test
Oct  1 10:51:17.999: INFO: sonobuoy from sonobuoy started at 2019-10-01 09:21:20 +0000 UTC (1 container statuses recorded)
Oct  1 10:51:17.999: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct  1 10:51:17.999: INFO: sonobuoy-systemd-logs-daemon-set-c998de73b1b44522-6mdfj from sonobuoy started at 2019-10-01 09:21:21 +0000 UTC (2 container statuses recorded)
Oct  1 10:51:17.999: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct  1 10:51:17.999: INFO: 	Container systemd-logs ready: true, restart count 1
Oct  1 10:51:17.999: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-29-44 before test
Oct  1 10:51:18.013: INFO: sonobuoy-e2e-job-41fbe38c4f734fd3 from sonobuoy started at 2019-10-01 09:21:21 +0000 UTC (2 container statuses recorded)
Oct  1 10:51:18.013: INFO: 	Container e2e ready: true, restart count 0
Oct  1 10:51:18.013: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  1 10:51:18.013: INFO: coredns-9b8997588-8dd8w from kube-system started at 2019-10-01 09:06:34 +0000 UTC (1 container statuses recorded)
Oct  1 10:51:18.013: INFO: 	Container coredns ready: true, restart count 0
Oct  1 10:51:18.013: INFO: sonobuoy-systemd-logs-daemon-set-c998de73b1b44522-4jgxd from sonobuoy started at 2019-10-01 09:21:21 +0000 UTC (2 container statuses recorded)
Oct  1 10:51:18.013: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct  1 10:51:18.013: INFO: 	Container systemd-logs ready: true, restart count 1
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-06909e31-6ee9-4de9-b8fe-83adfec2d221 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-06909e31-6ee9-4de9-b8fe-83adfec2d221 off the node ip-172-31-16-136
STEP: verifying the node doesn't have the label kubernetes.io/e2e-06909e31-6ee9-4de9-b8fe-83adfec2d221
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:51:24.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4052" for this suite.
Oct  1 10:51:34.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:51:34.133: INFO: namespace sched-pred-4052 deletion completed in 10.063795898s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:16.179 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
I1001 10:51:34.133934      17 request.go:706] Error in request: resource name may not be empty
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:51:34.134: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-njw4
STEP: Creating a pod to test atomic-volume-subpath
Oct  1 10:51:34.169: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-njw4" in namespace "subpath-6167" to be "success or failure"
Oct  1 10:51:34.171: INFO: Pod "pod-subpath-test-configmap-njw4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.186366ms
Oct  1 10:51:36.174: INFO: Pod "pod-subpath-test-configmap-njw4": Phase="Running", Reason="", readiness=true. Elapsed: 2.005144981s
Oct  1 10:51:38.177: INFO: Pod "pod-subpath-test-configmap-njw4": Phase="Running", Reason="", readiness=true. Elapsed: 4.008190742s
Oct  1 10:51:40.180: INFO: Pod "pod-subpath-test-configmap-njw4": Phase="Running", Reason="", readiness=true. Elapsed: 6.011309109s
Oct  1 10:51:42.183: INFO: Pod "pod-subpath-test-configmap-njw4": Phase="Running", Reason="", readiness=true. Elapsed: 8.014355421s
Oct  1 10:51:44.186: INFO: Pod "pod-subpath-test-configmap-njw4": Phase="Running", Reason="", readiness=true. Elapsed: 10.01677903s
Oct  1 10:51:46.189: INFO: Pod "pod-subpath-test-configmap-njw4": Phase="Running", Reason="", readiness=true. Elapsed: 12.019831958s
Oct  1 10:51:48.192: INFO: Pod "pod-subpath-test-configmap-njw4": Phase="Running", Reason="", readiness=true. Elapsed: 14.02288731s
Oct  1 10:51:50.195: INFO: Pod "pod-subpath-test-configmap-njw4": Phase="Running", Reason="", readiness=true. Elapsed: 16.026066556s
Oct  1 10:51:52.198: INFO: Pod "pod-subpath-test-configmap-njw4": Phase="Running", Reason="", readiness=true. Elapsed: 18.028944858s
Oct  1 10:51:54.201: INFO: Pod "pod-subpath-test-configmap-njw4": Phase="Running", Reason="", readiness=true. Elapsed: 20.032029454s
Oct  1 10:51:56.204: INFO: Pod "pod-subpath-test-configmap-njw4": Phase="Running", Reason="", readiness=true. Elapsed: 22.035142607s
Oct  1 10:51:58.207: INFO: Pod "pod-subpath-test-configmap-njw4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.03826947s
STEP: Saw pod success
Oct  1 10:51:58.207: INFO: Pod "pod-subpath-test-configmap-njw4" satisfied condition "success or failure"
Oct  1 10:51:58.209: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-subpath-test-configmap-njw4 container test-container-subpath-configmap-njw4: <nil>
STEP: delete the pod
Oct  1 10:51:58.222: INFO: Waiting for pod pod-subpath-test-configmap-njw4 to disappear
Oct  1 10:51:58.229: INFO: Pod pod-subpath-test-configmap-njw4 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-njw4
Oct  1 10:51:58.229: INFO: Deleting pod "pod-subpath-test-configmap-njw4" in namespace "subpath-6167"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:51:58.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6167" for this suite.
Oct  1 10:52:04.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:52:04.290: INFO: namespace subpath-6167 deletion completed in 6.056466533s

• [SLOW TEST:30.156 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:52:04.290: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1433
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-1433
Oct  1 10:52:04.320: INFO: Found 0 stateful pods, waiting for 1
Oct  1 10:52:14.324: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct  1 10:52:14.336: INFO: Deleting all statefulset in ns statefulset-1433
Oct  1 10:52:14.338: INFO: Scaling statefulset ss to 0
Oct  1 10:52:24.369: INFO: Waiting for statefulset status.replicas updated to 0
Oct  1 10:52:24.371: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:52:24.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1433" for this suite.
Oct  1 10:52:30.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:52:30.445: INFO: namespace statefulset-1433 deletion completed in 6.064282124s

• [SLOW TEST:26.155 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:52:30.446: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Oct  1 10:52:30.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 --namespace=kubectl-3803 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Oct  1 10:52:32.526: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Oct  1 10:52:32.526: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:52:34.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3803" for this suite.
Oct  1 10:52:40.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:52:40.593: INFO: namespace kubectl-3803 deletion completed in 6.060969362s

• [SLOW TEST:10.147 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:52:40.593: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:52:51.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8622" for this suite.
Oct  1 10:52:57.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:52:57.698: INFO: namespace resourcequota-8622 deletion completed in 6.056763619s

• [SLOW TEST:17.105 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:52:57.698: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct  1 10:52:57.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-7309'
Oct  1 10:52:57.793: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct  1 10:52:57.793: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Oct  1 10:52:57.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 delete deployment e2e-test-httpd-deployment --namespace=kubectl-7309'
Oct  1 10:52:57.876: INFO: stderr: ""
Oct  1 10:52:57.876: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:52:57.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7309" for this suite.
Oct  1 10:53:25.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:53:25.940: INFO: namespace kubectl-7309 deletion completed in 28.061108525s

• [SLOW TEST:28.243 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:53:25.940: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-faf33bd8-1b2c-4d2f-b5ec-39388330cd74
STEP: Creating a pod to test consume configMaps
Oct  1 10:53:25.972: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-acfd2563-3a2b-457f-9b1a-bb568a052ef9" in namespace "projected-6052" to be "success or failure"
Oct  1 10:53:25.974: INFO: Pod "pod-projected-configmaps-acfd2563-3a2b-457f-9b1a-bb568a052ef9": Phase="Pending", Reason="", readiness=false. Elapsed: 1.980415ms
Oct  1 10:53:27.977: INFO: Pod "pod-projected-configmaps-acfd2563-3a2b-457f-9b1a-bb568a052ef9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00496018s
STEP: Saw pod success
Oct  1 10:53:27.977: INFO: Pod "pod-projected-configmaps-acfd2563-3a2b-457f-9b1a-bb568a052ef9" satisfied condition "success or failure"
Oct  1 10:53:27.979: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-projected-configmaps-acfd2563-3a2b-457f-9b1a-bb568a052ef9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 10:53:27.991: INFO: Waiting for pod pod-projected-configmaps-acfd2563-3a2b-457f-9b1a-bb568a052ef9 to disappear
Oct  1 10:53:27.999: INFO: Pod pod-projected-configmaps-acfd2563-3a2b-457f-9b1a-bb568a052ef9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:53:27.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6052" for this suite.
Oct  1 10:53:34.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:53:34.061: INFO: namespace projected-6052 deletion completed in 6.060164881s

• [SLOW TEST:8.121 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:53:34.062: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:53:34.086: INFO: Waiting up to 5m0s for pod "busybox-user-65534-b70bb741-f973-40ea-a653-e6c43de423e3" in namespace "security-context-test-2436" to be "success or failure"
Oct  1 10:53:34.088: INFO: Pod "busybox-user-65534-b70bb741-f973-40ea-a653-e6c43de423e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064024ms
Oct  1 10:53:36.091: INFO: Pod "busybox-user-65534-b70bb741-f973-40ea-a653-e6c43de423e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005048578s
Oct  1 10:53:36.091: INFO: Pod "busybox-user-65534-b70bb741-f973-40ea-a653-e6c43de423e3" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:53:36.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2436" for this suite.
Oct  1 10:53:42.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:53:42.152: INFO: namespace security-context-test-2436 deletion completed in 6.058457592s

• [SLOW TEST:8.090 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:53:42.152: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-9ff3ecbd-a530-4e4f-9a5c-8cefcd51474a
STEP: Creating a pod to test consume configMaps
Oct  1 10:53:42.182: INFO: Waiting up to 5m0s for pod "pod-configmaps-3180a653-402a-4aac-8bf4-bf871c308925" in namespace "configmap-2930" to be "success or failure"
Oct  1 10:53:42.184: INFO: Pod "pod-configmaps-3180a653-402a-4aac-8bf4-bf871c308925": Phase="Pending", Reason="", readiness=false. Elapsed: 1.703747ms
Oct  1 10:53:44.187: INFO: Pod "pod-configmaps-3180a653-402a-4aac-8bf4-bf871c308925": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004724895s
STEP: Saw pod success
Oct  1 10:53:44.187: INFO: Pod "pod-configmaps-3180a653-402a-4aac-8bf4-bf871c308925" satisfied condition "success or failure"
Oct  1 10:53:44.189: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-configmaps-3180a653-402a-4aac-8bf4-bf871c308925 container configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 10:53:44.202: INFO: Waiting for pod pod-configmaps-3180a653-402a-4aac-8bf4-bf871c308925 to disappear
Oct  1 10:53:44.209: INFO: Pod pod-configmaps-3180a653-402a-4aac-8bf4-bf871c308925 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:53:44.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2930" for this suite.
Oct  1 10:53:50.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:53:50.267: INFO: namespace configmap-2930 deletion completed in 6.056412894s

• [SLOW TEST:8.115 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:53:50.268: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct  1 10:53:50.290: INFO: Waiting up to 5m0s for pod "pod-a766060b-eeb3-4abf-ab57-874770f9c8e7" in namespace "emptydir-990" to be "success or failure"
Oct  1 10:53:50.296: INFO: Pod "pod-a766060b-eeb3-4abf-ab57-874770f9c8e7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.637429ms
Oct  1 10:53:52.300: INFO: Pod "pod-a766060b-eeb3-4abf-ab57-874770f9c8e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009722965s
STEP: Saw pod success
Oct  1 10:53:52.300: INFO: Pod "pod-a766060b-eeb3-4abf-ab57-874770f9c8e7" satisfied condition "success or failure"
Oct  1 10:53:52.301: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-a766060b-eeb3-4abf-ab57-874770f9c8e7 container test-container: <nil>
STEP: delete the pod
Oct  1 10:53:52.314: INFO: Waiting for pod pod-a766060b-eeb3-4abf-ab57-874770f9c8e7 to disappear
Oct  1 10:53:52.325: INFO: Pod pod-a766060b-eeb3-4abf-ab57-874770f9c8e7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:53:52.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-990" for this suite.
Oct  1 10:53:58.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:53:58.389: INFO: namespace emptydir-990 deletion completed in 6.060536497s

• [SLOW TEST:8.121 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:53:58.389: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:53:58.409: INFO: Creating deployment "test-recreate-deployment"
Oct  1 10:53:58.417: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Oct  1 10:53:58.421: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Oct  1 10:54:00.426: INFO: Waiting deployment "test-recreate-deployment" to complete
Oct  1 10:54:00.428: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Oct  1 10:54:00.433: INFO: Updating deployment test-recreate-deployment
Oct  1 10:54:00.433: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Oct  1 10:54:00.522: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-6276 /apis/apps/v1/namespaces/deployment-6276/deployments/test-recreate-deployment d8d744dd-6365-4376-acd3-ebe01a190417 20704 2 2019-10-01 10:53:58 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003adafc8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-10-01 10:54:00 +0000 UTC,LastTransitionTime:2019-10-01 10:54:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2019-10-01 10:54:00 +0000 UTC,LastTransitionTime:2019-10-01 10:53:58 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Oct  1 10:54:00.524: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-6276 /apis/apps/v1/namespaces/deployment-6276/replicasets/test-recreate-deployment-5f94c574ff 17a61e60-9035-4b67-aaf5-088fac79fb02 20701 1 2019-10-01 10:54:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment d8d744dd-6365-4376-acd3-ebe01a190417 0xc003adb3b7 0xc003adb3b8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003adb418 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct  1 10:54:00.524: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Oct  1 10:54:00.524: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-6276 /apis/apps/v1/namespaces/deployment-6276/replicasets/test-recreate-deployment-68fc85c7bb c23ecf0d-bba1-41b6-8b76-004a03f5adf3 20693 2 2019-10-01 10:53:58 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment d8d744dd-6365-4376-acd3-ebe01a190417 0xc003adb487 0xc003adb488}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003adb4e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct  1 10:54:00.527: INFO: Pod "test-recreate-deployment-5f94c574ff-snhnd" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-snhnd test-recreate-deployment-5f94c574ff- deployment-6276 /api/v1/namespaces/deployment-6276/pods/test-recreate-deployment-5f94c574ff-snhnd 7712bf1e-2772-47a7-9ce2-691804ebaf54 20705 0 2019-10-01 10:54:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff 17a61e60-9035-4b67-aaf5-088fac79fb02 0xc003646747 0xc003646748}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-czw2f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-czw2f,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-czw2f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-16-136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:54:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:54:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:54:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:54:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.16.136,PodIP:,StartTime:2019-10-01 10:54:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:54:00.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6276" for this suite.
Oct  1 10:54:06.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:54:06.587: INFO: namespace deployment-6276 deletion completed in 6.058179406s

• [SLOW TEST:8.198 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:54:06.587: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-4293
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct  1 10:54:06.605: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct  1 10:54:24.648: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.1.2.73 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4293 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 10:54:24.649: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 10:54:25.763: INFO: Found all expected endpoints: [netserver-0]
Oct  1 10:54:25.765: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.1.63.5 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4293 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  1 10:54:25.765: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 10:54:26.878: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:54:26.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4293" for this suite.
Oct  1 10:54:38.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:54:38.944: INFO: namespace pod-network-test-4293 deletion completed in 12.062813663s

• [SLOW TEST:32.356 seconds]
[sig-network] Networking
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:54:38.944: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct  1 10:54:38.970: INFO: Waiting up to 5m0s for pod "pod-240dad55-dfb7-4afb-9065-9232adadfb9f" in namespace "emptydir-5327" to be "success or failure"
Oct  1 10:54:38.976: INFO: Pod "pod-240dad55-dfb7-4afb-9065-9232adadfb9f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.247796ms
Oct  1 10:54:40.979: INFO: Pod "pod-240dad55-dfb7-4afb-9065-9232adadfb9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008399321s
STEP: Saw pod success
Oct  1 10:54:40.979: INFO: Pod "pod-240dad55-dfb7-4afb-9065-9232adadfb9f" satisfied condition "success or failure"
Oct  1 10:54:40.981: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-240dad55-dfb7-4afb-9065-9232adadfb9f container test-container: <nil>
STEP: delete the pod
Oct  1 10:54:40.990: INFO: Waiting for pod pod-240dad55-dfb7-4afb-9065-9232adadfb9f to disappear
Oct  1 10:54:40.993: INFO: Pod pod-240dad55-dfb7-4afb-9065-9232adadfb9f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:54:40.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5327" for this suite.
Oct  1 10:54:47.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:54:47.069: INFO: namespace emptydir-5327 deletion completed in 6.073708648s

• [SLOW TEST:8.125 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:54:47.069: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8487.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8487.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8487.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8487.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8487.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8487.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct  1 10:54:49.125: INFO: DNS probes using dns-8487/dns-test-98a41c92-20c5-4651-b752-04340c3a2969 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:54:49.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8487" for this suite.
Oct  1 10:54:55.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:54:55.216: INFO: namespace dns-8487 deletion completed in 6.059988219s

• [SLOW TEST:8.147 seconds]
[sig-network] DNS
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:54:55.216: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-bbb0d78a-b4b2-4ad5-812a-41b8e926dcdc
STEP: Creating secret with name s-test-opt-upd-989bd8e0-6526-47d9-a769-7bf6dd10b1a1
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-bbb0d78a-b4b2-4ad5-812a-41b8e926dcdc
STEP: Updating secret s-test-opt-upd-989bd8e0-6526-47d9-a769-7bf6dd10b1a1
STEP: Creating secret with name s-test-opt-create-1455a02e-db96-4261-a8fd-7ae344695f96
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:54:59.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9900" for this suite.
Oct  1 10:55:11.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:55:11.383: INFO: namespace secrets-9900 deletion completed in 12.061086007s

• [SLOW TEST:16.167 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:55:11.383: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Oct  1 10:55:11.408: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct  1 10:55:11.420: INFO: Waiting for terminating namespaces to be deleted...
Oct  1 10:55:11.422: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-16-136 before test
Oct  1 10:55:11.425: INFO: sonobuoy from sonobuoy started at 2019-10-01 09:21:20 +0000 UTC (1 container statuses recorded)
Oct  1 10:55:11.425: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct  1 10:55:11.425: INFO: sonobuoy-systemd-logs-daemon-set-c998de73b1b44522-6mdfj from sonobuoy started at 2019-10-01 09:21:21 +0000 UTC (2 container statuses recorded)
Oct  1 10:55:11.425: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct  1 10:55:11.425: INFO: 	Container systemd-logs ready: true, restart count 1
Oct  1 10:55:11.425: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-29-44 before test
Oct  1 10:55:11.448: INFO: sonobuoy-systemd-logs-daemon-set-c998de73b1b44522-4jgxd from sonobuoy started at 2019-10-01 09:21:21 +0000 UTC (2 container statuses recorded)
Oct  1 10:55:11.449: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct  1 10:55:11.449: INFO: 	Container systemd-logs ready: true, restart count 1
Oct  1 10:55:11.449: INFO: coredns-9b8997588-8dd8w from kube-system started at 2019-10-01 09:06:34 +0000 UTC (1 container statuses recorded)
Oct  1 10:55:11.449: INFO: 	Container coredns ready: true, restart count 0
Oct  1 10:55:11.449: INFO: sonobuoy-e2e-job-41fbe38c4f734fd3 from sonobuoy started at 2019-10-01 09:21:21 +0000 UTC (2 container statuses recorded)
Oct  1 10:55:11.449: INFO: 	Container e2e ready: true, restart count 0
Oct  1 10:55:11.449: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node ip-172-31-16-136
STEP: verifying the node has the label node ip-172-31-29-44
Oct  1 10:55:11.479: INFO: Pod coredns-9b8997588-8dd8w requesting resource cpu=100m on Node ip-172-31-29-44
Oct  1 10:55:11.479: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-16-136
Oct  1 10:55:11.479: INFO: Pod sonobuoy-e2e-job-41fbe38c4f734fd3 requesting resource cpu=0m on Node ip-172-31-29-44
Oct  1 10:55:11.479: INFO: Pod sonobuoy-systemd-logs-daemon-set-c998de73b1b44522-4jgxd requesting resource cpu=0m on Node ip-172-31-29-44
Oct  1 10:55:11.479: INFO: Pod sonobuoy-systemd-logs-daemon-set-c998de73b1b44522-6mdfj requesting resource cpu=0m on Node ip-172-31-16-136
STEP: Starting Pods to consume most of the cluster CPU.
Oct  1 10:55:11.479: INFO: Creating a pod which consumes cpu=2730m on Node ip-172-31-29-44
Oct  1 10:55:11.483: INFO: Creating a pod which consumes cpu=2800m on Node ip-172-31-16-136
STEP: Creating another pod that requires unavailable amount of CPU.
I1001 10:55:13.504016      17 reflector.go:120] Starting reflector *v1.Event (0s) from k8s.io/kubernetes/test/e2e/common/events.go:136
I1001 10:55:13.504044      17 reflector.go:158] Listing and watching *v1.Event from k8s.io/kubernetes/test/e2e/common/events.go:136
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3849ecf3-c1dc-4416-9551-78240405a422.15c980926bd1cd4e], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9892/filler-pod-3849ecf3-c1dc-4416-9551-78240405a422 to ip-172-31-16-136]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3849ecf3-c1dc-4416-9551-78240405a422.15c980929c5c528e], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3849ecf3-c1dc-4416-9551-78240405a422.15c98092a3113a2d], Reason = [Created], Message = [Created container filler-pod-3849ecf3-c1dc-4416-9551-78240405a422]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3849ecf3-c1dc-4416-9551-78240405a422.15c98092b2594297], Reason = [Started], Message = [Started container filler-pod-3849ecf3-c1dc-4416-9551-78240405a422]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7dc12bcd-a85c-4b7a-9e7d-7e79b46bb8bf.15c980926b1cbeac], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9892/filler-pod-7dc12bcd-a85c-4b7a-9e7d-7e79b46bb8bf to ip-172-31-29-44]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7dc12bcd-a85c-4b7a-9e7d-7e79b46bb8bf.15c980929ac2450d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7dc12bcd-a85c-4b7a-9e7d-7e79b46bb8bf.15c98092a15caed0], Reason = [Created], Message = [Created container filler-pod-7dc12bcd-a85c-4b7a-9e7d-7e79b46bb8bf]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7dc12bcd-a85c-4b7a-9e7d-7e79b46bb8bf.15c98092ab555f46], Reason = [Started], Message = [Started container filler-pod-7dc12bcd-a85c-4b7a-9e7d-7e79b46bb8bf]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15c98092e3bbf2c7], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node ip-172-31-16-136
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-31-29-44
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:55:14.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9892" for this suite.
Oct  1 10:55:20.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:55:20.602: INFO: namespace sched-pred-9892 deletion completed in 6.062101096s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

I1001 10:55:20.602112      17 request.go:706] Error in request: resource name may not be empty
• [SLOW TEST:9.219 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:55:20.602: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Oct  1 10:55:20.636: INFO: Waiting up to 5m0s for pod "downward-api-4a1e8a4c-30f3-4966-bbe4-9192229ed460" in namespace "downward-api-3329" to be "success or failure"
Oct  1 10:55:20.638: INFO: Pod "downward-api-4a1e8a4c-30f3-4966-bbe4-9192229ed460": Phase="Pending", Reason="", readiness=false. Elapsed: 1.711035ms
Oct  1 10:55:22.641: INFO: Pod "downward-api-4a1e8a4c-30f3-4966-bbe4-9192229ed460": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004465248s
STEP: Saw pod success
Oct  1 10:55:22.641: INFO: Pod "downward-api-4a1e8a4c-30f3-4966-bbe4-9192229ed460" satisfied condition "success or failure"
Oct  1 10:55:22.643: INFO: Trying to get logs from node ip-172-31-16-136 pod downward-api-4a1e8a4c-30f3-4966-bbe4-9192229ed460 container dapi-container: <nil>
STEP: delete the pod
Oct  1 10:55:22.653: INFO: Waiting for pod downward-api-4a1e8a4c-30f3-4966-bbe4-9192229ed460 to disappear
Oct  1 10:55:22.655: INFO: Pod downward-api-4a1e8a4c-30f3-4966-bbe4-9192229ed460 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:55:22.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3329" for this suite.
Oct  1 10:55:28.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:55:28.716: INFO: namespace downward-api-3329 deletion completed in 6.058437766s

• [SLOW TEST:8.114 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:55:28.716: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-3939
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-3939
STEP: creating replication controller externalsvc in namespace services-3939
I1001 10:55:28.755296      17 runners.go:184] Created replication controller with name: externalsvc, namespace: services-3939, replica count: 2
I1001 10:55:28.755387      17 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 10:55:28.755412      17 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 10:55:31.805793      17 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Oct  1 10:55:31.815: INFO: Creating new exec pod
Oct  1 10:55:33.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=services-3939 execpodbpdlz -- /bin/sh -x -c nslookup clusterip-service'
Oct  1 10:55:34.055: INFO: stderr: "+ nslookup clusterip-service\n"
Oct  1 10:55:34.055: INFO: stdout: "Server:\t\t10.152.183.10\nAddress:\t10.152.183.10#53\n\nclusterip-service.services-3939.svc.cluster.local\tcanonical name = externalsvc.services-3939.svc.cluster.local.\nName:\texternalsvc.services-3939.svc.cluster.local\nAddress: 10.152.183.104\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-3939, will wait for the garbage collector to delete the pods
I1001 10:55:34.058831      17 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I1001 10:55:34.058861      17 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Oct  1 10:55:34.114: INFO: Deleting ReplicationController externalsvc took: 5.150026ms
Oct  1 10:55:34.414: INFO: Terminating ReplicationController externalsvc pods took: 300.36302ms
I1001 10:55:34.414502      17 controller_utils.go:810] Ignoring inactive pod services-3939/externalsvc-jg5lx in state Running, deletion time 2019-10-01 10:55:35 +0000 UTC
I1001 10:55:34.414546      17 controller_utils.go:810] Ignoring inactive pod services-3939/externalsvc-nw4zj in state Running, deletion time 2019-10-01 10:55:35 +0000 UTC
Oct  1 10:55:49.124: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:55:49.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3939" for this suite.
Oct  1 10:55:55.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:55:55.197: INFO: namespace services-3939 deletion completed in 6.062280888s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:26.481 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:55:55.198: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:55:55.218: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Oct  1 10:55:57.244: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:55:58.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9909" for this suite.
Oct  1 10:56:04.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:56:04.314: INFO: namespace replication-controller-9909 deletion completed in 6.060961383s

• [SLOW TEST:9.116 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:56:04.314: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct  1 10:56:04.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-4531'
Oct  1 10:56:04.406: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct  1 10:56:04.406: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Oct  1 10:56:04.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 delete jobs e2e-test-httpd-job --namespace=kubectl-4531'
Oct  1 10:56:04.484: INFO: stderr: ""
Oct  1 10:56:04.484: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:56:04.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4531" for this suite.
Oct  1 10:56:20.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:56:20.556: INFO: namespace kubectl-4531 deletion completed in 16.069422715s

• [SLOW TEST:16.242 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:56:20.556: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Oct  1 10:56:20.584: INFO: Waiting up to 5m0s for pod "client-containers-77c2bd08-9790-446b-a753-a71dca0adb81" in namespace "containers-5923" to be "success or failure"
Oct  1 10:56:20.586: INFO: Pod "client-containers-77c2bd08-9790-446b-a753-a71dca0adb81": Phase="Pending", Reason="", readiness=false. Elapsed: 1.820847ms
Oct  1 10:56:22.589: INFO: Pod "client-containers-77c2bd08-9790-446b-a753-a71dca0adb81": Phase="Running", Reason="", readiness=true. Elapsed: 2.004922189s
Oct  1 10:56:24.592: INFO: Pod "client-containers-77c2bd08-9790-446b-a753-a71dca0adb81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007936291s
STEP: Saw pod success
Oct  1 10:56:24.592: INFO: Pod "client-containers-77c2bd08-9790-446b-a753-a71dca0adb81" satisfied condition "success or failure"
Oct  1 10:56:24.594: INFO: Trying to get logs from node ip-172-31-16-136 pod client-containers-77c2bd08-9790-446b-a753-a71dca0adb81 container test-container: <nil>
STEP: delete the pod
Oct  1 10:56:24.603: INFO: Waiting for pod client-containers-77c2bd08-9790-446b-a753-a71dca0adb81 to disappear
Oct  1 10:56:24.605: INFO: Pod client-containers-77c2bd08-9790-446b-a753-a71dca0adb81 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:56:24.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5923" for this suite.
Oct  1 10:56:30.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:56:30.664: INFO: namespace containers-5923 deletion completed in 6.057112936s

• [SLOW TEST:10.108 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:56:30.664: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Oct  1 10:56:30.685: INFO: Waiting up to 5m0s for pod "client-containers-933d3e4a-f781-42c2-94c2-aeaf5454a476" in namespace "containers-4261" to be "success or failure"
Oct  1 10:56:30.688: INFO: Pod "client-containers-933d3e4a-f781-42c2-94c2-aeaf5454a476": Phase="Pending", Reason="", readiness=false. Elapsed: 2.622749ms
Oct  1 10:56:32.691: INFO: Pod "client-containers-933d3e4a-f781-42c2-94c2-aeaf5454a476": Phase="Running", Reason="", readiness=true. Elapsed: 2.005769894s
Oct  1 10:56:34.694: INFO: Pod "client-containers-933d3e4a-f781-42c2-94c2-aeaf5454a476": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008824552s
STEP: Saw pod success
Oct  1 10:56:34.694: INFO: Pod "client-containers-933d3e4a-f781-42c2-94c2-aeaf5454a476" satisfied condition "success or failure"
Oct  1 10:56:34.696: INFO: Trying to get logs from node ip-172-31-16-136 pod client-containers-933d3e4a-f781-42c2-94c2-aeaf5454a476 container test-container: <nil>
STEP: delete the pod
Oct  1 10:56:34.705: INFO: Waiting for pod client-containers-933d3e4a-f781-42c2-94c2-aeaf5454a476 to disappear
Oct  1 10:56:34.709: INFO: Pod client-containers-933d3e4a-f781-42c2-94c2-aeaf5454a476 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:56:34.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4261" for this suite.
Oct  1 10:56:40.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:56:40.772: INFO: namespace containers-4261 deletion completed in 6.059892634s

• [SLOW TEST:10.108 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:56:40.772: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct  1 10:56:40.802: INFO: Waiting up to 5m0s for pod "pod-92cc0514-da79-47d9-8569-288987ee3c5a" in namespace "emptydir-8694" to be "success or failure"
Oct  1 10:56:40.804: INFO: Pod "pod-92cc0514-da79-47d9-8569-288987ee3c5a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.821085ms
Oct  1 10:56:42.807: INFO: Pod "pod-92cc0514-da79-47d9-8569-288987ee3c5a": Phase="Running", Reason="", readiness=true. Elapsed: 2.004799226s
Oct  1 10:56:44.809: INFO: Pod "pod-92cc0514-da79-47d9-8569-288987ee3c5a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007305734s
STEP: Saw pod success
Oct  1 10:56:44.809: INFO: Pod "pod-92cc0514-da79-47d9-8569-288987ee3c5a" satisfied condition "success or failure"
Oct  1 10:56:44.811: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-92cc0514-da79-47d9-8569-288987ee3c5a container test-container: <nil>
STEP: delete the pod
Oct  1 10:56:44.820: INFO: Waiting for pod pod-92cc0514-da79-47d9-8569-288987ee3c5a to disappear
Oct  1 10:56:44.822: INFO: Pod pod-92cc0514-da79-47d9-8569-288987ee3c5a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:56:44.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8694" for this suite.
Oct  1 10:56:50.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:56:50.882: INFO: namespace emptydir-8694 deletion completed in 6.058039138s

• [SLOW TEST:10.110 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:56:50.882: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Oct  1 10:56:50.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 create -f - --namespace=kubectl-2423'
Oct  1 10:56:51.109: INFO: stderr: ""
Oct  1 10:56:51.109: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct  1 10:56:52.112: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 10:56:52.112: INFO: Found 0 / 1
Oct  1 10:56:53.112: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 10:56:53.112: INFO: Found 1 / 1
Oct  1 10:56:53.112: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Oct  1 10:56:53.115: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 10:56:53.115: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct  1 10:56:53.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 patch pod redis-master-vp7xc --namespace=kubectl-2423 -p {"metadata":{"annotations":{"x":"y"}}}'
Oct  1 10:56:53.185: INFO: stderr: ""
Oct  1 10:56:53.185: INFO: stdout: "pod/redis-master-vp7xc patched\n"
STEP: checking annotations
Oct  1 10:56:53.187: INFO: Selector matched 1 pods for map[app:redis]
Oct  1 10:56:53.187: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:56:53.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2423" for this suite.
Oct  1 10:57:21.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:57:21.248: INFO: namespace kubectl-2423 deletion completed in 28.058877069s

• [SLOW TEST:30.366 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:57:21.248: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:57:21.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6132" for this suite.
Oct  1 10:57:49.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:57:49.350: INFO: namespace pods-6132 deletion completed in 28.066207455s

• [SLOW TEST:28.101 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:57:49.350: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:58:05.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2712" for this suite.
Oct  1 10:58:11.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:58:11.504: INFO: namespace resourcequota-2712 deletion completed in 6.059402797s

• [SLOW TEST:22.155 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:58:11.505: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:58:11.534: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Oct  1 10:58:16.538: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct  1 10:58:16.538: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Oct  1 10:58:16.549: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-7158 /apis/apps/v1/namespaces/deployment-7158/deployments/test-cleanup-deployment 885cc014-4ffb-45c1-838c-70a0ace00d09 21702 1 2019-10-01 10:58:16 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000ca51a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Oct  1 10:58:16.554: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-7158 /apis/apps/v1/namespaces/deployment-7158/replicasets/test-cleanup-deployment-65db99849b dbb3761f-e824-4255-9339-c3dbb92c4846 21704 1 2019-10-01 10:58:16 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 885cc014-4ffb-45c1-838c-70a0ace00d09 0xc0029a3d57 0xc0029a3d58}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0029a3db8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct  1 10:58:16.554: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Oct  1 10:58:16.555: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-7158 /apis/apps/v1/namespaces/deployment-7158/replicasets/test-cleanup-controller 9101627b-c55b-4d67-800f-023559c0d9c1 21703 1 2019-10-01 10:58:11 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 885cc014-4ffb-45c1-838c-70a0ace00d09 0xc0029a3c87 0xc0029a3c88}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0029a3ce8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct  1 10:58:16.564: INFO: Pod "test-cleanup-controller-f268n" is available:
&Pod{ObjectMeta:{test-cleanup-controller-f268n test-cleanup-controller- deployment-7158 /api/v1/namespaces/deployment-7158/pods/test-cleanup-controller-f268n 505aa84d-1ba9-4925-a247-db2c7374ca86 21695 0 2019-10-01 10:58:11 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller 9101627b-c55b-4d67-800f-023559c0d9c1 0xc0039be7a7 0xc0039be7a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-49zxs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-49zxs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-49zxs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-16-136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:58:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:58:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:58:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:58:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.16.136,PodIP:10.1.63.22,StartTime:2019-10-01 10:58:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-01 10:58:12 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://1ab2e71e5a20434683508b5612877f29f6790f86aa176c6528bcdcb73b69b553,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.63.22,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  1 10:58:16.564: INFO: Pod "test-cleanup-deployment-65db99849b-jmvqg" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-65db99849b-jmvqg test-cleanup-deployment-65db99849b- deployment-7158 /api/v1/namespaces/deployment-7158/pods/test-cleanup-deployment-65db99849b-jmvqg 7b1b711d-4e09-4e61-ba68-2a25447dc950 21707 0 2019-10-01 10:58:16 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-65db99849b dbb3761f-e824-4255-9339-c3dbb92c4846 0xc0039be927 0xc0039be928}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-49zxs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-49zxs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-49zxs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:58:16.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7158" for this suite.
Oct  1 10:58:22.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:58:22.637: INFO: namespace deployment-7158 deletion completed in 6.070366547s

• [SLOW TEST:11.132 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:58:22.637: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  1 10:58:22.666: INFO: Waiting up to 5m0s for pod "downwardapi-volume-29b1e02a-0b1c-40a4-996c-fc1787503f9c" in namespace "projected-1897" to be "success or failure"
Oct  1 10:58:22.668: INFO: Pod "downwardapi-volume-29b1e02a-0b1c-40a4-996c-fc1787503f9c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.093415ms
Oct  1 10:58:24.671: INFO: Pod "downwardapi-volume-29b1e02a-0b1c-40a4-996c-fc1787503f9c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005031861s
STEP: Saw pod success
Oct  1 10:58:24.671: INFO: Pod "downwardapi-volume-29b1e02a-0b1c-40a4-996c-fc1787503f9c" satisfied condition "success or failure"
Oct  1 10:58:24.673: INFO: Trying to get logs from node ip-172-31-16-136 pod downwardapi-volume-29b1e02a-0b1c-40a4-996c-fc1787503f9c container client-container: <nil>
STEP: delete the pod
Oct  1 10:58:24.695: INFO: Waiting for pod downwardapi-volume-29b1e02a-0b1c-40a4-996c-fc1787503f9c to disappear
Oct  1 10:58:24.703: INFO: Pod downwardapi-volume-29b1e02a-0b1c-40a4-996c-fc1787503f9c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:58:24.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1897" for this suite.
Oct  1 10:58:30.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:58:30.762: INFO: namespace projected-1897 deletion completed in 6.057360422s

• [SLOW TEST:8.125 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:58:30.762: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-595c14eb-17e6-45f4-afdf-b926561fab0d
STEP: Creating a pod to test consume configMaps
Oct  1 10:58:30.793: INFO: Waiting up to 5m0s for pod "pod-configmaps-f4ae84ae-ceae-48e3-93d2-76a6ccc55772" in namespace "configmap-1194" to be "success or failure"
Oct  1 10:58:30.795: INFO: Pod "pod-configmaps-f4ae84ae-ceae-48e3-93d2-76a6ccc55772": Phase="Pending", Reason="", readiness=false. Elapsed: 1.559896ms
Oct  1 10:58:32.798: INFO: Pod "pod-configmaps-f4ae84ae-ceae-48e3-93d2-76a6ccc55772": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004569771s
STEP: Saw pod success
Oct  1 10:58:32.798: INFO: Pod "pod-configmaps-f4ae84ae-ceae-48e3-93d2-76a6ccc55772" satisfied condition "success or failure"
Oct  1 10:58:32.799: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-configmaps-f4ae84ae-ceae-48e3-93d2-76a6ccc55772 container configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 10:58:32.813: INFO: Waiting for pod pod-configmaps-f4ae84ae-ceae-48e3-93d2-76a6ccc55772 to disappear
Oct  1 10:58:32.824: INFO: Pod pod-configmaps-f4ae84ae-ceae-48e3-93d2-76a6ccc55772 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:58:32.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1194" for this suite.
Oct  1 10:58:38.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:58:38.884: INFO: namespace configmap-1194 deletion completed in 6.057759795s

• [SLOW TEST:8.121 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:58:38.884: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  1 10:58:38.914: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6954de04-f146-4034-a009-344aceb86a4b" in namespace "projected-7227" to be "success or failure"
Oct  1 10:58:38.917: INFO: Pod "downwardapi-volume-6954de04-f146-4034-a009-344aceb86a4b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.589042ms
Oct  1 10:58:40.920: INFO: Pod "downwardapi-volume-6954de04-f146-4034-a009-344aceb86a4b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006810641s
STEP: Saw pod success
Oct  1 10:58:40.920: INFO: Pod "downwardapi-volume-6954de04-f146-4034-a009-344aceb86a4b" satisfied condition "success or failure"
Oct  1 10:58:40.922: INFO: Trying to get logs from node ip-172-31-16-136 pod downwardapi-volume-6954de04-f146-4034-a009-344aceb86a4b container client-container: <nil>
STEP: delete the pod
Oct  1 10:58:40.936: INFO: Waiting for pod downwardapi-volume-6954de04-f146-4034-a009-344aceb86a4b to disappear
Oct  1 10:58:40.948: INFO: Pod downwardapi-volume-6954de04-f146-4034-a009-344aceb86a4b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:58:40.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7227" for this suite.
Oct  1 10:58:46.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:58:47.010: INFO: namespace projected-7227 deletion completed in 6.056817821s

• [SLOW TEST:8.126 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:58:47.011: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:58:47.039: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-55e4f687-50e5-49b1-ac1c-4004c9b0e1c3" in namespace "security-context-test-8483" to be "success or failure"
Oct  1 10:58:47.041: INFO: Pod "alpine-nnp-false-55e4f687-50e5-49b1-ac1c-4004c9b0e1c3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.64078ms
Oct  1 10:58:49.044: INFO: Pod "alpine-nnp-false-55e4f687-50e5-49b1-ac1c-4004c9b0e1c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004632153s
Oct  1 10:58:51.047: INFO: Pod "alpine-nnp-false-55e4f687-50e5-49b1-ac1c-4004c9b0e1c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007800465s
Oct  1 10:58:51.047: INFO: Pod "alpine-nnp-false-55e4f687-50e5-49b1-ac1c-4004c9b0e1c3" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:58:51.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8483" for this suite.
Oct  1 10:58:57.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:58:57.116: INFO: namespace security-context-test-8483 deletion completed in 6.062822914s

• [SLOW TEST:10.106 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:58:57.116: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:58:57.146: INFO: Pod name rollover-pod: Found 0 pods out of 1
Oct  1 10:59:02.150: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct  1 10:59:02.150: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Oct  1 10:59:04.153: INFO: Creating deployment "test-rollover-deployment"
Oct  1 10:59:04.158: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Oct  1 10:59:06.162: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Oct  1 10:59:06.166: INFO: Ensure that both replica sets have 1 created replica
Oct  1 10:59:06.170: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Oct  1 10:59:06.174: INFO: Updating deployment test-rollover-deployment
Oct  1 10:59:06.174: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Oct  1 10:59:08.179: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Oct  1 10:59:08.184: INFO: Make sure deployment "test-rollover-deployment" is complete
Oct  1 10:59:08.187: INFO: all replica sets need to contain the pod-template-hash label
Oct  1 10:59:08.187: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524344, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524344, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524348, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524344, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  1 10:59:10.192: INFO: all replica sets need to contain the pod-template-hash label
Oct  1 10:59:10.192: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524344, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524344, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524348, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524344, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  1 10:59:12.193: INFO: all replica sets need to contain the pod-template-hash label
Oct  1 10:59:12.193: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524344, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524344, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524348, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524344, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  1 10:59:14.193: INFO: all replica sets need to contain the pod-template-hash label
Oct  1 10:59:14.193: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524344, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524344, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524348, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524344, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  1 10:59:16.193: INFO: all replica sets need to contain the pod-template-hash label
Oct  1 10:59:16.193: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524344, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524344, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524348, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524344, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  1 10:59:18.193: INFO: 
Oct  1 10:59:18.193: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Oct  1 10:59:18.198: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-421 /apis/apps/v1/namespaces/deployment-421/deployments/test-rollover-deployment 79e14c83-689d-4bc2-aef8-446a08bcb790 22002 2 2019-10-01 10:59:04 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003d1aa18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-10-01 10:59:04 +0000 UTC,LastTransitionTime:2019-10-01 10:59:04 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2019-10-01 10:59:18 +0000 UTC,LastTransitionTime:2019-10-01 10:59:04 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Oct  1 10:59:18.201: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-421 /apis/apps/v1/namespaces/deployment-421/replicasets/test-rollover-deployment-7d7dc6548c c5ea8550-a1c1-4ef1-be67-3c808f40d89c 21991 2 2019-10-01 10:59:06 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 79e14c83-689d-4bc2-aef8-446a08bcb790 0xc003d1aed7 0xc003d1aed8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003d1af38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct  1 10:59:18.201: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Oct  1 10:59:18.201: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-421 /apis/apps/v1/namespaces/deployment-421/replicasets/test-rollover-controller 3d141da9-2e28-45ac-9100-12a0743029e7 22001 2 2019-10-01 10:58:57 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 79e14c83-689d-4bc2-aef8-446a08bcb790 0xc003d1ae07 0xc003d1ae08}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003d1ae68 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct  1 10:59:18.201: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-421 /apis/apps/v1/namespaces/deployment-421/replicasets/test-rollover-deployment-f6c94f66c ec6e15e9-9e6f-4959-983c-352c0f7b48e9 21966 2 2019-10-01 10:59:04 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 79e14c83-689d-4bc2-aef8-446a08bcb790 0xc003d1afa0 0xc003d1afa1}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003d1b018 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct  1 10:59:18.203: INFO: Pod "test-rollover-deployment-7d7dc6548c-tpgk6" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-tpgk6 test-rollover-deployment-7d7dc6548c- deployment-421 /api/v1/namespaces/deployment-421/pods/test-rollover-deployment-7d7dc6548c-tpgk6 14516f79-ca12-48a9-afa1-ecb5dde52194 21975 0 2019-10-01 10:59:06 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c c5ea8550-a1c1-4ef1-be67-3c808f40d89c 0xc003d1b6e7 0xc003d1b6e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-npt87,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-npt87,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-npt87,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-16-136,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:59:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:59:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:59:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-01 10:59:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.16.136,PodIP:10.1.63.28,StartTime:2019-10-01 10:59:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-01 10:59:07 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://f816e4ec1421bd4f9f698d70a41f403e45976415144e68dbb778d1d4e1e55079,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.63.28,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:59:18.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-421" for this suite.
Oct  1 10:59:24.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:59:24.265: INFO: namespace deployment-421 deletion completed in 6.060072414s

• [SLOW TEST:27.149 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:59:24.266: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Oct  1 10:59:24.296: INFO: Pod name pod-release: Found 0 pods out of 1
Oct  1 10:59:29.299: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:59:30.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1644" for this suite.
Oct  1 10:59:36.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:59:36.369: INFO: namespace replication-controller-1644 deletion completed in 6.058013987s

• [SLOW TEST:12.103 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:59:36.369: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Oct  1 10:59:42.413: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1001 10:59:42.413897      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:59:42.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8780" for this suite.
Oct  1 10:59:48.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:59:48.474: INFO: namespace gc-8780 deletion completed in 6.058647928s

• [SLOW TEST:12.105 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:59:48.474: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Oct  1 10:59:48.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 create -f - --namespace=kubectl-4991'
Oct  1 10:59:48.660: INFO: stderr: ""
Oct  1 10:59:48.660: INFO: stdout: "pod/pause created\n"
Oct  1 10:59:48.660: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Oct  1 10:59:48.660: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-4991" to be "running and ready"
Oct  1 10:59:48.669: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 9.072398ms
Oct  1 10:59:50.672: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.012024845s
Oct  1 10:59:50.672: INFO: Pod "pause" satisfied condition "running and ready"
Oct  1 10:59:50.672: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Oct  1 10:59:50.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 label pods pause testing-label=testing-label-value --namespace=kubectl-4991'
Oct  1 10:59:50.744: INFO: stderr: ""
Oct  1 10:59:50.744: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Oct  1 10:59:50.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pod pause -L testing-label --namespace=kubectl-4991'
Oct  1 10:59:50.811: INFO: stderr: ""
Oct  1 10:59:50.811: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Oct  1 10:59:50.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 label pods pause testing-label- --namespace=kubectl-4991'
Oct  1 10:59:50.880: INFO: stderr: ""
Oct  1 10:59:50.880: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Oct  1 10:59:50.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pod pause -L testing-label --namespace=kubectl-4991'
Oct  1 10:59:50.945: INFO: stderr: ""
Oct  1 10:59:50.945: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Oct  1 10:59:50.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 delete --grace-period=0 --force -f - --namespace=kubectl-4991'
Oct  1 10:59:51.031: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  1 10:59:51.031: INFO: stdout: "pod \"pause\" force deleted\n"
Oct  1 10:59:51.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get rc,svc -l name=pause --no-headers --namespace=kubectl-4991'
Oct  1 10:59:51.102: INFO: stderr: "No resources found in kubectl-4991 namespace.\n"
Oct  1 10:59:51.102: INFO: stdout: ""
Oct  1 10:59:51.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods -l name=pause --namespace=kubectl-4991 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct  1 10:59:51.167: INFO: stderr: ""
Oct  1 10:59:51.167: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:59:51.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4991" for this suite.
Oct  1 10:59:57.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 10:59:57.228: INFO: namespace kubectl-4991 deletion completed in 6.058917085s

• [SLOW TEST:8.754 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 10:59:57.229: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 10:59:57.257: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-6a7feaf2-63c9-454e-8bf9-d946ed148e7e" in namespace "security-context-test-7736" to be "success or failure"
Oct  1 10:59:57.260: INFO: Pod "busybox-readonly-false-6a7feaf2-63c9-454e-8bf9-d946ed148e7e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.34124ms
Oct  1 10:59:59.263: INFO: Pod "busybox-readonly-false-6a7feaf2-63c9-454e-8bf9-d946ed148e7e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005397912s
Oct  1 10:59:59.263: INFO: Pod "busybox-readonly-false-6a7feaf2-63c9-454e-8bf9-d946ed148e7e" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 10:59:59.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7736" for this suite.
Oct  1 11:00:05.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:00:05.327: INFO: namespace security-context-test-7736 deletion completed in 6.061415111s

• [SLOW TEST:8.098 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:00:05.328: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  1 11:00:06.218: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  1 11:00:09.229: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:00:09.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1087" for this suite.
Oct  1 11:00:15.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:00:15.320: INFO: namespace webhook-1087 deletion completed in 6.064013886s
STEP: Destroying namespace "webhook-1087-markers" for this suite.
Oct  1 11:00:21.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:00:21.380: INFO: namespace webhook-1087-markers deletion completed in 6.059790386s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.061 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:00:21.388: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  1 11:00:22.105: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct  1 11:00:24.113: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524422, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524422, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524422, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524422, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  1 11:00:27.121: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Oct  1 11:00:29.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 attach --namespace=webhook-5485 to-be-attached-pod -i -c=container1'
Oct  1 11:00:29.225: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:00:29.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5485" for this suite.
Oct  1 11:00:41.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:00:41.291: INFO: namespace webhook-5485 deletion completed in 12.059502438s
STEP: Destroying namespace "webhook-5485-markers" for this suite.
Oct  1 11:00:47.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:00:47.350: INFO: namespace webhook-5485-markers deletion completed in 6.059066962s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:25.970 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:00:47.359: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Oct  1 11:00:47.388: INFO: Waiting up to 5m0s for pod "var-expansion-e4c9b042-08ea-4dd2-ba07-9393b5bd6af9" in namespace "var-expansion-1590" to be "success or failure"
Oct  1 11:00:47.390: INFO: Pod "var-expansion-e4c9b042-08ea-4dd2-ba07-9393b5bd6af9": Phase="Pending", Reason="", readiness=false. Elapsed: 1.850612ms
Oct  1 11:00:49.393: INFO: Pod "var-expansion-e4c9b042-08ea-4dd2-ba07-9393b5bd6af9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004974453s
STEP: Saw pod success
Oct  1 11:00:49.393: INFO: Pod "var-expansion-e4c9b042-08ea-4dd2-ba07-9393b5bd6af9" satisfied condition "success or failure"
Oct  1 11:00:49.395: INFO: Trying to get logs from node ip-172-31-16-136 pod var-expansion-e4c9b042-08ea-4dd2-ba07-9393b5bd6af9 container dapi-container: <nil>
STEP: delete the pod
Oct  1 11:00:49.412: INFO: Waiting for pod var-expansion-e4c9b042-08ea-4dd2-ba07-9393b5bd6af9 to disappear
Oct  1 11:00:49.414: INFO: Pod var-expansion-e4c9b042-08ea-4dd2-ba07-9393b5bd6af9 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:00:49.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1590" for this suite.
Oct  1 11:00:55.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:00:55.474: INFO: namespace var-expansion-1590 deletion completed in 6.058115183s

• [SLOW TEST:8.115 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:00:55.474: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:01:01.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2427" for this suite.
Oct  1 11:01:07.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:01:07.617: INFO: namespace namespaces-2427 deletion completed in 6.061279594s
STEP: Destroying namespace "nsdeletetest-1937" for this suite.
Oct  1 11:01:07.619: INFO: Namespace nsdeletetest-1937 was already deleted
STEP: Destroying namespace "nsdeletetest-1339" for this suite.
Oct  1 11:01:13.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:01:13.677: INFO: namespace nsdeletetest-1339 deletion completed in 6.058261832s

• [SLOW TEST:18.203 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:01:13.678: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Oct  1 11:01:13.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 api-versions'
Oct  1 11:01:13.785: INFO: stderr: ""
Oct  1 11:01:13.785: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:01:13.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8900" for this suite.
Oct  1 11:01:19.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:01:19.855: INFO: namespace kubectl-8900 deletion completed in 6.067168131s

• [SLOW TEST:6.177 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:01:19.855: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Oct  1 11:01:19.875: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
Oct  1 11:01:22.802: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:01:32.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7444" for this suite.
Oct  1 11:01:38.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:01:38.425: INFO: namespace crd-publish-openapi-7444 deletion completed in 6.059447261s

• [SLOW TEST:18.570 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:01:38.426: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct  1 11:01:38.458: INFO: Waiting up to 5m0s for pod "pod-307b2683-abd3-4f30-b5a3-bc05e8b1f2e2" in namespace "emptydir-7602" to be "success or failure"
Oct  1 11:01:38.461: INFO: Pod "pod-307b2683-abd3-4f30-b5a3-bc05e8b1f2e2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.993588ms
Oct  1 11:01:40.464: INFO: Pod "pod-307b2683-abd3-4f30-b5a3-bc05e8b1f2e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005081127s
STEP: Saw pod success
Oct  1 11:01:40.464: INFO: Pod "pod-307b2683-abd3-4f30-b5a3-bc05e8b1f2e2" satisfied condition "success or failure"
Oct  1 11:01:40.466: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-307b2683-abd3-4f30-b5a3-bc05e8b1f2e2 container test-container: <nil>
STEP: delete the pod
Oct  1 11:01:40.475: INFO: Waiting for pod pod-307b2683-abd3-4f30-b5a3-bc05e8b1f2e2 to disappear
Oct  1 11:01:40.477: INFO: Pod pod-307b2683-abd3-4f30-b5a3-bc05e8b1f2e2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:01:40.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7602" for this suite.
Oct  1 11:01:46.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:01:46.536: INFO: namespace emptydir-7602 deletion completed in 6.057409336s

• [SLOW TEST:8.111 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:01:46.537: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Oct  1 11:01:49.082: INFO: Successfully updated pod "labelsupdate8c7f426a-aa35-409c-b593-d5685e8f8ae8"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:01:51.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1058" for this suite.
Oct  1 11:02:13.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:02:13.155: INFO: namespace downward-api-1058 deletion completed in 22.061523934s

• [SLOW TEST:26.619 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:02:13.156: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-10c7ae54-6f2b-4e35-b971-f3a22758a1e7
STEP: Creating a pod to test consume secrets
Oct  1 11:02:13.187: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-540f7df2-26ba-4c10-82c1-fab283004bef" in namespace "projected-8335" to be "success or failure"
Oct  1 11:02:13.190: INFO: Pod "pod-projected-secrets-540f7df2-26ba-4c10-82c1-fab283004bef": Phase="Pending", Reason="", readiness=false. Elapsed: 3.397847ms
Oct  1 11:02:15.194: INFO: Pod "pod-projected-secrets-540f7df2-26ba-4c10-82c1-fab283004bef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006666428s
Oct  1 11:02:17.197: INFO: Pod "pod-projected-secrets-540f7df2-26ba-4c10-82c1-fab283004bef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009788044s
STEP: Saw pod success
Oct  1 11:02:17.197: INFO: Pod "pod-projected-secrets-540f7df2-26ba-4c10-82c1-fab283004bef" satisfied condition "success or failure"
Oct  1 11:02:17.199: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-projected-secrets-540f7df2-26ba-4c10-82c1-fab283004bef container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct  1 11:02:17.212: INFO: Waiting for pod pod-projected-secrets-540f7df2-26ba-4c10-82c1-fab283004bef to disappear
Oct  1 11:02:17.220: INFO: Pod pod-projected-secrets-540f7df2-26ba-4c10-82c1-fab283004bef no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:02:17.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8335" for this suite.
Oct  1 11:02:23.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:02:23.287: INFO: namespace projected-8335 deletion completed in 6.064021138s

• [SLOW TEST:10.131 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:02:23.287: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-7114
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-7114
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7114
Oct  1 11:02:23.318: INFO: Found 0 stateful pods, waiting for 1
Oct  1 11:02:33.321: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Oct  1 11:02:33.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=statefulset-7114 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  1 11:02:34.251: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  1 11:02:34.251: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  1 11:02:34.251: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  1 11:02:34.254: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct  1 11:02:44.257: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct  1 11:02:44.257: INFO: Waiting for statefulset status.replicas updated to 0
Oct  1 11:02:44.271: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Oct  1 11:02:44.271: INFO: ss-0  ip-172-31-16-136  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:23 +0000 UTC  }]
Oct  1 11:02:44.271: INFO: ss-1                    Pending         []
Oct  1 11:02:44.271: INFO: 
Oct  1 11:02:44.271: INFO: StatefulSet ss has not reached scale 3, at 2
Oct  1 11:02:45.274: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994340801s
Oct  1 11:02:46.278: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991089159s
Oct  1 11:02:47.281: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987575354s
Oct  1 11:02:48.285: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.983962624s
Oct  1 11:02:49.288: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.980658671s
Oct  1 11:02:50.291: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.977240783s
Oct  1 11:02:51.295: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.97376661s
Oct  1 11:02:52.298: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.970333538s
Oct  1 11:02:53.302: INFO: Verifying statefulset ss doesn't scale past 3 for another 967.148391ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7114
Oct  1 11:02:54.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=statefulset-7114 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  1 11:02:54.503: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct  1 11:02:54.503: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  1 11:02:54.503: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  1 11:02:54.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=statefulset-7114 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  1 11:02:54.717: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct  1 11:02:54.717: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  1 11:02:54.717: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  1 11:02:54.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=statefulset-7114 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  1 11:02:54.917: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct  1 11:02:54.917: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  1 11:02:54.917: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  1 11:02:54.920: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Oct  1 11:03:04.924: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 11:03:04.925: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 11:03:04.925: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Oct  1 11:03:04.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=statefulset-7114 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  1 11:03:05.129: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  1 11:03:05.129: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  1 11:03:05.129: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  1 11:03:05.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=statefulset-7114 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  1 11:03:05.343: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  1 11:03:05.343: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  1 11:03:05.343: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  1 11:03:05.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=statefulset-7114 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  1 11:03:05.560: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  1 11:03:05.560: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  1 11:03:05.560: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  1 11:03:05.560: INFO: Waiting for statefulset status.replicas updated to 0
Oct  1 11:03:05.562: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Oct  1 11:03:15.568: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct  1 11:03:15.568: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct  1 11:03:15.568: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct  1 11:03:15.575: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Oct  1 11:03:15.575: INFO: ss-0  ip-172-31-16-136  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:23 +0000 UTC  }]
Oct  1 11:03:15.575: INFO: ss-1  ip-172-31-29-44   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:44 +0000 UTC  }]
Oct  1 11:03:15.575: INFO: ss-2  ip-172-31-16-136  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:44 +0000 UTC  }]
Oct  1 11:03:15.575: INFO: 
Oct  1 11:03:15.575: INFO: StatefulSet ss has not reached scale 0, at 3
Oct  1 11:03:16.578: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Oct  1 11:03:16.579: INFO: ss-0  ip-172-31-16-136  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:23 +0000 UTC  }]
Oct  1 11:03:16.579: INFO: ss-1  ip-172-31-29-44   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:44 +0000 UTC  }]
Oct  1 11:03:16.579: INFO: ss-2  ip-172-31-16-136  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:44 +0000 UTC  }]
Oct  1 11:03:16.579: INFO: 
Oct  1 11:03:16.579: INFO: StatefulSet ss has not reached scale 0, at 3
Oct  1 11:03:17.582: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Oct  1 11:03:17.582: INFO: ss-1  ip-172-31-29-44   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:44 +0000 UTC  }]
Oct  1 11:03:17.582: INFO: ss-2  ip-172-31-16-136  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:44 +0000 UTC  }]
Oct  1 11:03:17.582: INFO: 
Oct  1 11:03:17.582: INFO: StatefulSet ss has not reached scale 0, at 2
Oct  1 11:03:18.585: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Oct  1 11:03:18.585: INFO: ss-1  ip-172-31-29-44   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:44 +0000 UTC  }]
Oct  1 11:03:18.585: INFO: ss-2  ip-172-31-16-136  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:44 +0000 UTC  }]
Oct  1 11:03:18.585: INFO: 
Oct  1 11:03:18.585: INFO: StatefulSet ss has not reached scale 0, at 2
Oct  1 11:03:19.589: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Oct  1 11:03:19.589: INFO: ss-1  ip-172-31-29-44  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:44 +0000 UTC  }]
Oct  1 11:03:19.589: INFO: 
Oct  1 11:03:19.589: INFO: StatefulSet ss has not reached scale 0, at 1
Oct  1 11:03:20.591: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Oct  1 11:03:20.591: INFO: ss-1  ip-172-31-29-44  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:44 +0000 UTC  }]
Oct  1 11:03:20.591: INFO: 
Oct  1 11:03:20.591: INFO: StatefulSet ss has not reached scale 0, at 1
Oct  1 11:03:21.595: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Oct  1 11:03:21.595: INFO: ss-1  ip-172-31-29-44  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:03:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-01 11:02:44 +0000 UTC  }]
Oct  1 11:03:21.595: INFO: 
Oct  1 11:03:21.595: INFO: StatefulSet ss has not reached scale 0, at 1
Oct  1 11:03:22.598: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.977560305s
Oct  1 11:03:23.601: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.974420778s
Oct  1 11:03:24.604: INFO: Verifying statefulset ss doesn't scale past 0 for another 971.419554ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7114
Oct  1 11:03:25.607: INFO: Scaling statefulset ss to 0
Oct  1 11:03:25.613: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct  1 11:03:25.615: INFO: Deleting all statefulset in ns statefulset-7114
Oct  1 11:03:25.617: INFO: Scaling statefulset ss to 0
Oct  1 11:03:25.622: INFO: Waiting for statefulset status.replicas updated to 0
Oct  1 11:03:25.624: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:03:25.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7114" for this suite.
Oct  1 11:03:31.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:03:31.693: INFO: namespace statefulset-7114 deletion completed in 6.060032842s

• [SLOW TEST:68.406 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:03:31.694: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Oct  1 11:03:34.239: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-585 pod-service-account-dd5b3fcc-b424-4093-ba53-53e54f3b9a9e -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Oct  1 11:03:34.441: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-585 pod-service-account-dd5b3fcc-b424-4093-ba53-53e54f3b9a9e -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Oct  1 11:03:34.645: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-585 pod-service-account-dd5b3fcc-b424-4093-ba53-53e54f3b9a9e -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:03:34.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-585" for this suite.
Oct  1 11:03:40.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:03:40.902: INFO: namespace svcaccounts-585 deletion completed in 6.057193173s

• [SLOW TEST:9.209 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:03:40.903: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Oct  1 11:04:11.449: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1001 11:04:11.449492      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:04:11.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4717" for this suite.
Oct  1 11:04:17.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:04:17.508: INFO: namespace gc-4717 deletion completed in 6.056747465s

• [SLOW TEST:36.605 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:04:17.508: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-9924
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-9924
STEP: Deleting pre-stop pod
Oct  1 11:04:26.568: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:04:26.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-9924" for this suite.
Oct  1 11:05:10.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:05:10.636: INFO: namespace prestop-9924 deletion completed in 44.058493621s

• [SLOW TEST:53.128 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:05:10.636: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-ee689afe-5757-4d28-866b-f4f21bbf9905
STEP: Creating a pod to test consume secrets
Oct  1 11:05:10.667: INFO: Waiting up to 5m0s for pod "pod-secrets-41476250-dc9f-4da4-89cc-b320c80119b8" in namespace "secrets-4354" to be "success or failure"
Oct  1 11:05:10.670: INFO: Pod "pod-secrets-41476250-dc9f-4da4-89cc-b320c80119b8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.278151ms
Oct  1 11:05:12.673: INFO: Pod "pod-secrets-41476250-dc9f-4da4-89cc-b320c80119b8": Phase="Running", Reason="", readiness=true. Elapsed: 2.006284813s
Oct  1 11:05:14.676: INFO: Pod "pod-secrets-41476250-dc9f-4da4-89cc-b320c80119b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00895319s
STEP: Saw pod success
Oct  1 11:05:14.676: INFO: Pod "pod-secrets-41476250-dc9f-4da4-89cc-b320c80119b8" satisfied condition "success or failure"
Oct  1 11:05:14.678: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-secrets-41476250-dc9f-4da4-89cc-b320c80119b8 container secret-volume-test: <nil>
STEP: delete the pod
Oct  1 11:05:14.697: INFO: Waiting for pod pod-secrets-41476250-dc9f-4da4-89cc-b320c80119b8 to disappear
Oct  1 11:05:14.705: INFO: Pod pod-secrets-41476250-dc9f-4da4-89cc-b320c80119b8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:05:14.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4354" for this suite.
Oct  1 11:05:20.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:05:20.768: INFO: namespace secrets-4354 deletion completed in 6.060353375s

• [SLOW TEST:10.132 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:05:20.768: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 11:05:20.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 version'
Oct  1 11:05:20.862: INFO: stderr: ""
Oct  1 11:05:20.862: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.0\", GitCommit:\"2bd9643cee5b3b3a5ecbd3af49d09018f0773c77\", GitTreeState:\"clean\", BuildDate:\"2019-09-18T14:36:53Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.0\", GitCommit:\"2bd9643cee5b3b3a5ecbd3af49d09018f0773c77\", GitTreeState:\"clean\", BuildDate:\"2019-09-18T14:27:17Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:05:20.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5612" for this suite.
Oct  1 11:05:26.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:05:26.924: INFO: namespace kubectl-5612 deletion completed in 6.05892019s

• [SLOW TEST:6.156 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:05:26.925: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Oct  1 11:05:26.954: INFO: Waiting up to 5m0s for pod "pod-6aeb7bf6-fd62-4bb8-b1c4-f85697cf680d" in namespace "emptydir-4286" to be "success or failure"
Oct  1 11:05:26.957: INFO: Pod "pod-6aeb7bf6-fd62-4bb8-b1c4-f85697cf680d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.978443ms
Oct  1 11:05:28.960: INFO: Pod "pod-6aeb7bf6-fd62-4bb8-b1c4-f85697cf680d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004978886s
STEP: Saw pod success
Oct  1 11:05:28.960: INFO: Pod "pod-6aeb7bf6-fd62-4bb8-b1c4-f85697cf680d" satisfied condition "success or failure"
Oct  1 11:05:28.961: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-6aeb7bf6-fd62-4bb8-b1c4-f85697cf680d container test-container: <nil>
STEP: delete the pod
Oct  1 11:05:28.971: INFO: Waiting for pod pod-6aeb7bf6-fd62-4bb8-b1c4-f85697cf680d to disappear
Oct  1 11:05:28.972: INFO: Pod pod-6aeb7bf6-fd62-4bb8-b1c4-f85697cf680d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:05:28.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4286" for this suite.
Oct  1 11:05:34.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:05:35.033: INFO: namespace emptydir-4286 deletion completed in 6.059254416s

• [SLOW TEST:8.109 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:05:35.034: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  1 11:05:35.529: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  1 11:05:38.547: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:05:38.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7673" for this suite.
Oct  1 11:05:44.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:05:44.777: INFO: namespace webhook-7673 deletion completed in 6.058228355s
STEP: Destroying namespace "webhook-7673-markers" for this suite.
Oct  1 11:05:50.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:05:50.835: INFO: namespace webhook-7673-markers deletion completed in 6.058241554s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:15.810 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:05:50.844: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  1 11:05:51.359: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct  1 11:05:53.368: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524751, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524751, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524751, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524751, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  1 11:05:56.377: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Oct  1 11:05:56.391: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:05:56.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8670" for this suite.
Oct  1 11:06:02.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:06:02.462: INFO: namespace webhook-8670 deletion completed in 6.059506259s
STEP: Destroying namespace "webhook-8670-markers" for this suite.
Oct  1 11:06:08.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:06:08.518: INFO: namespace webhook-8670-markers deletion completed in 6.056826712s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.682 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:06:08.527: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 11:06:10.568: INFO: Waiting up to 5m0s for pod "client-envvars-76ccd17e-4342-493a-a394-6e1cf8d366e0" in namespace "pods-114" to be "success or failure"
Oct  1 11:06:10.570: INFO: Pod "client-envvars-76ccd17e-4342-493a-a394-6e1cf8d366e0": Phase="Pending", Reason="", readiness=false. Elapsed: 1.911064ms
Oct  1 11:06:12.573: INFO: Pod "client-envvars-76ccd17e-4342-493a-a394-6e1cf8d366e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004583408s
STEP: Saw pod success
Oct  1 11:06:12.573: INFO: Pod "client-envvars-76ccd17e-4342-493a-a394-6e1cf8d366e0" satisfied condition "success or failure"
Oct  1 11:06:12.574: INFO: Trying to get logs from node ip-172-31-16-136 pod client-envvars-76ccd17e-4342-493a-a394-6e1cf8d366e0 container env3cont: <nil>
STEP: delete the pod
Oct  1 11:06:12.583: INFO: Waiting for pod client-envvars-76ccd17e-4342-493a-a394-6e1cf8d366e0 to disappear
Oct  1 11:06:12.585: INFO: Pod client-envvars-76ccd17e-4342-493a-a394-6e1cf8d366e0 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:06:12.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-114" for this suite.
Oct  1 11:06:40.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:06:40.647: INFO: namespace pods-114 deletion completed in 28.060097821s

• [SLOW TEST:32.121 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:06:40.647: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Oct  1 11:06:40.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 create -f - --namespace=kubectl-6003'
Oct  1 11:06:40.866: INFO: stderr: ""
Oct  1 11:06:40.866: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  1 11:06:40.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6003'
Oct  1 11:06:40.935: INFO: stderr: ""
Oct  1 11:06:40.935: INFO: stdout: "update-demo-nautilus-kt7xc update-demo-nautilus-rcmvl "
Oct  1 11:06:40.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-nautilus-kt7xc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6003'
Oct  1 11:06:41.004: INFO: stderr: ""
Oct  1 11:06:41.004: INFO: stdout: ""
Oct  1 11:06:41.004: INFO: update-demo-nautilus-kt7xc is created but not running
Oct  1 11:06:46.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6003'
Oct  1 11:06:46.074: INFO: stderr: ""
Oct  1 11:06:46.074: INFO: stdout: "update-demo-nautilus-kt7xc update-demo-nautilus-rcmvl "
Oct  1 11:06:46.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-nautilus-kt7xc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6003'
Oct  1 11:06:46.145: INFO: stderr: ""
Oct  1 11:06:46.145: INFO: stdout: "true"
Oct  1 11:06:46.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-nautilus-kt7xc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6003'
Oct  1 11:06:46.213: INFO: stderr: ""
Oct  1 11:06:46.213: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  1 11:06:46.213: INFO: validating pod update-demo-nautilus-kt7xc
Oct  1 11:06:46.216: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  1 11:06:46.216: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  1 11:06:46.216: INFO: update-demo-nautilus-kt7xc is verified up and running
Oct  1 11:06:46.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-nautilus-rcmvl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6003'
Oct  1 11:06:46.283: INFO: stderr: ""
Oct  1 11:06:46.283: INFO: stdout: "true"
Oct  1 11:06:46.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-nautilus-rcmvl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6003'
Oct  1 11:06:46.349: INFO: stderr: ""
Oct  1 11:06:46.349: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  1 11:06:46.349: INFO: validating pod update-demo-nautilus-rcmvl
Oct  1 11:06:46.353: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  1 11:06:46.353: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  1 11:06:46.353: INFO: update-demo-nautilus-rcmvl is verified up and running
STEP: scaling down the replication controller
Oct  1 11:06:46.355: INFO: scanned /root for discovery docs: <nil>
Oct  1 11:06:46.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-6003'
Oct  1 11:06:47.444: INFO: stderr: ""
Oct  1 11:06:47.444: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  1 11:06:47.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6003'
Oct  1 11:06:47.511: INFO: stderr: ""
Oct  1 11:06:47.511: INFO: stdout: "update-demo-nautilus-kt7xc update-demo-nautilus-rcmvl "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct  1 11:06:52.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6003'
Oct  1 11:06:52.580: INFO: stderr: ""
Oct  1 11:06:52.580: INFO: stdout: "update-demo-nautilus-kt7xc "
Oct  1 11:06:52.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-nautilus-kt7xc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6003'
Oct  1 11:06:52.647: INFO: stderr: ""
Oct  1 11:06:52.647: INFO: stdout: "true"
Oct  1 11:06:52.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-nautilus-kt7xc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6003'
Oct  1 11:06:52.719: INFO: stderr: ""
Oct  1 11:06:52.719: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  1 11:06:52.719: INFO: validating pod update-demo-nautilus-kt7xc
Oct  1 11:06:52.722: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  1 11:06:52.722: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  1 11:06:52.722: INFO: update-demo-nautilus-kt7xc is verified up and running
STEP: scaling up the replication controller
Oct  1 11:06:52.724: INFO: scanned /root for discovery docs: <nil>
Oct  1 11:06:52.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-6003'
Oct  1 11:06:53.818: INFO: stderr: ""
Oct  1 11:06:53.818: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  1 11:06:53.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6003'
Oct  1 11:06:53.889: INFO: stderr: ""
Oct  1 11:06:53.889: INFO: stdout: "update-demo-nautilus-j82hs update-demo-nautilus-kt7xc "
Oct  1 11:06:53.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-nautilus-j82hs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6003'
Oct  1 11:06:53.956: INFO: stderr: ""
Oct  1 11:06:53.956: INFO: stdout: ""
Oct  1 11:06:53.956: INFO: update-demo-nautilus-j82hs is created but not running
Oct  1 11:06:58.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6003'
Oct  1 11:06:59.024: INFO: stderr: ""
Oct  1 11:06:59.024: INFO: stdout: "update-demo-nautilus-j82hs update-demo-nautilus-kt7xc "
Oct  1 11:06:59.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-nautilus-j82hs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6003'
Oct  1 11:06:59.090: INFO: stderr: ""
Oct  1 11:06:59.090: INFO: stdout: "true"
Oct  1 11:06:59.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-nautilus-j82hs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6003'
Oct  1 11:06:59.156: INFO: stderr: ""
Oct  1 11:06:59.156: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  1 11:06:59.156: INFO: validating pod update-demo-nautilus-j82hs
Oct  1 11:06:59.160: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  1 11:06:59.160: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  1 11:06:59.160: INFO: update-demo-nautilus-j82hs is verified up and running
Oct  1 11:06:59.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-nautilus-kt7xc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6003'
Oct  1 11:06:59.225: INFO: stderr: ""
Oct  1 11:06:59.225: INFO: stdout: "true"
Oct  1 11:06:59.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods update-demo-nautilus-kt7xc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6003'
Oct  1 11:06:59.291: INFO: stderr: ""
Oct  1 11:06:59.291: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  1 11:06:59.291: INFO: validating pod update-demo-nautilus-kt7xc
Oct  1 11:06:59.293: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  1 11:06:59.293: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  1 11:06:59.293: INFO: update-demo-nautilus-kt7xc is verified up and running
STEP: using delete to clean up resources
Oct  1 11:06:59.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 delete --grace-period=0 --force -f - --namespace=kubectl-6003'
Oct  1 11:06:59.361: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  1 11:06:59.361: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct  1 11:06:59.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6003'
Oct  1 11:06:59.430: INFO: stderr: "No resources found in kubectl-6003 namespace.\n"
Oct  1 11:06:59.430: INFO: stdout: ""
Oct  1 11:06:59.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods -l name=update-demo --namespace=kubectl-6003 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct  1 11:06:59.498: INFO: stderr: ""
Oct  1 11:06:59.499: INFO: stdout: "update-demo-nautilus-j82hs\nupdate-demo-nautilus-kt7xc\n"
Oct  1 11:06:59.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6003'
Oct  1 11:07:00.069: INFO: stderr: "No resources found in kubectl-6003 namespace.\n"
Oct  1 11:07:00.069: INFO: stdout: ""
Oct  1 11:07:00.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 get pods -l name=update-demo --namespace=kubectl-6003 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct  1 11:07:00.138: INFO: stderr: ""
Oct  1 11:07:00.138: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:07:00.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6003" for this suite.
Oct  1 11:07:12.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:07:12.204: INFO: namespace kubectl-6003 deletion completed in 12.064310764s

• [SLOW TEST:31.557 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:07:12.205: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Oct  1 11:07:14.758: INFO: Successfully updated pod "annotationupdate3ede2890-80b7-4a22-8e7f-43d5b675eaf8"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:07:16.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3549" for this suite.
Oct  1 11:07:44.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:07:44.834: INFO: namespace downward-api-3549 deletion completed in 28.061973557s

• [SLOW TEST:32.630 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:07:44.835: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:07:46.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1462" for this suite.
Oct  1 11:07:52.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:07:52.948: INFO: namespace emptydir-wrapper-1462 deletion completed in 6.060103917s

• [SLOW TEST:8.114 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:07:52.948: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:07:56.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9682" for this suite.
Oct  1 11:08:02.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:08:03.050: INFO: namespace kubelet-test-9682 deletion completed in 6.065551852s

• [SLOW TEST:10.101 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:08:03.050: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  1 11:08:03.509: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct  1 11:08:05.516: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524883, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524883, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524883, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705524883, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  1 11:08:08.523: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:08:08.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-337" for this suite.
Oct  1 11:08:14.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:08:14.634: INFO: namespace webhook-337 deletion completed in 6.057924156s
STEP: Destroying namespace "webhook-337-markers" for this suite.
Oct  1 11:08:20.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:08:20.693: INFO: namespace webhook-337-markers deletion completed in 6.058852955s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.651 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:08:20.701: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  1 11:08:20.729: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3f81c370-3257-4a66-900d-de4c743a1c56" in namespace "downward-api-3961" to be "success or failure"
Oct  1 11:08:20.731: INFO: Pod "downwardapi-volume-3f81c370-3257-4a66-900d-de4c743a1c56": Phase="Pending", Reason="", readiness=false. Elapsed: 2.381058ms
Oct  1 11:08:22.735: INFO: Pod "downwardapi-volume-3f81c370-3257-4a66-900d-de4c743a1c56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005552755s
STEP: Saw pod success
Oct  1 11:08:22.735: INFO: Pod "downwardapi-volume-3f81c370-3257-4a66-900d-de4c743a1c56" satisfied condition "success or failure"
Oct  1 11:08:22.737: INFO: Trying to get logs from node ip-172-31-16-136 pod downwardapi-volume-3f81c370-3257-4a66-900d-de4c743a1c56 container client-container: <nil>
STEP: delete the pod
Oct  1 11:08:22.754: INFO: Waiting for pod downwardapi-volume-3f81c370-3257-4a66-900d-de4c743a1c56 to disappear
Oct  1 11:08:22.756: INFO: Pod downwardapi-volume-3f81c370-3257-4a66-900d-de4c743a1c56 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:08:22.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3961" for this suite.
Oct  1 11:08:28.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:08:28.816: INFO: namespace downward-api-3961 deletion completed in 6.05789787s

• [SLOW TEST:8.115 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:08:28.816: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Oct  1 11:08:28.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-8500 -- logs-generator --log-lines-total 100 --run-duration 20s'
Oct  1 11:08:28.917: INFO: stderr: ""
Oct  1 11:08:28.917: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Oct  1 11:08:28.917: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Oct  1 11:08:28.917: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-8500" to be "running and ready, or succeeded"
Oct  1 11:08:28.919: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 1.906033ms
Oct  1 11:08:30.921: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.00445553s
Oct  1 11:08:30.921: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Oct  1 11:08:30.921: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Oct  1 11:08:30.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 logs logs-generator logs-generator --namespace=kubectl-8500'
Oct  1 11:08:30.997: INFO: stderr: ""
Oct  1 11:08:30.997: INFO: stdout: "I1001 11:08:29.954175       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/x65 364\nI1001 11:08:30.154434       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/2rj 561\nI1001 11:08:30.354396       1 logs_generator.go:76] 2 POST /api/v1/namespaces/default/pods/vvhw 322\nI1001 11:08:30.554400       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/2jqq 421\nI1001 11:08:30.754398       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/cbf5 268\nI1001 11:08:30.954388       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/khv 273\n"
STEP: limiting log lines
Oct  1 11:08:30.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 logs logs-generator logs-generator --namespace=kubectl-8500 --tail=1'
Oct  1 11:08:31.074: INFO: stderr: ""
Oct  1 11:08:31.074: INFO: stdout: "I1001 11:08:30.954388       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/khv 273\n"
STEP: limiting log bytes
Oct  1 11:08:31.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 logs logs-generator logs-generator --namespace=kubectl-8500 --limit-bytes=1'
Oct  1 11:08:31.150: INFO: stderr: ""
Oct  1 11:08:31.150: INFO: stdout: "I"
STEP: exposing timestamps
Oct  1 11:08:31.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 logs logs-generator logs-generator --namespace=kubectl-8500 --tail=1 --timestamps'
Oct  1 11:08:31.226: INFO: stderr: ""
Oct  1 11:08:31.226: INFO: stdout: "2019-10-01T11:08:31.154565728Z I1001 11:08:31.154391       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/97n9 501\n"
STEP: restricting to a time range
Oct  1 11:08:33.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 logs logs-generator logs-generator --namespace=kubectl-8500 --since=1s'
Oct  1 11:08:33.804: INFO: stderr: ""
Oct  1 11:08:33.804: INFO: stdout: "I1001 11:08:32.954398       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/q96 236\nI1001 11:08:33.154341       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/7rc 416\nI1001 11:08:33.354401       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/p9v 383\nI1001 11:08:33.554344       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/56h 594\nI1001 11:08:33.754428       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/8rr6 510\n"
Oct  1 11:08:33.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 logs logs-generator logs-generator --namespace=kubectl-8500 --since=24h'
Oct  1 11:08:33.881: INFO: stderr: ""
Oct  1 11:08:33.881: INFO: stdout: "I1001 11:08:29.954175       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/x65 364\nI1001 11:08:30.154434       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/2rj 561\nI1001 11:08:30.354396       1 logs_generator.go:76] 2 POST /api/v1/namespaces/default/pods/vvhw 322\nI1001 11:08:30.554400       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/2jqq 421\nI1001 11:08:30.754398       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/cbf5 268\nI1001 11:08:30.954388       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/khv 273\nI1001 11:08:31.154391       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/97n9 501\nI1001 11:08:31.354440       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/7w2v 242\nI1001 11:08:31.554393       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/zfs9 574\nI1001 11:08:31.754413       1 logs_generator.go:76] 9 POST /api/v1/namespaces/default/pods/xdqw 355\nI1001 11:08:31.954408       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/gxb 589\nI1001 11:08:32.154382       1 logs_generator.go:76] 11 POST /api/v1/namespaces/default/pods/hllc 506\nI1001 11:08:32.354396       1 logs_generator.go:76] 12 POST /api/v1/namespaces/default/pods/5jxn 377\nI1001 11:08:32.554292       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/fzd 244\nI1001 11:08:32.754429       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/ns/pods/vzll 513\nI1001 11:08:32.954398       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/q96 236\nI1001 11:08:33.154341       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/7rc 416\nI1001 11:08:33.354401       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/p9v 383\nI1001 11:08:33.554344       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/56h 594\nI1001 11:08:33.754428       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/8rr6 510\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Oct  1 11:08:33.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 delete pod logs-generator --namespace=kubectl-8500'
Oct  1 11:08:39.038: INFO: stderr: ""
Oct  1 11:08:39.038: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:08:39.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8500" for this suite.
Oct  1 11:08:45.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:08:45.100: INFO: namespace kubectl-8500 deletion completed in 6.059682061s

• [SLOW TEST:16.284 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:08:45.100: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Oct  1 11:08:45.121: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-021449899 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:08:45.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7698" for this suite.
Oct  1 11:08:51.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:08:51.239: INFO: namespace kubectl-7698 deletion completed in 6.055611723s

• [SLOW TEST:6.139 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:08:51.239: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct  1 11:08:51.261: INFO: Waiting up to 5m0s for pod "pod-d5043a0f-9a9a-4dab-830b-8d74289f206b" in namespace "emptydir-2917" to be "success or failure"
Oct  1 11:08:51.268: INFO: Pod "pod-d5043a0f-9a9a-4dab-830b-8d74289f206b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.782572ms
Oct  1 11:08:53.271: INFO: Pod "pod-d5043a0f-9a9a-4dab-830b-8d74289f206b": Phase="Running", Reason="", readiness=true. Elapsed: 2.009998155s
Oct  1 11:08:55.274: INFO: Pod "pod-d5043a0f-9a9a-4dab-830b-8d74289f206b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013203469s
STEP: Saw pod success
Oct  1 11:08:55.274: INFO: Pod "pod-d5043a0f-9a9a-4dab-830b-8d74289f206b" satisfied condition "success or failure"
Oct  1 11:08:55.276: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-d5043a0f-9a9a-4dab-830b-8d74289f206b container test-container: <nil>
STEP: delete the pod
Oct  1 11:08:55.290: INFO: Waiting for pod pod-d5043a0f-9a9a-4dab-830b-8d74289f206b to disappear
Oct  1 11:08:55.297: INFO: Pod pod-d5043a0f-9a9a-4dab-830b-8d74289f206b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:08:55.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2917" for this suite.
Oct  1 11:09:01.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:09:01.363: INFO: namespace emptydir-2917 deletion completed in 6.063596675s

• [SLOW TEST:10.124 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:09:01.364: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Oct  1 11:09:03.407: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-021449899 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Oct  1 11:09:13.474: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:09:13.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8376" for this suite.
Oct  1 11:09:19.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:09:19.542: INFO: namespace pods-8376 deletion completed in 6.063850007s

• [SLOW TEST:18.178 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:09:19.542: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-7501a115-84a6-4e93-8004-e22f5cb2a01b
STEP: Creating a pod to test consume configMaps
Oct  1 11:09:19.573: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7682d012-7ed6-4254-81bd-c52c860f0e60" in namespace "projected-3954" to be "success or failure"
Oct  1 11:09:19.585: INFO: Pod "pod-projected-configmaps-7682d012-7ed6-4254-81bd-c52c860f0e60": Phase="Pending", Reason="", readiness=false. Elapsed: 11.190042ms
Oct  1 11:09:21.588: INFO: Pod "pod-projected-configmaps-7682d012-7ed6-4254-81bd-c52c860f0e60": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014252243s
Oct  1 11:09:23.591: INFO: Pod "pod-projected-configmaps-7682d012-7ed6-4254-81bd-c52c860f0e60": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01743127s
STEP: Saw pod success
Oct  1 11:09:23.591: INFO: Pod "pod-projected-configmaps-7682d012-7ed6-4254-81bd-c52c860f0e60" satisfied condition "success or failure"
Oct  1 11:09:23.593: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-projected-configmaps-7682d012-7ed6-4254-81bd-c52c860f0e60 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  1 11:09:23.603: INFO: Waiting for pod pod-projected-configmaps-7682d012-7ed6-4254-81bd-c52c860f0e60 to disappear
Oct  1 11:09:23.606: INFO: Pod pod-projected-configmaps-7682d012-7ed6-4254-81bd-c52c860f0e60 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:09:23.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3954" for this suite.
Oct  1 11:09:29.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:09:29.668: INFO: namespace projected-3954 deletion completed in 6.060082783s

• [SLOW TEST:10.126 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:09:29.669: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-3a6e2ef9-84f3-4dbf-8bc3-6ebfae3e40e6
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:09:33.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6659" for this suite.
Oct  1 11:09:51.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:09:51.776: INFO: namespace configmap-6659 deletion completed in 18.056856418s

• [SLOW TEST:22.108 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:09:51.777: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-503fa0bf-ee40-4215-aeb0-5c76951c603d
STEP: Creating a pod to test consume secrets
Oct  1 11:09:51.808: INFO: Waiting up to 5m0s for pod "pod-secrets-52a5e1ee-8d7f-4ee7-806d-076884702a66" in namespace "secrets-991" to be "success or failure"
Oct  1 11:09:51.811: INFO: Pod "pod-secrets-52a5e1ee-8d7f-4ee7-806d-076884702a66": Phase="Pending", Reason="", readiness=false. Elapsed: 2.444275ms
Oct  1 11:09:53.814: INFO: Pod "pod-secrets-52a5e1ee-8d7f-4ee7-806d-076884702a66": Phase="Running", Reason="", readiness=true. Elapsed: 2.005467674s
Oct  1 11:09:55.817: INFO: Pod "pod-secrets-52a5e1ee-8d7f-4ee7-806d-076884702a66": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008506906s
STEP: Saw pod success
Oct  1 11:09:55.817: INFO: Pod "pod-secrets-52a5e1ee-8d7f-4ee7-806d-076884702a66" satisfied condition "success or failure"
Oct  1 11:09:55.819: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-secrets-52a5e1ee-8d7f-4ee7-806d-076884702a66 container secret-volume-test: <nil>
STEP: delete the pod
Oct  1 11:09:55.831: INFO: Waiting for pod pod-secrets-52a5e1ee-8d7f-4ee7-806d-076884702a66 to disappear
Oct  1 11:09:55.839: INFO: Pod pod-secrets-52a5e1ee-8d7f-4ee7-806d-076884702a66 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:09:55.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-991" for this suite.
Oct  1 11:10:01.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:10:01.907: INFO: namespace secrets-991 deletion completed in 6.066101436s

• [SLOW TEST:10.131 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:10:01.907: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  1 11:10:02.328: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  1 11:10:05.342: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 11:10:05.345: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4437-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:10:06.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2442" for this suite.
Oct  1 11:10:12.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:10:12.581: INFO: namespace webhook-2442 deletion completed in 6.060892624s
STEP: Destroying namespace "webhook-2442-markers" for this suite.
Oct  1 11:10:18.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:10:18.639: INFO: namespace webhook-2442-markers deletion completed in 6.05792406s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.740 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:10:18.648: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-9296
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Oct  1 11:10:18.680: INFO: Found 0 stateful pods, waiting for 3
Oct  1 11:10:28.684: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 11:10:28.684: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 11:10:28.684: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Oct  1 11:10:28.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=statefulset-9296 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  1 11:10:28.895: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  1 11:10:28.895: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  1 11:10:28.895: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Oct  1 11:10:38.921: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Oct  1 11:10:48.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=statefulset-9296 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  1 11:10:49.136: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct  1 11:10:49.136: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  1 11:10:49.136: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  1 11:10:59.150: INFO: Waiting for StatefulSet statefulset-9296/ss2 to complete update
Oct  1 11:10:59.150: INFO: Waiting for Pod statefulset-9296/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Oct  1 11:10:59.150: INFO: Waiting for Pod statefulset-9296/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Oct  1 11:10:59.150: INFO: Waiting for Pod statefulset-9296/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Oct  1 11:11:09.155: INFO: Waiting for StatefulSet statefulset-9296/ss2 to complete update
Oct  1 11:11:09.155: INFO: Waiting for Pod statefulset-9296/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Oct  1 11:11:19.155: INFO: Waiting for StatefulSet statefulset-9296/ss2 to complete update
STEP: Rolling back to a previous revision
Oct  1 11:11:29.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=statefulset-9296 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  1 11:11:29.394: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  1 11:11:29.394: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  1 11:11:29.394: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  1 11:11:39.420: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Oct  1 11:11:49.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 exec --namespace=statefulset-9296 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  1 11:11:49.636: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct  1 11:11:49.637: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  1 11:11:49.637: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  1 11:11:59.651: INFO: Waiting for StatefulSet statefulset-9296/ss2 to complete update
Oct  1 11:11:59.651: INFO: Waiting for Pod statefulset-9296/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Oct  1 11:11:59.651: INFO: Waiting for Pod statefulset-9296/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Oct  1 11:11:59.651: INFO: Waiting for Pod statefulset-9296/ss2-2 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Oct  1 11:12:09.656: INFO: Waiting for StatefulSet statefulset-9296/ss2 to complete update
Oct  1 11:12:09.656: INFO: Waiting for Pod statefulset-9296/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Oct  1 11:12:09.656: INFO: Waiting for Pod statefulset-9296/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct  1 11:12:19.656: INFO: Deleting all statefulset in ns statefulset-9296
Oct  1 11:12:19.658: INFO: Scaling statefulset ss2 to 0
Oct  1 11:12:39.670: INFO: Waiting for statefulset status.replicas updated to 0
Oct  1 11:12:39.672: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:12:39.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9296" for this suite.
Oct  1 11:12:45.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:12:45.739: INFO: namespace statefulset-9296 deletion completed in 6.05818703s

• [SLOW TEST:147.091 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:12:45.739: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Oct  1 11:12:45.757: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:12:48.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8380" for this suite.
Oct  1 11:12:54.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:12:54.490: INFO: namespace init-container-8380 deletion completed in 6.063494021s

• [SLOW TEST:8.751 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:12:54.491: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct  1 11:12:54.521: INFO: Waiting up to 5m0s for pod "pod-4c931df4-6e6b-411e-aac0-a08e6fdac2f4" in namespace "emptydir-3617" to be "success or failure"
Oct  1 11:12:54.523: INFO: Pod "pod-4c931df4-6e6b-411e-aac0-a08e6fdac2f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.687196ms
Oct  1 11:12:56.527: INFO: Pod "pod-4c931df4-6e6b-411e-aac0-a08e6fdac2f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006354661s
STEP: Saw pod success
Oct  1 11:12:56.527: INFO: Pod "pod-4c931df4-6e6b-411e-aac0-a08e6fdac2f4" satisfied condition "success or failure"
Oct  1 11:12:56.529: INFO: Trying to get logs from node ip-172-31-16-136 pod pod-4c931df4-6e6b-411e-aac0-a08e6fdac2f4 container test-container: <nil>
STEP: delete the pod
Oct  1 11:12:56.549: INFO: Waiting for pod pod-4c931df4-6e6b-411e-aac0-a08e6fdac2f4 to disappear
Oct  1 11:12:56.556: INFO: Pod pod-4c931df4-6e6b-411e-aac0-a08e6fdac2f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:12:56.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3617" for this suite.
Oct  1 11:13:02.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:13:02.622: INFO: namespace emptydir-3617 deletion completed in 6.062599828s

• [SLOW TEST:8.131 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:13:02.622: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:13:04.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4831" for this suite.
Oct  1 11:13:48.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:13:48.727: INFO: namespace kubelet-test-4831 deletion completed in 44.059773926s

• [SLOW TEST:46.105 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:13:48.727: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  1 11:13:48.755: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1a6a0d62-a08a-491b-baf9-3112278783b4" in namespace "projected-9902" to be "success or failure"
Oct  1 11:13:48.757: INFO: Pod "downwardapi-volume-1a6a0d62-a08a-491b-baf9-3112278783b4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.903421ms
Oct  1 11:13:50.761: INFO: Pod "downwardapi-volume-1a6a0d62-a08a-491b-baf9-3112278783b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005292979s
STEP: Saw pod success
Oct  1 11:13:50.761: INFO: Pod "downwardapi-volume-1a6a0d62-a08a-491b-baf9-3112278783b4" satisfied condition "success or failure"
Oct  1 11:13:50.767: INFO: Trying to get logs from node ip-172-31-16-136 pod downwardapi-volume-1a6a0d62-a08a-491b-baf9-3112278783b4 container client-container: <nil>
STEP: delete the pod
Oct  1 11:13:50.777: INFO: Waiting for pod downwardapi-volume-1a6a0d62-a08a-491b-baf9-3112278783b4 to disappear
Oct  1 11:13:50.779: INFO: Pod downwardapi-volume-1a6a0d62-a08a-491b-baf9-3112278783b4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:13:50.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9902" for this suite.
Oct  1 11:13:56.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:13:56.839: INFO: namespace projected-9902 deletion completed in 6.057582733s

• [SLOW TEST:8.112 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:13:56.839: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct  1 11:13:56.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-9517'
Oct  1 11:13:57.710: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct  1 11:13:57.710: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Oct  1 11:13:57.723: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-vmlw9]
Oct  1 11:13:57.723: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-vmlw9" in namespace "kubectl-9517" to be "running and ready"
Oct  1 11:13:57.733: INFO: Pod "e2e-test-httpd-rc-vmlw9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.831097ms
Oct  1 11:13:59.735: INFO: Pod "e2e-test-httpd-rc-vmlw9": Phase="Running", Reason="", readiness=true. Elapsed: 2.012034088s
Oct  1 11:13:59.735: INFO: Pod "e2e-test-httpd-rc-vmlw9" satisfied condition "running and ready"
Oct  1 11:13:59.735: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-vmlw9]
Oct  1 11:13:59.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 logs rc/e2e-test-httpd-rc --namespace=kubectl-9517'
Oct  1 11:13:59.815: INFO: stderr: ""
Oct  1 11:13:59.815: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.1.63.78. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.1.63.78. Set the 'ServerName' directive globally to suppress this message\n[Tue Oct 01 11:13:58.759613 2019] [mpm_event:notice] [pid 1:tid 139793791818600] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Tue Oct 01 11:13:58.759653 2019] [core:notice] [pid 1:tid 139793791818600] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Oct  1 11:13:59.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 delete rc e2e-test-httpd-rc --namespace=kubectl-9517'
Oct  1 11:13:59.885: INFO: stderr: ""
Oct  1 11:13:59.885: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:13:59.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9517" for this suite.
Oct  1 11:14:05.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:14:05.950: INFO: namespace kubectl-9517 deletion completed in 6.061991013s

• [SLOW TEST:9.111 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:14:05.950: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:14:08.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7827" for this suite.
Oct  1 11:14:52.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:14:52.062: INFO: namespace kubelet-test-7827 deletion completed in 44.056710797s

• [SLOW TEST:46.112 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:14:52.062: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:14:54.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8404" for this suite.
Oct  1 11:15:12.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:15:12.165: INFO: namespace containers-8404 deletion completed in 18.06261262s

• [SLOW TEST:20.103 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:15:12.166: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:15:19.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6343" for this suite.
Oct  1 11:15:25.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:15:25.255: INFO: namespace resourcequota-6343 deletion completed in 6.057871801s

• [SLOW TEST:13.089 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:15:25.255: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Oct  1 11:15:25.274: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Oct  1 11:15:25.751: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Oct  1 11:15:27.781: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525325, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525325, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525325, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525325, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  1 11:15:29.784: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525325, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525325, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525325, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525325, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  1 11:15:31.785: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525325, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525325, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525325, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525325, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  1 11:15:33.785: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525325, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525325, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525325, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525325, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  1 11:15:35.784: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525325, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525325, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525325, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525325, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  1 11:15:38.514: INFO: Waited 718.877216ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:15:38.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1019" for this suite.
Oct  1 11:15:45.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:15:45.112: INFO: namespace aggregator-1019 deletion completed in 6.157778019s

• [SLOW TEST:19.857 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:15:45.112: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  1 11:15:45.132: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Oct  1 11:15:47.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 --namespace=crd-publish-openapi-636 create -f -'
Oct  1 11:15:48.057: INFO: stderr: ""
Oct  1 11:15:48.057: INFO: stdout: "e2e-test-crd-publish-openapi-4083-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Oct  1 11:15:48.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 --namespace=crd-publish-openapi-636 delete e2e-test-crd-publish-openapi-4083-crds test-cr'
Oct  1 11:15:48.127: INFO: stderr: ""
Oct  1 11:15:48.127: INFO: stdout: "e2e-test-crd-publish-openapi-4083-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Oct  1 11:15:48.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 --namespace=crd-publish-openapi-636 apply -f -'
Oct  1 11:15:48.287: INFO: stderr: ""
Oct  1 11:15:48.287: INFO: stdout: "e2e-test-crd-publish-openapi-4083-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Oct  1 11:15:48.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 --namespace=crd-publish-openapi-636 delete e2e-test-crd-publish-openapi-4083-crds test-cr'
Oct  1 11:15:48.355: INFO: stderr: ""
Oct  1 11:15:48.355: INFO: stdout: "e2e-test-crd-publish-openapi-4083-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Oct  1 11:15:48.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-021449899 explain e2e-test-crd-publish-openapi-4083-crds'
Oct  1 11:15:48.502: INFO: stderr: ""
Oct  1 11:15:48.502: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4083-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:15:51.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-636" for this suite.
Oct  1 11:15:57.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:15:57.468: INFO: namespace crd-publish-openapi-636 deletion completed in 6.060178234s

• [SLOW TEST:12.356 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  1 11:15:57.468: INFO: >>> kubeConfig: /tmp/kubeconfig-021449899
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  1 11:15:58.307: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct  1 11:16:00.314: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525358, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525358, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525358, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705525358, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  1 11:16:03.322: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  1 11:16:15.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-222" for this suite.
Oct  1 11:16:21.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:16:21.460: INFO: namespace webhook-222 deletion completed in 6.058678646s
STEP: Destroying namespace "webhook-222-markers" for this suite.
Oct  1 11:16:27.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  1 11:16:27.518: INFO: namespace webhook-222-markers deletion completed in 6.057842779s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:30.059 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
Oct  1 11:16:27.527: INFO: Running AfterSuite actions on all nodes
Oct  1 11:16:27.527: INFO: Running AfterSuite actions on node 1
Oct  1 11:16:27.527: INFO: Skipping dumping logs from cluster

Ran 274 of 4897 Specs in 6878.999 seconds
SUCCESS! -- 274 Passed | 0 Failed | 0 Pending | 4623 Skipped
PASS

Ginkgo ran 1 suite in 1h54m40.474435379s
Test Suite Passed
