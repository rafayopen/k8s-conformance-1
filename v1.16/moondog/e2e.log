I0206 18:40:23.938252      19 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-481697501
I0206 18:40:23.938578      19 e2e.go:92] Starting e2e run "3cde2692-1cd2-44f2-b1f0-dd4227d6e199" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1581014422 - Will randomize all specs
Will run 276 of 4731 specs

Feb  6 18:40:23.950: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 18:40:23.953: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb  6 18:40:23.969: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb  6 18:40:24.003: INFO: 27 / 27 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb  6 18:40:24.003: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Feb  6 18:40:24.003: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb  6 18:40:24.011: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Feb  6 18:40:24.011: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Feb  6 18:40:24.011: INFO: e2e test version: v1.16.6-beta.0
Feb  6 18:40:24.013: INFO: kube-apiserver version: v1.16.6-beta.0
Feb  6 18:40:24.013: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 18:40:24.018: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:40:24.018: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename secrets
Feb  6 18:40:24.065: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Feb  6 18:40:24.073: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5307
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-6368
STEP: Creating secret with name secret-test-c2dc6f7d-549b-42ef-9eba-47b158384df0
STEP: Creating a pod to test consume secrets
Feb  6 18:40:24.340: INFO: Waiting up to 5m0s for pod "pod-secrets-ca9f954a-45c7-47ab-aa88-fda42c07107f" in namespace "secrets-5307" to be "success or failure"
Feb  6 18:40:24.343: INFO: Pod "pod-secrets-ca9f954a-45c7-47ab-aa88-fda42c07107f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.777104ms
Feb  6 18:40:26.346: INFO: Pod "pod-secrets-ca9f954a-45c7-47ab-aa88-fda42c07107f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005863808s
STEP: Saw pod success
Feb  6 18:40:26.346: INFO: Pod "pod-secrets-ca9f954a-45c7-47ab-aa88-fda42c07107f" satisfied condition "success or failure"
Feb  6 18:40:26.350: INFO: Trying to get logs from node ip-10-10-2-209.ec2.internal pod pod-secrets-ca9f954a-45c7-47ab-aa88-fda42c07107f container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 18:40:26.381: INFO: Waiting for pod pod-secrets-ca9f954a-45c7-47ab-aa88-fda42c07107f to disappear
Feb  6 18:40:26.385: INFO: Pod pod-secrets-ca9f954a-45c7-47ab-aa88-fda42c07107f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:40:26.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5307" for this suite.
Feb  6 18:40:32.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:40:32.870: INFO: namespace secrets-5307 deletion completed in 6.480348128s
STEP: Destroying namespace "secret-namespace-6368" for this suite.
Feb  6 18:40:38.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:40:39.345: INFO: namespace secret-namespace-6368 deletion completed in 6.475461795s

• [SLOW TEST:15.327 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:40:39.345: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5163
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 18:40:39.750: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 18:40:42.771: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:40:42.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5163" for this suite.
Feb  6 18:40:48.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:40:49.306: INFO: namespace webhook-5163 deletion completed in 6.48441754s
STEP: Destroying namespace "webhook-5163-markers" for this suite.
Feb  6 18:40:55.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:40:55.781: INFO: namespace webhook-5163-markers deletion completed in 6.475162886s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.451 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:40:55.796: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9032
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-fcd123e7-acc2-4c7e-92a8-d36e8d97540a
STEP: Creating a pod to test consume configMaps
Feb  6 18:40:55.961: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-76915e07-f61b-47e8-aa2b-ae31c92a9e80" in namespace "projected-9032" to be "success or failure"
Feb  6 18:40:55.964: INFO: Pod "pod-projected-configmaps-76915e07-f61b-47e8-aa2b-ae31c92a9e80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.889023ms
Feb  6 18:40:57.967: INFO: Pod "pod-projected-configmaps-76915e07-f61b-47e8-aa2b-ae31c92a9e80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006360177s
STEP: Saw pod success
Feb  6 18:40:57.967: INFO: Pod "pod-projected-configmaps-76915e07-f61b-47e8-aa2b-ae31c92a9e80" satisfied condition "success or failure"
Feb  6 18:40:57.970: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-projected-configmaps-76915e07-f61b-47e8-aa2b-ae31c92a9e80 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 18:40:58.003: INFO: Waiting for pod pod-projected-configmaps-76915e07-f61b-47e8-aa2b-ae31c92a9e80 to disappear
Feb  6 18:40:58.006: INFO: Pod pod-projected-configmaps-76915e07-f61b-47e8-aa2b-ae31c92a9e80 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:40:58.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9032" for this suite.
Feb  6 18:41:04.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:41:04.485: INFO: namespace projected-9032 deletion completed in 6.474729975s

• [SLOW TEST:8.689 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:41:04.485: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9367
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-decb1c33-4252-4ba0-a677-187c3affb53d
STEP: Creating a pod to test consume configMaps
Feb  6 18:41:04.654: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-29b08ccc-60ad-417e-9ef4-48703dabc1f1" in namespace "projected-9367" to be "success or failure"
Feb  6 18:41:04.657: INFO: Pod "pod-projected-configmaps-29b08ccc-60ad-417e-9ef4-48703dabc1f1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.003916ms
Feb  6 18:41:06.661: INFO: Pod "pod-projected-configmaps-29b08ccc-60ad-417e-9ef4-48703dabc1f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006635724s
STEP: Saw pod success
Feb  6 18:41:06.661: INFO: Pod "pod-projected-configmaps-29b08ccc-60ad-417e-9ef4-48703dabc1f1" satisfied condition "success or failure"
Feb  6 18:41:06.664: INFO: Trying to get logs from node ip-10-10-2-209.ec2.internal pod pod-projected-configmaps-29b08ccc-60ad-417e-9ef4-48703dabc1f1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 18:41:06.686: INFO: Waiting for pod pod-projected-configmaps-29b08ccc-60ad-417e-9ef4-48703dabc1f1 to disappear
Feb  6 18:41:06.689: INFO: Pod pod-projected-configmaps-29b08ccc-60ad-417e-9ef4-48703dabc1f1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:41:06.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9367" for this suite.
Feb  6 18:41:12.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:41:13.188: INFO: namespace projected-9367 deletion completed in 6.494749665s

• [SLOW TEST:8.703 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:41:13.189: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-9928
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Feb  6 18:41:13.746: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 18:41:16.771: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 18:41:16.775: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:41:17.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-9928" for this suite.
Feb  6 18:41:23.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:41:24.392: INFO: namespace crd-webhook-9928 deletion completed in 6.478557421s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:11.219 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:41:24.408: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2076
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb  6 18:41:27.092: INFO: Successfully updated pod "pod-update-activedeadlineseconds-471dc4ec-55db-4f88-8d7d-c11c81900f46"
Feb  6 18:41:27.092: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-471dc4ec-55db-4f88-8d7d-c11c81900f46" in namespace "pods-2076" to be "terminated due to deadline exceeded"
Feb  6 18:41:27.098: INFO: Pod "pod-update-activedeadlineseconds-471dc4ec-55db-4f88-8d7d-c11c81900f46": Phase="Running", Reason="", readiness=true. Elapsed: 5.469144ms
Feb  6 18:41:29.110: INFO: Pod "pod-update-activedeadlineseconds-471dc4ec-55db-4f88-8d7d-c11c81900f46": Phase="Running", Reason="", readiness=true. Elapsed: 2.017222419s
Feb  6 18:41:31.113: INFO: Pod "pod-update-activedeadlineseconds-471dc4ec-55db-4f88-8d7d-c11c81900f46": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.02080694s
Feb  6 18:41:31.113: INFO: Pod "pod-update-activedeadlineseconds-471dc4ec-55db-4f88-8d7d-c11c81900f46" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:41:31.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2076" for this suite.
Feb  6 18:41:37.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:41:37.595: INFO: namespace pods-2076 deletion completed in 6.477123557s

• [SLOW TEST:13.187 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:41:37.595: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3000
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Feb  6 18:41:37.751: INFO: Waiting up to 5m0s for pod "client-containers-f67b47dc-a449-4d38-9389-b85154968f40" in namespace "containers-3000" to be "success or failure"
Feb  6 18:41:37.754: INFO: Pod "client-containers-f67b47dc-a449-4d38-9389-b85154968f40": Phase="Pending", Reason="", readiness=false. Elapsed: 2.906491ms
Feb  6 18:41:39.757: INFO: Pod "client-containers-f67b47dc-a449-4d38-9389-b85154968f40": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0058728s
STEP: Saw pod success
Feb  6 18:41:39.757: INFO: Pod "client-containers-f67b47dc-a449-4d38-9389-b85154968f40" satisfied condition "success or failure"
Feb  6 18:41:39.760: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod client-containers-f67b47dc-a449-4d38-9389-b85154968f40 container test-container: <nil>
STEP: delete the pod
Feb  6 18:41:39.780: INFO: Waiting for pod client-containers-f67b47dc-a449-4d38-9389-b85154968f40 to disappear
Feb  6 18:41:39.784: INFO: Pod client-containers-f67b47dc-a449-4d38-9389-b85154968f40 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:41:39.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3000" for this suite.
Feb  6 18:41:45.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:41:46.266: INFO: namespace containers-3000 deletion completed in 6.477239987s

• [SLOW TEST:8.671 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:41:46.266: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-3404
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:41:59.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3404" for this suite.
Feb  6 18:42:05.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:42:05.978: INFO: namespace resourcequota-3404 deletion completed in 6.490483559s

• [SLOW TEST:19.712 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:42:05.978: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5811
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 18:42:06.973: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 18:42:09.996: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:42:10.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5811" for this suite.
Feb  6 18:42:16.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:42:16.532: INFO: namespace webhook-5811 deletion completed in 6.48880885s
STEP: Destroying namespace "webhook-5811-markers" for this suite.
Feb  6 18:42:22.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:42:23.010: INFO: namespace webhook-5811-markers deletion completed in 6.477936427s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.049 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:42:23.027: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9054
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb  6 18:42:23.218: INFO: Waiting up to 5m0s for pod "pod-a9b49319-8749-44ae-8676-4e997fc21d52" in namespace "emptydir-9054" to be "success or failure"
Feb  6 18:42:23.221: INFO: Pod "pod-a9b49319-8749-44ae-8676-4e997fc21d52": Phase="Pending", Reason="", readiness=false. Elapsed: 3.199907ms
Feb  6 18:42:25.225: INFO: Pod "pod-a9b49319-8749-44ae-8676-4e997fc21d52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00721262s
STEP: Saw pod success
Feb  6 18:42:25.225: INFO: Pod "pod-a9b49319-8749-44ae-8676-4e997fc21d52" satisfied condition "success or failure"
Feb  6 18:42:25.228: INFO: Trying to get logs from node ip-10-10-2-209.ec2.internal pod pod-a9b49319-8749-44ae-8676-4e997fc21d52 container test-container: <nil>
STEP: delete the pod
Feb  6 18:42:25.249: INFO: Waiting for pod pod-a9b49319-8749-44ae-8676-4e997fc21d52 to disappear
Feb  6 18:42:25.252: INFO: Pod pod-a9b49319-8749-44ae-8676-4e997fc21d52 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:42:25.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9054" for this suite.
Feb  6 18:42:31.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:42:31.732: INFO: namespace emptydir-9054 deletion completed in 6.475468121s

• [SLOW TEST:8.706 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:42:31.732: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2956
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Feb  6 18:42:31.888: INFO: Waiting up to 5m0s for pod "var-expansion-d51d4437-6bdf-4069-95de-b725c71ab65a" in namespace "var-expansion-2956" to be "success or failure"
Feb  6 18:42:31.891: INFO: Pod "var-expansion-d51d4437-6bdf-4069-95de-b725c71ab65a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.155445ms
Feb  6 18:42:33.895: INFO: Pod "var-expansion-d51d4437-6bdf-4069-95de-b725c71ab65a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006680696s
STEP: Saw pod success
Feb  6 18:42:33.895: INFO: Pod "var-expansion-d51d4437-6bdf-4069-95de-b725c71ab65a" satisfied condition "success or failure"
Feb  6 18:42:33.898: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod var-expansion-d51d4437-6bdf-4069-95de-b725c71ab65a container dapi-container: <nil>
STEP: delete the pod
Feb  6 18:42:33.918: INFO: Waiting for pod var-expansion-d51d4437-6bdf-4069-95de-b725c71ab65a to disappear
Feb  6 18:42:33.922: INFO: Pod var-expansion-d51d4437-6bdf-4069-95de-b725c71ab65a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:42:33.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2956" for this suite.
Feb  6 18:42:39.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:42:40.405: INFO: namespace var-expansion-2956 deletion completed in 6.478959834s

• [SLOW TEST:8.673 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:42:40.405: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-834
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0206 18:42:42.101713      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  6 18:42:42.101: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:42:42.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-834" for this suite.
Feb  6 18:42:48.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:42:48.578: INFO: namespace gc-834 deletion completed in 6.473648174s

• [SLOW TEST:8.173 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:42:48.578: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8106
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-82a00a96-185d-4492-a540-fb7dbf5c3da4
STEP: Creating a pod to test consume configMaps
Feb  6 18:42:48.739: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3b1f053c-efaf-4399-ab73-5ef44c35dcf8" in namespace "projected-8106" to be "success or failure"
Feb  6 18:42:48.742: INFO: Pod "pod-projected-configmaps-3b1f053c-efaf-4399-ab73-5ef44c35dcf8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.995843ms
Feb  6 18:42:50.746: INFO: Pod "pod-projected-configmaps-3b1f053c-efaf-4399-ab73-5ef44c35dcf8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006968181s
STEP: Saw pod success
Feb  6 18:42:50.746: INFO: Pod "pod-projected-configmaps-3b1f053c-efaf-4399-ab73-5ef44c35dcf8" satisfied condition "success or failure"
Feb  6 18:42:50.749: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-projected-configmaps-3b1f053c-efaf-4399-ab73-5ef44c35dcf8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 18:42:50.771: INFO: Waiting for pod pod-projected-configmaps-3b1f053c-efaf-4399-ab73-5ef44c35dcf8 to disappear
Feb  6 18:42:50.774: INFO: Pod pod-projected-configmaps-3b1f053c-efaf-4399-ab73-5ef44c35dcf8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:42:50.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8106" for this suite.
Feb  6 18:42:56.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:42:57.254: INFO: namespace projected-8106 deletion completed in 6.47620682s

• [SLOW TEST:8.676 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:42:57.254: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1792
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb  6 18:42:59.938: INFO: Successfully updated pod "annotationupdated12cd168-a73a-49bd-928f-3fb2ef7ef21d"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:43:01.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1792" for this suite.
Feb  6 18:43:13.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:43:14.443: INFO: namespace projected-1792 deletion completed in 12.476233091s

• [SLOW TEST:17.189 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:43:14.443: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9623
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb  6 18:43:14.601: INFO: Waiting up to 5m0s for pod "pod-185808cf-33c0-4467-bfb3-4deb71bf7b6e" in namespace "emptydir-9623" to be "success or failure"
Feb  6 18:43:14.604: INFO: Pod "pod-185808cf-33c0-4467-bfb3-4deb71bf7b6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.953013ms
Feb  6 18:43:16.607: INFO: Pod "pod-185808cf-33c0-4467-bfb3-4deb71bf7b6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00678394s
STEP: Saw pod success
Feb  6 18:43:16.607: INFO: Pod "pod-185808cf-33c0-4467-bfb3-4deb71bf7b6e" satisfied condition "success or failure"
Feb  6 18:43:16.610: INFO: Trying to get logs from node ip-10-10-2-209.ec2.internal pod pod-185808cf-33c0-4467-bfb3-4deb71bf7b6e container test-container: <nil>
STEP: delete the pod
Feb  6 18:43:16.641: INFO: Waiting for pod pod-185808cf-33c0-4467-bfb3-4deb71bf7b6e to disappear
Feb  6 18:43:16.644: INFO: Pod pod-185808cf-33c0-4467-bfb3-4deb71bf7b6e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:43:16.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9623" for this suite.
Feb  6 18:43:22.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:43:23.125: INFO: namespace emptydir-9623 deletion completed in 6.476235535s

• [SLOW TEST:8.682 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:43:23.125: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7524
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 18:43:23.777: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb  6 18:43:25.786: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716611403, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716611403, loc:(*time.Location)(0x788a6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716611403, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716611403, loc:(*time.Location)(0x788a6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 18:43:28.806: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:43:28.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7524" for this suite.
Feb  6 18:43:36.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:43:37.447: INFO: namespace webhook-7524 deletion completed in 8.475316808s
STEP: Destroying namespace "webhook-7524-markers" for this suite.
Feb  6 18:43:43.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:43:43.920: INFO: namespace webhook-7524-markers deletion completed in 6.473639042s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:20.810 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:43:43.935: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-535
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:43:44.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-535" for this suite.
Feb  6 18:43:50.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:43:50.566: INFO: namespace tables-535 deletion completed in 6.474304259s

• [SLOW TEST:6.630 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:43:50.566: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-542
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-dd38863d-ef59-4a7e-a72d-f0dcbdb2db6f
STEP: Creating a pod to test consume secrets
Feb  6 18:43:50.727: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1d5c5029-7619-49b3-a3c5-d24ab6e96c04" in namespace "projected-542" to be "success or failure"
Feb  6 18:43:50.730: INFO: Pod "pod-projected-secrets-1d5c5029-7619-49b3-a3c5-d24ab6e96c04": Phase="Pending", Reason="", readiness=false. Elapsed: 3.643046ms
Feb  6 18:43:52.734: INFO: Pod "pod-projected-secrets-1d5c5029-7619-49b3-a3c5-d24ab6e96c04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007140961s
STEP: Saw pod success
Feb  6 18:43:52.734: INFO: Pod "pod-projected-secrets-1d5c5029-7619-49b3-a3c5-d24ab6e96c04" satisfied condition "success or failure"
Feb  6 18:43:52.737: INFO: Trying to get logs from node ip-10-10-2-209.ec2.internal pod pod-projected-secrets-1d5c5029-7619-49b3-a3c5-d24ab6e96c04 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  6 18:43:52.758: INFO: Waiting for pod pod-projected-secrets-1d5c5029-7619-49b3-a3c5-d24ab6e96c04 to disappear
Feb  6 18:43:52.761: INFO: Pod pod-projected-secrets-1d5c5029-7619-49b3-a3c5-d24ab6e96c04 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:43:52.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-542" for this suite.
Feb  6 18:43:58.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:43:59.238: INFO: namespace projected-542 deletion completed in 6.473431945s

• [SLOW TEST:8.673 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:43:59.239: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9348
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 18:44:00.005: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb  6 18:44:02.015: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716611440, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716611440, loc:(*time.Location)(0x788a6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716611440, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716611440, loc:(*time.Location)(0x788a6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 18:44:05.257: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:44:17.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9348" for this suite.
Feb  6 18:44:23.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:44:23.876: INFO: namespace webhook-9348 deletion completed in 6.482249069s
STEP: Destroying namespace "webhook-9348-markers" for this suite.
Feb  6 18:44:29.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:44:30.350: INFO: namespace webhook-9348-markers deletion completed in 6.474218686s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:31.127 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:44:30.366: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7076
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-f1af590d-f449-4e65-95c7-8abcc290f7f9
STEP: Creating a pod to test consume secrets
Feb  6 18:44:30.536: INFO: Waiting up to 5m0s for pod "pod-secrets-42f2d06e-d5ed-476d-82d3-58f908e12d42" in namespace "secrets-7076" to be "success or failure"
Feb  6 18:44:30.540: INFO: Pod "pod-secrets-42f2d06e-d5ed-476d-82d3-58f908e12d42": Phase="Pending", Reason="", readiness=false. Elapsed: 3.694003ms
Feb  6 18:44:32.544: INFO: Pod "pod-secrets-42f2d06e-d5ed-476d-82d3-58f908e12d42": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007645147s
STEP: Saw pod success
Feb  6 18:44:32.544: INFO: Pod "pod-secrets-42f2d06e-d5ed-476d-82d3-58f908e12d42" satisfied condition "success or failure"
Feb  6 18:44:32.546: INFO: Trying to get logs from node ip-10-10-2-209.ec2.internal pod pod-secrets-42f2d06e-d5ed-476d-82d3-58f908e12d42 container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 18:44:32.570: INFO: Waiting for pod pod-secrets-42f2d06e-d5ed-476d-82d3-58f908e12d42 to disappear
Feb  6 18:44:32.573: INFO: Pod pod-secrets-42f2d06e-d5ed-476d-82d3-58f908e12d42 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:44:32.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7076" for this suite.
Feb  6 18:44:38.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:44:39.053: INFO: namespace secrets-7076 deletion completed in 6.475371296s

• [SLOW TEST:8.687 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:44:39.053: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-9683
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Feb  6 18:44:39.208: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-9683" to be "success or failure"
Feb  6 18:44:39.211: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 3.06777ms
Feb  6 18:44:41.214: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006515245s
Feb  6 18:44:43.218: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010035665s
STEP: Saw pod success
Feb  6 18:44:43.218: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb  6 18:44:43.221: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb  6 18:44:43.250: INFO: Waiting for pod pod-host-path-test to disappear
Feb  6 18:44:43.253: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:44:43.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-9683" for this suite.
Feb  6 18:44:49.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:44:49.732: INFO: namespace hostpath-9683 deletion completed in 6.474425612s

• [SLOW TEST:10.679 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:44:49.732: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4255
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-4255
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-4255
I0206 18:44:49.926686      19 runners.go:184] Created replication controller with name: externalname-service, namespace: services-4255, replica count: 2
I0206 18:44:52.977290      19 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  6 18:44:52.977: INFO: Creating new exec pod
Feb  6 18:44:56.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=services-4255 execpodw5qs9 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Feb  6 18:44:56.413: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Feb  6 18:44:56.413: INFO: stdout: ""
Feb  6 18:44:56.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=services-4255 execpodw5qs9 -- /bin/sh -x -c nc -zv -t -w 2 10.106.236.229 80'
Feb  6 18:44:56.652: INFO: stderr: "+ nc -zv -t -w 2 10.106.236.229 80\nConnection to 10.106.236.229 80 port [tcp/http] succeeded!\n"
Feb  6 18:44:56.652: INFO: stdout: ""
Feb  6 18:44:56.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=services-4255 execpodw5qs9 -- /bin/sh -x -c nc -zv -t -w 2 10.10.1.217 32480'
Feb  6 18:44:56.880: INFO: stderr: "+ nc -zv -t -w 2 10.10.1.217 32480\nConnection to 10.10.1.217 32480 port [tcp/32480] succeeded!\n"
Feb  6 18:44:56.880: INFO: stdout: ""
Feb  6 18:44:56.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=services-4255 execpodw5qs9 -- /bin/sh -x -c nc -zv -t -w 2 10.10.2.209 32480'
Feb  6 18:44:57.108: INFO: stderr: "+ nc -zv -t -w 2 10.10.2.209 32480\nConnection to 10.10.2.209 32480 port [tcp/32480] succeeded!\n"
Feb  6 18:44:57.108: INFO: stdout: ""
Feb  6 18:44:57.108: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:44:57.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4255" for this suite.
Feb  6 18:45:05.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:45:05.621: INFO: namespace services-4255 deletion completed in 8.477504547s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:15.889 seconds]
[sig-network] Services
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:45:05.621: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1064
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb  6 18:45:05.779: INFO: Waiting up to 5m0s for pod "pod-28574b21-d7c5-44ff-8a57-0c2a7926e8db" in namespace "emptydir-1064" to be "success or failure"
Feb  6 18:45:05.783: INFO: Pod "pod-28574b21-d7c5-44ff-8a57-0c2a7926e8db": Phase="Pending", Reason="", readiness=false. Elapsed: 3.644116ms
Feb  6 18:45:07.786: INFO: Pod "pod-28574b21-d7c5-44ff-8a57-0c2a7926e8db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007388384s
STEP: Saw pod success
Feb  6 18:45:07.786: INFO: Pod "pod-28574b21-d7c5-44ff-8a57-0c2a7926e8db" satisfied condition "success or failure"
Feb  6 18:45:07.789: INFO: Trying to get logs from node ip-10-10-2-209.ec2.internal pod pod-28574b21-d7c5-44ff-8a57-0c2a7926e8db container test-container: <nil>
STEP: delete the pod
Feb  6 18:45:07.809: INFO: Waiting for pod pod-28574b21-d7c5-44ff-8a57-0c2a7926e8db to disappear
Feb  6 18:45:07.812: INFO: Pod pod-28574b21-d7c5-44ff-8a57-0c2a7926e8db no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:45:07.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1064" for this suite.
Feb  6 18:45:13.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:45:14.291: INFO: namespace emptydir-1064 deletion completed in 6.474715379s

• [SLOW TEST:8.670 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:45:14.291: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5763
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 18:45:15.327: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb  6 18:45:17.337: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716611515, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716611515, loc:(*time.Location)(0x788a6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716611515, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716611515, loc:(*time.Location)(0x788a6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 18:45:20.355: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 18:45:20.359: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-356-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:45:21.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5763" for this suite.
Feb  6 18:45:27.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:45:27.975: INFO: namespace webhook-5763 deletion completed in 6.493959799s
STEP: Destroying namespace "webhook-5763-markers" for this suite.
Feb  6 18:45:33.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:45:34.451: INFO: namespace webhook-5763-markers deletion completed in 6.475644421s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:20.177 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:45:34.468: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6523
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb  6 18:45:34.634: INFO: Waiting up to 5m0s for pod "pod-b468cd29-ec12-46d6-9178-89fd2d9607ef" in namespace "emptydir-6523" to be "success or failure"
Feb  6 18:45:34.638: INFO: Pod "pod-b468cd29-ec12-46d6-9178-89fd2d9607ef": Phase="Pending", Reason="", readiness=false. Elapsed: 3.859227ms
Feb  6 18:45:36.642: INFO: Pod "pod-b468cd29-ec12-46d6-9178-89fd2d9607ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00760853s
Feb  6 18:45:38.646: INFO: Pod "pod-b468cd29-ec12-46d6-9178-89fd2d9607ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011576485s
STEP: Saw pod success
Feb  6 18:45:38.646: INFO: Pod "pod-b468cd29-ec12-46d6-9178-89fd2d9607ef" satisfied condition "success or failure"
Feb  6 18:45:38.649: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-b468cd29-ec12-46d6-9178-89fd2d9607ef container test-container: <nil>
STEP: delete the pod
Feb  6 18:45:38.669: INFO: Waiting for pod pod-b468cd29-ec12-46d6-9178-89fd2d9607ef to disappear
Feb  6 18:45:38.673: INFO: Pod pod-b468cd29-ec12-46d6-9178-89fd2d9607ef no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:45:38.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6523" for this suite.
Feb  6 18:45:44.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:45:45.153: INFO: namespace emptydir-6523 deletion completed in 6.475405212s

• [SLOW TEST:10.685 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:45:45.153: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6307
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:45:49.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6307" for this suite.
Feb  6 18:45:55.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:45:55.805: INFO: namespace kubelet-test-6307 deletion completed in 6.478116924s

• [SLOW TEST:10.652 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:45:55.805: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7790
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Feb  6 18:46:35.991: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0206 18:46:35.991797      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:46:35.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7790" for this suite.
Feb  6 18:46:44.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:46:44.479: INFO: namespace gc-7790 deletion completed in 8.48374702s

• [SLOW TEST:48.674 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:46:44.479: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9021
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 18:46:44.655: INFO: Waiting up to 5m0s for pod "downwardapi-volume-91c2715d-96a0-4d46-b75e-2566cf38ea90" in namespace "projected-9021" to be "success or failure"
Feb  6 18:46:44.658: INFO: Pod "downwardapi-volume-91c2715d-96a0-4d46-b75e-2566cf38ea90": Phase="Pending", Reason="", readiness=false. Elapsed: 3.4619ms
Feb  6 18:46:46.662: INFO: Pod "downwardapi-volume-91c2715d-96a0-4d46-b75e-2566cf38ea90": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007184819s
STEP: Saw pod success
Feb  6 18:46:46.662: INFO: Pod "downwardapi-volume-91c2715d-96a0-4d46-b75e-2566cf38ea90" satisfied condition "success or failure"
Feb  6 18:46:46.665: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod downwardapi-volume-91c2715d-96a0-4d46-b75e-2566cf38ea90 container client-container: <nil>
STEP: delete the pod
Feb  6 18:46:46.691: INFO: Waiting for pod downwardapi-volume-91c2715d-96a0-4d46-b75e-2566cf38ea90 to disappear
Feb  6 18:46:46.693: INFO: Pod downwardapi-volume-91c2715d-96a0-4d46-b75e-2566cf38ea90 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:46:46.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9021" for this suite.
Feb  6 18:46:52.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:46:53.172: INFO: namespace projected-9021 deletion completed in 6.474343057s

• [SLOW TEST:8.692 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:46:53.172: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7152
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 18:46:53.318: INFO: Creating deployment "test-recreate-deployment"
Feb  6 18:46:53.323: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb  6 18:46:53.331: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Feb  6 18:46:55.338: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb  6 18:46:55.341: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb  6 18:46:55.349: INFO: Updating deployment test-recreate-deployment
Feb  6 18:46:55.349: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb  6 18:46:55.458: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-7152 /apis/apps/v1/namespaces/deployment-7152/deployments/test-recreate-deployment f50d2194-3cba-446a-853c-8bc2ee3f9dd6 55149 2 2020-02-06 18:46:53 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003cb8678 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-02-06 18:46:55 +0000 UTC,LastTransitionTime:2020-02-06 18:46:55 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2020-02-06 18:46:55 +0000 UTC,LastTransitionTime:2020-02-06 18:46:53 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Feb  6 18:46:55.462: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-7152 /apis/apps/v1/namespaces/deployment-7152/replicasets/test-recreate-deployment-5f94c574ff 6fd1a3e4-e2d8-4a4b-9606-f2d12d938530 55146 1 2020-02-06 18:46:55 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment f50d2194-3cba-446a-853c-8bc2ee3f9dd6 0xc003cb8a47 0xc003cb8a48}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003cb8aa8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb  6 18:46:55.462: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb  6 18:46:55.462: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-7152 /apis/apps/v1/namespaces/deployment-7152/replicasets/test-recreate-deployment-68fc85c7bb 8beb958e-885f-404e-ba7d-8ed9713e6bfe 55137 2 2020-02-06 18:46:53 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment f50d2194-3cba-446a-853c-8bc2ee3f9dd6 0xc003cb8b17 0xc003cb8b18}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003cb8b78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb  6 18:46:55.466: INFO: Pod "test-recreate-deployment-5f94c574ff-tgqbm" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-tgqbm test-recreate-deployment-5f94c574ff- deployment-7152 /api/v1/namespaces/deployment-7152/pods/test-recreate-deployment-5f94c574ff-tgqbm f50de24c-d372-48dc-a293-9fb524755e1d 55148 0 2020-02-06 18:46:55 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff 6fd1a3e4-e2d8-4a4b-9606-f2d12d938530 0xc003cb8fe7 0xc003cb8fe8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jfwp8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jfwp8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jfwp8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-10-3-246.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 18:46:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 18:46:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 18:46:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 18:46:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.3.246,PodIP:,StartTime:2020-02-06 18:46:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:46:55.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7152" for this suite.
Feb  6 18:47:01.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:47:02.024: INFO: namespace deployment-7152 deletion completed in 6.552068892s

• [SLOW TEST:8.852 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:47:02.024: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9758
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:47:19.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9758" for this suite.
Feb  6 18:47:25.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:47:25.723: INFO: namespace resourcequota-9758 deletion completed in 6.476615995s

• [SLOW TEST:23.699 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:47:25.724: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8208
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-3e238252-7134-4c5f-9eec-c83fa7b91d89
STEP: Creating a pod to test consume secrets
Feb  6 18:47:25.883: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9e8fd656-9dcf-40e4-85e4-c9f6c33fde07" in namespace "projected-8208" to be "success or failure"
Feb  6 18:47:25.886: INFO: Pod "pod-projected-secrets-9e8fd656-9dcf-40e4-85e4-c9f6c33fde07": Phase="Pending", Reason="", readiness=false. Elapsed: 3.007261ms
Feb  6 18:47:27.890: INFO: Pod "pod-projected-secrets-9e8fd656-9dcf-40e4-85e4-c9f6c33fde07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00709999s
Feb  6 18:47:29.894: INFO: Pod "pod-projected-secrets-9e8fd656-9dcf-40e4-85e4-c9f6c33fde07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010782791s
STEP: Saw pod success
Feb  6 18:47:29.894: INFO: Pod "pod-projected-secrets-9e8fd656-9dcf-40e4-85e4-c9f6c33fde07" satisfied condition "success or failure"
Feb  6 18:47:29.897: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-projected-secrets-9e8fd656-9dcf-40e4-85e4-c9f6c33fde07 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  6 18:47:29.920: INFO: Waiting for pod pod-projected-secrets-9e8fd656-9dcf-40e4-85e4-c9f6c33fde07 to disappear
Feb  6 18:47:29.923: INFO: Pod pod-projected-secrets-9e8fd656-9dcf-40e4-85e4-c9f6c33fde07 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:47:29.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8208" for this suite.
Feb  6 18:47:35.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:47:36.400: INFO: namespace projected-8208 deletion completed in 6.47273842s

• [SLOW TEST:10.677 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:47:36.400: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-5966
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb  6 18:47:36.590: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5966 /api/v1/namespaces/watch-5966/configmaps/e2e-watch-test-label-changed a3bfd368-c8cc-4d97-8704-dce3648d23d8 55451 0 2020-02-06 18:47:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  6 18:47:36.591: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5966 /api/v1/namespaces/watch-5966/configmaps/e2e-watch-test-label-changed a3bfd368-c8cc-4d97-8704-dce3648d23d8 55452 0 2020-02-06 18:47:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb  6 18:47:36.591: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5966 /api/v1/namespaces/watch-5966/configmaps/e2e-watch-test-label-changed a3bfd368-c8cc-4d97-8704-dce3648d23d8 55453 0 2020-02-06 18:47:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb  6 18:47:46.621: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5966 /api/v1/namespaces/watch-5966/configmaps/e2e-watch-test-label-changed a3bfd368-c8cc-4d97-8704-dce3648d23d8 55494 0 2020-02-06 18:47:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  6 18:47:46.621: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5966 /api/v1/namespaces/watch-5966/configmaps/e2e-watch-test-label-changed a3bfd368-c8cc-4d97-8704-dce3648d23d8 55495 0 2020-02-06 18:47:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb  6 18:47:46.621: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5966 /api/v1/namespaces/watch-5966/configmaps/e2e-watch-test-label-changed a3bfd368-c8cc-4d97-8704-dce3648d23d8 55496 0 2020-02-06 18:47:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:47:46.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5966" for this suite.
Feb  6 18:47:52.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:47:53.109: INFO: namespace watch-5966 deletion completed in 6.482686816s

• [SLOW TEST:16.708 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:47:53.109: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3851
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb  6 18:47:57.809: INFO: Successfully updated pod "pod-update-27425e06-67b5-4b47-a178-17fa73dcca18"
STEP: verifying the updated pod is in kubernetes
Feb  6 18:47:57.819: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:47:57.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3851" for this suite.
Feb  6 18:48:09.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:48:10.298: INFO: namespace pods-3851 deletion completed in 12.473990016s

• [SLOW TEST:17.189 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:48:10.298: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-34
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 18:48:10.455: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:48:19.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-34" for this suite.
Feb  6 18:48:25.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:48:25.795: INFO: namespace custom-resource-definition-34 deletion completed in 6.475962202s

• [SLOW TEST:15.498 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:48:25.796: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-585
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:48:25.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-585" for this suite.
Feb  6 18:48:31.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:48:32.428: INFO: namespace custom-resource-definition-585 deletion completed in 6.476032066s

• [SLOW TEST:6.632 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:48:32.428: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1813
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:48:48.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1813" for this suite.
Feb  6 18:48:54.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:48:55.158: INFO: namespace resourcequota-1813 deletion completed in 6.475097492s

• [SLOW TEST:22.731 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:48:55.159: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6410
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb  6 18:48:55.316: INFO: Waiting up to 5m0s for pod "pod-1769d27e-d9fd-46ee-abce-4c634ccc88da" in namespace "emptydir-6410" to be "success or failure"
Feb  6 18:48:55.319: INFO: Pod "pod-1769d27e-d9fd-46ee-abce-4c634ccc88da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.600132ms
Feb  6 18:48:57.323: INFO: Pod "pod-1769d27e-d9fd-46ee-abce-4c634ccc88da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006581517s
STEP: Saw pod success
Feb  6 18:48:57.323: INFO: Pod "pod-1769d27e-d9fd-46ee-abce-4c634ccc88da" satisfied condition "success or failure"
Feb  6 18:48:57.325: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-1769d27e-d9fd-46ee-abce-4c634ccc88da container test-container: <nil>
STEP: delete the pod
Feb  6 18:48:57.346: INFO: Waiting for pod pod-1769d27e-d9fd-46ee-abce-4c634ccc88da to disappear
Feb  6 18:48:57.348: INFO: Pod pod-1769d27e-d9fd-46ee-abce-4c634ccc88da no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:48:57.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6410" for this suite.
Feb  6 18:49:03.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:49:04.399: INFO: namespace emptydir-6410 deletion completed in 7.037368782s

• [SLOW TEST:9.240 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:49:04.399: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9466
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb  6 18:49:04.546: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  6 18:49:04.560: INFO: Waiting for terminating namespaces to be deleted...
Feb  6 18:49:04.564: INFO: 
Logging pods the kubelet thinks is on node ip-10-10-1-217.ec2.internal before test
Feb  6 18:49:04.585: INFO: md-flux-6d54668955-bl6sl from md-flux started at 2020-02-06 18:11:25 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.585: INFO: 	Container flux ready: true, restart count 0
Feb  6 18:49:04.585: INFO: md-cert-manager-cainjector-7758b57b8d-4j8jj from md-cert-manager started at 2020-02-06 18:11:31 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.585: INFO: 	Container cert-manager ready: true, restart count 0
Feb  6 18:49:04.585: INFO: md-prometheus-operator-prometheus-node-exporter-mxlfh from md-prometheus-operator started at 2020-02-06 18:12:39 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.585: INFO: 	Container node-exporter ready: true, restart count 0
Feb  6 18:49:04.585: INFO: loki-6877765b9c-2n9vf from md-loki-stack started at 2020-02-06 18:12:01 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.585: INFO: 	Container loki ready: true, restart count 0
Feb  6 18:49:04.585: INFO: prometheus-md-prometheus-operator-prometheus-0 from md-prometheus-operator started at 2020-02-06 18:12:58 +0000 UTC (3 container statuses recorded)
Feb  6 18:49:04.585: INFO: 	Container prometheus ready: true, restart count 1
Feb  6 18:49:04.585: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Feb  6 18:49:04.585: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Feb  6 18:49:04.585: INFO: kube-proxy-dj7kw from kube-system started at 2020-02-06 15:57:54 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.585: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  6 18:49:04.585: INFO: md-prometheus-operator-operator-f975b4dd9-rw84h from md-prometheus-operator started at 2020-02-06 18:12:39 +0000 UTC (2 container statuses recorded)
Feb  6 18:49:04.585: INFO: 	Container prometheus-operator ready: true, restart count 0
Feb  6 18:49:04.585: INFO: 	Container tls-proxy ready: true, restart count 0
Feb  6 18:49:04.585: INFO: md-oauth2-proxy-5cff658bcc-zlwms from md-oauth2-proxy started at 2020-02-06 18:46:40 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.585: INFO: 	Container oauth2-proxy ready: false, restart count 4
Feb  6 18:49:04.585: INFO: calico-node-hrxsw from kube-system started at 2020-02-06 15:57:54 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.585: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 18:49:04.585: INFO: sonobuoy-systemd-logs-daemon-set-936a433795204ed3-lmxgr from sonobuoy started at 2020-02-06 18:40:06 +0000 UTC (2 container statuses recorded)
Feb  6 18:49:04.585: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 18:49:04.585: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 18:49:04.585: INFO: md-cert-manager-669497f667-mb9js from md-cert-manager started at 2020-02-06 18:11:31 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.585: INFO: 	Container cert-manager ready: true, restart count 0
Feb  6 18:49:04.585: INFO: md-loki-stack-promtail-mmws9 from md-loki-stack started at 2020-02-06 18:12:01 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.585: INFO: 	Container promtail ready: true, restart count 0
Feb  6 18:49:04.585: INFO: md-nginx-ingress-controller-5cff997b69-9qwpx from md-nginx-ingress started at 2020-02-06 18:12:09 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.585: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb  6 18:49:04.585: INFO: 
Logging pods the kubelet thinks is on node ip-10-10-2-209.ec2.internal before test
Feb  6 18:49:04.608: INFO: md-prometheus-operator-prometheus-node-exporter-p52sm from md-prometheus-operator started at 2020-02-06 18:12:39 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.608: INFO: 	Container node-exporter ready: true, restart count 0
Feb  6 18:49:04.608: INFO: md-helm-operator-59d9c54dbf-85p6w from md-helm-operator started at 2020-02-06 18:11:03 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.608: INFO: 	Container flux-helm-operator ready: true, restart count 0
Feb  6 18:49:04.608: INFO: md-navigator-moondog-navigator-65f699786c-6sbxm from md-navigator started at 2020-02-06 18:11:28 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.608: INFO: 	Container moondog-navigator ready: true, restart count 0
Feb  6 18:49:04.608: INFO: md-loki-stack-promtail-wl8xd from md-loki-stack started at 2020-02-06 18:12:01 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.608: INFO: 	Container promtail ready: true, restart count 0
Feb  6 18:49:04.608: INFO: cm-acme-http-solver-tg7qw from md-dex started at 2020-02-06 18:12:35 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.608: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 18:49:04.608: INFO: md-flux-memcached-77b577bb4c-z77xr from md-flux started at 2020-02-06 18:11:26 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.608: INFO: 	Container memcached ready: true, restart count 0
Feb  6 18:49:04.608: INFO: md-dex-bfbfd7887-c9sjp from md-dex started at 2020-02-06 18:11:32 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.608: INFO: 	Container main ready: true, restart count 1
Feb  6 18:49:04.608: INFO: md-gangway-548f557b49-v4cb5 from md-gangway started at 2020-02-06 18:11:59 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.608: INFO: 	Container gangway ready: true, restart count 0
Feb  6 18:49:04.608: INFO: md-nginx-ingress-default-backend-7d86d446b4-kp67r from md-nginx-ingress started at 2020-02-06 18:12:09 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.608: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
Feb  6 18:49:04.608: INFO: md-prometheus-operator-kube-state-metrics-b65d855df-b9v58 from md-prometheus-operator started at 2020-02-06 18:12:39 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.608: INFO: 	Container kube-state-metrics ready: true, restart count 0
Feb  6 18:49:04.608: INFO: md-prometheus-operator-grafana-6699695c84-cpjdc from md-prometheus-operator started at 2020-02-06 18:12:49 +0000 UTC (2 container statuses recorded)
Feb  6 18:49:04.608: INFO: 	Container grafana ready: true, restart count 0
Feb  6 18:49:04.608: INFO: 	Container grafana-sc-dashboard ready: true, restart count 0
Feb  6 18:49:04.608: INFO: calico-node-jcts8 from kube-system started at 2020-02-06 15:57:51 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.608: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 18:49:04.608: INFO: kube-proxy-zp49w from kube-system started at 2020-02-06 15:57:51 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.608: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  6 18:49:04.608: INFO: sonobuoy-systemd-logs-daemon-set-936a433795204ed3-fdsl7 from sonobuoy started at 2020-02-06 18:40:06 +0000 UTC (2 container statuses recorded)
Feb  6 18:49:04.608: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 18:49:04.608: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 18:49:04.608: INFO: 
Logging pods the kubelet thinks is on node ip-10-10-3-246.ec2.internal before test
Feb  6 18:49:04.617: INFO: md-cert-manager-webhook-58b4496d5-m9r65 from md-cert-manager started at 2020-02-06 18:11:31 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.617: INFO: 	Container cert-manager ready: true, restart count 0
Feb  6 18:49:04.617: INFO: sonobuoy-systemd-logs-daemon-set-936a433795204ed3-q2qnm from sonobuoy started at 2020-02-06 18:40:06 +0000 UTC (2 container statuses recorded)
Feb  6 18:49:04.617: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 18:49:04.617: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 18:49:04.617: INFO: md-prometheus-operator-prometheus-node-exporter-5lb5f from md-prometheus-operator started at 2020-02-06 18:12:39 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.617: INFO: 	Container node-exporter ready: true, restart count 0
Feb  6 18:49:04.617: INFO: alertmanager-md-prometheus-operator-alertmanager-0 from md-prometheus-operator started at 2020-02-06 18:12:48 +0000 UTC (2 container statuses recorded)
Feb  6 18:49:04.617: INFO: 	Container alertmanager ready: true, restart count 0
Feb  6 18:49:04.617: INFO: 	Container config-reloader ready: true, restart count 0
Feb  6 18:49:04.617: INFO: cm-acme-http-solver-fk6cq from md-prometheus-operator started at 2020-02-06 18:22:29 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.617: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 18:49:04.617: INFO: calico-node-n4lqx from kube-system started at 2020-02-06 15:57:51 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.617: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 18:49:04.617: INFO: cm-acme-http-solver-rp5cz from md-oauth2-proxy started at 2020-02-06 18:47:31 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.617: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 18:49:04.617: INFO: md-loki-stack-promtail-mfhtv from md-loki-stack started at 2020-02-06 18:12:01 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.617: INFO: 	Container promtail ready: true, restart count 0
Feb  6 18:49:04.617: INFO: cm-acme-http-solver-vmrlr from md-gangway started at 2020-02-06 18:12:16 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.617: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 18:49:04.617: INFO: cm-acme-http-solver-965sg from md-navigator started at 2020-02-06 18:12:35 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.617: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 18:49:04.617: INFO: cm-acme-http-solver-2grg5 from md-prometheus-operator started at 2020-02-06 18:22:29 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.617: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 18:49:04.617: INFO: cm-acme-http-solver-l4dnj from md-prometheus-operator started at 2020-02-06 18:22:31 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.617: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 18:49:04.617: INFO: kube-proxy-jfqqq from kube-system started at 2020-02-06 15:57:51 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.617: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  6 18:49:04.617: INFO: sonobuoy from sonobuoy started at 2020-02-06 18:40:05 +0000 UTC (1 container statuses recorded)
Feb  6 18:49:04.617: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  6 18:49:04.617: INFO: sonobuoy-e2e-job-7dfb3a3ef75e43b0 from sonobuoy started at 2020-02-06 18:40:06 +0000 UTC (2 container statuses recorded)
Feb  6 18:49:04.617: INFO: 	Container e2e ready: true, restart count 0
Feb  6 18:49:04.617: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-a85fb82c-0cad-4cf6-b55f-0fb2d43027ce 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-a85fb82c-0cad-4cf6-b55f-0fb2d43027ce off the node ip-10-10-3-246.ec2.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-a85fb82c-0cad-4cf6-b55f-0fb2d43027ce
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:54:12.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9466" for this suite.
Feb  6 18:54:20.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:54:21.205: INFO: namespace sched-pred-9466 deletion completed in 8.473526978s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:316.806 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:54:21.205: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6413
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 18:54:21.927: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Feb  6 18:54:23.937: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716612061, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716612061, loc:(*time.Location)(0x788a6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716612061, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716612061, loc:(*time.Location)(0x788a6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 18:54:26.954: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:54:27.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6413" for this suite.
Feb  6 18:54:39.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:54:39.485: INFO: namespace webhook-6413 deletion completed in 12.475915156s
STEP: Destroying namespace "webhook-6413-markers" for this suite.
Feb  6 18:54:45.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:54:45.960: INFO: namespace webhook-6413-markers deletion completed in 6.474781332s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.772 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:54:45.977: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5151
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 18:54:46.161: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6dc26f62-3211-44ef-9f52-dd3877533591" in namespace "downward-api-5151" to be "success or failure"
Feb  6 18:54:46.165: INFO: Pod "downwardapi-volume-6dc26f62-3211-44ef-9f52-dd3877533591": Phase="Pending", Reason="", readiness=false. Elapsed: 4.155642ms
Feb  6 18:54:48.169: INFO: Pod "downwardapi-volume-6dc26f62-3211-44ef-9f52-dd3877533591": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008021635s
Feb  6 18:54:50.173: INFO: Pod "downwardapi-volume-6dc26f62-3211-44ef-9f52-dd3877533591": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011749008s
STEP: Saw pod success
Feb  6 18:54:50.173: INFO: Pod "downwardapi-volume-6dc26f62-3211-44ef-9f52-dd3877533591" satisfied condition "success or failure"
Feb  6 18:54:50.175: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod downwardapi-volume-6dc26f62-3211-44ef-9f52-dd3877533591 container client-container: <nil>
STEP: delete the pod
Feb  6 18:54:50.206: INFO: Waiting for pod downwardapi-volume-6dc26f62-3211-44ef-9f52-dd3877533591 to disappear
Feb  6 18:54:50.212: INFO: Pod downwardapi-volume-6dc26f62-3211-44ef-9f52-dd3877533591 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:54:50.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5151" for this suite.
Feb  6 18:54:56.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:54:56.703: INFO: namespace downward-api-5151 deletion completed in 6.485921669s

• [SLOW TEST:10.726 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:54:56.704: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6628
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb  6 18:55:00.915: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 18:55:00.921: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 18:55:02.923: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 18:55:02.927: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 18:55:04.921: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 18:55:04.925: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 18:55:06.921: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 18:55:06.925: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 18:55:08.921: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 18:55:08.925: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 18:55:10.921: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 18:55:10.925: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 18:55:12.921: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 18:55:12.925: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:55:12.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6628" for this suite.
Feb  6 18:55:42.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:55:43.403: INFO: namespace container-lifecycle-hook-6628 deletion completed in 30.474025502s

• [SLOW TEST:46.700 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:55:43.404: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8442
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-ec1ccd9a-50f4-41ee-888f-cb563ecc21f2
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:55:43.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8442" for this suite.
Feb  6 18:55:49.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:55:50.041: INFO: namespace secrets-8442 deletion completed in 6.478256767s

• [SLOW TEST:6.638 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:55:50.041: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6337
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6337
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-6337
Feb  6 18:55:50.206: INFO: Found 0 stateful pods, waiting for 1
Feb  6 18:56:00.209: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb  6 18:56:00.228: INFO: Deleting all statefulset in ns statefulset-6337
Feb  6 18:56:00.234: INFO: Scaling statefulset ss to 0
Feb  6 18:56:20.251: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 18:56:20.254: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:56:20.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6337" for this suite.
Feb  6 18:56:26.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:56:26.748: INFO: namespace statefulset-6337 deletion completed in 6.475558756s

• [SLOW TEST:36.707 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:56:26.749: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7492
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-7492
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  6 18:56:26.898: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  6 18:56:46.983: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.162.49:8080/dial?request=hostName&protocol=http&host=192.168.126.57&port=8080&tries=1'] Namespace:pod-network-test-7492 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 18:56:46.983: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 18:56:47.150: INFO: Waiting for endpoints: map[]
Feb  6 18:56:47.153: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.162.49:8080/dial?request=hostName&protocol=http&host=192.168.162.47&port=8080&tries=1'] Namespace:pod-network-test-7492 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 18:56:47.153: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 18:56:47.321: INFO: Waiting for endpoints: map[]
Feb  6 18:56:47.324: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.162.49:8080/dial?request=hostName&protocol=http&host=192.168.3.16&port=8080&tries=1'] Namespace:pod-network-test-7492 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 18:56:47.324: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 18:56:47.498: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:56:47.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7492" for this suite.
Feb  6 18:56:59.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:56:59.978: INFO: namespace pod-network-test-7492 deletion completed in 12.474896622s

• [SLOW TEST:33.229 seconds]
[sig-network] Networking
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:56:59.978: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6430
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-35c08487-190b-4a00-a634-d3693b8afdac
STEP: Creating a pod to test consume secrets
Feb  6 18:57:00.140: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e72a7c58-3213-48b7-8804-4798692c479d" in namespace "projected-6430" to be "success or failure"
Feb  6 18:57:00.144: INFO: Pod "pod-projected-secrets-e72a7c58-3213-48b7-8804-4798692c479d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.55668ms
Feb  6 18:57:02.148: INFO: Pod "pod-projected-secrets-e72a7c58-3213-48b7-8804-4798692c479d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008447009s
Feb  6 18:57:04.152: INFO: Pod "pod-projected-secrets-e72a7c58-3213-48b7-8804-4798692c479d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012274002s
STEP: Saw pod success
Feb  6 18:57:04.152: INFO: Pod "pod-projected-secrets-e72a7c58-3213-48b7-8804-4798692c479d" satisfied condition "success or failure"
Feb  6 18:57:04.155: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-projected-secrets-e72a7c58-3213-48b7-8804-4798692c479d container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  6 18:57:04.185: INFO: Waiting for pod pod-projected-secrets-e72a7c58-3213-48b7-8804-4798692c479d to disappear
Feb  6 18:57:04.188: INFO: Pod pod-projected-secrets-e72a7c58-3213-48b7-8804-4798692c479d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:57:04.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6430" for this suite.
Feb  6 18:57:10.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:57:10.673: INFO: namespace projected-6430 deletion completed in 6.476919495s

• [SLOW TEST:10.695 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:57:10.674: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2168
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 18:57:10.866: INFO: (0) /api/v1/nodes/ip-10-10-1-217.ec2.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 31.164339ms)
Feb  6 18:57:10.871: INFO: (1) /api/v1/nodes/ip-10-10-1-217.ec2.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.832587ms)
Feb  6 18:57:10.878: INFO: (2) /api/v1/nodes/ip-10-10-1-217.ec2.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.995686ms)
Feb  6 18:57:10.882: INFO: (3) /api/v1/nodes/ip-10-10-1-217.ec2.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.26733ms)
Feb  6 18:57:10.887: INFO: (4) /api/v1/nodes/ip-10-10-1-217.ec2.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.266287ms)
Feb  6 18:57:10.891: INFO: (5) /api/v1/nodes/ip-10-10-1-217.ec2.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.999357ms)
Feb  6 18:57:10.895: INFO: (6) /api/v1/nodes/ip-10-10-1-217.ec2.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.030796ms)
Feb  6 18:57:10.899: INFO: (7) /api/v1/nodes/ip-10-10-1-217.ec2.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.084455ms)
Feb  6 18:57:10.904: INFO: (8) /api/v1/nodes/ip-10-10-1-217.ec2.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.790529ms)
Feb  6 18:57:10.908: INFO: (9) /api/v1/nodes/ip-10-10-1-217.ec2.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.254976ms)
Feb  6 18:57:10.912: INFO: (10) /api/v1/nodes/ip-10-10-1-217.ec2.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.469034ms)
Feb  6 18:57:10.917: INFO: (11) /api/v1/nodes/ip-10-10-1-217.ec2.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.502397ms)
Feb  6 18:57:10.921: INFO: (12) /api/v1/nodes/ip-10-10-1-217.ec2.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.346702ms)
Feb  6 18:57:10.926: INFO: (13) /api/v1/nodes/ip-10-10-1-217.ec2.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.765978ms)
Feb  6 18:57:10.932: INFO: (14) /api/v1/nodes/ip-10-10-1-217.ec2.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.467147ms)
Feb  6 18:57:10.936: INFO: (15) /api/v1/nodes/ip-10-10-1-217.ec2.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.629378ms)
Feb  6 18:57:10.941: INFO: (16) /api/v1/nodes/ip-10-10-1-217.ec2.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.436532ms)
Feb  6 18:57:10.945: INFO: (17) /api/v1/nodes/ip-10-10-1-217.ec2.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.227324ms)
Feb  6 18:57:10.949: INFO: (18) /api/v1/nodes/ip-10-10-1-217.ec2.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.159914ms)
Feb  6 18:57:10.954: INFO: (19) /api/v1/nodes/ip-10-10-1-217.ec2.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.410079ms)
[AfterEach] version v1
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:57:10.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2168" for this suite.
Feb  6 18:57:16.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:57:17.128: INFO: namespace proxy-2168 deletion completed in 6.169784402s

• [SLOW TEST:6.454 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:57:17.128: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8390
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8390.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8390.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  6 18:57:21.477: INFO: DNS probes using dns-8390/dns-test-dc5830c8-57cd-43b7-9b58-2e7e0384e62c succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:57:21.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8390" for this suite.
Feb  6 18:57:27.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:57:28.079: INFO: namespace dns-8390 deletion completed in 6.506012944s

• [SLOW TEST:10.951 seconds]
[sig-network] DNS
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:57:28.079: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7486
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 18:57:28.605: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 18:57:31.638: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:57:31.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7486" for this suite.
Feb  6 18:57:37.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:57:38.309: INFO: namespace webhook-7486 deletion completed in 6.47645234s
STEP: Destroying namespace "webhook-7486-markers" for this suite.
Feb  6 18:57:44.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:57:44.787: INFO: namespace webhook-7486-markers deletion completed in 6.477269819s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.722 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:57:44.802: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3875
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 18:57:44.958: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9d6c9959-946f-4fa1-96d7-46c2ddb20d2b" in namespace "downward-api-3875" to be "success or failure"
Feb  6 18:57:44.961: INFO: Pod "downwardapi-volume-9d6c9959-946f-4fa1-96d7-46c2ddb20d2b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.997373ms
Feb  6 18:57:46.965: INFO: Pod "downwardapi-volume-9d6c9959-946f-4fa1-96d7-46c2ddb20d2b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006561721s
STEP: Saw pod success
Feb  6 18:57:46.965: INFO: Pod "downwardapi-volume-9d6c9959-946f-4fa1-96d7-46c2ddb20d2b" satisfied condition "success or failure"
Feb  6 18:57:46.967: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod downwardapi-volume-9d6c9959-946f-4fa1-96d7-46c2ddb20d2b container client-container: <nil>
STEP: delete the pod
Feb  6 18:57:46.988: INFO: Waiting for pod downwardapi-volume-9d6c9959-946f-4fa1-96d7-46c2ddb20d2b to disappear
Feb  6 18:57:46.991: INFO: Pod downwardapi-volume-9d6c9959-946f-4fa1-96d7-46c2ddb20d2b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:57:46.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3875" for this suite.
Feb  6 18:57:53.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:57:53.476: INFO: namespace downward-api-3875 deletion completed in 6.480219933s

• [SLOW TEST:8.674 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:57:53.476: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3390
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-505b63db-9706-4f13-b312-d175a5e5bac9
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:57:53.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3390" for this suite.
Feb  6 18:57:59.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:58:00.099: INFO: namespace configmap-3390 deletion completed in 6.472446663s

• [SLOW TEST:6.624 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:58:00.100: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6826
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb  6 18:58:00.253: INFO: Waiting up to 5m0s for pod "downward-api-de48b75f-f6c4-4806-8631-95b9ee9f864d" in namespace "downward-api-6826" to be "success or failure"
Feb  6 18:58:00.257: INFO: Pod "downward-api-de48b75f-f6c4-4806-8631-95b9ee9f864d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.836296ms
Feb  6 18:58:02.261: INFO: Pod "downward-api-de48b75f-f6c4-4806-8631-95b9ee9f864d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007547094s
STEP: Saw pod success
Feb  6 18:58:02.261: INFO: Pod "downward-api-de48b75f-f6c4-4806-8631-95b9ee9f864d" satisfied condition "success or failure"
Feb  6 18:58:02.264: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod downward-api-de48b75f-f6c4-4806-8631-95b9ee9f864d container dapi-container: <nil>
STEP: delete the pod
Feb  6 18:58:02.286: INFO: Waiting for pod downward-api-de48b75f-f6c4-4806-8631-95b9ee9f864d to disappear
Feb  6 18:58:02.290: INFO: Pod downward-api-de48b75f-f6c4-4806-8631-95b9ee9f864d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:58:02.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6826" for this suite.
Feb  6 18:58:08.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:58:08.783: INFO: namespace downward-api-6826 deletion completed in 6.482370258s

• [SLOW TEST:8.684 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:58:08.784: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8284
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 18:58:08.933: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Feb  6 18:58:13.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 --namespace=crd-publish-openapi-8284 create -f -'
Feb  6 18:58:13.725: INFO: stderr: ""
Feb  6 18:58:13.725: INFO: stdout: "e2e-test-crd-publish-openapi-2675-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Feb  6 18:58:13.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 --namespace=crd-publish-openapi-8284 delete e2e-test-crd-publish-openapi-2675-crds test-cr'
Feb  6 18:58:13.847: INFO: stderr: ""
Feb  6 18:58:13.847: INFO: stdout: "e2e-test-crd-publish-openapi-2675-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Feb  6 18:58:13.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 --namespace=crd-publish-openapi-8284 apply -f -'
Feb  6 18:58:14.096: INFO: stderr: ""
Feb  6 18:58:14.096: INFO: stdout: "e2e-test-crd-publish-openapi-2675-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Feb  6 18:58:14.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 --namespace=crd-publish-openapi-8284 delete e2e-test-crd-publish-openapi-2675-crds test-cr'
Feb  6 18:58:14.239: INFO: stderr: ""
Feb  6 18:58:14.239: INFO: stdout: "e2e-test-crd-publish-openapi-2675-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Feb  6 18:58:14.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 explain e2e-test-crd-publish-openapi-2675-crds'
Feb  6 18:58:14.424: INFO: stderr: ""
Feb  6 18:58:14.424: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2675-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:58:18.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8284" for this suite.
Feb  6 18:58:24.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:58:25.186: INFO: namespace crd-publish-openapi-8284 deletion completed in 6.474427961s

• [SLOW TEST:16.403 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:58:25.186: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6848
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 18:59:25.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6848" for this suite.
Feb  6 18:59:51.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 18:59:51.827: INFO: namespace container-probe-6848 deletion completed in 26.477532968s

• [SLOW TEST:86.641 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 18:59:51.827: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2277
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Feb  6 19:00:22.535: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:00:22.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0206 19:00:22.535620      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-2277" for this suite.
Feb  6 19:00:28.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:00:29.016: INFO: namespace gc-2277 deletion completed in 6.475506332s

• [SLOW TEST:37.188 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:00:29.016: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1176
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb  6 19:00:31.195: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:00:31.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1176" for this suite.
Feb  6 19:00:37.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:00:37.709: INFO: namespace container-runtime-1176 deletion completed in 6.479511906s

• [SLOW TEST:8.693 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:00:37.709: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9528
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb  6 19:00:40.409: INFO: Successfully updated pod "labelsupdatedf1cc5f2-0db3-4621-9858-6a9d14b6e416"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:00:42.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9528" for this suite.
Feb  6 19:00:54.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:00:54.909: INFO: namespace downward-api-9528 deletion completed in 12.474973521s

• [SLOW TEST:17.200 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:00:54.909: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-330
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:00:55.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-330" for this suite.
Feb  6 19:01:01.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:01:01.574: INFO: namespace kubelet-test-330 deletion completed in 6.478445848s

• [SLOW TEST:6.665 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:01:01.574: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6312
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:01:17.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6312" for this suite.
Feb  6 19:01:23.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:01:24.304: INFO: namespace resourcequota-6312 deletion completed in 6.484083587s

• [SLOW TEST:22.730 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:01:24.304: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9215
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Feb  6 19:01:28.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec pod-sharedvolume-eec3d4c7-2291-46b3-a1a9-9846c53d60bb -c busybox-main-container --namespace=emptydir-9215 -- cat /usr/share/volumeshare/shareddata.txt'
Feb  6 19:01:28.704: INFO: stderr: ""
Feb  6 19:01:28.704: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:01:28.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9215" for this suite.
Feb  6 19:01:34.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:01:35.187: INFO: namespace emptydir-9215 deletion completed in 6.477448766s

• [SLOW TEST:10.883 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:01:35.188: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-436
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb  6 19:01:35.346: INFO: Waiting up to 5m0s for pod "pod-498a912b-1b69-4489-81ad-823ed90a675b" in namespace "emptydir-436" to be "success or failure"
Feb  6 19:01:35.350: INFO: Pod "pod-498a912b-1b69-4489-81ad-823ed90a675b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.68025ms
Feb  6 19:01:37.354: INFO: Pod "pod-498a912b-1b69-4489-81ad-823ed90a675b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008431448s
STEP: Saw pod success
Feb  6 19:01:37.354: INFO: Pod "pod-498a912b-1b69-4489-81ad-823ed90a675b" satisfied condition "success or failure"
Feb  6 19:01:37.357: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-498a912b-1b69-4489-81ad-823ed90a675b container test-container: <nil>
STEP: delete the pod
Feb  6 19:01:37.387: INFO: Waiting for pod pod-498a912b-1b69-4489-81ad-823ed90a675b to disappear
Feb  6 19:01:37.390: INFO: Pod pod-498a912b-1b69-4489-81ad-823ed90a675b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:01:37.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-436" for this suite.
Feb  6 19:01:43.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:01:43.875: INFO: namespace emptydir-436 deletion completed in 6.479772858s

• [SLOW TEST:8.687 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:01:43.875: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4122
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb  6 19:01:44.030: INFO: PodSpec: initContainers in spec.initContainers
Feb  6 19:02:23.748: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-df2dcfac-6f2d-4418-b827-588fcffcce8a", GenerateName:"", Namespace:"init-container-4122", SelfLink:"/api/v1/namespaces/init-container-4122/pods/pod-init-df2dcfac-6f2d-4418-b827-588fcffcce8a", UID:"203363fc-519c-4430-9179-b2bfa6b63954", ResourceVersion:"60176", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63716612504, loc:(*time.Location)(0x788a6e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"30332759"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.162.52/32", "kubernetes.io/psp":"admin"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-67ndv", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc006cde000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-67ndv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-67ndv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-67ndv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003d94088), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-10-2-209.ec2.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002e3c060), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003d94100)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003d94130)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc003d94138), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc003d9413c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716612504, loc:(*time.Location)(0x788a6e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716612504, loc:(*time.Location)(0x788a6e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716612504, loc:(*time.Location)(0x788a6e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716612504, loc:(*time.Location)(0x788a6e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.10.2.209", PodIP:"192.168.162.52", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.162.52"}}, StartTime:(*v1.Time)(0xc00364e040), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0008a00e0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0008a01c0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://03a10b67681ba6dc05c90bcedeb3facac14f92a6a81131dac361225c4b80b49c", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00364e080), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00364e060), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc003d941bf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:02:23.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4122" for this suite.
Feb  6 19:02:53.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:02:54.228: INFO: namespace init-container-4122 deletion completed in 30.474628967s

• [SLOW TEST:70.353 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:02:54.228: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8962
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-8962
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8962 to expose endpoints map[]
Feb  6 19:02:54.394: INFO: Get endpoints failed (2.942123ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Feb  6 19:02:55.398: INFO: successfully validated that service multi-endpoint-test in namespace services-8962 exposes endpoints map[] (1.006635471s elapsed)
STEP: Creating pod pod1 in namespace services-8962
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8962 to expose endpoints map[pod1:[100]]
Feb  6 19:02:57.431: INFO: successfully validated that service multi-endpoint-test in namespace services-8962 exposes endpoints map[pod1:[100]] (2.024905825s elapsed)
STEP: Creating pod pod2 in namespace services-8962
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8962 to expose endpoints map[pod1:[100] pod2:[101]]
Feb  6 19:02:59.466: INFO: successfully validated that service multi-endpoint-test in namespace services-8962 exposes endpoints map[pod1:[100] pod2:[101]] (2.029977335s elapsed)
STEP: Deleting pod pod1 in namespace services-8962
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8962 to expose endpoints map[pod2:[101]]
Feb  6 19:03:00.496: INFO: successfully validated that service multi-endpoint-test in namespace services-8962 exposes endpoints map[pod2:[101]] (1.023400636s elapsed)
STEP: Deleting pod pod2 in namespace services-8962
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8962 to expose endpoints map[]
Feb  6 19:03:00.513: INFO: successfully validated that service multi-endpoint-test in namespace services-8962 exposes endpoints map[] (6.083388ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:03:00.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8962" for this suite.
Feb  6 19:03:12.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:03:13.025: INFO: namespace services-8962 deletion completed in 12.477847898s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:18.797 seconds]
[sig-network] Services
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:03:13.025: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-6159
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 19:03:13.189: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:03:14.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6159" for this suite.
Feb  6 19:03:20.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:03:20.775: INFO: namespace custom-resource-definition-6159 deletion completed in 6.553192881s

• [SLOW TEST:7.750 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:03:20.775: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7254
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:03:20.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7254" for this suite.
Feb  6 19:03:26.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:03:27.429: INFO: namespace resourcequota-7254 deletion completed in 6.474364136s

• [SLOW TEST:6.654 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:03:27.429: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1986
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:03:31.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1986" for this suite.
Feb  6 19:04:17.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:04:18.154: INFO: namespace kubelet-test-1986 deletion completed in 46.473002729s

• [SLOW TEST:50.725 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:04:18.154: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1006
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 19:04:18.866: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Feb  6 19:04:20.876: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716612658, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716612658, loc:(*time.Location)(0x788a6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716612658, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716612658, loc:(*time.Location)(0x788a6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 19:04:23.893: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:04:23.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1006" for this suite.
Feb  6 19:04:29.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:04:30.380: INFO: namespace webhook-1006 deletion completed in 6.476062384s
STEP: Destroying namespace "webhook-1006-markers" for this suite.
Feb  6 19:04:36.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:04:36.855: INFO: namespace webhook-1006-markers deletion completed in 6.474973949s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.717 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:04:36.871: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-9653
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 19:04:37.020: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Feb  6 19:04:41.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 --namespace=crd-publish-openapi-9653 create -f -'
Feb  6 19:04:41.806: INFO: stderr: ""
Feb  6 19:04:41.806: INFO: stdout: "e2e-test-crd-publish-openapi-9206-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Feb  6 19:04:41.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 --namespace=crd-publish-openapi-9653 delete e2e-test-crd-publish-openapi-9206-crds test-cr'
Feb  6 19:04:41.936: INFO: stderr: ""
Feb  6 19:04:41.936: INFO: stdout: "e2e-test-crd-publish-openapi-9206-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Feb  6 19:04:41.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 --namespace=crd-publish-openapi-9653 apply -f -'
Feb  6 19:04:42.189: INFO: stderr: ""
Feb  6 19:04:42.189: INFO: stdout: "e2e-test-crd-publish-openapi-9206-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Feb  6 19:04:42.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 --namespace=crd-publish-openapi-9653 delete e2e-test-crd-publish-openapi-9206-crds test-cr'
Feb  6 19:04:42.272: INFO: stderr: ""
Feb  6 19:04:42.272: INFO: stdout: "e2e-test-crd-publish-openapi-9206-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Feb  6 19:04:42.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 explain e2e-test-crd-publish-openapi-9206-crds'
Feb  6 19:04:42.456: INFO: stderr: ""
Feb  6 19:04:42.456: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9206-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:04:46.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9653" for this suite.
Feb  6 19:04:52.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:04:53.230: INFO: namespace crd-publish-openapi-9653 deletion completed in 6.476658578s

• [SLOW TEST:16.359 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:04:53.230: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-858
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-858
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-858
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-858
Feb  6 19:04:53.399: INFO: Found 0 stateful pods, waiting for 1
Feb  6 19:05:03.403: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb  6 19:05:03.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=statefulset-858 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb  6 19:05:03.640: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb  6 19:05:03.640: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb  6 19:05:03.640: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb  6 19:05:03.644: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb  6 19:05:13.648: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 19:05:13.648: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 19:05:13.661: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
Feb  6 19:05:13.661: INFO: ss-0  ip-10-10-2-209.ec2.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:04:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:04:53 +0000 UTC  }]
Feb  6 19:05:13.661: INFO: 
Feb  6 19:05:13.661: INFO: StatefulSet ss has not reached scale 3, at 1
Feb  6 19:05:14.666: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996449936s
Feb  6 19:05:15.670: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992011831s
Feb  6 19:05:16.674: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.988322697s
Feb  6 19:05:17.678: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.984295487s
Feb  6 19:05:18.682: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.980192085s
Feb  6 19:05:19.686: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.976062664s
Feb  6 19:05:20.690: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.971802265s
Feb  6 19:05:21.695: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.967679925s
Feb  6 19:05:22.699: INFO: Verifying statefulset ss doesn't scale past 3 for another 963.420807ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-858
Feb  6 19:05:23.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=statefulset-858 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 19:05:23.930: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb  6 19:05:23.930: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb  6 19:05:23.930: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb  6 19:05:23.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=statefulset-858 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 19:05:24.148: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb  6 19:05:24.148: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb  6 19:05:24.148: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb  6 19:05:24.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=statefulset-858 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 19:05:24.409: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb  6 19:05:24.409: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb  6 19:05:24.409: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb  6 19:05:24.413: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Feb  6 19:05:34.417: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 19:05:34.417: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 19:05:34.417: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb  6 19:05:34.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=statefulset-858 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb  6 19:05:34.649: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb  6 19:05:34.650: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb  6 19:05:34.650: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb  6 19:05:34.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=statefulset-858 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb  6 19:05:34.886: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb  6 19:05:34.886: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb  6 19:05:34.886: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb  6 19:05:34.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=statefulset-858 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb  6 19:05:35.147: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb  6 19:05:35.147: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb  6 19:05:35.147: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb  6 19:05:35.147: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 19:05:35.150: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb  6 19:05:45.157: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 19:05:45.157: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 19:05:45.157: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 19:05:45.168: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
Feb  6 19:05:45.168: INFO: ss-0  ip-10-10-2-209.ec2.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:04:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:04:53 +0000 UTC  }]
Feb  6 19:05:45.168: INFO: ss-1  ip-10-10-3-246.ec2.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:13 +0000 UTC  }]
Feb  6 19:05:45.168: INFO: ss-2  ip-10-10-1-217.ec2.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:13 +0000 UTC  }]
Feb  6 19:05:45.168: INFO: 
Feb  6 19:05:45.168: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  6 19:05:46.173: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
Feb  6 19:05:46.173: INFO: ss-0  ip-10-10-2-209.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:04:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:04:53 +0000 UTC  }]
Feb  6 19:05:46.173: INFO: ss-1  ip-10-10-3-246.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:13 +0000 UTC  }]
Feb  6 19:05:46.173: INFO: ss-2  ip-10-10-1-217.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:13 +0000 UTC  }]
Feb  6 19:05:46.173: INFO: 
Feb  6 19:05:46.173: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  6 19:05:47.177: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
Feb  6 19:05:47.177: INFO: ss-0  ip-10-10-2-209.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:04:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:04:53 +0000 UTC  }]
Feb  6 19:05:47.177: INFO: ss-1  ip-10-10-3-246.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:13 +0000 UTC  }]
Feb  6 19:05:47.177: INFO: 
Feb  6 19:05:47.177: INFO: StatefulSet ss has not reached scale 0, at 2
Feb  6 19:05:48.181: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
Feb  6 19:05:48.181: INFO: ss-0  ip-10-10-2-209.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:04:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:04:53 +0000 UTC  }]
Feb  6 19:05:48.181: INFO: ss-1  ip-10-10-3-246.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:13 +0000 UTC  }]
Feb  6 19:05:48.181: INFO: 
Feb  6 19:05:48.181: INFO: StatefulSet ss has not reached scale 0, at 2
Feb  6 19:05:49.185: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
Feb  6 19:05:49.185: INFO: ss-0  ip-10-10-2-209.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:04:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:04:53 +0000 UTC  }]
Feb  6 19:05:49.185: INFO: ss-1  ip-10-10-3-246.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:13 +0000 UTC  }]
Feb  6 19:05:49.185: INFO: 
Feb  6 19:05:49.185: INFO: StatefulSet ss has not reached scale 0, at 2
Feb  6 19:05:50.189: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
Feb  6 19:05:50.189: INFO: ss-0  ip-10-10-2-209.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:04:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:04:53 +0000 UTC  }]
Feb  6 19:05:50.189: INFO: ss-1  ip-10-10-3-246.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:13 +0000 UTC  }]
Feb  6 19:05:50.189: INFO: 
Feb  6 19:05:50.189: INFO: StatefulSet ss has not reached scale 0, at 2
Feb  6 19:05:51.193: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
Feb  6 19:05:51.193: INFO: ss-0  ip-10-10-2-209.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:04:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:04:53 +0000 UTC  }]
Feb  6 19:05:51.193: INFO: ss-1  ip-10-10-3-246.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 19:05:13 +0000 UTC  }]
Feb  6 19:05:51.193: INFO: 
Feb  6 19:05:51.193: INFO: StatefulSet ss has not reached scale 0, at 2
Feb  6 19:05:52.197: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.972087541s
Feb  6 19:05:53.201: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.96793038s
Feb  6 19:05:54.205: INFO: Verifying statefulset ss doesn't scale past 0 for another 964.005574ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-858
Feb  6 19:05:55.208: INFO: Scaling statefulset ss to 0
Feb  6 19:05:55.217: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb  6 19:05:55.220: INFO: Deleting all statefulset in ns statefulset-858
Feb  6 19:05:55.223: INFO: Scaling statefulset ss to 0
Feb  6 19:05:55.231: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 19:05:55.234: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:05:55.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-858" for this suite.
Feb  6 19:06:01.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:06:01.732: INFO: namespace statefulset-858 deletion completed in 6.478706429s

• [SLOW TEST:68.502 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:06:01.733: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-9216
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Feb  6 19:06:01.887: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:06:24.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9216" for this suite.
Feb  6 19:06:30.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:06:30.634: INFO: namespace crd-publish-openapi-9216 deletion completed in 6.475466799s

• [SLOW TEST:28.901 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:06:30.634: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-multiple-pods-737
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Feb  6 19:06:30.781: INFO: Waiting up to 1m0s for all nodes to be ready
Feb  6 19:07:30.817: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 19:07:30.820: INFO: Starting informer...
STEP: Starting pods...
Feb  6 19:07:31.036: INFO: Pod1 is running on ip-10-10-3-246.ec2.internal. Tainting Node
Feb  6 19:07:33.256: INFO: Pod2 is running on ip-10-10-3-246.ec2.internal. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Feb  6 19:07:44.446: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Feb  6 19:07:59.877: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:07:59.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-737" for this suite.
Feb  6 19:08:05.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:08:06.381: INFO: namespace taint-multiple-pods-737 deletion completed in 6.478527885s

• [SLOW TEST:95.747 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:08:06.381: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2973
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-2973/secret-test-3c100b42-242b-4cca-8211-d8836fb078f5
STEP: Creating a pod to test consume secrets
Feb  6 19:08:06.540: INFO: Waiting up to 5m0s for pod "pod-configmaps-a1eb3868-dd4c-4f99-be2e-8d34675e0d6f" in namespace "secrets-2973" to be "success or failure"
Feb  6 19:08:06.543: INFO: Pod "pod-configmaps-a1eb3868-dd4c-4f99-be2e-8d34675e0d6f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.118817ms
Feb  6 19:08:08.546: INFO: Pod "pod-configmaps-a1eb3868-dd4c-4f99-be2e-8d34675e0d6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006263457s
STEP: Saw pod success
Feb  6 19:08:08.546: INFO: Pod "pod-configmaps-a1eb3868-dd4c-4f99-be2e-8d34675e0d6f" satisfied condition "success or failure"
Feb  6 19:08:08.549: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-configmaps-a1eb3868-dd4c-4f99-be2e-8d34675e0d6f container env-test: <nil>
STEP: delete the pod
Feb  6 19:08:08.580: INFO: Waiting for pod pod-configmaps-a1eb3868-dd4c-4f99-be2e-8d34675e0d6f to disappear
Feb  6 19:08:08.583: INFO: Pod pod-configmaps-a1eb3868-dd4c-4f99-be2e-8d34675e0d6f no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:08:08.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2973" for this suite.
Feb  6 19:08:14.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:08:15.063: INFO: namespace secrets-2973 deletion completed in 6.474489713s

• [SLOW TEST:8.682 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:08:15.063: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5423
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 19:08:15.221: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb  6 19:08:20.225: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  6 19:08:20.225: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb  6 19:08:20.241: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-5423 /apis/apps/v1/namespaces/deployment-5423/deployments/test-cleanup-deployment 87ffa6f3-59ae-43b1-85b6-c03d95935b1a 62427 1 2020-02-06 19:08:20 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004d0af08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Feb  6 19:08:20.244: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:08:20.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5423" for this suite.
Feb  6 19:08:26.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:08:26.735: INFO: namespace deployment-5423 deletion completed in 6.483055241s

• [SLOW TEST:11.672 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:08:26.735: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8818
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 19:08:26.891: INFO: Waiting up to 5m0s for pod "downwardapi-volume-af9fb85a-7b94-45fb-9ce3-338c75863285" in namespace "projected-8818" to be "success or failure"
Feb  6 19:08:26.894: INFO: Pod "downwardapi-volume-af9fb85a-7b94-45fb-9ce3-338c75863285": Phase="Pending", Reason="", readiness=false. Elapsed: 2.688167ms
Feb  6 19:08:28.897: INFO: Pod "downwardapi-volume-af9fb85a-7b94-45fb-9ce3-338c75863285": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006556044s
STEP: Saw pod success
Feb  6 19:08:28.898: INFO: Pod "downwardapi-volume-af9fb85a-7b94-45fb-9ce3-338c75863285" satisfied condition "success or failure"
Feb  6 19:08:28.900: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod downwardapi-volume-af9fb85a-7b94-45fb-9ce3-338c75863285 container client-container: <nil>
STEP: delete the pod
Feb  6 19:08:28.919: INFO: Waiting for pod downwardapi-volume-af9fb85a-7b94-45fb-9ce3-338c75863285 to disappear
Feb  6 19:08:28.923: INFO: Pod downwardapi-volume-af9fb85a-7b94-45fb-9ce3-338c75863285 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:08:28.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8818" for this suite.
Feb  6 19:08:34.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:08:35.403: INFO: namespace projected-8818 deletion completed in 6.474986768s

• [SLOW TEST:8.668 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:08:35.403: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-663
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-663.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-663.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-663.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-663.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-663.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-663.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  6 19:08:39.610: INFO: DNS probes using dns-663/dns-test-45f864c2-c521-4446-99fa-fffc5afee1e1 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:08:39.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-663" for this suite.
Feb  6 19:08:45.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:08:46.142: INFO: namespace dns-663 deletion completed in 6.48005106s

• [SLOW TEST:10.738 seconds]
[sig-network] DNS
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:08:46.142: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2216
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 19:08:47.338: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb  6 19:08:49.348: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716612927, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716612927, loc:(*time.Location)(0x788a6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716612927, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716612927, loc:(*time.Location)(0x788a6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 19:08:52.365: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Feb  6 19:08:52.383: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:08:52.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2216" for this suite.
Feb  6 19:08:58.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:08:58.877: INFO: namespace webhook-2216 deletion completed in 6.475766344s
STEP: Destroying namespace "webhook-2216-markers" for this suite.
Feb  6 19:09:04.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:09:05.353: INFO: namespace webhook-2216-markers deletion completed in 6.475952289s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.227 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:09:05.369: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3247
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-7d446f6a-4048-4de7-a7b6-b389a73b2417
STEP: Creating a pod to test consume secrets
Feb  6 19:09:05.526: INFO: Waiting up to 5m0s for pod "pod-secrets-9f94934c-8933-450a-9a06-efcdf806af5f" in namespace "secrets-3247" to be "success or failure"
Feb  6 19:09:05.530: INFO: Pod "pod-secrets-9f94934c-8933-450a-9a06-efcdf806af5f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.18406ms
Feb  6 19:09:07.533: INFO: Pod "pod-secrets-9f94934c-8933-450a-9a06-efcdf806af5f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006996558s
STEP: Saw pod success
Feb  6 19:09:07.533: INFO: Pod "pod-secrets-9f94934c-8933-450a-9a06-efcdf806af5f" satisfied condition "success or failure"
Feb  6 19:09:07.536: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-secrets-9f94934c-8933-450a-9a06-efcdf806af5f container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 19:09:07.555: INFO: Waiting for pod pod-secrets-9f94934c-8933-450a-9a06-efcdf806af5f to disappear
Feb  6 19:09:07.560: INFO: Pod pod-secrets-9f94934c-8933-450a-9a06-efcdf806af5f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:09:07.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3247" for this suite.
Feb  6 19:09:13.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:09:14.040: INFO: namespace secrets-3247 deletion completed in 6.4736563s

• [SLOW TEST:8.670 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:09:14.040: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3086
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Feb  6 19:09:14.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 cluster-info'
Feb  6 19:09:14.305: INFO: stderr: ""
Feb  6 19:09:14.305: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:09:14.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3086" for this suite.
Feb  6 19:09:20.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:09:20.788: INFO: namespace kubectl-3086 deletion completed in 6.475759946s

• [SLOW TEST:6.748 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:09:20.788: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8097
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb  6 19:09:20.964: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:09:20.964: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:09:20.964: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:09:20.966: INFO: Number of nodes with available pods: 0
Feb  6 19:09:20.966: INFO: Node ip-10-10-1-217.ec2.internal is running more than one daemon pod
Feb  6 19:09:21.973: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:09:21.973: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:09:21.973: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:09:21.977: INFO: Number of nodes with available pods: 0
Feb  6 19:09:21.977: INFO: Node ip-10-10-1-217.ec2.internal is running more than one daemon pod
Feb  6 19:09:22.972: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:09:22.972: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:09:22.972: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:09:22.975: INFO: Number of nodes with available pods: 3
Feb  6 19:09:22.975: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb  6 19:09:22.992: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:09:22.992: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:09:22.992: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:09:22.997: INFO: Number of nodes with available pods: 3
Feb  6 19:09:22.997: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8097, will wait for the garbage collector to delete the pods
Feb  6 19:09:24.075: INFO: Deleting DaemonSet.extensions daemon-set took: 7.539292ms
Feb  6 19:09:24.776: INFO: Terminating DaemonSet.extensions daemon-set pods took: 700.214185ms
Feb  6 19:09:31.479: INFO: Number of nodes with available pods: 0
Feb  6 19:09:31.479: INFO: Number of running nodes: 0, number of available pods: 0
Feb  6 19:09:31.483: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8097/daemonsets","resourceVersion":"63003"},"items":null}

Feb  6 19:09:31.486: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8097/pods","resourceVersion":"63003"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:09:31.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8097" for this suite.
Feb  6 19:09:37.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:09:37.990: INFO: namespace daemonsets-8097 deletion completed in 6.474555158s

• [SLOW TEST:17.202 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:09:37.990: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7218
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Feb  6 19:09:38.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 create -f - --namespace=kubectl-7218'
Feb  6 19:09:38.383: INFO: stderr: ""
Feb  6 19:09:38.383: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 19:09:38.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7218'
Feb  6 19:09:38.477: INFO: stderr: ""
Feb  6 19:09:38.477: INFO: stdout: "update-demo-nautilus-mszwh update-demo-nautilus-qskqd "
Feb  6 19:09:38.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-nautilus-mszwh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7218'
Feb  6 19:09:38.552: INFO: stderr: ""
Feb  6 19:09:38.552: INFO: stdout: ""
Feb  6 19:09:38.552: INFO: update-demo-nautilus-mszwh is created but not running
Feb  6 19:09:43.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7218'
Feb  6 19:09:43.632: INFO: stderr: ""
Feb  6 19:09:43.632: INFO: stdout: "update-demo-nautilus-mszwh update-demo-nautilus-qskqd "
Feb  6 19:09:43.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-nautilus-mszwh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7218'
Feb  6 19:09:43.708: INFO: stderr: ""
Feb  6 19:09:43.708: INFO: stdout: "true"
Feb  6 19:09:43.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-nautilus-mszwh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7218'
Feb  6 19:09:43.783: INFO: stderr: ""
Feb  6 19:09:43.783: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 19:09:43.783: INFO: validating pod update-demo-nautilus-mszwh
Feb  6 19:09:43.788: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 19:09:43.788: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 19:09:43.788: INFO: update-demo-nautilus-mszwh is verified up and running
Feb  6 19:09:43.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-nautilus-qskqd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7218'
Feb  6 19:09:43.864: INFO: stderr: ""
Feb  6 19:09:43.864: INFO: stdout: "true"
Feb  6 19:09:43.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-nautilus-qskqd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7218'
Feb  6 19:09:43.940: INFO: stderr: ""
Feb  6 19:09:43.940: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 19:09:43.940: INFO: validating pod update-demo-nautilus-qskqd
Feb  6 19:09:43.945: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 19:09:43.945: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 19:09:43.945: INFO: update-demo-nautilus-qskqd is verified up and running
STEP: rolling-update to new replication controller
Feb  6 19:09:43.947: INFO: scanned /root for discovery docs: <nil>
Feb  6 19:09:43.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-7218'
Feb  6 19:10:06.476: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb  6 19:10:06.476: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 19:10:06.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7218'
Feb  6 19:10:06.570: INFO: stderr: ""
Feb  6 19:10:06.570: INFO: stdout: "update-demo-kitten-hfgjp update-demo-kitten-nsldn "
Feb  6 19:10:06.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-kitten-hfgjp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7218'
Feb  6 19:10:06.647: INFO: stderr: ""
Feb  6 19:10:06.647: INFO: stdout: "true"
Feb  6 19:10:06.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-kitten-hfgjp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7218'
Feb  6 19:10:06.722: INFO: stderr: ""
Feb  6 19:10:06.722: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb  6 19:10:06.722: INFO: validating pod update-demo-kitten-hfgjp
Feb  6 19:10:06.727: INFO: got data: {
  "image": "kitten.jpg"
}

Feb  6 19:10:06.727: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb  6 19:10:06.727: INFO: update-demo-kitten-hfgjp is verified up and running
Feb  6 19:10:06.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-kitten-nsldn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7218'
Feb  6 19:10:06.806: INFO: stderr: ""
Feb  6 19:10:06.806: INFO: stdout: "true"
Feb  6 19:10:06.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-kitten-nsldn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7218'
Feb  6 19:10:06.880: INFO: stderr: ""
Feb  6 19:10:06.880: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb  6 19:10:06.880: INFO: validating pod update-demo-kitten-nsldn
Feb  6 19:10:06.884: INFO: got data: {
  "image": "kitten.jpg"
}

Feb  6 19:10:06.884: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb  6 19:10:06.884: INFO: update-demo-kitten-nsldn is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:10:06.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7218" for this suite.
Feb  6 19:10:36.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:10:37.367: INFO: namespace kubectl-7218 deletion completed in 30.476068466s

• [SLOW TEST:59.377 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:10:37.368: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9761
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-9761
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  6 19:10:37.514: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  6 19:10:51.606: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.162.2 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9761 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 19:10:51.606: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 19:10:52.731: INFO: Found all expected endpoints: [netserver-0]
Feb  6 19:10:52.734: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.3.23 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9761 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 19:10:52.734: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 19:10:53.894: INFO: Found all expected endpoints: [netserver-1]
Feb  6 19:10:53.897: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.126.31 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9761 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 19:10:53.897: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 19:10:55.044: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:10:55.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9761" for this suite.
Feb  6 19:11:07.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:11:07.524: INFO: namespace pod-network-test-9761 deletion completed in 12.474933987s

• [SLOW TEST:30.156 seconds]
[sig-network] Networking
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:11:07.524: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5826
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb  6 19:11:10.220: INFO: Successfully updated pod "annotationupdate13f8f143-f2f7-4726-a159-c27e6e3511da"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:11:12.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5826" for this suite.
Feb  6 19:11:24.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:11:24.716: INFO: namespace downward-api-5826 deletion completed in 12.475694664s

• [SLOW TEST:17.192 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:11:24.716: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1608
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1608
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Feb  6 19:11:24.882: INFO: Found 0 stateful pods, waiting for 3
Feb  6 19:11:34.886: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 19:11:34.886: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 19:11:34.886: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Feb  6 19:11:34.913: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb  6 19:11:44.947: INFO: Updating stateful set ss2
Feb  6 19:11:44.958: INFO: Waiting for Pod statefulset-1608/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Feb  6 19:11:54.998: INFO: Found 1 stateful pods, waiting for 3
Feb  6 19:12:05.003: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 19:12:05.003: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 19:12:05.003: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb  6 19:12:05.028: INFO: Updating stateful set ss2
Feb  6 19:12:05.036: INFO: Waiting for Pod statefulset-1608/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb  6 19:12:15.062: INFO: Updating stateful set ss2
Feb  6 19:12:15.068: INFO: Waiting for StatefulSet statefulset-1608/ss2 to complete update
Feb  6 19:12:15.068: INFO: Waiting for Pod statefulset-1608/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb  6 19:12:25.079: INFO: Deleting all statefulset in ns statefulset-1608
Feb  6 19:12:25.082: INFO: Scaling statefulset ss2 to 0
Feb  6 19:12:45.098: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 19:12:45.101: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:12:45.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1608" for this suite.
Feb  6 19:12:53.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:12:53.598: INFO: namespace statefulset-1608 deletion completed in 8.47820265s

• [SLOW TEST:88.882 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:12:53.599: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2616
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 19:12:53.746: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:12:55.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2616" for this suite.
Feb  6 19:13:41.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:13:42.264: INFO: namespace pods-2616 deletion completed in 46.47600281s

• [SLOW TEST:48.665 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:13:42.264: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3552
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 19:13:42.424: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cd1614f4-eac1-43ae-8d6b-0be5bee45bba" in namespace "projected-3552" to be "success or failure"
Feb  6 19:13:42.428: INFO: Pod "downwardapi-volume-cd1614f4-eac1-43ae-8d6b-0be5bee45bba": Phase="Pending", Reason="", readiness=false. Elapsed: 3.434076ms
Feb  6 19:13:44.432: INFO: Pod "downwardapi-volume-cd1614f4-eac1-43ae-8d6b-0be5bee45bba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007405311s
STEP: Saw pod success
Feb  6 19:13:44.432: INFO: Pod "downwardapi-volume-cd1614f4-eac1-43ae-8d6b-0be5bee45bba" satisfied condition "success or failure"
Feb  6 19:13:44.434: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod downwardapi-volume-cd1614f4-eac1-43ae-8d6b-0be5bee45bba container client-container: <nil>
STEP: delete the pod
Feb  6 19:13:44.460: INFO: Waiting for pod downwardapi-volume-cd1614f4-eac1-43ae-8d6b-0be5bee45bba to disappear
Feb  6 19:13:44.464: INFO: Pod downwardapi-volume-cd1614f4-eac1-43ae-8d6b-0be5bee45bba no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:13:44.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3552" for this suite.
Feb  6 19:13:50.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:13:50.947: INFO: namespace projected-3552 deletion completed in 6.476784775s

• [SLOW TEST:8.683 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:13:50.947: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-6693
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 19:13:51.113: INFO: Creating ReplicaSet my-hostname-basic-e3399c93-9fa9-4370-8e09-e0a3909e0f70
Feb  6 19:13:51.123: INFO: Pod name my-hostname-basic-e3399c93-9fa9-4370-8e09-e0a3909e0f70: Found 0 pods out of 1
Feb  6 19:13:56.127: INFO: Pod name my-hostname-basic-e3399c93-9fa9-4370-8e09-e0a3909e0f70: Found 1 pods out of 1
Feb  6 19:13:56.127: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-e3399c93-9fa9-4370-8e09-e0a3909e0f70" is running
Feb  6 19:13:56.132: INFO: Pod "my-hostname-basic-e3399c93-9fa9-4370-8e09-e0a3909e0f70-6dv2g" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-06 19:13:51 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-06 19:13:52 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-06 19:13:52 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-06 19:13:51 +0000 UTC Reason: Message:}])
Feb  6 19:13:56.132: INFO: Trying to dial the pod
Feb  6 19:14:01.144: INFO: Controller my-hostname-basic-e3399c93-9fa9-4370-8e09-e0a3909e0f70: Got expected result from replica 1 [my-hostname-basic-e3399c93-9fa9-4370-8e09-e0a3909e0f70-6dv2g]: "my-hostname-basic-e3399c93-9fa9-4370-8e09-e0a3909e0f70-6dv2g", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:14:01.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6693" for this suite.
Feb  6 19:14:07.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:14:07.627: INFO: namespace replicaset-6693 deletion completed in 6.478058549s

• [SLOW TEST:16.681 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:14:07.627: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1714
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb  6 19:14:07.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-1714'
Feb  6 19:14:07.863: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  6 19:14:07.863: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Feb  6 19:14:09.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 delete deployment e2e-test-httpd-deployment --namespace=kubectl-1714'
Feb  6 19:14:09.964: INFO: stderr: ""
Feb  6 19:14:09.964: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:14:09.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1714" for this suite.
Feb  6 19:14:37.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:14:38.445: INFO: namespace kubectl-1714 deletion completed in 28.475782904s

• [SLOW TEST:30.818 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:14:38.445: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-7125
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-7125
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-7125
STEP: Creating statefulset with conflicting port in namespace statefulset-7125
STEP: Waiting until pod test-pod will start running in namespace statefulset-7125
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-7125
Feb  6 19:14:42.626: INFO: Observed stateful pod in namespace: statefulset-7125, name: ss-0, uid: dd92f05e-bd92-4eb7-88b8-cc8a61acc8a9, status phase: Pending. Waiting for statefulset controller to delete.
Feb  6 19:14:42.646: INFO: Observed stateful pod in namespace: statefulset-7125, name: ss-0, uid: dd92f05e-bd92-4eb7-88b8-cc8a61acc8a9, status phase: Failed. Waiting for statefulset controller to delete.
Feb  6 19:14:42.658: INFO: Observed stateful pod in namespace: statefulset-7125, name: ss-0, uid: dd92f05e-bd92-4eb7-88b8-cc8a61acc8a9, status phase: Failed. Waiting for statefulset controller to delete.
Feb  6 19:14:42.667: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-7125
STEP: Removing pod with conflicting port in namespace statefulset-7125
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-7125 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb  6 19:14:46.698: INFO: Deleting all statefulset in ns statefulset-7125
Feb  6 19:14:46.701: INFO: Scaling statefulset ss to 0
Feb  6 19:14:56.714: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 19:14:56.717: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:14:56.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7125" for this suite.
Feb  6 19:15:04.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:15:05.210: INFO: namespace statefulset-7125 deletion completed in 8.475285884s

• [SLOW TEST:26.765 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:15:05.210: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-511
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:15:05.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-511" for this suite.
Feb  6 19:15:11.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:15:11.842: INFO: namespace services-511 deletion completed in 6.47622727s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.632 seconds]
[sig-network] Services
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:15:11.843: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3724
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:15:14.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3724" for this suite.
Feb  6 19:16:02.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:16:02.705: INFO: namespace kubelet-test-3724 deletion completed in 48.57220044s

• [SLOW TEST:50.862 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:16:02.705: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2122
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 19:16:02.882: INFO: (0) /api/v1/nodes/ip-10-10-1-217.ec2.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 19.082548ms)
Feb  6 19:16:02.887: INFO: (1) /api/v1/nodes/ip-10-10-1-217.ec2.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.337054ms)
Feb  6 19:16:02.892: INFO: (2) /api/v1/nodes/ip-10-10-1-217.ec2.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.622345ms)
Feb  6 19:16:02.897: INFO: (3) /api/v1/nodes/ip-10-10-1-217.ec2.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.463515ms)
Feb  6 19:16:02.902: INFO: (4) /api/v1/nodes/ip-10-10-1-217.ec2.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.258055ms)
Feb  6 19:16:02.908: INFO: (5) /api/v1/nodes/ip-10-10-1-217.ec2.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.96533ms)
Feb  6 19:16:02.912: INFO: (6) /api/v1/nodes/ip-10-10-1-217.ec2.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.543054ms)
Feb  6 19:16:02.916: INFO: (7) /api/v1/nodes/ip-10-10-1-217.ec2.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.079301ms)
Feb  6 19:16:02.922: INFO: (8) /api/v1/nodes/ip-10-10-1-217.ec2.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.313212ms)
Feb  6 19:16:02.926: INFO: (9) /api/v1/nodes/ip-10-10-1-217.ec2.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.134808ms)
Feb  6 19:16:02.930: INFO: (10) /api/v1/nodes/ip-10-10-1-217.ec2.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.148974ms)
Feb  6 19:16:02.934: INFO: (11) /api/v1/nodes/ip-10-10-1-217.ec2.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.182735ms)
Feb  6 19:16:02.938: INFO: (12) /api/v1/nodes/ip-10-10-1-217.ec2.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.085507ms)
Feb  6 19:16:02.943: INFO: (13) /api/v1/nodes/ip-10-10-1-217.ec2.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.218838ms)
Feb  6 19:16:02.947: INFO: (14) /api/v1/nodes/ip-10-10-1-217.ec2.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.195133ms)
Feb  6 19:16:02.951: INFO: (15) /api/v1/nodes/ip-10-10-1-217.ec2.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.394736ms)
Feb  6 19:16:02.955: INFO: (16) /api/v1/nodes/ip-10-10-1-217.ec2.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.073547ms)
Feb  6 19:16:02.959: INFO: (17) /api/v1/nodes/ip-10-10-1-217.ec2.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.077937ms)
Feb  6 19:16:02.964: INFO: (18) /api/v1/nodes/ip-10-10-1-217.ec2.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.463218ms)
Feb  6 19:16:02.969: INFO: (19) /api/v1/nodes/ip-10-10-1-217.ec2.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.333375ms)
[AfterEach] version v1
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:16:02.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2122" for this suite.
Feb  6 19:16:08.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:16:09.169: INFO: namespace proxy-2122 deletion completed in 6.195815941s

• [SLOW TEST:6.464 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:16:09.170: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7122
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Feb  6 19:16:09.319: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 19:16:13.156: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:16:29.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7122" for this suite.
Feb  6 19:16:35.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:16:35.600: INFO: namespace crd-publish-openapi-7122 deletion completed in 6.475046527s

• [SLOW TEST:26.431 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:16:35.600: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6728
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb  6 19:16:35.758: INFO: Waiting up to 5m0s for pod "downward-api-36905b13-edb0-460f-8c19-6eed8f2635a4" in namespace "downward-api-6728" to be "success or failure"
Feb  6 19:16:35.761: INFO: Pod "downward-api-36905b13-edb0-460f-8c19-6eed8f2635a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.909764ms
Feb  6 19:16:37.765: INFO: Pod "downward-api-36905b13-edb0-460f-8c19-6eed8f2635a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006496009s
STEP: Saw pod success
Feb  6 19:16:37.765: INFO: Pod "downward-api-36905b13-edb0-460f-8c19-6eed8f2635a4" satisfied condition "success or failure"
Feb  6 19:16:37.768: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod downward-api-36905b13-edb0-460f-8c19-6eed8f2635a4 container dapi-container: <nil>
STEP: delete the pod
Feb  6 19:16:37.791: INFO: Waiting for pod downward-api-36905b13-edb0-460f-8c19-6eed8f2635a4 to disappear
Feb  6 19:16:37.794: INFO: Pod downward-api-36905b13-edb0-460f-8c19-6eed8f2635a4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:16:37.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6728" for this suite.
Feb  6 19:16:43.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:16:44.292: INFO: namespace downward-api-6728 deletion completed in 6.494320994s

• [SLOW TEST:8.692 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:16:44.292: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3437
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-0460682d-e596-4e51-b038-bd8500ce5d42
STEP: Creating a pod to test consume configMaps
Feb  6 19:16:44.493: INFO: Waiting up to 5m0s for pod "pod-configmaps-233b8df3-ba53-47c4-aa79-760d98b71144" in namespace "configmap-3437" to be "success or failure"
Feb  6 19:16:44.500: INFO: Pod "pod-configmaps-233b8df3-ba53-47c4-aa79-760d98b71144": Phase="Pending", Reason="", readiness=false. Elapsed: 7.275583ms
Feb  6 19:16:46.504: INFO: Pod "pod-configmaps-233b8df3-ba53-47c4-aa79-760d98b71144": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01134622s
Feb  6 19:16:48.508: INFO: Pod "pod-configmaps-233b8df3-ba53-47c4-aa79-760d98b71144": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015250129s
STEP: Saw pod success
Feb  6 19:16:48.508: INFO: Pod "pod-configmaps-233b8df3-ba53-47c4-aa79-760d98b71144" satisfied condition "success or failure"
Feb  6 19:16:48.511: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-configmaps-233b8df3-ba53-47c4-aa79-760d98b71144 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 19:16:48.534: INFO: Waiting for pod pod-configmaps-233b8df3-ba53-47c4-aa79-760d98b71144 to disappear
Feb  6 19:16:48.537: INFO: Pod pod-configmaps-233b8df3-ba53-47c4-aa79-760d98b71144 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:16:48.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3437" for this suite.
Feb  6 19:16:54.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:16:55.021: INFO: namespace configmap-3437 deletion completed in 6.479354888s

• [SLOW TEST:10.728 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:16:55.021: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1046
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-d79255db-3bf7-4bfd-a628-c3ac371c860c
STEP: Creating a pod to test consume configMaps
Feb  6 19:16:55.182: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1b038a89-16d1-47a8-a171-62b856eb33fa" in namespace "projected-1046" to be "success or failure"
Feb  6 19:16:55.186: INFO: Pod "pod-projected-configmaps-1b038a89-16d1-47a8-a171-62b856eb33fa": Phase="Pending", Reason="", readiness=false. Elapsed: 4.375309ms
Feb  6 19:16:57.190: INFO: Pod "pod-projected-configmaps-1b038a89-16d1-47a8-a171-62b856eb33fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008291719s
STEP: Saw pod success
Feb  6 19:16:57.190: INFO: Pod "pod-projected-configmaps-1b038a89-16d1-47a8-a171-62b856eb33fa" satisfied condition "success or failure"
Feb  6 19:16:57.193: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-projected-configmaps-1b038a89-16d1-47a8-a171-62b856eb33fa container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 19:16:57.212: INFO: Waiting for pod pod-projected-configmaps-1b038a89-16d1-47a8-a171-62b856eb33fa to disappear
Feb  6 19:16:57.216: INFO: Pod pod-projected-configmaps-1b038a89-16d1-47a8-a171-62b856eb33fa no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:16:57.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1046" for this suite.
Feb  6 19:17:03.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:17:03.695: INFO: namespace projected-1046 deletion completed in 6.474515176s

• [SLOW TEST:8.674 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:17:03.695: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6479
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb  6 19:17:11.900: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 19:17:11.909: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 19:17:13.910: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 19:17:13.913: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 19:17:15.910: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 19:17:15.913: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:17:15.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6479" for this suite.
Feb  6 19:17:27.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:17:28.393: INFO: namespace container-lifecycle-hook-6479 deletion completed in 12.475483341s

• [SLOW TEST:24.698 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:17:28.394: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4844
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-4844/configmap-test-fc6ec3a1-9c62-4de4-8e9a-c2f7402c582d
STEP: Creating a pod to test consume configMaps
Feb  6 19:17:28.553: INFO: Waiting up to 5m0s for pod "pod-configmaps-5ececf17-7529-41c1-bb2d-8eafb85e178b" in namespace "configmap-4844" to be "success or failure"
Feb  6 19:17:28.556: INFO: Pod "pod-configmaps-5ececf17-7529-41c1-bb2d-8eafb85e178b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.856876ms
Feb  6 19:17:30.561: INFO: Pod "pod-configmaps-5ececf17-7529-41c1-bb2d-8eafb85e178b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007898284s
STEP: Saw pod success
Feb  6 19:17:30.561: INFO: Pod "pod-configmaps-5ececf17-7529-41c1-bb2d-8eafb85e178b" satisfied condition "success or failure"
Feb  6 19:17:30.564: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-configmaps-5ececf17-7529-41c1-bb2d-8eafb85e178b container env-test: <nil>
STEP: delete the pod
Feb  6 19:17:30.586: INFO: Waiting for pod pod-configmaps-5ececf17-7529-41c1-bb2d-8eafb85e178b to disappear
Feb  6 19:17:30.589: INFO: Pod pod-configmaps-5ececf17-7529-41c1-bb2d-8eafb85e178b no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:17:30.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4844" for this suite.
Feb  6 19:17:36.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:17:37.076: INFO: namespace configmap-4844 deletion completed in 6.47958187s

• [SLOW TEST:8.683 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:17:37.076: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3431
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 19:17:37.670: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb  6 19:17:39.682: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716613457, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716613457, loc:(*time.Location)(0x788a6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716613457, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716613457, loc:(*time.Location)(0x788a6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 19:17:42.700: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 19:17:42.703: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7794-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:17:43.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3431" for this suite.
Feb  6 19:17:51.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:17:52.276: INFO: namespace webhook-3431 deletion completed in 8.478950287s
STEP: Destroying namespace "webhook-3431-markers" for this suite.
Feb  6 19:17:58.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:17:58.752: INFO: namespace webhook-3431-markers deletion completed in 6.476667113s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.691 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:17:58.767: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2686
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb  6 19:17:58.917: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:18:02.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2686" for this suite.
Feb  6 19:18:10.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:18:10.555: INFO: namespace init-container-2686 deletion completed in 8.475045053s

• [SLOW TEST:11.788 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:18:10.555: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4297
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb  6 19:18:10.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-4297'
Feb  6 19:18:10.933: INFO: stderr: ""
Feb  6 19:18:10.933: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Feb  6 19:18:10.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 delete pods e2e-test-httpd-pod --namespace=kubectl-4297'
Feb  6 19:18:21.378: INFO: stderr: ""
Feb  6 19:18:21.378: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:18:21.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4297" for this suite.
Feb  6 19:18:27.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:18:27.860: INFO: namespace kubectl-4297 deletion completed in 6.475423557s

• [SLOW TEST:17.304 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:18:27.860: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7296
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Feb  6 19:18:28.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-7296 -- logs-generator --log-lines-total 100 --run-duration 20s'
Feb  6 19:18:28.091: INFO: stderr: ""
Feb  6 19:18:28.091: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Feb  6 19:18:28.091: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Feb  6 19:18:28.091: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-7296" to be "running and ready, or succeeded"
Feb  6 19:18:28.097: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 5.712388ms
Feb  6 19:18:30.101: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.010346238s
Feb  6 19:18:30.101: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Feb  6 19:18:30.101: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Feb  6 19:18:30.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 logs logs-generator logs-generator --namespace=kubectl-7296'
Feb  6 19:18:30.209: INFO: stderr: ""
Feb  6 19:18:30.209: INFO: stdout: "I0206 19:18:29.023498       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/mjv7 492\nI0206 19:18:29.223615       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/hrp 273\nI0206 19:18:29.423620       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/djms 487\nI0206 19:18:29.623628       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/5n4 557\nI0206 19:18:29.823687       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/5kt 395\nI0206 19:18:30.023640       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/z64 286\n"
STEP: limiting log lines
Feb  6 19:18:30.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 logs logs-generator logs-generator --namespace=kubectl-7296 --tail=1'
Feb  6 19:18:30.298: INFO: stderr: ""
Feb  6 19:18:30.298: INFO: stdout: "I0206 19:18:30.223648       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/2vmr 383\n"
STEP: limiting log bytes
Feb  6 19:18:30.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 logs logs-generator logs-generator --namespace=kubectl-7296 --limit-bytes=1'
Feb  6 19:18:30.403: INFO: stderr: ""
Feb  6 19:18:30.403: INFO: stdout: "I"
STEP: exposing timestamps
Feb  6 19:18:30.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 logs logs-generator logs-generator --namespace=kubectl-7296 --tail=1 --timestamps'
Feb  6 19:18:30.497: INFO: stderr: ""
Feb  6 19:18:30.497: INFO: stdout: "2020-02-06T19:18:30.423765582Z I0206 19:18:30.423591       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/zjfg 524\n"
STEP: restricting to a time range
Feb  6 19:18:32.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 logs logs-generator logs-generator --namespace=kubectl-7296 --since=1s'
Feb  6 19:18:33.089: INFO: stderr: ""
Feb  6 19:18:33.089: INFO: stdout: "I0206 19:18:32.223641       1 logs_generator.go:76] 16 GET /api/v1/namespaces/kube-system/pods/ft8 599\nI0206 19:18:32.423627       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/ns/pods/7qp 555\nI0206 19:18:32.623626       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/default/pods/8gr 418\nI0206 19:18:32.823634       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/hxn 408\nI0206 19:18:33.024476       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/lh9 576\n"
Feb  6 19:18:33.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 logs logs-generator logs-generator --namespace=kubectl-7296 --since=24h'
Feb  6 19:18:33.181: INFO: stderr: ""
Feb  6 19:18:33.181: INFO: stdout: "I0206 19:18:29.023498       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/mjv7 492\nI0206 19:18:29.223615       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/hrp 273\nI0206 19:18:29.423620       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/djms 487\nI0206 19:18:29.623628       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/5n4 557\nI0206 19:18:29.823687       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/5kt 395\nI0206 19:18:30.023640       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/z64 286\nI0206 19:18:30.223648       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/2vmr 383\nI0206 19:18:30.423591       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/zjfg 524\nI0206 19:18:30.623608       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/xz6 567\nI0206 19:18:30.823678       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/j9w 420\nI0206 19:18:31.023623       1 logs_generator.go:76] 10 POST /api/v1/namespaces/default/pods/qnn 316\nI0206 19:18:31.223688       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/fzx8 451\nI0206 19:18:31.424461       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/default/pods/jpv 298\nI0206 19:18:31.623738       1 logs_generator.go:76] 13 POST /api/v1/namespaces/default/pods/k9mp 272\nI0206 19:18:31.823694       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/ns/pods/z2d 358\nI0206 19:18:32.023634       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/tdj 328\nI0206 19:18:32.223641       1 logs_generator.go:76] 16 GET /api/v1/namespaces/kube-system/pods/ft8 599\nI0206 19:18:32.423627       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/ns/pods/7qp 555\nI0206 19:18:32.623626       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/default/pods/8gr 418\nI0206 19:18:32.823634       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/hxn 408\nI0206 19:18:33.024476       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/lh9 576\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Feb  6 19:18:33.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 delete pod logs-generator --namespace=kubectl-7296'
Feb  6 19:18:35.419: INFO: stderr: ""
Feb  6 19:18:35.419: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:18:35.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7296" for this suite.
Feb  6 19:18:41.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:18:41.899: INFO: namespace kubectl-7296 deletion completed in 6.475221168s

• [SLOW TEST:14.039 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:18:41.899: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7143
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 19:18:42.429: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Feb  6 19:18:44.439: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716613522, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716613522, loc:(*time.Location)(0x788a6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716613522, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716613522, loc:(*time.Location)(0x788a6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 19:18:47.457: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:18:47.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7143" for this suite.
Feb  6 19:18:53.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:18:54.004: INFO: namespace webhook-7143 deletion completed in 6.47291863s
STEP: Destroying namespace "webhook-7143-markers" for this suite.
Feb  6 19:19:00.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:19:00.482: INFO: namespace webhook-7143-markers deletion completed in 6.477613313s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.598 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:19:00.497: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-734
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Feb  6 19:19:00.663: INFO: Waiting up to 5m0s for pod "var-expansion-63fd1afc-61d3-451d-bb50-9ff5cdd8a62a" in namespace "var-expansion-734" to be "success or failure"
Feb  6 19:19:00.666: INFO: Pod "var-expansion-63fd1afc-61d3-451d-bb50-9ff5cdd8a62a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.217379ms
Feb  6 19:19:02.669: INFO: Pod "var-expansion-63fd1afc-61d3-451d-bb50-9ff5cdd8a62a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006836439s
Feb  6 19:19:04.673: INFO: Pod "var-expansion-63fd1afc-61d3-451d-bb50-9ff5cdd8a62a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010783822s
STEP: Saw pod success
Feb  6 19:19:04.673: INFO: Pod "var-expansion-63fd1afc-61d3-451d-bb50-9ff5cdd8a62a" satisfied condition "success or failure"
Feb  6 19:19:04.676: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod var-expansion-63fd1afc-61d3-451d-bb50-9ff5cdd8a62a container dapi-container: <nil>
STEP: delete the pod
Feb  6 19:19:04.700: INFO: Waiting for pod var-expansion-63fd1afc-61d3-451d-bb50-9ff5cdd8a62a to disappear
Feb  6 19:19:04.704: INFO: Pod var-expansion-63fd1afc-61d3-451d-bb50-9ff5cdd8a62a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:19:04.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-734" for this suite.
Feb  6 19:19:10.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:19:11.187: INFO: namespace var-expansion-734 deletion completed in 6.478543554s

• [SLOW TEST:10.689 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:19:11.187: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2401
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb  6 19:19:11.346: INFO: Waiting up to 5m0s for pod "pod-a34b5adf-6d2f-44e0-b661-9fe898e6fb12" in namespace "emptydir-2401" to be "success or failure"
Feb  6 19:19:11.349: INFO: Pod "pod-a34b5adf-6d2f-44e0-b661-9fe898e6fb12": Phase="Pending", Reason="", readiness=false. Elapsed: 2.994063ms
Feb  6 19:19:13.353: INFO: Pod "pod-a34b5adf-6d2f-44e0-b661-9fe898e6fb12": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007545672s
STEP: Saw pod success
Feb  6 19:19:13.353: INFO: Pod "pod-a34b5adf-6d2f-44e0-b661-9fe898e6fb12" satisfied condition "success or failure"
Feb  6 19:19:13.356: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-a34b5adf-6d2f-44e0-b661-9fe898e6fb12 container test-container: <nil>
STEP: delete the pod
Feb  6 19:19:13.383: INFO: Waiting for pod pod-a34b5adf-6d2f-44e0-b661-9fe898e6fb12 to disappear
Feb  6 19:19:13.386: INFO: Pod pod-a34b5adf-6d2f-44e0-b661-9fe898e6fb12 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:19:13.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2401" for this suite.
Feb  6 19:19:19.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:19:19.867: INFO: namespace emptydir-2401 deletion completed in 6.47711232s

• [SLOW TEST:8.681 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:19:19.868: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1064
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 19:19:21.019: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb  6 19:19:23.036: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716613561, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716613561, loc:(*time.Location)(0x788a6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716613561, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716613561, loc:(*time.Location)(0x788a6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 19:19:26.054: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 19:19:26.058: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:19:27.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1064" for this suite.
Feb  6 19:19:33.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:19:33.961: INFO: namespace webhook-1064 deletion completed in 6.656786573s
STEP: Destroying namespace "webhook-1064-markers" for this suite.
Feb  6 19:19:39.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:19:40.444: INFO: namespace webhook-1064-markers deletion completed in 6.483048841s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:20.592 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:19:40.459: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4805
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-5c55f313-9483-41f1-b957-a6a33e31a9a9 in namespace container-probe-4805
Feb  6 19:19:42.625: INFO: Started pod liveness-5c55f313-9483-41f1-b957-a6a33e31a9a9 in namespace container-probe-4805
STEP: checking the pod's current state and verifying that restartCount is present
Feb  6 19:19:42.628: INFO: Initial restart count of pod liveness-5c55f313-9483-41f1-b957-a6a33e31a9a9 is 0
Feb  6 19:20:00.668: INFO: Restart count of pod container-probe-4805/liveness-5c55f313-9483-41f1-b957-a6a33e31a9a9 is now 1 (18.03956462s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:20:00.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4805" for this suite.
Feb  6 19:20:06.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:20:07.168: INFO: namespace container-probe-4805 deletion completed in 6.477093471s

• [SLOW TEST:26.708 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:20:07.168: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7739
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb  6 19:20:07.320: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  6 19:20:07.334: INFO: Waiting for terminating namespaces to be deleted...
Feb  6 19:20:07.337: INFO: 
Logging pods the kubelet thinks is on node ip-10-10-1-217.ec2.internal before test
Feb  6 19:20:07.358: INFO: calico-node-hrxsw from kube-system started at 2020-02-06 15:57:54 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.358: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 19:20:07.358: INFO: sonobuoy-systemd-logs-daemon-set-936a433795204ed3-lmxgr from sonobuoy started at 2020-02-06 18:40:06 +0000 UTC (2 container statuses recorded)
Feb  6 19:20:07.358: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 19:20:07.358: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 19:20:07.358: INFO: md-cert-manager-669497f667-mb9js from md-cert-manager started at 2020-02-06 18:11:31 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.358: INFO: 	Container cert-manager ready: true, restart count 0
Feb  6 19:20:07.358: INFO: md-loki-stack-promtail-mmws9 from md-loki-stack started at 2020-02-06 18:12:01 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.358: INFO: 	Container promtail ready: true, restart count 0
Feb  6 19:20:07.358: INFO: md-nginx-ingress-controller-5cff997b69-9qwpx from md-nginx-ingress started at 2020-02-06 18:12:09 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.358: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb  6 19:20:07.358: INFO: md-flux-6d54668955-bl6sl from md-flux started at 2020-02-06 18:11:25 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.358: INFO: 	Container flux ready: true, restart count 0
Feb  6 19:20:07.358: INFO: md-cert-manager-cainjector-7758b57b8d-4j8jj from md-cert-manager started at 2020-02-06 18:11:31 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.358: INFO: 	Container cert-manager ready: true, restart count 0
Feb  6 19:20:07.358: INFO: md-prometheus-operator-prometheus-node-exporter-mxlfh from md-prometheus-operator started at 2020-02-06 18:12:39 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.358: INFO: 	Container node-exporter ready: true, restart count 0
Feb  6 19:20:07.358: INFO: alertmanager-md-prometheus-operator-alertmanager-0 from md-prometheus-operator started at 2020-02-06 19:07:45 +0000 UTC (2 container statuses recorded)
Feb  6 19:20:07.358: INFO: 	Container alertmanager ready: true, restart count 0
Feb  6 19:20:07.358: INFO: 	Container config-reloader ready: true, restart count 0
Feb  6 19:20:07.358: INFO: loki-6877765b9c-2n9vf from md-loki-stack started at 2020-02-06 18:12:01 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.358: INFO: 	Container loki ready: true, restart count 0
Feb  6 19:20:07.358: INFO: prometheus-md-prometheus-operator-prometheus-0 from md-prometheus-operator started at 2020-02-06 18:12:58 +0000 UTC (3 container statuses recorded)
Feb  6 19:20:07.358: INFO: 	Container prometheus ready: true, restart count 1
Feb  6 19:20:07.358: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Feb  6 19:20:07.358: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Feb  6 19:20:07.358: INFO: kube-proxy-dj7kw from kube-system started at 2020-02-06 15:57:54 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.358: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  6 19:20:07.358: INFO: md-prometheus-operator-operator-f975b4dd9-rw84h from md-prometheus-operator started at 2020-02-06 18:12:39 +0000 UTC (2 container statuses recorded)
Feb  6 19:20:07.358: INFO: 	Container prometheus-operator ready: true, restart count 0
Feb  6 19:20:07.358: INFO: 	Container tls-proxy ready: true, restart count 0
Feb  6 19:20:07.358: INFO: 
Logging pods the kubelet thinks is on node ip-10-10-2-209.ec2.internal before test
Feb  6 19:20:07.381: INFO: md-cert-manager-webhook-58b4496d5-lx8m5 from md-cert-manager started at 2020-02-06 19:07:33 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.381: INFO: 	Container cert-manager ready: true, restart count 0
Feb  6 19:20:07.381: INFO: cm-acme-http-solver-nnxf2 from md-prometheus-operator started at 2020-02-06 19:07:48 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.381: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 19:20:07.381: INFO: cm-acme-http-solver-tmzk6 from md-prometheus-operator started at 2020-02-06 19:07:48 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.381: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 19:20:07.381: INFO: md-flux-memcached-77b577bb4c-z77xr from md-flux started at 2020-02-06 18:11:26 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.381: INFO: 	Container memcached ready: true, restart count 0
Feb  6 19:20:07.381: INFO: md-dex-bfbfd7887-c9sjp from md-dex started at 2020-02-06 18:11:32 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.381: INFO: 	Container main ready: true, restart count 1
Feb  6 19:20:07.381: INFO: md-gangway-548f557b49-v4cb5 from md-gangway started at 2020-02-06 18:11:59 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.381: INFO: 	Container gangway ready: true, restart count 0
Feb  6 19:20:07.381: INFO: md-nginx-ingress-default-backend-7d86d446b4-kp67r from md-nginx-ingress started at 2020-02-06 18:12:09 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.381: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
Feb  6 19:20:07.381: INFO: md-prometheus-operator-kube-state-metrics-b65d855df-b9v58 from md-prometheus-operator started at 2020-02-06 18:12:39 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.381: INFO: 	Container kube-state-metrics ready: true, restart count 0
Feb  6 19:20:07.381: INFO: md-prometheus-operator-grafana-6699695c84-cpjdc from md-prometheus-operator started at 2020-02-06 18:12:49 +0000 UTC (2 container statuses recorded)
Feb  6 19:20:07.381: INFO: 	Container grafana ready: true, restart count 0
Feb  6 19:20:07.381: INFO: 	Container grafana-sc-dashboard ready: true, restart count 0
Feb  6 19:20:07.381: INFO: cm-acme-http-solver-9f7tx from md-navigator started at 2020-02-06 19:07:48 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.381: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 19:20:07.381: INFO: calico-node-jcts8 from kube-system started at 2020-02-06 15:57:51 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.381: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 19:20:07.381: INFO: kube-proxy-zp49w from kube-system started at 2020-02-06 15:57:51 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.381: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  6 19:20:07.381: INFO: sonobuoy-systemd-logs-daemon-set-936a433795204ed3-fdsl7 from sonobuoy started at 2020-02-06 18:40:06 +0000 UTC (2 container statuses recorded)
Feb  6 19:20:07.381: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 19:20:07.381: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 19:20:07.381: INFO: cm-acme-http-solver-9nppr from md-gangway started at 2020-02-06 19:07:48 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.381: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 19:20:07.381: INFO: md-prometheus-operator-prometheus-node-exporter-p52sm from md-prometheus-operator started at 2020-02-06 18:12:39 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.381: INFO: 	Container node-exporter ready: true, restart count 0
Feb  6 19:20:07.381: INFO: cm-acme-http-solver-jq4qb from md-prometheus-operator started at 2020-02-06 19:07:48 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.381: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 19:20:07.381: INFO: md-helm-operator-59d9c54dbf-85p6w from md-helm-operator started at 2020-02-06 18:11:03 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.381: INFO: 	Container flux-helm-operator ready: true, restart count 0
Feb  6 19:20:07.381: INFO: md-navigator-moondog-navigator-65f699786c-6sbxm from md-navigator started at 2020-02-06 18:11:28 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.381: INFO: 	Container moondog-navigator ready: true, restart count 0
Feb  6 19:20:07.381: INFO: md-loki-stack-promtail-wl8xd from md-loki-stack started at 2020-02-06 18:12:01 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.381: INFO: 	Container promtail ready: true, restart count 0
Feb  6 19:20:07.381: INFO: cm-acme-http-solver-tg7qw from md-dex started at 2020-02-06 18:12:35 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.381: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 19:20:07.381: INFO: 
Logging pods the kubelet thinks is on node ip-10-10-3-246.ec2.internal before test
Feb  6 19:20:07.389: INFO: md-prometheus-operator-prometheus-node-exporter-v8kp7 from md-prometheus-operator started at 2020-02-06 19:07:59 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.389: INFO: 	Container node-exporter ready: true, restart count 0
Feb  6 19:20:07.389: INFO: sonobuoy-systemd-logs-daemon-set-936a433795204ed3-q2qnm from sonobuoy started at 2020-02-06 18:40:06 +0000 UTC (2 container statuses recorded)
Feb  6 19:20:07.389: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 19:20:07.389: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 19:20:07.389: INFO: calico-node-n4lqx from kube-system started at 2020-02-06 15:57:51 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.389: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 19:20:07.389: INFO: md-loki-stack-promtail-4r8n6 from md-loki-stack started at 2020-02-06 19:07:59 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.389: INFO: 	Container promtail ready: true, restart count 0
Feb  6 19:20:07.389: INFO: cm-acme-http-solver-qhjp7 from md-oauth2-proxy started at 2020-02-06 19:17:32 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.389: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 19:20:07.389: INFO: md-oauth2-proxy-6559885d88-zt8t4 from md-oauth2-proxy started at 2020-02-06 19:16:44 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.389: INFO: 	Container oauth2-proxy ready: false, restart count 5
Feb  6 19:20:07.389: INFO: kube-proxy-jfqqq from kube-system started at 2020-02-06 15:57:51 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.389: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  6 19:20:07.389: INFO: sonobuoy from sonobuoy started at 2020-02-06 18:40:05 +0000 UTC (1 container statuses recorded)
Feb  6 19:20:07.389: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  6 19:20:07.389: INFO: sonobuoy-e2e-job-7dfb3a3ef75e43b0 from sonobuoy started at 2020-02-06 18:40:06 +0000 UTC (2 container statuses recorded)
Feb  6 19:20:07.389: INFO: 	Container e2e ready: true, restart count 0
Feb  6 19:20:07.389: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-7cabaa58-1b6b-40d4-b111-3f0e22001de0 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-7cabaa58-1b6b-40d4-b111-3f0e22001de0 off the node ip-10-10-3-246.ec2.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-7cabaa58-1b6b-40d4-b111-3f0e22001de0
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:20:15.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7739" for this suite.
Feb  6 19:20:33.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:20:33.985: INFO: namespace sched-pred-7739 deletion completed in 18.474545424s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:26.817 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:20:33.985: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-6148
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 19:20:34.145: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-6978b157-7c87-46a5-8a7a-36524ff08db4" in namespace "security-context-test-6148" to be "success or failure"
Feb  6 19:20:34.150: INFO: Pod "alpine-nnp-false-6978b157-7c87-46a5-8a7a-36524ff08db4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.249479ms
Feb  6 19:20:36.154: INFO: Pod "alpine-nnp-false-6978b157-7c87-46a5-8a7a-36524ff08db4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009364938s
Feb  6 19:20:38.158: INFO: Pod "alpine-nnp-false-6978b157-7c87-46a5-8a7a-36524ff08db4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012707864s
Feb  6 19:20:38.158: INFO: Pod "alpine-nnp-false-6978b157-7c87-46a5-8a7a-36524ff08db4" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:20:38.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6148" for this suite.
Feb  6 19:20:44.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:20:44.653: INFO: namespace security-context-test-6148 deletion completed in 6.479245246s

• [SLOW TEST:10.668 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:20:44.653: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-1329
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 19:20:44.803: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Creating first CR 
Feb  6 19:20:45.348: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-06T19:20:45Z generation:1 name:name1 resourceVersion:67440 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:624fdac0-a1be-44fc-830c-e78a31d0b421] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Feb  6 19:20:55.353: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-06T19:20:55Z generation:1 name:name2 resourceVersion:67475 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:21c71e49-6eaf-466f-b75e-fe2e3ecf56fe] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Feb  6 19:21:05.359: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-06T19:20:45Z generation:2 name:name1 resourceVersion:67512 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:624fdac0-a1be-44fc-830c-e78a31d0b421] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Feb  6 19:21:15.365: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-06T19:20:55Z generation:2 name:name2 resourceVersion:67542 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:21c71e49-6eaf-466f-b75e-fe2e3ecf56fe] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Feb  6 19:21:25.373: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-06T19:20:45Z generation:2 name:name1 resourceVersion:67578 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:624fdac0-a1be-44fc-830c-e78a31d0b421] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Feb  6 19:21:35.381: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-06T19:20:55Z generation:2 name:name2 resourceVersion:67614 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:21c71e49-6eaf-466f-b75e-fe2e3ecf56fe] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:21:45.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-1329" for this suite.
Feb  6 19:21:51.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:21:52.398: INFO: namespace crd-watch-1329 deletion completed in 6.479199439s

• [SLOW TEST:67.745 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:21:52.399: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-7275
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb  6 19:21:54.570: INFO: &Pod{ObjectMeta:{send-events-4b0f66f5-862d-4d8c-bffe-f8d14c1a47d6  events-7275 /api/v1/namespaces/events-7275/pods/send-events-4b0f66f5-862d-4d8c-bffe-f8d14c1a47d6 0d2544f1-7384-4c78-b994-c062e9628dcf 67780 0 2020-02-06 19:21:52 +0000 UTC <nil> <nil> map[name:foo time:548730728] map[cni.projectcalico.org/podIP:192.168.126.20/32 kubernetes.io/psp:admin] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-5sg7m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-5sg7m,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-5sg7m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-10-3-246.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 19:21:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 19:21:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 19:21:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 19:21:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.3.246,PodIP:192.168.126.20,StartTime:2020-02-06 19:21:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-06 19:21:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:docker://21e7cc032be71dfac89c56e3212f89cebff7f3b559f6bc82341336b7bfd3ec06,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.126.20,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Feb  6 19:21:56.574: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb  6 19:21:58.578: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:21:58.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7275" for this suite.
Feb  6 19:22:44.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:22:45.068: INFO: namespace events-7275 deletion completed in 46.47357076s

• [SLOW TEST:52.670 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:22:45.068: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8550
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Feb  6 19:22:45.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 --namespace=kubectl-8550 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb  6 19:22:47.140: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb  6 19:22:47.140: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:22:49.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8550" for this suite.
Feb  6 19:22:55.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:22:55.626: INFO: namespace kubectl-8550 deletion completed in 6.474812757s

• [SLOW TEST:10.558 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:22:55.627: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1334
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-3150a5c1-8a21-423d-92ca-55bbc36e662d
STEP: Creating a pod to test consume secrets
Feb  6 19:22:55.782: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-03db5ae1-1e18-4d28-8d0a-7e6173af7715" in namespace "projected-1334" to be "success or failure"
Feb  6 19:22:55.785: INFO: Pod "pod-projected-secrets-03db5ae1-1e18-4d28-8d0a-7e6173af7715": Phase="Pending", Reason="", readiness=false. Elapsed: 2.916638ms
Feb  6 19:22:57.789: INFO: Pod "pod-projected-secrets-03db5ae1-1e18-4d28-8d0a-7e6173af7715": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006597391s
STEP: Saw pod success
Feb  6 19:22:57.789: INFO: Pod "pod-projected-secrets-03db5ae1-1e18-4d28-8d0a-7e6173af7715" satisfied condition "success or failure"
Feb  6 19:22:57.792: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-projected-secrets-03db5ae1-1e18-4d28-8d0a-7e6173af7715 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  6 19:22:57.820: INFO: Waiting for pod pod-projected-secrets-03db5ae1-1e18-4d28-8d0a-7e6173af7715 to disappear
Feb  6 19:22:57.822: INFO: Pod pod-projected-secrets-03db5ae1-1e18-4d28-8d0a-7e6173af7715 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:22:57.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1334" for this suite.
Feb  6 19:23:03.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:23:04.302: INFO: namespace projected-1334 deletion completed in 6.475115275s

• [SLOW TEST:8.675 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:23:04.302: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8473
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 19:23:04.464: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b2f38210-9b65-4062-b315-230de92ca705" in namespace "projected-8473" to be "success or failure"
Feb  6 19:23:04.469: INFO: Pod "downwardapi-volume-b2f38210-9b65-4062-b315-230de92ca705": Phase="Pending", Reason="", readiness=false. Elapsed: 5.105894ms
Feb  6 19:23:06.473: INFO: Pod "downwardapi-volume-b2f38210-9b65-4062-b315-230de92ca705": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008990171s
STEP: Saw pod success
Feb  6 19:23:06.473: INFO: Pod "downwardapi-volume-b2f38210-9b65-4062-b315-230de92ca705" satisfied condition "success or failure"
Feb  6 19:23:06.475: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod downwardapi-volume-b2f38210-9b65-4062-b315-230de92ca705 container client-container: <nil>
STEP: delete the pod
Feb  6 19:23:06.498: INFO: Waiting for pod downwardapi-volume-b2f38210-9b65-4062-b315-230de92ca705 to disappear
Feb  6 19:23:06.502: INFO: Pod downwardapi-volume-b2f38210-9b65-4062-b315-230de92ca705 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:23:06.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8473" for this suite.
Feb  6 19:23:12.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:23:12.983: INFO: namespace projected-8473 deletion completed in 6.476183565s

• [SLOW TEST:8.681 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:23:12.983: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2429
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-2429
STEP: creating replication controller nodeport-test in namespace services-2429
I0206 19:23:13.180445      19 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-2429, replica count: 2
Feb  6 19:23:16.230: INFO: Creating new exec pod
I0206 19:23:16.230894      19 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  6 19:23:19.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=services-2429 execpoddqz6q -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Feb  6 19:23:19.504: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Feb  6 19:23:19.504: INFO: stdout: ""
Feb  6 19:23:19.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=services-2429 execpoddqz6q -- /bin/sh -x -c nc -zv -t -w 2 10.100.55.94 80'
Feb  6 19:23:19.744: INFO: stderr: "+ nc -zv -t -w 2 10.100.55.94 80\nConnection to 10.100.55.94 80 port [tcp/http] succeeded!\n"
Feb  6 19:23:19.744: INFO: stdout: ""
Feb  6 19:23:19.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=services-2429 execpoddqz6q -- /bin/sh -x -c nc -zv -t -w 2 10.10.1.217 30450'
Feb  6 19:23:19.976: INFO: stderr: "+ nc -zv -t -w 2 10.10.1.217 30450\nConnection to 10.10.1.217 30450 port [tcp/30450] succeeded!\n"
Feb  6 19:23:19.976: INFO: stdout: ""
Feb  6 19:23:19.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=services-2429 execpoddqz6q -- /bin/sh -x -c nc -zv -t -w 2 10.10.2.209 30450'
Feb  6 19:23:20.203: INFO: stderr: "+ nc -zv -t -w 2 10.10.2.209 30450\nConnection to 10.10.2.209 30450 port [tcp/30450] succeeded!\n"
Feb  6 19:23:20.203: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:23:20.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2429" for this suite.
Feb  6 19:23:26.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:23:26.687: INFO: namespace services-2429 deletion completed in 6.478301048s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.704 seconds]
[sig-network] Services
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:23:26.687: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3535
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-zsnl
STEP: Creating a pod to test atomic-volume-subpath
Feb  6 19:23:26.850: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-zsnl" in namespace "subpath-3535" to be "success or failure"
Feb  6 19:23:26.855: INFO: Pod "pod-subpath-test-projected-zsnl": Phase="Pending", Reason="", readiness=false. Elapsed: 4.400221ms
Feb  6 19:23:28.858: INFO: Pod "pod-subpath-test-projected-zsnl": Phase="Running", Reason="", readiness=true. Elapsed: 2.007692492s
Feb  6 19:23:30.861: INFO: Pod "pod-subpath-test-projected-zsnl": Phase="Running", Reason="", readiness=true. Elapsed: 4.011111874s
Feb  6 19:23:32.866: INFO: Pod "pod-subpath-test-projected-zsnl": Phase="Running", Reason="", readiness=true. Elapsed: 6.015896961s
Feb  6 19:23:34.870: INFO: Pod "pod-subpath-test-projected-zsnl": Phase="Running", Reason="", readiness=true. Elapsed: 8.019455989s
Feb  6 19:23:36.875: INFO: Pod "pod-subpath-test-projected-zsnl": Phase="Running", Reason="", readiness=true. Elapsed: 10.024496433s
Feb  6 19:23:38.878: INFO: Pod "pod-subpath-test-projected-zsnl": Phase="Running", Reason="", readiness=true. Elapsed: 12.028300027s
Feb  6 19:23:40.884: INFO: Pod "pod-subpath-test-projected-zsnl": Phase="Running", Reason="", readiness=true. Elapsed: 14.033938689s
Feb  6 19:23:42.893: INFO: Pod "pod-subpath-test-projected-zsnl": Phase="Running", Reason="", readiness=true. Elapsed: 16.043337175s
Feb  6 19:23:44.901: INFO: Pod "pod-subpath-test-projected-zsnl": Phase="Running", Reason="", readiness=true. Elapsed: 18.050627824s
Feb  6 19:23:46.907: INFO: Pod "pod-subpath-test-projected-zsnl": Phase="Running", Reason="", readiness=true. Elapsed: 20.057278131s
Feb  6 19:23:48.914: INFO: Pod "pod-subpath-test-projected-zsnl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.064197265s
STEP: Saw pod success
Feb  6 19:23:48.914: INFO: Pod "pod-subpath-test-projected-zsnl" satisfied condition "success or failure"
Feb  6 19:23:48.921: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-subpath-test-projected-zsnl container test-container-subpath-projected-zsnl: <nil>
STEP: delete the pod
Feb  6 19:23:48.947: INFO: Waiting for pod pod-subpath-test-projected-zsnl to disappear
Feb  6 19:23:48.953: INFO: Pod pod-subpath-test-projected-zsnl no longer exists
STEP: Deleting pod pod-subpath-test-projected-zsnl
Feb  6 19:23:48.953: INFO: Deleting pod "pod-subpath-test-projected-zsnl" in namespace "subpath-3535"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:23:48.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3535" for this suite.
Feb  6 19:23:54.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:23:55.457: INFO: namespace subpath-3535 deletion completed in 6.480588964s

• [SLOW TEST:28.770 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:23:55.457: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2421
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 19:23:55.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 create -f - --namespace=kubectl-2421'
Feb  6 19:23:55.853: INFO: stderr: ""
Feb  6 19:23:55.853: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb  6 19:23:55.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 create -f - --namespace=kubectl-2421'
Feb  6 19:23:56.145: INFO: stderr: ""
Feb  6 19:23:56.145: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  6 19:23:57.149: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 19:23:57.149: INFO: Found 0 / 1
Feb  6 19:23:58.149: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 19:23:58.149: INFO: Found 1 / 1
Feb  6 19:23:58.149: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  6 19:23:58.152: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 19:23:58.152: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  6 19:23:58.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 describe pod redis-master-v792l --namespace=kubectl-2421'
Feb  6 19:23:58.247: INFO: stderr: ""
Feb  6 19:23:58.247: INFO: stdout: "Name:         redis-master-v792l\nNamespace:    kubectl-2421\nPriority:     0\nNode:         ip-10-10-3-246.ec2.internal/10.10.3.246\nStart Time:   Thu, 06 Feb 2020 19:23:55 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  cni.projectcalico.org/podIP: 192.168.126.22/32\n              kubernetes.io/psp: e2e-test-privileged-psp\nStatus:       Running\nIP:           192.168.126.22\nIPs:\n  IP:           192.168.126.22\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://31640541cbcadfb0685e90f6887f33c19da99e391328e50d0875df284ce128b1\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 06 Feb 2020 19:23:56 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-l2mvp (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-l2mvp:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-l2mvp\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                                  Message\n  ----    ------     ----       ----                                  -------\n  Normal  Scheduled  <unknown>  default-scheduler                     Successfully assigned kubectl-2421/redis-master-v792l to ip-10-10-3-246.ec2.internal\n  Normal  Pulled     2s         kubelet, ip-10-10-3-246.ec2.internal  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    2s         kubelet, ip-10-10-3-246.ec2.internal  Created container redis-master\n  Normal  Started    2s         kubelet, ip-10-10-3-246.ec2.internal  Started container redis-master\n"
Feb  6 19:23:58.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 describe rc redis-master --namespace=kubectl-2421'
Feb  6 19:23:58.349: INFO: stderr: ""
Feb  6 19:23:58.349: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-2421\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-v792l\n"
Feb  6 19:23:58.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 describe service redis-master --namespace=kubectl-2421'
Feb  6 19:23:58.434: INFO: stderr: ""
Feb  6 19:23:58.434: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-2421\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.109.19.176\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         192.168.126.22:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb  6 19:23:58.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 describe node ip-10-10-1-217.ec2.internal'
Feb  6 19:23:58.559: INFO: stderr: ""
Feb  6 19:23:58.559: INFO: stdout: "Name:               ip-10-10-1-217.ec2.internal\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=t2.medium\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-east-1\n                    failure-domain.beta.kubernetes.io/zone=us-east-1a\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-10-10-1-217.ec2.internal\n                    kubernetes.io/os=linux\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.10.1.217/24\n                    projectcalico.org/IPv4IPIPTunnelAddr: 192.168.3.0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 06 Feb 2020 15:57:54 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Thu, 06 Feb 2020 15:58:12 +0000   Thu, 06 Feb 2020 15:58:12 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Thu, 06 Feb 2020 19:23:06 +0000   Thu, 06 Feb 2020 15:57:54 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Thu, 06 Feb 2020 19:23:06 +0000   Thu, 06 Feb 2020 15:57:54 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Thu, 06 Feb 2020 19:23:06 +0000   Thu, 06 Feb 2020 15:57:54 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Thu, 06 Feb 2020 19:23:06 +0000   Thu, 06 Feb 2020 15:58:04 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:   10.10.1.217\n  Hostname:     ip-10-10-1-217.ec2.internal\n  InternalDNS:  ip-10-10-1-217.ec2.internal\nCapacity:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           52417516Ki\n hugepages-2Mi:               0\n memory:                      3878876Ki\n pods:                        110\nAllocatable:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           48307982666\n hugepages-2Mi:               0\n memory:                      3776476Ki\n pods:                        110\nSystem Info:\n Machine ID:                 05cb8c7b39fe0f70e3ce97e5beab809d\n System UUID:                EC2F58E5-E67A-844D-365E-50EE7B4B5B5D\n Boot ID:                    725db4b9-5be8-402a-a8c5-1907f0f0a095\n Kernel Version:             3.10.0-957.1.3.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://19.3.5\n Kubelet Version:            v1.16.6-beta.0\n Kube-Proxy Version:         v1.16.6-beta.0\nPodCIDR:                     192.168.5.0/24\nPodCIDRs:                    192.168.5.0/24\nProviderID:                  aws:///us-east-1a/i-0d975477b84a70e02\nNon-terminated Pods:         (13 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                calico-node-hrxsw                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)         3h26m\n  kube-system                kube-proxy-dj7kw                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         3h26m\n  md-cert-manager            md-cert-manager-669497f667-mb9js                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         72m\n  md-cert-manager            md-cert-manager-cainjector-7758b57b8d-4j8jj                0 (0%)        0 (0%)      0 (0%)           0 (0%)         72m\n  md-flux                    md-flux-6d54668955-bl6sl                                   50m (2%)      0 (0%)      64Mi (1%)        0 (0%)         72m\n  md-loki-stack              loki-6877765b9c-2n9vf                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         71m\n  md-loki-stack              md-loki-stack-promtail-mmws9                               0 (0%)        0 (0%)      0 (0%)           0 (0%)         71m\n  md-nginx-ingress           md-nginx-ingress-controller-5cff997b69-9qwpx               0 (0%)        0 (0%)      0 (0%)           0 (0%)         71m\n  md-prometheus-operator     alertmanager-md-prometheus-operator-alertmanager-0         100m (5%)     100m (5%)   225Mi (6%)       25Mi (0%)      16m\n  md-prometheus-operator     md-prometheus-operator-operator-f975b4dd9-rw84h            0 (0%)        0 (0%)      0 (0%)           0 (0%)         71m\n  md-prometheus-operator     md-prometheus-operator-prometheus-node-exporter-mxlfh      0 (0%)        0 (0%)      0 (0%)           0 (0%)         71m\n  md-prometheus-operator     prometheus-md-prometheus-operator-prometheus-0             200m (10%)    200m (10%)  50Mi (1%)        50Mi (1%)      71m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-936a433795204ed3-lmxgr    0 (0%)        0 (0%)      0 (0%)           0 (0%)         43m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                    Requests    Limits\n  --------                    --------    ------\n  cpu                         600m (30%)  300m (15%)\n  memory                      339Mi (9%)  75Mi (2%)\n  ephemeral-storage           0 (0%)      0 (0%)\n  attachable-volumes-aws-ebs  0           0\nEvents:                       <none>\n"
Feb  6 19:23:58.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 describe namespace kubectl-2421'
Feb  6 19:23:58.652: INFO: stderr: ""
Feb  6 19:23:58.652: INFO: stdout: "Name:         kubectl-2421\nLabels:       e2e-framework=kubectl\n              e2e-run=3cde2692-1cd2-44f2-b1f0-dd4227d6e199\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:23:58.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2421" for this suite.
Feb  6 19:24:12.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:24:13.138: INFO: namespace kubectl-2421 deletion completed in 14.480966792s

• [SLOW TEST:17.681 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:24:13.138: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3924
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 19:24:13.300: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6e04f509-d1de-4122-9fa2-57e0482bab45" in namespace "projected-3924" to be "success or failure"
Feb  6 19:24:13.303: INFO: Pod "downwardapi-volume-6e04f509-d1de-4122-9fa2-57e0482bab45": Phase="Pending", Reason="", readiness=false. Elapsed: 2.858127ms
Feb  6 19:24:15.307: INFO: Pod "downwardapi-volume-6e04f509-d1de-4122-9fa2-57e0482bab45": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006690153s
STEP: Saw pod success
Feb  6 19:24:15.307: INFO: Pod "downwardapi-volume-6e04f509-d1de-4122-9fa2-57e0482bab45" satisfied condition "success or failure"
Feb  6 19:24:15.310: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod downwardapi-volume-6e04f509-d1de-4122-9fa2-57e0482bab45 container client-container: <nil>
STEP: delete the pod
Feb  6 19:24:15.334: INFO: Waiting for pod downwardapi-volume-6e04f509-d1de-4122-9fa2-57e0482bab45 to disappear
Feb  6 19:24:15.338: INFO: Pod downwardapi-volume-6e04f509-d1de-4122-9fa2-57e0482bab45 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:24:15.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3924" for this suite.
Feb  6 19:24:21.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:24:21.827: INFO: namespace projected-3924 deletion completed in 6.483070876s

• [SLOW TEST:8.689 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:24:21.827: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1004
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb  6 19:24:21.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-1004'
Feb  6 19:24:22.069: INFO: stderr: ""
Feb  6 19:24:22.069: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Feb  6 19:24:27.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pod e2e-test-httpd-pod --namespace=kubectl-1004 -o json'
Feb  6 19:24:27.201: INFO: stderr: ""
Feb  6 19:24:27.201: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"192.168.126.26/32\",\n            \"kubernetes.io/psp\": \"admin\"\n        },\n        \"creationTimestamp\": \"2020-02-06T19:24:22Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-1004\",\n        \"resourceVersion\": \"68713\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-1004/pods/e2e-test-httpd-pod\",\n        \"uid\": \"54b3d61a-eaf3-47a9-adc1-6f7fc7efa257\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-jp79b\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-10-10-3-246.ec2.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-jp79b\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-jp79b\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-06T19:24:22Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-06T19:24:23Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-06T19:24:23Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-06T19:24:22Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://964752ae8cecfcc8ff543ac77699daff5e0efbfde402790f6cbd20341c3ac2ef\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-02-06T19:24:23Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.10.3.246\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.126.26\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.126.26\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-02-06T19:24:22Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb  6 19:24:27.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 replace -f - --namespace=kubectl-1004'
Feb  6 19:24:27.396: INFO: stderr: ""
Feb  6 19:24:27.396: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Feb  6 19:24:27.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 delete pods e2e-test-httpd-pod --namespace=kubectl-1004'
Feb  6 19:24:31.382: INFO: stderr: ""
Feb  6 19:24:31.382: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:24:31.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1004" for this suite.
Feb  6 19:24:37.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:24:37.863: INFO: namespace kubectl-1004 deletion completed in 6.47590189s

• [SLOW TEST:16.036 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:24:37.863: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6419
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-6419.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-6419.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-6419.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-6419.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6419.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-6419.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-6419.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-6419.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-6419.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6419.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  6 19:24:42.051: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:42.055: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:42.058: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:42.062: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:42.073: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:42.077: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:42.080: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:42.086: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:42.103: INFO: Lookups using dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6419.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6419.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local jessie_udp@dns-test-service-2.dns-6419.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6419.svc.cluster.local]

Feb  6 19:24:47.108: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:47.112: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:47.115: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:47.119: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:47.133: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:47.136: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:47.140: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:47.144: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:47.150: INFO: Lookups using dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6419.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6419.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local jessie_udp@dns-test-service-2.dns-6419.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6419.svc.cluster.local]

Feb  6 19:24:52.108: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:52.112: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:52.116: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:52.119: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:52.130: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:52.133: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:52.136: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:52.139: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:52.150: INFO: Lookups using dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6419.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6419.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local jessie_udp@dns-test-service-2.dns-6419.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6419.svc.cluster.local]

Feb  6 19:24:57.108: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:57.111: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:57.115: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:57.118: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:57.129: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:57.133: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:57.136: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:57.140: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:24:57.147: INFO: Lookups using dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6419.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6419.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local jessie_udp@dns-test-service-2.dns-6419.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6419.svc.cluster.local]

Feb  6 19:25:02.109: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:25:02.113: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:25:02.117: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:25:02.120: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:25:02.132: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:25:02.139: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:25:02.143: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:25:02.148: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:25:02.156: INFO: Lookups using dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6419.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6419.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local jessie_udp@dns-test-service-2.dns-6419.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6419.svc.cluster.local]

Feb  6 19:25:07.114: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:25:07.118: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:25:07.121: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:25:07.127: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:25:07.138: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:25:07.141: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:25:07.145: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:25:07.148: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6419.svc.cluster.local from pod dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510: the server could not find the requested resource (get pods dns-test-2c5732a2-1eac-4070-a657-910476e05510)
Feb  6 19:25:07.157: INFO: Lookups using dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6419.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6419.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6419.svc.cluster.local jessie_udp@dns-test-service-2.dns-6419.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6419.svc.cluster.local]

Feb  6 19:25:12.146: INFO: DNS probes using dns-6419/dns-test-2c5732a2-1eac-4070-a657-910476e05510 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:25:12.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6419" for this suite.
Feb  6 19:25:18.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:25:18.683: INFO: namespace dns-6419 deletion completed in 6.47838914s

• [SLOW TEST:40.820 seconds]
[sig-network] DNS
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:25:18.684: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-308
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Feb  6 19:25:19.238: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 19:25:22.263: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 19:25:22.266: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:25:23.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-308" for this suite.
Feb  6 19:25:29.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:25:30.106: INFO: namespace crd-webhook-308 deletion completed in 6.484742557s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:11.437 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:25:30.121: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5466
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 19:25:32.306: INFO: Waiting up to 5m0s for pod "client-envvars-ee8a643a-aa63-4e72-9812-f6fd9dfe1eeb" in namespace "pods-5466" to be "success or failure"
Feb  6 19:25:32.310: INFO: Pod "client-envvars-ee8a643a-aa63-4e72-9812-f6fd9dfe1eeb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.250138ms
Feb  6 19:25:34.314: INFO: Pod "client-envvars-ee8a643a-aa63-4e72-9812-f6fd9dfe1eeb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008002192s
STEP: Saw pod success
Feb  6 19:25:34.314: INFO: Pod "client-envvars-ee8a643a-aa63-4e72-9812-f6fd9dfe1eeb" satisfied condition "success or failure"
Feb  6 19:25:34.316: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod client-envvars-ee8a643a-aa63-4e72-9812-f6fd9dfe1eeb container env3cont: <nil>
STEP: delete the pod
Feb  6 19:25:34.339: INFO: Waiting for pod client-envvars-ee8a643a-aa63-4e72-9812-f6fd9dfe1eeb to disappear
Feb  6 19:25:34.342: INFO: Pod client-envvars-ee8a643a-aa63-4e72-9812-f6fd9dfe1eeb no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:25:34.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5466" for this suite.
Feb  6 19:25:46.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:25:46.824: INFO: namespace pods-5466 deletion completed in 12.475888831s

• [SLOW TEST:16.703 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:25:46.824: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-197
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-197
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-197
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-197
Feb  6 19:25:46.985: INFO: Found 0 stateful pods, waiting for 1
Feb  6 19:25:56.989: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb  6 19:25:56.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=statefulset-197 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb  6 19:25:57.201: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb  6 19:25:57.201: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb  6 19:25:57.201: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb  6 19:25:57.205: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb  6 19:26:07.209: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 19:26:07.209: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 19:26:07.224: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998947s
Feb  6 19:26:08.228: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996118099s
Feb  6 19:26:09.231: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.992017408s
Feb  6 19:26:10.235: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.988396373s
Feb  6 19:26:11.239: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.984184127s
Feb  6 19:26:12.243: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.980452839s
Feb  6 19:26:13.247: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.976493019s
Feb  6 19:26:14.251: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.972561266s
Feb  6 19:26:15.255: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.968209608s
Feb  6 19:26:16.259: INFO: Verifying statefulset ss doesn't scale past 1 for another 964.5442ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-197
Feb  6 19:26:17.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=statefulset-197 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 19:26:17.470: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb  6 19:26:17.470: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb  6 19:26:17.470: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb  6 19:26:17.474: INFO: Found 1 stateful pods, waiting for 3
Feb  6 19:26:27.478: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 19:26:27.478: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 19:26:27.478: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb  6 19:26:27.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=statefulset-197 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb  6 19:26:27.693: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb  6 19:26:27.693: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb  6 19:26:27.693: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb  6 19:26:27.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=statefulset-197 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb  6 19:26:27.939: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb  6 19:26:27.939: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb  6 19:26:27.939: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb  6 19:26:27.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=statefulset-197 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb  6 19:26:28.162: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb  6 19:26:28.162: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb  6 19:26:28.162: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb  6 19:26:28.162: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 19:26:28.165: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb  6 19:26:38.172: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 19:26:38.172: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 19:26:38.172: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 19:26:38.183: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998946s
Feb  6 19:26:39.187: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996211221s
Feb  6 19:26:40.191: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992212323s
Feb  6 19:26:41.195: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.988239735s
Feb  6 19:26:42.199: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.984400698s
Feb  6 19:26:43.203: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.980186614s
Feb  6 19:26:44.207: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.976006414s
Feb  6 19:26:45.212: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.97146799s
Feb  6 19:26:46.217: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.96712501s
Feb  6 19:26:47.221: INFO: Verifying statefulset ss doesn't scale past 3 for another 961.724549ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-197
Feb  6 19:26:48.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=statefulset-197 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 19:26:48.481: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb  6 19:26:48.481: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb  6 19:26:48.481: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb  6 19:26:48.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=statefulset-197 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 19:26:48.723: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb  6 19:26:48.723: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb  6 19:26:48.723: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb  6 19:26:48.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=statefulset-197 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 19:26:48.942: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb  6 19:26:48.942: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb  6 19:26:48.942: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb  6 19:26:48.942: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb  6 19:27:28.956: INFO: Deleting all statefulset in ns statefulset-197
Feb  6 19:27:28.959: INFO: Scaling statefulset ss to 0
Feb  6 19:27:28.968: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 19:27:28.971: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:27:28.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-197" for this suite.
Feb  6 19:27:35.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:27:35.466: INFO: namespace statefulset-197 deletion completed in 6.477337175s

• [SLOW TEST:108.642 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:27:35.466: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7500
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb  6 19:27:35.617: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7500 /api/v1/namespaces/watch-7500/configmaps/e2e-watch-test-configmap-a 6d7ca87e-0774-4300-b3fd-90b3b462cfae 69957 0 2020-02-06 19:27:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  6 19:27:35.617: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7500 /api/v1/namespaces/watch-7500/configmaps/e2e-watch-test-configmap-a 6d7ca87e-0774-4300-b3fd-90b3b462cfae 69957 0 2020-02-06 19:27:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb  6 19:27:45.629: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7500 /api/v1/namespaces/watch-7500/configmaps/e2e-watch-test-configmap-a 6d7ca87e-0774-4300-b3fd-90b3b462cfae 69992 0 2020-02-06 19:27:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb  6 19:27:45.629: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7500 /api/v1/namespaces/watch-7500/configmaps/e2e-watch-test-configmap-a 6d7ca87e-0774-4300-b3fd-90b3b462cfae 69992 0 2020-02-06 19:27:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb  6 19:27:55.638: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7500 /api/v1/namespaces/watch-7500/configmaps/e2e-watch-test-configmap-a 6d7ca87e-0774-4300-b3fd-90b3b462cfae 70028 0 2020-02-06 19:27:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  6 19:27:55.638: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7500 /api/v1/namespaces/watch-7500/configmaps/e2e-watch-test-configmap-a 6d7ca87e-0774-4300-b3fd-90b3b462cfae 70028 0 2020-02-06 19:27:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb  6 19:28:05.647: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7500 /api/v1/namespaces/watch-7500/configmaps/e2e-watch-test-configmap-a 6d7ca87e-0774-4300-b3fd-90b3b462cfae 70065 0 2020-02-06 19:27:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  6 19:28:05.647: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7500 /api/v1/namespaces/watch-7500/configmaps/e2e-watch-test-configmap-a 6d7ca87e-0774-4300-b3fd-90b3b462cfae 70065 0 2020-02-06 19:27:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb  6 19:28:15.654: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7500 /api/v1/namespaces/watch-7500/configmaps/e2e-watch-test-configmap-b 309e82f6-91a1-43ec-b271-2af1476923cf 70099 0 2020-02-06 19:28:15 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  6 19:28:15.654: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7500 /api/v1/namespaces/watch-7500/configmaps/e2e-watch-test-configmap-b 309e82f6-91a1-43ec-b271-2af1476923cf 70099 0 2020-02-06 19:28:15 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb  6 19:28:25.662: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7500 /api/v1/namespaces/watch-7500/configmaps/e2e-watch-test-configmap-b 309e82f6-91a1-43ec-b271-2af1476923cf 70139 0 2020-02-06 19:28:15 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  6 19:28:25.662: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7500 /api/v1/namespaces/watch-7500/configmaps/e2e-watch-test-configmap-b 309e82f6-91a1-43ec-b271-2af1476923cf 70139 0 2020-02-06 19:28:15 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:28:35.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7500" for this suite.
Feb  6 19:28:41.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:28:42.144: INFO: namespace watch-7500 deletion completed in 6.475958718s

• [SLOW TEST:66.677 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:28:42.144: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4666
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 19:28:42.901: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb  6 19:28:44.910: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716614122, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716614122, loc:(*time.Location)(0x788a6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716614122, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716614122, loc:(*time.Location)(0x788a6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 19:28:47.928: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 19:28:47.931: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6397-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:28:49.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4666" for this suite.
Feb  6 19:28:55.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:28:55.600: INFO: namespace webhook-4666 deletion completed in 6.476927812s
STEP: Destroying namespace "webhook-4666-markers" for this suite.
Feb  6 19:29:01.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:29:02.081: INFO: namespace webhook-4666-markers deletion completed in 6.480450149s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.953 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:29:02.097: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5272
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb  6 19:29:02.252: INFO: Waiting up to 5m0s for pod "pod-0abd0a11-7138-4ac9-9d3c-02fad22ab68e" in namespace "emptydir-5272" to be "success or failure"
Feb  6 19:29:02.255: INFO: Pod "pod-0abd0a11-7138-4ac9-9d3c-02fad22ab68e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.13331ms
Feb  6 19:29:04.259: INFO: Pod "pod-0abd0a11-7138-4ac9-9d3c-02fad22ab68e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006829449s
STEP: Saw pod success
Feb  6 19:29:04.259: INFO: Pod "pod-0abd0a11-7138-4ac9-9d3c-02fad22ab68e" satisfied condition "success or failure"
Feb  6 19:29:04.262: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-0abd0a11-7138-4ac9-9d3c-02fad22ab68e container test-container: <nil>
STEP: delete the pod
Feb  6 19:29:04.293: INFO: Waiting for pod pod-0abd0a11-7138-4ac9-9d3c-02fad22ab68e to disappear
Feb  6 19:29:04.296: INFO: Pod pod-0abd0a11-7138-4ac9-9d3c-02fad22ab68e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:29:04.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5272" for this suite.
Feb  6 19:29:10.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:29:10.777: INFO: namespace emptydir-5272 deletion completed in 6.47410821s

• [SLOW TEST:8.681 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:29:10.778: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2321
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb  6 19:29:10.936: INFO: Waiting up to 5m0s for pod "pod-b36bc744-5f29-439c-8829-a70226ce9967" in namespace "emptydir-2321" to be "success or failure"
Feb  6 19:29:10.940: INFO: Pod "pod-b36bc744-5f29-439c-8829-a70226ce9967": Phase="Pending", Reason="", readiness=false. Elapsed: 4.066905ms
Feb  6 19:29:12.944: INFO: Pod "pod-b36bc744-5f29-439c-8829-a70226ce9967": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007943943s
STEP: Saw pod success
Feb  6 19:29:12.944: INFO: Pod "pod-b36bc744-5f29-439c-8829-a70226ce9967" satisfied condition "success or failure"
Feb  6 19:29:12.947: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-b36bc744-5f29-439c-8829-a70226ce9967 container test-container: <nil>
STEP: delete the pod
Feb  6 19:29:12.969: INFO: Waiting for pod pod-b36bc744-5f29-439c-8829-a70226ce9967 to disappear
Feb  6 19:29:12.973: INFO: Pod pod-b36bc744-5f29-439c-8829-a70226ce9967 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:29:12.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2321" for this suite.
Feb  6 19:29:19.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:29:19.463: INFO: namespace emptydir-2321 deletion completed in 6.482758606s

• [SLOW TEST:8.686 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:29:19.464: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3874
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-e17a81a0-cdf6-4674-aef4-5d68efa065a4 in namespace container-probe-3874
Feb  6 19:29:21.628: INFO: Started pod test-webserver-e17a81a0-cdf6-4674-aef4-5d68efa065a4 in namespace container-probe-3874
STEP: checking the pod's current state and verifying that restartCount is present
Feb  6 19:29:21.632: INFO: Initial restart count of pod test-webserver-e17a81a0-cdf6-4674-aef4-5d68efa065a4 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:33:22.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3874" for this suite.
Feb  6 19:33:28.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:33:28.597: INFO: namespace container-probe-3874 deletion completed in 6.481094614s

• [SLOW TEST:249.133 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:33:28.597: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8366
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-2dd5f4a6-9d16-43f8-908a-8501f4b15420
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:33:30.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8366" for this suite.
Feb  6 19:33:42.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:33:43.281: INFO: namespace configmap-8366 deletion completed in 12.476509717s

• [SLOW TEST:14.684 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:33:43.281: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4715
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb  6 19:33:43.435: INFO: Pod name pod-release: Found 0 pods out of 1
Feb  6 19:33:48.439: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:33:49.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4715" for this suite.
Feb  6 19:33:55.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:33:55.953: INFO: namespace replication-controller-4715 deletion completed in 6.483974614s

• [SLOW TEST:12.672 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:33:55.953: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-6168
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Feb  6 19:33:56.650: INFO: created pod pod-service-account-defaultsa
Feb  6 19:33:56.650: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb  6 19:33:56.655: INFO: created pod pod-service-account-mountsa
Feb  6 19:33:56.655: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb  6 19:33:56.663: INFO: created pod pod-service-account-nomountsa
Feb  6 19:33:56.663: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb  6 19:33:56.669: INFO: created pod pod-service-account-defaultsa-mountspec
Feb  6 19:33:56.669: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb  6 19:33:56.683: INFO: created pod pod-service-account-mountsa-mountspec
Feb  6 19:33:56.683: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb  6 19:33:56.690: INFO: created pod pod-service-account-nomountsa-mountspec
Feb  6 19:33:56.690: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb  6 19:33:56.699: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb  6 19:33:56.699: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb  6 19:33:56.706: INFO: created pod pod-service-account-mountsa-nomountspec
Feb  6 19:33:56.706: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb  6 19:33:56.713: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb  6 19:33:56.713: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:33:56.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6168" for this suite.
Feb  6 19:34:04.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:34:05.202: INFO: namespace svcaccounts-6168 deletion completed in 8.477261997s

• [SLOW TEST:9.249 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:34:05.202: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3633
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-48c8b11b-2eb6-45dc-a102-8e1ef96d1e25
STEP: Creating secret with name secret-projected-all-test-volume-00f6a46e-76b2-4832-9f02-371e36b20915
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb  6 19:34:05.370: INFO: Waiting up to 5m0s for pod "projected-volume-edc34ce5-c96d-4511-9780-df7be5234650" in namespace "projected-3633" to be "success or failure"
Feb  6 19:34:05.373: INFO: Pod "projected-volume-edc34ce5-c96d-4511-9780-df7be5234650": Phase="Pending", Reason="", readiness=false. Elapsed: 3.075266ms
Feb  6 19:34:07.377: INFO: Pod "projected-volume-edc34ce5-c96d-4511-9780-df7be5234650": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006882701s
STEP: Saw pod success
Feb  6 19:34:07.377: INFO: Pod "projected-volume-edc34ce5-c96d-4511-9780-df7be5234650" satisfied condition "success or failure"
Feb  6 19:34:07.380: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod projected-volume-edc34ce5-c96d-4511-9780-df7be5234650 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb  6 19:34:07.399: INFO: Waiting for pod projected-volume-edc34ce5-c96d-4511-9780-df7be5234650 to disappear
Feb  6 19:34:07.403: INFO: Pod projected-volume-edc34ce5-c96d-4511-9780-df7be5234650 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:34:07.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3633" for this suite.
Feb  6 19:34:13.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:34:13.884: INFO: namespace projected-3633 deletion completed in 6.47639462s

• [SLOW TEST:8.681 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:34:13.884: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4131
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 19:34:14.042: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b5f3c2db-e5f2-418c-a596-a77614823619" in namespace "downward-api-4131" to be "success or failure"
Feb  6 19:34:14.053: INFO: Pod "downwardapi-volume-b5f3c2db-e5f2-418c-a596-a77614823619": Phase="Pending", Reason="", readiness=false. Elapsed: 10.833311ms
Feb  6 19:34:16.057: INFO: Pod "downwardapi-volume-b5f3c2db-e5f2-418c-a596-a77614823619": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014317744s
STEP: Saw pod success
Feb  6 19:34:16.057: INFO: Pod "downwardapi-volume-b5f3c2db-e5f2-418c-a596-a77614823619" satisfied condition "success or failure"
Feb  6 19:34:16.060: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod downwardapi-volume-b5f3c2db-e5f2-418c-a596-a77614823619 container client-container: <nil>
STEP: delete the pod
Feb  6 19:34:16.106: INFO: Waiting for pod downwardapi-volume-b5f3c2db-e5f2-418c-a596-a77614823619 to disappear
Feb  6 19:34:16.111: INFO: Pod downwardapi-volume-b5f3c2db-e5f2-418c-a596-a77614823619 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:34:16.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4131" for this suite.
Feb  6 19:34:22.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:34:22.605: INFO: namespace downward-api-4131 deletion completed in 6.485994164s

• [SLOW TEST:8.721 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:34:22.605: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7579
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Feb  6 19:34:22.761: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 19:34:26.578: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:34:42.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7579" for this suite.
Feb  6 19:34:48.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:34:48.747: INFO: namespace crd-publish-openapi-7579 deletion completed in 6.475076229s

• [SLOW TEST:26.143 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:34:48.748: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8432
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 19:34:48.909: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d2c66d0e-2675-47d7-ae81-7f697b91fc10" in namespace "projected-8432" to be "success or failure"
Feb  6 19:34:48.913: INFO: Pod "downwardapi-volume-d2c66d0e-2675-47d7-ae81-7f697b91fc10": Phase="Pending", Reason="", readiness=false. Elapsed: 3.54393ms
Feb  6 19:34:50.916: INFO: Pod "downwardapi-volume-d2c66d0e-2675-47d7-ae81-7f697b91fc10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006980526s
STEP: Saw pod success
Feb  6 19:34:50.916: INFO: Pod "downwardapi-volume-d2c66d0e-2675-47d7-ae81-7f697b91fc10" satisfied condition "success or failure"
Feb  6 19:34:50.919: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod downwardapi-volume-d2c66d0e-2675-47d7-ae81-7f697b91fc10 container client-container: <nil>
STEP: delete the pod
Feb  6 19:34:50.940: INFO: Waiting for pod downwardapi-volume-d2c66d0e-2675-47d7-ae81-7f697b91fc10 to disappear
Feb  6 19:34:50.945: INFO: Pod downwardapi-volume-d2c66d0e-2675-47d7-ae81-7f697b91fc10 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:34:50.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8432" for this suite.
Feb  6 19:34:56.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:34:57.424: INFO: namespace projected-8432 deletion completed in 6.47410558s

• [SLOW TEST:8.676 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:34:57.424: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1576
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-sgcs
STEP: Creating a pod to test atomic-volume-subpath
Feb  6 19:34:57.588: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-sgcs" in namespace "subpath-1576" to be "success or failure"
Feb  6 19:34:57.591: INFO: Pod "pod-subpath-test-downwardapi-sgcs": Phase="Pending", Reason="", readiness=false. Elapsed: 3.040331ms
Feb  6 19:34:59.594: INFO: Pod "pod-subpath-test-downwardapi-sgcs": Phase="Running", Reason="", readiness=true. Elapsed: 2.00665791s
Feb  6 19:35:01.599: INFO: Pod "pod-subpath-test-downwardapi-sgcs": Phase="Running", Reason="", readiness=true. Elapsed: 4.010999255s
Feb  6 19:35:03.602: INFO: Pod "pod-subpath-test-downwardapi-sgcs": Phase="Running", Reason="", readiness=true. Elapsed: 6.014833509s
Feb  6 19:35:05.606: INFO: Pod "pod-subpath-test-downwardapi-sgcs": Phase="Running", Reason="", readiness=true. Elapsed: 8.018767488s
Feb  6 19:35:07.610: INFO: Pod "pod-subpath-test-downwardapi-sgcs": Phase="Running", Reason="", readiness=true. Elapsed: 10.022416034s
Feb  6 19:35:09.614: INFO: Pod "pod-subpath-test-downwardapi-sgcs": Phase="Running", Reason="", readiness=true. Elapsed: 12.026211935s
Feb  6 19:35:11.618: INFO: Pod "pod-subpath-test-downwardapi-sgcs": Phase="Running", Reason="", readiness=true. Elapsed: 14.030458958s
Feb  6 19:35:13.622: INFO: Pod "pod-subpath-test-downwardapi-sgcs": Phase="Running", Reason="", readiness=true. Elapsed: 16.034536276s
Feb  6 19:35:15.626: INFO: Pod "pod-subpath-test-downwardapi-sgcs": Phase="Running", Reason="", readiness=true. Elapsed: 18.038270591s
Feb  6 19:35:17.630: INFO: Pod "pod-subpath-test-downwardapi-sgcs": Phase="Running", Reason="", readiness=true. Elapsed: 20.042041209s
Feb  6 19:35:19.633: INFO: Pod "pod-subpath-test-downwardapi-sgcs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.045766224s
STEP: Saw pod success
Feb  6 19:35:19.633: INFO: Pod "pod-subpath-test-downwardapi-sgcs" satisfied condition "success or failure"
Feb  6 19:35:19.637: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-subpath-test-downwardapi-sgcs container test-container-subpath-downwardapi-sgcs: <nil>
STEP: delete the pod
Feb  6 19:35:19.657: INFO: Waiting for pod pod-subpath-test-downwardapi-sgcs to disappear
Feb  6 19:35:19.662: INFO: Pod pod-subpath-test-downwardapi-sgcs no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-sgcs
Feb  6 19:35:19.662: INFO: Deleting pod "pod-subpath-test-downwardapi-sgcs" in namespace "subpath-1576"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:35:19.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1576" for this suite.
Feb  6 19:35:25.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:35:26.155: INFO: namespace subpath-1576 deletion completed in 6.476546356s

• [SLOW TEST:28.731 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:35:26.156: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2264
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 19:35:29.713: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1e9cbb97-506f-43fc-b712-83dcbe9e93d7" in namespace "projected-2264" to be "success or failure"
Feb  6 19:35:29.721: INFO: Pod "downwardapi-volume-1e9cbb97-506f-43fc-b712-83dcbe9e93d7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.455014ms
Feb  6 19:35:31.726: INFO: Pod "downwardapi-volume-1e9cbb97-506f-43fc-b712-83dcbe9e93d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012798015s
STEP: Saw pod success
Feb  6 19:35:31.726: INFO: Pod "downwardapi-volume-1e9cbb97-506f-43fc-b712-83dcbe9e93d7" satisfied condition "success or failure"
Feb  6 19:35:31.729: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod downwardapi-volume-1e9cbb97-506f-43fc-b712-83dcbe9e93d7 container client-container: <nil>
STEP: delete the pod
Feb  6 19:35:31.752: INFO: Waiting for pod downwardapi-volume-1e9cbb97-506f-43fc-b712-83dcbe9e93d7 to disappear
Feb  6 19:35:31.756: INFO: Pod downwardapi-volume-1e9cbb97-506f-43fc-b712-83dcbe9e93d7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:35:31.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2264" for this suite.
Feb  6 19:35:37.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:35:38.235: INFO: namespace projected-2264 deletion completed in 6.474099878s

• [SLOW TEST:12.079 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:35:38.235: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-5306
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb  6 19:35:38.383: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:35:40.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5306" for this suite.
Feb  6 19:35:46.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:35:47.154: INFO: namespace init-container-5306 deletion completed in 6.477641198s

• [SLOW TEST:8.919 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:35:47.154: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8535
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Feb  6 19:35:47.305: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:36:01.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8535" for this suite.
Feb  6 19:36:07.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:36:07.860: INFO: namespace pods-8535 deletion completed in 6.474808227s

• [SLOW TEST:20.705 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:36:07.860: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7393
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 19:36:34.034: INFO: Container started at 2020-02-06 19:36:09 +0000 UTC, pod became ready at 2020-02-06 19:36:33 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:36:34.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7393" for this suite.
Feb  6 19:36:46.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:36:46.517: INFO: namespace container-probe-7393 deletion completed in 12.478879677s

• [SLOW TEST:38.657 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:36:46.518: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7309
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Feb  6 19:36:46.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 create -f - --namespace=kubectl-7309'
Feb  6 19:36:47.195: INFO: stderr: ""
Feb  6 19:36:47.195: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 19:36:47.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7309'
Feb  6 19:36:47.300: INFO: stderr: ""
Feb  6 19:36:47.300: INFO: stdout: "update-demo-nautilus-2zlwr update-demo-nautilus-8z9rl "
Feb  6 19:36:47.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-nautilus-2zlwr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7309'
Feb  6 19:36:47.532: INFO: stderr: ""
Feb  6 19:36:47.532: INFO: stdout: ""
Feb  6 19:36:47.532: INFO: update-demo-nautilus-2zlwr is created but not running
Feb  6 19:36:52.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7309'
Feb  6 19:36:52.613: INFO: stderr: ""
Feb  6 19:36:52.613: INFO: stdout: "update-demo-nautilus-2zlwr update-demo-nautilus-8z9rl "
Feb  6 19:36:52.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-nautilus-2zlwr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7309'
Feb  6 19:36:52.697: INFO: stderr: ""
Feb  6 19:36:52.697: INFO: stdout: "true"
Feb  6 19:36:52.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-nautilus-2zlwr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7309'
Feb  6 19:36:52.772: INFO: stderr: ""
Feb  6 19:36:52.772: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 19:36:52.772: INFO: validating pod update-demo-nautilus-2zlwr
Feb  6 19:36:52.776: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 19:36:52.776: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 19:36:52.776: INFO: update-demo-nautilus-2zlwr is verified up and running
Feb  6 19:36:52.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-nautilus-8z9rl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7309'
Feb  6 19:36:52.851: INFO: stderr: ""
Feb  6 19:36:52.851: INFO: stdout: "true"
Feb  6 19:36:52.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-nautilus-8z9rl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7309'
Feb  6 19:36:52.928: INFO: stderr: ""
Feb  6 19:36:52.928: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 19:36:52.928: INFO: validating pod update-demo-nautilus-8z9rl
Feb  6 19:36:52.935: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 19:36:52.935: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 19:36:52.935: INFO: update-demo-nautilus-8z9rl is verified up and running
STEP: using delete to clean up resources
Feb  6 19:36:52.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 delete --grace-period=0 --force -f - --namespace=kubectl-7309'
Feb  6 19:36:53.020: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 19:36:53.020: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb  6 19:36:53.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7309'
Feb  6 19:36:53.107: INFO: stderr: "No resources found in kubectl-7309 namespace.\n"
Feb  6 19:36:53.107: INFO: stdout: ""
Feb  6 19:36:53.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods -l name=update-demo --namespace=kubectl-7309 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  6 19:36:53.186: INFO: stderr: ""
Feb  6 19:36:53.186: INFO: stdout: "update-demo-nautilus-2zlwr\nupdate-demo-nautilus-8z9rl\n"
Feb  6 19:36:53.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7309'
Feb  6 19:36:53.810: INFO: stderr: "No resources found in kubectl-7309 namespace.\n"
Feb  6 19:36:53.810: INFO: stdout: ""
Feb  6 19:36:53.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods -l name=update-demo --namespace=kubectl-7309 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  6 19:36:53.901: INFO: stderr: ""
Feb  6 19:36:53.901: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:36:53.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7309" for this suite.
Feb  6 19:36:59.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:37:00.386: INFO: namespace kubectl-7309 deletion completed in 6.475901525s

• [SLOW TEST:13.868 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:37:00.386: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-10
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-e1b1817b-f873-42b9-8309-19694f0a6162
STEP: Creating a pod to test consume secrets
Feb  6 19:37:00.553: INFO: Waiting up to 5m0s for pod "pod-secrets-ed1203b4-e24f-409d-9888-6506d37d1194" in namespace "secrets-10" to be "success or failure"
Feb  6 19:37:00.556: INFO: Pod "pod-secrets-ed1203b4-e24f-409d-9888-6506d37d1194": Phase="Pending", Reason="", readiness=false. Elapsed: 3.40642ms
Feb  6 19:37:02.560: INFO: Pod "pod-secrets-ed1203b4-e24f-409d-9888-6506d37d1194": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007016434s
STEP: Saw pod success
Feb  6 19:37:02.560: INFO: Pod "pod-secrets-ed1203b4-e24f-409d-9888-6506d37d1194" satisfied condition "success or failure"
Feb  6 19:37:02.563: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-secrets-ed1203b4-e24f-409d-9888-6506d37d1194 container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 19:37:02.584: INFO: Waiting for pod pod-secrets-ed1203b4-e24f-409d-9888-6506d37d1194 to disappear
Feb  6 19:37:02.589: INFO: Pod pod-secrets-ed1203b4-e24f-409d-9888-6506d37d1194 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:37:02.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-10" for this suite.
Feb  6 19:37:08.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:37:09.073: INFO: namespace secrets-10 deletion completed in 6.479027393s

• [SLOW TEST:8.686 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:37:09.073: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5849
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb  6 19:37:09.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-5849'
Feb  6 19:37:09.310: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  6 19:37:09.310: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Feb  6 19:37:09.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 delete jobs e2e-test-httpd-job --namespace=kubectl-5849'
Feb  6 19:37:09.428: INFO: stderr: ""
Feb  6 19:37:09.428: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:37:09.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5849" for this suite.
Feb  6 19:37:39.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:37:39.918: INFO: namespace kubectl-5849 deletion completed in 30.477367676s

• [SLOW TEST:30.845 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:37:39.918: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7614
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Feb  6 19:37:40.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 create -f - --namespace=kubectl-7614'
Feb  6 19:37:40.331: INFO: stderr: ""
Feb  6 19:37:40.331: INFO: stdout: "pod/pause created\n"
Feb  6 19:37:40.331: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb  6 19:37:40.331: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-7614" to be "running and ready"
Feb  6 19:37:40.335: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.130327ms
Feb  6 19:37:42.339: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.007589893s
Feb  6 19:37:42.339: INFO: Pod "pause" satisfied condition "running and ready"
Feb  6 19:37:42.339: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Feb  6 19:37:42.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 label pods pause testing-label=testing-label-value --namespace=kubectl-7614'
Feb  6 19:37:42.422: INFO: stderr: ""
Feb  6 19:37:42.422: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb  6 19:37:42.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pod pause -L testing-label --namespace=kubectl-7614'
Feb  6 19:37:42.495: INFO: stderr: ""
Feb  6 19:37:42.495: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb  6 19:37:42.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 label pods pause testing-label- --namespace=kubectl-7614'
Feb  6 19:37:42.584: INFO: stderr: ""
Feb  6 19:37:42.584: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb  6 19:37:42.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pod pause -L testing-label --namespace=kubectl-7614'
Feb  6 19:37:42.669: INFO: stderr: ""
Feb  6 19:37:42.669: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Feb  6 19:37:42.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 delete --grace-period=0 --force -f - --namespace=kubectl-7614'
Feb  6 19:37:42.775: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 19:37:42.775: INFO: stdout: "pod \"pause\" force deleted\n"
Feb  6 19:37:42.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get rc,svc -l name=pause --no-headers --namespace=kubectl-7614'
Feb  6 19:37:42.892: INFO: stderr: "No resources found in kubectl-7614 namespace.\n"
Feb  6 19:37:42.892: INFO: stdout: ""
Feb  6 19:37:42.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods -l name=pause --namespace=kubectl-7614 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  6 19:37:42.984: INFO: stderr: ""
Feb  6 19:37:42.984: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:37:42.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7614" for this suite.
Feb  6 19:37:49.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:37:49.468: INFO: namespace kubectl-7614 deletion completed in 6.478627078s

• [SLOW TEST:9.550 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:37:49.468: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1581
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-7d02fb61-febf-413a-9a27-4bebabc356b0
STEP: Creating a pod to test consume secrets
Feb  6 19:37:49.627: INFO: Waiting up to 5m0s for pod "pod-secrets-fa86f302-8cca-49a0-a406-af5bbe737be3" in namespace "secrets-1581" to be "success or failure"
Feb  6 19:37:49.631: INFO: Pod "pod-secrets-fa86f302-8cca-49a0-a406-af5bbe737be3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029676ms
Feb  6 19:37:51.634: INFO: Pod "pod-secrets-fa86f302-8cca-49a0-a406-af5bbe737be3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007456959s
STEP: Saw pod success
Feb  6 19:37:51.634: INFO: Pod "pod-secrets-fa86f302-8cca-49a0-a406-af5bbe737be3" satisfied condition "success or failure"
Feb  6 19:37:51.640: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-secrets-fa86f302-8cca-49a0-a406-af5bbe737be3 container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 19:37:51.664: INFO: Waiting for pod pod-secrets-fa86f302-8cca-49a0-a406-af5bbe737be3 to disappear
Feb  6 19:37:51.668: INFO: Pod pod-secrets-fa86f302-8cca-49a0-a406-af5bbe737be3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:37:51.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1581" for this suite.
Feb  6 19:37:57.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:37:58.154: INFO: namespace secrets-1581 deletion completed in 6.474483133s

• [SLOW TEST:8.686 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:37:58.155: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-503
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-503.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-503.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-503.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-503.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-503.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-503.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-503.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-503.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-503.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-503.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-503.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 181.227.103.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.103.227.181_udp@PTR;check="$$(dig +tcp +noall +answer +search 181.227.103.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.103.227.181_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-503.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-503.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-503.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-503.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-503.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-503.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-503.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-503.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-503.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-503.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-503.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 181.227.103.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.103.227.181_udp@PTR;check="$$(dig +tcp +noall +answer +search 181.227.103.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.103.227.181_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  6 19:38:02.354: INFO: Unable to read wheezy_udp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:02.358: INFO: Unable to read wheezy_tcp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:02.362: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:02.366: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:02.393: INFO: Unable to read jessie_udp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:02.397: INFO: Unable to read jessie_tcp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:02.400: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:02.404: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:02.428: INFO: Lookups using dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e failed for: [wheezy_udp@dns-test-service.dns-503.svc.cluster.local wheezy_tcp@dns-test-service.dns-503.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local jessie_udp@dns-test-service.dns-503.svc.cluster.local jessie_tcp@dns-test-service.dns-503.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local]

Feb  6 19:38:07.432: INFO: Unable to read wheezy_udp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:07.436: INFO: Unable to read wheezy_tcp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:07.439: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:07.442: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:07.468: INFO: Unable to read jessie_udp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:07.472: INFO: Unable to read jessie_tcp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:07.475: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:07.478: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:07.499: INFO: Lookups using dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e failed for: [wheezy_udp@dns-test-service.dns-503.svc.cluster.local wheezy_tcp@dns-test-service.dns-503.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local jessie_udp@dns-test-service.dns-503.svc.cluster.local jessie_tcp@dns-test-service.dns-503.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local]

Feb  6 19:38:12.437: INFO: Unable to read wheezy_udp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:12.440: INFO: Unable to read wheezy_tcp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:12.444: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:12.447: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:12.471: INFO: Unable to read jessie_udp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:12.475: INFO: Unable to read jessie_tcp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:12.478: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:12.482: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:12.503: INFO: Lookups using dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e failed for: [wheezy_udp@dns-test-service.dns-503.svc.cluster.local wheezy_tcp@dns-test-service.dns-503.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local jessie_udp@dns-test-service.dns-503.svc.cluster.local jessie_tcp@dns-test-service.dns-503.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local]

Feb  6 19:38:17.432: INFO: Unable to read wheezy_udp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:17.436: INFO: Unable to read wheezy_tcp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:17.439: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:17.442: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:17.477: INFO: Unable to read jessie_udp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:17.480: INFO: Unable to read jessie_tcp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:17.483: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:17.486: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:17.508: INFO: Lookups using dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e failed for: [wheezy_udp@dns-test-service.dns-503.svc.cluster.local wheezy_tcp@dns-test-service.dns-503.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local jessie_udp@dns-test-service.dns-503.svc.cluster.local jessie_tcp@dns-test-service.dns-503.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local]

Feb  6 19:38:22.432: INFO: Unable to read wheezy_udp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:22.436: INFO: Unable to read wheezy_tcp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:22.440: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:22.444: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:22.469: INFO: Unable to read jessie_udp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:22.472: INFO: Unable to read jessie_tcp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:22.475: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:22.479: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:22.507: INFO: Lookups using dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e failed for: [wheezy_udp@dns-test-service.dns-503.svc.cluster.local wheezy_tcp@dns-test-service.dns-503.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local jessie_udp@dns-test-service.dns-503.svc.cluster.local jessie_tcp@dns-test-service.dns-503.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local]

Feb  6 19:38:27.432: INFO: Unable to read wheezy_udp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:27.435: INFO: Unable to read wheezy_tcp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:27.438: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:27.442: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:27.465: INFO: Unable to read jessie_udp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:27.468: INFO: Unable to read jessie_tcp@dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:27.471: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:27.475: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local from pod dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e: the server could not find the requested resource (get pods dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e)
Feb  6 19:38:27.497: INFO: Lookups using dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e failed for: [wheezy_udp@dns-test-service.dns-503.svc.cluster.local wheezy_tcp@dns-test-service.dns-503.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local jessie_udp@dns-test-service.dns-503.svc.cluster.local jessie_tcp@dns-test-service.dns-503.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-503.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-503.svc.cluster.local]

Feb  6 19:38:32.494: INFO: DNS probes using dns-503/dns-test-8f8642b2-4d63-47c7-bd37-b456f5242a1e succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:38:32.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-503" for this suite.
Feb  6 19:38:38.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:38:39.105: INFO: namespace dns-503 deletion completed in 6.487396504s

• [SLOW TEST:40.950 seconds]
[sig-network] DNS
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:38:39.105: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2161
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb  6 19:38:39.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-2161'
Feb  6 19:38:39.336: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  6 19:38:39.336: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Feb  6 19:38:39.341: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Feb  6 19:38:39.347: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb  6 19:38:39.355: INFO: scanned /root for discovery docs: <nil>
Feb  6 19:38:39.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-2161'
Feb  6 19:38:55.150: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb  6 19:38:55.150: INFO: stdout: "Created e2e-test-httpd-rc-2158c5d11a571ec8826ca1fbf456e491\nScaling up e2e-test-httpd-rc-2158c5d11a571ec8826ca1fbf456e491 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-2158c5d11a571ec8826ca1fbf456e491 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-2158c5d11a571ec8826ca1fbf456e491 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Feb  6 19:38:55.150: INFO: stdout: "Created e2e-test-httpd-rc-2158c5d11a571ec8826ca1fbf456e491\nScaling up e2e-test-httpd-rc-2158c5d11a571ec8826ca1fbf456e491 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-2158c5d11a571ec8826ca1fbf456e491 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-2158c5d11a571ec8826ca1fbf456e491 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Feb  6 19:38:55.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-2161'
Feb  6 19:38:55.238: INFO: stderr: ""
Feb  6 19:38:55.238: INFO: stdout: "e2e-test-httpd-rc-2158c5d11a571ec8826ca1fbf456e491-z2k9n "
Feb  6 19:38:55.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods e2e-test-httpd-rc-2158c5d11a571ec8826ca1fbf456e491-z2k9n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2161'
Feb  6 19:38:55.316: INFO: stderr: ""
Feb  6 19:38:55.316: INFO: stdout: "true"
Feb  6 19:38:55.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods e2e-test-httpd-rc-2158c5d11a571ec8826ca1fbf456e491-z2k9n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2161'
Feb  6 19:38:55.395: INFO: stderr: ""
Feb  6 19:38:55.395: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Feb  6 19:38:55.395: INFO: e2e-test-httpd-rc-2158c5d11a571ec8826ca1fbf456e491-z2k9n is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Feb  6 19:38:55.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 delete rc e2e-test-httpd-rc --namespace=kubectl-2161'
Feb  6 19:38:55.482: INFO: stderr: ""
Feb  6 19:38:55.482: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:38:55.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2161" for this suite.
Feb  6 19:39:07.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:39:07.962: INFO: namespace kubectl-2161 deletion completed in 12.475486391s

• [SLOW TEST:28.857 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:39:07.962: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1873
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 19:39:08.112: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Feb  6 19:39:12.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 --namespace=crd-publish-openapi-1873 create -f -'
Feb  6 19:39:12.697: INFO: stderr: ""
Feb  6 19:39:12.697: INFO: stdout: "e2e-test-crd-publish-openapi-8978-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Feb  6 19:39:12.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 --namespace=crd-publish-openapi-1873 delete e2e-test-crd-publish-openapi-8978-crds test-cr'
Feb  6 19:39:12.788: INFO: stderr: ""
Feb  6 19:39:12.788: INFO: stdout: "e2e-test-crd-publish-openapi-8978-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Feb  6 19:39:12.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 --namespace=crd-publish-openapi-1873 apply -f -'
Feb  6 19:39:13.207: INFO: stderr: ""
Feb  6 19:39:13.207: INFO: stdout: "e2e-test-crd-publish-openapi-8978-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Feb  6 19:39:13.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 --namespace=crd-publish-openapi-1873 delete e2e-test-crd-publish-openapi-8978-crds test-cr'
Feb  6 19:39:13.323: INFO: stderr: ""
Feb  6 19:39:13.323: INFO: stdout: "e2e-test-crd-publish-openapi-8978-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Feb  6 19:39:13.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 explain e2e-test-crd-publish-openapi-8978-crds'
Feb  6 19:39:13.586: INFO: stderr: ""
Feb  6 19:39:13.586: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8978-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:39:17.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1873" for this suite.
Feb  6 19:39:23.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:39:23.882: INFO: namespace crd-publish-openapi-1873 deletion completed in 6.475628671s

• [SLOW TEST:15.920 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:39:23.882: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8024
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-8024
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Feb  6 19:39:24.048: INFO: Found 0 stateful pods, waiting for 3
Feb  6 19:39:34.053: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 19:39:34.053: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 19:39:34.053: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 19:39:34.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=statefulset-8024 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb  6 19:39:34.307: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb  6 19:39:34.307: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb  6 19:39:34.307: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Feb  6 19:39:44.339: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb  6 19:39:54.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=statefulset-8024 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 19:39:54.569: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb  6 19:39:54.569: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb  6 19:39:54.569: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb  6 19:40:04.591: INFO: Waiting for StatefulSet statefulset-8024/ss2 to complete update
Feb  6 19:40:04.591: INFO: Waiting for Pod statefulset-8024/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb  6 19:40:04.591: INFO: Waiting for Pod statefulset-8024/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Feb  6 19:40:14.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=statefulset-8024 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb  6 19:40:14.831: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb  6 19:40:14.831: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb  6 19:40:14.831: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb  6 19:40:24.864: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb  6 19:40:34.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=statefulset-8024 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 19:40:35.104: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb  6 19:40:35.104: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb  6 19:40:35.104: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb  6 19:40:55.123: INFO: Waiting for StatefulSet statefulset-8024/ss2 to complete update
Feb  6 19:40:55.123: INFO: Waiting for Pod statefulset-8024/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb  6 19:41:05.131: INFO: Deleting all statefulset in ns statefulset-8024
Feb  6 19:41:05.133: INFO: Scaling statefulset ss2 to 0
Feb  6 19:41:25.149: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 19:41:25.152: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:41:25.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8024" for this suite.
Feb  6 19:41:33.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:41:33.651: INFO: namespace statefulset-8024 deletion completed in 8.477958035s

• [SLOW TEST:129.769 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:41:33.651: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5106
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 19:41:33.830: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"a5daefd6-216f-4770-996e-f8fdc2f4d9f9", Controller:(*bool)(0xc0051efe3e), BlockOwnerDeletion:(*bool)(0xc0051efe3f)}}
Feb  6 19:41:33.845: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"b99cfe66-1e9e-47be-ac4f-fc9878639719", Controller:(*bool)(0xc0051effde), BlockOwnerDeletion:(*bool)(0xc0051effdf)}}
Feb  6 19:41:33.851: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"ed45abf7-267c-42e5-8c65-1679140f794a", Controller:(*bool)(0xc0069aa8be), BlockOwnerDeletion:(*bool)(0xc0069aa8bf)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:41:38.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5106" for this suite.
Feb  6 19:41:44.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:41:45.337: INFO: namespace gc-5106 deletion completed in 6.47336225s

• [SLOW TEST:11.686 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:41:45.337: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8390
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Feb  6 19:41:45.491: INFO: namespace kubectl-8390
Feb  6 19:41:45.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 create -f - --namespace=kubectl-8390'
Feb  6 19:41:45.753: INFO: stderr: ""
Feb  6 19:41:45.753: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  6 19:41:46.758: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 19:41:46.758: INFO: Found 0 / 1
Feb  6 19:41:47.767: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 19:41:47.767: INFO: Found 0 / 1
Feb  6 19:41:48.756: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 19:41:48.756: INFO: Found 1 / 1
Feb  6 19:41:48.756: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  6 19:41:48.759: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 19:41:48.759: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  6 19:41:48.759: INFO: wait on redis-master startup in kubectl-8390 
Feb  6 19:41:48.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 logs redis-master-v5r87 redis-master --namespace=kubectl-8390'
Feb  6 19:41:48.907: INFO: stderr: ""
Feb  6 19:41:48.907: INFO: stdout: "1:C 06 Feb 2020 19:41:46.761 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 06 Feb 2020 19:41:46.761 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 06 Feb 2020 19:41:46.761 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 06 Feb 2020 19:41:46.763 * Running mode=standalone, port=6379.\n1:M 06 Feb 2020 19:41:46.763 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 06 Feb 2020 19:41:46.763 # Server initialized\n1:M 06 Feb 2020 19:41:46.763 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 06 Feb 2020 19:41:46.763 * Ready to accept connections\n"
STEP: exposing RC
Feb  6 19:41:48.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-8390'
Feb  6 19:41:49.016: INFO: stderr: ""
Feb  6 19:41:49.016: INFO: stdout: "service/rm2 exposed\n"
Feb  6 19:41:49.019: INFO: Service rm2 in namespace kubectl-8390 found.
STEP: exposing service
Feb  6 19:41:51.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-8390'
Feb  6 19:41:51.136: INFO: stderr: ""
Feb  6 19:41:51.136: INFO: stdout: "service/rm3 exposed\n"
Feb  6 19:41:51.139: INFO: Service rm3 in namespace kubectl-8390 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:41:53.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8390" for this suite.
Feb  6 19:42:05.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:42:05.637: INFO: namespace kubectl-8390 deletion completed in 12.481250594s

• [SLOW TEST:20.300 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:42:05.637: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5780
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:42:08.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5780" for this suite.
Feb  6 19:42:20.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:42:21.295: INFO: namespace replication-controller-5780 deletion completed in 12.474874362s

• [SLOW TEST:15.658 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:42:21.295: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7517
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 19:42:21.452: INFO: Waiting up to 5m0s for pod "downwardapi-volume-192ed31f-f9dd-4d18-8ed9-27e4a4c961f7" in namespace "downward-api-7517" to be "success or failure"
Feb  6 19:42:21.455: INFO: Pod "downwardapi-volume-192ed31f-f9dd-4d18-8ed9-27e4a4c961f7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.230817ms
Feb  6 19:42:23.459: INFO: Pod "downwardapi-volume-192ed31f-f9dd-4d18-8ed9-27e4a4c961f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007106302s
STEP: Saw pod success
Feb  6 19:42:23.459: INFO: Pod "downwardapi-volume-192ed31f-f9dd-4d18-8ed9-27e4a4c961f7" satisfied condition "success or failure"
Feb  6 19:42:23.464: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod downwardapi-volume-192ed31f-f9dd-4d18-8ed9-27e4a4c961f7 container client-container: <nil>
STEP: delete the pod
Feb  6 19:42:23.511: INFO: Waiting for pod downwardapi-volume-192ed31f-f9dd-4d18-8ed9-27e4a4c961f7 to disappear
Feb  6 19:42:23.514: INFO: Pod downwardapi-volume-192ed31f-f9dd-4d18-8ed9-27e4a4c961f7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:42:23.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7517" for this suite.
Feb  6 19:42:29.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:42:30.001: INFO: namespace downward-api-7517 deletion completed in 6.480410632s

• [SLOW TEST:8.705 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:42:30.001: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7269
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-53439450-8c2a-4460-acf1-40fe37aff513
STEP: Creating a pod to test consume configMaps
Feb  6 19:42:30.164: INFO: Waiting up to 5m0s for pod "pod-configmaps-a2c67e9a-c84c-4914-b5b5-4211c505beca" in namespace "configmap-7269" to be "success or failure"
Feb  6 19:42:30.167: INFO: Pod "pod-configmaps-a2c67e9a-c84c-4914-b5b5-4211c505beca": Phase="Pending", Reason="", readiness=false. Elapsed: 3.167831ms
Feb  6 19:42:32.171: INFO: Pod "pod-configmaps-a2c67e9a-c84c-4914-b5b5-4211c505beca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006793893s
STEP: Saw pod success
Feb  6 19:42:32.171: INFO: Pod "pod-configmaps-a2c67e9a-c84c-4914-b5b5-4211c505beca" satisfied condition "success or failure"
Feb  6 19:42:32.174: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-configmaps-a2c67e9a-c84c-4914-b5b5-4211c505beca container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 19:42:32.195: INFO: Waiting for pod pod-configmaps-a2c67e9a-c84c-4914-b5b5-4211c505beca to disappear
Feb  6 19:42:32.198: INFO: Pod pod-configmaps-a2c67e9a-c84c-4914-b5b5-4211c505beca no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:42:32.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7269" for this suite.
Feb  6 19:42:38.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:42:38.677: INFO: namespace configmap-7269 deletion completed in 6.474717709s

• [SLOW TEST:8.676 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:42:38.677: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3419
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Feb  6 19:42:38.824: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-481697501 proxy --unix-socket=/tmp/kubectl-proxy-unix442633828/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:42:38.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3419" for this suite.
Feb  6 19:42:46.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:42:47.357: INFO: namespace kubectl-3419 deletion completed in 8.473343992s

• [SLOW TEST:8.679 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:42:47.357: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1213
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-11b31620-e5ef-4941-858a-e9ae8604d3ce
STEP: Creating a pod to test consume configMaps
Feb  6 19:42:47.523: INFO: Waiting up to 5m0s for pod "pod-configmaps-7c52de34-caac-49cb-926a-48b90a6cd46f" in namespace "configmap-1213" to be "success or failure"
Feb  6 19:42:47.526: INFO: Pod "pod-configmaps-7c52de34-caac-49cb-926a-48b90a6cd46f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.74806ms
Feb  6 19:42:49.530: INFO: Pod "pod-configmaps-7c52de34-caac-49cb-926a-48b90a6cd46f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006393944s
STEP: Saw pod success
Feb  6 19:42:49.530: INFO: Pod "pod-configmaps-7c52de34-caac-49cb-926a-48b90a6cd46f" satisfied condition "success or failure"
Feb  6 19:42:49.532: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-configmaps-7c52de34-caac-49cb-926a-48b90a6cd46f container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 19:42:49.561: INFO: Waiting for pod pod-configmaps-7c52de34-caac-49cb-926a-48b90a6cd46f to disappear
Feb  6 19:42:49.566: INFO: Pod pod-configmaps-7c52de34-caac-49cb-926a-48b90a6cd46f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:42:49.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1213" for this suite.
Feb  6 19:42:55.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:42:56.050: INFO: namespace configmap-1213 deletion completed in 6.478673612s

• [SLOW TEST:8.693 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:42:56.050: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1284
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 19:42:56.217: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b45aa53f-a0b8-4a04-bcf7-781e70a00320" in namespace "downward-api-1284" to be "success or failure"
Feb  6 19:42:56.220: INFO: Pod "downwardapi-volume-b45aa53f-a0b8-4a04-bcf7-781e70a00320": Phase="Pending", Reason="", readiness=false. Elapsed: 2.459254ms
Feb  6 19:42:58.223: INFO: Pod "downwardapi-volume-b45aa53f-a0b8-4a04-bcf7-781e70a00320": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006222869s
STEP: Saw pod success
Feb  6 19:42:58.223: INFO: Pod "downwardapi-volume-b45aa53f-a0b8-4a04-bcf7-781e70a00320" satisfied condition "success or failure"
Feb  6 19:42:58.226: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod downwardapi-volume-b45aa53f-a0b8-4a04-bcf7-781e70a00320 container client-container: <nil>
STEP: delete the pod
Feb  6 19:42:58.250: INFO: Waiting for pod downwardapi-volume-b45aa53f-a0b8-4a04-bcf7-781e70a00320 to disappear
Feb  6 19:42:58.254: INFO: Pod downwardapi-volume-b45aa53f-a0b8-4a04-bcf7-781e70a00320 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:42:58.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1284" for this suite.
Feb  6 19:43:04.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:43:04.735: INFO: namespace downward-api-1284 deletion completed in 6.476917904s

• [SLOW TEST:8.686 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:43:04.735: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3099
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-47978b27-2b1c-4fc7-bf51-79bb58e6666e
STEP: Creating a pod to test consume secrets
Feb  6 19:43:04.903: INFO: Waiting up to 5m0s for pod "pod-secrets-da995ee0-cc6d-48ac-bd67-7a7cdb23c27b" in namespace "secrets-3099" to be "success or failure"
Feb  6 19:43:04.906: INFO: Pod "pod-secrets-da995ee0-cc6d-48ac-bd67-7a7cdb23c27b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.895388ms
Feb  6 19:43:06.910: INFO: Pod "pod-secrets-da995ee0-cc6d-48ac-bd67-7a7cdb23c27b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006897142s
STEP: Saw pod success
Feb  6 19:43:06.910: INFO: Pod "pod-secrets-da995ee0-cc6d-48ac-bd67-7a7cdb23c27b" satisfied condition "success or failure"
Feb  6 19:43:06.913: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-secrets-da995ee0-cc6d-48ac-bd67-7a7cdb23c27b container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 19:43:06.934: INFO: Waiting for pod pod-secrets-da995ee0-cc6d-48ac-bd67-7a7cdb23c27b to disappear
Feb  6 19:43:06.937: INFO: Pod pod-secrets-da995ee0-cc6d-48ac-bd67-7a7cdb23c27b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:43:06.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3099" for this suite.
Feb  6 19:43:12.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:43:13.417: INFO: namespace secrets-3099 deletion completed in 6.475336478s

• [SLOW TEST:8.682 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:43:13.417: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9579
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-9579
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-9579
STEP: creating replication controller externalsvc in namespace services-9579
I0206 19:43:13.602505      19 runners.go:184] Created replication controller with name: externalsvc, namespace: services-9579, replica count: 2
I0206 19:43:16.652902      19 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Feb  6 19:43:16.675: INFO: Creating new exec pod
Feb  6 19:43:18.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=services-9579 execpodg77k7 -- /bin/sh -x -c nslookup clusterip-service'
Feb  6 19:43:18.954: INFO: stderr: "+ nslookup clusterip-service\n"
Feb  6 19:43:18.954: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-9579.svc.cluster.local\tcanonical name = externalsvc.services-9579.svc.cluster.local.\nName:\texternalsvc.services-9579.svc.cluster.local\nAddress: 10.108.32.174\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-9579, will wait for the garbage collector to delete the pods
Feb  6 19:43:19.017: INFO: Deleting ReplicationController externalsvc took: 9.583769ms
Feb  6 19:43:19.717: INFO: Terminating ReplicationController externalsvc pods took: 700.271951ms
Feb  6 19:43:23.542: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:43:23.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9579" for this suite.
Feb  6 19:43:29.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:43:30.064: INFO: namespace services-9579 deletion completed in 6.494198615s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:16.646 seconds]
[sig-network] Services
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:43:30.064: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-9310
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb  6 19:43:34.253: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  6 19:43:34.256: INFO: Pod pod-with-prestop-http-hook still exists
Feb  6 19:43:36.257: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  6 19:43:36.260: INFO: Pod pod-with-prestop-http-hook still exists
Feb  6 19:43:38.257: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  6 19:43:38.260: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:43:38.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9310" for this suite.
Feb  6 19:43:50.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:43:50.746: INFO: namespace container-lifecycle-hook-9310 deletion completed in 12.473237267s

• [SLOW TEST:20.682 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:43:50.746: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6002
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:43:50.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6002" for this suite.
Feb  6 19:44:02.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:44:03.391: INFO: namespace pods-6002 deletion completed in 12.478618808s

• [SLOW TEST:12.645 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:44:03.391: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7273
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb  6 19:44:04.436: INFO: Waiting up to 5m0s for pod "downward-api-4a037fd7-6ec9-483a-818c-21fe1e31e00c" in namespace "downward-api-7273" to be "success or failure"
Feb  6 19:44:04.440: INFO: Pod "downward-api-4a037fd7-6ec9-483a-818c-21fe1e31e00c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.353625ms
Feb  6 19:44:06.451: INFO: Pod "downward-api-4a037fd7-6ec9-483a-818c-21fe1e31e00c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014200579s
STEP: Saw pod success
Feb  6 19:44:06.451: INFO: Pod "downward-api-4a037fd7-6ec9-483a-818c-21fe1e31e00c" satisfied condition "success or failure"
Feb  6 19:44:06.453: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod downward-api-4a037fd7-6ec9-483a-818c-21fe1e31e00c container dapi-container: <nil>
STEP: delete the pod
Feb  6 19:44:06.473: INFO: Waiting for pod downward-api-4a037fd7-6ec9-483a-818c-21fe1e31e00c to disappear
Feb  6 19:44:06.476: INFO: Pod downward-api-4a037fd7-6ec9-483a-818c-21fe1e31e00c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:44:06.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7273" for this suite.
Feb  6 19:44:12.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:44:12.978: INFO: namespace downward-api-7273 deletion completed in 6.479407818s

• [SLOW TEST:9.587 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:44:12.978: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2100
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-0ae89239-399a-4372-a8be-619d47f18aa7 in namespace container-probe-2100
Feb  6 19:44:15.158: INFO: Started pod liveness-0ae89239-399a-4372-a8be-619d47f18aa7 in namespace container-probe-2100
STEP: checking the pod's current state and verifying that restartCount is present
Feb  6 19:44:15.161: INFO: Initial restart count of pod liveness-0ae89239-399a-4372-a8be-619d47f18aa7 is 0
Feb  6 19:44:29.188: INFO: Restart count of pod container-probe-2100/liveness-0ae89239-399a-4372-a8be-619d47f18aa7 is now 1 (14.027230301s elapsed)
Feb  6 19:44:49.227: INFO: Restart count of pod container-probe-2100/liveness-0ae89239-399a-4372-a8be-619d47f18aa7 is now 2 (34.065378132s elapsed)
Feb  6 19:45:09.266: INFO: Restart count of pod container-probe-2100/liveness-0ae89239-399a-4372-a8be-619d47f18aa7 is now 3 (54.104878468s elapsed)
Feb  6 19:45:29.302: INFO: Restart count of pod container-probe-2100/liveness-0ae89239-399a-4372-a8be-619d47f18aa7 is now 4 (1m14.141049199s elapsed)
Feb  6 19:46:31.431: INFO: Restart count of pod container-probe-2100/liveness-0ae89239-399a-4372-a8be-619d47f18aa7 is now 5 (2m16.269299307s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:46:31.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2100" for this suite.
Feb  6 19:46:37.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:46:37.949: INFO: namespace container-probe-2100 deletion completed in 6.492184809s

• [SLOW TEST:144.971 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:46:37.949: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1528
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-0f898f52-525f-4c33-bf9c-0e5fd02c87d0
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-0f898f52-525f-4c33-bf9c-0e5fd02c87d0
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:46:42.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1528" for this suite.
Feb  6 19:47:02.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:47:02.638: INFO: namespace configmap-1528 deletion completed in 20.475397459s

• [SLOW TEST:24.688 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:47:02.638: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-335
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Feb  6 19:47:04.816: INFO: Pod pod-hostip-bde21d9f-728f-439c-a372-27dc6874e745 has hostIP: 10.10.3.246
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:47:04.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-335" for this suite.
Feb  6 19:47:16.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:47:17.297: INFO: namespace pods-335 deletion completed in 12.476611061s

• [SLOW TEST:14.660 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:47:17.297: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4825
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-e190aca0-1e4f-44f7-acd1-ac5961ae2c11
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-e190aca0-1e4f-44f7-acd1-ac5961ae2c11
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:47:21.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4825" for this suite.
Feb  6 19:47:33.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:47:33.997: INFO: namespace projected-4825 deletion completed in 12.477610737s

• [SLOW TEST:16.699 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:47:33.997: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9567
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:47:45.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9567" for this suite.
Feb  6 19:47:51.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:47:51.686: INFO: namespace resourcequota-9567 deletion completed in 6.478334522s

• [SLOW TEST:17.689 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:47:51.686: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-631
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Feb  6 19:47:51.837: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb  6 19:47:51.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 create -f - --namespace=kubectl-631'
Feb  6 19:47:52.084: INFO: stderr: ""
Feb  6 19:47:52.084: INFO: stdout: "service/redis-slave created\n"
Feb  6 19:47:52.084: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb  6 19:47:52.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 create -f - --namespace=kubectl-631'
Feb  6 19:47:52.331: INFO: stderr: ""
Feb  6 19:47:52.331: INFO: stdout: "service/redis-master created\n"
Feb  6 19:47:52.331: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb  6 19:47:52.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 create -f - --namespace=kubectl-631'
Feb  6 19:47:52.572: INFO: stderr: ""
Feb  6 19:47:52.572: INFO: stdout: "service/frontend created\n"
Feb  6 19:47:52.572: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb  6 19:47:52.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 create -f - --namespace=kubectl-631'
Feb  6 19:47:52.854: INFO: stderr: ""
Feb  6 19:47:52.854: INFO: stdout: "deployment.apps/frontend created\n"
Feb  6 19:47:52.854: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb  6 19:47:52.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 create -f - --namespace=kubectl-631'
Feb  6 19:47:53.147: INFO: stderr: ""
Feb  6 19:47:53.147: INFO: stdout: "deployment.apps/redis-master created\n"
Feb  6 19:47:53.147: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb  6 19:47:53.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 create -f - --namespace=kubectl-631'
Feb  6 19:47:53.951: INFO: stderr: ""
Feb  6 19:47:53.951: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Feb  6 19:47:53.951: INFO: Waiting for all frontend pods to be Running.
Feb  6 19:47:59.006: INFO: Waiting for frontend to serve content.
Feb  6 19:47:59.021: INFO: Trying to add a new entry to the guestbook.
Feb  6 19:47:59.045: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Feb  6 19:47:59.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 delete --grace-period=0 --force -f - --namespace=kubectl-631'
Feb  6 19:47:59.176: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 19:47:59.176: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb  6 19:47:59.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 delete --grace-period=0 --force -f - --namespace=kubectl-631'
Feb  6 19:47:59.306: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 19:47:59.306: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb  6 19:47:59.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 delete --grace-period=0 --force -f - --namespace=kubectl-631'
Feb  6 19:47:59.494: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 19:47:59.494: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb  6 19:47:59.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 delete --grace-period=0 --force -f - --namespace=kubectl-631'
Feb  6 19:47:59.601: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 19:47:59.601: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb  6 19:47:59.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 delete --grace-period=0 --force -f - --namespace=kubectl-631'
Feb  6 19:47:59.688: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 19:47:59.688: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb  6 19:47:59.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 delete --grace-period=0 --force -f - --namespace=kubectl-631'
Feb  6 19:47:59.772: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 19:47:59.772: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:47:59.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-631" for this suite.
Feb  6 19:48:29.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:48:30.257: INFO: namespace kubectl-631 deletion completed in 30.479745003s

• [SLOW TEST:38.571 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:48:30.257: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-6447
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-6447
I0206 19:48:30.409209      19 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6447, replica count: 1
I0206 19:48:31.460595      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0206 19:48:32.460801      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  6 19:48:32.575: INFO: Created: latency-svc-pft6k
Feb  6 19:48:32.588: INFO: Got endpoints: latency-svc-pft6k [27.357597ms]
Feb  6 19:48:32.634: INFO: Created: latency-svc-lbvdt
Feb  6 19:48:32.653: INFO: Got endpoints: latency-svc-lbvdt [64.978123ms]
Feb  6 19:48:32.668: INFO: Created: latency-svc-75cfx
Feb  6 19:48:32.681: INFO: Got endpoints: latency-svc-75cfx [92.788665ms]
Feb  6 19:48:32.688: INFO: Created: latency-svc-9m2sn
Feb  6 19:48:32.698: INFO: Got endpoints: latency-svc-9m2sn [109.263401ms]
Feb  6 19:48:32.703: INFO: Created: latency-svc-72zrj
Feb  6 19:48:32.720: INFO: Got endpoints: latency-svc-72zrj [131.348602ms]
Feb  6 19:48:32.723: INFO: Created: latency-svc-jm9zs
Feb  6 19:48:32.731: INFO: Got endpoints: latency-svc-jm9zs [142.182266ms]
Feb  6 19:48:32.737: INFO: Created: latency-svc-crq5w
Feb  6 19:48:32.756: INFO: Got endpoints: latency-svc-crq5w [167.016807ms]
Feb  6 19:48:32.758: INFO: Created: latency-svc-f7m7h
Feb  6 19:48:32.771: INFO: Got endpoints: latency-svc-f7m7h [182.739296ms]
Feb  6 19:48:32.781: INFO: Created: latency-svc-vct2z
Feb  6 19:48:32.792: INFO: Got endpoints: latency-svc-vct2z [203.546925ms]
Feb  6 19:48:32.803: INFO: Created: latency-svc-lrtjr
Feb  6 19:48:32.812: INFO: Got endpoints: latency-svc-lrtjr [222.968891ms]
Feb  6 19:48:32.815: INFO: Created: latency-svc-xxlqv
Feb  6 19:48:32.824: INFO: Got endpoints: latency-svc-xxlqv [235.476241ms]
Feb  6 19:48:32.834: INFO: Created: latency-svc-ng86x
Feb  6 19:48:32.845: INFO: Created: latency-svc-v5bc7
Feb  6 19:48:32.847: INFO: Got endpoints: latency-svc-ng86x [257.808695ms]
Feb  6 19:48:32.857: INFO: Got endpoints: latency-svc-v5bc7 [267.915901ms]
Feb  6 19:48:32.862: INFO: Created: latency-svc-lpk8m
Feb  6 19:48:32.873: INFO: Got endpoints: latency-svc-lpk8m [283.506253ms]
Feb  6 19:48:32.882: INFO: Created: latency-svc-n62mw
Feb  6 19:48:32.889: INFO: Got endpoints: latency-svc-n62mw [299.272055ms]
Feb  6 19:48:32.896: INFO: Created: latency-svc-4v2kk
Feb  6 19:48:32.903: INFO: Got endpoints: latency-svc-4v2kk [313.992525ms]
Feb  6 19:48:32.926: INFO: Created: latency-svc-x5h7x
Feb  6 19:48:32.926: INFO: Got endpoints: latency-svc-x5h7x [272.723161ms]
Feb  6 19:48:32.943: INFO: Created: latency-svc-fzhmn
Feb  6 19:48:33.060: INFO: Got endpoints: latency-svc-fzhmn [379.090962ms]
Feb  6 19:48:33.074: INFO: Created: latency-svc-mpqqh
Feb  6 19:48:33.136: INFO: Got endpoints: latency-svc-mpqqh [438.334185ms]
Feb  6 19:48:33.330: INFO: Created: latency-svc-q54kc
Feb  6 19:48:33.359: INFO: Got endpoints: latency-svc-q54kc [638.782054ms]
Feb  6 19:48:33.364: INFO: Created: latency-svc-g6t55
Feb  6 19:48:33.397: INFO: Got endpoints: latency-svc-g6t55 [666.425375ms]
Feb  6 19:48:33.398: INFO: Created: latency-svc-spmrh
Feb  6 19:48:33.411: INFO: Got endpoints: latency-svc-spmrh [655.314805ms]
Feb  6 19:48:33.415: INFO: Created: latency-svc-5cnwk
Feb  6 19:48:33.424: INFO: Got endpoints: latency-svc-5cnwk [652.732453ms]
Feb  6 19:48:33.430: INFO: Created: latency-svc-rjxhd
Feb  6 19:48:33.440: INFO: Got endpoints: latency-svc-rjxhd [647.327562ms]
Feb  6 19:48:33.450: INFO: Created: latency-svc-649s7
Feb  6 19:48:33.458: INFO: Got endpoints: latency-svc-649s7 [646.155258ms]
Feb  6 19:48:33.468: INFO: Created: latency-svc-7r5wn
Feb  6 19:48:33.475: INFO: Created: latency-svc-mxkjq
Feb  6 19:48:33.477: INFO: Got endpoints: latency-svc-7r5wn [652.667267ms]
Feb  6 19:48:33.484: INFO: Got endpoints: latency-svc-mxkjq [636.639311ms]
Feb  6 19:48:33.488: INFO: Created: latency-svc-nlqpx
Feb  6 19:48:33.514: INFO: Got endpoints: latency-svc-nlqpx [657.426874ms]
Feb  6 19:48:33.535: INFO: Created: latency-svc-n9dfq
Feb  6 19:48:33.545: INFO: Got endpoints: latency-svc-n9dfq [672.215216ms]
Feb  6 19:48:33.552: INFO: Created: latency-svc-fzgs2
Feb  6 19:48:33.561: INFO: Got endpoints: latency-svc-fzgs2 [672.189224ms]
Feb  6 19:48:33.562: INFO: Created: latency-svc-8tdpt
Feb  6 19:48:33.573: INFO: Got endpoints: latency-svc-8tdpt [669.243799ms]
Feb  6 19:48:33.578: INFO: Created: latency-svc-2pgtw
Feb  6 19:48:33.588: INFO: Got endpoints: latency-svc-2pgtw [662.543567ms]
Feb  6 19:48:33.590: INFO: Created: latency-svc-rtrdj
Feb  6 19:48:33.599: INFO: Got endpoints: latency-svc-rtrdj [539.145237ms]
Feb  6 19:48:33.605: INFO: Created: latency-svc-6dlb4
Feb  6 19:48:33.613: INFO: Got endpoints: latency-svc-6dlb4 [477.105073ms]
Feb  6 19:48:33.623: INFO: Created: latency-svc-kf2l6
Feb  6 19:48:33.633: INFO: Got endpoints: latency-svc-kf2l6 [274.418623ms]
Feb  6 19:48:33.637: INFO: Created: latency-svc-q2cmt
Feb  6 19:48:33.646: INFO: Got endpoints: latency-svc-q2cmt [248.414838ms]
Feb  6 19:48:33.649: INFO: Created: latency-svc-x8ldl
Feb  6 19:48:33.657: INFO: Got endpoints: latency-svc-x8ldl [245.782043ms]
Feb  6 19:48:33.663: INFO: Created: latency-svc-ms7nj
Feb  6 19:48:33.670: INFO: Got endpoints: latency-svc-ms7nj [245.855095ms]
Feb  6 19:48:33.681: INFO: Created: latency-svc-nnz6q
Feb  6 19:48:33.689: INFO: Got endpoints: latency-svc-nnz6q [248.794859ms]
Feb  6 19:48:33.692: INFO: Created: latency-svc-nvxct
Feb  6 19:48:33.710: INFO: Created: latency-svc-jsr78
Feb  6 19:48:33.728: INFO: Created: latency-svc-htcwx
Feb  6 19:48:33.746: INFO: Created: latency-svc-l8hqt
Feb  6 19:48:33.778: INFO: Created: latency-svc-hpbk7
Feb  6 19:48:33.793: INFO: Created: latency-svc-7gwh6
Feb  6 19:48:33.807: INFO: Created: latency-svc-rrkhq
Feb  6 19:48:33.820: INFO: Created: latency-svc-44qtg
Feb  6 19:48:33.820: INFO: Got endpoints: latency-svc-jsr78 [343.266963ms]
Feb  6 19:48:33.821: INFO: Got endpoints: latency-svc-nvxct [362.566707ms]
Feb  6 19:48:33.824: INFO: Got endpoints: latency-svc-l8hqt [309.170173ms]
Feb  6 19:48:33.824: INFO: Got endpoints: latency-svc-htcwx [340.353398ms]
Feb  6 19:48:33.832: INFO: Got endpoints: latency-svc-hpbk7 [287.156099ms]
Feb  6 19:48:33.832: INFO: Got endpoints: latency-svc-7gwh6 [271.570677ms]
Feb  6 19:48:33.837: INFO: Got endpoints: latency-svc-rrkhq [264.771597ms]
Feb  6 19:48:33.839: INFO: Got endpoints: latency-svc-44qtg [250.777552ms]
Feb  6 19:48:33.846: INFO: Created: latency-svc-mg2dg
Feb  6 19:48:33.856: INFO: Got endpoints: latency-svc-mg2dg [256.270375ms]
Feb  6 19:48:33.863: INFO: Created: latency-svc-6vwwg
Feb  6 19:48:33.873: INFO: Got endpoints: latency-svc-6vwwg [259.74616ms]
Feb  6 19:48:33.879: INFO: Created: latency-svc-qvhrf
Feb  6 19:48:33.889: INFO: Got endpoints: latency-svc-qvhrf [256.072045ms]
Feb  6 19:48:33.896: INFO: Created: latency-svc-sd4q7
Feb  6 19:48:33.906: INFO: Got endpoints: latency-svc-sd4q7 [259.959048ms]
Feb  6 19:48:33.908: INFO: Created: latency-svc-7n2pw
Feb  6 19:48:33.916: INFO: Got endpoints: latency-svc-7n2pw [259.349374ms]
Feb  6 19:48:33.925: INFO: Created: latency-svc-z55zd
Feb  6 19:48:33.941: INFO: Got endpoints: latency-svc-z55zd [270.920356ms]
Feb  6 19:48:33.942: INFO: Created: latency-svc-5887w
Feb  6 19:48:33.948: INFO: Got endpoints: latency-svc-5887w [259.865845ms]
Feb  6 19:48:33.949: INFO: Created: latency-svc-smbss
Feb  6 19:48:33.958: INFO: Got endpoints: latency-svc-smbss [137.13454ms]
Feb  6 19:48:33.962: INFO: Created: latency-svc-45hft
Feb  6 19:48:33.970: INFO: Got endpoints: latency-svc-45hft [148.879206ms]
Feb  6 19:48:33.975: INFO: Created: latency-svc-v9lgt
Feb  6 19:48:33.985: INFO: Got endpoints: latency-svc-v9lgt [161.589314ms]
Feb  6 19:48:33.993: INFO: Created: latency-svc-922c5
Feb  6 19:48:34.012: INFO: Got endpoints: latency-svc-922c5 [188.175439ms]
Feb  6 19:48:34.026: INFO: Created: latency-svc-2f5h4
Feb  6 19:48:34.038: INFO: Created: latency-svc-jspgz
Feb  6 19:48:34.053: INFO: Got endpoints: latency-svc-2f5h4 [221.108411ms]
Feb  6 19:48:34.054: INFO: Created: latency-svc-2zdrx
Feb  6 19:48:34.071: INFO: Created: latency-svc-f4clc
Feb  6 19:48:34.080: INFO: Created: latency-svc-gzkcb
Feb  6 19:48:34.094: INFO: Created: latency-svc-fdwtp
Feb  6 19:48:34.096: INFO: Got endpoints: latency-svc-jspgz [263.56969ms]
Feb  6 19:48:34.114: INFO: Created: latency-svc-zzrdj
Feb  6 19:48:34.173: INFO: Got endpoints: latency-svc-2zdrx [335.934275ms]
Feb  6 19:48:34.178: INFO: Created: latency-svc-gp9ll
Feb  6 19:48:34.192: INFO: Created: latency-svc-jlm4v
Feb  6 19:48:34.196: INFO: Got endpoints: latency-svc-f4clc [357.080122ms]
Feb  6 19:48:34.203: INFO: Created: latency-svc-s2nbp
Feb  6 19:48:34.224: INFO: Created: latency-svc-qv458
Feb  6 19:48:34.243: INFO: Created: latency-svc-swldn
Feb  6 19:48:34.250: INFO: Got endpoints: latency-svc-gzkcb [394.046021ms]
Feb  6 19:48:34.258: INFO: Created: latency-svc-v77zm
Feb  6 19:48:34.283: INFO: Created: latency-svc-sspdn
Feb  6 19:48:34.293: INFO: Created: latency-svc-5x4mg
Feb  6 19:48:34.296: INFO: Got endpoints: latency-svc-fdwtp [422.380013ms]
Feb  6 19:48:34.312: INFO: Created: latency-svc-vjrkm
Feb  6 19:48:34.326: INFO: Created: latency-svc-kzb56
Feb  6 19:48:34.349: INFO: Got endpoints: latency-svc-zzrdj [459.869019ms]
Feb  6 19:48:34.356: INFO: Created: latency-svc-5c5lx
Feb  6 19:48:34.376: INFO: Created: latency-svc-pptb4
Feb  6 19:48:34.391: INFO: Created: latency-svc-7f622
Feb  6 19:48:34.394: INFO: Got endpoints: latency-svc-gp9ll [488.535517ms]
Feb  6 19:48:34.409: INFO: Created: latency-svc-982kv
Feb  6 19:48:34.424: INFO: Created: latency-svc-vw99p
Feb  6 19:48:34.438: INFO: Created: latency-svc-9ph6b
Feb  6 19:48:34.448: INFO: Got endpoints: latency-svc-jlm4v [531.929967ms]
Feb  6 19:48:34.466: INFO: Created: latency-svc-s7p54
Feb  6 19:48:34.492: INFO: Got endpoints: latency-svc-s2nbp [550.477786ms]
Feb  6 19:48:34.521: INFO: Created: latency-svc-8hscs
Feb  6 19:48:34.541: INFO: Got endpoints: latency-svc-qv458 [592.923821ms]
Feb  6 19:48:34.563: INFO: Created: latency-svc-jc5gm
Feb  6 19:48:34.596: INFO: Got endpoints: latency-svc-swldn [638.702878ms]
Feb  6 19:48:34.626: INFO: Created: latency-svc-xtkt9
Feb  6 19:48:34.642: INFO: Got endpoints: latency-svc-v77zm [672.462704ms]
Feb  6 19:48:34.659: INFO: Created: latency-svc-fgg2r
Feb  6 19:48:34.691: INFO: Got endpoints: latency-svc-sspdn [705.623527ms]
Feb  6 19:48:34.713: INFO: Created: latency-svc-gmnzt
Feb  6 19:48:34.742: INFO: Got endpoints: latency-svc-5x4mg [729.880061ms]
Feb  6 19:48:34.763: INFO: Created: latency-svc-8fh6d
Feb  6 19:48:34.798: INFO: Got endpoints: latency-svc-vjrkm [744.807762ms]
Feb  6 19:48:34.839: INFO: Created: latency-svc-96kzd
Feb  6 19:48:34.843: INFO: Got endpoints: latency-svc-kzb56 [747.129005ms]
Feb  6 19:48:34.864: INFO: Created: latency-svc-w7qz6
Feb  6 19:48:34.893: INFO: Got endpoints: latency-svc-5c5lx [719.765267ms]
Feb  6 19:48:34.920: INFO: Created: latency-svc-srlwp
Feb  6 19:48:34.946: INFO: Got endpoints: latency-svc-pptb4 [749.329684ms]
Feb  6 19:48:34.966: INFO: Created: latency-svc-76rg5
Feb  6 19:48:34.990: INFO: Got endpoints: latency-svc-7f622 [740.545084ms]
Feb  6 19:48:35.006: INFO: Created: latency-svc-kcj46
Feb  6 19:48:35.041: INFO: Got endpoints: latency-svc-982kv [745.450837ms]
Feb  6 19:48:35.061: INFO: Created: latency-svc-wpft2
Feb  6 19:48:35.092: INFO: Got endpoints: latency-svc-vw99p [743.152241ms]
Feb  6 19:48:35.110: INFO: Created: latency-svc-qmpb6
Feb  6 19:48:35.142: INFO: Got endpoints: latency-svc-9ph6b [747.895418ms]
Feb  6 19:48:35.161: INFO: Created: latency-svc-rw697
Feb  6 19:48:35.191: INFO: Got endpoints: latency-svc-s7p54 [743.058046ms]
Feb  6 19:48:35.211: INFO: Created: latency-svc-pdj4t
Feb  6 19:48:35.241: INFO: Got endpoints: latency-svc-8hscs [748.98008ms]
Feb  6 19:48:35.259: INFO: Created: latency-svc-nl8hv
Feb  6 19:48:35.292: INFO: Got endpoints: latency-svc-jc5gm [750.918774ms]
Feb  6 19:48:35.309: INFO: Created: latency-svc-4s2tq
Feb  6 19:48:35.346: INFO: Got endpoints: latency-svc-xtkt9 [749.299952ms]
Feb  6 19:48:35.367: INFO: Created: latency-svc-rhqgp
Feb  6 19:48:35.393: INFO: Got endpoints: latency-svc-fgg2r [750.496919ms]
Feb  6 19:48:35.416: INFO: Created: latency-svc-rf8g2
Feb  6 19:48:35.442: INFO: Got endpoints: latency-svc-gmnzt [751.269541ms]
Feb  6 19:48:35.459: INFO: Created: latency-svc-vhl5x
Feb  6 19:48:35.493: INFO: Got endpoints: latency-svc-8fh6d [751.384959ms]
Feb  6 19:48:35.508: INFO: Created: latency-svc-5d2j4
Feb  6 19:48:35.543: INFO: Got endpoints: latency-svc-96kzd [745.346212ms]
Feb  6 19:48:35.563: INFO: Created: latency-svc-69vzx
Feb  6 19:48:35.591: INFO: Got endpoints: latency-svc-w7qz6 [748.327338ms]
Feb  6 19:48:35.611: INFO: Created: latency-svc-876x4
Feb  6 19:48:35.642: INFO: Got endpoints: latency-svc-srlwp [749.280999ms]
Feb  6 19:48:35.659: INFO: Created: latency-svc-jwfzk
Feb  6 19:48:35.692: INFO: Got endpoints: latency-svc-76rg5 [746.23467ms]
Feb  6 19:48:35.713: INFO: Created: latency-svc-f9qmp
Feb  6 19:48:35.743: INFO: Got endpoints: latency-svc-kcj46 [752.757366ms]
Feb  6 19:48:35.761: INFO: Created: latency-svc-xclzg
Feb  6 19:48:35.791: INFO: Got endpoints: latency-svc-wpft2 [749.814876ms]
Feb  6 19:48:35.812: INFO: Created: latency-svc-ndw7n
Feb  6 19:48:35.842: INFO: Got endpoints: latency-svc-qmpb6 [749.46667ms]
Feb  6 19:48:35.860: INFO: Created: latency-svc-jp2wf
Feb  6 19:48:35.892: INFO: Got endpoints: latency-svc-rw697 [749.736267ms]
Feb  6 19:48:35.913: INFO: Created: latency-svc-mbv4f
Feb  6 19:48:35.942: INFO: Got endpoints: latency-svc-pdj4t [750.537062ms]
Feb  6 19:48:35.959: INFO: Created: latency-svc-nprx4
Feb  6 19:48:35.997: INFO: Got endpoints: latency-svc-nl8hv [756.817434ms]
Feb  6 19:48:36.053: INFO: Created: latency-svc-ssljx
Feb  6 19:48:36.071: INFO: Got endpoints: latency-svc-4s2tq [779.002609ms]
Feb  6 19:48:36.104: INFO: Created: latency-svc-4pdcz
Feb  6 19:48:36.104: INFO: Got endpoints: latency-svc-rhqgp [758.548507ms]
Feb  6 19:48:36.134: INFO: Created: latency-svc-hq4sm
Feb  6 19:48:36.145: INFO: Got endpoints: latency-svc-rf8g2 [752.396016ms]
Feb  6 19:48:36.165: INFO: Created: latency-svc-nppq8
Feb  6 19:48:36.191: INFO: Got endpoints: latency-svc-vhl5x [748.296821ms]
Feb  6 19:48:36.210: INFO: Created: latency-svc-fxgxn
Feb  6 19:48:36.241: INFO: Got endpoints: latency-svc-5d2j4 [747.225176ms]
Feb  6 19:48:36.258: INFO: Created: latency-svc-hk4dc
Feb  6 19:48:36.292: INFO: Got endpoints: latency-svc-69vzx [748.385842ms]
Feb  6 19:48:36.312: INFO: Created: latency-svc-jg4rg
Feb  6 19:48:36.341: INFO: Got endpoints: latency-svc-876x4 [749.269427ms]
Feb  6 19:48:36.373: INFO: Created: latency-svc-wv76h
Feb  6 19:48:36.393: INFO: Got endpoints: latency-svc-jwfzk [750.297281ms]
Feb  6 19:48:36.411: INFO: Created: latency-svc-6m9qt
Feb  6 19:48:36.442: INFO: Got endpoints: latency-svc-f9qmp [749.613006ms]
Feb  6 19:48:36.461: INFO: Created: latency-svc-s6857
Feb  6 19:48:36.493: INFO: Got endpoints: latency-svc-xclzg [749.727335ms]
Feb  6 19:48:36.514: INFO: Created: latency-svc-g6jqd
Feb  6 19:48:36.541: INFO: Got endpoints: latency-svc-ndw7n [750.442515ms]
Feb  6 19:48:36.557: INFO: Created: latency-svc-zr8l6
Feb  6 19:48:36.594: INFO: Got endpoints: latency-svc-jp2wf [752.219291ms]
Feb  6 19:48:36.611: INFO: Created: latency-svc-g4929
Feb  6 19:48:36.642: INFO: Got endpoints: latency-svc-mbv4f [749.715135ms]
Feb  6 19:48:36.658: INFO: Created: latency-svc-gj8qm
Feb  6 19:48:36.691: INFO: Got endpoints: latency-svc-nprx4 [749.455436ms]
Feb  6 19:48:36.716: INFO: Created: latency-svc-rdddb
Feb  6 19:48:36.741: INFO: Got endpoints: latency-svc-ssljx [743.567621ms]
Feb  6 19:48:36.758: INFO: Created: latency-svc-2z76w
Feb  6 19:48:36.792: INFO: Got endpoints: latency-svc-4pdcz [720.550255ms]
Feb  6 19:48:36.809: INFO: Created: latency-svc-ltxsm
Feb  6 19:48:36.841: INFO: Got endpoints: latency-svc-hq4sm [736.4058ms]
Feb  6 19:48:36.857: INFO: Created: latency-svc-j9l6c
Feb  6 19:48:36.891: INFO: Got endpoints: latency-svc-nppq8 [745.451785ms]
Feb  6 19:48:36.909: INFO: Created: latency-svc-d5qnr
Feb  6 19:48:36.941: INFO: Got endpoints: latency-svc-fxgxn [750.388702ms]
Feb  6 19:48:36.957: INFO: Created: latency-svc-k2b5j
Feb  6 19:48:36.992: INFO: Got endpoints: latency-svc-hk4dc [750.800598ms]
Feb  6 19:48:37.011: INFO: Created: latency-svc-kjsgq
Feb  6 19:48:37.043: INFO: Got endpoints: latency-svc-jg4rg [750.838967ms]
Feb  6 19:48:37.062: INFO: Created: latency-svc-64vz7
Feb  6 19:48:37.091: INFO: Got endpoints: latency-svc-wv76h [750.286248ms]
Feb  6 19:48:37.110: INFO: Created: latency-svc-9qnc4
Feb  6 19:48:37.141: INFO: Got endpoints: latency-svc-6m9qt [748.093943ms]
Feb  6 19:48:37.157: INFO: Created: latency-svc-vjl45
Feb  6 19:48:37.191: INFO: Got endpoints: latency-svc-s6857 [749.184535ms]
Feb  6 19:48:37.208: INFO: Created: latency-svc-bnq49
Feb  6 19:48:37.241: INFO: Got endpoints: latency-svc-g6jqd [748.023991ms]
Feb  6 19:48:37.262: INFO: Created: latency-svc-rwcq6
Feb  6 19:48:37.291: INFO: Got endpoints: latency-svc-zr8l6 [749.166713ms]
Feb  6 19:48:37.307: INFO: Created: latency-svc-wpm2c
Feb  6 19:48:37.344: INFO: Got endpoints: latency-svc-g4929 [750.14628ms]
Feb  6 19:48:37.363: INFO: Created: latency-svc-4bpl9
Feb  6 19:48:37.391: INFO: Got endpoints: latency-svc-gj8qm [749.376433ms]
Feb  6 19:48:37.410: INFO: Created: latency-svc-gnkz9
Feb  6 19:48:37.442: INFO: Got endpoints: latency-svc-rdddb [751.144584ms]
Feb  6 19:48:37.462: INFO: Created: latency-svc-hb4v6
Feb  6 19:48:37.494: INFO: Got endpoints: latency-svc-2z76w [753.312962ms]
Feb  6 19:48:37.517: INFO: Created: latency-svc-mpntk
Feb  6 19:48:37.540: INFO: Got endpoints: latency-svc-ltxsm [748.475241ms]
Feb  6 19:48:37.566: INFO: Created: latency-svc-z9d8k
Feb  6 19:48:37.591: INFO: Got endpoints: latency-svc-j9l6c [750.503469ms]
Feb  6 19:48:37.613: INFO: Created: latency-svc-bm7vl
Feb  6 19:48:37.642: INFO: Got endpoints: latency-svc-d5qnr [751.256233ms]
Feb  6 19:48:37.659: INFO: Created: latency-svc-p6zmv
Feb  6 19:48:37.703: INFO: Got endpoints: latency-svc-k2b5j [761.625385ms]
Feb  6 19:48:37.720: INFO: Created: latency-svc-ft6l9
Feb  6 19:48:37.743: INFO: Got endpoints: latency-svc-kjsgq [751.178673ms]
Feb  6 19:48:37.759: INFO: Created: latency-svc-h59tv
Feb  6 19:48:37.793: INFO: Got endpoints: latency-svc-64vz7 [749.760596ms]
Feb  6 19:48:37.811: INFO: Created: latency-svc-6wtcw
Feb  6 19:48:37.844: INFO: Got endpoints: latency-svc-9qnc4 [753.275054ms]
Feb  6 19:48:37.860: INFO: Created: latency-svc-ms2wh
Feb  6 19:48:37.891: INFO: Got endpoints: latency-svc-vjl45 [750.418281ms]
Feb  6 19:48:37.909: INFO: Created: latency-svc-4qf8s
Feb  6 19:48:37.941: INFO: Got endpoints: latency-svc-bnq49 [750.250392ms]
Feb  6 19:48:37.963: INFO: Created: latency-svc-fvmpj
Feb  6 19:48:37.992: INFO: Got endpoints: latency-svc-rwcq6 [750.721146ms]
Feb  6 19:48:38.011: INFO: Created: latency-svc-zsv4w
Feb  6 19:48:38.043: INFO: Got endpoints: latency-svc-wpm2c [752.317053ms]
Feb  6 19:48:38.078: INFO: Created: latency-svc-jbkx4
Feb  6 19:48:38.093: INFO: Got endpoints: latency-svc-4bpl9 [748.619009ms]
Feb  6 19:48:38.111: INFO: Created: latency-svc-mfsm8
Feb  6 19:48:38.141: INFO: Got endpoints: latency-svc-gnkz9 [750.378378ms]
Feb  6 19:48:38.163: INFO: Created: latency-svc-jfmls
Feb  6 19:48:38.191: INFO: Got endpoints: latency-svc-hb4v6 [748.165906ms]
Feb  6 19:48:38.209: INFO: Created: latency-svc-b847j
Feb  6 19:48:38.241: INFO: Got endpoints: latency-svc-mpntk [746.725096ms]
Feb  6 19:48:38.268: INFO: Created: latency-svc-6824m
Feb  6 19:48:38.295: INFO: Got endpoints: latency-svc-z9d8k [754.165169ms]
Feb  6 19:48:38.312: INFO: Created: latency-svc-n6682
Feb  6 19:48:38.341: INFO: Got endpoints: latency-svc-bm7vl [749.631677ms]
Feb  6 19:48:38.359: INFO: Created: latency-svc-fvw5c
Feb  6 19:48:38.393: INFO: Got endpoints: latency-svc-p6zmv [751.456124ms]
Feb  6 19:48:38.410: INFO: Created: latency-svc-7nh9g
Feb  6 19:48:38.441: INFO: Got endpoints: latency-svc-ft6l9 [738.472975ms]
Feb  6 19:48:38.458: INFO: Created: latency-svc-9wlxj
Feb  6 19:48:38.493: INFO: Got endpoints: latency-svc-h59tv [750.009583ms]
Feb  6 19:48:38.516: INFO: Created: latency-svc-v2tvt
Feb  6 19:48:38.541: INFO: Got endpoints: latency-svc-6wtcw [748.312565ms]
Feb  6 19:48:38.556: INFO: Created: latency-svc-c2qgx
Feb  6 19:48:38.592: INFO: Got endpoints: latency-svc-ms2wh [747.602286ms]
Feb  6 19:48:38.614: INFO: Created: latency-svc-nbnd5
Feb  6 19:48:38.641: INFO: Got endpoints: latency-svc-4qf8s [749.356698ms]
Feb  6 19:48:38.656: INFO: Created: latency-svc-p5qbx
Feb  6 19:48:38.691: INFO: Got endpoints: latency-svc-fvmpj [750.396776ms]
Feb  6 19:48:38.710: INFO: Created: latency-svc-dglsd
Feb  6 19:48:38.743: INFO: Got endpoints: latency-svc-zsv4w [751.438636ms]
Feb  6 19:48:38.762: INFO: Created: latency-svc-6j5wj
Feb  6 19:48:38.794: INFO: Got endpoints: latency-svc-jbkx4 [751.390477ms]
Feb  6 19:48:38.814: INFO: Created: latency-svc-qf4zp
Feb  6 19:48:38.843: INFO: Got endpoints: latency-svc-mfsm8 [750.158258ms]
Feb  6 19:48:38.861: INFO: Created: latency-svc-l76xt
Feb  6 19:48:38.891: INFO: Got endpoints: latency-svc-jfmls [749.543904ms]
Feb  6 19:48:38.910: INFO: Created: latency-svc-wgdb7
Feb  6 19:48:38.941: INFO: Got endpoints: latency-svc-b847j [750.121373ms]
Feb  6 19:48:38.979: INFO: Created: latency-svc-ftcg9
Feb  6 19:48:38.994: INFO: Got endpoints: latency-svc-6824m [752.633047ms]
Feb  6 19:48:39.013: INFO: Created: latency-svc-4xx9n
Feb  6 19:48:39.043: INFO: Got endpoints: latency-svc-n6682 [748.502406ms]
Feb  6 19:48:39.062: INFO: Created: latency-svc-2nn52
Feb  6 19:48:39.134: INFO: Got endpoints: latency-svc-fvw5c [793.460419ms]
Feb  6 19:48:39.150: INFO: Got endpoints: latency-svc-7nh9g [756.647777ms]
Feb  6 19:48:39.157: INFO: Created: latency-svc-4rt2n
Feb  6 19:48:39.177: INFO: Created: latency-svc-rkvqz
Feb  6 19:48:39.193: INFO: Got endpoints: latency-svc-9wlxj [751.882731ms]
Feb  6 19:48:39.214: INFO: Created: latency-svc-jvxkz
Feb  6 19:48:39.245: INFO: Got endpoints: latency-svc-v2tvt [752.029163ms]
Feb  6 19:48:39.263: INFO: Created: latency-svc-vrnm7
Feb  6 19:48:39.291: INFO: Got endpoints: latency-svc-c2qgx [750.069694ms]
Feb  6 19:48:39.317: INFO: Created: latency-svc-b757p
Feb  6 19:48:39.341: INFO: Got endpoints: latency-svc-nbnd5 [749.341985ms]
Feb  6 19:48:39.371: INFO: Created: latency-svc-pnw5d
Feb  6 19:48:39.392: INFO: Got endpoints: latency-svc-p5qbx [751.619841ms]
Feb  6 19:48:39.417: INFO: Created: latency-svc-lggc6
Feb  6 19:48:39.441: INFO: Got endpoints: latency-svc-dglsd [749.485381ms]
Feb  6 19:48:39.460: INFO: Created: latency-svc-zxqhz
Feb  6 19:48:39.494: INFO: Got endpoints: latency-svc-6j5wj [751.0401ms]
Feb  6 19:48:39.512: INFO: Created: latency-svc-pqlzh
Feb  6 19:48:39.546: INFO: Got endpoints: latency-svc-qf4zp [751.423225ms]
Feb  6 19:48:39.570: INFO: Created: latency-svc-5qcnf
Feb  6 19:48:39.596: INFO: Got endpoints: latency-svc-l76xt [752.836916ms]
Feb  6 19:48:39.613: INFO: Created: latency-svc-cj7kd
Feb  6 19:48:39.641: INFO: Got endpoints: latency-svc-wgdb7 [749.686002ms]
Feb  6 19:48:39.658: INFO: Created: latency-svc-k9q7q
Feb  6 19:48:39.691: INFO: Got endpoints: latency-svc-ftcg9 [750.294037ms]
Feb  6 19:48:39.709: INFO: Created: latency-svc-mjhts
Feb  6 19:48:39.746: INFO: Got endpoints: latency-svc-4xx9n [752.147885ms]
Feb  6 19:48:39.763: INFO: Created: latency-svc-p94j9
Feb  6 19:48:39.792: INFO: Got endpoints: latency-svc-2nn52 [748.81826ms]
Feb  6 19:48:39.823: INFO: Created: latency-svc-wmwgp
Feb  6 19:48:39.843: INFO: Got endpoints: latency-svc-4rt2n [708.653379ms]
Feb  6 19:48:39.862: INFO: Created: latency-svc-lr7c8
Feb  6 19:48:39.893: INFO: Got endpoints: latency-svc-rkvqz [742.902209ms]
Feb  6 19:48:39.911: INFO: Created: latency-svc-7sx77
Feb  6 19:48:39.942: INFO: Got endpoints: latency-svc-jvxkz [749.088272ms]
Feb  6 19:48:39.963: INFO: Created: latency-svc-rdbtg
Feb  6 19:48:39.993: INFO: Got endpoints: latency-svc-vrnm7 [748.175993ms]
Feb  6 19:48:40.010: INFO: Created: latency-svc-lgd8h
Feb  6 19:48:40.041: INFO: Got endpoints: latency-svc-b757p [749.982127ms]
Feb  6 19:48:40.056: INFO: Created: latency-svc-gn9jx
Feb  6 19:48:40.091: INFO: Got endpoints: latency-svc-pnw5d [749.906217ms]
Feb  6 19:48:40.117: INFO: Created: latency-svc-6gwzr
Feb  6 19:48:40.142: INFO: Got endpoints: latency-svc-lggc6 [749.339763ms]
Feb  6 19:48:40.160: INFO: Created: latency-svc-4c5l2
Feb  6 19:48:40.192: INFO: Got endpoints: latency-svc-zxqhz [751.103055ms]
Feb  6 19:48:40.212: INFO: Created: latency-svc-7bz2n
Feb  6 19:48:40.242: INFO: Got endpoints: latency-svc-pqlzh [747.813442ms]
Feb  6 19:48:40.262: INFO: Created: latency-svc-z6vrb
Feb  6 19:48:40.295: INFO: Got endpoints: latency-svc-5qcnf [748.73973ms]
Feb  6 19:48:40.311: INFO: Created: latency-svc-l76x4
Feb  6 19:48:40.347: INFO: Got endpoints: latency-svc-cj7kd [750.626876ms]
Feb  6 19:48:40.366: INFO: Created: latency-svc-jjzcm
Feb  6 19:48:40.394: INFO: Got endpoints: latency-svc-k9q7q [752.924778ms]
Feb  6 19:48:40.416: INFO: Created: latency-svc-rb9hz
Feb  6 19:48:40.447: INFO: Got endpoints: latency-svc-mjhts [755.29998ms]
Feb  6 19:48:40.492: INFO: Got endpoints: latency-svc-p94j9 [745.682904ms]
Feb  6 19:48:40.552: INFO: Got endpoints: latency-svc-wmwgp [759.962903ms]
Feb  6 19:48:40.591: INFO: Got endpoints: latency-svc-lr7c8 [747.693422ms]
Feb  6 19:48:40.642: INFO: Got endpoints: latency-svc-7sx77 [749.155513ms]
Feb  6 19:48:40.692: INFO: Got endpoints: latency-svc-rdbtg [750.131277ms]
Feb  6 19:48:40.742: INFO: Got endpoints: latency-svc-lgd8h [748.548514ms]
Feb  6 19:48:40.794: INFO: Got endpoints: latency-svc-gn9jx [752.680497ms]
Feb  6 19:48:40.842: INFO: Got endpoints: latency-svc-6gwzr [750.179546ms]
Feb  6 19:48:40.892: INFO: Got endpoints: latency-svc-4c5l2 [750.42966ms]
Feb  6 19:48:40.943: INFO: Got endpoints: latency-svc-7bz2n [750.347246ms]
Feb  6 19:48:40.993: INFO: Got endpoints: latency-svc-z6vrb [750.966191ms]
Feb  6 19:48:41.045: INFO: Got endpoints: latency-svc-l76x4 [750.754852ms]
Feb  6 19:48:41.093: INFO: Got endpoints: latency-svc-jjzcm [746.642631ms]
Feb  6 19:48:41.142: INFO: Got endpoints: latency-svc-rb9hz [748.489906ms]
Feb  6 19:48:41.142: INFO: Latencies: [64.978123ms 92.788665ms 109.263401ms 131.348602ms 137.13454ms 142.182266ms 148.879206ms 161.589314ms 167.016807ms 182.739296ms 188.175439ms 203.546925ms 221.108411ms 222.968891ms 235.476241ms 245.782043ms 245.855095ms 248.414838ms 248.794859ms 250.777552ms 256.072045ms 256.270375ms 257.808695ms 259.349374ms 259.74616ms 259.865845ms 259.959048ms 263.56969ms 264.771597ms 267.915901ms 270.920356ms 271.570677ms 272.723161ms 274.418623ms 283.506253ms 287.156099ms 299.272055ms 309.170173ms 313.992525ms 335.934275ms 340.353398ms 343.266963ms 357.080122ms 362.566707ms 379.090962ms 394.046021ms 422.380013ms 438.334185ms 459.869019ms 477.105073ms 488.535517ms 531.929967ms 539.145237ms 550.477786ms 592.923821ms 636.639311ms 638.702878ms 638.782054ms 646.155258ms 647.327562ms 652.667267ms 652.732453ms 655.314805ms 657.426874ms 662.543567ms 666.425375ms 669.243799ms 672.189224ms 672.215216ms 672.462704ms 705.623527ms 708.653379ms 719.765267ms 720.550255ms 729.880061ms 736.4058ms 738.472975ms 740.545084ms 742.902209ms 743.058046ms 743.152241ms 743.567621ms 744.807762ms 745.346212ms 745.450837ms 745.451785ms 745.682904ms 746.23467ms 746.642631ms 746.725096ms 747.129005ms 747.225176ms 747.602286ms 747.693422ms 747.813442ms 747.895418ms 748.023991ms 748.093943ms 748.165906ms 748.175993ms 748.296821ms 748.312565ms 748.327338ms 748.385842ms 748.475241ms 748.489906ms 748.502406ms 748.548514ms 748.619009ms 748.73973ms 748.81826ms 748.98008ms 749.088272ms 749.155513ms 749.166713ms 749.184535ms 749.269427ms 749.280999ms 749.299952ms 749.329684ms 749.339763ms 749.341985ms 749.356698ms 749.376433ms 749.455436ms 749.46667ms 749.485381ms 749.543904ms 749.613006ms 749.631677ms 749.686002ms 749.715135ms 749.727335ms 749.736267ms 749.760596ms 749.814876ms 749.906217ms 749.982127ms 750.009583ms 750.069694ms 750.121373ms 750.131277ms 750.14628ms 750.158258ms 750.179546ms 750.250392ms 750.286248ms 750.294037ms 750.297281ms 750.347246ms 750.378378ms 750.388702ms 750.396776ms 750.418281ms 750.42966ms 750.442515ms 750.496919ms 750.503469ms 750.537062ms 750.626876ms 750.721146ms 750.754852ms 750.800598ms 750.838967ms 750.918774ms 750.966191ms 751.0401ms 751.103055ms 751.144584ms 751.178673ms 751.256233ms 751.269541ms 751.384959ms 751.390477ms 751.423225ms 751.438636ms 751.456124ms 751.619841ms 751.882731ms 752.029163ms 752.147885ms 752.219291ms 752.317053ms 752.396016ms 752.633047ms 752.680497ms 752.757366ms 752.836916ms 752.924778ms 753.275054ms 753.312962ms 754.165169ms 755.29998ms 756.647777ms 756.817434ms 758.548507ms 759.962903ms 761.625385ms 779.002609ms 793.460419ms]
Feb  6 19:48:41.142: INFO: 50 %ile: 748.296821ms
Feb  6 19:48:41.142: INFO: 90 %ile: 752.147885ms
Feb  6 19:48:41.142: INFO: 99 %ile: 779.002609ms
Feb  6 19:48:41.142: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:48:41.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-6447" for this suite.
Feb  6 19:49:03.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:49:03.973: INFO: namespace svc-latency-6447 deletion completed in 22.825159567s

• [SLOW TEST:33.716 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:49:03.973: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7610
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-a2a8e0f2-b54f-4983-b8ff-d18c42305d7b
STEP: Creating a pod to test consume configMaps
Feb  6 19:49:04.385: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-44dfb46f-3161-4c0d-88f6-c3a9c1e3f633" in namespace "projected-7610" to be "success or failure"
Feb  6 19:49:04.388: INFO: Pod "pod-projected-configmaps-44dfb46f-3161-4c0d-88f6-c3a9c1e3f633": Phase="Pending", Reason="", readiness=false. Elapsed: 3.237445ms
Feb  6 19:49:06.393: INFO: Pod "pod-projected-configmaps-44dfb46f-3161-4c0d-88f6-c3a9c1e3f633": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008173256s
STEP: Saw pod success
Feb  6 19:49:06.393: INFO: Pod "pod-projected-configmaps-44dfb46f-3161-4c0d-88f6-c3a9c1e3f633" satisfied condition "success or failure"
Feb  6 19:49:06.396: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-projected-configmaps-44dfb46f-3161-4c0d-88f6-c3a9c1e3f633 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 19:49:06.431: INFO: Waiting for pod pod-projected-configmaps-44dfb46f-3161-4c0d-88f6-c3a9c1e3f633 to disappear
Feb  6 19:49:06.435: INFO: Pod pod-projected-configmaps-44dfb46f-3161-4c0d-88f6-c3a9c1e3f633 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:49:06.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7610" for this suite.
Feb  6 19:49:12.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:49:12.915: INFO: namespace projected-7610 deletion completed in 6.475963295s

• [SLOW TEST:8.942 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:49:12.915: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7075
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:49:24.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7075" for this suite.
Feb  6 19:49:30.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:49:30.588: INFO: namespace resourcequota-7075 deletion completed in 6.473862373s

• [SLOW TEST:17.673 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:49:30.588: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1733
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Feb  6 19:49:30.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 create -f - --namespace=kubectl-1733'
Feb  6 19:49:31.214: INFO: stderr: ""
Feb  6 19:49:31.214: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 19:49:31.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1733'
Feb  6 19:49:31.303: INFO: stderr: ""
Feb  6 19:49:31.303: INFO: stdout: "update-demo-nautilus-bn5nt update-demo-nautilus-s7hcl "
Feb  6 19:49:31.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-nautilus-bn5nt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1733'
Feb  6 19:49:31.381: INFO: stderr: ""
Feb  6 19:49:31.381: INFO: stdout: ""
Feb  6 19:49:31.381: INFO: update-demo-nautilus-bn5nt is created but not running
Feb  6 19:49:36.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1733'
Feb  6 19:49:36.485: INFO: stderr: ""
Feb  6 19:49:36.485: INFO: stdout: "update-demo-nautilus-bn5nt update-demo-nautilus-s7hcl "
Feb  6 19:49:36.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-nautilus-bn5nt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1733'
Feb  6 19:49:36.564: INFO: stderr: ""
Feb  6 19:49:36.564: INFO: stdout: "true"
Feb  6 19:49:36.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-nautilus-bn5nt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1733'
Feb  6 19:49:36.641: INFO: stderr: ""
Feb  6 19:49:36.641: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 19:49:36.641: INFO: validating pod update-demo-nautilus-bn5nt
Feb  6 19:49:36.646: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 19:49:36.646: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 19:49:36.646: INFO: update-demo-nautilus-bn5nt is verified up and running
Feb  6 19:49:36.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-nautilus-s7hcl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1733'
Feb  6 19:49:36.724: INFO: stderr: ""
Feb  6 19:49:36.724: INFO: stdout: "true"
Feb  6 19:49:36.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-nautilus-s7hcl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1733'
Feb  6 19:49:36.803: INFO: stderr: ""
Feb  6 19:49:36.803: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 19:49:36.803: INFO: validating pod update-demo-nautilus-s7hcl
Feb  6 19:49:36.809: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 19:49:36.809: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 19:49:36.809: INFO: update-demo-nautilus-s7hcl is verified up and running
STEP: scaling down the replication controller
Feb  6 19:49:36.811: INFO: scanned /root for discovery docs: <nil>
Feb  6 19:49:36.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-1733'
Feb  6 19:49:37.916: INFO: stderr: ""
Feb  6 19:49:37.916: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 19:49:37.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1733'
Feb  6 19:49:37.995: INFO: stderr: ""
Feb  6 19:49:37.995: INFO: stdout: "update-demo-nautilus-bn5nt update-demo-nautilus-s7hcl "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb  6 19:49:42.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1733'
Feb  6 19:49:43.073: INFO: stderr: ""
Feb  6 19:49:43.073: INFO: stdout: "update-demo-nautilus-bn5nt "
Feb  6 19:49:43.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-nautilus-bn5nt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1733'
Feb  6 19:49:43.150: INFO: stderr: ""
Feb  6 19:49:43.150: INFO: stdout: "true"
Feb  6 19:49:43.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-nautilus-bn5nt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1733'
Feb  6 19:49:43.222: INFO: stderr: ""
Feb  6 19:49:43.223: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 19:49:43.223: INFO: validating pod update-demo-nautilus-bn5nt
Feb  6 19:49:43.226: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 19:49:43.226: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 19:49:43.226: INFO: update-demo-nautilus-bn5nt is verified up and running
STEP: scaling up the replication controller
Feb  6 19:49:43.228: INFO: scanned /root for discovery docs: <nil>
Feb  6 19:49:43.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-1733'
Feb  6 19:49:44.333: INFO: stderr: ""
Feb  6 19:49:44.333: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 19:49:44.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1733'
Feb  6 19:49:44.411: INFO: stderr: ""
Feb  6 19:49:44.412: INFO: stdout: "update-demo-nautilus-bn5nt update-demo-nautilus-v5plk "
Feb  6 19:49:44.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-nautilus-bn5nt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1733'
Feb  6 19:49:44.492: INFO: stderr: ""
Feb  6 19:49:44.492: INFO: stdout: "true"
Feb  6 19:49:44.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-nautilus-bn5nt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1733'
Feb  6 19:49:44.569: INFO: stderr: ""
Feb  6 19:49:44.569: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 19:49:44.569: INFO: validating pod update-demo-nautilus-bn5nt
Feb  6 19:49:44.574: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 19:49:44.574: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 19:49:44.574: INFO: update-demo-nautilus-bn5nt is verified up and running
Feb  6 19:49:44.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-nautilus-v5plk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1733'
Feb  6 19:49:44.650: INFO: stderr: ""
Feb  6 19:49:44.651: INFO: stdout: "true"
Feb  6 19:49:44.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods update-demo-nautilus-v5plk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1733'
Feb  6 19:49:44.727: INFO: stderr: ""
Feb  6 19:49:44.727: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 19:49:44.727: INFO: validating pod update-demo-nautilus-v5plk
Feb  6 19:49:44.732: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 19:49:44.732: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 19:49:44.732: INFO: update-demo-nautilus-v5plk is verified up and running
STEP: using delete to clean up resources
Feb  6 19:49:44.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 delete --grace-period=0 --force -f - --namespace=kubectl-1733'
Feb  6 19:49:44.816: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 19:49:44.816: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb  6 19:49:44.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1733'
Feb  6 19:49:44.904: INFO: stderr: "No resources found in kubectl-1733 namespace.\n"
Feb  6 19:49:44.904: INFO: stdout: ""
Feb  6 19:49:44.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods -l name=update-demo --namespace=kubectl-1733 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  6 19:49:44.985: INFO: stderr: ""
Feb  6 19:49:44.985: INFO: stdout: "update-demo-nautilus-bn5nt\nupdate-demo-nautilus-v5plk\n"
Feb  6 19:49:45.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1733'
Feb  6 19:49:45.609: INFO: stderr: "No resources found in kubectl-1733 namespace.\n"
Feb  6 19:49:45.609: INFO: stdout: ""
Feb  6 19:49:45.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 get pods -l name=update-demo --namespace=kubectl-1733 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  6 19:49:45.702: INFO: stderr: ""
Feb  6 19:49:45.702: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:49:45.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1733" for this suite.
Feb  6 19:49:57.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:49:58.187: INFO: namespace kubectl-1733 deletion completed in 12.474487903s

• [SLOW TEST:27.599 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:49:58.188: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2098
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-nvzf
STEP: Creating a pod to test atomic-volume-subpath
Feb  6 19:49:58.348: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-nvzf" in namespace "subpath-2098" to be "success or failure"
Feb  6 19:49:58.353: INFO: Pod "pod-subpath-test-configmap-nvzf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.587444ms
Feb  6 19:50:00.357: INFO: Pod "pod-subpath-test-configmap-nvzf": Phase="Running", Reason="", readiness=true. Elapsed: 2.008312905s
Feb  6 19:50:02.361: INFO: Pod "pod-subpath-test-configmap-nvzf": Phase="Running", Reason="", readiness=true. Elapsed: 4.012261688s
Feb  6 19:50:04.366: INFO: Pod "pod-subpath-test-configmap-nvzf": Phase="Running", Reason="", readiness=true. Elapsed: 6.017399974s
Feb  6 19:50:06.369: INFO: Pod "pod-subpath-test-configmap-nvzf": Phase="Running", Reason="", readiness=true. Elapsed: 8.021000703s
Feb  6 19:50:08.373: INFO: Pod "pod-subpath-test-configmap-nvzf": Phase="Running", Reason="", readiness=true. Elapsed: 10.024549145s
Feb  6 19:50:10.376: INFO: Pod "pod-subpath-test-configmap-nvzf": Phase="Running", Reason="", readiness=true. Elapsed: 12.027867153s
Feb  6 19:50:12.380: INFO: Pod "pod-subpath-test-configmap-nvzf": Phase="Running", Reason="", readiness=true. Elapsed: 14.031667898s
Feb  6 19:50:14.384: INFO: Pod "pod-subpath-test-configmap-nvzf": Phase="Running", Reason="", readiness=true. Elapsed: 16.035405907s
Feb  6 19:50:16.388: INFO: Pod "pod-subpath-test-configmap-nvzf": Phase="Running", Reason="", readiness=true. Elapsed: 18.039267382s
Feb  6 19:50:18.392: INFO: Pod "pod-subpath-test-configmap-nvzf": Phase="Running", Reason="", readiness=true. Elapsed: 20.043130423s
Feb  6 19:50:20.395: INFO: Pod "pod-subpath-test-configmap-nvzf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.046723287s
STEP: Saw pod success
Feb  6 19:50:20.395: INFO: Pod "pod-subpath-test-configmap-nvzf" satisfied condition "success or failure"
Feb  6 19:50:20.398: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-subpath-test-configmap-nvzf container test-container-subpath-configmap-nvzf: <nil>
STEP: delete the pod
Feb  6 19:50:20.420: INFO: Waiting for pod pod-subpath-test-configmap-nvzf to disappear
Feb  6 19:50:20.427: INFO: Pod pod-subpath-test-configmap-nvzf no longer exists
STEP: Deleting pod pod-subpath-test-configmap-nvzf
Feb  6 19:50:20.427: INFO: Deleting pod "pod-subpath-test-configmap-nvzf" in namespace "subpath-2098"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:50:20.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2098" for this suite.
Feb  6 19:50:26.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:50:26.911: INFO: namespace subpath-2098 deletion completed in 6.475993847s

• [SLOW TEST:28.724 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:50:26.912: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8357
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb  6 19:50:27.058: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:50:30.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8357" for this suite.
Feb  6 19:50:42.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:50:43.341: INFO: namespace init-container-8357 deletion completed in 12.475448687s

• [SLOW TEST:16.429 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:50:43.341: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2304
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 19:50:43.493: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Feb  6 19:50:45.694: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:50:46.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2304" for this suite.
Feb  6 19:50:54.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:50:55.184: INFO: namespace replication-controller-2304 deletion completed in 8.477182101s

• [SLOW TEST:11.843 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:50:55.184: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9817
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Feb  6 19:51:05.362: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:51:05.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0206 19:51:05.362867      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-9817" for this suite.
Feb  6 19:51:11.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:51:11.841: INFO: namespace gc-9817 deletion completed in 6.474021607s

• [SLOW TEST:16.657 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:51:11.841: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1656
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb  6 19:51:12.079: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:12.079: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:12.079: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:12.082: INFO: Number of nodes with available pods: 0
Feb  6 19:51:12.082: INFO: Node ip-10-10-1-217.ec2.internal is running more than one daemon pod
Feb  6 19:51:13.095: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:13.095: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:13.096: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:13.099: INFO: Number of nodes with available pods: 0
Feb  6 19:51:13.099: INFO: Node ip-10-10-1-217.ec2.internal is running more than one daemon pod
Feb  6 19:51:14.088: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:14.088: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:14.088: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:14.091: INFO: Number of nodes with available pods: 3
Feb  6 19:51:14.091: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb  6 19:51:14.107: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:14.107: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:14.107: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:14.110: INFO: Number of nodes with available pods: 2
Feb  6 19:51:14.111: INFO: Node ip-10-10-2-209.ec2.internal is running more than one daemon pod
Feb  6 19:51:15.116: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:15.116: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:15.116: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:15.120: INFO: Number of nodes with available pods: 2
Feb  6 19:51:15.120: INFO: Node ip-10-10-2-209.ec2.internal is running more than one daemon pod
Feb  6 19:51:16.116: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:16.116: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:16.117: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:16.122: INFO: Number of nodes with available pods: 2
Feb  6 19:51:16.122: INFO: Node ip-10-10-2-209.ec2.internal is running more than one daemon pod
Feb  6 19:51:17.116: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:17.116: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:17.116: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:17.121: INFO: Number of nodes with available pods: 2
Feb  6 19:51:17.121: INFO: Node ip-10-10-2-209.ec2.internal is running more than one daemon pod
Feb  6 19:51:18.116: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:18.116: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:18.116: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:18.119: INFO: Number of nodes with available pods: 2
Feb  6 19:51:18.119: INFO: Node ip-10-10-2-209.ec2.internal is running more than one daemon pod
Feb  6 19:51:19.116: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:19.116: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:19.116: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:19.119: INFO: Number of nodes with available pods: 2
Feb  6 19:51:19.119: INFO: Node ip-10-10-2-209.ec2.internal is running more than one daemon pod
Feb  6 19:51:20.124: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:20.124: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:20.124: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 19:51:20.127: INFO: Number of nodes with available pods: 3
Feb  6 19:51:20.127: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1656, will wait for the garbage collector to delete the pods
Feb  6 19:51:20.190: INFO: Deleting DaemonSet.extensions daemon-set took: 7.574408ms
Feb  6 19:51:20.291: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.18155ms
Feb  6 19:51:24.694: INFO: Number of nodes with available pods: 0
Feb  6 19:51:24.694: INFO: Number of running nodes: 0, number of available pods: 0
Feb  6 19:51:24.696: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1656/daemonsets","resourceVersion":"79699"},"items":null}

Feb  6 19:51:24.699: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1656/pods","resourceVersion":"79699"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:51:24.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1656" for this suite.
Feb  6 19:51:30.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:51:31.195: INFO: namespace daemonsets-1656 deletion completed in 6.477083838s

• [SLOW TEST:19.353 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:51:31.195: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8743
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 19:51:31.349: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb  6 19:51:36.353: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  6 19:51:36.353: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb  6 19:51:38.357: INFO: Creating deployment "test-rollover-deployment"
Feb  6 19:51:38.366: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb  6 19:51:40.372: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb  6 19:51:40.380: INFO: Ensure that both replica sets have 1 created replica
Feb  6 19:51:40.393: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb  6 19:51:40.402: INFO: Updating deployment test-rollover-deployment
Feb  6 19:51:40.402: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb  6 19:51:42.409: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb  6 19:51:42.414: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb  6 19:51:42.420: INFO: all replica sets need to contain the pod-template-hash label
Feb  6 19:51:42.420: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615498, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615498, loc:(*time.Location)(0x788a6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615500, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615498, loc:(*time.Location)(0x788a6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 19:51:44.427: INFO: all replica sets need to contain the pod-template-hash label
Feb  6 19:51:44.427: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615498, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615498, loc:(*time.Location)(0x788a6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615502, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615498, loc:(*time.Location)(0x788a6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 19:51:46.431: INFO: all replica sets need to contain the pod-template-hash label
Feb  6 19:51:46.431: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615498, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615498, loc:(*time.Location)(0x788a6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615502, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615498, loc:(*time.Location)(0x788a6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 19:51:48.427: INFO: all replica sets need to contain the pod-template-hash label
Feb  6 19:51:48.427: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615498, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615498, loc:(*time.Location)(0x788a6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615502, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615498, loc:(*time.Location)(0x788a6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 19:51:50.428: INFO: all replica sets need to contain the pod-template-hash label
Feb  6 19:51:50.429: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615498, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615498, loc:(*time.Location)(0x788a6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615502, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615498, loc:(*time.Location)(0x788a6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 19:51:52.427: INFO: all replica sets need to contain the pod-template-hash label
Feb  6 19:51:52.427: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615498, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615498, loc:(*time.Location)(0x788a6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615502, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615498, loc:(*time.Location)(0x788a6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 19:51:54.427: INFO: 
Feb  6 19:51:54.427: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb  6 19:51:54.435: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-8743 /apis/apps/v1/namespaces/deployment-8743/deployments/test-rollover-deployment 79add067-cb4a-41b7-a02f-7569524c6cb1 79988 2 2020-02-06 19:51:38 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0051c5e58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-02-06 19:51:38 +0000 UTC,LastTransitionTime:2020-02-06 19:51:38 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2020-02-06 19:51:52 +0000 UTC,LastTransitionTime:2020-02-06 19:51:38 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Feb  6 19:51:54.438: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-8743 /apis/apps/v1/namespaces/deployment-8743/replicasets/test-rollover-deployment-7d7dc6548c a058d6a1-3bcc-4942-be91-ef800f4f7390 79977 2 2020-02-06 19:51:40 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 79add067-cb4a-41b7-a02f-7569524c6cb1 0xc002a38747 0xc002a38748}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002a387f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb  6 19:51:54.438: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb  6 19:51:54.438: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-8743 /apis/apps/v1/namespaces/deployment-8743/replicasets/test-rollover-controller a7effffe-64c8-4bae-954f-c476f667f867 79986 2 2020-02-06 19:51:31 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 79add067-cb4a-41b7-a02f-7569524c6cb1 0xc002a38487 0xc002a38488}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002a38588 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb  6 19:51:54.438: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-8743 /apis/apps/v1/namespaces/deployment-8743/replicasets/test-rollover-deployment-f6c94f66c fa6809d2-73f5-4320-8323-d865639f4d54 79843 2 2020-02-06 19:51:38 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 79add067-cb4a-41b7-a02f-7569524c6cb1 0xc002a388e0 0xc002a388e1}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002a38988 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb  6 19:51:54.441: INFO: Pod "test-rollover-deployment-7d7dc6548c-7jjd8" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-7jjd8 test-rollover-deployment-7d7dc6548c- deployment-8743 /api/v1/namespaces/deployment-8743/pods/test-rollover-deployment-7d7dc6548c-7jjd8 618ca774-e5ac-4c54-8803-ca23cefc3aa1 79866 0 2020-02-06 19:51:40 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[cni.projectcalico.org/podIP:192.168.126.63/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c a058d6a1-3bcc-4942-be91-ef800f4f7390 0xc002a39087 0xc002a39088}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-kppnq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-kppnq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-kppnq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-10-3-246.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 19:51:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 19:51:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 19:51:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 19:51:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.3.246,PodIP:192.168.126.63,StartTime:2020-02-06 19:51:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-06 19:51:41 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://bfa3f141ac4d60935b9a1aa8dbaac1d9b93070703874fcaa189d36cc2f65cb65,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.126.63,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:51:54.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8743" for this suite.
Feb  6 19:52:02.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:52:02.924: INFO: namespace deployment-8743 deletion completed in 8.478877331s

• [SLOW TEST:31.729 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:52:02.925: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7119
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb  6 19:52:07.116: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 19:52:07.119: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 19:52:09.119: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 19:52:09.123: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 19:52:11.119: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 19:52:11.123: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 19:52:13.119: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 19:52:13.123: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 19:52:15.119: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 19:52:15.123: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 19:52:17.119: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 19:52:17.123: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 19:52:19.119: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 19:52:19.123: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 19:52:21.119: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 19:52:21.123: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 19:52:23.119: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 19:52:23.124: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:52:23.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7119" for this suite.
Feb  6 19:52:51.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:52:51.624: INFO: namespace container-lifecycle-hook-7119 deletion completed in 28.474768323s

• [SLOW TEST:48.699 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:52:51.624: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9747
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb  6 19:52:51.771: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  6 19:52:51.784: INFO: Waiting for terminating namespaces to be deleted...
Feb  6 19:52:51.787: INFO: 
Logging pods the kubelet thinks is on node ip-10-10-1-217.ec2.internal before test
Feb  6 19:52:51.808: INFO: kube-proxy-dj7kw from kube-system started at 2020-02-06 15:57:54 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.808: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  6 19:52:51.808: INFO: md-prometheus-operator-operator-f975b4dd9-rw84h from md-prometheus-operator started at 2020-02-06 18:12:39 +0000 UTC (2 container statuses recorded)
Feb  6 19:52:51.808: INFO: 	Container prometheus-operator ready: true, restart count 0
Feb  6 19:52:51.808: INFO: 	Container tls-proxy ready: true, restart count 0
Feb  6 19:52:51.808: INFO: calico-node-hrxsw from kube-system started at 2020-02-06 15:57:54 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.808: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 19:52:51.808: INFO: sonobuoy-systemd-logs-daemon-set-936a433795204ed3-lmxgr from sonobuoy started at 2020-02-06 18:40:06 +0000 UTC (2 container statuses recorded)
Feb  6 19:52:51.808: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb  6 19:52:51.808: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 19:52:51.808: INFO: md-cert-manager-669497f667-mb9js from md-cert-manager started at 2020-02-06 18:11:31 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.808: INFO: 	Container cert-manager ready: true, restart count 0
Feb  6 19:52:51.808: INFO: md-loki-stack-promtail-mmws9 from md-loki-stack started at 2020-02-06 18:12:01 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.808: INFO: 	Container promtail ready: true, restart count 0
Feb  6 19:52:51.808: INFO: md-nginx-ingress-controller-5cff997b69-9qwpx from md-nginx-ingress started at 2020-02-06 18:12:09 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.808: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb  6 19:52:51.808: INFO: md-flux-6d54668955-bl6sl from md-flux started at 2020-02-06 18:11:25 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.808: INFO: 	Container flux ready: true, restart count 0
Feb  6 19:52:51.808: INFO: md-cert-manager-cainjector-7758b57b8d-4j8jj from md-cert-manager started at 2020-02-06 18:11:31 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.808: INFO: 	Container cert-manager ready: true, restart count 0
Feb  6 19:52:51.808: INFO: md-prometheus-operator-prometheus-node-exporter-mxlfh from md-prometheus-operator started at 2020-02-06 18:12:39 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.808: INFO: 	Container node-exporter ready: true, restart count 0
Feb  6 19:52:51.808: INFO: alertmanager-md-prometheus-operator-alertmanager-0 from md-prometheus-operator started at 2020-02-06 19:07:45 +0000 UTC (2 container statuses recorded)
Feb  6 19:52:51.808: INFO: 	Container alertmanager ready: true, restart count 0
Feb  6 19:52:51.808: INFO: 	Container config-reloader ready: true, restart count 0
Feb  6 19:52:51.808: INFO: loki-6877765b9c-2n9vf from md-loki-stack started at 2020-02-06 18:12:01 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.808: INFO: 	Container loki ready: true, restart count 0
Feb  6 19:52:51.808: INFO: prometheus-md-prometheus-operator-prometheus-0 from md-prometheus-operator started at 2020-02-06 18:12:58 +0000 UTC (3 container statuses recorded)
Feb  6 19:52:51.808: INFO: 	Container prometheus ready: true, restart count 1
Feb  6 19:52:51.808: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Feb  6 19:52:51.808: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Feb  6 19:52:51.808: INFO: 
Logging pods the kubelet thinks is on node ip-10-10-2-209.ec2.internal before test
Feb  6 19:52:51.832: INFO: cm-acme-http-solver-9nppr from md-gangway started at 2020-02-06 19:07:48 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.832: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 19:52:51.832: INFO: cm-acme-http-solver-jq4qb from md-prometheus-operator started at 2020-02-06 19:07:48 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.832: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 19:52:51.832: INFO: md-helm-operator-59d9c54dbf-85p6w from md-helm-operator started at 2020-02-06 18:11:03 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.832: INFO: 	Container flux-helm-operator ready: true, restart count 0
Feb  6 19:52:51.832: INFO: md-navigator-moondog-navigator-65f699786c-6sbxm from md-navigator started at 2020-02-06 18:11:28 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.832: INFO: 	Container moondog-navigator ready: true, restart count 0
Feb  6 19:52:51.832: INFO: md-loki-stack-promtail-wl8xd from md-loki-stack started at 2020-02-06 18:12:01 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.832: INFO: 	Container promtail ready: true, restart count 0
Feb  6 19:52:51.832: INFO: cm-acme-http-solver-tg7qw from md-dex started at 2020-02-06 18:12:35 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.832: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 19:52:51.832: INFO: md-prometheus-operator-prometheus-node-exporter-p52sm from md-prometheus-operator started at 2020-02-06 18:12:39 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.832: INFO: 	Container node-exporter ready: true, restart count 0
Feb  6 19:52:51.832: INFO: cm-acme-http-solver-nnxf2 from md-prometheus-operator started at 2020-02-06 19:07:48 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.832: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 19:52:51.832: INFO: cm-acme-http-solver-tmzk6 from md-prometheus-operator started at 2020-02-06 19:07:48 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.832: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 19:52:51.832: INFO: md-flux-memcached-77b577bb4c-z77xr from md-flux started at 2020-02-06 18:11:26 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.832: INFO: 	Container memcached ready: true, restart count 0
Feb  6 19:52:51.832: INFO: md-dex-bfbfd7887-c9sjp from md-dex started at 2020-02-06 18:11:32 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.832: INFO: 	Container main ready: true, restart count 1
Feb  6 19:52:51.832: INFO: md-gangway-548f557b49-v4cb5 from md-gangway started at 2020-02-06 18:11:59 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.832: INFO: 	Container gangway ready: true, restart count 0
Feb  6 19:52:51.832: INFO: md-nginx-ingress-default-backend-7d86d446b4-kp67r from md-nginx-ingress started at 2020-02-06 18:12:09 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.832: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
Feb  6 19:52:51.832: INFO: md-cert-manager-webhook-58b4496d5-lx8m5 from md-cert-manager started at 2020-02-06 19:07:33 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.832: INFO: 	Container cert-manager ready: true, restart count 0
Feb  6 19:52:51.832: INFO: md-prometheus-operator-grafana-6699695c84-cpjdc from md-prometheus-operator started at 2020-02-06 18:12:49 +0000 UTC (2 container statuses recorded)
Feb  6 19:52:51.832: INFO: 	Container grafana ready: true, restart count 0
Feb  6 19:52:51.832: INFO: 	Container grafana-sc-dashboard ready: true, restart count 0
Feb  6 19:52:51.832: INFO: cm-acme-http-solver-9f7tx from md-navigator started at 2020-02-06 19:07:48 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.832: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 19:52:51.832: INFO: calico-node-jcts8 from kube-system started at 2020-02-06 15:57:51 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.832: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 19:52:51.832: INFO: kube-proxy-zp49w from kube-system started at 2020-02-06 15:57:51 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.832: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  6 19:52:51.832: INFO: sonobuoy-systemd-logs-daemon-set-936a433795204ed3-fdsl7 from sonobuoy started at 2020-02-06 18:40:06 +0000 UTC (2 container statuses recorded)
Feb  6 19:52:51.832: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb  6 19:52:51.832: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 19:52:51.832: INFO: md-prometheus-operator-kube-state-metrics-b65d855df-b9v58 from md-prometheus-operator started at 2020-02-06 18:12:39 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.832: INFO: 	Container kube-state-metrics ready: true, restart count 0
Feb  6 19:52:51.832: INFO: 
Logging pods the kubelet thinks is on node ip-10-10-3-246.ec2.internal before test
Feb  6 19:52:51.842: INFO: sonobuoy-systemd-logs-daemon-set-936a433795204ed3-q2qnm from sonobuoy started at 2020-02-06 18:40:06 +0000 UTC (2 container statuses recorded)
Feb  6 19:52:51.842: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb  6 19:52:51.842: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 19:52:51.842: INFO: md-prometheus-operator-prometheus-node-exporter-v8kp7 from md-prometheus-operator started at 2020-02-06 19:07:59 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.842: INFO: 	Container node-exporter ready: true, restart count 0
Feb  6 19:52:51.842: INFO: md-loki-stack-promtail-4r8n6 from md-loki-stack started at 2020-02-06 19:07:59 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.842: INFO: 	Container promtail ready: true, restart count 0
Feb  6 19:52:51.842: INFO: md-oauth2-proxy-5cff658bcc-ghfpp from md-oauth2-proxy started at 2020-02-06 19:51:49 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.842: INFO: 	Container oauth2-proxy ready: false, restart count 3
Feb  6 19:52:51.842: INFO: cm-acme-http-solver-4x9vs from md-oauth2-proxy started at 2020-02-06 19:52:31 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.842: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 19:52:51.842: INFO: calico-node-n4lqx from kube-system started at 2020-02-06 15:57:51 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.842: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 19:52:51.842: INFO: sonobuoy from sonobuoy started at 2020-02-06 18:40:05 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.842: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  6 19:52:51.842: INFO: sonobuoy-e2e-job-7dfb3a3ef75e43b0 from sonobuoy started at 2020-02-06 18:40:06 +0000 UTC (2 container statuses recorded)
Feb  6 19:52:51.842: INFO: 	Container e2e ready: true, restart count 0
Feb  6 19:52:51.842: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 19:52:51.842: INFO: kube-proxy-jfqqq from kube-system started at 2020-02-06 15:57:51 +0000 UTC (1 container statuses recorded)
Feb  6 19:52:51.842: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node ip-10-10-1-217.ec2.internal
STEP: verifying the node has the label node ip-10-10-2-209.ec2.internal
STEP: verifying the node has the label node ip-10-10-3-246.ec2.internal
Feb  6 19:52:51.930: INFO: Pod calico-node-hrxsw requesting resource cpu=250m on Node ip-10-10-1-217.ec2.internal
Feb  6 19:52:51.930: INFO: Pod calico-node-jcts8 requesting resource cpu=250m on Node ip-10-10-2-209.ec2.internal
Feb  6 19:52:51.930: INFO: Pod calico-node-n4lqx requesting resource cpu=250m on Node ip-10-10-3-246.ec2.internal
Feb  6 19:52:51.930: INFO: Pod kube-proxy-dj7kw requesting resource cpu=0m on Node ip-10-10-1-217.ec2.internal
Feb  6 19:52:51.930: INFO: Pod kube-proxy-jfqqq requesting resource cpu=0m on Node ip-10-10-3-246.ec2.internal
Feb  6 19:52:51.930: INFO: Pod kube-proxy-zp49w requesting resource cpu=0m on Node ip-10-10-2-209.ec2.internal
Feb  6 19:52:51.930: INFO: Pod md-cert-manager-669497f667-mb9js requesting resource cpu=0m on Node ip-10-10-1-217.ec2.internal
Feb  6 19:52:51.930: INFO: Pod md-cert-manager-cainjector-7758b57b8d-4j8jj requesting resource cpu=0m on Node ip-10-10-1-217.ec2.internal
Feb  6 19:52:51.930: INFO: Pod md-cert-manager-webhook-58b4496d5-lx8m5 requesting resource cpu=0m on Node ip-10-10-2-209.ec2.internal
Feb  6 19:52:51.930: INFO: Pod cm-acme-http-solver-tg7qw requesting resource cpu=10m on Node ip-10-10-2-209.ec2.internal
Feb  6 19:52:51.930: INFO: Pod md-dex-bfbfd7887-c9sjp requesting resource cpu=0m on Node ip-10-10-2-209.ec2.internal
Feb  6 19:52:51.930: INFO: Pod md-flux-6d54668955-bl6sl requesting resource cpu=50m on Node ip-10-10-1-217.ec2.internal
Feb  6 19:52:51.930: INFO: Pod md-flux-memcached-77b577bb4c-z77xr requesting resource cpu=0m on Node ip-10-10-2-209.ec2.internal
Feb  6 19:52:51.930: INFO: Pod cm-acme-http-solver-9nppr requesting resource cpu=10m on Node ip-10-10-2-209.ec2.internal
Feb  6 19:52:51.930: INFO: Pod md-gangway-548f557b49-v4cb5 requesting resource cpu=0m on Node ip-10-10-2-209.ec2.internal
Feb  6 19:52:51.930: INFO: Pod md-helm-operator-59d9c54dbf-85p6w requesting resource cpu=50m on Node ip-10-10-2-209.ec2.internal
Feb  6 19:52:51.930: INFO: Pod loki-6877765b9c-2n9vf requesting resource cpu=0m on Node ip-10-10-1-217.ec2.internal
Feb  6 19:52:51.930: INFO: Pod md-loki-stack-promtail-4r8n6 requesting resource cpu=0m on Node ip-10-10-3-246.ec2.internal
Feb  6 19:52:51.930: INFO: Pod md-loki-stack-promtail-mmws9 requesting resource cpu=0m on Node ip-10-10-1-217.ec2.internal
Feb  6 19:52:51.930: INFO: Pod md-loki-stack-promtail-wl8xd requesting resource cpu=0m on Node ip-10-10-2-209.ec2.internal
Feb  6 19:52:51.930: INFO: Pod cm-acme-http-solver-9f7tx requesting resource cpu=10m on Node ip-10-10-2-209.ec2.internal
Feb  6 19:52:51.930: INFO: Pod md-navigator-moondog-navigator-65f699786c-6sbxm requesting resource cpu=0m on Node ip-10-10-2-209.ec2.internal
Feb  6 19:52:51.930: INFO: Pod md-nginx-ingress-controller-5cff997b69-9qwpx requesting resource cpu=0m on Node ip-10-10-1-217.ec2.internal
Feb  6 19:52:51.930: INFO: Pod md-nginx-ingress-default-backend-7d86d446b4-kp67r requesting resource cpu=0m on Node ip-10-10-2-209.ec2.internal
Feb  6 19:52:51.930: INFO: Pod cm-acme-http-solver-4x9vs requesting resource cpu=10m on Node ip-10-10-3-246.ec2.internal
Feb  6 19:52:51.930: INFO: Pod md-oauth2-proxy-5cff658bcc-ghfpp requesting resource cpu=0m on Node ip-10-10-3-246.ec2.internal
Feb  6 19:52:51.930: INFO: Pod alertmanager-md-prometheus-operator-alertmanager-0 requesting resource cpu=100m on Node ip-10-10-1-217.ec2.internal
Feb  6 19:52:51.930: INFO: Pod cm-acme-http-solver-jq4qb requesting resource cpu=10m on Node ip-10-10-2-209.ec2.internal
Feb  6 19:52:51.930: INFO: Pod cm-acme-http-solver-nnxf2 requesting resource cpu=10m on Node ip-10-10-2-209.ec2.internal
Feb  6 19:52:51.930: INFO: Pod cm-acme-http-solver-tmzk6 requesting resource cpu=10m on Node ip-10-10-2-209.ec2.internal
Feb  6 19:52:51.930: INFO: Pod md-prometheus-operator-grafana-6699695c84-cpjdc requesting resource cpu=0m on Node ip-10-10-2-209.ec2.internal
Feb  6 19:52:51.930: INFO: Pod md-prometheus-operator-kube-state-metrics-b65d855df-b9v58 requesting resource cpu=0m on Node ip-10-10-2-209.ec2.internal
Feb  6 19:52:51.930: INFO: Pod md-prometheus-operator-operator-f975b4dd9-rw84h requesting resource cpu=0m on Node ip-10-10-1-217.ec2.internal
Feb  6 19:52:51.930: INFO: Pod md-prometheus-operator-prometheus-node-exporter-mxlfh requesting resource cpu=0m on Node ip-10-10-1-217.ec2.internal
Feb  6 19:52:51.930: INFO: Pod md-prometheus-operator-prometheus-node-exporter-p52sm requesting resource cpu=0m on Node ip-10-10-2-209.ec2.internal
Feb  6 19:52:51.930: INFO: Pod md-prometheus-operator-prometheus-node-exporter-v8kp7 requesting resource cpu=0m on Node ip-10-10-3-246.ec2.internal
Feb  6 19:52:51.930: INFO: Pod prometheus-md-prometheus-operator-prometheus-0 requesting resource cpu=200m on Node ip-10-10-1-217.ec2.internal
Feb  6 19:52:51.930: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-10-10-3-246.ec2.internal
Feb  6 19:52:51.930: INFO: Pod sonobuoy-e2e-job-7dfb3a3ef75e43b0 requesting resource cpu=0m on Node ip-10-10-3-246.ec2.internal
Feb  6 19:52:51.930: INFO: Pod sonobuoy-systemd-logs-daemon-set-936a433795204ed3-fdsl7 requesting resource cpu=0m on Node ip-10-10-2-209.ec2.internal
Feb  6 19:52:51.930: INFO: Pod sonobuoy-systemd-logs-daemon-set-936a433795204ed3-lmxgr requesting resource cpu=0m on Node ip-10-10-1-217.ec2.internal
Feb  6 19:52:51.930: INFO: Pod sonobuoy-systemd-logs-daemon-set-936a433795204ed3-q2qnm requesting resource cpu=0m on Node ip-10-10-3-246.ec2.internal
STEP: Starting Pods to consume most of the cluster CPU.
Feb  6 19:52:51.930: INFO: Creating a pod which consumes cpu=980m on Node ip-10-10-1-217.ec2.internal
Feb  6 19:52:51.937: INFO: Creating a pod which consumes cpu=1148m on Node ip-10-10-2-209.ec2.internal
Feb  6 19:52:51.942: INFO: Creating a pod which consumes cpu=1218m on Node ip-10-10-3-246.ec2.internal
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-51b84a50-7852-43c6-9f08-c5151179692f.15f0e8324e28ef67], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9747/filler-pod-51b84a50-7852-43c6-9f08-c5151179692f to ip-10-10-3-246.ec2.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-51b84a50-7852-43c6-9f08-c5151179692f.15f0e83280aec83c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-51b84a50-7852-43c6-9f08-c5151179692f.15f0e832826bb261], Reason = [Created], Message = [Created container filler-pod-51b84a50-7852-43c6-9f08-c5151179692f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-51b84a50-7852-43c6-9f08-c5151179692f.15f0e8328a7337bc], Reason = [Started], Message = [Started container filler-pod-51b84a50-7852-43c6-9f08-c5151179692f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-521adfe7-bc2f-4ec8-868d-696bd62e27f6.15f0e8324d716f17], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9747/filler-pod-521adfe7-bc2f-4ec8-868d-696bd62e27f6 to ip-10-10-1-217.ec2.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-521adfe7-bc2f-4ec8-868d-696bd62e27f6.15f0e8327ef6a2e1], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-521adfe7-bc2f-4ec8-868d-696bd62e27f6.15f0e83281d4170a], Reason = [Created], Message = [Created container filler-pod-521adfe7-bc2f-4ec8-868d-696bd62e27f6]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-521adfe7-bc2f-4ec8-868d-696bd62e27f6.15f0e8328a14b5ca], Reason = [Started], Message = [Started container filler-pod-521adfe7-bc2f-4ec8-868d-696bd62e27f6]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b8ecad34-153b-4fb8-b99f-f8012b713a81.15f0e8324db9f860], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9747/filler-pod-b8ecad34-153b-4fb8-b99f-f8012b713a81 to ip-10-10-2-209.ec2.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b8ecad34-153b-4fb8-b99f-f8012b713a81.15f0e8328078d6e2], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b8ecad34-153b-4fb8-b99f-f8012b713a81.15f0e83283049b33], Reason = [Created], Message = [Created container filler-pod-b8ecad34-153b-4fb8-b99f-f8012b713a81]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b8ecad34-153b-4fb8-b99f-f8012b713a81.15f0e8328ce34add], Reason = [Started], Message = [Started container filler-pod-b8ecad34-153b-4fb8-b99f-f8012b713a81]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15f0e832c6709847], Reason = [FailedScheduling], Message = [0/6 nodes are available: 3 Insufficient cpu, 3 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node ip-10-10-3-246.ec2.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-10-1-217.ec2.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-10-2-209.ec2.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:52:55.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9747" for this suite.
Feb  6 19:53:01.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:53:01.512: INFO: namespace sched-pred-9747 deletion completed in 6.480540364s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:9.888 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:53:01.512: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2695
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 19:53:01.698: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb  6 19:53:01.705: INFO: Number of nodes with available pods: 0
Feb  6 19:53:01.705: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb  6 19:53:01.730: INFO: Number of nodes with available pods: 0
Feb  6 19:53:01.730: INFO: Node ip-10-10-1-217.ec2.internal is running more than one daemon pod
Feb  6 19:53:02.735: INFO: Number of nodes with available pods: 0
Feb  6 19:53:02.735: INFO: Node ip-10-10-1-217.ec2.internal is running more than one daemon pod
Feb  6 19:53:03.734: INFO: Number of nodes with available pods: 1
Feb  6 19:53:03.735: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb  6 19:53:03.753: INFO: Number of nodes with available pods: 1
Feb  6 19:53:03.753: INFO: Number of running nodes: 0, number of available pods: 1
Feb  6 19:53:04.757: INFO: Number of nodes with available pods: 0
Feb  6 19:53:04.757: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb  6 19:53:04.765: INFO: Number of nodes with available pods: 0
Feb  6 19:53:04.765: INFO: Node ip-10-10-1-217.ec2.internal is running more than one daemon pod
Feb  6 19:53:05.768: INFO: Number of nodes with available pods: 0
Feb  6 19:53:05.768: INFO: Node ip-10-10-1-217.ec2.internal is running more than one daemon pod
Feb  6 19:53:06.769: INFO: Number of nodes with available pods: 0
Feb  6 19:53:06.769: INFO: Node ip-10-10-1-217.ec2.internal is running more than one daemon pod
Feb  6 19:53:07.768: INFO: Number of nodes with available pods: 0
Feb  6 19:53:07.768: INFO: Node ip-10-10-1-217.ec2.internal is running more than one daemon pod
Feb  6 19:53:08.768: INFO: Number of nodes with available pods: 0
Feb  6 19:53:08.768: INFO: Node ip-10-10-1-217.ec2.internal is running more than one daemon pod
Feb  6 19:53:09.768: INFO: Number of nodes with available pods: 1
Feb  6 19:53:09.768: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2695, will wait for the garbage collector to delete the pods
Feb  6 19:53:09.835: INFO: Deleting DaemonSet.extensions daemon-set took: 8.304204ms
Feb  6 19:53:10.535: INFO: Terminating DaemonSet.extensions daemon-set pods took: 700.246274ms
Feb  6 19:53:24.738: INFO: Number of nodes with available pods: 0
Feb  6 19:53:24.739: INFO: Number of running nodes: 0, number of available pods: 0
Feb  6 19:53:24.741: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2695/daemonsets","resourceVersion":"80629"},"items":null}

Feb  6 19:53:24.744: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2695/pods","resourceVersion":"80629"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:53:24.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2695" for this suite.
Feb  6 19:53:30.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:53:31.248: INFO: namespace daemonsets-2695 deletion completed in 6.47743707s

• [SLOW TEST:29.736 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:53:31.248: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3835
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-c8fefb80-5ca7-4644-9cf1-0cab274ae657 in namespace container-probe-3835
Feb  6 19:53:33.409: INFO: Started pod busybox-c8fefb80-5ca7-4644-9cf1-0cab274ae657 in namespace container-probe-3835
STEP: checking the pod's current state and verifying that restartCount is present
Feb  6 19:53:33.412: INFO: Initial restart count of pod busybox-c8fefb80-5ca7-4644-9cf1-0cab274ae657 is 0
Feb  6 19:54:25.787: INFO: Restart count of pod container-probe-3835/busybox-c8fefb80-5ca7-4644-9cf1-0cab274ae657 is now 1 (52.374976974s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:54:25.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3835" for this suite.
Feb  6 19:54:31.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:54:32.293: INFO: namespace container-probe-3835 deletion completed in 6.485205993s

• [SLOW TEST:61.045 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:54:32.293: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-2750
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:54:34.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2750" for this suite.
Feb  6 19:54:40.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:54:40.997: INFO: namespace emptydir-wrapper-2750 deletion completed in 6.484015908s

• [SLOW TEST:8.704 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:54:40.997: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3132
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-3cfe4308-c6f2-4413-bb0a-6e581d6a8782
STEP: Creating a pod to test consume secrets
Feb  6 19:54:41.157: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9bed5a16-423c-428a-8bfa-6e9883f40d6e" in namespace "projected-3132" to be "success or failure"
Feb  6 19:54:41.160: INFO: Pod "pod-projected-secrets-9bed5a16-423c-428a-8bfa-6e9883f40d6e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.166273ms
Feb  6 19:54:43.163: INFO: Pod "pod-projected-secrets-9bed5a16-423c-428a-8bfa-6e9883f40d6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006664485s
STEP: Saw pod success
Feb  6 19:54:43.163: INFO: Pod "pod-projected-secrets-9bed5a16-423c-428a-8bfa-6e9883f40d6e" satisfied condition "success or failure"
Feb  6 19:54:43.167: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-projected-secrets-9bed5a16-423c-428a-8bfa-6e9883f40d6e container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 19:54:43.199: INFO: Waiting for pod pod-projected-secrets-9bed5a16-423c-428a-8bfa-6e9883f40d6e to disappear
Feb  6 19:54:43.204: INFO: Pod pod-projected-secrets-9bed5a16-423c-428a-8bfa-6e9883f40d6e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:54:43.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3132" for this suite.
Feb  6 19:54:49.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:54:49.860: INFO: namespace projected-3132 deletion completed in 6.651095793s

• [SLOW TEST:8.863 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:54:49.860: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8375
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-ws7j
STEP: Creating a pod to test atomic-volume-subpath
Feb  6 19:54:50.028: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ws7j" in namespace "subpath-8375" to be "success or failure"
Feb  6 19:54:50.031: INFO: Pod "pod-subpath-test-configmap-ws7j": Phase="Pending", Reason="", readiness=false. Elapsed: 2.789078ms
Feb  6 19:54:52.035: INFO: Pod "pod-subpath-test-configmap-ws7j": Phase="Running", Reason="", readiness=true. Elapsed: 2.00680235s
Feb  6 19:54:54.038: INFO: Pod "pod-subpath-test-configmap-ws7j": Phase="Running", Reason="", readiness=true. Elapsed: 4.010503819s
Feb  6 19:54:56.045: INFO: Pod "pod-subpath-test-configmap-ws7j": Phase="Running", Reason="", readiness=true. Elapsed: 6.017492419s
Feb  6 19:54:58.049: INFO: Pod "pod-subpath-test-configmap-ws7j": Phase="Running", Reason="", readiness=true. Elapsed: 8.021219491s
Feb  6 19:55:00.053: INFO: Pod "pod-subpath-test-configmap-ws7j": Phase="Running", Reason="", readiness=true. Elapsed: 10.02511772s
Feb  6 19:55:02.057: INFO: Pod "pod-subpath-test-configmap-ws7j": Phase="Running", Reason="", readiness=true. Elapsed: 12.028931938s
Feb  6 19:55:04.061: INFO: Pod "pod-subpath-test-configmap-ws7j": Phase="Running", Reason="", readiness=true. Elapsed: 14.032642146s
Feb  6 19:55:06.064: INFO: Pod "pod-subpath-test-configmap-ws7j": Phase="Running", Reason="", readiness=true. Elapsed: 16.036521458s
Feb  6 19:55:08.068: INFO: Pod "pod-subpath-test-configmap-ws7j": Phase="Running", Reason="", readiness=true. Elapsed: 18.0404146s
Feb  6 19:55:10.072: INFO: Pod "pod-subpath-test-configmap-ws7j": Phase="Running", Reason="", readiness=true. Elapsed: 20.044026854s
Feb  6 19:55:12.077: INFO: Pod "pod-subpath-test-configmap-ws7j": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.048609826s
STEP: Saw pod success
Feb  6 19:55:12.077: INFO: Pod "pod-subpath-test-configmap-ws7j" satisfied condition "success or failure"
Feb  6 19:55:12.079: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-subpath-test-configmap-ws7j container test-container-subpath-configmap-ws7j: <nil>
STEP: delete the pod
Feb  6 19:55:12.104: INFO: Waiting for pod pod-subpath-test-configmap-ws7j to disappear
Feb  6 19:55:12.107: INFO: Pod pod-subpath-test-configmap-ws7j no longer exists
STEP: Deleting pod pod-subpath-test-configmap-ws7j
Feb  6 19:55:12.107: INFO: Deleting pod "pod-subpath-test-configmap-ws7j" in namespace "subpath-8375"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:55:12.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8375" for this suite.
Feb  6 19:55:18.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:55:18.591: INFO: namespace subpath-8375 deletion completed in 6.476666565s

• [SLOW TEST:28.731 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:55:18.591: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-4105
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 19:55:18.746: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-04941dab-cda0-4230-9f12-c23ad9c076f4" in namespace "security-context-test-4105" to be "success or failure"
Feb  6 19:55:18.748: INFO: Pod "busybox-privileged-false-04941dab-cda0-4230-9f12-c23ad9c076f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.682311ms
Feb  6 19:55:20.763: INFO: Pod "busybox-privileged-false-04941dab-cda0-4230-9f12-c23ad9c076f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016762809s
Feb  6 19:55:20.763: INFO: Pod "busybox-privileged-false-04941dab-cda0-4230-9f12-c23ad9c076f4" satisfied condition "success or failure"
Feb  6 19:55:20.771: INFO: Got logs for pod "busybox-privileged-false-04941dab-cda0-4230-9f12-c23ad9c076f4": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:55:20.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4105" for this suite.
Feb  6 19:55:26.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:55:27.252: INFO: namespace security-context-test-4105 deletion completed in 6.47637756s

• [SLOW TEST:8.661 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:55:27.252: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-9158
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 19:55:27.410: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-c442c463-e96b-4d97-b37f-e31b944b772a" in namespace "security-context-test-9158" to be "success or failure"
Feb  6 19:55:27.413: INFO: Pod "busybox-readonly-false-c442c463-e96b-4d97-b37f-e31b944b772a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.875452ms
Feb  6 19:55:29.417: INFO: Pod "busybox-readonly-false-c442c463-e96b-4d97-b37f-e31b944b772a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006602762s
Feb  6 19:55:29.417: INFO: Pod "busybox-readonly-false-c442c463-e96b-4d97-b37f-e31b944b772a" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:55:29.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9158" for this suite.
Feb  6 19:55:35.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:55:35.896: INFO: namespace security-context-test-9158 deletion completed in 6.474278456s

• [SLOW TEST:8.644 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:55:35.897: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1658
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Feb  6 19:55:36.082: INFO: Waiting up to 5m0s for pod "client-containers-b48e701a-4332-45d5-849e-4a16ea7935a6" in namespace "containers-1658" to be "success or failure"
Feb  6 19:55:36.100: INFO: Pod "client-containers-b48e701a-4332-45d5-849e-4a16ea7935a6": Phase="Pending", Reason="", readiness=false. Elapsed: 17.581695ms
Feb  6 19:55:38.103: INFO: Pod "client-containers-b48e701a-4332-45d5-849e-4a16ea7935a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021061856s
STEP: Saw pod success
Feb  6 19:55:38.103: INFO: Pod "client-containers-b48e701a-4332-45d5-849e-4a16ea7935a6" satisfied condition "success or failure"
Feb  6 19:55:38.106: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod client-containers-b48e701a-4332-45d5-849e-4a16ea7935a6 container test-container: <nil>
STEP: delete the pod
Feb  6 19:55:38.125: INFO: Waiting for pod client-containers-b48e701a-4332-45d5-849e-4a16ea7935a6 to disappear
Feb  6 19:55:38.128: INFO: Pod client-containers-b48e701a-4332-45d5-849e-4a16ea7935a6 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:55:38.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1658" for this suite.
Feb  6 19:55:44.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:55:44.694: INFO: namespace containers-1658 deletion completed in 6.554445263s

• [SLOW TEST:8.797 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:55:44.694: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-462
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:56:07.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-462" for this suite.
Feb  6 19:56:13.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:56:13.558: INFO: namespace container-runtime-462 deletion completed in 6.483143932s

• [SLOW TEST:28.865 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:56:13.559: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-1633
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Feb  6 19:56:13.704: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Feb  6 19:56:14.348: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Feb  6 19:56:16.404: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615774, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615774, loc:(*time.Location)(0x788a6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615774, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615774, loc:(*time.Location)(0x788a6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 19:56:18.408: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615774, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615774, loc:(*time.Location)(0x788a6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615774, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615774, loc:(*time.Location)(0x788a6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 19:56:20.411: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615774, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615774, loc:(*time.Location)(0x788a6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615774, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716615774, loc:(*time.Location)(0x788a6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 19:56:23.448: INFO: Waited 1.025561599s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:56:24.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1633" for this suite.
Feb  6 19:56:30.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:56:30.937: INFO: namespace aggregator-1633 deletion completed in 6.550834146s

• [SLOW TEST:17.378 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:56:30.937: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6216
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb  6 19:56:33.629: INFO: Successfully updated pod "labelsupdate95594c76-61d2-4a62-87f7-6e1aa6e06964"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:56:37.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6216" for this suite.
Feb  6 19:56:49.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:56:50.145: INFO: namespace projected-6216 deletion completed in 12.485576278s

• [SLOW TEST:19.208 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:56:50.146: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1287
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb  6 19:56:54.363: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:56:54.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1287" for this suite.
Feb  6 19:57:00.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:57:00.859: INFO: namespace container-runtime-1287 deletion completed in 6.473805684s

• [SLOW TEST:10.713 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:57:00.859: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2316
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb  6 19:57:01.020: INFO: Waiting up to 5m0s for pod "downward-api-dac3c7e5-0d72-4b49-b6b5-34ccb9d25048" in namespace "downward-api-2316" to be "success or failure"
Feb  6 19:57:01.024: INFO: Pod "downward-api-dac3c7e5-0d72-4b49-b6b5-34ccb9d25048": Phase="Pending", Reason="", readiness=false. Elapsed: 3.711274ms
Feb  6 19:57:03.028: INFO: Pod "downward-api-dac3c7e5-0d72-4b49-b6b5-34ccb9d25048": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007339554s
STEP: Saw pod success
Feb  6 19:57:03.028: INFO: Pod "downward-api-dac3c7e5-0d72-4b49-b6b5-34ccb9d25048" satisfied condition "success or failure"
Feb  6 19:57:03.033: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod downward-api-dac3c7e5-0d72-4b49-b6b5-34ccb9d25048 container dapi-container: <nil>
STEP: delete the pod
Feb  6 19:57:03.077: INFO: Waiting for pod downward-api-dac3c7e5-0d72-4b49-b6b5-34ccb9d25048 to disappear
Feb  6 19:57:03.085: INFO: Pod downward-api-dac3c7e5-0d72-4b49-b6b5-34ccb9d25048 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:57:03.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2316" for this suite.
Feb  6 19:57:09.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:57:09.574: INFO: namespace downward-api-2316 deletion completed in 6.483628951s

• [SLOW TEST:8.715 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:57:09.574: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6163
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-d2635195-fd1e-41d8-8dfb-c0be198ef41c
STEP: Creating a pod to test consume configMaps
Feb  6 19:57:09.736: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6dd73995-fe89-42f7-a146-7be140df8f2d" in namespace "projected-6163" to be "success or failure"
Feb  6 19:57:09.739: INFO: Pod "pod-projected-configmaps-6dd73995-fe89-42f7-a146-7be140df8f2d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.908929ms
Feb  6 19:57:11.743: INFO: Pod "pod-projected-configmaps-6dd73995-fe89-42f7-a146-7be140df8f2d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007038701s
STEP: Saw pod success
Feb  6 19:57:11.743: INFO: Pod "pod-projected-configmaps-6dd73995-fe89-42f7-a146-7be140df8f2d" satisfied condition "success or failure"
Feb  6 19:57:11.756: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-projected-configmaps-6dd73995-fe89-42f7-a146-7be140df8f2d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 19:57:11.780: INFO: Waiting for pod pod-projected-configmaps-6dd73995-fe89-42f7-a146-7be140df8f2d to disappear
Feb  6 19:57:11.783: INFO: Pod pod-projected-configmaps-6dd73995-fe89-42f7-a146-7be140df8f2d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:57:11.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6163" for this suite.
Feb  6 19:57:17.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:57:18.263: INFO: namespace projected-6163 deletion completed in 6.473908782s

• [SLOW TEST:8.689 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:57:18.263: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-8603
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-1224
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-136
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:57:32.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8603" for this suite.
Feb  6 19:57:38.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:57:39.263: INFO: namespace namespaces-8603 deletion completed in 6.475199731s
STEP: Destroying namespace "nsdeletetest-1224" for this suite.
Feb  6 19:57:39.266: INFO: Namespace nsdeletetest-1224 was already deleted
STEP: Destroying namespace "nsdeletetest-136" for this suite.
Feb  6 19:57:45.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:57:45.745: INFO: namespace nsdeletetest-136 deletion completed in 6.478656314s

• [SLOW TEST:27.482 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:57:45.745: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7327
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb  6 19:57:45.899: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  6 19:57:45.914: INFO: Waiting for terminating namespaces to be deleted...
Feb  6 19:57:45.917: INFO: 
Logging pods the kubelet thinks is on node ip-10-10-1-217.ec2.internal before test
Feb  6 19:57:45.938: INFO: md-flux-6d54668955-bl6sl from md-flux started at 2020-02-06 18:11:25 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.938: INFO: 	Container flux ready: true, restart count 0
Feb  6 19:57:45.938: INFO: md-cert-manager-cainjector-7758b57b8d-4j8jj from md-cert-manager started at 2020-02-06 18:11:31 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.938: INFO: 	Container cert-manager ready: true, restart count 0
Feb  6 19:57:45.938: INFO: md-prometheus-operator-prometheus-node-exporter-mxlfh from md-prometheus-operator started at 2020-02-06 18:12:39 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.938: INFO: 	Container node-exporter ready: true, restart count 0
Feb  6 19:57:45.938: INFO: alertmanager-md-prometheus-operator-alertmanager-0 from md-prometheus-operator started at 2020-02-06 19:07:45 +0000 UTC (2 container statuses recorded)
Feb  6 19:57:45.938: INFO: 	Container alertmanager ready: true, restart count 0
Feb  6 19:57:45.938: INFO: 	Container config-reloader ready: true, restart count 0
Feb  6 19:57:45.938: INFO: loki-6877765b9c-2n9vf from md-loki-stack started at 2020-02-06 18:12:01 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.938: INFO: 	Container loki ready: true, restart count 0
Feb  6 19:57:45.938: INFO: prometheus-md-prometheus-operator-prometheus-0 from md-prometheus-operator started at 2020-02-06 18:12:58 +0000 UTC (3 container statuses recorded)
Feb  6 19:57:45.938: INFO: 	Container prometheus ready: true, restart count 1
Feb  6 19:57:45.938: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Feb  6 19:57:45.938: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Feb  6 19:57:45.938: INFO: kube-proxy-dj7kw from kube-system started at 2020-02-06 15:57:54 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.938: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  6 19:57:45.938: INFO: md-prometheus-operator-operator-f975b4dd9-rw84h from md-prometheus-operator started at 2020-02-06 18:12:39 +0000 UTC (2 container statuses recorded)
Feb  6 19:57:45.938: INFO: 	Container prometheus-operator ready: true, restart count 0
Feb  6 19:57:45.938: INFO: 	Container tls-proxy ready: true, restart count 0
Feb  6 19:57:45.938: INFO: calico-node-hrxsw from kube-system started at 2020-02-06 15:57:54 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.938: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 19:57:45.938: INFO: sonobuoy-systemd-logs-daemon-set-936a433795204ed3-lmxgr from sonobuoy started at 2020-02-06 18:40:06 +0000 UTC (2 container statuses recorded)
Feb  6 19:57:45.938: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb  6 19:57:45.938: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 19:57:45.938: INFO: md-cert-manager-669497f667-mb9js from md-cert-manager started at 2020-02-06 18:11:31 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.938: INFO: 	Container cert-manager ready: true, restart count 0
Feb  6 19:57:45.938: INFO: md-loki-stack-promtail-mmws9 from md-loki-stack started at 2020-02-06 18:12:01 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.939: INFO: 	Container promtail ready: true, restart count 0
Feb  6 19:57:45.939: INFO: md-nginx-ingress-controller-5cff997b69-9qwpx from md-nginx-ingress started at 2020-02-06 18:12:09 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.939: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb  6 19:57:45.939: INFO: 
Logging pods the kubelet thinks is on node ip-10-10-2-209.ec2.internal before test
Feb  6 19:57:45.960: INFO: cm-acme-http-solver-9nppr from md-gangway started at 2020-02-06 19:07:48 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.960: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 19:57:45.960: INFO: md-helm-operator-59d9c54dbf-85p6w from md-helm-operator started at 2020-02-06 18:11:03 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.960: INFO: 	Container flux-helm-operator ready: true, restart count 0
Feb  6 19:57:45.960: INFO: md-navigator-moondog-navigator-65f699786c-6sbxm from md-navigator started at 2020-02-06 18:11:28 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.960: INFO: 	Container moondog-navigator ready: true, restart count 0
Feb  6 19:57:45.960: INFO: md-loki-stack-promtail-wl8xd from md-loki-stack started at 2020-02-06 18:12:01 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.960: INFO: 	Container promtail ready: true, restart count 0
Feb  6 19:57:45.960: INFO: cm-acme-http-solver-tg7qw from md-dex started at 2020-02-06 18:12:35 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.960: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 19:57:45.960: INFO: md-prometheus-operator-prometheus-node-exporter-p52sm from md-prometheus-operator started at 2020-02-06 18:12:39 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.960: INFO: 	Container node-exporter ready: true, restart count 0
Feb  6 19:57:45.960: INFO: cm-acme-http-solver-jq4qb from md-prometheus-operator started at 2020-02-06 19:07:48 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.960: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 19:57:45.960: INFO: md-flux-memcached-77b577bb4c-z77xr from md-flux started at 2020-02-06 18:11:26 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.960: INFO: 	Container memcached ready: true, restart count 0
Feb  6 19:57:45.960: INFO: md-dex-bfbfd7887-c9sjp from md-dex started at 2020-02-06 18:11:32 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.960: INFO: 	Container main ready: true, restart count 1
Feb  6 19:57:45.960: INFO: md-gangway-548f557b49-v4cb5 from md-gangway started at 2020-02-06 18:11:59 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.960: INFO: 	Container gangway ready: true, restart count 0
Feb  6 19:57:45.960: INFO: md-nginx-ingress-default-backend-7d86d446b4-kp67r from md-nginx-ingress started at 2020-02-06 18:12:09 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.960: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
Feb  6 19:57:45.960: INFO: md-cert-manager-webhook-58b4496d5-lx8m5 from md-cert-manager started at 2020-02-06 19:07:33 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.960: INFO: 	Container cert-manager ready: true, restart count 0
Feb  6 19:57:45.960: INFO: cm-acme-http-solver-nnxf2 from md-prometheus-operator started at 2020-02-06 19:07:48 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.960: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 19:57:45.960: INFO: cm-acme-http-solver-tmzk6 from md-prometheus-operator started at 2020-02-06 19:07:48 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.960: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 19:57:45.960: INFO: calico-node-jcts8 from kube-system started at 2020-02-06 15:57:51 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.960: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 19:57:45.960: INFO: kube-proxy-zp49w from kube-system started at 2020-02-06 15:57:51 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.960: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  6 19:57:45.960: INFO: sonobuoy-systemd-logs-daemon-set-936a433795204ed3-fdsl7 from sonobuoy started at 2020-02-06 18:40:06 +0000 UTC (2 container statuses recorded)
Feb  6 19:57:45.960: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb  6 19:57:45.960: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 19:57:45.960: INFO: md-prometheus-operator-kube-state-metrics-b65d855df-b9v58 from md-prometheus-operator started at 2020-02-06 18:12:39 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.960: INFO: 	Container kube-state-metrics ready: true, restart count 0
Feb  6 19:57:45.960: INFO: md-prometheus-operator-grafana-6699695c84-cpjdc from md-prometheus-operator started at 2020-02-06 18:12:49 +0000 UTC (2 container statuses recorded)
Feb  6 19:57:45.960: INFO: 	Container grafana ready: true, restart count 0
Feb  6 19:57:45.960: INFO: 	Container grafana-sc-dashboard ready: true, restart count 0
Feb  6 19:57:45.960: INFO: cm-acme-http-solver-9f7tx from md-navigator started at 2020-02-06 19:07:48 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.960: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 19:57:45.960: INFO: 
Logging pods the kubelet thinks is on node ip-10-10-3-246.ec2.internal before test
Feb  6 19:57:45.972: INFO: md-prometheus-operator-prometheus-node-exporter-v8kp7 from md-prometheus-operator started at 2020-02-06 19:07:59 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.972: INFO: 	Container node-exporter ready: true, restart count 0
Feb  6 19:57:45.972: INFO: sonobuoy-systemd-logs-daemon-set-936a433795204ed3-q2qnm from sonobuoy started at 2020-02-06 18:40:06 +0000 UTC (2 container statuses recorded)
Feb  6 19:57:45.972: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb  6 19:57:45.972: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 19:57:45.972: INFO: calico-node-n4lqx from kube-system started at 2020-02-06 15:57:51 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.972: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 19:57:45.972: INFO: md-loki-stack-promtail-4r8n6 from md-loki-stack started at 2020-02-06 19:07:59 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.972: INFO: 	Container promtail ready: true, restart count 0
Feb  6 19:57:45.972: INFO: cm-acme-http-solver-tpl66 from md-oauth2-proxy started at 2020-02-06 19:56:51 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.972: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 19:57:45.972: INFO: kube-proxy-jfqqq from kube-system started at 2020-02-06 15:57:51 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.972: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  6 19:57:45.972: INFO: md-oauth2-proxy-6559885d88-7rfk6 from md-oauth2-proxy started at 2020-02-06 19:56:50 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.972: INFO: 	Container oauth2-proxy ready: false, restart count 2
Feb  6 19:57:45.972: INFO: sonobuoy from sonobuoy started at 2020-02-06 18:40:05 +0000 UTC (1 container statuses recorded)
Feb  6 19:57:45.972: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  6 19:57:45.972: INFO: sonobuoy-e2e-job-7dfb3a3ef75e43b0 from sonobuoy started at 2020-02-06 18:40:06 +0000 UTC (2 container statuses recorded)
Feb  6 19:57:45.972: INFO: 	Container e2e ready: true, restart count 0
Feb  6 19:57:45.972: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15f0e876c4d51a8f], Reason = [FailedScheduling], Message = [0/6 nodes are available: 6 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15f0e876c5d90d8b], Reason = [FailedScheduling], Message = [0/6 nodes are available: 6 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:57:47.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7327" for this suite.
Feb  6 19:57:53.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:57:53.501: INFO: namespace sched-pred-7327 deletion completed in 6.482110629s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:7.756 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:57:53.501: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-4966
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb  6 19:57:59.681: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4966 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 19:57:59.681: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 19:57:59.838: INFO: Exec stderr: ""
Feb  6 19:57:59.838: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4966 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 19:57:59.838: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 19:57:59.988: INFO: Exec stderr: ""
Feb  6 19:57:59.988: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4966 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 19:57:59.988: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 19:58:00.128: INFO: Exec stderr: ""
Feb  6 19:58:00.128: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4966 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 19:58:00.128: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 19:58:00.277: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb  6 19:58:00.277: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4966 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 19:58:00.277: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 19:58:00.416: INFO: Exec stderr: ""
Feb  6 19:58:00.416: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4966 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 19:58:00.416: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 19:58:00.569: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb  6 19:58:00.569: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4966 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 19:58:00.569: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 19:58:00.712: INFO: Exec stderr: ""
Feb  6 19:58:00.712: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4966 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 19:58:00.712: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 19:58:00.872: INFO: Exec stderr: ""
Feb  6 19:58:00.872: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4966 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 19:58:00.872: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 19:58:01.006: INFO: Exec stderr: ""
Feb  6 19:58:01.006: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4966 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 19:58:01.006: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 19:58:01.156: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 19:58:01.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-4966" for this suite.
Feb  6 19:58:47.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 19:58:47.636: INFO: namespace e2e-kubelet-etc-hosts-4966 deletion completed in 46.474002552s

• [SLOW TEST:54.135 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 19:58:47.636: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4708
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-6c0abbcc-1b55-4aa7-af2f-21e8b8925c87 in namespace container-probe-4708
Feb  6 19:58:49.800: INFO: Started pod busybox-6c0abbcc-1b55-4aa7-af2f-21e8b8925c87 in namespace container-probe-4708
STEP: checking the pod's current state and verifying that restartCount is present
Feb  6 19:58:49.803: INFO: Initial restart count of pod busybox-6c0abbcc-1b55-4aa7-af2f-21e8b8925c87 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:02:50.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4708" for this suite.
Feb  6 20:02:56.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:02:56.940: INFO: namespace container-probe-4708 deletion completed in 6.474573398s

• [SLOW TEST:249.305 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:02:56.940: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3988
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Feb  6 20:02:59.167: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-481697501 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Feb  6 20:03:14.251: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:03:14.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3988" for this suite.
Feb  6 20:03:20.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:03:20.737: INFO: namespace pods-3988 deletion completed in 6.478550479s

• [SLOW TEST:23.797 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:03:20.737: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3279
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-ba7b55f3-7cde-4762-bf02-8978dedecba1
STEP: Creating a pod to test consume configMaps
Feb  6 20:03:20.899: INFO: Waiting up to 5m0s for pod "pod-configmaps-26ec9306-3742-4d45-96c8-38688a0cd6bf" in namespace "configmap-3279" to be "success or failure"
Feb  6 20:03:20.902: INFO: Pod "pod-configmaps-26ec9306-3742-4d45-96c8-38688a0cd6bf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.693535ms
Feb  6 20:03:22.907: INFO: Pod "pod-configmaps-26ec9306-3742-4d45-96c8-38688a0cd6bf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008876002s
Feb  6 20:03:24.911: INFO: Pod "pod-configmaps-26ec9306-3742-4d45-96c8-38688a0cd6bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012599232s
STEP: Saw pod success
Feb  6 20:03:24.911: INFO: Pod "pod-configmaps-26ec9306-3742-4d45-96c8-38688a0cd6bf" satisfied condition "success or failure"
Feb  6 20:03:24.914: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-configmaps-26ec9306-3742-4d45-96c8-38688a0cd6bf container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 20:03:24.933: INFO: Waiting for pod pod-configmaps-26ec9306-3742-4d45-96c8-38688a0cd6bf to disappear
Feb  6 20:03:24.937: INFO: Pod pod-configmaps-26ec9306-3742-4d45-96c8-38688a0cd6bf no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:03:24.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3279" for this suite.
Feb  6 20:03:30.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:03:31.421: INFO: namespace configmap-3279 deletion completed in 6.475036728s

• [SLOW TEST:10.684 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:03:31.422: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-5175
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:03:36.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5175" for this suite.
Feb  6 20:03:42.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:03:43.043: INFO: namespace watch-5175 deletion completed in 6.564648049s

• [SLOW TEST:11.621 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:03:43.043: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6197
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 20:03:43.244: INFO: Create a RollingUpdate DaemonSet
Feb  6 20:03:43.249: INFO: Check that daemon pods launch on every node of the cluster
Feb  6 20:03:43.253: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:43.253: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:43.253: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:43.257: INFO: Number of nodes with available pods: 0
Feb  6 20:03:43.257: INFO: Node ip-10-10-1-217.ec2.internal is running more than one daemon pod
Feb  6 20:03:44.273: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:44.274: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:44.274: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:44.278: INFO: Number of nodes with available pods: 0
Feb  6 20:03:44.278: INFO: Node ip-10-10-1-217.ec2.internal is running more than one daemon pod
Feb  6 20:03:45.262: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:45.262: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:45.262: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:45.266: INFO: Number of nodes with available pods: 1
Feb  6 20:03:45.266: INFO: Node ip-10-10-1-217.ec2.internal is running more than one daemon pod
Feb  6 20:03:46.262: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:46.263: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:46.263: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:46.266: INFO: Number of nodes with available pods: 3
Feb  6 20:03:46.266: INFO: Number of running nodes: 3, number of available pods: 3
Feb  6 20:03:46.266: INFO: Update the DaemonSet to trigger a rollout
Feb  6 20:03:46.273: INFO: Updating DaemonSet daemon-set
Feb  6 20:03:50.289: INFO: Roll back the DaemonSet before rollout is complete
Feb  6 20:03:50.296: INFO: Updating DaemonSet daemon-set
Feb  6 20:03:50.296: INFO: Make sure DaemonSet rollback is complete
Feb  6 20:03:50.299: INFO: Wrong image for pod: daemon-set-6h2zs. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb  6 20:03:50.299: INFO: Pod daemon-set-6h2zs is not available
Feb  6 20:03:50.303: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:50.303: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:50.303: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:51.307: INFO: Wrong image for pod: daemon-set-6h2zs. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb  6 20:03:51.307: INFO: Pod daemon-set-6h2zs is not available
Feb  6 20:03:51.312: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:51.312: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:51.312: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:52.308: INFO: Wrong image for pod: daemon-set-6h2zs. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb  6 20:03:52.308: INFO: Pod daemon-set-6h2zs is not available
Feb  6 20:03:52.312: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:52.312: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:52.312: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:53.307: INFO: Wrong image for pod: daemon-set-6h2zs. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb  6 20:03:53.307: INFO: Pod daemon-set-6h2zs is not available
Feb  6 20:03:53.312: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:53.312: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:53.312: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:54.307: INFO: Wrong image for pod: daemon-set-6h2zs. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb  6 20:03:54.307: INFO: Pod daemon-set-6h2zs is not available
Feb  6 20:03:54.312: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:54.312: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:54.312: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:55.307: INFO: Pod daemon-set-4vsr7 is not available
Feb  6 20:03:55.312: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:55.312: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:03:55.312: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6197, will wait for the garbage collector to delete the pods
Feb  6 20:03:55.378: INFO: Deleting DaemonSet.extensions daemon-set took: 7.664434ms
Feb  6 20:03:56.178: INFO: Terminating DaemonSet.extensions daemon-set pods took: 800.233123ms
Feb  6 20:05:14.682: INFO: Number of nodes with available pods: 0
Feb  6 20:05:14.682: INFO: Number of running nodes: 0, number of available pods: 0
Feb  6 20:05:14.685: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6197/daemonsets","resourceVersion":"84412"},"items":null}

Feb  6 20:05:14.688: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6197/pods","resourceVersion":"84412"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:05:14.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6197" for this suite.
Feb  6 20:05:22.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:05:23.187: INFO: namespace daemonsets-6197 deletion completed in 8.481119882s

• [SLOW TEST:100.144 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:05:23.187: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5700
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Feb  6 20:05:23.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 api-versions'
Feb  6 20:05:23.413: INFO: stderr: ""
Feb  6 20:05:23.413: INFO: stdout: "acme.cert-manager.io/v1alpha2\nadmissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\nappcatalog.appscode.com/v1alpha1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncatalog.kubedb.com/v1alpha1\ncert-manager.io/v1alpha2\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\ndex.coreos.com/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nhelm.fluxcd.io/v1\nkubedb.com/v1alpha1\nmonitoring.coreos.com/v1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:05:23.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5700" for this suite.
Feb  6 20:05:29.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:05:29.895: INFO: namespace kubectl-5700 deletion completed in 6.476878802s

• [SLOW TEST:6.708 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:05:29.895: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-325
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb  6 20:05:30.058: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-325 /api/v1/namespaces/watch-325/configmaps/e2e-watch-test-watch-closed 9e2e7659-e2f6-4644-933f-60c9016a94ce 84518 0 2020-02-06 20:05:30 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  6 20:05:30.058: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-325 /api/v1/namespaces/watch-325/configmaps/e2e-watch-test-watch-closed 9e2e7659-e2f6-4644-933f-60c9016a94ce 84519 0 2020-02-06 20:05:30 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb  6 20:05:30.074: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-325 /api/v1/namespaces/watch-325/configmaps/e2e-watch-test-watch-closed 9e2e7659-e2f6-4644-933f-60c9016a94ce 84520 0 2020-02-06 20:05:30 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  6 20:05:30.074: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-325 /api/v1/namespaces/watch-325/configmaps/e2e-watch-test-watch-closed 9e2e7659-e2f6-4644-933f-60c9016a94ce 84521 0 2020-02-06 20:05:30 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:05:30.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-325" for this suite.
Feb  6 20:05:36.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:05:36.556: INFO: namespace watch-325 deletion completed in 6.477840918s

• [SLOW TEST:6.661 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:05:36.556: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2300
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-9989
STEP: Creating a pod to test atomic-volume-subpath
Feb  6 20:05:36.722: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-9989" in namespace "subpath-2300" to be "success or failure"
Feb  6 20:05:36.724: INFO: Pod "pod-subpath-test-secret-9989": Phase="Pending", Reason="", readiness=false. Elapsed: 2.573594ms
Feb  6 20:05:38.728: INFO: Pod "pod-subpath-test-secret-9989": Phase="Running", Reason="", readiness=true. Elapsed: 2.006214824s
Feb  6 20:05:40.732: INFO: Pod "pod-subpath-test-secret-9989": Phase="Running", Reason="", readiness=true. Elapsed: 4.0098447s
Feb  6 20:05:42.736: INFO: Pod "pod-subpath-test-secret-9989": Phase="Running", Reason="", readiness=true. Elapsed: 6.01372769s
Feb  6 20:05:44.739: INFO: Pod "pod-subpath-test-secret-9989": Phase="Running", Reason="", readiness=true. Elapsed: 8.017220789s
Feb  6 20:05:46.743: INFO: Pod "pod-subpath-test-secret-9989": Phase="Running", Reason="", readiness=true. Elapsed: 10.020877066s
Feb  6 20:05:48.747: INFO: Pod "pod-subpath-test-secret-9989": Phase="Running", Reason="", readiness=true. Elapsed: 12.024835867s
Feb  6 20:05:50.750: INFO: Pod "pod-subpath-test-secret-9989": Phase="Running", Reason="", readiness=true. Elapsed: 14.028482538s
Feb  6 20:05:52.754: INFO: Pod "pod-subpath-test-secret-9989": Phase="Running", Reason="", readiness=true. Elapsed: 16.032319902s
Feb  6 20:05:54.758: INFO: Pod "pod-subpath-test-secret-9989": Phase="Running", Reason="", readiness=true. Elapsed: 18.03625065s
Feb  6 20:05:56.762: INFO: Pod "pod-subpath-test-secret-9989": Phase="Running", Reason="", readiness=true. Elapsed: 20.039770187s
Feb  6 20:05:58.765: INFO: Pod "pod-subpath-test-secret-9989": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.04348169s
STEP: Saw pod success
Feb  6 20:05:58.765: INFO: Pod "pod-subpath-test-secret-9989" satisfied condition "success or failure"
Feb  6 20:05:58.768: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-subpath-test-secret-9989 container test-container-subpath-secret-9989: <nil>
STEP: delete the pod
Feb  6 20:05:58.801: INFO: Waiting for pod pod-subpath-test-secret-9989 to disappear
Feb  6 20:05:58.804: INFO: Pod pod-subpath-test-secret-9989 no longer exists
STEP: Deleting pod pod-subpath-test-secret-9989
Feb  6 20:05:58.804: INFO: Deleting pod "pod-subpath-test-secret-9989" in namespace "subpath-2300"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:05:58.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2300" for this suite.
Feb  6 20:06:04.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:06:05.286: INFO: namespace subpath-2300 deletion completed in 6.474508115s

• [SLOW TEST:28.729 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:06:05.286: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8301
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-8301
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  6 20:06:05.436: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  6 20:06:27.527: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.162.18:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8301 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 20:06:27.527: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 20:06:27.665: INFO: Found all expected endpoints: [netserver-0]
Feb  6 20:06:27.670: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.3.35:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8301 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 20:06:27.670: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 20:06:27.837: INFO: Found all expected endpoints: [netserver-1]
Feb  6 20:06:27.841: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.126.58:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8301 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 20:06:27.841: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 20:06:28.015: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:06:28.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8301" for this suite.
Feb  6 20:06:40.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:06:40.499: INFO: namespace pod-network-test-8301 deletion completed in 12.476869363s

• [SLOW TEST:35.214 seconds]
[sig-network] Networking
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:06:40.500: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7272
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 20:06:40.687: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb  6 20:06:40.696: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:40.696: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:40.696: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:40.699: INFO: Number of nodes with available pods: 0
Feb  6 20:06:40.699: INFO: Node ip-10-10-1-217.ec2.internal is running more than one daemon pod
Feb  6 20:06:41.707: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:41.707: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:41.707: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:41.710: INFO: Number of nodes with available pods: 0
Feb  6 20:06:41.710: INFO: Node ip-10-10-1-217.ec2.internal is running more than one daemon pod
Feb  6 20:06:42.704: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:42.704: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:42.704: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:42.708: INFO: Number of nodes with available pods: 3
Feb  6 20:06:42.708: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb  6 20:06:42.734: INFO: Wrong image for pod: daemon-set-9shvp. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:42.734: INFO: Wrong image for pod: daemon-set-fgmqq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:42.734: INFO: Wrong image for pod: daemon-set-wlspk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:42.739: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:42.739: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:42.739: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:43.745: INFO: Wrong image for pod: daemon-set-9shvp. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:43.745: INFO: Wrong image for pod: daemon-set-fgmqq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:43.745: INFO: Wrong image for pod: daemon-set-wlspk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:43.749: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:43.749: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:43.749: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:44.744: INFO: Wrong image for pod: daemon-set-9shvp. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:44.744: INFO: Wrong image for pod: daemon-set-fgmqq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:44.744: INFO: Wrong image for pod: daemon-set-wlspk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:44.748: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:44.748: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:44.748: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:45.744: INFO: Wrong image for pod: daemon-set-9shvp. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:45.744: INFO: Pod daemon-set-9shvp is not available
Feb  6 20:06:45.744: INFO: Wrong image for pod: daemon-set-fgmqq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:45.744: INFO: Wrong image for pod: daemon-set-wlspk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:45.749: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:45.749: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:45.749: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:46.743: INFO: Wrong image for pod: daemon-set-fgmqq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:46.743: INFO: Pod daemon-set-kxpgd is not available
Feb  6 20:06:46.743: INFO: Wrong image for pod: daemon-set-wlspk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:46.748: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:46.748: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:46.748: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:47.743: INFO: Wrong image for pod: daemon-set-fgmqq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:47.743: INFO: Pod daemon-set-kxpgd is not available
Feb  6 20:06:47.743: INFO: Wrong image for pod: daemon-set-wlspk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:47.747: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:47.748: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:47.748: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:48.743: INFO: Wrong image for pod: daemon-set-fgmqq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:48.743: INFO: Wrong image for pod: daemon-set-wlspk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:48.747: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:48.747: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:48.747: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:49.743: INFO: Wrong image for pod: daemon-set-fgmqq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:49.743: INFO: Pod daemon-set-fgmqq is not available
Feb  6 20:06:49.743: INFO: Wrong image for pod: daemon-set-wlspk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:49.747: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:49.747: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:49.747: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:50.743: INFO: Pod daemon-set-jxllb is not available
Feb  6 20:06:50.743: INFO: Wrong image for pod: daemon-set-wlspk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:50.747: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:50.747: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:50.747: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:51.743: INFO: Pod daemon-set-jxllb is not available
Feb  6 20:06:51.743: INFO: Wrong image for pod: daemon-set-wlspk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:51.748: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:51.748: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:51.748: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:52.743: INFO: Wrong image for pod: daemon-set-wlspk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:52.748: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:52.748: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:52.748: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:53.743: INFO: Wrong image for pod: daemon-set-wlspk. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 20:06:53.743: INFO: Pod daemon-set-wlspk is not available
Feb  6 20:06:53.748: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:53.748: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:53.748: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:54.743: INFO: Pod daemon-set-jx4zm is not available
Feb  6 20:06:54.747: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:54.748: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:54.748: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Feb  6 20:06:54.754: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:54.754: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:54.754: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:54.760: INFO: Number of nodes with available pods: 2
Feb  6 20:06:54.760: INFO: Node ip-10-10-1-217.ec2.internal is running more than one daemon pod
Feb  6 20:06:55.792: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:55.792: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:55.792: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:55.890: INFO: Number of nodes with available pods: 2
Feb  6 20:06:55.890: INFO: Node ip-10-10-1-217.ec2.internal is running more than one daemon pod
Feb  6 20:06:56.765: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:56.765: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:56.765: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:56.768: INFO: Number of nodes with available pods: 2
Feb  6 20:06:56.768: INFO: Node ip-10-10-1-217.ec2.internal is running more than one daemon pod
Feb  6 20:06:57.765: INFO: DaemonSet pods can't tolerate node ip-10-10-1-66.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:57.765: INFO: DaemonSet pods can't tolerate node ip-10-10-2-17.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:57.765: INFO: DaemonSet pods can't tolerate node ip-10-10-3-177.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  6 20:06:57.769: INFO: Number of nodes with available pods: 3
Feb  6 20:06:57.769: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7272, will wait for the garbage collector to delete the pods
Feb  6 20:06:57.845: INFO: Deleting DaemonSet.extensions daemon-set took: 7.716246ms
Feb  6 20:06:57.945: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.228717ms
Feb  6 20:07:11.454: INFO: Number of nodes with available pods: 0
Feb  6 20:07:11.454: INFO: Number of running nodes: 0, number of available pods: 0
Feb  6 20:07:11.467: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7272/daemonsets","resourceVersion":"85242"},"items":null}

Feb  6 20:07:11.478: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7272/pods","resourceVersion":"85242"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:07:11.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7272" for this suite.
Feb  6 20:07:19.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:07:20.017: INFO: namespace daemonsets-7272 deletion completed in 8.487130603s

• [SLOW TEST:39.517 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:07:20.017: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-3106
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb  6 20:07:23.200: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:07:24.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3106" for this suite.
Feb  6 20:07:54.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:07:54.701: INFO: namespace replicaset-3106 deletion completed in 30.473828945s

• [SLOW TEST:34.684 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:07:54.701: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4875
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:07:56.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4875" for this suite.
Feb  6 20:08:42.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:08:43.363: INFO: namespace kubelet-test-4875 deletion completed in 46.473801926s

• [SLOW TEST:48.662 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:08:43.363: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5728
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 20:08:43.983: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Feb  6 20:08:45.995: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716616524, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716616524, loc:(*time.Location)(0x788a6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716616524, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716616523, loc:(*time.Location)(0x788a6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 20:08:49.013: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:08:59.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5728" for this suite.
Feb  6 20:09:07.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:09:07.615: INFO: namespace webhook-5728 deletion completed in 8.477170973s
STEP: Destroying namespace "webhook-5728-markers" for this suite.
Feb  6 20:09:13.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:09:14.101: INFO: namespace webhook-5728-markers deletion completed in 6.486259397s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:30.753 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:09:14.116: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-915
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2199
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-109
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:09:20.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-915" for this suite.
Feb  6 20:09:26.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:09:27.076: INFO: namespace namespaces-915 deletion completed in 6.474370751s
STEP: Destroying namespace "nsdeletetest-2199" for this suite.
Feb  6 20:09:27.078: INFO: Namespace nsdeletetest-2199 was already deleted
STEP: Destroying namespace "nsdeletetest-109" for this suite.
Feb  6 20:09:33.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:09:33.560: INFO: namespace nsdeletetest-109 deletion completed in 6.481343654s

• [SLOW TEST:19.443 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:09:33.560: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1885
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-1885
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-1885
I0206 20:09:33.738895      19 runners.go:184] Created replication controller with name: externalname-service, namespace: services-1885, replica count: 2
I0206 20:09:36.789349      19 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  6 20:09:36.789: INFO: Creating new exec pod
Feb  6 20:09:39.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=services-1885 execpod4b875 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Feb  6 20:09:40.187: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Feb  6 20:09:40.187: INFO: stdout: ""
Feb  6 20:09:40.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=services-1885 execpod4b875 -- /bin/sh -x -c nc -zv -t -w 2 10.102.178.48 80'
Feb  6 20:09:40.429: INFO: stderr: "+ nc -zv -t -w 2 10.102.178.48 80\nConnection to 10.102.178.48 80 port [tcp/http] succeeded!\n"
Feb  6 20:09:40.429: INFO: stdout: ""
Feb  6 20:09:40.429: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:09:40.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1885" for this suite.
Feb  6 20:09:46.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:09:46.950: INFO: namespace services-1885 deletion completed in 6.487597375s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.390 seconds]
[sig-network] Services
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:09:46.950: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-6445
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Feb  6 20:09:49.615: INFO: Successfully updated pod "adopt-release-4xm7z"
STEP: Checking that the Job readopts the Pod
Feb  6 20:09:49.615: INFO: Waiting up to 15m0s for pod "adopt-release-4xm7z" in namespace "job-6445" to be "adopted"
Feb  6 20:09:49.621: INFO: Pod "adopt-release-4xm7z": Phase="Running", Reason="", readiness=true. Elapsed: 6.35378ms
Feb  6 20:09:51.634: INFO: Pod "adopt-release-4xm7z": Phase="Running", Reason="", readiness=true. Elapsed: 2.019596889s
Feb  6 20:09:51.634: INFO: Pod "adopt-release-4xm7z" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Feb  6 20:09:52.145: INFO: Successfully updated pod "adopt-release-4xm7z"
STEP: Checking that the Job releases the Pod
Feb  6 20:09:52.145: INFO: Waiting up to 15m0s for pod "adopt-release-4xm7z" in namespace "job-6445" to be "released"
Feb  6 20:09:52.148: INFO: Pod "adopt-release-4xm7z": Phase="Running", Reason="", readiness=true. Elapsed: 2.975779ms
Feb  6 20:09:54.151: INFO: Pod "adopt-release-4xm7z": Phase="Running", Reason="", readiness=true. Elapsed: 2.006437005s
Feb  6 20:09:54.151: INFO: Pod "adopt-release-4xm7z" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:09:54.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6445" for this suite.
Feb  6 20:10:40.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:10:40.633: INFO: namespace job-6445 deletion completed in 46.47770918s

• [SLOW TEST:53.684 seconds]
[sig-apps] Job
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:10:40.634: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9072
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9072.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-9072.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9072.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9072.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-9072.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9072.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  6 20:10:42.879: INFO: DNS probes using dns-9072/dns-test-fdf32b17-af3a-45f3-93dd-146fd823bfaa succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:10:42.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9072" for this suite.
Feb  6 20:10:48.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:10:49.386: INFO: namespace dns-9072 deletion completed in 6.480933619s

• [SLOW TEST:8.752 seconds]
[sig-network] DNS
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:10:49.386: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7581
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb  6 20:10:49.559: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7581 /api/v1/namespaces/watch-7581/configmaps/e2e-watch-test-resource-version 413ff571-6c40-4df9-a457-a866945c67dc 86550 0 2020-02-06 20:10:49 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  6 20:10:49.559: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7581 /api/v1/namespaces/watch-7581/configmaps/e2e-watch-test-resource-version 413ff571-6c40-4df9-a457-a866945c67dc 86551 0 2020-02-06 20:10:49 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:10:49.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7581" for this suite.
Feb  6 20:10:55.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:10:56.037: INFO: namespace watch-7581 deletion completed in 6.473430396s

• [SLOW TEST:6.651 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:10:56.038: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9763
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-61392a60-a40e-4d1c-8fbe-a89f755e0b2d
STEP: Creating configMap with name cm-test-opt-upd-516654ea-c26b-4985-a6da-17f8883dabf1
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-61392a60-a40e-4d1c-8fbe-a89f755e0b2d
STEP: Updating configmap cm-test-opt-upd-516654ea-c26b-4985-a6da-17f8883dabf1
STEP: Creating configMap with name cm-test-opt-create-b7915123-48e8-4a4f-8ae3-5841877d1f77
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:11:00.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9763" for this suite.
Feb  6 20:11:12.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:11:12.801: INFO: namespace projected-9763 deletion completed in 12.47791377s

• [SLOW TEST:16.763 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:11:12.801: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-4030
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 20:11:12.947: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:11:13.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4030" for this suite.
Feb  6 20:11:19.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:11:19.990: INFO: namespace custom-resource-definition-4030 deletion completed in 6.484042421s

• [SLOW TEST:7.189 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:11:19.990: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2124
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-9dc8f137-8618-4de5-954c-c019553b351b
STEP: Creating a pod to test consume configMaps
Feb  6 20:11:20.149: INFO: Waiting up to 5m0s for pod "pod-configmaps-1f19d6ce-e417-4ad6-8298-f2a39f5ef308" in namespace "configmap-2124" to be "success or failure"
Feb  6 20:11:20.152: INFO: Pod "pod-configmaps-1f19d6ce-e417-4ad6-8298-f2a39f5ef308": Phase="Pending", Reason="", readiness=false. Elapsed: 2.511095ms
Feb  6 20:11:22.157: INFO: Pod "pod-configmaps-1f19d6ce-e417-4ad6-8298-f2a39f5ef308": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007328227s
STEP: Saw pod success
Feb  6 20:11:22.157: INFO: Pod "pod-configmaps-1f19d6ce-e417-4ad6-8298-f2a39f5ef308" satisfied condition "success or failure"
Feb  6 20:11:22.160: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-configmaps-1f19d6ce-e417-4ad6-8298-f2a39f5ef308 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 20:11:22.186: INFO: Waiting for pod pod-configmaps-1f19d6ce-e417-4ad6-8298-f2a39f5ef308 to disappear
Feb  6 20:11:22.189: INFO: Pod pod-configmaps-1f19d6ce-e417-4ad6-8298-f2a39f5ef308 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:11:22.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2124" for this suite.
Feb  6 20:11:28.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:11:28.669: INFO: namespace configmap-2124 deletion completed in 6.473428751s

• [SLOW TEST:8.679 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:11:28.670: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8828
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-b824e9aa-eb58-411b-8868-d6e754adb8aa
STEP: Creating configMap with name cm-test-opt-upd-24273f7a-de3a-4240-8efe-40faaa2f724c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-b824e9aa-eb58-411b-8868-d6e754adb8aa
STEP: Updating configmap cm-test-opt-upd-24273f7a-de3a-4240-8efe-40faaa2f724c
STEP: Creating configMap with name cm-test-opt-create-2505ddda-af19-4557-a333-399c7a7d05d4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:11:32.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8828" for this suite.
Feb  6 20:11:52.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:11:53.403: INFO: namespace configmap-8828 deletion completed in 20.477176146s

• [SLOW TEST:24.733 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:11:53.403: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2896
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb  6 20:11:53.567: INFO: Waiting up to 5m0s for pod "pod-4adc7339-20eb-4871-9ed8-706d5c3a6c2f" in namespace "emptydir-2896" to be "success or failure"
Feb  6 20:11:53.570: INFO: Pod "pod-4adc7339-20eb-4871-9ed8-706d5c3a6c2f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.040422ms
Feb  6 20:11:55.576: INFO: Pod "pod-4adc7339-20eb-4871-9ed8-706d5c3a6c2f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008235044s
STEP: Saw pod success
Feb  6 20:11:55.576: INFO: Pod "pod-4adc7339-20eb-4871-9ed8-706d5c3a6c2f" satisfied condition "success or failure"
Feb  6 20:11:55.578: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-4adc7339-20eb-4871-9ed8-706d5c3a6c2f container test-container: <nil>
STEP: delete the pod
Feb  6 20:11:55.621: INFO: Waiting for pod pod-4adc7339-20eb-4871-9ed8-706d5c3a6c2f to disappear
Feb  6 20:11:55.624: INFO: Pod pod-4adc7339-20eb-4871-9ed8-706d5c3a6c2f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:11:55.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2896" for this suite.
Feb  6 20:12:01.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:12:02.107: INFO: namespace emptydir-2896 deletion completed in 6.478638187s

• [SLOW TEST:8.704 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:12:02.107: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2636
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-2636
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2636 to expose endpoints map[]
Feb  6 20:12:02.275: INFO: Get endpoints failed (5.475084ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Feb  6 20:12:03.278: INFO: successfully validated that service endpoint-test2 in namespace services-2636 exposes endpoints map[] (1.008419946s elapsed)
STEP: Creating pod pod1 in namespace services-2636
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2636 to expose endpoints map[pod1:[80]]
Feb  6 20:12:05.308: INFO: successfully validated that service endpoint-test2 in namespace services-2636 exposes endpoints map[pod1:[80]] (2.022095309s elapsed)
STEP: Creating pod pod2 in namespace services-2636
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2636 to expose endpoints map[pod1:[80] pod2:[80]]
Feb  6 20:12:07.345: INFO: successfully validated that service endpoint-test2 in namespace services-2636 exposes endpoints map[pod1:[80] pod2:[80]] (2.029477894s elapsed)
STEP: Deleting pod pod1 in namespace services-2636
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2636 to expose endpoints map[pod2:[80]]
Feb  6 20:12:08.372: INFO: successfully validated that service endpoint-test2 in namespace services-2636 exposes endpoints map[pod2:[80]] (1.019019167s elapsed)
STEP: Deleting pod pod2 in namespace services-2636
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2636 to expose endpoints map[]
Feb  6 20:12:09.386: INFO: successfully validated that service endpoint-test2 in namespace services-2636 exposes endpoints map[] (1.008091425s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:12:09.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2636" for this suite.
Feb  6 20:12:39.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:12:39.902: INFO: namespace services-2636 deletion completed in 30.477432661s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:37.795 seconds]
[sig-network] Services
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:12:39.902: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6289
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:12:56.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6289" for this suite.
Feb  6 20:13:02.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:13:02.581: INFO: namespace resourcequota-6289 deletion completed in 6.481215779s

• [SLOW TEST:22.678 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:13:02.581: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6422
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 20:13:03.142: INFO: Creating deployment "webserver-deployment"
Feb  6 20:13:03.146: INFO: Waiting for observed generation 1
Feb  6 20:13:05.160: INFO: Waiting for all required pods to come up
Feb  6 20:13:05.165: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb  6 20:13:09.180: INFO: Waiting for deployment "webserver-deployment" to complete
Feb  6 20:13:09.187: INFO: Updating deployment "webserver-deployment" with a non-existent image
Feb  6 20:13:09.194: INFO: Updating deployment webserver-deployment
Feb  6 20:13:09.194: INFO: Waiting for observed generation 2
Feb  6 20:13:11.202: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb  6 20:13:11.209: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb  6 20:13:11.215: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Feb  6 20:13:11.224: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb  6 20:13:11.224: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb  6 20:13:11.227: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Feb  6 20:13:11.234: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Feb  6 20:13:11.234: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Feb  6 20:13:11.241: INFO: Updating deployment webserver-deployment
Feb  6 20:13:11.241: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Feb  6 20:13:11.248: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb  6 20:13:11.251: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb  6 20:13:11.261: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-6422 /apis/apps/v1/namespaces/deployment-6422/deployments/webserver-deployment 14d48e13-ddfa-4c89-95c5-0a62750cb841 87728 3 2020-02-06 20:13:03 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003eb5348 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-02-06 20:13:07 +0000 UTC,LastTransitionTime:2020-02-06 20:13:07 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2020-02-06 20:13:09 +0000 UTC,LastTransitionTime:2020-02-06 20:13:03 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Feb  6 20:13:11.274: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-6422 /apis/apps/v1/namespaces/deployment-6422/replicasets/webserver-deployment-c7997dcc8 7dec1391-1867-4d2a-b31e-837499b44409 87731 3 2020-02-06 20:13:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 14d48e13-ddfa-4c89-95c5-0a62750cb841 0xc003eb5847 0xc003eb5848}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003eb58b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb  6 20:13:11.274: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Feb  6 20:13:11.274: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-6422 /apis/apps/v1/namespaces/deployment-6422/replicasets/webserver-deployment-595b5b9587 3e6fcc94-8ace-409c-8698-a0dcc85ff7bd 87729 3 2020-02-06 20:13:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 14d48e13-ddfa-4c89-95c5-0a62750cb841 0xc003eb5787 0xc003eb5788}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003eb57e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Feb  6 20:13:11.280: INFO: Pod "webserver-deployment-595b5b9587-4gwfc" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-4gwfc webserver-deployment-595b5b9587- deployment-6422 /api/v1/namespaces/deployment-6422/pods/webserver-deployment-595b5b9587-4gwfc 9b688cdb-8d69-49e7-9db7-77e1aba95292 87596 0 2020-02-06 20:13:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:192.168.126.43/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3e6fcc94-8ace-409c-8698-a0dcc85ff7bd 0xc003eb5dc7 0xc003eb5dc8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-7tnlw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-7tnlw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-7tnlw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-10-3-246.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.3.246,PodIP:192.168.126.43,StartTime:2020-02-06 20:13:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-06 20:13:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://1a0b48b5bc50e9e1c41d3644c113a9f8491b9bca0b0a2725372715a2c1c663f1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.126.43,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 20:13:11.281: INFO: Pod "webserver-deployment-595b5b9587-99647" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-99647 webserver-deployment-595b5b9587- deployment-6422 /api/v1/namespaces/deployment-6422/pods/webserver-deployment-595b5b9587-99647 8001cde7-b51e-4e83-8331-16053d19c71e 87592 0 2020-02-06 20:13:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:192.168.126.35/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3e6fcc94-8ace-409c-8698-a0dcc85ff7bd 0xc003eb5f47 0xc003eb5f48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-7tnlw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-7tnlw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-7tnlw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-10-3-246.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.3.246,PodIP:192.168.126.35,StartTime:2020-02-06 20:13:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-06 20:13:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://87c1e095c388f868866149da3739aa9d6756a40407a8189e71d244e263636ea2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.126.35,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 20:13:11.281: INFO: Pod "webserver-deployment-595b5b9587-9qhkz" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-9qhkz webserver-deployment-595b5b9587- deployment-6422 /api/v1/namespaces/deployment-6422/pods/webserver-deployment-595b5b9587-9qhkz 55e4ccf5-c64d-4ec8-bd63-e19216234314 87583 0 2020-02-06 20:13:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:192.168.126.45/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3e6fcc94-8ace-409c-8698-a0dcc85ff7bd 0xc003e680c7 0xc003e680c8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-7tnlw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-7tnlw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-7tnlw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-10-3-246.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.3.246,PodIP:192.168.126.45,StartTime:2020-02-06 20:13:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-06 20:13:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://12fe83beb6bdf5a9a27ca6eece8cf411ee2b9309afb7dadf0af63783115c65b0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.126.45,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 20:13:11.281: INFO: Pod "webserver-deployment-595b5b9587-9vtzz" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-9vtzz webserver-deployment-595b5b9587- deployment-6422 /api/v1/namespaces/deployment-6422/pods/webserver-deployment-595b5b9587-9vtzz 1614a4f1-3b01-4ffb-8c66-4260473cf70b 87586 0 2020-02-06 20:13:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:192.168.126.31/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3e6fcc94-8ace-409c-8698-a0dcc85ff7bd 0xc003e68237 0xc003e68238}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-7tnlw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-7tnlw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-7tnlw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-10-3-246.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.3.246,PodIP:192.168.126.31,StartTime:2020-02-06 20:13:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-06 20:13:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://8e2189ae1bd4447a6f80da0466ab36c0c0bfce56e22de4da1073dd0885db46bf,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.126.31,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 20:13:11.281: INFO: Pod "webserver-deployment-595b5b9587-f4fbn" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-f4fbn webserver-deployment-595b5b9587- deployment-6422 /api/v1/namespaces/deployment-6422/pods/webserver-deployment-595b5b9587-f4fbn bbc32fa6-9ec7-4d4d-9d1b-e4b0306a52c2 87533 0 2020-02-06 20:13:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:192.168.162.35/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3e6fcc94-8ace-409c-8698-a0dcc85ff7bd 0xc003e683a7 0xc003e683a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-7tnlw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-7tnlw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-7tnlw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-10-2-209.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.2.209,PodIP:192.168.162.35,StartTime:2020-02-06 20:13:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-06 20:13:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://ce6f3ad81418fb90a712e7132dd6f02b63847f324b93c07fde37e92904aad8f9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.162.35,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 20:13:11.281: INFO: Pod "webserver-deployment-595b5b9587-jnccv" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-jnccv webserver-deployment-595b5b9587- deployment-6422 /api/v1/namespaces/deployment-6422/pods/webserver-deployment-595b5b9587-jnccv 7529c6f7-83fb-4149-a902-8f6a6a3d4aa1 87589 0 2020-02-06 20:13:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:192.168.126.62/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3e6fcc94-8ace-409c-8698-a0dcc85ff7bd 0xc003e68517 0xc003e68518}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-7tnlw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-7tnlw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-7tnlw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-10-3-246.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.3.246,PodIP:192.168.126.62,StartTime:2020-02-06 20:13:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-06 20:13:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://9b2a7f24e074fe8854be231e17e8999bd77fb53402e11be12c2dce4480c425c8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.126.62,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 20:13:11.281: INFO: Pod "webserver-deployment-595b5b9587-ktwfp" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-ktwfp webserver-deployment-595b5b9587- deployment-6422 /api/v1/namespaces/deployment-6422/pods/webserver-deployment-595b5b9587-ktwfp 134f0015-30f8-4853-a7ea-50949eddd11f 87734 0 2020-02-06 20:13:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3e6fcc94-8ace-409c-8698-a0dcc85ff7bd 0xc003e68687 0xc003e68688}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-7tnlw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-7tnlw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-7tnlw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 20:13:11.281: INFO: Pod "webserver-deployment-595b5b9587-rcwrw" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-rcwrw webserver-deployment-595b5b9587- deployment-6422 /api/v1/namespaces/deployment-6422/pods/webserver-deployment-595b5b9587-rcwrw 72b3125f-a386-42dd-97a8-4243d270343c 87733 0 2020-02-06 20:13:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3e6fcc94-8ace-409c-8698-a0dcc85ff7bd 0xc003e68777 0xc003e68778}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-7tnlw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-7tnlw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-7tnlw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-10-1-217.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 20:13:11.281: INFO: Pod "webserver-deployment-595b5b9587-sq5m7" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-sq5m7 webserver-deployment-595b5b9587- deployment-6422 /api/v1/namespaces/deployment-6422/pods/webserver-deployment-595b5b9587-sq5m7 565f0a3e-172b-4a2d-ac02-8225993c373c 87738 0 2020-02-06 20:13:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3e6fcc94-8ace-409c-8698-a0dcc85ff7bd 0xc003e68890 0xc003e68891}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-7tnlw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-7tnlw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-7tnlw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 20:13:11.281: INFO: Pod "webserver-deployment-595b5b9587-xczsm" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-xczsm webserver-deployment-595b5b9587- deployment-6422 /api/v1/namespaces/deployment-6422/pods/webserver-deployment-595b5b9587-xczsm c81cf872-b247-4eb5-85ac-3eccfd6a520b 87601 0 2020-02-06 20:13:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:192.168.126.3/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3e6fcc94-8ace-409c-8698-a0dcc85ff7bd 0xc003e68987 0xc003e68988}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-7tnlw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-7tnlw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-7tnlw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-10-3-246.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.3.246,PodIP:192.168.126.3,StartTime:2020-02-06 20:13:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-06 20:13:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://c971fa52a7e703303b8ba19e08388b2f3eb0d5d334df9c921138d55dacb36ded,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.126.3,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 20:13:11.282: INFO: Pod "webserver-deployment-595b5b9587-xtk8x" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-xtk8x webserver-deployment-595b5b9587- deployment-6422 /api/v1/namespaces/deployment-6422/pods/webserver-deployment-595b5b9587-xtk8x c4e72e22-3a5e-4be2-8582-377f359bdaae 87529 0 2020-02-06 20:13:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:192.168.3.39/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3e6fcc94-8ace-409c-8698-a0dcc85ff7bd 0xc003e68b07 0xc003e68b08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-7tnlw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-7tnlw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-7tnlw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-10-1-217.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.217,PodIP:192.168.3.39,StartTime:2020-02-06 20:13:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-06 20:13:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://5efcb5bf350c210cc41104130278e3267dd6e004c86c3250482ea20b696c69de,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.3.39,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 20:13:11.282: INFO: Pod "webserver-deployment-c7997dcc8-5v5hj" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-5v5hj webserver-deployment-c7997dcc8- deployment-6422 /api/v1/namespaces/deployment-6422/pods/webserver-deployment-c7997dcc8-5v5hj 7dc67ceb-36b4-4779-bc7c-2236ecfb2a3b 87719 0 2020-02-06 20:13:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:192.168.3.37/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 7dec1391-1867-4d2a-b31e-837499b44409 0xc003e68c87 0xc003e68c88}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-7tnlw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-7tnlw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-7tnlw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-10-1-217.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.217,PodIP:192.168.3.37,StartTime:2020-02-06 20:13:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.3.37,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 20:13:11.282: INFO: Pod "webserver-deployment-c7997dcc8-96c76" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-96c76 webserver-deployment-c7997dcc8- deployment-6422 /api/v1/namespaces/deployment-6422/pods/webserver-deployment-c7997dcc8-96c76 45827f87-2e6d-4515-bf36-46def6524bdf 87737 0 2020-02-06 20:13:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 7dec1391-1867-4d2a-b31e-837499b44409 0xc003e68e20 0xc003e68e21}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-7tnlw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-7tnlw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-7tnlw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 20:13:11.282: INFO: Pod "webserver-deployment-c7997dcc8-cc22m" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-cc22m webserver-deployment-c7997dcc8- deployment-6422 /api/v1/namespaces/deployment-6422/pods/webserver-deployment-c7997dcc8-cc22m 20f6e738-ea97-4b2d-8fc5-ccf6047a4b68 87715 0 2020-02-06 20:13:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:192.168.3.38/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 7dec1391-1867-4d2a-b31e-837499b44409 0xc003e68f27 0xc003e68f28}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-7tnlw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-7tnlw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-7tnlw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-10-1-217.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.217,PodIP:,StartTime:2020-02-06 20:13:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 20:13:11.282: INFO: Pod "webserver-deployment-c7997dcc8-d8jt6" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-d8jt6 webserver-deployment-c7997dcc8- deployment-6422 /api/v1/namespaces/deployment-6422/pods/webserver-deployment-c7997dcc8-d8jt6 240a1c2c-cb9d-49cb-9c61-c3d0106e44cb 87720 0 2020-02-06 20:13:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:192.168.162.37/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 7dec1391-1867-4d2a-b31e-837499b44409 0xc003e690a0 0xc003e690a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-7tnlw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-7tnlw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-7tnlw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-10-2-209.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.2.209,PodIP:,StartTime:2020-02-06 20:13:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 20:13:11.282: INFO: Pod "webserver-deployment-c7997dcc8-k76n8" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-k76n8 webserver-deployment-c7997dcc8- deployment-6422 /api/v1/namespaces/deployment-6422/pods/webserver-deployment-c7997dcc8-k76n8 ab79d699-848f-4aca-a834-c2d2bea3ba06 87726 0 2020-02-06 20:13:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:192.168.126.6/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 7dec1391-1867-4d2a-b31e-837499b44409 0xc003e69220 0xc003e69221}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-7tnlw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-7tnlw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-7tnlw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-10-3-246.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.3.246,PodIP:192.168.126.6,StartTime:2020-02-06 20:13:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.126.6,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 20:13:11.283: INFO: Pod "webserver-deployment-c7997dcc8-p2cg4" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-p2cg4 webserver-deployment-c7997dcc8- deployment-6422 /api/v1/namespaces/deployment-6422/pods/webserver-deployment-c7997dcc8-p2cg4 3279e53b-330b-4bf6-b92a-75113720e060 87723 0 2020-02-06 20:13:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:192.168.126.7/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 7dec1391-1867-4d2a-b31e-837499b44409 0xc003e693c0 0xc003e693c1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-7tnlw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-7tnlw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-7tnlw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-10-3-246.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:13:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.3.246,PodIP:192.168.126.7,StartTime:2020-02-06 20:13:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.126.7,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:13:11.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6422" for this suite.
Feb  6 20:13:19.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:13:19.829: INFO: namespace deployment-6422 deletion completed in 8.536290514s

• [SLOW TEST:17.249 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:13:19.829: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4359
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4359.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4359.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4359.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4359.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  6 20:13:24.035: INFO: DNS probes using dns-test-91b53496-daa1-444d-8b60-02e6fb89f6fc succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4359.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4359.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4359.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4359.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  6 20:13:28.098: INFO: File wheezy_udp@dns-test-service-3.dns-4359.svc.cluster.local from pod  dns-4359/dns-test-93bf2791-bfd5-44b5-9baa-db190ac1abdd contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb  6 20:13:28.102: INFO: File jessie_udp@dns-test-service-3.dns-4359.svc.cluster.local from pod  dns-4359/dns-test-93bf2791-bfd5-44b5-9baa-db190ac1abdd contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb  6 20:13:28.102: INFO: Lookups using dns-4359/dns-test-93bf2791-bfd5-44b5-9baa-db190ac1abdd failed for: [wheezy_udp@dns-test-service-3.dns-4359.svc.cluster.local jessie_udp@dns-test-service-3.dns-4359.svc.cluster.local]

Feb  6 20:13:33.108: INFO: File wheezy_udp@dns-test-service-3.dns-4359.svc.cluster.local from pod  dns-4359/dns-test-93bf2791-bfd5-44b5-9baa-db190ac1abdd contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb  6 20:13:33.112: INFO: File jessie_udp@dns-test-service-3.dns-4359.svc.cluster.local from pod  dns-4359/dns-test-93bf2791-bfd5-44b5-9baa-db190ac1abdd contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb  6 20:13:33.112: INFO: Lookups using dns-4359/dns-test-93bf2791-bfd5-44b5-9baa-db190ac1abdd failed for: [wheezy_udp@dns-test-service-3.dns-4359.svc.cluster.local jessie_udp@dns-test-service-3.dns-4359.svc.cluster.local]

Feb  6 20:13:38.106: INFO: File wheezy_udp@dns-test-service-3.dns-4359.svc.cluster.local from pod  dns-4359/dns-test-93bf2791-bfd5-44b5-9baa-db190ac1abdd contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb  6 20:13:38.110: INFO: File jessie_udp@dns-test-service-3.dns-4359.svc.cluster.local from pod  dns-4359/dns-test-93bf2791-bfd5-44b5-9baa-db190ac1abdd contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb  6 20:13:38.110: INFO: Lookups using dns-4359/dns-test-93bf2791-bfd5-44b5-9baa-db190ac1abdd failed for: [wheezy_udp@dns-test-service-3.dns-4359.svc.cluster.local jessie_udp@dns-test-service-3.dns-4359.svc.cluster.local]

Feb  6 20:13:43.109: INFO: File wheezy_udp@dns-test-service-3.dns-4359.svc.cluster.local from pod  dns-4359/dns-test-93bf2791-bfd5-44b5-9baa-db190ac1abdd contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb  6 20:13:43.112: INFO: File jessie_udp@dns-test-service-3.dns-4359.svc.cluster.local from pod  dns-4359/dns-test-93bf2791-bfd5-44b5-9baa-db190ac1abdd contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb  6 20:13:43.113: INFO: Lookups using dns-4359/dns-test-93bf2791-bfd5-44b5-9baa-db190ac1abdd failed for: [wheezy_udp@dns-test-service-3.dns-4359.svc.cluster.local jessie_udp@dns-test-service-3.dns-4359.svc.cluster.local]

Feb  6 20:13:48.106: INFO: File wheezy_udp@dns-test-service-3.dns-4359.svc.cluster.local from pod  dns-4359/dns-test-93bf2791-bfd5-44b5-9baa-db190ac1abdd contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb  6 20:13:48.110: INFO: File jessie_udp@dns-test-service-3.dns-4359.svc.cluster.local from pod  dns-4359/dns-test-93bf2791-bfd5-44b5-9baa-db190ac1abdd contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb  6 20:13:48.110: INFO: Lookups using dns-4359/dns-test-93bf2791-bfd5-44b5-9baa-db190ac1abdd failed for: [wheezy_udp@dns-test-service-3.dns-4359.svc.cluster.local jessie_udp@dns-test-service-3.dns-4359.svc.cluster.local]

Feb  6 20:13:53.113: INFO: DNS probes using dns-test-93bf2791-bfd5-44b5-9baa-db190ac1abdd succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4359.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-4359.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4359.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-4359.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  6 20:13:57.221: INFO: DNS probes using dns-test-50b054d2-369f-4e52-bde6-e8c82df0f82b succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:13:57.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4359" for this suite.
Feb  6 20:14:05.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:14:05.755: INFO: namespace dns-4359 deletion completed in 8.482912531s

• [SLOW TEST:45.926 seconds]
[sig-network] DNS
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:14:05.756: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5424
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-dddc9e28-e813-41e6-a82c-6f7bd41c348d
Feb  6 20:14:05.909: INFO: Pod name my-hostname-basic-dddc9e28-e813-41e6-a82c-6f7bd41c348d: Found 0 pods out of 1
Feb  6 20:14:10.913: INFO: Pod name my-hostname-basic-dddc9e28-e813-41e6-a82c-6f7bd41c348d: Found 1 pods out of 1
Feb  6 20:14:10.913: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-dddc9e28-e813-41e6-a82c-6f7bd41c348d" are running
Feb  6 20:14:10.916: INFO: Pod "my-hostname-basic-dddc9e28-e813-41e6-a82c-6f7bd41c348d-ntfjt" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-06 20:14:05 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-06 20:14:07 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-06 20:14:07 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-06 20:14:05 +0000 UTC Reason: Message:}])
Feb  6 20:14:10.916: INFO: Trying to dial the pod
Feb  6 20:14:15.927: INFO: Controller my-hostname-basic-dddc9e28-e813-41e6-a82c-6f7bd41c348d: Got expected result from replica 1 [my-hostname-basic-dddc9e28-e813-41e6-a82c-6f7bd41c348d-ntfjt]: "my-hostname-basic-dddc9e28-e813-41e6-a82c-6f7bd41c348d-ntfjt", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:14:15.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5424" for this suite.
Feb  6 20:14:21.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:14:22.413: INFO: namespace replication-controller-5424 deletion completed in 6.480181574s

• [SLOW TEST:16.657 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:14:22.413: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename taint-single-pod
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-single-pod-1855
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Feb  6 20:14:22.556: INFO: Waiting up to 1m0s for all nodes to be ready
Feb  6 20:15:22.594: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 20:15:22.598: INFO: Starting informer...
STEP: Starting pod...
Feb  6 20:15:22.811: INFO: Pod is running on ip-10-10-3-246.ec2.internal. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Feb  6 20:15:22.828: INFO: Pod wasn't evicted. Proceeding
Feb  6 20:15:22.828: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Feb  6 20:16:37.863: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:16:37.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-1855" for this suite.
Feb  6 20:17:07.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:17:08.345: INFO: namespace taint-single-pod-1855 deletion completed in 30.477222231s

• [SLOW TEST:165.932 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:17:08.345: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6284
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-33e815da-6ed5-458a-a360-1926749df57e
STEP: Creating a pod to test consume configMaps
Feb  6 20:17:08.512: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7fa276d0-d573-4c87-bb29-5f0a3c47fa4f" in namespace "projected-6284" to be "success or failure"
Feb  6 20:17:08.525: INFO: Pod "pod-projected-configmaps-7fa276d0-d573-4c87-bb29-5f0a3c47fa4f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.352294ms
Feb  6 20:17:10.529: INFO: Pod "pod-projected-configmaps-7fa276d0-d573-4c87-bb29-5f0a3c47fa4f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016330393s
STEP: Saw pod success
Feb  6 20:17:10.529: INFO: Pod "pod-projected-configmaps-7fa276d0-d573-4c87-bb29-5f0a3c47fa4f" satisfied condition "success or failure"
Feb  6 20:17:10.532: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-projected-configmaps-7fa276d0-d573-4c87-bb29-5f0a3c47fa4f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 20:17:10.564: INFO: Waiting for pod pod-projected-configmaps-7fa276d0-d573-4c87-bb29-5f0a3c47fa4f to disappear
Feb  6 20:17:10.569: INFO: Pod pod-projected-configmaps-7fa276d0-d573-4c87-bb29-5f0a3c47fa4f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:17:10.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6284" for this suite.
Feb  6 20:17:18.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:17:19.050: INFO: namespace projected-6284 deletion completed in 8.475934725s

• [SLOW TEST:10.705 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:17:19.051: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3615
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-3615/configmap-test-e29e08a6-d603-4f9e-935b-b0aa11bbcd7d
STEP: Creating a pod to test consume configMaps
Feb  6 20:17:19.215: INFO: Waiting up to 5m0s for pod "pod-configmaps-a09210d3-0b02-4868-a955-196b155e64c6" in namespace "configmap-3615" to be "success or failure"
Feb  6 20:17:19.219: INFO: Pod "pod-configmaps-a09210d3-0b02-4868-a955-196b155e64c6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.530367ms
Feb  6 20:17:21.223: INFO: Pod "pod-configmaps-a09210d3-0b02-4868-a955-196b155e64c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007643713s
STEP: Saw pod success
Feb  6 20:17:21.223: INFO: Pod "pod-configmaps-a09210d3-0b02-4868-a955-196b155e64c6" satisfied condition "success or failure"
Feb  6 20:17:21.226: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-configmaps-a09210d3-0b02-4868-a955-196b155e64c6 container env-test: <nil>
STEP: delete the pod
Feb  6 20:17:21.246: INFO: Waiting for pod pod-configmaps-a09210d3-0b02-4868-a955-196b155e64c6 to disappear
Feb  6 20:17:21.250: INFO: Pod pod-configmaps-a09210d3-0b02-4868-a955-196b155e64c6 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:17:21.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3615" for this suite.
Feb  6 20:17:27.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:17:27.732: INFO: namespace configmap-3615 deletion completed in 6.476716115s

• [SLOW TEST:8.682 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:17:27.732: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3999
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 20:17:27.889: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Feb  6 20:17:31.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 --namespace=crd-publish-openapi-3999 create -f -'
Feb  6 20:17:32.160: INFO: stderr: ""
Feb  6 20:17:32.160: INFO: stdout: "e2e-test-crd-publish-openapi-2510-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Feb  6 20:17:32.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 --namespace=crd-publish-openapi-3999 delete e2e-test-crd-publish-openapi-2510-crds test-foo'
Feb  6 20:17:32.343: INFO: stderr: ""
Feb  6 20:17:32.343: INFO: stdout: "e2e-test-crd-publish-openapi-2510-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Feb  6 20:17:32.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 --namespace=crd-publish-openapi-3999 apply -f -'
Feb  6 20:17:32.650: INFO: stderr: ""
Feb  6 20:17:32.650: INFO: stdout: "e2e-test-crd-publish-openapi-2510-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Feb  6 20:17:32.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 --namespace=crd-publish-openapi-3999 delete e2e-test-crd-publish-openapi-2510-crds test-foo'
Feb  6 20:17:32.780: INFO: stderr: ""
Feb  6 20:17:32.780: INFO: stdout: "e2e-test-crd-publish-openapi-2510-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Feb  6 20:17:32.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 --namespace=crd-publish-openapi-3999 create -f -'
Feb  6 20:17:33.049: INFO: rc: 1
Feb  6 20:17:33.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 --namespace=crd-publish-openapi-3999 apply -f -'
Feb  6 20:17:33.302: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Feb  6 20:17:33.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 --namespace=crd-publish-openapi-3999 create -f -'
Feb  6 20:17:33.561: INFO: rc: 1
Feb  6 20:17:33.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 --namespace=crd-publish-openapi-3999 apply -f -'
Feb  6 20:17:33.853: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Feb  6 20:17:33.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 explain e2e-test-crd-publish-openapi-2510-crds'
Feb  6 20:17:34.138: INFO: stderr: ""
Feb  6 20:17:34.138: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2510-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Feb  6 20:17:34.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 explain e2e-test-crd-publish-openapi-2510-crds.metadata'
Feb  6 20:17:34.333: INFO: stderr: ""
Feb  6 20:17:34.333: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2510-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Feb  6 20:17:34.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 explain e2e-test-crd-publish-openapi-2510-crds.spec'
Feb  6 20:17:34.601: INFO: stderr: ""
Feb  6 20:17:34.601: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2510-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Feb  6 20:17:34.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 explain e2e-test-crd-publish-openapi-2510-crds.spec.bars'
Feb  6 20:17:34.960: INFO: stderr: ""
Feb  6 20:17:34.960: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2510-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Feb  6 20:17:34.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 explain e2e-test-crd-publish-openapi-2510-crds.spec.bars2'
Feb  6 20:17:35.214: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:17:39.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3999" for this suite.
Feb  6 20:17:45.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:17:45.518: INFO: namespace crd-publish-openapi-3999 deletion completed in 6.475715475s

• [SLOW TEST:17.785 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:17:45.518: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5469
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Feb  6 20:17:45.668: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Feb  6 20:18:00.484: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 20:18:04.306: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:18:19.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5469" for this suite.
Feb  6 20:18:25.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:18:26.337: INFO: namespace crd-publish-openapi-5469 deletion completed in 6.484595704s

• [SLOW TEST:40.819 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:18:26.337: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4012
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-f8870f17-3c99-4d0a-b653-eeeaddbaec4d
STEP: Creating a pod to test consume configMaps
Feb  6 20:18:26.502: INFO: Waiting up to 5m0s for pod "pod-configmaps-7c9b77ff-ae40-4eaf-bed7-d5d24730996d" in namespace "configmap-4012" to be "success or failure"
Feb  6 20:18:26.506: INFO: Pod "pod-configmaps-7c9b77ff-ae40-4eaf-bed7-d5d24730996d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.4181ms
Feb  6 20:18:28.509: INFO: Pod "pod-configmaps-7c9b77ff-ae40-4eaf-bed7-d5d24730996d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00730306s
STEP: Saw pod success
Feb  6 20:18:28.510: INFO: Pod "pod-configmaps-7c9b77ff-ae40-4eaf-bed7-d5d24730996d" satisfied condition "success or failure"
Feb  6 20:18:28.512: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-configmaps-7c9b77ff-ae40-4eaf-bed7-d5d24730996d container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 20:18:28.535: INFO: Waiting for pod pod-configmaps-7c9b77ff-ae40-4eaf-bed7-d5d24730996d to disappear
Feb  6 20:18:28.539: INFO: Pod pod-configmaps-7c9b77ff-ae40-4eaf-bed7-d5d24730996d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:18:28.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4012" for this suite.
Feb  6 20:18:34.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:18:35.018: INFO: namespace configmap-4012 deletion completed in 6.474486513s

• [SLOW TEST:8.681 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:18:35.019: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4363
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 20:18:35.167: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb  6 20:18:35.175: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb  6 20:18:40.179: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  6 20:18:40.179: INFO: Creating deployment "test-rolling-update-deployment"
Feb  6 20:18:40.184: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb  6 20:18:40.190: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb  6 20:18:42.197: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb  6 20:18:42.200: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb  6 20:18:42.210: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-4363 /apis/apps/v1/namespaces/deployment-4363/deployments/test-rolling-update-deployment 29a98071-42c6-4939-9434-d092d9f6d6df 89888 1 2020-02-06 20:18:40 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004332678 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-02-06 20:18:40 +0000 UTC,LastTransitionTime:2020-02-06 20:18:40 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2020-02-06 20:18:41 +0000 UTC,LastTransitionTime:2020-02-06 20:18:40 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Feb  6 20:18:42.213: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-4363 /apis/apps/v1/namespaces/deployment-4363/replicasets/test-rolling-update-deployment-55d946486 45a5f04a-3e06-4abf-8b46-a64890aa010a 89876 1 2020-02-06 20:18:40 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 29a98071-42c6-4939-9434-d092d9f6d6df 0xc004332b50 0xc004332b51}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004332bb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb  6 20:18:42.213: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb  6 20:18:42.213: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-4363 /apis/apps/v1/namespaces/deployment-4363/replicasets/test-rolling-update-controller 0efa7f2a-7a32-4232-87e7-b802f8410316 89887 2 2020-02-06 20:18:35 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 29a98071-42c6-4939-9434-d092d9f6d6df 0xc004332a87 0xc004332a88}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004332ae8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb  6 20:18:42.216: INFO: Pod "test-rolling-update-deployment-55d946486-56ptb" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-56ptb test-rolling-update-deployment-55d946486- deployment-4363 /api/v1/namespaces/deployment-4363/pods/test-rolling-update-deployment-55d946486-56ptb c9fe0a8b-d0b5-45aa-8569-c8b69c6997ae 89875 0 2020-02-06 20:18:40 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[cni.projectcalico.org/podIP:192.168.126.5/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 45a5f04a-3e06-4abf-8b46-a64890aa010a 0xc0043102c0 0xc0043102c1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qq4n7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qq4n7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qq4n7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-10-3-246.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:18:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:18:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:18:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 20:18:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.3.246,PodIP:192.168.126.5,StartTime:2020-02-06 20:18:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-06 20:18:41 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://6e3378e3536e9b8848762bc4ccb1ec3035db8afac79682565bf7d0a09300b6a9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.126.5,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:18:42.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4363" for this suite.
Feb  6 20:18:50.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:18:50.696: INFO: namespace deployment-4363 deletion completed in 8.475281414s

• [SLOW TEST:15.678 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:18:50.696: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5318
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-4542ec14-4bc4-456f-84ca-8b0fea803bb0
STEP: Creating a pod to test consume secrets
Feb  6 20:18:50.859: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-90d5812e-eee3-4c87-a0b0-3999bca93ce8" in namespace "projected-5318" to be "success or failure"
Feb  6 20:18:50.861: INFO: Pod "pod-projected-secrets-90d5812e-eee3-4c87-a0b0-3999bca93ce8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.80217ms
Feb  6 20:18:52.865: INFO: Pod "pod-projected-secrets-90d5812e-eee3-4c87-a0b0-3999bca93ce8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006335528s
STEP: Saw pod success
Feb  6 20:18:52.865: INFO: Pod "pod-projected-secrets-90d5812e-eee3-4c87-a0b0-3999bca93ce8" satisfied condition "success or failure"
Feb  6 20:18:52.868: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-projected-secrets-90d5812e-eee3-4c87-a0b0-3999bca93ce8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  6 20:18:52.886: INFO: Waiting for pod pod-projected-secrets-90d5812e-eee3-4c87-a0b0-3999bca93ce8 to disappear
Feb  6 20:18:52.889: INFO: Pod pod-projected-secrets-90d5812e-eee3-4c87-a0b0-3999bca93ce8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:18:52.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5318" for this suite.
Feb  6 20:18:58.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:18:59.369: INFO: namespace projected-5318 deletion completed in 6.473788837s

• [SLOW TEST:8.673 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:18:59.369: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-123
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-2a32c995-645c-4e78-9750-dd577382c4ab
STEP: Creating secret with name s-test-opt-upd-c4d736f0-4968-4d66-b619-5d4860b6baaf
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-2a32c995-645c-4e78-9750-dd577382c4ab
STEP: Updating secret s-test-opt-upd-c4d736f0-4968-4d66-b619-5d4860b6baaf
STEP: Creating secret with name s-test-opt-create-f3473710-83de-4625-87da-df843e8224bf
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:19:04.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-123" for this suite.
Feb  6 20:19:22.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:19:22.926: INFO: namespace secrets-123 deletion completed in 18.650361683s

• [SLOW TEST:23.557 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:19:22.927: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4582
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-b8261afc-c44c-4add-9f45-2dc1fad308f0
STEP: Creating a pod to test consume secrets
Feb  6 20:19:23.091: INFO: Waiting up to 5m0s for pod "pod-secrets-a2926d08-e91d-4697-bf87-d563cf8a784d" in namespace "secrets-4582" to be "success or failure"
Feb  6 20:19:23.094: INFO: Pod "pod-secrets-a2926d08-e91d-4697-bf87-d563cf8a784d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.269335ms
Feb  6 20:19:25.098: INFO: Pod "pod-secrets-a2926d08-e91d-4697-bf87-d563cf8a784d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007092899s
STEP: Saw pod success
Feb  6 20:19:25.098: INFO: Pod "pod-secrets-a2926d08-e91d-4697-bf87-d563cf8a784d" satisfied condition "success or failure"
Feb  6 20:19:25.101: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-secrets-a2926d08-e91d-4697-bf87-d563cf8a784d container secret-env-test: <nil>
STEP: delete the pod
Feb  6 20:19:25.124: INFO: Waiting for pod pod-secrets-a2926d08-e91d-4697-bf87-d563cf8a784d to disappear
Feb  6 20:19:25.127: INFO: Pod pod-secrets-a2926d08-e91d-4697-bf87-d563cf8a784d no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:19:25.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4582" for this suite.
Feb  6 20:19:31.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:19:31.614: INFO: namespace secrets-4582 deletion completed in 6.477500839s

• [SLOW TEST:8.687 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:19:31.614: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-1259
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:19:39.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1259" for this suite.
Feb  6 20:19:45.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:19:46.248: INFO: namespace job-1259 deletion completed in 6.474413598s

• [SLOW TEST:14.635 seconds]
[sig-apps] Job
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:19:46.249: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7116
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 20:19:46.393: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:19:48.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7116" for this suite.
Feb  6 20:20:34.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:20:35.020: INFO: namespace pods-7116 deletion completed in 46.47932016s

• [SLOW TEST:48.772 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:20:35.021: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8510
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-8510
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  6 20:20:35.171: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  6 20:20:55.257: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.126.26:8080/dial?request=hostName&protocol=udp&host=192.168.126.19&port=8081&tries=1'] Namespace:pod-network-test-8510 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 20:20:55.257: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 20:20:55.424: INFO: Waiting for endpoints: map[]
Feb  6 20:20:55.429: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.126.26:8080/dial?request=hostName&protocol=udp&host=192.168.162.30&port=8081&tries=1'] Namespace:pod-network-test-8510 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 20:20:55.429: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 20:20:55.580: INFO: Waiting for endpoints: map[]
Feb  6 20:20:55.583: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.126.26:8080/dial?request=hostName&protocol=udp&host=192.168.3.44&port=8081&tries=1'] Namespace:pod-network-test-8510 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 20:20:55.583: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
Feb  6 20:20:55.736: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:20:55.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8510" for this suite.
Feb  6 20:21:07.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:21:08.227: INFO: namespace pod-network-test-8510 deletion completed in 12.484780744s

• [SLOW TEST:33.206 seconds]
[sig-network] Networking
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:21:08.227: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-9556
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb  6 20:21:08.659: INFO: Pod name wrapped-volume-race-d09d3b14-3cd7-403f-92b1-33315977dcf9: Found 0 pods out of 5
Feb  6 20:21:13.665: INFO: Pod name wrapped-volume-race-d09d3b14-3cd7-403f-92b1-33315977dcf9: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d09d3b14-3cd7-403f-92b1-33315977dcf9 in namespace emptydir-wrapper-9556, will wait for the garbage collector to delete the pods
Feb  6 20:21:23.745: INFO: Deleting ReplicationController wrapped-volume-race-d09d3b14-3cd7-403f-92b1-33315977dcf9 took: 8.366824ms
Feb  6 20:21:24.546: INFO: Terminating ReplicationController wrapped-volume-race-d09d3b14-3cd7-403f-92b1-33315977dcf9 pods took: 800.244941ms
STEP: Creating RC which spawns configmap-volume pods
Feb  6 20:22:04.763: INFO: Pod name wrapped-volume-race-870f152a-1b3b-4de9-9f57-2e3441e57a1e: Found 0 pods out of 5
Feb  6 20:22:09.769: INFO: Pod name wrapped-volume-race-870f152a-1b3b-4de9-9f57-2e3441e57a1e: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-870f152a-1b3b-4de9-9f57-2e3441e57a1e in namespace emptydir-wrapper-9556, will wait for the garbage collector to delete the pods
Feb  6 20:22:19.854: INFO: Deleting ReplicationController wrapped-volume-race-870f152a-1b3b-4de9-9f57-2e3441e57a1e took: 10.287527ms
Feb  6 20:22:19.954: INFO: Terminating ReplicationController wrapped-volume-race-870f152a-1b3b-4de9-9f57-2e3441e57a1e pods took: 100.234658ms
STEP: Creating RC which spawns configmap-volume pods
Feb  6 20:23:04.872: INFO: Pod name wrapped-volume-race-be2b444a-d956-4724-8b35-5d2d3bd2e8f3: Found 0 pods out of 5
Feb  6 20:23:09.878: INFO: Pod name wrapped-volume-race-be2b444a-d956-4724-8b35-5d2d3bd2e8f3: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-be2b444a-d956-4724-8b35-5d2d3bd2e8f3 in namespace emptydir-wrapper-9556, will wait for the garbage collector to delete the pods
Feb  6 20:23:19.960: INFO: Deleting ReplicationController wrapped-volume-race-be2b444a-d956-4724-8b35-5d2d3bd2e8f3 took: 8.646936ms
Feb  6 20:23:20.660: INFO: Terminating ReplicationController wrapped-volume-race-be2b444a-d956-4724-8b35-5d2d3bd2e8f3 pods took: 700.258685ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:23:58.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9556" for this suite.
Feb  6 20:24:08.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:24:08.672: INFO: namespace emptydir-wrapper-9556 deletion completed in 10.478960619s

• [SLOW TEST:180.446 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:24:08.673: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6099
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 20:24:08.841: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7ecbf2c0-d553-4bfa-8208-36091614c301" in namespace "downward-api-6099" to be "success or failure"
Feb  6 20:24:08.845: INFO: Pod "downwardapi-volume-7ecbf2c0-d553-4bfa-8208-36091614c301": Phase="Pending", Reason="", readiness=false. Elapsed: 3.668898ms
Feb  6 20:24:10.848: INFO: Pod "downwardapi-volume-7ecbf2c0-d553-4bfa-8208-36091614c301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007578362s
Feb  6 20:24:12.852: INFO: Pod "downwardapi-volume-7ecbf2c0-d553-4bfa-8208-36091614c301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011083087s
STEP: Saw pod success
Feb  6 20:24:12.852: INFO: Pod "downwardapi-volume-7ecbf2c0-d553-4bfa-8208-36091614c301" satisfied condition "success or failure"
Feb  6 20:24:12.855: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod downwardapi-volume-7ecbf2c0-d553-4bfa-8208-36091614c301 container client-container: <nil>
STEP: delete the pod
Feb  6 20:24:12.890: INFO: Waiting for pod downwardapi-volume-7ecbf2c0-d553-4bfa-8208-36091614c301 to disappear
Feb  6 20:24:12.894: INFO: Pod downwardapi-volume-7ecbf2c0-d553-4bfa-8208-36091614c301 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:24:12.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6099" for this suite.
Feb  6 20:24:18.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:24:19.375: INFO: namespace downward-api-6099 deletion completed in 6.475152558s

• [SLOW TEST:10.702 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:24:19.375: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-9812
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-gxdhp in namespace proxy-9812
I0206 20:24:19.548060      19 runners.go:184] Created replication controller with name: proxy-service-gxdhp, namespace: proxy-9812, replica count: 1
I0206 20:24:20.598980      19 runners.go:184] proxy-service-gxdhp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0206 20:24:21.599187      19 runners.go:184] proxy-service-gxdhp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0206 20:24:22.599425      19 runners.go:184] proxy-service-gxdhp Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  6 20:24:22.603: INFO: setup took 3.074840109s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb  6 20:24:22.613: INFO: (0) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 9.68969ms)
Feb  6 20:24:22.613: INFO: (0) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">test<... (200; 9.575157ms)
Feb  6 20:24:22.613: INFO: (0) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 9.915532ms)
Feb  6 20:24:22.613: INFO: (0) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 10.190263ms)
Feb  6 20:24:22.621: INFO: (0) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname2/proxy/: bar (200; 18.440828ms)
Feb  6 20:24:22.621: INFO: (0) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">... (200; 18.401752ms)
Feb  6 20:24:22.621: INFO: (0) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 17.984534ms)
Feb  6 20:24:22.621: INFO: (0) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname1/proxy/: foo (200; 17.95854ms)
Feb  6 20:24:22.621: INFO: (0) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/rewriteme">test</a> (200; 17.840421ms)
Feb  6 20:24:22.621: INFO: (0) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:460/proxy/: tls baz (200; 18.269158ms)
Feb  6 20:24:22.621: INFO: (0) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname1/proxy/: tls baz (200; 18.172755ms)
Feb  6 20:24:22.621: INFO: (0) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname1/proxy/: foo (200; 18.115887ms)
Feb  6 20:24:22.622: INFO: (0) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname2/proxy/: bar (200; 18.386763ms)
Feb  6 20:24:22.625: INFO: (0) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/tlsrewritem... (200; 21.752756ms)
Feb  6 20:24:22.625: INFO: (0) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:462/proxy/: tls qux (200; 22.020763ms)
Feb  6 20:24:22.625: INFO: (0) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname2/proxy/: tls qux (200; 21.181303ms)
Feb  6 20:24:22.637: INFO: (1) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 11.782558ms)
Feb  6 20:24:22.640: INFO: (1) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 14.662807ms)
Feb  6 20:24:22.640: INFO: (1) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">test<... (200; 14.918286ms)
Feb  6 20:24:22.640: INFO: (1) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 14.893325ms)
Feb  6 20:24:22.640: INFO: (1) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/rewriteme">test</a> (200; 15.130474ms)
Feb  6 20:24:22.640: INFO: (1) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/tlsrewritem... (200; 15.042504ms)
Feb  6 20:24:22.640: INFO: (1) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:462/proxy/: tls qux (200; 15.319764ms)
Feb  6 20:24:22.640: INFO: (1) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">... (200; 15.172654ms)
Feb  6 20:24:22.641: INFO: (1) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:460/proxy/: tls baz (200; 15.864479ms)
Feb  6 20:24:22.641: INFO: (1) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 15.680603ms)
Feb  6 20:24:22.644: INFO: (1) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname2/proxy/: bar (200; 18.887ms)
Feb  6 20:24:22.645: INFO: (1) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname2/proxy/: bar (200; 20.38542ms)
Feb  6 20:24:22.646: INFO: (1) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname1/proxy/: tls baz (200; 20.600595ms)
Feb  6 20:24:22.646: INFO: (1) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname1/proxy/: foo (200; 20.791263ms)
Feb  6 20:24:22.646: INFO: (1) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname2/proxy/: tls qux (200; 21.065643ms)
Feb  6 20:24:22.648: INFO: (1) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname1/proxy/: foo (200; 22.591027ms)
Feb  6 20:24:22.656: INFO: (2) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:460/proxy/: tls baz (200; 8.019555ms)
Feb  6 20:24:22.657: INFO: (2) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/rewriteme">test</a> (200; 8.342376ms)
Feb  6 20:24:22.657: INFO: (2) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 8.127701ms)
Feb  6 20:24:22.657: INFO: (2) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/tlsrewritem... (200; 9.105086ms)
Feb  6 20:24:22.658: INFO: (2) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 10.003952ms)
Feb  6 20:24:22.658: INFO: (2) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 9.437351ms)
Feb  6 20:24:22.658: INFO: (2) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">test<... (200; 9.803502ms)
Feb  6 20:24:22.658: INFO: (2) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname1/proxy/: foo (200; 10.151502ms)
Feb  6 20:24:22.658: INFO: (2) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 9.668386ms)
Feb  6 20:24:22.658: INFO: (2) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:462/proxy/: tls qux (200; 9.826257ms)
Feb  6 20:24:22.658: INFO: (2) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">... (200; 9.752011ms)
Feb  6 20:24:22.661: INFO: (2) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname2/proxy/: bar (200; 12.44243ms)
Feb  6 20:24:22.661: INFO: (2) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname2/proxy/: bar (200; 12.294555ms)
Feb  6 20:24:22.661: INFO: (2) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname1/proxy/: tls baz (200; 12.28105ms)
Feb  6 20:24:22.661: INFO: (2) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname2/proxy/: tls qux (200; 12.687537ms)
Feb  6 20:24:22.661: INFO: (2) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname1/proxy/: foo (200; 12.769162ms)
Feb  6 20:24:22.668: INFO: (3) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:462/proxy/: tls qux (200; 7.62202ms)
Feb  6 20:24:22.669: INFO: (3) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 7.307171ms)
Feb  6 20:24:22.669: INFO: (3) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 7.283302ms)
Feb  6 20:24:22.669: INFO: (3) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 7.827688ms)
Feb  6 20:24:22.669: INFO: (3) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">... (200; 8.151408ms)
Feb  6 20:24:22.669: INFO: (3) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 8.101948ms)
Feb  6 20:24:22.669: INFO: (3) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:460/proxy/: tls baz (200; 8.055918ms)
Feb  6 20:24:22.669: INFO: (3) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/tlsrewritem... (200; 7.843912ms)
Feb  6 20:24:22.669: INFO: (3) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/rewriteme">test</a> (200; 7.674581ms)
Feb  6 20:24:22.669: INFO: (3) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">test<... (200; 7.894393ms)
Feb  6 20:24:22.671: INFO: (3) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname2/proxy/: bar (200; 10.088007ms)
Feb  6 20:24:22.672: INFO: (3) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname1/proxy/: foo (200; 10.761312ms)
Feb  6 20:24:22.675: INFO: (3) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname2/proxy/: tls qux (200; 13.305606ms)
Feb  6 20:24:22.675: INFO: (3) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname1/proxy/: foo (200; 13.442445ms)
Feb  6 20:24:22.675: INFO: (3) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname2/proxy/: bar (200; 13.680461ms)
Feb  6 20:24:22.675: INFO: (3) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname1/proxy/: tls baz (200; 13.657531ms)
Feb  6 20:24:22.684: INFO: (4) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname1/proxy/: foo (200; 8.283649ms)
Feb  6 20:24:22.684: INFO: (4) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 8.565762ms)
Feb  6 20:24:22.684: INFO: (4) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:462/proxy/: tls qux (200; 8.467943ms)
Feb  6 20:24:22.684: INFO: (4) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 8.457547ms)
Feb  6 20:24:22.686: INFO: (4) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">test<... (200; 10.548255ms)
Feb  6 20:24:22.686: INFO: (4) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:460/proxy/: tls baz (200; 10.365755ms)
Feb  6 20:24:22.686: INFO: (4) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/rewriteme">test</a> (200; 10.632457ms)
Feb  6 20:24:22.687: INFO: (4) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname1/proxy/: foo (200; 11.678388ms)
Feb  6 20:24:22.687: INFO: (4) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 12.252781ms)
Feb  6 20:24:22.687: INFO: (4) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">... (200; 12.372492ms)
Feb  6 20:24:22.687: INFO: (4) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname2/proxy/: bar (200; 11.629283ms)
Feb  6 20:24:22.687: INFO: (4) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 12.23068ms)
Feb  6 20:24:22.687: INFO: (4) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname2/proxy/: bar (200; 12.12674ms)
Feb  6 20:24:22.687: INFO: (4) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/tlsrewritem... (200; 12.200821ms)
Feb  6 20:24:22.687: INFO: (4) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname1/proxy/: tls baz (200; 12.096692ms)
Feb  6 20:24:22.687: INFO: (4) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname2/proxy/: tls qux (200; 11.808617ms)
Feb  6 20:24:22.699: INFO: (5) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">... (200; 11.236422ms)
Feb  6 20:24:22.700: INFO: (5) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 11.679927ms)
Feb  6 20:24:22.700: INFO: (5) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 12.218978ms)
Feb  6 20:24:22.700: INFO: (5) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">test<... (200; 11.9248ms)
Feb  6 20:24:22.700: INFO: (5) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:460/proxy/: tls baz (200; 12.722552ms)
Feb  6 20:24:22.700: INFO: (5) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname1/proxy/: tls baz (200; 12.476138ms)
Feb  6 20:24:22.700: INFO: (5) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 12.690708ms)
Feb  6 20:24:22.701: INFO: (5) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:462/proxy/: tls qux (200; 12.705533ms)
Feb  6 20:24:22.701: INFO: (5) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/rewriteme">test</a> (200; 12.60554ms)
Feb  6 20:24:22.701: INFO: (5) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 12.787812ms)
Feb  6 20:24:22.701: INFO: (5) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/tlsrewritem... (200; 13.194188ms)
Feb  6 20:24:22.701: INFO: (5) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname2/proxy/: bar (200; 13.492203ms)
Feb  6 20:24:22.702: INFO: (5) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname1/proxy/: foo (200; 14.085117ms)
Feb  6 20:24:22.704: INFO: (5) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname1/proxy/: foo (200; 15.585322ms)
Feb  6 20:24:22.706: INFO: (5) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname2/proxy/: bar (200; 17.704581ms)
Feb  6 20:24:22.706: INFO: (5) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname2/proxy/: tls qux (200; 17.867092ms)
Feb  6 20:24:22.713: INFO: (6) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 7.132773ms)
Feb  6 20:24:22.716: INFO: (6) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:462/proxy/: tls qux (200; 10.086422ms)
Feb  6 20:24:22.716: INFO: (6) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">test<... (200; 10.381685ms)
Feb  6 20:24:22.717: INFO: (6) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 10.388052ms)
Feb  6 20:24:22.717: INFO: (6) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/rewriteme">test</a> (200; 10.86045ms)
Feb  6 20:24:22.717: INFO: (6) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/tlsrewritem... (200; 10.697044ms)
Feb  6 20:24:22.717: INFO: (6) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:460/proxy/: tls baz (200; 11.088574ms)
Feb  6 20:24:22.717: INFO: (6) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">... (200; 11.012619ms)
Feb  6 20:24:22.717: INFO: (6) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 11.290345ms)
Feb  6 20:24:22.717: INFO: (6) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname1/proxy/: foo (200; 11.391103ms)
Feb  6 20:24:22.717: INFO: (6) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 11.071732ms)
Feb  6 20:24:22.719: INFO: (6) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname1/proxy/: tls baz (200; 12.446562ms)
Feb  6 20:24:22.719: INFO: (6) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname2/proxy/: bar (200; 12.77975ms)
Feb  6 20:24:22.719: INFO: (6) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname2/proxy/: bar (200; 12.819708ms)
Feb  6 20:24:22.719: INFO: (6) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname2/proxy/: tls qux (200; 12.937814ms)
Feb  6 20:24:22.720: INFO: (6) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname1/proxy/: foo (200; 13.693086ms)
Feb  6 20:24:22.727: INFO: (7) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 6.971285ms)
Feb  6 20:24:22.728: INFO: (7) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/rewriteme">test</a> (200; 8.072972ms)
Feb  6 20:24:22.729: INFO: (7) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:460/proxy/: tls baz (200; 8.215379ms)
Feb  6 20:24:22.729: INFO: (7) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:462/proxy/: tls qux (200; 8.138205ms)
Feb  6 20:24:22.729: INFO: (7) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 8.085972ms)
Feb  6 20:24:22.729: INFO: (7) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/tlsrewritem... (200; 8.757751ms)
Feb  6 20:24:22.729: INFO: (7) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 8.579934ms)
Feb  6 20:24:22.729: INFO: (7) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">test<... (200; 8.334593ms)
Feb  6 20:24:22.729: INFO: (7) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">... (200; 8.198168ms)
Feb  6 20:24:22.729: INFO: (7) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 8.414754ms)
Feb  6 20:24:22.730: INFO: (7) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname1/proxy/: foo (200; 9.854784ms)
Feb  6 20:24:22.732: INFO: (7) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname2/proxy/: bar (200; 11.251019ms)
Feb  6 20:24:22.733: INFO: (7) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname2/proxy/: bar (200; 12.889496ms)
Feb  6 20:24:22.734: INFO: (7) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname2/proxy/: tls qux (200; 13.475255ms)
Feb  6 20:24:22.734: INFO: (7) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname1/proxy/: tls baz (200; 13.367027ms)
Feb  6 20:24:22.734: INFO: (7) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname1/proxy/: foo (200; 13.810855ms)
Feb  6 20:24:22.742: INFO: (8) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 7.381539ms)
Feb  6 20:24:22.742: INFO: (8) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:460/proxy/: tls baz (200; 7.528065ms)
Feb  6 20:24:22.742: INFO: (8) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 8.097069ms)
Feb  6 20:24:22.742: INFO: (8) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 7.696168ms)
Feb  6 20:24:22.743: INFO: (8) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/tlsrewritem... (200; 8.641053ms)
Feb  6 20:24:22.743: INFO: (8) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:462/proxy/: tls qux (200; 8.180637ms)
Feb  6 20:24:22.744: INFO: (8) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">test<... (200; 9.421298ms)
Feb  6 20:24:22.744: INFO: (8) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">... (200; 9.418422ms)
Feb  6 20:24:22.744: INFO: (8) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/rewriteme">test</a> (200; 9.714306ms)
Feb  6 20:24:22.745: INFO: (8) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 10.436306ms)
Feb  6 20:24:22.746: INFO: (8) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname1/proxy/: foo (200; 11.476126ms)
Feb  6 20:24:22.749: INFO: (8) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname1/proxy/: foo (200; 14.406369ms)
Feb  6 20:24:22.749: INFO: (8) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname2/proxy/: tls qux (200; 14.21732ms)
Feb  6 20:24:22.749: INFO: (8) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname2/proxy/: bar (200; 13.842641ms)
Feb  6 20:24:22.749: INFO: (8) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname2/proxy/: bar (200; 14.019703ms)
Feb  6 20:24:22.749: INFO: (8) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname1/proxy/: tls baz (200; 13.846641ms)
Feb  6 20:24:22.757: INFO: (9) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">... (200; 8.164017ms)
Feb  6 20:24:22.758: INFO: (9) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 8.286368ms)
Feb  6 20:24:22.758: INFO: (9) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 8.846673ms)
Feb  6 20:24:22.758: INFO: (9) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 8.934581ms)
Feb  6 20:24:22.758: INFO: (9) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:462/proxy/: tls qux (200; 8.459122ms)
Feb  6 20:24:22.758: INFO: (9) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/rewriteme">test</a> (200; 8.563614ms)
Feb  6 20:24:22.758: INFO: (9) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:460/proxy/: tls baz (200; 8.580838ms)
Feb  6 20:24:22.758: INFO: (9) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 8.897897ms)
Feb  6 20:24:22.758: INFO: (9) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">test<... (200; 8.836077ms)
Feb  6 20:24:22.760: INFO: (9) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname1/proxy/: foo (200; 10.719607ms)
Feb  6 20:24:22.760: INFO: (9) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/tlsrewritem... (200; 11.084869ms)
Feb  6 20:24:22.760: INFO: (9) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname2/proxy/: bar (200; 10.670322ms)
Feb  6 20:24:22.761: INFO: (9) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname1/proxy/: foo (200; 12.122109ms)
Feb  6 20:24:22.761: INFO: (9) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname2/proxy/: bar (200; 12.515517ms)
Feb  6 20:24:22.762: INFO: (9) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname1/proxy/: tls baz (200; 12.510336ms)
Feb  6 20:24:22.762: INFO: (9) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname2/proxy/: tls qux (200; 12.510551ms)
Feb  6 20:24:22.771: INFO: (10) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/rewriteme">test</a> (200; 8.879122ms)
Feb  6 20:24:22.772: INFO: (10) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">test<... (200; 8.99841ms)
Feb  6 20:24:22.772: INFO: (10) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname2/proxy/: bar (200; 9.77391ms)
Feb  6 20:24:22.772: INFO: (10) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:460/proxy/: tls baz (200; 9.932704ms)
Feb  6 20:24:22.772: INFO: (10) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 8.950415ms)
Feb  6 20:24:22.772: INFO: (10) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:462/proxy/: tls qux (200; 9.732445ms)
Feb  6 20:24:22.772: INFO: (10) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">... (200; 9.626654ms)
Feb  6 20:24:22.773: INFO: (10) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 10.400752ms)
Feb  6 20:24:22.773: INFO: (10) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/tlsrewritem... (200; 10.297018ms)
Feb  6 20:24:22.773: INFO: (10) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 10.40174ms)
Feb  6 20:24:22.773: INFO: (10) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 10.254575ms)
Feb  6 20:24:22.774: INFO: (10) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname1/proxy/: tls baz (200; 11.915391ms)
Feb  6 20:24:22.775: INFO: (10) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname2/proxy/: bar (200; 12.789335ms)
Feb  6 20:24:22.776: INFO: (10) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname1/proxy/: foo (200; 13.282387ms)
Feb  6 20:24:22.776: INFO: (10) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname1/proxy/: foo (200; 13.154259ms)
Feb  6 20:24:22.776: INFO: (10) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname2/proxy/: tls qux (200; 13.157074ms)
Feb  6 20:24:22.786: INFO: (11) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 9.534788ms)
Feb  6 20:24:22.786: INFO: (11) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">test<... (200; 9.909331ms)
Feb  6 20:24:22.786: INFO: (11) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:462/proxy/: tls qux (200; 9.904493ms)
Feb  6 20:24:22.786: INFO: (11) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 10.111941ms)
Feb  6 20:24:22.786: INFO: (11) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/rewriteme">test</a> (200; 10.000587ms)
Feb  6 20:24:22.787: INFO: (11) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:460/proxy/: tls baz (200; 10.862218ms)
Feb  6 20:24:22.787: INFO: (11) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">... (200; 10.186053ms)
Feb  6 20:24:22.787: INFO: (11) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 10.612989ms)
Feb  6 20:24:22.788: INFO: (11) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/tlsrewritem... (200; 11.946057ms)
Feb  6 20:24:22.788: INFO: (11) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname2/proxy/: bar (200; 12.236591ms)
Feb  6 20:24:22.788: INFO: (11) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 12.098296ms)
Feb  6 20:24:22.798: INFO: (11) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname1/proxy/: tls baz (200; 22.218653ms)
Feb  6 20:24:22.798: INFO: (11) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname2/proxy/: bar (200; 21.735117ms)
Feb  6 20:24:22.798: INFO: (11) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname1/proxy/: foo (200; 22.027032ms)
Feb  6 20:24:22.798: INFO: (11) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname2/proxy/: tls qux (200; 21.918782ms)
Feb  6 20:24:22.798: INFO: (11) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname1/proxy/: foo (200; 21.978604ms)
Feb  6 20:24:22.806: INFO: (12) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">... (200; 7.015808ms)
Feb  6 20:24:22.807: INFO: (12) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 8.39817ms)
Feb  6 20:24:22.807: INFO: (12) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:462/proxy/: tls qux (200; 8.923156ms)
Feb  6 20:24:22.808: INFO: (12) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 9.296228ms)
Feb  6 20:24:22.808: INFO: (12) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname1/proxy/: foo (200; 9.28507ms)
Feb  6 20:24:22.808: INFO: (12) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/rewriteme">test</a> (200; 8.955246ms)
Feb  6 20:24:22.808: INFO: (12) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">test<... (200; 9.175608ms)
Feb  6 20:24:22.808: INFO: (12) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:460/proxy/: tls baz (200; 8.953809ms)
Feb  6 20:24:22.808: INFO: (12) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 9.282258ms)
Feb  6 20:24:22.812: INFO: (12) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/tlsrewritem... (200; 12.573249ms)
Feb  6 20:24:22.812: INFO: (12) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 12.736651ms)
Feb  6 20:24:22.812: INFO: (12) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname2/proxy/: bar (200; 12.706061ms)
Feb  6 20:24:22.812: INFO: (12) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname1/proxy/: foo (200; 13.117817ms)
Feb  6 20:24:22.812: INFO: (12) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname1/proxy/: tls baz (200; 12.926697ms)
Feb  6 20:24:22.812: INFO: (12) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname2/proxy/: bar (200; 13.304579ms)
Feb  6 20:24:22.812: INFO: (12) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname2/proxy/: tls qux (200; 13.498398ms)
Feb  6 20:24:22.821: INFO: (13) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 8.537985ms)
Feb  6 20:24:22.821: INFO: (13) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 9.102381ms)
Feb  6 20:24:22.821: INFO: (13) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/tlsrewritem... (200; 8.216532ms)
Feb  6 20:24:22.821: INFO: (13) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:462/proxy/: tls qux (200; 8.729636ms)
Feb  6 20:24:22.821: INFO: (13) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">... (200; 8.664077ms)
Feb  6 20:24:22.821: INFO: (13) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/rewriteme">test</a> (200; 8.900074ms)
Feb  6 20:24:22.821: INFO: (13) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">test<... (200; 8.844414ms)
Feb  6 20:24:22.821: INFO: (13) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 8.218114ms)
Feb  6 20:24:22.821: INFO: (13) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:460/proxy/: tls baz (200; 8.654541ms)
Feb  6 20:24:22.821: INFO: (13) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 8.060209ms)
Feb  6 20:24:22.825: INFO: (13) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname1/proxy/: foo (200; 11.544043ms)
Feb  6 20:24:22.825: INFO: (13) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname1/proxy/: tls baz (200; 12.189277ms)
Feb  6 20:24:22.828: INFO: (13) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname2/proxy/: bar (200; 15.2403ms)
Feb  6 20:24:22.828: INFO: (13) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname1/proxy/: foo (200; 15.743368ms)
Feb  6 20:24:22.828: INFO: (13) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname2/proxy/: bar (200; 15.424648ms)
Feb  6 20:24:22.828: INFO: (13) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname2/proxy/: tls qux (200; 15.692611ms)
Feb  6 20:24:22.836: INFO: (14) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 7.621409ms)
Feb  6 20:24:22.836: INFO: (14) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 7.820064ms)
Feb  6 20:24:22.836: INFO: (14) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">test<... (200; 7.45069ms)
Feb  6 20:24:22.836: INFO: (14) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:460/proxy/: tls baz (200; 8.261628ms)
Feb  6 20:24:22.836: INFO: (14) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 8.00298ms)
Feb  6 20:24:22.836: INFO: (14) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 7.388907ms)
Feb  6 20:24:22.837: INFO: (14) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:462/proxy/: tls qux (200; 7.725162ms)
Feb  6 20:24:22.837: INFO: (14) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/tlsrewritem... (200; 8.096392ms)
Feb  6 20:24:22.837: INFO: (14) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">... (200; 7.734472ms)
Feb  6 20:24:22.837: INFO: (14) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/rewriteme">test</a> (200; 7.968901ms)
Feb  6 20:24:22.841: INFO: (14) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname2/proxy/: bar (200; 12.783198ms)
Feb  6 20:24:22.844: INFO: (14) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname1/proxy/: foo (200; 15.527215ms)
Feb  6 20:24:22.844: INFO: (14) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname2/proxy/: bar (200; 15.205316ms)
Feb  6 20:24:22.844: INFO: (14) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname1/proxy/: foo (200; 15.436364ms)
Feb  6 20:24:22.844: INFO: (14) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname2/proxy/: tls qux (200; 15.413765ms)
Feb  6 20:24:22.844: INFO: (14) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname1/proxy/: tls baz (200; 15.888445ms)
Feb  6 20:24:22.851: INFO: (15) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">... (200; 6.211886ms)
Feb  6 20:24:22.851: INFO: (15) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:462/proxy/: tls qux (200; 6.573615ms)
Feb  6 20:24:22.854: INFO: (15) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">test<... (200; 8.788078ms)
Feb  6 20:24:22.854: INFO: (15) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 9.070119ms)
Feb  6 20:24:22.854: INFO: (15) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 9.2065ms)
Feb  6 20:24:22.854: INFO: (15) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 9.4739ms)
Feb  6 20:24:22.854: INFO: (15) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 9.270817ms)
Feb  6 20:24:22.854: INFO: (15) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/rewriteme">test</a> (200; 9.016627ms)
Feb  6 20:24:22.854: INFO: (15) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/tlsrewritem... (200; 9.600675ms)
Feb  6 20:24:22.854: INFO: (15) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:460/proxy/: tls baz (200; 9.860607ms)
Feb  6 20:24:22.854: INFO: (15) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname2/proxy/: bar (200; 10.077466ms)
Feb  6 20:24:22.855: INFO: (15) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname1/proxy/: foo (200; 10.398906ms)
Feb  6 20:24:22.858: INFO: (15) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname1/proxy/: foo (200; 13.409727ms)
Feb  6 20:24:22.858: INFO: (15) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname1/proxy/: tls baz (200; 13.65226ms)
Feb  6 20:24:22.858: INFO: (15) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname2/proxy/: bar (200; 13.709914ms)
Feb  6 20:24:22.858: INFO: (15) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname2/proxy/: tls qux (200; 13.435934ms)
Feb  6 20:24:22.868: INFO: (16) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 8.917781ms)
Feb  6 20:24:22.868: INFO: (16) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">... (200; 9.417716ms)
Feb  6 20:24:22.868: INFO: (16) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 8.978095ms)
Feb  6 20:24:22.868: INFO: (16) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/tlsrewritem... (200; 9.577421ms)
Feb  6 20:24:22.868: INFO: (16) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname2/proxy/: bar (200; 9.872846ms)
Feb  6 20:24:22.868: INFO: (16) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:462/proxy/: tls qux (200; 9.318007ms)
Feb  6 20:24:22.868: INFO: (16) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 9.559915ms)
Feb  6 20:24:22.869: INFO: (16) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">test<... (200; 10.093587ms)
Feb  6 20:24:22.869: INFO: (16) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/rewriteme">test</a> (200; 9.318066ms)
Feb  6 20:24:22.869: INFO: (16) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:460/proxy/: tls baz (200; 10.110791ms)
Feb  6 20:24:22.869: INFO: (16) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 10.28353ms)
Feb  6 20:24:22.871: INFO: (16) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname2/proxy/: bar (200; 12.654592ms)
Feb  6 20:24:22.874: INFO: (16) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname2/proxy/: tls qux (200; 14.344074ms)
Feb  6 20:24:22.874: INFO: (16) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname1/proxy/: foo (200; 14.47633ms)
Feb  6 20:24:22.874: INFO: (16) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname1/proxy/: foo (200; 14.719422ms)
Feb  6 20:24:22.874: INFO: (16) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname1/proxy/: tls baz (200; 14.882674ms)
Feb  6 20:24:22.884: INFO: (17) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">test<... (200; 9.712383ms)
Feb  6 20:24:22.885: INFO: (17) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">... (200; 10.042643ms)
Feb  6 20:24:22.885: INFO: (17) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:462/proxy/: tls qux (200; 10.367573ms)
Feb  6 20:24:22.885: INFO: (17) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 10.81375ms)
Feb  6 20:24:22.885: INFO: (17) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:460/proxy/: tls baz (200; 11.512795ms)
Feb  6 20:24:22.886: INFO: (17) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/tlsrewritem... (200; 11.531105ms)
Feb  6 20:24:22.886: INFO: (17) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 11.614072ms)
Feb  6 20:24:22.886: INFO: (17) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 11.482128ms)
Feb  6 20:24:22.886: INFO: (17) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/rewriteme">test</a> (200; 11.499824ms)
Feb  6 20:24:22.886: INFO: (17) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 11.574033ms)
Feb  6 20:24:22.886: INFO: (17) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname2/proxy/: bar (200; 12.294177ms)
Feb  6 20:24:22.894: INFO: (17) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname1/proxy/: tls baz (200; 20.390105ms)
Feb  6 20:24:22.894: INFO: (17) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname2/proxy/: tls qux (200; 20.049578ms)
Feb  6 20:24:22.894: INFO: (17) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname1/proxy/: foo (200; 20.126943ms)
Feb  6 20:24:22.894: INFO: (17) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname1/proxy/: foo (200; 20.220944ms)
Feb  6 20:24:22.895: INFO: (17) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname2/proxy/: bar (200; 19.999877ms)
Feb  6 20:24:22.906: INFO: (18) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 10.909922ms)
Feb  6 20:24:22.906: INFO: (18) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">... (200; 11.408868ms)
Feb  6 20:24:22.906: INFO: (18) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 11.129653ms)
Feb  6 20:24:22.906: INFO: (18) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:460/proxy/: tls baz (200; 11.287831ms)
Feb  6 20:24:22.906: INFO: (18) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/tlsrewritem... (200; 11.088289ms)
Feb  6 20:24:22.906: INFO: (18) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:462/proxy/: tls qux (200; 11.657597ms)
Feb  6 20:24:22.909: INFO: (18) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname1/proxy/: foo (200; 14.175879ms)
Feb  6 20:24:22.909: INFO: (18) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname2/proxy/: bar (200; 14.770115ms)
Feb  6 20:24:22.909: INFO: (18) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname2/proxy/: bar (200; 14.501845ms)
Feb  6 20:24:22.910: INFO: (18) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">test<... (200; 14.132329ms)
Feb  6 20:24:22.910: INFO: (18) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/rewriteme">test</a> (200; 14.191216ms)
Feb  6 20:24:22.910: INFO: (18) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 14.701024ms)
Feb  6 20:24:22.910: INFO: (18) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 14.452797ms)
Feb  6 20:24:22.910: INFO: (18) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname2/proxy/: tls qux (200; 14.50938ms)
Feb  6 20:24:22.910: INFO: (18) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname1/proxy/: foo (200; 14.661112ms)
Feb  6 20:24:22.910: INFO: (18) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname1/proxy/: tls baz (200; 14.836528ms)
Feb  6 20:24:22.918: INFO: (19) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 7.52181ms)
Feb  6 20:24:22.918: INFO: (19) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">test<... (200; 7.892199ms)
Feb  6 20:24:22.918: INFO: (19) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:1080/proxy/rewriteme">... (200; 7.745761ms)
Feb  6 20:24:22.918: INFO: (19) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 7.740933ms)
Feb  6 20:24:22.918: INFO: (19) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname1/proxy/: foo (200; 8.243829ms)
Feb  6 20:24:22.918: INFO: (19) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:462/proxy/: tls qux (200; 7.972588ms)
Feb  6 20:24:22.918: INFO: (19) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:162/proxy/: bar (200; 8.47336ms)
Feb  6 20:24:22.919: INFO: (19) /api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/proxy-service-gxdhp-9wj77/proxy/rewriteme">test</a> (200; 8.443365ms)
Feb  6 20:24:22.919: INFO: (19) /api/v1/namespaces/proxy-9812/pods/http:proxy-service-gxdhp-9wj77:160/proxy/: foo (200; 8.021521ms)
Feb  6 20:24:22.919: INFO: (19) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:460/proxy/: tls baz (200; 8.33244ms)
Feb  6 20:24:22.919: INFO: (19) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname1/proxy/: foo (200; 8.581381ms)
Feb  6 20:24:22.919: INFO: (19) /api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/: <a href="/api/v1/namespaces/proxy-9812/pods/https:proxy-service-gxdhp-9wj77:443/proxy/tlsrewritem... (200; 8.745271ms)
Feb  6 20:24:22.923: INFO: (19) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname2/proxy/: tls qux (200; 12.396606ms)
Feb  6 20:24:22.923: INFO: (19) /api/v1/namespaces/proxy-9812/services/http:proxy-service-gxdhp:portname2/proxy/: bar (200; 12.283373ms)
Feb  6 20:24:22.923: INFO: (19) /api/v1/namespaces/proxy-9812/services/proxy-service-gxdhp:portname2/proxy/: bar (200; 12.342881ms)
Feb  6 20:24:22.923: INFO: (19) /api/v1/namespaces/proxy-9812/services/https:proxy-service-gxdhp:tlsportname1/proxy/: tls baz (200; 12.530517ms)
STEP: deleting ReplicationController proxy-service-gxdhp in namespace proxy-9812, will wait for the garbage collector to delete the pods
Feb  6 20:24:22.989: INFO: Deleting ReplicationController proxy-service-gxdhp took: 12.58764ms
Feb  6 20:24:23.690: INFO: Terminating ReplicationController proxy-service-gxdhp pods took: 700.696517ms
[AfterEach] version v1
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:24:31.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9812" for this suite.
Feb  6 20:24:37.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:24:37.572: INFO: namespace proxy-9812 deletion completed in 6.177314886s

• [SLOW TEST:18.197 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:24:37.572: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7570
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 20:24:37.733: INFO: Waiting up to 5m0s for pod "downwardapi-volume-79a6cc5c-a8fa-4145-af12-1a9e3e4cbee9" in namespace "projected-7570" to be "success or failure"
Feb  6 20:24:37.737: INFO: Pod "downwardapi-volume-79a6cc5c-a8fa-4145-af12-1a9e3e4cbee9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.318539ms
Feb  6 20:24:39.741: INFO: Pod "downwardapi-volume-79a6cc5c-a8fa-4145-af12-1a9e3e4cbee9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008065346s
STEP: Saw pod success
Feb  6 20:24:39.741: INFO: Pod "downwardapi-volume-79a6cc5c-a8fa-4145-af12-1a9e3e4cbee9" satisfied condition "success or failure"
Feb  6 20:24:39.744: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod downwardapi-volume-79a6cc5c-a8fa-4145-af12-1a9e3e4cbee9 container client-container: <nil>
STEP: delete the pod
Feb  6 20:24:39.763: INFO: Waiting for pod downwardapi-volume-79a6cc5c-a8fa-4145-af12-1a9e3e4cbee9 to disappear
Feb  6 20:24:39.766: INFO: Pod downwardapi-volume-79a6cc5c-a8fa-4145-af12-1a9e3e4cbee9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:24:39.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7570" for this suite.
Feb  6 20:24:45.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:24:46.248: INFO: namespace projected-7570 deletion completed in 6.476528482s

• [SLOW TEST:8.676 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:24:46.248: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2791
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb  6 20:24:46.414: INFO: Waiting up to 5m0s for pod "downward-api-9e451222-7ebe-4c1f-8cce-cec9cba9ca3a" in namespace "downward-api-2791" to be "success or failure"
Feb  6 20:24:46.418: INFO: Pod "downward-api-9e451222-7ebe-4c1f-8cce-cec9cba9ca3a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.309223ms
Feb  6 20:24:48.421: INFO: Pod "downward-api-9e451222-7ebe-4c1f-8cce-cec9cba9ca3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006750919s
STEP: Saw pod success
Feb  6 20:24:48.421: INFO: Pod "downward-api-9e451222-7ebe-4c1f-8cce-cec9cba9ca3a" satisfied condition "success or failure"
Feb  6 20:24:48.424: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod downward-api-9e451222-7ebe-4c1f-8cce-cec9cba9ca3a container dapi-container: <nil>
STEP: delete the pod
Feb  6 20:24:48.444: INFO: Waiting for pod downward-api-9e451222-7ebe-4c1f-8cce-cec9cba9ca3a to disappear
Feb  6 20:24:48.447: INFO: Pod downward-api-9e451222-7ebe-4c1f-8cce-cec9cba9ca3a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:24:48.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2791" for this suite.
Feb  6 20:24:54.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:24:54.926: INFO: namespace downward-api-2791 deletion completed in 6.474640406s

• [SLOW TEST:8.678 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:24:54.927: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-124
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:25:06.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-124" for this suite.
Feb  6 20:25:12.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:25:12.610: INFO: namespace resourcequota-124 deletion completed in 6.478784968s

• [SLOW TEST:17.683 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:25:12.610: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-2990
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:25:16.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2990" for this suite.
Feb  6 20:25:24.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:25:25.274: INFO: namespace containers-2990 deletion completed in 8.485743622s

• [SLOW TEST:12.664 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:25:25.274: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7613
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-c05701db-21e1-4143-bf61-366e0d86703e
STEP: Creating a pod to test consume secrets
Feb  6 20:25:25.464: INFO: Waiting up to 5m0s for pod "pod-secrets-7be20493-7885-4caa-bcc0-e54e8e2de103" in namespace "secrets-7613" to be "success or failure"
Feb  6 20:25:25.469: INFO: Pod "pod-secrets-7be20493-7885-4caa-bcc0-e54e8e2de103": Phase="Pending", Reason="", readiness=false. Elapsed: 5.139545ms
Feb  6 20:25:27.473: INFO: Pod "pod-secrets-7be20493-7885-4caa-bcc0-e54e8e2de103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008998966s
STEP: Saw pod success
Feb  6 20:25:27.473: INFO: Pod "pod-secrets-7be20493-7885-4caa-bcc0-e54e8e2de103" satisfied condition "success or failure"
Feb  6 20:25:27.477: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-secrets-7be20493-7885-4caa-bcc0-e54e8e2de103 container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 20:25:27.531: INFO: Waiting for pod pod-secrets-7be20493-7885-4caa-bcc0-e54e8e2de103 to disappear
Feb  6 20:25:27.538: INFO: Pod pod-secrets-7be20493-7885-4caa-bcc0-e54e8e2de103 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:25:27.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7613" for this suite.
Feb  6 20:25:33.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:25:34.928: INFO: namespace secrets-7613 deletion completed in 7.379261775s

• [SLOW TEST:9.654 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:25:34.929: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-909
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb  6 20:25:35.215: INFO: Waiting up to 5m0s for pod "pod-ace6c9ca-bc8e-4fc1-a0cc-895f00c01e3a" in namespace "emptydir-909" to be "success or failure"
Feb  6 20:25:35.241: INFO: Pod "pod-ace6c9ca-bc8e-4fc1-a0cc-895f00c01e3a": Phase="Pending", Reason="", readiness=false. Elapsed: 26.656825ms
Feb  6 20:25:37.263: INFO: Pod "pod-ace6c9ca-bc8e-4fc1-a0cc-895f00c01e3a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048183528s
Feb  6 20:25:39.278: INFO: Pod "pod-ace6c9ca-bc8e-4fc1-a0cc-895f00c01e3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063256656s
STEP: Saw pod success
Feb  6 20:25:39.278: INFO: Pod "pod-ace6c9ca-bc8e-4fc1-a0cc-895f00c01e3a" satisfied condition "success or failure"
Feb  6 20:25:39.293: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-ace6c9ca-bc8e-4fc1-a0cc-895f00c01e3a container test-container: <nil>
STEP: delete the pod
Feb  6 20:25:39.348: INFO: Waiting for pod pod-ace6c9ca-bc8e-4fc1-a0cc-895f00c01e3a to disappear
Feb  6 20:25:39.362: INFO: Pod pod-ace6c9ca-bc8e-4fc1-a0cc-895f00c01e3a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:25:39.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-909" for this suite.
Feb  6 20:25:47.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:25:47.912: INFO: namespace emptydir-909 deletion completed in 8.501240109s

• [SLOW TEST:12.984 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:25:47.913: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1982
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0206 20:25:58.162337      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  6 20:25:58.162: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:25:58.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1982" for this suite.
Feb  6 20:26:06.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:26:06.644: INFO: namespace gc-1982 deletion completed in 8.477807701s

• [SLOW TEST:18.732 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:26:06.644: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3494
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 20:26:06.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 version'
Feb  6 20:26:06.864: INFO: stderr: ""
Feb  6 20:26:06.864: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16+\", GitVersion:\"v1.16.6-beta.0\", GitCommit:\"e7f962ba86f4ce7033828210ca3556393c377bcc\", GitTreeState:\"clean\", BuildDate:\"2020-01-15T08:46:32Z\", GoVersion:\"go1.13.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16+\", GitVersion:\"v1.16.6-beta.0\", GitCommit:\"e7f962ba86f4ce7033828210ca3556393c377bcc\", GitTreeState:\"clean\", BuildDate:\"2020-01-15T08:18:29Z\", GoVersion:\"go1.13.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:26:06.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3494" for this suite.
Feb  6 20:26:12.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:26:13.353: INFO: namespace kubectl-3494 deletion completed in 6.478671428s

• [SLOW TEST:6.709 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:26:13.353: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9557
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Feb  6 20:26:13.509: INFO: Waiting up to 5m0s for pod "pod-5caf86e9-d0a9-4dbf-8fe4-71eab4b1d3bb" in namespace "emptydir-9557" to be "success or failure"
Feb  6 20:26:13.512: INFO: Pod "pod-5caf86e9-d0a9-4dbf-8fe4-71eab4b1d3bb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.148354ms
Feb  6 20:26:15.516: INFO: Pod "pod-5caf86e9-d0a9-4dbf-8fe4-71eab4b1d3bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006891191s
STEP: Saw pod success
Feb  6 20:26:15.516: INFO: Pod "pod-5caf86e9-d0a9-4dbf-8fe4-71eab4b1d3bb" satisfied condition "success or failure"
Feb  6 20:26:15.519: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-5caf86e9-d0a9-4dbf-8fe4-71eab4b1d3bb container test-container: <nil>
STEP: delete the pod
Feb  6 20:26:15.542: INFO: Waiting for pod pod-5caf86e9-d0a9-4dbf-8fe4-71eab4b1d3bb to disappear
Feb  6 20:26:15.546: INFO: Pod pod-5caf86e9-d0a9-4dbf-8fe4-71eab4b1d3bb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:26:15.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9557" for this suite.
Feb  6 20:26:21.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:26:22.026: INFO: namespace emptydir-9557 deletion completed in 6.47535701s

• [SLOW TEST:8.673 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:26:22.026: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6418
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Feb  6 20:26:22.184: INFO: Waiting up to 5m0s for pod "client-containers-da636197-7085-4f33-9d56-1f2f3bfda280" in namespace "containers-6418" to be "success or failure"
Feb  6 20:26:22.191: INFO: Pod "client-containers-da636197-7085-4f33-9d56-1f2f3bfda280": Phase="Pending", Reason="", readiness=false. Elapsed: 6.727555ms
Feb  6 20:26:24.195: INFO: Pod "client-containers-da636197-7085-4f33-9d56-1f2f3bfda280": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010518004s
STEP: Saw pod success
Feb  6 20:26:24.195: INFO: Pod "client-containers-da636197-7085-4f33-9d56-1f2f3bfda280" satisfied condition "success or failure"
Feb  6 20:26:24.198: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod client-containers-da636197-7085-4f33-9d56-1f2f3bfda280 container test-container: <nil>
STEP: delete the pod
Feb  6 20:26:24.216: INFO: Waiting for pod client-containers-da636197-7085-4f33-9d56-1f2f3bfda280 to disappear
Feb  6 20:26:24.220: INFO: Pod client-containers-da636197-7085-4f33-9d56-1f2f3bfda280 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:26:24.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6418" for this suite.
Feb  6 20:26:30.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:26:30.702: INFO: namespace containers-6418 deletion completed in 6.476680756s

• [SLOW TEST:8.676 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:26:30.702: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7083
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 20:26:31.504: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb  6 20:26:33.515: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716617591, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716617591, loc:(*time.Location)(0x788a6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716617591, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716617591, loc:(*time.Location)(0x788a6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 20:26:36.536: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:26:36.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7083" for this suite.
Feb  6 20:26:42.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:26:43.082: INFO: namespace webhook-7083 deletion completed in 6.478799969s
STEP: Destroying namespace "webhook-7083-markers" for this suite.
Feb  6 20:26:49.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:26:49.560: INFO: namespace webhook-7083-markers deletion completed in 6.47850042s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.874 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:26:49.576: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-6186
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-6186
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-6186
STEP: Deleting pre-stop pod
Feb  6 20:26:58.777: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:26:58.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-6186" for this suite.
Feb  6 20:27:44.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:27:45.270: INFO: namespace prestop-6186 deletion completed in 46.475409121s

• [SLOW TEST:55.694 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:27:45.270: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2610
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Feb  6 20:27:45.425: INFO: Waiting up to 5m0s for pod "var-expansion-adc92a79-3d22-4535-ae59-292594b1143a" in namespace "var-expansion-2610" to be "success or failure"
Feb  6 20:27:45.428: INFO: Pod "var-expansion-adc92a79-3d22-4535-ae59-292594b1143a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.248899ms
Feb  6 20:27:47.432: INFO: Pod "var-expansion-adc92a79-3d22-4535-ae59-292594b1143a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007410956s
STEP: Saw pod success
Feb  6 20:27:47.432: INFO: Pod "var-expansion-adc92a79-3d22-4535-ae59-292594b1143a" satisfied condition "success or failure"
Feb  6 20:27:47.436: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod var-expansion-adc92a79-3d22-4535-ae59-292594b1143a container dapi-container: <nil>
STEP: delete the pod
Feb  6 20:27:47.456: INFO: Waiting for pod var-expansion-adc92a79-3d22-4535-ae59-292594b1143a to disappear
Feb  6 20:27:47.459: INFO: Pod var-expansion-adc92a79-3d22-4535-ae59-292594b1143a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:27:47.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2610" for this suite.
Feb  6 20:27:53.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:27:53.943: INFO: namespace var-expansion-2610 deletion completed in 6.478731599s

• [SLOW TEST:8.673 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:27:53.943: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7604
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Feb  6 20:27:54.090: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:28:14.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7604" for this suite.
Feb  6 20:28:20.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:28:21.047: INFO: namespace crd-publish-openapi-7604 deletion completed in 6.475888797s

• [SLOW TEST:27.104 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:28:21.047: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9780
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 20:28:21.201: INFO: Waiting up to 5m0s for pod "downwardapi-volume-489a4a8f-ef13-4606-93ca-2fda517cec7e" in namespace "downward-api-9780" to be "success or failure"
Feb  6 20:28:21.204: INFO: Pod "downwardapi-volume-489a4a8f-ef13-4606-93ca-2fda517cec7e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.144377ms
Feb  6 20:28:23.208: INFO: Pod "downwardapi-volume-489a4a8f-ef13-4606-93ca-2fda517cec7e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00674141s
STEP: Saw pod success
Feb  6 20:28:23.208: INFO: Pod "downwardapi-volume-489a4a8f-ef13-4606-93ca-2fda517cec7e" satisfied condition "success or failure"
Feb  6 20:28:23.215: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod downwardapi-volume-489a4a8f-ef13-4606-93ca-2fda517cec7e container client-container: <nil>
STEP: delete the pod
Feb  6 20:28:23.242: INFO: Waiting for pod downwardapi-volume-489a4a8f-ef13-4606-93ca-2fda517cec7e to disappear
Feb  6 20:28:23.246: INFO: Pod downwardapi-volume-489a4a8f-ef13-4606-93ca-2fda517cec7e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:28:23.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9780" for this suite.
Feb  6 20:28:29.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:28:29.725: INFO: namespace downward-api-9780 deletion completed in 6.47424151s

• [SLOW TEST:8.677 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:28:29.725: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-766
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-766
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-766
STEP: creating replication controller externalsvc in namespace services-766
I0206 20:28:29.971896      19 runners.go:184] Created replication controller with name: externalsvc, namespace: services-766, replica count: 2
I0206 20:28:33.022323      19 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Feb  6 20:28:33.081: INFO: Creating new exec pod
Feb  6 20:28:35.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 exec --namespace=services-766 execpod2gxn2 -- /bin/sh -x -c nslookup nodeport-service'
Feb  6 20:28:35.533: INFO: stderr: "+ nslookup nodeport-service\n"
Feb  6 20:28:35.533: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-766.svc.cluster.local\tcanonical name = externalsvc.services-766.svc.cluster.local.\nName:\texternalsvc.services-766.svc.cluster.local\nAddress: 10.96.104.109\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-766, will wait for the garbage collector to delete the pods
Feb  6 20:28:35.600: INFO: Deleting ReplicationController externalsvc took: 10.29934ms
Feb  6 20:28:36.302: INFO: Terminating ReplicationController externalsvc pods took: 701.690531ms
Feb  6 20:28:51.429: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:28:51.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-766" for this suite.
Feb  6 20:28:57.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:28:57.934: INFO: namespace services-766 deletion completed in 6.480284742s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:28.209 seconds]
[sig-network] Services
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:28:57.934: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8809
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb  6 20:29:00.105: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:29:00.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8809" for this suite.
Feb  6 20:29:06.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:29:06.618: INFO: namespace container-runtime-8809 deletion completed in 6.475329619s

• [SLOW TEST:8.684 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:29:06.619: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-514
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Feb  6 20:29:06.769: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-481697501 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:29:06.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-514" for this suite.
Feb  6 20:29:12.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:29:13.316: INFO: namespace kubectl-514 deletion completed in 6.474872745s

• [SLOW TEST:6.697 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:29:13.316: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-491
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Feb  6 20:29:15.992: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-491 pod-service-account-e9396f00-97ce-44dd-b1ef-12d763ec28be -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Feb  6 20:29:16.205: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-491 pod-service-account-e9396f00-97ce-44dd-b1ef-12d763ec28be -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Feb  6 20:29:16.438: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-491 pod-service-account-e9396f00-97ce-44dd-b1ef-12d763ec28be -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:29:16.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-491" for this suite.
Feb  6 20:29:22.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:29:23.163: INFO: namespace svcaccounts-491 deletion completed in 6.476773167s

• [SLOW TEST:9.847 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:29:23.163: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6210
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 20:29:23.569: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb  6 20:29:25.578: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716617763, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716617763, loc:(*time.Location)(0x788a6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716617763, loc:(*time.Location)(0x788a6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716617763, loc:(*time.Location)(0x788a6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 20:29:28.599: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Feb  6 20:29:30.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 attach --namespace=webhook-6210 to-be-attached-pod -i -c=container1'
Feb  6 20:29:30.740: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:29:30.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6210" for this suite.
Feb  6 20:29:42.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:29:43.228: INFO: namespace webhook-6210 deletion completed in 12.473595529s
STEP: Destroying namespace "webhook-6210-markers" for this suite.
Feb  6 20:29:49.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:29:49.703: INFO: namespace webhook-6210-markers deletion completed in 6.474958453s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:26.555 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:29:49.718: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1493
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb  6 20:29:52.941: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:29:52.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1493" for this suite.
Feb  6 20:29:58.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:29:59.436: INFO: namespace container-runtime-1493 deletion completed in 6.473500353s

• [SLOW TEST:9.719 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:29:59.437: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4972
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Feb  6 20:29:59.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 create -f - --namespace=kubectl-4972'
Feb  6 20:29:59.850: INFO: stderr: ""
Feb  6 20:29:59.850: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  6 20:30:00.856: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 20:30:00.856: INFO: Found 0 / 1
Feb  6 20:30:01.855: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 20:30:01.855: INFO: Found 1 / 1
Feb  6 20:30:01.855: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb  6 20:30:01.859: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 20:30:01.859: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  6 20:30:01.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 patch pod redis-master-kx96r --namespace=kubectl-4972 -p {"metadata":{"annotations":{"x":"y"}}}'
Feb  6 20:30:01.993: INFO: stderr: ""
Feb  6 20:30:01.993: INFO: stdout: "pod/redis-master-kx96r patched\n"
STEP: checking annotations
Feb  6 20:30:01.998: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 20:30:01.998: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:30:01.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4972" for this suite.
Feb  6 20:30:14.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:30:14.526: INFO: namespace kubectl-4972 deletion completed in 12.51568255s

• [SLOW TEST:15.089 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:30:14.526: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4843
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 20:30:15.249: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 20:30:18.276: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:30:18.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4843" for this suite.
Feb  6 20:30:24.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:30:24.818: INFO: namespace webhook-4843 deletion completed in 6.475835071s
STEP: Destroying namespace "webhook-4843-markers" for this suite.
Feb  6 20:30:30.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:30:31.302: INFO: namespace webhook-4843-markers deletion completed in 6.484001253s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.794 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:30:31.320: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3083
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb  6 20:30:31.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-3083'
Feb  6 20:30:31.580: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  6 20:30:31.580: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Feb  6 20:30:31.588: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-mskj9]
Feb  6 20:30:31.588: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-mskj9" in namespace "kubectl-3083" to be "running and ready"
Feb  6 20:30:31.592: INFO: Pod "e2e-test-httpd-rc-mskj9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.908608ms
Feb  6 20:30:33.596: INFO: Pod "e2e-test-httpd-rc-mskj9": Phase="Running", Reason="", readiness=true. Elapsed: 2.007813041s
Feb  6 20:30:33.596: INFO: Pod "e2e-test-httpd-rc-mskj9" satisfied condition "running and ready"
Feb  6 20:30:33.596: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-mskj9]
Feb  6 20:30:33.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 logs rc/e2e-test-httpd-rc --namespace=kubectl-3083'
Feb  6 20:30:33.712: INFO: stderr: ""
Feb  6 20:30:33.712: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 192.168.126.47. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 192.168.126.47. Set the 'ServerName' directive globally to suppress this message\n[Thu Feb 06 20:30:32.639447 2020] [mpm_event:notice] [pid 1:tid 139891189361512] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Thu Feb 06 20:30:32.639487 2020] [core:notice] [pid 1:tid 139891189361512] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Feb  6 20:30:33.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 delete rc e2e-test-httpd-rc --namespace=kubectl-3083'
Feb  6 20:30:33.812: INFO: stderr: ""
Feb  6 20:30:33.812: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:30:33.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3083" for this suite.
Feb  6 20:30:39.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:30:40.298: INFO: namespace kubectl-3083 deletion completed in 6.480869067s

• [SLOW TEST:8.978 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:30:40.298: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1856
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb  6 20:30:40.444: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  6 20:30:40.462: INFO: Waiting for terminating namespaces to be deleted...
Feb  6 20:30:40.465: INFO: 
Logging pods the kubelet thinks is on node ip-10-10-1-217.ec2.internal before test
Feb  6 20:30:40.498: INFO: kube-proxy-dj7kw from kube-system started at 2020-02-06 15:57:54 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.498: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  6 20:30:40.498: INFO: md-prometheus-operator-operator-f975b4dd9-rw84h from md-prometheus-operator started at 2020-02-06 18:12:39 +0000 UTC (2 container statuses recorded)
Feb  6 20:30:40.498: INFO: 	Container prometheus-operator ready: true, restart count 0
Feb  6 20:30:40.498: INFO: 	Container tls-proxy ready: true, restart count 0
Feb  6 20:30:40.498: INFO: calico-node-hrxsw from kube-system started at 2020-02-06 15:57:54 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.498: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 20:30:40.498: INFO: sonobuoy-systemd-logs-daemon-set-936a433795204ed3-lmxgr from sonobuoy started at 2020-02-06 18:40:06 +0000 UTC (2 container statuses recorded)
Feb  6 20:30:40.498: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb  6 20:30:40.498: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 20:30:40.498: INFO: md-cert-manager-669497f667-mb9js from md-cert-manager started at 2020-02-06 18:11:31 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.498: INFO: 	Container cert-manager ready: true, restart count 0
Feb  6 20:30:40.498: INFO: md-loki-stack-promtail-mmws9 from md-loki-stack started at 2020-02-06 18:12:01 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.498: INFO: 	Container promtail ready: true, restart count 0
Feb  6 20:30:40.498: INFO: md-nginx-ingress-controller-5cff997b69-9qwpx from md-nginx-ingress started at 2020-02-06 18:12:09 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.498: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb  6 20:30:40.498: INFO: md-flux-6d54668955-bl6sl from md-flux started at 2020-02-06 18:11:25 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.498: INFO: 	Container flux ready: true, restart count 0
Feb  6 20:30:40.498: INFO: md-cert-manager-cainjector-7758b57b8d-4j8jj from md-cert-manager started at 2020-02-06 18:11:31 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.498: INFO: 	Container cert-manager ready: true, restart count 0
Feb  6 20:30:40.498: INFO: md-prometheus-operator-prometheus-node-exporter-mxlfh from md-prometheus-operator started at 2020-02-06 18:12:39 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.498: INFO: 	Container node-exporter ready: true, restart count 0
Feb  6 20:30:40.498: INFO: alertmanager-md-prometheus-operator-alertmanager-0 from md-prometheus-operator started at 2020-02-06 19:07:45 +0000 UTC (2 container statuses recorded)
Feb  6 20:30:40.498: INFO: 	Container alertmanager ready: true, restart count 0
Feb  6 20:30:40.498: INFO: 	Container config-reloader ready: true, restart count 0
Feb  6 20:30:40.498: INFO: loki-6877765b9c-2n9vf from md-loki-stack started at 2020-02-06 18:12:01 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.498: INFO: 	Container loki ready: true, restart count 0
Feb  6 20:30:40.498: INFO: prometheus-md-prometheus-operator-prometheus-0 from md-prometheus-operator started at 2020-02-06 18:12:58 +0000 UTC (3 container statuses recorded)
Feb  6 20:30:40.498: INFO: 	Container prometheus ready: true, restart count 1
Feb  6 20:30:40.498: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Feb  6 20:30:40.498: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Feb  6 20:30:40.498: INFO: 
Logging pods the kubelet thinks is on node ip-10-10-2-209.ec2.internal before test
Feb  6 20:30:40.527: INFO: cm-acme-http-solver-jq4qb from md-prometheus-operator started at 2020-02-06 19:07:48 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.527: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 20:30:40.527: INFO: md-helm-operator-59d9c54dbf-85p6w from md-helm-operator started at 2020-02-06 18:11:03 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.527: INFO: 	Container flux-helm-operator ready: true, restart count 0
Feb  6 20:30:40.527: INFO: md-navigator-moondog-navigator-65f699786c-6sbxm from md-navigator started at 2020-02-06 18:11:28 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.527: INFO: 	Container moondog-navigator ready: true, restart count 0
Feb  6 20:30:40.527: INFO: md-loki-stack-promtail-wl8xd from md-loki-stack started at 2020-02-06 18:12:01 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.527: INFO: 	Container promtail ready: true, restart count 0
Feb  6 20:30:40.527: INFO: cm-acme-http-solver-tg7qw from md-dex started at 2020-02-06 18:12:35 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.527: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 20:30:40.528: INFO: md-prometheus-operator-prometheus-node-exporter-p52sm from md-prometheus-operator started at 2020-02-06 18:12:39 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.528: INFO: 	Container node-exporter ready: true, restart count 0
Feb  6 20:30:40.528: INFO: cm-acme-http-solver-nnxf2 from md-prometheus-operator started at 2020-02-06 19:07:48 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.528: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 20:30:40.528: INFO: cm-acme-http-solver-tmzk6 from md-prometheus-operator started at 2020-02-06 19:07:48 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.528: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 20:30:40.528: INFO: md-flux-memcached-77b577bb4c-z77xr from md-flux started at 2020-02-06 18:11:26 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.528: INFO: 	Container memcached ready: true, restart count 0
Feb  6 20:30:40.528: INFO: md-dex-bfbfd7887-c9sjp from md-dex started at 2020-02-06 18:11:32 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.528: INFO: 	Container main ready: true, restart count 1
Feb  6 20:30:40.528: INFO: md-gangway-548f557b49-v4cb5 from md-gangway started at 2020-02-06 18:11:59 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.528: INFO: 	Container gangway ready: true, restart count 0
Feb  6 20:30:40.528: INFO: md-nginx-ingress-default-backend-7d86d446b4-kp67r from md-nginx-ingress started at 2020-02-06 18:12:09 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.528: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
Feb  6 20:30:40.528: INFO: md-cert-manager-webhook-58b4496d5-lx8m5 from md-cert-manager started at 2020-02-06 19:07:33 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.528: INFO: 	Container cert-manager ready: true, restart count 0
Feb  6 20:30:40.528: INFO: md-prometheus-operator-grafana-6699695c84-cpjdc from md-prometheus-operator started at 2020-02-06 18:12:49 +0000 UTC (2 container statuses recorded)
Feb  6 20:30:40.528: INFO: 	Container grafana ready: true, restart count 0
Feb  6 20:30:40.528: INFO: 	Container grafana-sc-dashboard ready: true, restart count 0
Feb  6 20:30:40.528: INFO: cm-acme-http-solver-9f7tx from md-navigator started at 2020-02-06 19:07:48 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.528: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 20:30:40.528: INFO: calico-node-jcts8 from kube-system started at 2020-02-06 15:57:51 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.528: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 20:30:40.528: INFO: kube-proxy-zp49w from kube-system started at 2020-02-06 15:57:51 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.528: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  6 20:30:40.528: INFO: sonobuoy-systemd-logs-daemon-set-936a433795204ed3-fdsl7 from sonobuoy started at 2020-02-06 18:40:06 +0000 UTC (2 container statuses recorded)
Feb  6 20:30:40.528: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb  6 20:30:40.528: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 20:30:40.528: INFO: md-prometheus-operator-kube-state-metrics-b65d855df-b9v58 from md-prometheus-operator started at 2020-02-06 18:12:39 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.528: INFO: 	Container kube-state-metrics ready: true, restart count 0
Feb  6 20:30:40.528: INFO: cm-acme-http-solver-9nppr from md-gangway started at 2020-02-06 19:07:48 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.528: INFO: 	Container acmesolver ready: true, restart count 0
Feb  6 20:30:40.528: INFO: 
Logging pods the kubelet thinks is on node ip-10-10-3-246.ec2.internal before test
Feb  6 20:30:40.543: INFO: kube-proxy-jfqqq from kube-system started at 2020-02-06 15:57:51 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.543: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  6 20:30:40.543: INFO: md-loki-stack-promtail-2687p from md-loki-stack started at 2020-02-06 20:15:27 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.543: INFO: 	Container promtail ready: true, restart count 0
Feb  6 20:30:40.543: INFO: sonobuoy from sonobuoy started at 2020-02-06 18:40:05 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.543: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  6 20:30:40.543: INFO: sonobuoy-e2e-job-7dfb3a3ef75e43b0 from sonobuoy started at 2020-02-06 18:40:06 +0000 UTC (2 container statuses recorded)
Feb  6 20:30:40.543: INFO: 	Container e2e ready: true, restart count 0
Feb  6 20:30:40.543: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 20:30:40.543: INFO: sonobuoy-systemd-logs-daemon-set-936a433795204ed3-q2qnm from sonobuoy started at 2020-02-06 18:40:06 +0000 UTC (2 container statuses recorded)
Feb  6 20:30:40.543: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb  6 20:30:40.543: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 20:30:40.543: INFO: calico-node-n4lqx from kube-system started at 2020-02-06 15:57:51 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.543: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 20:30:40.543: INFO: md-prometheus-operator-prometheus-node-exporter-7x2lj from md-prometheus-operator started at 2020-02-06 20:15:31 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.543: INFO: 	Container node-exporter ready: true, restart count 0
Feb  6 20:30:40.543: INFO: md-oauth2-proxy-6559885d88-prwzt from md-oauth2-proxy started at 2020-02-06 20:26:54 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.543: INFO: 	Container oauth2-proxy ready: false, restart count 5
Feb  6 20:30:40.543: INFO: cm-acme-http-solver-np225 from md-oauth2-proxy started at 2020-02-06 20:27:32 +0000 UTC (1 container statuses recorded)
Feb  6 20:30:40.543: INFO: 	Container acmesolver ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-9dbf2fce-f90f-4aa3-8b43-1fd85fe15390 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-9dbf2fce-f90f-4aa3-8b43-1fd85fe15390 off the node ip-10-10-3-246.ec2.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-9dbf2fce-f90f-4aa3-8b43-1fd85fe15390
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:30:48.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1856" for this suite.
Feb  6 20:31:04.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:31:05.160: INFO: namespace sched-pred-1856 deletion completed in 16.476177177s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:24.861 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:31:05.160: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3463
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-e36013ab-e2ea-40bc-9e54-1451e9266be5
STEP: Creating a pod to test consume configMaps
Feb  6 20:31:05.321: INFO: Waiting up to 5m0s for pod "pod-configmaps-b1272793-3b40-4423-8e77-9270acf67627" in namespace "configmap-3463" to be "success or failure"
Feb  6 20:31:05.324: INFO: Pod "pod-configmaps-b1272793-3b40-4423-8e77-9270acf67627": Phase="Pending", Reason="", readiness=false. Elapsed: 2.777309ms
Feb  6 20:31:07.330: INFO: Pod "pod-configmaps-b1272793-3b40-4423-8e77-9270acf67627": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008323385s
STEP: Saw pod success
Feb  6 20:31:07.330: INFO: Pod "pod-configmaps-b1272793-3b40-4423-8e77-9270acf67627" satisfied condition "success or failure"
Feb  6 20:31:07.335: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-configmaps-b1272793-3b40-4423-8e77-9270acf67627 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 20:31:07.361: INFO: Waiting for pod pod-configmaps-b1272793-3b40-4423-8e77-9270acf67627 to disappear
Feb  6 20:31:07.365: INFO: Pod pod-configmaps-b1272793-3b40-4423-8e77-9270acf67627 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:31:07.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3463" for this suite.
Feb  6 20:31:13.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:31:13.844: INFO: namespace configmap-3463 deletion completed in 6.475042914s

• [SLOW TEST:8.685 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:31:13.845: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-756
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 20:31:14.003: INFO: Waiting up to 5m0s for pod "downwardapi-volume-df88240a-fabf-4d39-bc30-aa71f01e6009" in namespace "projected-756" to be "success or failure"
Feb  6 20:31:14.007: INFO: Pod "downwardapi-volume-df88240a-fabf-4d39-bc30-aa71f01e6009": Phase="Pending", Reason="", readiness=false. Elapsed: 3.640305ms
Feb  6 20:31:16.013: INFO: Pod "downwardapi-volume-df88240a-fabf-4d39-bc30-aa71f01e6009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009953424s
STEP: Saw pod success
Feb  6 20:31:16.013: INFO: Pod "downwardapi-volume-df88240a-fabf-4d39-bc30-aa71f01e6009" satisfied condition "success or failure"
Feb  6 20:31:16.019: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod downwardapi-volume-df88240a-fabf-4d39-bc30-aa71f01e6009 container client-container: <nil>
STEP: delete the pod
Feb  6 20:31:16.068: INFO: Waiting for pod downwardapi-volume-df88240a-fabf-4d39-bc30-aa71f01e6009 to disappear
Feb  6 20:31:16.072: INFO: Pod downwardapi-volume-df88240a-fabf-4d39-bc30-aa71f01e6009 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:31:16.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-756" for this suite.
Feb  6 20:31:22.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:31:22.554: INFO: namespace projected-756 deletion completed in 6.476732056s

• [SLOW TEST:8.710 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:31:22.555: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3728
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-9a8edf41-4936-48e9-98a5-1c8940be6fcd
STEP: Creating secret with name s-test-opt-upd-60870f8d-55bf-4681-9eb8-11da5be3f2f7
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-9a8edf41-4936-48e9-98a5-1c8940be6fcd
STEP: Updating secret s-test-opt-upd-60870f8d-55bf-4681-9eb8-11da5be3f2f7
STEP: Creating secret with name s-test-opt-create-941f21e3-0373-429a-919f-0c9782e20752
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:32:37.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3728" for this suite.
Feb  6 20:33:07.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:33:07.864: INFO: namespace projected-3728 deletion completed in 30.477778544s

• [SLOW TEST:105.310 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:33:07.864: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9349
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 20:33:08.022: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3f41fb7d-aab5-45b2-9e88-f8433480cab6" in namespace "downward-api-9349" to be "success or failure"
Feb  6 20:33:08.026: INFO: Pod "downwardapi-volume-3f41fb7d-aab5-45b2-9e88-f8433480cab6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.129103ms
Feb  6 20:33:10.030: INFO: Pod "downwardapi-volume-3f41fb7d-aab5-45b2-9e88-f8433480cab6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007930784s
STEP: Saw pod success
Feb  6 20:33:10.030: INFO: Pod "downwardapi-volume-3f41fb7d-aab5-45b2-9e88-f8433480cab6" satisfied condition "success or failure"
Feb  6 20:33:10.033: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod downwardapi-volume-3f41fb7d-aab5-45b2-9e88-f8433480cab6 container client-container: <nil>
STEP: delete the pod
Feb  6 20:33:10.052: INFO: Waiting for pod downwardapi-volume-3f41fb7d-aab5-45b2-9e88-f8433480cab6 to disappear
Feb  6 20:33:10.074: INFO: Pod downwardapi-volume-3f41fb7d-aab5-45b2-9e88-f8433480cab6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:33:10.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9349" for this suite.
Feb  6 20:33:16.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:33:16.558: INFO: namespace downward-api-9349 deletion completed in 6.477199951s

• [SLOW TEST:8.693 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:33:16.558: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1315
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:33:23.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1315" for this suite.
Feb  6 20:33:29.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:33:30.196: INFO: namespace resourcequota-1315 deletion completed in 6.474972961s

• [SLOW TEST:13.638 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:33:30.196: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-9005
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-9005, will wait for the garbage collector to delete the pods
Feb  6 20:33:32.419: INFO: Deleting Job.batch foo took: 7.799942ms
Feb  6 20:33:33.119: INFO: Terminating Job.batch foo pods took: 700.234413ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:34:11.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9005" for this suite.
Feb  6 20:34:17.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:34:17.902: INFO: namespace job-9005 deletion completed in 6.474905117s

• [SLOW TEST:47.706 seconds]
[sig-apps] Job
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:34:17.902: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6320
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb  6 20:34:18.077: INFO: Waiting up to 5m0s for pod "pod-2d7ca42b-92fb-4301-aabd-f5eede29bbf7" in namespace "emptydir-6320" to be "success or failure"
Feb  6 20:34:18.081: INFO: Pod "pod-2d7ca42b-92fb-4301-aabd-f5eede29bbf7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.213305ms
Feb  6 20:34:20.085: INFO: Pod "pod-2d7ca42b-92fb-4301-aabd-f5eede29bbf7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007918228s
STEP: Saw pod success
Feb  6 20:34:20.085: INFO: Pod "pod-2d7ca42b-92fb-4301-aabd-f5eede29bbf7" satisfied condition "success or failure"
Feb  6 20:34:20.087: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-2d7ca42b-92fb-4301-aabd-f5eede29bbf7 container test-container: <nil>
STEP: delete the pod
Feb  6 20:34:20.106: INFO: Waiting for pod pod-2d7ca42b-92fb-4301-aabd-f5eede29bbf7 to disappear
Feb  6 20:34:20.109: INFO: Pod pod-2d7ca42b-92fb-4301-aabd-f5eede29bbf7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:34:20.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6320" for this suite.
Feb  6 20:34:26.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:34:26.597: INFO: namespace emptydir-6320 deletion completed in 6.482888666s

• [SLOW TEST:8.695 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:34:26.598: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5709
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Feb  6 20:34:32.789: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:34:32.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0206 20:34:32.789843      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-5709" for this suite.
Feb  6 20:34:40.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:34:41.305: INFO: namespace gc-5709 deletion completed in 8.497916877s

• [SLOW TEST:14.708 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:34:41.306: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2885
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 20:34:41.461: INFO: Waiting up to 5m0s for pod "downwardapi-volume-36785799-6cba-42e3-8841-53f276f53be1" in namespace "downward-api-2885" to be "success or failure"
Feb  6 20:34:41.465: INFO: Pod "downwardapi-volume-36785799-6cba-42e3-8841-53f276f53be1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.2165ms
Feb  6 20:34:43.468: INFO: Pod "downwardapi-volume-36785799-6cba-42e3-8841-53f276f53be1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00681081s
STEP: Saw pod success
Feb  6 20:34:43.468: INFO: Pod "downwardapi-volume-36785799-6cba-42e3-8841-53f276f53be1" satisfied condition "success or failure"
Feb  6 20:34:43.471: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod downwardapi-volume-36785799-6cba-42e3-8841-53f276f53be1 container client-container: <nil>
STEP: delete the pod
Feb  6 20:34:43.499: INFO: Waiting for pod downwardapi-volume-36785799-6cba-42e3-8841-53f276f53be1 to disappear
Feb  6 20:34:43.502: INFO: Pod downwardapi-volume-36785799-6cba-42e3-8841-53f276f53be1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:34:43.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2885" for this suite.
Feb  6 20:34:49.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:34:49.982: INFO: namespace downward-api-2885 deletion completed in 6.475711694s

• [SLOW TEST:8.677 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:34:49.983: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5902
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb  6 20:34:50.138: INFO: Waiting up to 5m0s for pod "pod-2f5e8604-a37c-4b05-be93-75e3f26a1286" in namespace "emptydir-5902" to be "success or failure"
Feb  6 20:34:50.141: INFO: Pod "pod-2f5e8604-a37c-4b05-be93-75e3f26a1286": Phase="Pending", Reason="", readiness=false. Elapsed: 3.10714ms
Feb  6 20:34:52.144: INFO: Pod "pod-2f5e8604-a37c-4b05-be93-75e3f26a1286": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006682268s
STEP: Saw pod success
Feb  6 20:34:52.144: INFO: Pod "pod-2f5e8604-a37c-4b05-be93-75e3f26a1286" satisfied condition "success or failure"
Feb  6 20:34:52.148: INFO: Trying to get logs from node ip-10-10-3-246.ec2.internal pod pod-2f5e8604-a37c-4b05-be93-75e3f26a1286 container test-container: <nil>
STEP: delete the pod
Feb  6 20:34:52.169: INFO: Waiting for pod pod-2f5e8604-a37c-4b05-be93-75e3f26a1286 to disappear
Feb  6 20:34:52.175: INFO: Pod pod-2f5e8604-a37c-4b05-be93-75e3f26a1286 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:34:52.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5902" for this suite.
Feb  6 20:34:58.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:34:58.656: INFO: namespace emptydir-5902 deletion completed in 6.476285128s

• [SLOW TEST:8.674 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:34:58.656: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6315
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb  6 20:34:58.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-6315'
Feb  6 20:34:58.887: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  6 20:34:58.887: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Feb  6 20:35:02.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481697501 delete deployment e2e-test-httpd-deployment --namespace=kubectl-6315'
Feb  6 20:35:02.993: INFO: stderr: ""
Feb  6 20:35:02.993: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:35:02.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6315" for this suite.
Feb  6 20:35:09.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:35:09.481: INFO: namespace kubectl-6315 deletion completed in 6.482406049s

• [SLOW TEST:10.825 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 20:35:09.481: INFO: >>> kubeConfig: /tmp/kubeconfig-481697501
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-5186
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 20:35:09.642: INFO: Waiting up to 5m0s for pod "busybox-user-65534-4724467b-75ca-4b60-90d4-8d9537ad32e1" in namespace "security-context-test-5186" to be "success or failure"
Feb  6 20:35:09.646: INFO: Pod "busybox-user-65534-4724467b-75ca-4b60-90d4-8d9537ad32e1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.141483ms
Feb  6 20:35:11.653: INFO: Pod "busybox-user-65534-4724467b-75ca-4b60-90d4-8d9537ad32e1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011320298s
Feb  6 20:35:11.653: INFO: Pod "busybox-user-65534-4724467b-75ca-4b60-90d4-8d9537ad32e1" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 20:35:11.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5186" for this suite.
Feb  6 20:35:17.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 20:35:18.145: INFO: namespace security-context-test-5186 deletion completed in 6.482874674s

• [SLOW TEST:8.664 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.5-beta.1.51+e7f962ba86f4ce/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SFeb  6 20:35:18.145: INFO: Running AfterSuite actions on all nodes
Feb  6 20:35:18.145: INFO: Running AfterSuite actions on node 1
Feb  6 20:35:18.145: INFO: Skipping dumping logs from cluster

Ran 276 of 4731 Specs in 6894.198 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Pending | 4455 Skipped
PASS

Ginkgo ran 1 suite in 1h54m55.741538758s
Test Suite Passed
